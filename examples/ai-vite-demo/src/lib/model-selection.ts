import { OPENAI_CHAT_MODELS } from '@/lib/generated'
import type { OpenAIChatModel } from '@/lib/generated'

export type Provider =
  | 'openai'
  | 'anthropic'
  | 'gemini'
  | 'ollama'
  | 'grok'
  | 'openrouter'

export interface ModelOption {
  provider: Provider
  model: string
  label: string
}

/**
 * Build OpenAI model options from the generated model list.
 * The ai-vite plugin fetches these from the OpenAI /v1/models endpoint
 * so they're always up to date.
 */
function buildOpenAIModelOptions(): Array<ModelOption> {
  return OPENAI_CHAT_MODELS.map((model: OpenAIChatModel) => ({
    provider: 'openai' as const,
    model,
    label: `OpenAI - ${model}`,
  }))
}

export const MODEL_OPTIONS: Array<ModelOption> = [
  // OpenAI - dynamically generated by @tanstack/ai-vite
  ...buildOpenAIModelOptions(),

  // Anthropic
  {
    provider: 'anthropic',
    model: 'claude-sonnet-4-5-20250929',
    label: 'Anthropic - Claude Sonnet 4.5',
  },
  {
    provider: 'anthropic',
    model: 'claude-opus-4-5-20251101',
    label: 'Anthropic - Claude Opus 4.5',
  },
  {
    provider: 'anthropic',
    model: 'claude-haiku-4-0-20250514',
    label: 'Anthropic - Claude Haiku 4.0',
  },

  // Gemini
  {
    provider: 'gemini',
    model: 'gemini-2.0-flash',
    label: 'Gemini - 2.0 Flash',
  },
  {
    provider: 'gemini',
    model: 'gemini-2.5-flash',
    label: 'Gemini - 2.5 Flash',
  },
  {
    provider: 'gemini',
    model: 'gemini-2.5-pro',
    label: 'Gemini - 2.5 Pro',
  },

  // Openrouter
  {
    provider: 'openrouter',
    model: 'openai/chatgpt-4o-latest',
    label: 'Openrouter - ChatGPT 4o Latest',
  },
  {
    provider: 'openrouter',
    model: 'openai/chatgpt-4o-mini',
    label: 'Openrouter - ChatGPT 4o Mini',
  },

  // Ollama
  {
    provider: 'ollama',
    model: 'mistral:7b',
    label: 'Ollama - Mistral 7B',
  },
  {
    provider: 'ollama',
    model: 'mistral',
    label: 'Ollama - Mistral',
  },
  {
    provider: 'ollama',
    model: 'gpt-oss:20b',
    label: 'Ollama - GPT-OSS 20B',
  },
  {
    provider: 'ollama',
    model: 'granite4:3b',
    label: 'Ollama - Granite4 3B',
  },
  {
    provider: 'ollama',
    model: 'smollm',
    label: 'Ollama - SmolLM',
  },

  // Grok
  {
    provider: 'grok',
    model: 'grok-4',
    label: 'Grok - Grok 4',
  },
  {
    provider: 'grok',
    model: 'grok-4-fast-non-reasoning',
    label: 'Grok - Grok 4 Fast',
  },
  {
    provider: 'grok',
    model: 'grok-3',
    label: 'Grok - Grok 3',
  },
  {
    provider: 'grok',
    model: 'grok-3-mini',
    label: 'Grok - Grok 3 Mini',
  },
]

export const DEFAULT_MODEL_OPTION = MODEL_OPTIONS[0]
