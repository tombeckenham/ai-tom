import { useState } from 'react'

// These types are generated by @tanstack/ai-vite when the dev server starts.
// If `src/generated/` doesn't exist yet, run `pnpm dev` to trigger codegen.
// import { OPENAI_CHAT_MODELS, type OpenAIChatModel } from './generated'

// For demonstration purposes, we use a small hardcoded list as a fallback.
// In a real project, you'd import from './generated' after the plugin runs.
const DEMO_MODELS = ['gpt-4o', 'gpt-4o-mini', 'gpt-4.1-mini'] as const

export function App() {
  const [selectedModel, setSelectedModel] = useState<string>(DEMO_MODELS[0])

  return (
    <div
      style={{
        fontFamily: 'system-ui, sans-serif',
        maxWidth: 600,
        margin: '2rem auto',
        padding: '0 1rem',
      }}
    >
      <h1>TanStack AI Vite Plugin Demo</h1>
      <p>
        This example demonstrates the <code>@tanstack/ai-vite</code> plugin
        generating model types from the OpenAI API.
      </p>

      <section style={{ marginTop: '1.5rem' }}>
        <h2>Model Selector</h2>
        <label
          htmlFor="model-select"
          style={{ display: 'block', marginBottom: '0.5rem' }}
        >
          Choose a model:
        </label>
        <select
          id="model-select"
          value={selectedModel}
          onChange={(e) => setSelectedModel(e.target.value)}
          style={{ padding: '0.5rem', fontSize: '1rem', width: '100%' }}
        >
          {DEMO_MODELS.map((model) => (
            <option key={model} value={model}>
              {model}
            </option>
          ))}
        </select>
      </section>

      <section style={{ marginTop: '1.5rem' }}>
        <h2>Selected Model</h2>
        <pre
          style={{
            background: '#f5f5f5',
            padding: '1rem',
            borderRadius: 8,
            overflow: 'auto',
          }}
        >
          {selectedModel}
        </pre>
        <p style={{ color: '#666', fontSize: '0.875rem' }}>
          In a real app, you'd pass this to{' '}
          <code>openaiText(selectedModel)</code> on the server side.
        </p>
      </section>

      <section
        style={{ marginTop: '1.5rem', color: '#666', fontSize: '0.875rem' }}
      >
        <h2 style={{ color: '#333', fontSize: '1.25rem' }}>How it works</h2>
        <ol style={{ lineHeight: 1.8 }}>
          <li>
            The <code>@tanstack/ai-vite</code> plugin runs at dev server start
          </li>
          <li>
            It downloads the OpenAI spec and generates TypeScript types in{' '}
            <code>src/generated/</code>
          </li>
          <li>
            If <code>OPENAI_API_KEY</code> is set (in <code>.env.local</code> or
            env), it also fetches live model names and generates a type-safe
            union
          </li>
          <li>
            Import <code>OpenAIChatModel</code> from{' '}
            <code>./generated</code> and use it with{' '}
            <code>openaiText()</code> for full autocomplete
          </li>
        </ol>
      </section>
    </div>
  )
}
