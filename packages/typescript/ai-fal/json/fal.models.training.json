{
  "generated_at": "2026-01-28T02:51:51.856Z",
  "total_models": 35,
  "category": "training",
  "models": [
    {
      "endpoint_id": "fal-ai/flux-krea-trainer",
      "metadata": {
        "display_name": "Train Flux Krea LoRA",
        "category": "training",
        "description": "Train styles, people and other subjects at blazing speeds using the FLUX.1 Krea [dev] base model.",
        "status": "active",
        "tags": [
          "lora",
          "personalization"
        ],
        "updated_at": "2026-01-26T21:43:08.430Z",
        "is_favorited": false,
        "thumbnail_url": "https://v3.fal.media/files/rabbit/uKINGMekBEYrVNUULujts_RVU-Kvlhsr5rEwqG7Uc-s_56e80afe7c1243d5a2f5eed5868ae63d.jpg",
        "model_url": "https://fal.run/fal-ai/flux-krea-trainer",
        "license_type": "commercial",
        "date": "2025-08-01T23:43:35.378Z",
        "highlighted": true,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/flux-krea-lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/flux-krea-trainer",
          "version": "1.0.0",
          "description": "The OpenAPI schema for the fal-ai/flux-krea-trainer queue.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/flux-krea-trainer",
            "category": "training",
            "thumbnailUrl": "https://v3.fal.media/files/rabbit/uKINGMekBEYrVNUULujts_RVU-Kvlhsr5rEwqG7Uc-s_56e80afe7c1243d5a2f5eed5868ae63d.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/flux-krea-trainer",
            "documentationUrl": "https://fal.ai/models/fal-ai/flux-krea-trainer/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "FluxKreaTrainerInput": {
              "title": "PublicInput",
              "type": "object",
              "properties": {
                "images_data_url": {
                  "title": "Images Data Url",
                  "type": "string",
                  "description": "\n        URL to zip archive with images. Try to use at least 4 images in general the more the better.\n\n        In addition to images the archive can contain text files with captions. Each text file should have the same name as the image file it corresponds to.\n    "
                },
                "is_input_format_already_preprocessed": {
                  "title": "Is Input Format Already Preprocessed",
                  "type": "boolean",
                  "description": "Specifies whether the input data is already in a processed format. When set to False (default), the system expects raw input where image files and their corresponding caption files share the same name (e.g., 'photo.jpg' and 'photo.txt'). Set to True if your data is already in a preprocessed format.",
                  "default": false
                },
                "trigger_word": {
                  "title": "Trigger Word",
                  "type": "string",
                  "description": "Trigger word to be used in the captions. If None, a trigger word will not be used.\n        If no captions are provide the trigger_word will be used instead of captions. If captions are the trigger word will not be used.\n        ",
                  "nullable": true
                },
                "steps": {
                  "description": "Number of steps to train the LoRA on.",
                  "type": "integer",
                  "examples": [
                    1000
                  ],
                  "maximum": 10000,
                  "title": "Steps",
                  "minimum": 1
                },
                "data_archive_format": {
                  "title": "Data Archive Format",
                  "type": "string",
                  "description": "The format of the archive. If not specified, the format will be inferred from the URL.",
                  "nullable": true
                },
                "is_style": {
                  "title": "Is Style",
                  "type": "boolean",
                  "description": "If True, the training will be for a style. This will deactivate segmentation, captioning and will use trigger word instead. Use the trigger word to specify the style.",
                  "default": false
                },
                "create_masks": {
                  "title": "Create Masks",
                  "type": "boolean",
                  "description": "If True segmentation masks will be used in the weight the training loss. For people a face mask is used if possible.",
                  "default": true
                }
              },
              "x-fal-order-properties": [
                "images_data_url",
                "trigger_word",
                "create_masks",
                "steps",
                "is_style",
                "is_input_format_already_preprocessed",
                "data_archive_format"
              ],
              "required": [
                "images_data_url"
              ]
            },
            "FluxKreaTrainerOutput": {
              "title": "Output",
              "type": "object",
              "properties": {
                "config_file": {
                  "title": "Config File",
                  "description": "URL to the training configuration file.",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                },
                "debug_preprocessed_output": {
                  "title": "Debug Preprocessed Output",
                  "description": "URL to the preprocessed images.",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                },
                "diffusers_lora_file": {
                  "title": "Diffusers Lora File",
                  "description": "URL to the trained diffusers lora weights.",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                }
              },
              "x-fal-order-properties": [
                "diffusers_lora_file",
                "config_file",
                "debug_preprocessed_output"
              ],
              "required": [
                "diffusers_lora_file",
                "config_file"
              ]
            },
            "File": {
              "title": "File",
              "type": "object",
              "properties": {
                "file_size": {
                  "examples": [
                    4404019
                  ],
                  "title": "File Size",
                  "type": "integer",
                  "description": "The size of the file in bytes."
                },
                "file_name": {
                  "examples": [
                    "z9RV14K95DvU.png"
                  ],
                  "title": "File Name",
                  "type": "string",
                  "description": "The name of the file. It will be auto-generated if not provided."
                },
                "content_type": {
                  "examples": [
                    "image/png"
                  ],
                  "title": "Content Type",
                  "type": "string",
                  "description": "The mime type of the file."
                },
                "url": {
                  "title": "Url",
                  "type": "string",
                  "description": "The URL where the file can be downloaded from."
                },
                "file_data": {
                  "format": "binary",
                  "title": "File Data",
                  "type": "string",
                  "description": "File data"
                }
              },
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size",
                "file_data"
              ],
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/flux-krea-trainer/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-krea-trainer/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-krea-trainer": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/FluxKreaTrainerInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-krea-trainer/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/FluxKreaTrainerOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/flux-kontext-trainer",
      "metadata": {
        "display_name": "Flux Kontext Trainer",
        "category": "training",
        "description": "LoRA trainer for FLUX.1 Kontext [dev]",
        "status": "active",
        "tags": [],
        "updated_at": "2026-01-26T21:43:23.103Z",
        "is_favorited": false,
        "thumbnail_url": "https://v3.fal.media/files/monkey/pYXiffttc2Skv36wflufu_dec4efe0d27e4527b64acfbc0e91536a.jpg",
        "model_url": "https://fal.run/fal-ai/flux-kontext-trainer",
        "license_type": "commercial",
        "date": "2025-06-26T13:55:28.583Z",
        "highlighted": true,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/flux-kontext-lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/flux-kontext-trainer",
          "version": "1.0.0",
          "description": "LoRA trainer for FLUX.1 Kontext [dev]. Train custom LoRAs to extend the image editing functionality of FLUX.1 Kontext [dev]",
          "x-fal-metadata": {
            "endpointId": "fal-ai/flux-kontext-trainer",
            "category": "training",
            "thumbnailUrl": "https://v3.fal.media/files/monkey/pYXiffttc2Skv36wflufu_dec4efe0d27e4527b64acfbc0e91536a.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/flux-kontext-trainer",
            "documentationUrl": "https://fal.ai/models/fal-ai/flux-kontext-trainer/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "FluxKontextTrainerInput": {
              "title": "Input",
              "type": "object",
              "properties": {
                "steps": {
                  "description": "Number of steps to train for",
                  "type": "integer",
                  "minimum": 2,
                  "maximum": 10000,
                  "title": "Steps",
                  "default": 1000
                },
                "image_data_url": {
                  "title": "Image Data Url",
                  "type": "string",
                  "description": "\n        URL to the input data zip archive.\n\n        The zip should contain pairs of images. The images should be named:\n\n        ROOT_start.EXT and ROOT_end.EXT\n        For example:\n        photo_start.jpg and photo_end.jpg\n\n        The zip can also contain a text file for each image pair. The text file should be named:\n        ROOT.txt\n        For example:\n        photo.txt\n\n        This text file can be used to specify the edit instructions for the image pair.\n\n        If no text file is provided, the default_caption will be used.\n\n        If no default_caption is provided, the training will fail.\n        "
                },
                "learning_rate": {
                  "title": "Learning Rate",
                  "type": "number",
                  "default": 0.0001
                },
                "default_caption": {
                  "title": "Default Caption",
                  "type": "string",
                  "description": "Default caption to use when caption files are missing. If None, missing captions will cause an error."
                },
                "output_lora_format": {
                  "enum": [
                    "fal",
                    "comfy"
                  ],
                  "title": "Output Lora Format",
                  "type": "string",
                  "description": "Dictates the naming scheme for the output weights",
                  "default": "fal"
                }
              },
              "x-fal-order-properties": [
                "image_data_url",
                "steps",
                "learning_rate",
                "default_caption",
                "output_lora_format"
              ],
              "required": [
                "image_data_url"
              ]
            },
            "FluxKontextTrainerOutput": {
              "title": "Output",
              "type": "object",
              "properties": {
                "config_file": {
                  "title": "Config File",
                  "description": "URL to the configuration file for the trained model.",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                },
                "diffusers_lora_file": {
                  "title": "Diffusers Lora File",
                  "description": "URL to the trained diffusers lora weights.",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                }
              },
              "x-fal-order-properties": [
                "diffusers_lora_file",
                "config_file"
              ],
              "required": [
                "diffusers_lora_file",
                "config_file"
              ]
            },
            "File": {
              "title": "File",
              "type": "object",
              "properties": {
                "file_size": {
                  "examples": [
                    4404019
                  ],
                  "title": "File Size",
                  "type": "integer",
                  "description": "The size of the file in bytes."
                },
                "file_name": {
                  "examples": [
                    "z9RV14K95DvU.png"
                  ],
                  "title": "File Name",
                  "type": "string",
                  "description": "The name of the file. It will be auto-generated if not provided."
                },
                "content_type": {
                  "examples": [
                    "image/png"
                  ],
                  "title": "Content Type",
                  "type": "string",
                  "description": "The mime type of the file."
                },
                "url": {
                  "title": "Url",
                  "type": "string",
                  "description": "The URL where the file can be downloaded from."
                },
                "file_data": {
                  "format": "binary",
                  "title": "File Data",
                  "type": "string",
                  "description": "File data"
                }
              },
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size",
                "file_data"
              ],
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/flux-kontext-trainer/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-kontext-trainer/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-kontext-trainer": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/FluxKontextTrainerInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-kontext-trainer/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/FluxKontextTrainerOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/flux-lora-fast-training",
      "metadata": {
        "display_name": "Train Flux LoRA",
        "category": "training",
        "description": "Train styles, people and other subjects at blazing speeds.",
        "status": "active",
        "tags": [
          "lora",
          "personalization"
        ],
        "updated_at": "2026-01-26T21:44:09.199Z",
        "is_favorited": false,
        "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/video-training.webp",
        "model_url": "https://fal.run/fal-ai/flux-lora-fast-training",
        "license_type": "commercial",
        "date": "2025-01-01T00:00:00.000Z",
        "highlighted": true,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/flux-lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/flux-lora-fast-training",
          "version": "1.0.0",
          "description": "The OpenAPI schema for the fal-ai/flux-lora-fast-training queue.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/flux-lora-fast-training",
            "category": "training",
            "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/video-training.webp",
            "playgroundUrl": "https://fal.ai/models/fal-ai/flux-lora-fast-training",
            "documentationUrl": "https://fal.ai/models/fal-ai/flux-lora-fast-training/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "FluxLoraFastTrainingInput": {
              "title": "PublicInput",
              "type": "object",
              "properties": {
                "images_data_url": {
                  "title": "Images Data Url",
                  "type": "string",
                  "description": "\n        URL to zip archive with images. Try to use at least 4 images in general the more the better.\n\n        In addition to images the archive can contain text files with captions. Each text file should have the same name as the image file it corresponds to.\n    "
                },
                "is_input_format_already_preprocessed": {
                  "title": "Is Input Format Already Preprocessed",
                  "type": "boolean",
                  "description": "Specifies whether the input data is already in a processed format. When set to False (default), the system expects raw input where image files and their corresponding caption files share the same name (e.g., 'photo.jpg' and 'photo.txt'). Set to True if your data is already in a preprocessed format.",
                  "default": false
                },
                "trigger_word": {
                  "title": "Trigger Word",
                  "type": "string",
                  "description": "Trigger word to be used in the captions. If None, a trigger word will not be used.\n        If no captions are provide the trigger_word will be used instead of captions. If captions are the trigger word will not be used.\n        ",
                  "nullable": true
                },
                "steps": {
                  "description": "Number of steps to train the LoRA on.",
                  "type": "integer",
                  "minimum": 1,
                  "maximum": 10000,
                  "examples": [
                    1000
                  ],
                  "title": "Steps"
                },
                "data_archive_format": {
                  "title": "Data Archive Format",
                  "type": "string",
                  "description": "The format of the archive. If not specified, the format will be inferred from the URL.",
                  "nullable": true
                },
                "is_style": {
                  "title": "Is Style",
                  "type": "boolean",
                  "description": "If True, the training will be for a style. This will deactivate segmentation, captioning and will use trigger word instead. Use the trigger word to specify the style.",
                  "default": false
                },
                "create_masks": {
                  "title": "Create Masks",
                  "type": "boolean",
                  "description": "If True segmentation masks will be used in the weight the training loss. For people a face mask is used if possible.",
                  "default": true
                }
              },
              "x-fal-order-properties": [
                "images_data_url",
                "trigger_word",
                "create_masks",
                "steps",
                "is_style",
                "is_input_format_already_preprocessed",
                "data_archive_format"
              ],
              "required": [
                "images_data_url"
              ]
            },
            "FluxLoraFastTrainingOutput": {
              "title": "Output",
              "type": "object",
              "properties": {
                "config_file": {
                  "title": "Config File",
                  "description": "URL to the training configuration file.",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                },
                "debug_preprocessed_output": {
                  "title": "Debug Preprocessed Output",
                  "description": "URL to the preprocessed images.",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                },
                "diffusers_lora_file": {
                  "title": "Diffusers Lora File",
                  "description": "URL to the trained diffusers lora weights.",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                }
              },
              "x-fal-order-properties": [
                "diffusers_lora_file",
                "config_file",
                "debug_preprocessed_output"
              ],
              "required": [
                "diffusers_lora_file",
                "config_file"
              ]
            },
            "File": {
              "title": "File",
              "type": "object",
              "properties": {
                "file_size": {
                  "examples": [
                    4404019
                  ],
                  "title": "File Size",
                  "type": "integer",
                  "description": "The size of the file in bytes."
                },
                "file_name": {
                  "examples": [
                    "z9RV14K95DvU.png"
                  ],
                  "title": "File Name",
                  "type": "string",
                  "description": "The name of the file. It will be auto-generated if not provided."
                },
                "content_type": {
                  "examples": [
                    "image/png"
                  ],
                  "title": "Content Type",
                  "type": "string",
                  "description": "The mime type of the file."
                },
                "url": {
                  "title": "Url",
                  "type": "string",
                  "description": "The URL where the file can be downloaded from."
                },
                "file_data": {
                  "format": "binary",
                  "title": "File Data",
                  "type": "string",
                  "description": "File data"
                }
              },
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size",
                "file_data"
              ],
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/flux-lora-fast-training/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-lora-fast-training/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-lora-fast-training": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/FluxLoraFastTrainingInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-lora-fast-training/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/FluxLoraFastTrainingOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/flux-lora-portrait-trainer",
      "metadata": {
        "display_name": "Train Flux LoRAs For Portraits",
        "category": "training",
        "description": "FLUX LoRA training optimized for portrait generation, with bright highlights, excellent prompt following and highly detailed results.",
        "status": "active",
        "tags": [
          "lora",
          "personalization"
        ],
        "updated_at": "2026-01-26T21:44:11.904Z",
        "is_favorited": false,
        "thumbnail_url": "https://fal.media/files/rabbit/kh3cW2FXV5m3jigGYxcVU_3657df3e2e324e628af565129148736d.jpg",
        "model_url": "https://fal.run/fal-ai/flux-lora-portrait-trainer",
        "license_type": "commercial",
        "date": "2024-11-07T00:00:00.000Z",
        "highlighted": true,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/flux-lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/flux-lora-portrait-trainer",
          "version": "1.0.0",
          "description": "The OpenAPI schema for the fal-ai/flux-lora-portrait-trainer queue.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/flux-lora-portrait-trainer",
            "category": "training",
            "thumbnailUrl": "https://fal.media/files/rabbit/kh3cW2FXV5m3jigGYxcVU_3657df3e2e324e628af565129148736d.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/flux-lora-portrait-trainer",
            "documentationUrl": "https://fal.ai/models/fal-ai/flux-lora-portrait-trainer/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "FluxLoraPortraitTrainerInput": {
              "title": "PublicInput",
              "type": "object",
              "properties": {
                "images_data_url": {
                  "description": "\n        URL to zip archive with images of a consistent style. Try to use at least 10 images, although more is better.\n\n        In addition to images the archive can contain text files with captions. Each text file should have the same name as the image file it corresponds to.\n\n        The captions can include a special string `[trigger]`. If a trigger_word is specified, it will replace `[trigger]` in the captions.\n    ",
                  "type": "string",
                  "title": "Images Data Url"
                },
                "trigger_phrase": {
                  "description": "Trigger phrase to be used in the captions. If None, a trigger word will not be used.\n        If no captions are provide the trigger_work will be used instead of captions. If captions are provided, the trigger word will replace the `[trigger]` string in the captions.\n        ",
                  "type": "string",
                  "title": "Trigger Phrase",
                  "nullable": true
                },
                "resume_from_checkpoint": {
                  "description": "URL to a checkpoint to resume training from.",
                  "type": "string",
                  "title": "Resume From Checkpoint",
                  "default": ""
                },
                "subject_crop": {
                  "examples": [
                    true
                  ],
                  "description": "If True, the subject will be cropped from the image.",
                  "type": "boolean",
                  "title": "Subject Crop",
                  "default": true
                },
                "learning_rate": {
                  "description": "Learning rate to use for training.",
                  "type": "number",
                  "minimum": 0.000001,
                  "maximum": 0.001,
                  "title": "Learning Rate",
                  "examples": [
                    0.0002
                  ],
                  "default": 0.00009
                },
                "multiresolution_training": {
                  "examples": [
                    true
                  ],
                  "description": "If True, multiresolution training will be used.",
                  "type": "boolean",
                  "title": "Multiresolution Training",
                  "default": true
                },
                "steps": {
                  "description": "Number of steps to train the LoRA on.",
                  "type": "integer",
                  "minimum": 1,
                  "maximum": 10000,
                  "title": "Steps",
                  "examples": [
                    1000
                  ],
                  "default": 2500
                },
                "data_archive_format": {
                  "description": "The format of the archive. If not specified, the format will be inferred from the URL.",
                  "type": "string",
                  "title": "Data Archive Format",
                  "nullable": true
                },
                "create_masks": {
                  "examples": [
                    false
                  ],
                  "description": "If True, masks will be created for the subject.",
                  "type": "boolean",
                  "title": "Create Masks",
                  "default": false
                }
              },
              "x-fal-order-properties": [
                "images_data_url",
                "trigger_phrase",
                "learning_rate",
                "steps",
                "multiresolution_training",
                "subject_crop",
                "data_archive_format",
                "resume_from_checkpoint",
                "create_masks"
              ],
              "required": [
                "images_data_url"
              ]
            },
            "FluxLoraPortraitTrainerOutput": {
              "title": "Output",
              "type": "object",
              "properties": {
                "config_file": {
                  "description": "URL to the training configuration file.",
                  "title": "Config File",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                },
                "diffusers_lora_file": {
                  "description": "URL to the trained diffusers lora weights.",
                  "title": "Diffusers Lora File",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                }
              },
              "x-fal-order-properties": [
                "diffusers_lora_file",
                "config_file"
              ],
              "required": [
                "diffusers_lora_file",
                "config_file"
              ]
            },
            "File": {
              "title": "File",
              "type": "object",
              "properties": {
                "file_size": {
                  "examples": [
                    4404019
                  ],
                  "description": "The size of the file in bytes.",
                  "type": "integer",
                  "title": "File Size"
                },
                "file_name": {
                  "examples": [
                    "z9RV14K95DvU.png"
                  ],
                  "description": "The name of the file. It will be auto-generated if not provided.",
                  "type": "string",
                  "title": "File Name"
                },
                "content_type": {
                  "examples": [
                    "image/png"
                  ],
                  "description": "The mime type of the file.",
                  "type": "string",
                  "title": "Content Type"
                },
                "url": {
                  "description": "The URL where the file can be downloaded from.",
                  "type": "string",
                  "title": "Url"
                },
                "file_data": {
                  "format": "binary",
                  "description": "File data",
                  "type": "string",
                  "title": "File Data"
                }
              },
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size",
                "file_data"
              ],
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/flux-lora-portrait-trainer/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-lora-portrait-trainer/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-lora-portrait-trainer": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/FluxLoraPortraitTrainerInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-lora-portrait-trainer/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/FluxLoraPortraitTrainerOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/z-image-base-trainer",
      "metadata": {
        "display_name": "Z-Image Trainer",
        "category": "training",
        "description": "Fast LoRA trainer for Z-Image, a super fast text-to-image model of 6B parameters developed by Tongyi-MAI.",
        "status": "active",
        "tags": [
          "lora",
          "personalization",
          "trainer"
        ],
        "updated_at": "2026-01-27T22:58:54.194Z",
        "is_favorited": false,
        "thumbnail_url": "https://v3b.fal.media/files/b/0a8c1e96/pZXwtJOoyFLNKCmXZo865_a1f570b30c7140379cac4faa237a6619.jpg",
        "model_url": "https://fal.run/fal-ai/z-image-base-trainer",
        "license_type": "commercial",
        "date": "2026-01-27T21:47:15.156Z",
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/z-image/base/lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/z-image-base-trainer",
          "version": "1.0.0",
          "description": "The OpenAPI schema for the fal-ai/z-image-base-trainer queue.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/z-image-base-trainer",
            "category": "training",
            "thumbnailUrl": "https://v3b.fal.media/files/b/0a8c1e96/pZXwtJOoyFLNKCmXZo865_a1f570b30c7140379cac4faa237a6619.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/z-image-base-trainer",
            "documentationUrl": "https://fal.ai/models/fal-ai/z-image-base-trainer/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "ZImageBaseTrainerInput": {
              "x-fal-order-properties": [
                "image_data_url",
                "steps",
                "default_caption",
                "learning_rate"
              ],
              "type": "object",
              "properties": {
                "steps": {
                  "description": "Number of steps to train for",
                  "type": "integer",
                  "minimum": 10,
                  "maximum": 40000,
                  "title": "Steps",
                  "default": 2000
                },
                "image_data_url": {
                  "description": "\n        URL to the input data zip archive.\n\n        The zip should contain pairs of images and corresponding captions.\n\n        The images should be named: ROOT.EXT. For example: 001.jpg\n\n        The corresponding captions should be named: ROOT.txt. For example: 001.txt\n\n        If no text file is provided for an image, the default_caption will be used.\n        ",
                  "type": "string",
                  "title": "Image Data Url"
                },
                "learning_rate": {
                  "description": "Learning rate.",
                  "type": "number",
                  "title": "Learning Rate",
                  "default": 0.0005
                },
                "default_caption": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "Default caption to use when caption files are missing. If None, missing captions will cause an error.",
                  "title": "Default Caption"
                }
              },
              "title": "Input",
              "required": [
                "image_data_url"
              ]
            },
            "ZImageBaseTrainerOutput": {
              "x-fal-order-properties": [
                "diffusers_lora_file",
                "config_file"
              ],
              "type": "object",
              "properties": {
                "config_file": {
                  "description": "URL to the configuration file for the trained model.",
                  "$ref": "#/components/schemas/File"
                },
                "diffusers_lora_file": {
                  "description": "URL to the trained diffusers lora weights.",
                  "$ref": "#/components/schemas/File"
                }
              },
              "title": "Output",
              "required": [
                "diffusers_lora_file",
                "config_file"
              ]
            },
            "File": {
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size"
              ],
              "type": "object",
              "properties": {
                "file_size": {
                  "anyOf": [
                    {
                      "type": "integer"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The size of the file in bytes.",
                  "title": "File Size",
                  "examples": [
                    4404019
                  ]
                },
                "file_name": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The name of the file. It will be auto-generated if not provided.",
                  "title": "File Name",
                  "examples": [
                    "z9RV14K95DvU.png"
                  ]
                },
                "content_type": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The mime type of the file.",
                  "title": "Content Type",
                  "examples": [
                    "image/png"
                  ]
                },
                "url": {
                  "description": "The URL where the file can be downloaded from.",
                  "type": "string",
                  "title": "Url"
                }
              },
              "title": "File",
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/z-image-base-trainer/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/z-image-base-trainer/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/z-image-base-trainer": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/ZImageBaseTrainerInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/z-image-base-trainer/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/ZImageBaseTrainerOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/z-image-turbo-trainer-v2",
      "metadata": {
        "display_name": "Z Image Turbo Trainer V2",
        "category": "training",
        "description": "Fast LoRA trainer for Z-Image-Turbo, a super fast text-to-image model of 6B parameters developed by Tongyi-MAI.",
        "status": "active",
        "tags": [
          "lora",
          "personalization",
          "trainer"
        ],
        "updated_at": "2026-01-26T22:40:13.588Z",
        "is_favorited": false,
        "thumbnail_url": "https://v3b.fal.media/files/b/0a8b9eef/T4yyPE_lpuMlcnmqlF8Ns_ab635223ffad4b2cb49d48d926eae60f.jpg",
        "model_url": "https://fal.run/fal-ai/z-image-turbo-trainer-v2",
        "license_type": "commercial",
        "date": "2026-01-24T03:10:13.337Z",
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/z-image/turbo/lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/z-image-turbo-trainer-v2",
          "version": "1.0.0",
          "description": "The OpenAPI schema for the fal-ai/z-image-turbo-trainer-v2 queue.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/z-image-turbo-trainer-v2",
            "category": "training",
            "thumbnailUrl": "https://v3b.fal.media/files/b/0a8b9eef/T4yyPE_lpuMlcnmqlF8Ns_ab635223ffad4b2cb49d48d926eae60f.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/z-image-turbo-trainer-v2",
            "documentationUrl": "https://fal.ai/models/fal-ai/z-image-turbo-trainer-v2/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "ZImageTurboTrainerV2Input": {
              "x-fal-order-properties": [
                "image_data_url",
                "steps",
                "default_caption",
                "learning_rate"
              ],
              "type": "object",
              "properties": {
                "steps": {
                  "description": "Number of steps to train for",
                  "type": "integer",
                  "minimum": 10,
                  "title": "Steps",
                  "maximum": 40000,
                  "default": 2000
                },
                "image_data_url": {
                  "title": "Image Data Url",
                  "type": "string",
                  "description": "\n        URL to the input data zip archive.\n\n        The zip should contain pairs of images and corresponding captions.\n\n        The images should be named: ROOT.EXT. For example: 001.jpg\n\n        The corresponding captions should be named: ROOT.txt. For example: 001.txt\n\n        If no text file is provided for an image, the default_caption will be used.\n        "
                },
                "learning_rate": {
                  "description": "Learning rate.",
                  "type": "number",
                  "title": "Learning Rate",
                  "default": 0.0005
                },
                "default_caption": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "Default Caption",
                  "description": "Default caption to use when caption files are missing. If None, missing captions will cause an error."
                }
              },
              "title": "Input",
              "required": [
                "image_data_url"
              ]
            },
            "ZImageTurboTrainerV2Output": {
              "x-fal-order-properties": [
                "diffusers_lora_file",
                "config_file"
              ],
              "type": "object",
              "properties": {
                "config_file": {
                  "description": "URL to the configuration file for the trained model.",
                  "$ref": "#/components/schemas/File"
                },
                "diffusers_lora_file": {
                  "description": "URL to the trained diffusers lora weights.",
                  "$ref": "#/components/schemas/File"
                }
              },
              "title": "Output",
              "required": [
                "diffusers_lora_file",
                "config_file"
              ]
            },
            "File": {
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size"
              ],
              "type": "object",
              "properties": {
                "file_size": {
                  "anyOf": [
                    {
                      "type": "integer"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The size of the file in bytes.",
                  "title": "File Size",
                  "examples": [
                    4404019
                  ]
                },
                "file_name": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The name of the file. It will be auto-generated if not provided.",
                  "title": "File Name",
                  "examples": [
                    "z9RV14K95DvU.png"
                  ]
                },
                "content_type": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The mime type of the file.",
                  "title": "Content Type",
                  "examples": [
                    "image/png"
                  ]
                },
                "url": {
                  "description": "The URL where the file can be downloaded from.",
                  "type": "string",
                  "title": "Url"
                }
              },
              "title": "File",
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/z-image-turbo-trainer-v2/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/z-image-turbo-trainer-v2/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/z-image-turbo-trainer-v2": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/ZImageTurboTrainerV2Input"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/z-image-turbo-trainer-v2/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/ZImageTurboTrainerV2Output"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/flux-2-klein-9b-base-trainer/edit",
      "metadata": {
        "display_name": "Flux 2 Klein 9B Base Trainer",
        "category": "training",
        "description": "Fine-tune FLUX.2 [klein] 4B from Black Forest Labs with custom datasets. Create specialized LoRA adaptations for specific editing tasks.",
        "status": "active",
        "tags": [],
        "updated_at": "2026-01-26T21:41:32.562Z",
        "is_favorited": false,
        "thumbnail_url": "https://v3b.fal.media/files/b/0a8b0825/dvng2ddAgvgcH9WxFOxF7_b324e03aec15473c998151bb6fa0453c.jpg",
        "model_url": "https://fal.run/fal-ai/flux-2-klein-9b-base-trainer/edit",
        "license_type": "commercial",
        "date": "2026-01-17T00:12:09.074Z",
        "group": {
          "key": "flux-2-klein-9b-base-trainer",
          "label": "Edit"
        },
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/flux-2/klein/9b/base/edit/lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/flux-2-klein-9b-base-trainer/edit",
          "version": "1.0.0",
          "description": "Train image editing LoRAs for FLUX.2 [klein], BFL's latest image model. FLUX.2 [klein] offers enhanced realism, crisper and more accurate text generation, and native image editing capabilities.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/flux-2-klein-9b-base-trainer/edit",
            "category": "training",
            "thumbnailUrl": "https://v3b.fal.media/files/b/0a8b0825/dvng2ddAgvgcH9WxFOxF7_b324e03aec15473c998151bb6fa0453c.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/flux-2-klein-9b-base-trainer/edit",
            "documentationUrl": "https://fal.ai/models/fal-ai/flux-2-klein-9b-base-trainer/edit/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "Flux2Klein9bBaseTrainerEditInput": {
              "title": "InputEditV2",
              "type": "object",
              "properties": {
                "steps": {
                  "description": "Total number of training steps.",
                  "type": "integer",
                  "minimum": 100,
                  "title": "Steps",
                  "maximum": 10000,
                  "multipleOf": 100,
                  "default": 1000
                },
                "image_data_url": {
                  "title": "Image Data Url",
                  "type": "string",
                  "description": "\n    URL to the input data zip archive.\n\n    The zip should contain pairs of images. The images should be named:\n\n    ROOT_start.EXT and ROOT_end.EXT\n    For example:\n    photo_start.jpg and photo_end.jpg\n\n    The zip can also contain up to four reference image for each image pair. The reference images should be named:\n    ROOT_start.EXT, ROOT_start2.EXT, ROOT_start3.EXT, ROOT_start4.EXT, ROOT_end.EXT\n    For example:\n    photo_start.jpg, photo_start2.jpg, photo_end.jpg\n\n    The zip can also contain a text file for each image pair. The text file should be named:\n    ROOT.txt\n    For example:\n    photo.txt\n\n    This text file can be used to specify the edit instructions for the image pair.\n\n    If no text file is provided, the default_caption will be used.\n\n    If no default_caption is provided, the training will fail.\n    "
                },
                "learning_rate": {
                  "title": "Learning Rate",
                  "type": "number",
                  "description": "Learning rate applied to trainable parameters.",
                  "default": 0.00005
                },
                "default_caption": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "Default Caption",
                  "description": "Default caption to use when caption files are missing. If None, missing captions will cause an error."
                },
                "output_lora_format": {
                  "enum": [
                    "fal",
                    "comfy"
                  ],
                  "title": "Output Lora Format",
                  "type": "string",
                  "description": "Dictates the naming scheme for the output weights",
                  "default": "fal"
                }
              },
              "x-fal-order-properties": [
                "image_data_url",
                "steps",
                "learning_rate",
                "default_caption",
                "output_lora_format"
              ],
              "required": [
                "image_data_url"
              ]
            },
            "Flux2Klein9bBaseTrainerEditOutput": {
              "title": "Output",
              "type": "object",
              "properties": {
                "config_file": {
                  "description": "URL to the configuration file for the trained model.",
                  "$ref": "#/components/schemas/File"
                },
                "diffusers_lora_file": {
                  "description": "URL to the trained diffusers lora weights.",
                  "$ref": "#/components/schemas/File"
                }
              },
              "x-fal-order-properties": [
                "diffusers_lora_file",
                "config_file"
              ],
              "required": [
                "diffusers_lora_file",
                "config_file"
              ]
            },
            "File": {
              "title": "File",
              "type": "object",
              "properties": {
                "file_size": {
                  "anyOf": [
                    {
                      "type": "integer"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "File Size",
                  "description": "The size of the file in bytes.",
                  "examples": [
                    4404019
                  ]
                },
                "file_name": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "File Name",
                  "description": "The name of the file. It will be auto-generated if not provided.",
                  "examples": [
                    "z9RV14K95DvU.png"
                  ]
                },
                "content_type": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "Content Type",
                  "description": "The mime type of the file.",
                  "examples": [
                    "image/png"
                  ]
                },
                "url": {
                  "title": "Url",
                  "type": "string",
                  "description": "The URL where the file can be downloaded from."
                }
              },
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size"
              ],
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/flux-2-klein-9b-base-trainer/edit/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-2-klein-9b-base-trainer/edit/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-2-klein-9b-base-trainer/edit": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/Flux2Klein9bBaseTrainerEditInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-2-klein-9b-base-trainer/edit/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/Flux2Klein9bBaseTrainerEditOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/flux-2-klein-9b-base-trainer",
      "metadata": {
        "display_name": "Flux 2 Klein 9B Base Trainer",
        "category": "training",
        "description": "Fine-tune FLUX.2 [klein] 9B from Black Forest Labs with custom datasets. Create specialized LoRA adaptations for specific editing tasks.",
        "status": "active",
        "tags": [],
        "updated_at": "2026-01-26T21:41:32.687Z",
        "is_favorited": false,
        "thumbnail_url": "https://v3b.fal.media/files/b/0a8b082b/4dsf0LE8NoXuk9Pz0Ziue_d7c1c380c4d04e03b820d06500a5749f.jpg",
        "model_url": "https://fal.run/fal-ai/flux-2-klein-9b-base-trainer",
        "license_type": "commercial",
        "date": "2026-01-17T00:10:10.940Z",
        "group": {
          "key": "flux-2-klein-9b-base-trainer",
          "label": "Text to Image"
        },
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/flux-2/klein/9b/base/lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/flux-2-klein-9b-base-trainer",
          "version": "1.0.0",
          "description": "Train text-to-image LoRAs for Flux.2 [klein], BFL's latest image model. Flux.2 [klein] offers enhanced realism, crisper and more accurate text generation, and native image editing capabilities.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/flux-2-klein-9b-base-trainer",
            "category": "training",
            "thumbnailUrl": "https://v3b.fal.media/files/b/0a8b082b/4dsf0LE8NoXuk9Pz0Ziue_d7c1c380c4d04e03b820d06500a5749f.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/flux-2-klein-9b-base-trainer",
            "documentationUrl": "https://fal.ai/models/fal-ai/flux-2-klein-9b-base-trainer/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "Flux2Klein9bBaseTrainerInput": {
              "title": "InputT2IV2",
              "type": "object",
              "properties": {
                "steps": {
                  "description": "Total number of training steps.",
                  "type": "integer",
                  "minimum": 100,
                  "title": "Steps",
                  "maximum": 10000,
                  "multipleOf": 100,
                  "default": 1000
                },
                "image_data_url": {
                  "title": "Image Data Url",
                  "type": "string",
                  "description": "\n    URL to zip archive with images of a consistent style. Try to use at least 10 images, although more is better.\n\n    The zip can also contain a text file for each image. The text file should be named:\n    ROOT.txt\n    For example:\n    photo.txt\n\n    This text file can be used to specify the edit instructions for the image pair.\n\n    If no text file is provided, the default_caption will be used.\n\n    If no default_caption is provided, the training will fail.\n    "
                },
                "learning_rate": {
                  "title": "Learning Rate",
                  "type": "number",
                  "description": "Learning rate applied to trainable parameters.",
                  "default": 0.00005
                },
                "default_caption": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "Default Caption",
                  "description": "Default caption to use when caption files are missing. If None, missing captions will cause an error."
                },
                "output_lora_format": {
                  "enum": [
                    "fal",
                    "comfy"
                  ],
                  "title": "Output Lora Format",
                  "type": "string",
                  "description": "Dictates the naming scheme for the output weights",
                  "default": "fal"
                }
              },
              "x-fal-order-properties": [
                "image_data_url",
                "steps",
                "learning_rate",
                "default_caption",
                "output_lora_format"
              ],
              "description": "V2 input with multi-resolution bucketing.",
              "required": [
                "image_data_url"
              ]
            },
            "Flux2Klein9bBaseTrainerOutput": {
              "title": "Output",
              "type": "object",
              "properties": {
                "config_file": {
                  "description": "URL to the configuration file for the trained model.",
                  "$ref": "#/components/schemas/File"
                },
                "diffusers_lora_file": {
                  "description": "URL to the trained diffusers lora weights.",
                  "$ref": "#/components/schemas/File"
                }
              },
              "x-fal-order-properties": [
                "diffusers_lora_file",
                "config_file"
              ],
              "required": [
                "diffusers_lora_file",
                "config_file"
              ]
            },
            "File": {
              "title": "File",
              "type": "object",
              "properties": {
                "file_size": {
                  "anyOf": [
                    {
                      "type": "integer"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "File Size",
                  "description": "The size of the file in bytes.",
                  "examples": [
                    4404019
                  ]
                },
                "file_name": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "File Name",
                  "description": "The name of the file. It will be auto-generated if not provided.",
                  "examples": [
                    "z9RV14K95DvU.png"
                  ]
                },
                "content_type": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "Content Type",
                  "description": "The mime type of the file.",
                  "examples": [
                    "image/png"
                  ]
                },
                "url": {
                  "title": "Url",
                  "type": "string",
                  "description": "The URL where the file can be downloaded from."
                }
              },
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size"
              ],
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/flux-2-klein-9b-base-trainer/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-2-klein-9b-base-trainer/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-2-klein-9b-base-trainer": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/Flux2Klein9bBaseTrainerInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-2-klein-9b-base-trainer/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/Flux2Klein9bBaseTrainerOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/flux-2-klein-4b-base-trainer",
      "metadata": {
        "display_name": "Flux 2 Klein 4B Base Trainer",
        "category": "training",
        "description": "Fine-tune FLUX.2 [klein] 4B from Black Forest Labs with custom datasets. Create specialized LoRA adaptations for specific styles and domains.",
        "status": "active",
        "tags": [],
        "updated_at": "2026-01-26T21:41:32.812Z",
        "is_favorited": false,
        "thumbnail_url": "https://v3b.fal.media/files/b/0a8b082e/N8Fy12FSedqMd-2Ehh8z1_70e50238ee6b479ebd61270840b4806e.jpg",
        "model_url": "https://fal.run/fal-ai/flux-2-klein-4b-base-trainer",
        "license_type": "commercial",
        "date": "2026-01-17T00:00:25.052Z",
        "group": {
          "key": "flux-2-klein-4b-base-trainer",
          "label": "Text to Image"
        },
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/flux-2/klein/4b/base/lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/flux-2-klein-4b-base-trainer",
          "version": "1.0.0",
          "description": "Train text-to-image LoRAs for Flux.2 [klein], BFL's latest image model. Flux.2 [klein] offers enhanced realism, crisper and more accurate text generation, and native image editing capabilities.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/flux-2-klein-4b-base-trainer",
            "category": "training",
            "thumbnailUrl": "https://v3b.fal.media/files/b/0a8b082e/N8Fy12FSedqMd-2Ehh8z1_70e50238ee6b479ebd61270840b4806e.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/flux-2-klein-4b-base-trainer",
            "documentationUrl": "https://fal.ai/models/fal-ai/flux-2-klein-4b-base-trainer/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "Flux2Klein4bBaseTrainerInput": {
              "title": "InputT2IV2",
              "type": "object",
              "properties": {
                "steps": {
                  "description": "Total number of training steps.",
                  "type": "integer",
                  "minimum": 100,
                  "title": "Steps",
                  "maximum": 10000,
                  "multipleOf": 100,
                  "default": 1000
                },
                "image_data_url": {
                  "title": "Image Data Url",
                  "type": "string",
                  "description": "\n    URL to zip archive with images of a consistent style. Try to use at least 10 images, although more is better.\n\n    The zip can also contain a text file for each image. The text file should be named:\n    ROOT.txt\n    For example:\n    photo.txt\n\n    This text file can be used to specify the edit instructions for the image pair.\n\n    If no text file is provided, the default_caption will be used.\n\n    If no default_caption is provided, the training will fail.\n    "
                },
                "learning_rate": {
                  "title": "Learning Rate",
                  "type": "number",
                  "description": "Learning rate applied to trainable parameters.",
                  "default": 0.00005
                },
                "default_caption": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "Default Caption",
                  "description": "Default caption to use when caption files are missing. If None, missing captions will cause an error."
                },
                "output_lora_format": {
                  "enum": [
                    "fal",
                    "comfy"
                  ],
                  "title": "Output Lora Format",
                  "type": "string",
                  "description": "Dictates the naming scheme for the output weights",
                  "default": "fal"
                }
              },
              "x-fal-order-properties": [
                "image_data_url",
                "steps",
                "learning_rate",
                "default_caption",
                "output_lora_format"
              ],
              "description": "V2 input with multi-resolution bucketing.",
              "required": [
                "image_data_url"
              ]
            },
            "Flux2Klein4bBaseTrainerOutput": {
              "title": "Output",
              "type": "object",
              "properties": {
                "config_file": {
                  "description": "URL to the configuration file for the trained model.",
                  "$ref": "#/components/schemas/File"
                },
                "diffusers_lora_file": {
                  "description": "URL to the trained diffusers lora weights.",
                  "$ref": "#/components/schemas/File"
                }
              },
              "x-fal-order-properties": [
                "diffusers_lora_file",
                "config_file"
              ],
              "required": [
                "diffusers_lora_file",
                "config_file"
              ]
            },
            "File": {
              "title": "File",
              "type": "object",
              "properties": {
                "file_size": {
                  "examples": [
                    4404019
                  ],
                  "title": "File Size",
                  "anyOf": [
                    {
                      "type": "integer"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The size of the file in bytes."
                },
                "file_name": {
                  "examples": [
                    "z9RV14K95DvU.png"
                  ],
                  "title": "File Name",
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The name of the file. It will be auto-generated if not provided."
                },
                "content_type": {
                  "examples": [
                    "image/png"
                  ],
                  "title": "Content Type",
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The mime type of the file."
                },
                "url": {
                  "title": "Url",
                  "type": "string",
                  "description": "The URL where the file can be downloaded from."
                }
              },
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size"
              ],
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/flux-2-klein-4b-base-trainer/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-2-klein-4b-base-trainer/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-2-klein-4b-base-trainer": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/Flux2Klein4bBaseTrainerInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-2-klein-4b-base-trainer/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/Flux2Klein4bBaseTrainerOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/flux-2-klein-4b-base-trainer/edit",
      "metadata": {
        "display_name": "Flux 2 Klein 4B Base Trainer",
        "category": "training",
        "description": "Fine-tune FLUX.2 [klein] 4B from Black Forest Labs with custom datasets. Create specialized LoRA adaptations for specific editing tasks.",
        "status": "active",
        "tags": [],
        "updated_at": "2026-01-26T21:41:32.937Z",
        "is_favorited": false,
        "thumbnail_url": "https://v3b.fal.media/files/b/0a8b0832/jZ_NLBvIMIzZUSunU51Vv_3508e6e1b4f040078ec5ef718c3e77b9.jpg",
        "model_url": "https://fal.run/fal-ai/flux-2-klein-4b-base-trainer/edit",
        "license_type": "commercial",
        "date": "2026-01-16T23:53:13.121Z",
        "group": {
          "key": "flux-2-klein-4b-base-trainer",
          "label": "Edit"
        },
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/flux-2/klein/4b/base/edit/lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/flux-2-klein-4b-base-trainer/edit",
          "version": "1.0.0",
          "description": "Train image editing LoRAs for FLUX.2 [klein], BFL's latest image model. FLUX.2 [klein] offers enhanced realism, crisper and more accurate text generation, and native image editing capabilities.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/flux-2-klein-4b-base-trainer/edit",
            "category": "training",
            "thumbnailUrl": "https://v3b.fal.media/files/b/0a8b0832/jZ_NLBvIMIzZUSunU51Vv_3508e6e1b4f040078ec5ef718c3e77b9.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/flux-2-klein-4b-base-trainer/edit",
            "documentationUrl": "https://fal.ai/models/fal-ai/flux-2-klein-4b-base-trainer/edit/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "Flux2Klein4bBaseTrainerEditInput": {
              "title": "InputEditV2",
              "type": "object",
              "properties": {
                "steps": {
                  "description": "Total number of training steps.",
                  "type": "integer",
                  "minimum": 100,
                  "title": "Steps",
                  "maximum": 10000,
                  "multipleOf": 100,
                  "default": 1000
                },
                "image_data_url": {
                  "title": "Image Data Url",
                  "type": "string",
                  "description": "\n    URL to the input data zip archive.\n\n    The zip should contain pairs of images. The images should be named:\n\n    ROOT_start.EXT and ROOT_end.EXT\n    For example:\n    photo_start.jpg and photo_end.jpg\n\n    The zip can also contain up to four reference image for each image pair. The reference images should be named:\n    ROOT_start.EXT, ROOT_start2.EXT, ROOT_start3.EXT, ROOT_start4.EXT, ROOT_end.EXT\n    For example:\n    photo_start.jpg, photo_start2.jpg, photo_end.jpg\n\n    The zip can also contain a text file for each image pair. The text file should be named:\n    ROOT.txt\n    For example:\n    photo.txt\n\n    This text file can be used to specify the edit instructions for the image pair.\n\n    If no text file is provided, the default_caption will be used.\n\n    If no default_caption is provided, the training will fail.\n    "
                },
                "learning_rate": {
                  "title": "Learning Rate",
                  "type": "number",
                  "description": "Learning rate applied to trainable parameters.",
                  "default": 0.00005
                },
                "default_caption": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "Default Caption",
                  "description": "Default caption to use when caption files are missing. If None, missing captions will cause an error."
                },
                "output_lora_format": {
                  "enum": [
                    "fal",
                    "comfy"
                  ],
                  "title": "Output Lora Format",
                  "type": "string",
                  "description": "Dictates the naming scheme for the output weights",
                  "default": "fal"
                }
              },
              "x-fal-order-properties": [
                "image_data_url",
                "steps",
                "learning_rate",
                "default_caption",
                "output_lora_format"
              ],
              "required": [
                "image_data_url"
              ]
            },
            "Flux2Klein4bBaseTrainerEditOutput": {
              "title": "Output",
              "type": "object",
              "properties": {
                "config_file": {
                  "description": "URL to the configuration file for the trained model.",
                  "$ref": "#/components/schemas/File"
                },
                "diffusers_lora_file": {
                  "description": "URL to the trained diffusers lora weights.",
                  "$ref": "#/components/schemas/File"
                }
              },
              "x-fal-order-properties": [
                "diffusers_lora_file",
                "config_file"
              ],
              "required": [
                "diffusers_lora_file",
                "config_file"
              ]
            },
            "File": {
              "title": "File",
              "type": "object",
              "properties": {
                "file_size": {
                  "examples": [
                    4404019
                  ],
                  "title": "File Size",
                  "anyOf": [
                    {
                      "type": "integer"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The size of the file in bytes."
                },
                "file_name": {
                  "examples": [
                    "z9RV14K95DvU.png"
                  ],
                  "title": "File Name",
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The name of the file. It will be auto-generated if not provided."
                },
                "content_type": {
                  "examples": [
                    "image/png"
                  ],
                  "title": "Content Type",
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The mime type of the file."
                },
                "url": {
                  "title": "Url",
                  "type": "string",
                  "description": "The URL where the file can be downloaded from."
                }
              },
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size"
              ],
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/flux-2-klein-4b-base-trainer/edit/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-2-klein-4b-base-trainer/edit/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-2-klein-4b-base-trainer/edit": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/Flux2Klein4bBaseTrainerEditInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-2-klein-4b-base-trainer/edit/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/Flux2Klein4bBaseTrainerEditOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/qwen-image-2512-trainer-v2",
      "metadata": {
        "display_name": "Qwen Image 2512 Trainer V2",
        "category": "training",
        "description": "Fast LoRA trainer for Qwen-Image-2512",
        "status": "active",
        "tags": [
          "lora",
          "personalization"
        ],
        "updated_at": "2026-01-26T21:41:35.619Z",
        "is_favorited": false,
        "thumbnail_url": "https://v3b.fal.media/files/b/0a8a6d81/ftGhoUbrfMQ1ddU8Oi-oe_0a22ea3dbb8b428393765dea02fe1e9c.jpg",
        "model_url": "https://fal.run/fal-ai/qwen-image-2512-trainer-v2",
        "license_type": "commercial",
        "date": "2026-01-15T01:56:33.046Z",
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/qwen-image-2512/lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/qwen-image-2512-trainer-v2",
          "version": "1.0.0",
          "description": "The OpenAPI schema for the fal-ai/qwen-image-2512-trainer-v2 queue.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/qwen-image-2512-trainer-v2",
            "category": "training",
            "thumbnailUrl": "https://v3b.fal.media/files/b/0a8a6d81/ftGhoUbrfMQ1ddU8Oi-oe_0a22ea3dbb8b428393765dea02fe1e9c.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/qwen-image-2512-trainer-v2",
            "documentationUrl": "https://fal.ai/models/fal-ai/qwen-image-2512-trainer-v2/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "QwenImage2512TrainerV2Input": {
              "title": "Input",
              "type": "object",
              "properties": {
                "steps": {
                  "description": "Number of steps to train for",
                  "type": "integer",
                  "minimum": 10,
                  "maximum": 40000,
                  "title": "Steps",
                  "default": 2000
                },
                "image_data_url": {
                  "title": "Image Data Url",
                  "type": "string",
                  "description": "\n        URL to the input data zip archive.\n\n        The zip should contain pairs of images and corresponding captions.\n\n        The images should be named: ROOT.EXT. For example: 001.jpg\n\n        The corresponding captions should be named: ROOT.txt. For example: 001.txt\n\n        If no text file is provided for an image, the default_caption will be used.\n        "
                },
                "learning_rate": {
                  "title": "Learning Rate",
                  "type": "number",
                  "description": "Learning rate.",
                  "default": 0.0005
                },
                "default_caption": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "Default Caption",
                  "description": "Default caption to use when caption files are missing. If None, missing captions will cause an error."
                }
              },
              "x-fal-order-properties": [
                "image_data_url",
                "steps",
                "default_caption",
                "learning_rate"
              ],
              "required": [
                "image_data_url"
              ]
            },
            "QwenImage2512TrainerV2Output": {
              "title": "Output",
              "type": "object",
              "properties": {
                "config_file": {
                  "description": "URL to the configuration file for the trained model.",
                  "$ref": "#/components/schemas/File"
                },
                "diffusers_lora_file": {
                  "description": "URL to the trained diffusers lora weights.",
                  "$ref": "#/components/schemas/File"
                }
              },
              "x-fal-order-properties": [
                "diffusers_lora_file",
                "config_file"
              ],
              "required": [
                "diffusers_lora_file",
                "config_file"
              ]
            },
            "File": {
              "title": "File",
              "type": "object",
              "properties": {
                "file_size": {
                  "anyOf": [
                    {
                      "type": "integer"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "File Size",
                  "examples": [
                    4404019
                  ],
                  "description": "The size of the file in bytes."
                },
                "file_name": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "File Name",
                  "examples": [
                    "z9RV14K95DvU.png"
                  ],
                  "description": "The name of the file. It will be auto-generated if not provided."
                },
                "content_type": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "Content Type",
                  "examples": [
                    "image/png"
                  ],
                  "description": "The mime type of the file."
                },
                "url": {
                  "title": "Url",
                  "type": "string",
                  "description": "The URL where the file can be downloaded from."
                }
              },
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size"
              ],
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/qwen-image-2512-trainer-v2/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/qwen-image-2512-trainer-v2/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/qwen-image-2512-trainer-v2": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/QwenImage2512TrainerV2Input"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/qwen-image-2512-trainer-v2/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QwenImage2512TrainerV2Output"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/flux-2-trainer-v2/edit",
      "metadata": {
        "display_name": "Flux 2 Trainer V2",
        "category": "training",
        "description": "Fine-tune FLUX.2 [dev] from Black Forest Labs with custom datasets. Create specialized LoRA adaptations for specific editing tasks.",
        "status": "active",
        "tags": [],
        "updated_at": "2026-01-26T21:41:39.863Z",
        "is_favorited": false,
        "thumbnail_url": "https://v3b.fal.media/files/b/rabbit/QQxycBXjY75hch-HBAQKZ_4af8ba3ddb9d457ba5fc51fcd428e720.jpg",
        "model_url": "https://fal.run/fal-ai/flux-2-trainer-v2/edit",
        "license_type": "commercial",
        "date": "2026-01-10T01:08:01.647Z",
        "group": {
          "key": "flux2-trainer-v2",
          "label": "Edit"
        },
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/flux-2/lora/edit"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/flux-2-trainer-v2/edit",
          "version": "1.0.0",
          "description": "Train image editing LoRAs for FLUX.2 [dev], BFL's latest image model. FLUX.2 [dev] offers enhanced realism, crisper and more accurate text generation, and native image editing capabilities.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/flux-2-trainer-v2/edit",
            "category": "training",
            "thumbnailUrl": "https://v3b.fal.media/files/b/rabbit/QQxycBXjY75hch-HBAQKZ_4af8ba3ddb9d457ba5fc51fcd428e720.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/flux-2-trainer-v2/edit",
            "documentationUrl": "https://fal.ai/models/fal-ai/flux-2-trainer-v2/edit/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "Flux2TrainerV2EditInput": {
              "x-fal-order-properties": [
                "image_data_url",
                "steps",
                "learning_rate",
                "default_caption",
                "output_lora_format"
              ],
              "type": "object",
              "properties": {
                "steps": {
                  "description": "Total number of training steps.",
                  "type": "integer",
                  "minimum": 100,
                  "title": "Steps",
                  "maximum": 10000,
                  "multipleOf": 100,
                  "default": 1000
                },
                "image_data_url": {
                  "description": "\n    URL to the input data zip archive.\n\n    The zip should contain pairs of images. The images should be named:\n\n    ROOT_start.EXT and ROOT_end.EXT\n    For example:\n    photo_start.jpg and photo_end.jpg\n\n    The zip can also contain up to four reference image for each image pair. The reference images should be named:\n    ROOT_start.EXT, ROOT_start2.EXT, ROOT_start3.EXT, ROOT_start4.EXT, ROOT_end.EXT\n    For example:\n    photo_start.jpg, photo_start2.jpg, photo_end.jpg\n\n    The zip can also contain a text file for each image pair. The text file should be named:\n    ROOT.txt\n    For example:\n    photo.txt\n\n    This text file can be used to specify the edit instructions for the image pair.\n\n    If no text file is provided, the default_caption will be used.\n\n    If no default_caption is provided, the training will fail.\n    ",
                  "type": "string",
                  "title": "Image Data Url"
                },
                "learning_rate": {
                  "description": "Learning rate applied to trainable parameters.",
                  "type": "number",
                  "title": "Learning Rate",
                  "default": 0.00005
                },
                "default_caption": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "Default caption to use when caption files are missing. If None, missing captions will cause an error.",
                  "title": "Default Caption"
                },
                "output_lora_format": {
                  "enum": [
                    "fal",
                    "comfy"
                  ],
                  "title": "Output Lora Format",
                  "type": "string",
                  "description": "Dictates the naming scheme for the output weights",
                  "default": "fal"
                }
              },
              "title": "InputEditV2",
              "required": [
                "image_data_url"
              ]
            },
            "Flux2TrainerV2EditOutput": {
              "x-fal-order-properties": [
                "diffusers_lora_file",
                "config_file"
              ],
              "type": "object",
              "properties": {
                "config_file": {
                  "description": "URL to the configuration file for the trained model.",
                  "$ref": "#/components/schemas/File"
                },
                "diffusers_lora_file": {
                  "description": "URL to the trained diffusers lora weights.",
                  "$ref": "#/components/schemas/File"
                }
              },
              "title": "Output",
              "required": [
                "diffusers_lora_file",
                "config_file"
              ]
            },
            "File": {
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size"
              ],
              "type": "object",
              "properties": {
                "file_size": {
                  "anyOf": [
                    {
                      "type": "integer"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The size of the file in bytes.",
                  "title": "File Size",
                  "examples": [
                    4404019
                  ]
                },
                "file_name": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The name of the file. It will be auto-generated if not provided.",
                  "title": "File Name",
                  "examples": [
                    "z9RV14K95DvU.png"
                  ]
                },
                "content_type": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The mime type of the file.",
                  "title": "Content Type",
                  "examples": [
                    "image/png"
                  ]
                },
                "url": {
                  "description": "The URL where the file can be downloaded from.",
                  "type": "string",
                  "title": "Url"
                }
              },
              "title": "File",
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/flux-2-trainer-v2/edit/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-2-trainer-v2/edit/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-2-trainer-v2/edit": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/Flux2TrainerV2EditInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-2-trainer-v2/edit/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/Flux2TrainerV2EditOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/flux-2-trainer-v2",
      "metadata": {
        "display_name": "Flux 2 Trainer V2",
        "category": "training",
        "description": "Fine-tune FLUX.2 [dev] from Black Forest Labs with custom datasets. Create specialized LoRA adaptations for specific styles and domains.",
        "status": "active",
        "tags": [],
        "updated_at": "2026-01-26T21:41:39.988Z",
        "is_favorited": false,
        "thumbnail_url": "https://v3b.fal.media/files/b/tiger/nYv87OHdt503yjlNUk1P3_2551388f5f4e4537b67e8ed436333bca.jpg",
        "model_url": "https://fal.run/fal-ai/flux-2-trainer-v2",
        "license_type": "commercial",
        "date": "2026-01-10T00:59:39.928Z",
        "group": {
          "key": "flux2-trainer-v2",
          "label": "Text to Image"
        },
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/flux-2/lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/flux-2-trainer-v2",
          "version": "1.0.0",
          "description": "Train text-to-image LoRAs for Flux.2, BFL's latest image model. Flux.2 offers enhanced realism, crisper and more accurate text generation, and native image editing capabilities.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/flux-2-trainer-v2",
            "category": "training",
            "thumbnailUrl": "https://v3b.fal.media/files/b/tiger/nYv87OHdt503yjlNUk1P3_2551388f5f4e4537b67e8ed436333bca.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/flux-2-trainer-v2",
            "documentationUrl": "https://fal.ai/models/fal-ai/flux-2-trainer-v2/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "Flux2TrainerV2Input": {
              "description": "V2 input with multi-resolution bucketing.",
              "type": "object",
              "properties": {
                "steps": {
                  "description": "Total number of training steps.",
                  "type": "integer",
                  "minimum": 100,
                  "title": "Steps",
                  "maximum": 10000,
                  "multipleOf": 100,
                  "default": 1000
                },
                "image_data_url": {
                  "description": "\n    URL to zip archive with images of a consistent style. Try to use at least 10 images, although more is better.\n\n    The zip can also contain a text file for each image. The text file should be named:\n    ROOT.txt\n    For example:\n    photo.txt\n\n    This text file can be used to specify the edit instructions for the image pair.\n\n    If no text file is provided, the default_caption will be used.\n\n    If no default_caption is provided, the training will fail.\n    ",
                  "type": "string",
                  "title": "Image Data Url"
                },
                "learning_rate": {
                  "description": "Learning rate applied to trainable parameters.",
                  "type": "number",
                  "title": "Learning Rate",
                  "default": 0.00005
                },
                "default_caption": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "Default caption to use when caption files are missing. If None, missing captions will cause an error.",
                  "title": "Default Caption"
                },
                "output_lora_format": {
                  "enum": [
                    "fal",
                    "comfy"
                  ],
                  "title": "Output Lora Format",
                  "type": "string",
                  "description": "Dictates the naming scheme for the output weights",
                  "default": "fal"
                }
              },
              "title": "InputT2IV2",
              "x-fal-order-properties": [
                "image_data_url",
                "steps",
                "learning_rate",
                "default_caption",
                "output_lora_format"
              ],
              "required": [
                "image_data_url"
              ]
            },
            "Flux2TrainerV2Output": {
              "x-fal-order-properties": [
                "diffusers_lora_file",
                "config_file"
              ],
              "type": "object",
              "properties": {
                "config_file": {
                  "description": "URL to the configuration file for the trained model.",
                  "$ref": "#/components/schemas/File"
                },
                "diffusers_lora_file": {
                  "description": "URL to the trained diffusers lora weights.",
                  "$ref": "#/components/schemas/File"
                }
              },
              "title": "Output",
              "required": [
                "diffusers_lora_file",
                "config_file"
              ]
            },
            "File": {
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size"
              ],
              "type": "object",
              "properties": {
                "file_size": {
                  "anyOf": [
                    {
                      "type": "integer"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The size of the file in bytes.",
                  "title": "File Size",
                  "examples": [
                    4404019
                  ]
                },
                "file_name": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The name of the file. It will be auto-generated if not provided.",
                  "title": "File Name",
                  "examples": [
                    "z9RV14K95DvU.png"
                  ]
                },
                "content_type": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The mime type of the file.",
                  "title": "Content Type",
                  "examples": [
                    "image/png"
                  ]
                },
                "url": {
                  "description": "The URL where the file can be downloaded from.",
                  "type": "string",
                  "title": "Url"
                }
              },
              "title": "File",
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/flux-2-trainer-v2/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-2-trainer-v2/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-2-trainer-v2": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/Flux2TrainerV2Input"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-2-trainer-v2/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/Flux2TrainerV2Output"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/ltx2-v2v-trainer",
      "metadata": {
        "display_name": "LTX-2 Video to Video Trainer",
        "category": "training",
        "description": "Train LTX-2 for video transformation or video-conditioned generation.",
        "status": "active",
        "tags": [
          "ltx2-video",
          "fine-tuning",
          "video-to-video"
        ],
        "updated_at": "2026-01-26T21:41:40.838Z",
        "is_favorited": false,
        "thumbnail_url": "https://v3b.fal.media/files/b/0a8974c8/5HxQgdbMq2dg4Mp-8Kug1_a8a11ca50370401eacad6e04a14e18e1.jpg",
        "model_url": "https://fal.run/fal-ai/ltx2-v2v-trainer",
        "license_type": "commercial",
        "date": "2026-01-07T16:55:20.500Z",
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/ltx-2-19b/video-to-video/lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/ltx2-v2v-trainer",
          "version": "1.0.0",
          "description": "The OpenAPI schema for the fal-ai/ltx2-v2v-trainer queue.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/ltx2-v2v-trainer",
            "category": "training",
            "thumbnailUrl": "https://v3b.fal.media/files/b/0a8974c8/5HxQgdbMq2dg4Mp-8Kug1_a8a11ca50370401eacad6e04a14e18e1.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/ltx2-v2v-trainer",
            "documentationUrl": "https://fal.ai/models/fal-ai/ltx2-v2v-trainer/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "Ltx2V2vTrainerInput": {
              "title": "LTX2V2VInput",
              "type": "object",
              "properties": {
                "number_of_steps": {
                  "description": "The number of training steps.",
                  "type": "integer",
                  "examples": [
                    2000
                  ],
                  "maximum": 20000,
                  "title": "Number Of Steps",
                  "minimum": 100,
                  "step": 100,
                  "default": 2000
                },
                "frame_rate": {
                  "description": "Target frames per second for the video.",
                  "type": "integer",
                  "examples": [
                    25
                  ],
                  "maximum": 60,
                  "title": "Frame Rate",
                  "minimum": 8,
                  "default": 25
                },
                "learning_rate": {
                  "description": "Learning rate for optimization. Higher values can lead to faster training but may cause overfitting.",
                  "type": "number",
                  "examples": [
                    0.0002
                  ],
                  "maximum": 1,
                  "title": "Learning Rate",
                  "minimum": 0.000001,
                  "step": 0.0001,
                  "default": 0.0002
                },
                "validation": {
                  "title": "Validation",
                  "type": "array",
                  "description": "A list of validation inputs with prompts and reference videos.",
                  "maxItems": 2,
                  "items": {
                    "$ref": "#/components/schemas/V2VValidation"
                  },
                  "default": []
                },
                "number_of_frames": {
                  "description": "Number of frames per training sample. Must satisfy frames % 8 == 1 (e.g., 1, 9, 17, 25, 33, 41, 49, 57, 65, 73, 81, 89, 97).",
                  "type": "integer",
                  "examples": [
                    89
                  ],
                  "maximum": 121,
                  "title": "Number Of Frames",
                  "minimum": 9,
                  "default": 89
                },
                "training_data_url": {
                  "title": "Training Data Url",
                  "type": "string",
                  "description": "URL to zip archive with videos or images. Try to use at least 10 files, although more is better.\n\n        **Supported video formats:** .mp4, .mov, .avi, .mkv\n        **Supported image formats:** .png, .jpg, .jpeg\n\n        Note: The dataset must contain ONLY videos OR ONLY images - mixed datasets are not supported.\n\n        The archive can also contain text files with captions. Each text file should have the same name as the media file it corresponds to."
                },
                "split_input_duration_threshold": {
                  "description": "The duration threshold in seconds. If a video is longer than this, it will be split into scenes.",
                  "type": "number",
                  "examples": [
                    30
                  ],
                  "maximum": 60,
                  "title": "Split Input Duration Threshold",
                  "minimum": 1,
                  "default": 30
                },
                "rank": {
                  "examples": [
                    32
                  ],
                  "title": "Rank",
                  "type": "integer",
                  "description": "The rank of the LoRA adaptation. Higher values increase capacity but use more memory.",
                  "enum": [
                    8,
                    16,
                    32,
                    64,
                    128
                  ],
                  "default": 32
                },
                "stg_scale": {
                  "minimum": 0,
                  "maximum": 3,
                  "type": "number",
                  "description": "STG (Spatio-Temporal Guidance) scale. 0.0 disables STG. Recommended value is 1.0.",
                  "title": "Stg Scale",
                  "default": 1
                },
                "first_frame_conditioning_p": {
                  "minimum": 0,
                  "maximum": 1,
                  "type": "number",
                  "description": "Probability of conditioning on the first frame during training. Lower values work better for video-to-video transformation.",
                  "title": "First Frame Conditioning P",
                  "default": 0.1
                },
                "aspect_ratio": {
                  "examples": [
                    "1:1"
                  ],
                  "title": "Aspect Ratio",
                  "type": "string",
                  "description": "Aspect ratio to use for training.",
                  "enum": [
                    "16:9",
                    "1:1",
                    "9:16"
                  ],
                  "default": "1:1"
                },
                "trigger_phrase": {
                  "examples": [
                    ""
                  ],
                  "title": "Trigger Phrase",
                  "type": "string",
                  "description": "A phrase that will trigger the LoRA style. Will be prepended to captions during training.",
                  "default": ""
                },
                "resolution": {
                  "examples": [
                    "medium"
                  ],
                  "title": "Resolution",
                  "type": "string",
                  "description": "Resolution to use for training. Higher resolutions require more memory.",
                  "enum": [
                    "low",
                    "medium",
                    "high"
                  ],
                  "default": "medium"
                },
                "validation_frame_rate": {
                  "description": "Target frames per second for validation videos.",
                  "type": "integer",
                  "examples": [
                    25
                  ],
                  "maximum": 60,
                  "title": "Validation Frame Rate",
                  "minimum": 8,
                  "default": 25
                },
                "split_input_into_scenes": {
                  "examples": [
                    true
                  ],
                  "title": "Split Input Into Scenes",
                  "type": "boolean",
                  "description": "If true, videos above a certain duration threshold will be split into scenes.",
                  "default": true
                },
                "validation_resolution": {
                  "examples": [
                    "high"
                  ],
                  "title": "Validation Resolution",
                  "type": "string",
                  "description": "The resolution to use for validation.",
                  "enum": [
                    "low",
                    "medium",
                    "high"
                  ],
                  "default": "high"
                },
                "validation_number_of_frames": {
                  "description": "The number of frames in validation videos.",
                  "type": "integer",
                  "examples": [
                    89
                  ],
                  "maximum": 121,
                  "title": "Validation Number Of Frames",
                  "minimum": 9,
                  "default": 89
                },
                "validation_aspect_ratio": {
                  "examples": [
                    "1:1"
                  ],
                  "title": "Validation Aspect Ratio",
                  "type": "string",
                  "description": "The aspect ratio to use for validation.",
                  "enum": [
                    "16:9",
                    "1:1",
                    "9:16"
                  ],
                  "default": "1:1"
                },
                "validation_negative_prompt": {
                  "title": "Validation Negative Prompt",
                  "type": "string",
                  "description": "A negative prompt to use for validation.",
                  "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
                },
                "auto_scale_input": {
                  "examples": [
                    false
                  ],
                  "title": "Auto Scale Input",
                  "type": "boolean",
                  "description": "If true, videos will be automatically scaled to the target frame count and fps. This option has no effect on image datasets.",
                  "default": false
                }
              },
              "description": "Input configuration for LTX-2 video-to-video (IC-LoRA) training.",
              "x-fal-order-properties": [
                "training_data_url",
                "rank",
                "number_of_steps",
                "learning_rate",
                "number_of_frames",
                "frame_rate",
                "resolution",
                "aspect_ratio",
                "trigger_phrase",
                "auto_scale_input",
                "split_input_into_scenes",
                "split_input_duration_threshold",
                "first_frame_conditioning_p",
                "validation",
                "validation_negative_prompt",
                "validation_number_of_frames",
                "validation_frame_rate",
                "validation_resolution",
                "validation_aspect_ratio",
                "stg_scale"
              ],
              "required": [
                "training_data_url"
              ]
            },
            "Ltx2V2vTrainerOutput": {
              "title": "LTX2V2VOutput",
              "type": "object",
              "properties": {
                "lora_file": {
                  "description": "URL to the trained IC-LoRA weights (.safetensors).",
                  "$ref": "#/components/schemas/File"
                },
                "config_file": {
                  "description": "Configuration used for setting up inference endpoints.",
                  "$ref": "#/components/schemas/File"
                },
                "debug_dataset": {
                  "anyOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "URL to the debug dataset archive containing decoded videos."
                },
                "video": {
                  "anyOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The URL to the validation videos (with reference videos side-by-side), if any."
                }
              },
              "description": "Output from LTX-2 video-to-video training.",
              "x-fal-order-properties": [
                "video",
                "lora_file",
                "config_file",
                "debug_dataset"
              ],
              "required": [
                "video",
                "lora_file",
                "config_file"
              ]
            },
            "V2VValidation": {
              "title": "V2VValidation",
              "type": "object",
              "properties": {
                "prompt": {
                  "title": "Prompt",
                  "type": "string",
                  "description": "The prompt to use for validation."
                },
                "reference_video_url": {
                  "title": "Reference Video Url",
                  "minLength": 1,
                  "description": "URL to reference video for IC-LoRA validation. This is the input video that will be transformed.",
                  "type": "string"
                }
              },
              "description": "Validation input for video-to-video training.",
              "x-fal-order-properties": [
                "prompt",
                "reference_video_url"
              ],
              "required": [
                "prompt",
                "reference_video_url"
              ]
            },
            "File": {
              "title": "File",
              "type": "object",
              "properties": {
                "file_size": {
                  "examples": [
                    4404019
                  ],
                  "title": "File Size",
                  "anyOf": [
                    {
                      "type": "integer"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The size of the file in bytes."
                },
                "file_name": {
                  "examples": [
                    "z9RV14K95DvU.png"
                  ],
                  "title": "File Name",
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The name of the file. It will be auto-generated if not provided."
                },
                "content_type": {
                  "examples": [
                    "image/png"
                  ],
                  "title": "Content Type",
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The mime type of the file."
                },
                "url": {
                  "title": "Url",
                  "type": "string",
                  "description": "The URL where the file can be downloaded from."
                }
              },
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size"
              ],
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/ltx2-v2v-trainer/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/ltx2-v2v-trainer/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/ltx2-v2v-trainer": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/Ltx2V2vTrainerInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/ltx2-v2v-trainer/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/Ltx2V2vTrainerOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/ltx2-video-trainer",
      "metadata": {
        "display_name": "LTX-2 Video Trainer",
        "category": "training",
        "description": "Train LTX-2 for custom styles and effects.",
        "status": "active",
        "tags": [
          "ltx2-video",
          "fine-tuning"
        ],
        "updated_at": "2026-01-26T21:41:43.411Z",
        "is_favorited": false,
        "thumbnail_url": "https://v3b.fal.media/files/b/0a88dc8e/AzUBOgcNgP8TwHeO0UVHX_221203c7df6149b6ab546c6243092128.jpg",
        "model_url": "https://fal.run/fal-ai/ltx2-video-trainer",
        "license_type": "commercial",
        "date": "2026-01-03T04:40:56.768Z",
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/ltx-2-19b/text-to-video/lora",
          "fal-ai/ltx-2-19b/extend-video/lora",
          "fal-ai/ltx-2-19b/image-to-video/lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/ltx2-video-trainer",
          "version": "1.0.0",
          "description": "The OpenAPI schema for the fal-ai/ltx2-video-trainer queue.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/ltx2-video-trainer",
            "category": "training",
            "thumbnailUrl": "https://v3b.fal.media/files/b/0a88dc8e/AzUBOgcNgP8TwHeO0UVHX_221203c7df6149b6ab546c6243092128.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/ltx2-video-trainer",
            "documentationUrl": "https://fal.ai/models/fal-ai/ltx2-video-trainer/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "Ltx2VideoTrainerInput": {
              "description": "Input configuration for LTX-2 text-to-video training.",
              "type": "object",
              "properties": {
                "number_of_steps": {
                  "description": "The number of training steps.",
                  "type": "integer",
                  "minimum": 100,
                  "maximum": 20000,
                  "title": "Number Of Steps",
                  "examples": [
                    2000
                  ],
                  "step": 100,
                  "default": 2000
                },
                "audio_preserve_pitch": {
                  "description": "When audio duration doesn't match video duration, stretch/compress audio without changing pitch. If disabled, audio is trimmed or padded with silence.",
                  "type": "boolean",
                  "title": "Audio Preserve Pitch",
                  "default": true
                },
                "frame_rate": {
                  "description": "Target frames per second for the video.",
                  "type": "integer",
                  "examples": [
                    25
                  ],
                  "maximum": 60,
                  "minimum": 8,
                  "title": "Frame Rate",
                  "default": 25
                },
                "audio_normalize": {
                  "description": "Normalize audio peak amplitude to a consistent level. Recommended for consistent audio levels across the dataset.",
                  "type": "boolean",
                  "title": "Audio Normalize",
                  "default": true
                },
                "validation": {
                  "description": "A list of validation prompts to use during training. When providing an image, _all_ validation inputs must have an image.",
                  "type": "array",
                  "maxItems": 2,
                  "title": "Validation",
                  "items": {
                    "$ref": "#/components/schemas/Validation"
                  },
                  "default": []
                },
                "learning_rate": {
                  "description": "Learning rate for optimization. Higher values can lead to faster training but may cause overfitting.",
                  "type": "number",
                  "minimum": 0.000001,
                  "maximum": 1,
                  "title": "Learning Rate",
                  "examples": [
                    0.0002
                  ],
                  "step": 0.0001,
                  "default": 0.0002
                },
                "number_of_frames": {
                  "description": "Number of frames per training sample. Must satisfy frames % 8 == 1 (e.g., 1, 9, 17, 25, 33, 41, 49, 57, 65, 73, 81, 89, 97).",
                  "type": "integer",
                  "examples": [
                    89
                  ],
                  "maximum": 121,
                  "minimum": 9,
                  "title": "Number Of Frames",
                  "default": 89
                },
                "training_data_url": {
                  "description": "URL to zip archive with videos or images. Try to use at least 10 files, although more is better.\n\n        **Supported video formats:** .mp4, .mov, .avi, .mkv\n        **Supported image formats:** .png, .jpg, .jpeg\n\n        Note: The dataset must contain ONLY videos OR ONLY images - mixed datasets are not supported.\n\n        The archive can also contain text files with captions. Each text file should have the same name as the media file it corresponds to.",
                  "type": "string",
                  "title": "Training Data Url"
                },
                "split_input_duration_threshold": {
                  "description": "The duration threshold in seconds. If a video is longer than this, it will be split into scenes.",
                  "type": "number",
                  "examples": [
                    30
                  ],
                  "maximum": 60,
                  "minimum": 1,
                  "title": "Split Input Duration Threshold",
                  "default": 30
                },
                "rank": {
                  "examples": [
                    32
                  ],
                  "description": "The rank of the LoRA adaptation. Higher values increase capacity but use more memory.",
                  "type": "integer",
                  "enum": [
                    8,
                    16,
                    32,
                    64,
                    128
                  ],
                  "title": "Rank",
                  "default": 32
                },
                "first_frame_conditioning_p": {
                  "minimum": 0,
                  "description": "Probability of conditioning on the first frame during training. Higher values improve image-to-video performance.",
                  "type": "number",
                  "maximum": 1,
                  "title": "First Frame Conditioning P",
                  "default": 0.5
                },
                "stg_scale": {
                  "minimum": 0,
                  "description": "STG (Spatio-Temporal Guidance) scale. 0.0 disables STG. Recommended value is 1.0.",
                  "type": "number",
                  "maximum": 3,
                  "title": "Stg Scale",
                  "default": 1
                },
                "aspect_ratio": {
                  "examples": [
                    "1:1"
                  ],
                  "description": "Aspect ratio to use for training.",
                  "type": "string",
                  "enum": [
                    "16:9",
                    "1:1",
                    "9:16"
                  ],
                  "title": "Aspect Ratio",
                  "default": "1:1"
                },
                "with_audio": {
                  "anyOf": [
                    {
                      "type": "boolean"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "Enable joint audio-video training. If None (default), automatically detects whether input videos have audio. Set to True to force audio training, or False to disable.",
                  "title": "With Audio"
                },
                "trigger_phrase": {
                  "examples": [
                    ""
                  ],
                  "description": "A phrase that will trigger the LoRA style. Will be prepended to captions during training.",
                  "type": "string",
                  "title": "Trigger Phrase",
                  "default": ""
                },
                "validation_frame_rate": {
                  "description": "Target frames per second for validation videos.",
                  "type": "integer",
                  "examples": [
                    25
                  ],
                  "maximum": 60,
                  "minimum": 8,
                  "title": "Validation Frame Rate",
                  "default": 25
                },
                "resolution": {
                  "examples": [
                    "medium"
                  ],
                  "description": "Resolution to use for training. Higher resolutions require more memory.",
                  "type": "string",
                  "enum": [
                    "low",
                    "medium",
                    "high"
                  ],
                  "title": "Resolution",
                  "default": "medium"
                },
                "split_input_into_scenes": {
                  "examples": [
                    true
                  ],
                  "description": "If true, videos above a certain duration threshold will be split into scenes.",
                  "type": "boolean",
                  "title": "Split Input Into Scenes",
                  "default": true
                },
                "generate_audio_in_validation": {
                  "description": "Whether to generate audio in validation samples.",
                  "type": "boolean",
                  "title": "Generate Audio In Validation",
                  "default": true
                },
                "validation_resolution": {
                  "examples": [
                    "high"
                  ],
                  "description": "The resolution to use for validation.",
                  "type": "string",
                  "enum": [
                    "low",
                    "medium",
                    "high"
                  ],
                  "title": "Validation Resolution",
                  "default": "high"
                },
                "validation_number_of_frames": {
                  "description": "The number of frames in validation videos.",
                  "type": "integer",
                  "examples": [
                    89
                  ],
                  "maximum": 121,
                  "minimum": 9,
                  "title": "Validation Number Of Frames",
                  "default": 89
                },
                "validation_aspect_ratio": {
                  "examples": [
                    "1:1"
                  ],
                  "description": "The aspect ratio to use for validation.",
                  "type": "string",
                  "enum": [
                    "16:9",
                    "1:1",
                    "9:16"
                  ],
                  "title": "Validation Aspect Ratio",
                  "default": "1:1"
                },
                "validation_negative_prompt": {
                  "description": "A negative prompt to use for validation.",
                  "type": "string",
                  "title": "Validation Negative Prompt",
                  "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
                },
                "auto_scale_input": {
                  "examples": [
                    false
                  ],
                  "description": "If true, videos will be automatically scaled to the target frame count and fps. This option has no effect on image datasets.",
                  "type": "boolean",
                  "title": "Auto Scale Input",
                  "default": false
                }
              },
              "x-fal-order-properties": [
                "training_data_url",
                "rank",
                "number_of_steps",
                "learning_rate",
                "number_of_frames",
                "frame_rate",
                "resolution",
                "aspect_ratio",
                "trigger_phrase",
                "auto_scale_input",
                "split_input_into_scenes",
                "split_input_duration_threshold",
                "with_audio",
                "audio_normalize",
                "audio_preserve_pitch",
                "first_frame_conditioning_p",
                "validation",
                "validation_negative_prompt",
                "validation_number_of_frames",
                "validation_frame_rate",
                "validation_resolution",
                "validation_aspect_ratio",
                "stg_scale",
                "generate_audio_in_validation"
              ],
              "title": "LTX2Input",
              "required": [
                "training_data_url"
              ]
            },
            "Ltx2VideoTrainerOutput": {
              "description": "Output from LTX-2 training.",
              "type": "object",
              "properties": {
                "lora_file": {
                  "description": "URL to the trained LoRA weights (.safetensors).",
                  "$ref": "#/components/schemas/File"
                },
                "config_file": {
                  "description": "Configuration used for setting up inference endpoints.",
                  "$ref": "#/components/schemas/File"
                },
                "debug_dataset": {
                  "anyOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "URL to the debug dataset archive containing decoded videos and audio."
                },
                "video": {
                  "anyOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The URL to the validation videos, if any."
                }
              },
              "x-fal-order-properties": [
                "video",
                "lora_file",
                "config_file",
                "debug_dataset"
              ],
              "title": "LTX2Output",
              "required": [
                "video",
                "lora_file",
                "config_file"
              ]
            },
            "Validation": {
              "x-fal-order-properties": [
                "prompt",
                "image_url"
              ],
              "type": "object",
              "properties": {
                "prompt": {
                  "description": "The prompt to use for validation.",
                  "type": "string",
                  "title": "Prompt"
                },
                "image_url": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "An image to use for image-to-video validation. If provided for one validation, _all_ validation inputs must have an image.",
                  "title": "Image Url"
                }
              },
              "title": "Validation",
              "required": [
                "prompt"
              ]
            },
            "File": {
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size"
              ],
              "type": "object",
              "properties": {
                "file_size": {
                  "examples": [
                    4404019
                  ],
                  "description": "The size of the file in bytes.",
                  "anyOf": [
                    {
                      "type": "integer"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "File Size"
                },
                "file_name": {
                  "examples": [
                    "z9RV14K95DvU.png"
                  ],
                  "description": "The name of the file. It will be auto-generated if not provided.",
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "File Name"
                },
                "content_type": {
                  "examples": [
                    "image/png"
                  ],
                  "description": "The mime type of the file.",
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "Content Type"
                },
                "url": {
                  "description": "The URL where the file can be downloaded from.",
                  "type": "string",
                  "title": "Url"
                }
              },
              "title": "File",
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/ltx2-video-trainer/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/ltx2-video-trainer/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/ltx2-video-trainer": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/Ltx2VideoTrainerInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/ltx2-video-trainer/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/Ltx2VideoTrainerOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/qwen-image-2512-trainer",
      "metadata": {
        "display_name": "Qwen Image 2512 Trainer",
        "category": "training",
        "description": "Qwen Image 2512 LoRA training",
        "status": "active",
        "tags": [
          "lora",
          "personalization"
        ],
        "updated_at": "2026-01-26T21:41:43.663Z",
        "is_favorited": false,
        "thumbnail_url": "https://v3b.fal.media/files/b/0a88971d/RI2dnHIfi0FJ7BCSy83hh_089d63dbaf4b491ca15894cad8ee4741.jpg",
        "model_url": "https://fal.run/fal-ai/qwen-image-2512-trainer",
        "license_type": "commercial",
        "date": "2026-01-01T03:13:13.085Z",
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/qwen-image-2512/lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/qwen-image-2512-trainer",
          "version": "1.0.0",
          "description": "The OpenAPI schema for the fal-ai/qwen-image-2512-trainer queue.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/qwen-image-2512-trainer",
            "category": "training",
            "thumbnailUrl": "https://v3b.fal.media/files/b/0a88971d/RI2dnHIfi0FJ7BCSy83hh_089d63dbaf4b491ca15894cad8ee4741.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/qwen-image-2512-trainer",
            "documentationUrl": "https://fal.ai/models/fal-ai/qwen-image-2512-trainer/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "QwenImage2512TrainerInput": {
              "x-fal-order-properties": [
                "image_data_url",
                "learning_rate",
                "steps",
                "default_caption"
              ],
              "type": "object",
              "properties": {
                "steps": {
                  "description": "Number of steps to train for",
                  "type": "integer",
                  "minimum": 100,
                  "maximum": 30000,
                  "title": "Steps",
                  "multipleOf": 100,
                  "default": 1000
                },
                "image_data_url": {
                  "description": "\n    URL to the input data zip archive for text-to-image training.\n\n    The zip should contain images with their corresponding text captions:\n\n    image.EXT and image.txt\n    For example:\n    photo.jpg and photo.txt\n\n    The text file contains the caption/prompt describing the target image.\n\n    If no text file is provided for an image, the default_caption will be used.\n\n    If no default_caption is provided and a text file is missing, the training will fail.\n    ",
                  "type": "string",
                  "title": "Image Data Url"
                },
                "learning_rate": {
                  "description": "Learning rate for LoRA parameters.",
                  "type": "number",
                  "title": "Learning Rate",
                  "default": 0.0005
                },
                "default_caption": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "Default caption to use when caption files are missing. If None, missing captions will cause an error.",
                  "title": "Default Caption"
                }
              },
              "title": "InputImage",
              "required": [
                "image_data_url"
              ]
            },
            "QwenImage2512TrainerOutput": {
              "x-fal-order-properties": [
                "diffusers_lora_file",
                "config_file"
              ],
              "type": "object",
              "properties": {
                "config_file": {
                  "description": "URL to the configuration file for the trained model.",
                  "$ref": "#/components/schemas/File"
                },
                "diffusers_lora_file": {
                  "description": "URL to the trained diffusers lora weights.",
                  "$ref": "#/components/schemas/File"
                }
              },
              "title": "Output",
              "required": [
                "diffusers_lora_file",
                "config_file"
              ]
            },
            "File": {
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size"
              ],
              "type": "object",
              "properties": {
                "file_size": {
                  "examples": [
                    4404019
                  ],
                  "description": "The size of the file in bytes.",
                  "anyOf": [
                    {
                      "type": "integer"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "File Size"
                },
                "file_name": {
                  "examples": [
                    "z9RV14K95DvU.png"
                  ],
                  "description": "The name of the file. It will be auto-generated if not provided.",
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "File Name"
                },
                "content_type": {
                  "examples": [
                    "image/png"
                  ],
                  "description": "The mime type of the file.",
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "Content Type"
                },
                "url": {
                  "description": "The URL where the file can be downloaded from.",
                  "type": "string",
                  "title": "Url"
                }
              },
              "title": "File",
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/qwen-image-2512-trainer/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/qwen-image-2512-trainer/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/qwen-image-2512-trainer": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/QwenImage2512TrainerInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/qwen-image-2512-trainer/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QwenImage2512TrainerOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/qwen-image-edit-2511-trainer",
      "metadata": {
        "display_name": "Qwen Image Edit 2511 Trainer",
        "category": "training",
        "description": "LoRA trainer for Qwen Image Edit 2511",
        "status": "active",
        "tags": [],
        "updated_at": "2026-01-26T21:41:47.856Z",
        "is_favorited": false,
        "thumbnail_url": "https://v3b.fal.media/files/b/0a877998/iFlGCuBjmBr937TUS4j0s_5ef9846274ec45628f2c1d61c23597c9.jpg",
        "model_url": "https://fal.run/fal-ai/qwen-image-edit-2511-trainer",
        "license_type": "commercial",
        "date": "2025-12-23T16:15:33.735Z",
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/qwen-image-edit-2511/lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/qwen-image-edit-2511-trainer",
          "version": "1.0.0",
          "description": "LoRA trainer for Qwen Image Edit 2511. Train custom LoRAs to extend the image editing functionality of Qwen Image Edit 2511",
          "x-fal-metadata": {
            "endpointId": "fal-ai/qwen-image-edit-2511-trainer",
            "category": "training",
            "thumbnailUrl": "https://v3b.fal.media/files/b/0a877998/iFlGCuBjmBr937TUS4j0s_5ef9846274ec45628f2c1d61c23597c9.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/qwen-image-edit-2511-trainer",
            "documentationUrl": "https://fal.ai/models/fal-ai/qwen-image-edit-2511-trainer/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "QwenImageEdit2511TrainerInput": {
              "x-fal-order-properties": [
                "image_data_url",
                "learning_rate",
                "steps",
                "default_caption"
              ],
              "type": "object",
              "properties": {
                "steps": {
                  "description": "Number of steps to train for",
                  "type": "integer",
                  "minimum": 100,
                  "maximum": 30000,
                  "title": "Steps",
                  "multipleOf": 100,
                  "default": 1000
                },
                "image_data_url": {
                  "description": "\n    URL to the input data zip archive.\n\n    The zip should contain pairs of images. The images should be named:\n\n    ROOT_start.EXT and ROOT_end.EXT\n    For example:\n    photo_start.jpg and photo_end.jpg\n\n    The zip can also contain more than one reference image for each image pair. The reference images should be named:\n    ROOT_start.EXT, ROOT_start2.EXT, ROOT_start3.EXT, ..., ROOT_end.EXT\n    For example:\n    photo_start.jpg, photo_start2.jpg, photo_end.jpg\n\n    The Reference Image Count field should be set to the number of reference images.\n\n    The zip can also contain a text file for each image pair. The text file should be named:\n    ROOT.txt\n    For example:\n    photo.txt\n\n    This text file can be used to specify the edit instructions for the image pair.\n\n    If no text file is provided, the default_caption will be used.\n\n    If no default_caption is provided, the training will fail.\n    ",
                  "type": "string",
                  "title": "Image Data Url"
                },
                "learning_rate": {
                  "description": "Learning rate for LoRA parameters.",
                  "type": "number",
                  "title": "Learning Rate",
                  "default": 0.0001
                },
                "default_caption": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "Default caption to use when caption files are missing. If None, missing captions will cause an error.",
                  "title": "Default Caption"
                }
              },
              "title": "Input2511",
              "required": [
                "image_data_url"
              ]
            },
            "QwenImageEdit2511TrainerOutput": {
              "x-fal-order-properties": [
                "diffusers_lora_file",
                "config_file"
              ],
              "type": "object",
              "properties": {
                "config_file": {
                  "description": "URL to the configuration file for the trained model.",
                  "$ref": "#/components/schemas/File"
                },
                "diffusers_lora_file": {
                  "description": "URL to the trained diffusers lora weights.",
                  "$ref": "#/components/schemas/File"
                }
              },
              "title": "Output",
              "required": [
                "diffusers_lora_file",
                "config_file"
              ]
            },
            "File": {
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size"
              ],
              "type": "object",
              "properties": {
                "file_size": {
                  "anyOf": [
                    {
                      "type": "integer"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The size of the file in bytes.",
                  "examples": [
                    4404019
                  ],
                  "title": "File Size"
                },
                "file_name": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The name of the file. It will be auto-generated if not provided.",
                  "examples": [
                    "z9RV14K95DvU.png"
                  ],
                  "title": "File Name"
                },
                "content_type": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The mime type of the file.",
                  "examples": [
                    "image/png"
                  ],
                  "title": "Content Type"
                },
                "url": {
                  "description": "The URL where the file can be downloaded from.",
                  "type": "string",
                  "title": "Url"
                }
              },
              "title": "File",
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/qwen-image-edit-2511-trainer/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/qwen-image-edit-2511-trainer/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/qwen-image-edit-2511-trainer": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/QwenImageEdit2511TrainerInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/qwen-image-edit-2511-trainer/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QwenImageEdit2511TrainerOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/qwen-image-layered-trainer",
      "metadata": {
        "display_name": "Qwen Image Layered Trainer",
        "category": "training",
        "description": "Train LoRAs for the Qwen-Image-Layered model, customize how images are split into layers.",
        "status": "active",
        "tags": [
          "qwen",
          "layer",
          "trainer"
        ],
        "updated_at": "2026-01-26T21:41:48.664Z",
        "is_favorited": false,
        "thumbnail_url": "https://v3b.fal.media/files/b/0a8768c3/UAxjM9u4oT0-qP6IRgdUG_75ddfb38008f4271abb4a22013275ac4.jpg",
        "model_url": "https://fal.run/fal-ai/qwen-image-layered-trainer",
        "license_type": "commercial",
        "date": "2025-12-23T04:17:31.192Z",
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/qwen-image-layered/lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/qwen-image-layered-trainer",
          "version": "1.0.0",
          "description": "The OpenAPI schema for the fal-ai/qwen-image-layered-trainer queue.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/qwen-image-layered-trainer",
            "category": "training",
            "thumbnailUrl": "https://v3b.fal.media/files/b/0a8768c3/UAxjM9u4oT0-qP6IRgdUG_75ddfb38008f4271abb4a22013275ac4.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/qwen-image-layered-trainer",
            "documentationUrl": "https://fal.ai/models/fal-ai/qwen-image-layered-trainer/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "QwenImageLayeredTrainerInput": {
              "x-fal-order-properties": [
                "image_data_url",
                "learning_rate",
                "steps",
                "default_caption"
              ],
              "type": "object",
              "properties": {
                "steps": {
                  "description": "Number of steps to train for",
                  "type": "integer",
                  "minimum": 100,
                  "maximum": 10000,
                  "title": "Steps",
                  "multipleOf": 100,
                  "default": 1000
                },
                "image_data_url": {
                  "title": "Image Data Url",
                  "type": "string",
                  "description": "\n    URL to the input data zip archive.\n\n    The zip should contain groups of images. The images should be named:\n\n    ROOT_start.EXT, ROOT_end.EXT, ROOT_end2.EXT, ..., ROOT_endN.EXT\n    For example:\n    photo_start.png, photo_end.png, photo_end2.png, ..., photo_endN.png\n\n    The start image is the base image that will be decomposed into layers.\n    The end images are the layers that will be added to the base image.  ROOT_end.EXT is the first layer, ROOT_end2.EXT is the second layer, and so on.\n    You can have up to 8 layers.\n    All image groups must have the same number of output layers.\n\n    The end images can contain transparent regions. Only PNG and WebP images are supported since these are the only formats that support transparency.\n\n    The zip can also contain a text file for each image group. The text file should be named:\n    ROOT.txt\n    For example:\n    photo.txt\n\n    This text file can be used to specify a description of the base image.\n\n    If no text file is provided, the default_caption will be used.\n\n    If no default_caption is provided, the training will fail.\n    "
                },
                "learning_rate": {
                  "title": "Learning Rate",
                  "type": "number",
                  "description": "Learning rate for LoRA parameters.",
                  "default": 0.0001
                },
                "default_caption": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "Default caption to use when caption files are missing. If None, missing captions will cause an error.",
                  "title": "Default Caption"
                }
              },
              "title": "Input",
              "required": [
                "image_data_url"
              ]
            },
            "QwenImageLayeredTrainerOutput": {
              "x-fal-order-properties": [
                "diffusers_lora_file",
                "config_file"
              ],
              "type": "object",
              "properties": {
                "config_file": {
                  "description": "URL to the configuration file for the trained model.",
                  "$ref": "#/components/schemas/File"
                },
                "diffusers_lora_file": {
                  "description": "URL to the trained diffusers lora weights.",
                  "$ref": "#/components/schemas/File"
                }
              },
              "title": "Output",
              "required": [
                "diffusers_lora_file",
                "config_file"
              ]
            },
            "File": {
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size"
              ],
              "type": "object",
              "properties": {
                "file_size": {
                  "examples": [
                    4404019
                  ],
                  "title": "File Size",
                  "anyOf": [
                    {
                      "type": "integer"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The size of the file in bytes."
                },
                "file_name": {
                  "examples": [
                    "z9RV14K95DvU.png"
                  ],
                  "title": "File Name",
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The name of the file. It will be auto-generated if not provided."
                },
                "content_type": {
                  "examples": [
                    "image/png"
                  ],
                  "title": "Content Type",
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The mime type of the file."
                },
                "url": {
                  "title": "Url",
                  "type": "string",
                  "description": "The URL where the file can be downloaded from."
                }
              },
              "title": "File",
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/qwen-image-layered-trainer/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/qwen-image-layered-trainer/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/qwen-image-layered-trainer": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/QwenImageLayeredTrainerInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/qwen-image-layered-trainer/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QwenImageLayeredTrainerOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/qwen-image-edit-2509-trainer",
      "metadata": {
        "display_name": "Qwen Image Edit 2509 Trainer",
        "category": "training",
        "description": "LoRA trainer for Qwen Image Edit 2509",
        "status": "active",
        "tags": [],
        "updated_at": "2026-01-26T21:41:57.285Z",
        "is_favorited": false,
        "thumbnail_url": "https://v3b.fal.media/files/b/kangaroo/JUf-sx4jdYBPYceTS7zZL_f65366a94795483fad050e560a86513a.jpg",
        "model_url": "https://fal.run/fal-ai/qwen-image-edit-2509-trainer",
        "license_type": "commercial",
        "date": "2025-12-15T21:18:42.940Z",
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/qwen-image-edit-2509-lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/qwen-image-edit-2509-trainer",
          "version": "1.0.0",
          "description": "LoRA trainer for Qwen Image Edit 2509. Train custom LoRAs to extend the image editing functionality of Qwen Image Edit 2509",
          "x-fal-metadata": {
            "endpointId": "fal-ai/qwen-image-edit-2509-trainer",
            "category": "training",
            "thumbnailUrl": "https://v3b.fal.media/files/b/kangaroo/JUf-sx4jdYBPYceTS7zZL_f65366a94795483fad050e560a86513a.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/qwen-image-edit-2509-trainer",
            "documentationUrl": "https://fal.ai/models/fal-ai/qwen-image-edit-2509-trainer/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "QwenImageEdit2509TrainerInput": {
              "title": "InputPlus",
              "type": "object",
              "properties": {
                "steps": {
                  "description": "Number of steps to train for",
                  "type": "integer",
                  "minimum": 100,
                  "title": "Steps",
                  "maximum": 30000,
                  "multipleOf": 100,
                  "default": 1000
                },
                "image_data_url": {
                  "title": "Image Data Url",
                  "type": "string",
                  "description": "\n    URL to the input data zip archive.\n\n    The zip should contain pairs of images. The images should be named:\n\n    ROOT_start.EXT and ROOT_end.EXT\n    For example:\n    photo_start.jpg and photo_end.jpg\n\n    The zip can also contain more than one reference image for each image pair. The reference images should be named:\n    ROOT_start.EXT, ROOT_start2.EXT, ROOT_start3.EXT, ..., ROOT_end.EXT\n    For example:\n    photo_start.jpg, photo_start2.jpg, photo_end.jpg\n\n    The Reference Image Count field should be set to the number of reference images.\n\n    The zip can also contain a text file for each image pair. The text file should be named:\n    ROOT.txt\n    For example:\n    photo.txt\n\n    This text file can be used to specify the edit instructions for the image pair.\n\n    If no text file is provided, the default_caption will be used.\n\n    If no default_caption is provided, the training will fail.\n    "
                },
                "learning_rate": {
                  "title": "Learning Rate",
                  "type": "number",
                  "description": "Learning rate for LoRA parameters.",
                  "default": 0.0001
                },
                "default_caption": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "Default caption to use when caption files are missing. If None, missing captions will cause an error.",
                  "title": "Default Caption"
                }
              },
              "x-fal-order-properties": [
                "image_data_url",
                "learning_rate",
                "steps",
                "default_caption"
              ],
              "required": [
                "image_data_url"
              ]
            },
            "QwenImageEdit2509TrainerOutput": {
              "title": "Output",
              "type": "object",
              "properties": {
                "config_file": {
                  "description": "URL to the configuration file for the trained model.",
                  "$ref": "#/components/schemas/File"
                },
                "diffusers_lora_file": {
                  "description": "URL to the trained diffusers lora weights.",
                  "$ref": "#/components/schemas/File"
                }
              },
              "x-fal-order-properties": [
                "diffusers_lora_file",
                "config_file"
              ],
              "required": [
                "diffusers_lora_file",
                "config_file"
              ]
            },
            "File": {
              "title": "File",
              "type": "object",
              "properties": {
                "file_size": {
                  "anyOf": [
                    {
                      "type": "integer"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The size of the file in bytes.",
                  "title": "File Size",
                  "examples": [
                    4404019
                  ]
                },
                "file_name": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The name of the file. It will be auto-generated if not provided.",
                  "title": "File Name",
                  "examples": [
                    "z9RV14K95DvU.png"
                  ]
                },
                "content_type": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The mime type of the file.",
                  "title": "Content Type",
                  "examples": [
                    "image/png"
                  ]
                },
                "url": {
                  "title": "Url",
                  "type": "string",
                  "description": "The URL where the file can be downloaded from."
                }
              },
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size"
              ],
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/qwen-image-edit-2509-trainer/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/qwen-image-edit-2509-trainer/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/qwen-image-edit-2509-trainer": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/QwenImageEdit2509TrainerInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/qwen-image-edit-2509-trainer/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QwenImageEdit2509TrainerOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/z-image-trainer",
      "metadata": {
        "display_name": "Z Image Trainer",
        "category": "training",
        "description": "Train LoRAs on Z-Image Turbo, a super fast text-to-image model of 6B parameters developed by Tongyi-MAI.",
        "status": "active",
        "tags": [
          "turbo",
          "z-image",
          "fast",
          "trainer"
        ],
        "updated_at": "2026-01-26T21:42:06.044Z",
        "is_favorited": false,
        "thumbnail_url": "https://v3b.fal.media/files/b/0a84daae/ubfu5r0bOZVRBN1_V5AJY_fb0dc5421f4e413ba4a8c94c2e043225.jpg",
        "model_url": "https://fal.run/fal-ai/z-image-trainer",
        "license_type": "commercial",
        "date": "2025-12-03T19:09:57.722Z",
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/z-image/turbo/lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/z-image-trainer",
          "version": "1.0.0",
          "description": "The OpenAPI schema for the fal-ai/z-image-trainer queue.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/z-image-trainer",
            "category": "training",
            "thumbnailUrl": "https://v3b.fal.media/files/b/0a84daae/ubfu5r0bOZVRBN1_V5AJY_fb0dc5421f4e413ba4a8c94c2e043225.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/z-image-trainer",
            "documentationUrl": "https://fal.ai/models/fal-ai/z-image-trainer/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "ZImageTrainerInput": {
              "title": "Input",
              "type": "object",
              "properties": {
                "steps": {
                  "description": "Total number of training steps.",
                  "type": "integer",
                  "minimum": 100,
                  "title": "Steps",
                  "maximum": 10000,
                  "multipleOf": 100,
                  "default": 1000
                },
                "image_data_url": {
                  "title": "Image Data Url",
                  "type": "string",
                  "description": "\n    URL to zip archive with images of a consistent style. Try to use at least 10 images, although more is better.\n\n    The zip can also contain a text file for each image. The text file should be named:\n    ROOT.txt\n    For example:\n    photo.txt\n\n    This text file can be used to specify the edit instructions for the image pair.\n\n    If no text file is provided, the default_caption will be used.\n\n    If no default_caption is provided, the training will fail.\n    "
                },
                "training_type": {
                  "enum": [
                    "content",
                    "style",
                    "balanced"
                  ],
                  "title": "Training Type",
                  "type": "string",
                  "description": "Type of training to perform. Use 'content' to focus on the content of the images, 'style' to focus on the style of the images, and 'balanced' to focus on a combination of both.",
                  "default": "balanced"
                },
                "learning_rate": {
                  "title": "Learning Rate",
                  "type": "number",
                  "description": "Learning rate applied to trainable parameters.",
                  "default": 0.0001
                },
                "default_caption": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "Default Caption",
                  "description": "Default caption to use when caption files are missing. If None, missing captions will cause an error."
                }
              },
              "x-fal-order-properties": [
                "image_data_url",
                "steps",
                "learning_rate",
                "default_caption",
                "training_type"
              ],
              "required": [
                "image_data_url"
              ]
            },
            "ZImageTrainerOutput": {
              "title": "Output",
              "type": "object",
              "properties": {
                "config_file": {
                  "description": "URL to the configuration file for the trained model.",
                  "$ref": "#/components/schemas/File"
                },
                "diffusers_lora_file": {
                  "description": "URL to the trained diffusers lora weights.",
                  "$ref": "#/components/schemas/File"
                }
              },
              "x-fal-order-properties": [
                "diffusers_lora_file",
                "config_file"
              ],
              "required": [
                "diffusers_lora_file",
                "config_file"
              ]
            },
            "File": {
              "title": "File",
              "type": "object",
              "properties": {
                "file_size": {
                  "examples": [
                    4404019
                  ],
                  "title": "File Size",
                  "description": "The size of the file in bytes.",
                  "anyOf": [
                    {
                      "type": "integer"
                    },
                    {
                      "type": "null"
                    }
                  ]
                },
                "file_name": {
                  "examples": [
                    "z9RV14K95DvU.png"
                  ],
                  "title": "File Name",
                  "description": "The name of the file. It will be auto-generated if not provided.",
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ]
                },
                "content_type": {
                  "examples": [
                    "image/png"
                  ],
                  "title": "Content Type",
                  "description": "The mime type of the file.",
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ]
                },
                "url": {
                  "title": "Url",
                  "type": "string",
                  "description": "The URL where the file can be downloaded from."
                }
              },
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size"
              ],
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/z-image-trainer/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/z-image-trainer/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/z-image-trainer": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/ZImageTrainerInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/z-image-trainer/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/ZImageTrainerOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/flux-2-trainer/edit",
      "metadata": {
        "display_name": "Flux 2 Trainer",
        "category": "training",
        "description": "Fine-tune FLUX.2 [dev] from Black Forest Labs with custom datasets. Create specialized LoRA adaptations for specific editing tasks.",
        "status": "active",
        "tags": [],
        "updated_at": "2026-01-26T21:42:13.657Z",
        "is_favorited": false,
        "thumbnail_url": "https://v3b.fal.media/files/b/rabbit/QQxycBXjY75hch-HBAQKZ_4af8ba3ddb9d457ba5fc51fcd428e720.jpg",
        "model_url": "https://fal.run/fal-ai/flux-2-trainer/edit",
        "license_type": "commercial",
        "date": "2025-11-25T04:36:01.280Z",
        "group": {
          "key": "flux2-trainer",
          "label": "Edit"
        },
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/flux-2/lora/edit"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/flux-2-trainer/edit",
          "version": "1.0.0",
          "description": "Train image editing LoRAs for FLUX.2 [dev], BFL's latest image model. FLUX.2 [dev] offers enhanced realism, crisper and more accurate text generation, and native image editing capabilities.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/flux-2-trainer/edit",
            "category": "training",
            "thumbnailUrl": "https://v3b.fal.media/files/b/rabbit/QQxycBXjY75hch-HBAQKZ_4af8ba3ddb9d457ba5fc51fcd428e720.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/flux-2-trainer/edit",
            "documentationUrl": "https://fal.ai/models/fal-ai/flux-2-trainer/edit/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "Flux2TrainerEditInput": {
              "title": "InputEdit",
              "type": "object",
              "properties": {
                "steps": {
                  "description": "Total number of training steps.",
                  "type": "integer",
                  "minimum": 100,
                  "title": "Steps",
                  "maximum": 10000,
                  "multipleOf": 100,
                  "default": 1000
                },
                "image_data_url": {
                  "title": "Image Data Url",
                  "type": "string",
                  "description": "\n    URL to the input data zip archive.\n\n    The zip should contain pairs of images. The images should be named:\n\n    ROOT_start.EXT and ROOT_end.EXT\n    For example:\n    photo_start.jpg and photo_end.jpg\n\n    The zip can also contain up to four reference image for each image pair. The reference images should be named:\n    ROOT_start.EXT, ROOT_start2.EXT, ROOT_start3.EXT, ROOT_start4.EXT, ROOT_end.EXT\n    For example:\n    photo_start.jpg, photo_start2.jpg, photo_end.jpg\n\n    The zip can also contain a text file for each image pair. The text file should be named:\n    ROOT.txt\n    For example:\n    photo.txt\n\n    This text file can be used to specify the edit instructions for the image pair.\n\n    If no text file is provided, the default_caption will be used.\n\n    If no default_caption is provided, the training will fail.\n    "
                },
                "learning_rate": {
                  "title": "Learning Rate",
                  "type": "number",
                  "description": "Learning rate applied to trainable parameters.",
                  "default": 0.00005
                },
                "default_caption": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "Default Caption",
                  "description": "Default caption to use when caption files are missing. If None, missing captions will cause an error."
                },
                "output_lora_format": {
                  "enum": [
                    "fal",
                    "comfy"
                  ],
                  "title": "Output Lora Format",
                  "type": "string",
                  "description": "Dictates the naming scheme for the output weights",
                  "default": "fal"
                }
              },
              "x-fal-order-properties": [
                "image_data_url",
                "steps",
                "learning_rate",
                "default_caption",
                "output_lora_format"
              ],
              "required": [
                "image_data_url"
              ]
            },
            "Flux2TrainerEditOutput": {
              "title": "Output",
              "type": "object",
              "properties": {
                "config_file": {
                  "description": "URL to the configuration file for the trained model.",
                  "$ref": "#/components/schemas/File"
                },
                "diffusers_lora_file": {
                  "description": "URL to the trained diffusers lora weights.",
                  "$ref": "#/components/schemas/File"
                }
              },
              "x-fal-order-properties": [
                "diffusers_lora_file",
                "config_file"
              ],
              "required": [
                "diffusers_lora_file",
                "config_file"
              ]
            },
            "File": {
              "title": "File",
              "type": "object",
              "properties": {
                "file_size": {
                  "anyOf": [
                    {
                      "type": "integer"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "File Size",
                  "description": "The size of the file in bytes.",
                  "examples": [
                    4404019
                  ]
                },
                "file_name": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "File Name",
                  "description": "The name of the file. It will be auto-generated if not provided.",
                  "examples": [
                    "z9RV14K95DvU.png"
                  ]
                },
                "content_type": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "Content Type",
                  "description": "The mime type of the file.",
                  "examples": [
                    "image/png"
                  ]
                },
                "url": {
                  "title": "Url",
                  "type": "string",
                  "description": "The URL where the file can be downloaded from."
                }
              },
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size"
              ],
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/flux-2-trainer/edit/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-2-trainer/edit/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-2-trainer/edit": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/Flux2TrainerEditInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-2-trainer/edit/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/Flux2TrainerEditOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/flux-2-trainer",
      "metadata": {
        "display_name": "Flux 2 Trainer",
        "category": "training",
        "description": "Fine-tune FLUX.2 [dev] from Black Forest Labs with custom datasets. Create specialized LoRA adaptations for specific styles and domains.",
        "status": "active",
        "tags": [],
        "updated_at": "2026-01-26T21:42:13.787Z",
        "is_favorited": false,
        "thumbnail_url": "https://v3b.fal.media/files/b/tiger/nYv87OHdt503yjlNUk1P3_2551388f5f4e4537b67e8ed436333bca.jpg",
        "model_url": "https://fal.run/fal-ai/flux-2-trainer",
        "license_type": "commercial",
        "date": "2025-11-25T04:33:24.920Z",
        "group": {
          "key": "flux2-trainer",
          "label": "Text to Image"
        },
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/flux-2/lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/flux-2-trainer",
          "version": "1.0.0",
          "description": "Train text-to-image LoRAs for Flux.2, BFL's latest image model. Flux.2 offers enhanced realism, crisper and more accurate text generation, and native image editing capabilities.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/flux-2-trainer",
            "category": "training",
            "thumbnailUrl": "https://v3b.fal.media/files/b/tiger/nYv87OHdt503yjlNUk1P3_2551388f5f4e4537b67e8ed436333bca.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/flux-2-trainer",
            "documentationUrl": "https://fal.ai/models/fal-ai/flux-2-trainer/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "Flux2TrainerInput": {
              "title": "InputT2I",
              "type": "object",
              "properties": {
                "steps": {
                  "description": "Total number of training steps.",
                  "type": "integer",
                  "minimum": 100,
                  "title": "Steps",
                  "maximum": 10000,
                  "multipleOf": 100,
                  "default": 1000
                },
                "image_data_url": {
                  "title": "Image Data Url",
                  "type": "string",
                  "description": "\n    URL to zip archive with images of a consistent style. Try to use at least 10 images, although more is better.\n\n    The zip can also contain a text file for each image. The text file should be named:\n    ROOT.txt\n    For example:\n    photo.txt\n\n    This text file can be used to specify the edit instructions for the image pair.\n\n    If no text file is provided, the default_caption will be used.\n\n    If no default_caption is provided, the training will fail.\n    "
                },
                "learning_rate": {
                  "title": "Learning Rate",
                  "type": "number",
                  "description": "Learning rate applied to trainable parameters.",
                  "default": 0.00005
                },
                "default_caption": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "Default Caption",
                  "description": "Default caption to use when caption files are missing. If None, missing captions will cause an error."
                },
                "output_lora_format": {
                  "enum": [
                    "fal",
                    "comfy"
                  ],
                  "title": "Output Lora Format",
                  "type": "string",
                  "description": "Dictates the naming scheme for the output weights",
                  "default": "fal"
                }
              },
              "x-fal-order-properties": [
                "image_data_url",
                "steps",
                "learning_rate",
                "default_caption",
                "output_lora_format"
              ],
              "required": [
                "image_data_url"
              ]
            },
            "Flux2TrainerOutput": {
              "title": "Output",
              "type": "object",
              "properties": {
                "config_file": {
                  "description": "URL to the configuration file for the trained model.",
                  "$ref": "#/components/schemas/File"
                },
                "diffusers_lora_file": {
                  "description": "URL to the trained diffusers lora weights.",
                  "$ref": "#/components/schemas/File"
                }
              },
              "x-fal-order-properties": [
                "diffusers_lora_file",
                "config_file"
              ],
              "required": [
                "diffusers_lora_file",
                "config_file"
              ]
            },
            "File": {
              "title": "File",
              "type": "object",
              "properties": {
                "file_size": {
                  "anyOf": [
                    {
                      "type": "integer"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "File Size",
                  "description": "The size of the file in bytes.",
                  "examples": [
                    4404019
                  ]
                },
                "file_name": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "File Name",
                  "description": "The name of the file. It will be auto-generated if not provided.",
                  "examples": [
                    "z9RV14K95DvU.png"
                  ]
                },
                "content_type": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "Content Type",
                  "description": "The mime type of the file.",
                  "examples": [
                    "image/png"
                  ]
                },
                "url": {
                  "title": "Url",
                  "type": "string",
                  "description": "The URL where the file can be downloaded from."
                }
              },
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size"
              ],
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/flux-2-trainer/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-2-trainer/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-2-trainer": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/Flux2TrainerInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/flux-2-trainer/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/Flux2TrainerOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/qwen-image-edit-plus-trainer",
      "metadata": {
        "display_name": "Qwen Image Edit Plus Trainer",
        "category": "training",
        "description": "LoRA trainer for Qwen Image Edit Plus",
        "status": "active",
        "tags": [],
        "updated_at": "2026-01-26T21:42:28.817Z",
        "is_favorited": false,
        "thumbnail_url": "https://v3b.fal.media/files/b/kangaroo/JUf-sx4jdYBPYceTS7zZL_f65366a94795483fad050e560a86513a.jpg",
        "model_url": "https://fal.run/fal-ai/qwen-image-edit-plus-trainer",
        "license_type": "commercial",
        "date": "2025-10-30T18:26:29.952Z",
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/qwen-image-edit-plus-lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/qwen-image-edit-plus-trainer",
          "version": "1.0.0",
          "description": "LoRA trainer for Qwen Image Edit Plus. Train custom LoRAs to extend the image editing functionality of Qwen Image Edit Plus",
          "x-fal-metadata": {
            "endpointId": "fal-ai/qwen-image-edit-plus-trainer",
            "category": "training",
            "thumbnailUrl": "https://v3b.fal.media/files/b/kangaroo/JUf-sx4jdYBPYceTS7zZL_f65366a94795483fad050e560a86513a.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/qwen-image-edit-plus-trainer",
            "documentationUrl": "https://fal.ai/models/fal-ai/qwen-image-edit-plus-trainer/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "QwenImageEditPlusTrainerInput": {
              "title": "InputPlus",
              "type": "object",
              "properties": {
                "steps": {
                  "description": "Number of steps to train for",
                  "type": "integer",
                  "minimum": 100,
                  "title": "Steps",
                  "maximum": 30000,
                  "multipleOf": 100,
                  "default": 1000
                },
                "image_data_url": {
                  "title": "Image Data Url",
                  "type": "string",
                  "description": "\n    URL to the input data zip archive.\n\n    The zip should contain pairs of images. The images should be named:\n\n    ROOT_start.EXT and ROOT_end.EXT\n    For example:\n    photo_start.jpg and photo_end.jpg\n\n    The zip can also contain more than one reference image for each image pair. The reference images should be named:\n    ROOT_start.EXT, ROOT_start2.EXT, ROOT_start3.EXT, ..., ROOT_end.EXT\n    For example:\n    photo_start.jpg, photo_start2.jpg, photo_end.jpg\n\n    The Reference Image Count field should be set to the number of reference images.\n\n    The zip can also contain a text file for each image pair. The text file should be named:\n    ROOT.txt\n    For example:\n    photo.txt\n\n    This text file can be used to specify the edit instructions for the image pair.\n\n    If no text file is provided, the default_caption will be used.\n\n    If no default_caption is provided, the training will fail.\n    "
                },
                "learning_rate": {
                  "title": "Learning Rate",
                  "type": "number",
                  "description": "Learning rate for LoRA parameters.",
                  "default": 0.0001
                },
                "default_caption": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "Default caption to use when caption files are missing. If None, missing captions will cause an error.",
                  "title": "Default Caption"
                }
              },
              "x-fal-order-properties": [
                "image_data_url",
                "learning_rate",
                "steps",
                "default_caption"
              ],
              "required": [
                "image_data_url"
              ]
            },
            "QwenImageEditPlusTrainerOutput": {
              "title": "Output",
              "type": "object",
              "properties": {
                "config_file": {
                  "description": "URL to the configuration file for the trained model.",
                  "$ref": "#/components/schemas/File"
                },
                "diffusers_lora_file": {
                  "description": "URL to the trained diffusers lora weights.",
                  "$ref": "#/components/schemas/File"
                }
              },
              "x-fal-order-properties": [
                "diffusers_lora_file",
                "config_file"
              ],
              "required": [
                "diffusers_lora_file",
                "config_file"
              ]
            },
            "File": {
              "title": "File",
              "type": "object",
              "properties": {
                "file_size": {
                  "anyOf": [
                    {
                      "type": "integer"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The size of the file in bytes.",
                  "title": "File Size",
                  "examples": [
                    4404019
                  ]
                },
                "file_name": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The name of the file. It will be auto-generated if not provided.",
                  "title": "File Name",
                  "examples": [
                    "z9RV14K95DvU.png"
                  ]
                },
                "content_type": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The mime type of the file.",
                  "title": "Content Type",
                  "examples": [
                    "image/png"
                  ]
                },
                "url": {
                  "title": "Url",
                  "type": "string",
                  "description": "The URL where the file can be downloaded from."
                }
              },
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size"
              ],
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/qwen-image-edit-plus-trainer/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/qwen-image-edit-plus-trainer/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/qwen-image-edit-plus-trainer": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/QwenImageEditPlusTrainerInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/qwen-image-edit-plus-trainer/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QwenImageEditPlusTrainerOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/qwen-image-edit-trainer",
      "metadata": {
        "display_name": "Qwen Image Edit Trainer",
        "category": "training",
        "description": "LoRA trainer for Qwen Image Edit",
        "status": "active",
        "tags": [],
        "updated_at": "2026-01-26T21:42:28.946Z",
        "is_favorited": false,
        "thumbnail_url": "https://v3b.fal.media/files/b/rabbit/pB3FhNP-IEVkffftFpArb_54830ef85194496cbf11cf7f061cd2ba.jpg",
        "model_url": "https://fal.run/fal-ai/qwen-image-edit-trainer",
        "license_type": "commercial",
        "date": "2025-10-30T18:17:15.299Z",
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/qwen-image-edit-lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/qwen-image-edit-trainer",
          "version": "1.0.0",
          "description": "LoRA trainer for Qwen Image Edit. Train custom LoRAs to extend the image editing functionality of Qwen Image Edit",
          "x-fal-metadata": {
            "endpointId": "fal-ai/qwen-image-edit-trainer",
            "category": "training",
            "thumbnailUrl": "https://v3b.fal.media/files/b/rabbit/pB3FhNP-IEVkffftFpArb_54830ef85194496cbf11cf7f061cd2ba.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/qwen-image-edit-trainer",
            "documentationUrl": "https://fal.ai/models/fal-ai/qwen-image-edit-trainer/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "QwenImageEditTrainerInput": {
              "x-fal-order-properties": [
                "image_data_url",
                "learning_rate",
                "steps",
                "default_caption"
              ],
              "type": "object",
              "properties": {
                "steps": {
                  "description": "Number of steps to train for",
                  "type": "integer",
                  "minimum": 100,
                  "maximum": 30000,
                  "title": "Steps",
                  "multipleOf": 100,
                  "default": 1000
                },
                "image_data_url": {
                  "title": "Image Data Url",
                  "type": "string",
                  "description": "\n    URL to the input data zip archive.\n\n    The zip should contain pairs of images. The images should be named:\n\n    ROOT_start.EXT and ROOT_end.EXT\n    For example:\n    photo_start.jpg and photo_end.jpg\n\n    The zip can also contain a text file for each image pair. The text file should be named:\n    ROOT.txt\n    For example:\n    photo.txt\n\n    This text file can be used to specify the edit instructions for the image pair.\n\n    If no text file is provided, the default_caption will be used.\n\n    If no default_caption is provided, the training will fail.\n    "
                },
                "learning_rate": {
                  "title": "Learning Rate",
                  "type": "number",
                  "description": "Learning rate for LoRA parameters.",
                  "default": 0.0001
                },
                "default_caption": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "Default Caption",
                  "description": "Default caption to use when caption files are missing. If None, missing captions will cause an error."
                }
              },
              "title": "InputEdit",
              "required": [
                "image_data_url"
              ]
            },
            "QwenImageEditTrainerOutput": {
              "x-fal-order-properties": [
                "diffusers_lora_file",
                "config_file"
              ],
              "type": "object",
              "properties": {
                "config_file": {
                  "description": "URL to the configuration file for the trained model.",
                  "$ref": "#/components/schemas/File"
                },
                "diffusers_lora_file": {
                  "description": "URL to the trained diffusers lora weights.",
                  "$ref": "#/components/schemas/File"
                }
              },
              "title": "Output",
              "required": [
                "diffusers_lora_file",
                "config_file"
              ]
            },
            "File": {
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size"
              ],
              "type": "object",
              "properties": {
                "file_size": {
                  "anyOf": [
                    {
                      "type": "integer"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "File Size",
                  "examples": [
                    4404019
                  ],
                  "description": "The size of the file in bytes."
                },
                "file_name": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "File Name",
                  "examples": [
                    "z9RV14K95DvU.png"
                  ],
                  "description": "The name of the file. It will be auto-generated if not provided."
                },
                "content_type": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "Content Type",
                  "examples": [
                    "image/png"
                  ],
                  "description": "The mime type of the file."
                },
                "url": {
                  "title": "Url",
                  "type": "string",
                  "description": "The URL where the file can be downloaded from."
                }
              },
              "title": "File",
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/qwen-image-edit-trainer/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/qwen-image-edit-trainer/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/qwen-image-edit-trainer": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/QwenImageEditTrainerInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/qwen-image-edit-trainer/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QwenImageEditTrainerOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/qwen-image-trainer",
      "metadata": {
        "display_name": "Qwen Image Trainer",
        "category": "training",
        "description": "Qwen Image LoRA training",
        "status": "active",
        "tags": [
          "lora",
          "personalization"
        ],
        "updated_at": "2026-01-26T21:43:04.890Z",
        "is_favorited": false,
        "thumbnail_url": "https://fal.media/files/kangaroo/Ezdr45OqUN2jaBP8tBuqL_d7bb3b0fadd54124b9884975b7e2f626.jpg",
        "model_url": "https://fal.run/fal-ai/qwen-image-trainer",
        "license_type": "commercial",
        "date": "2025-08-14T01:23:07.232Z",
        "highlighted": false,
        "kind": "training",
        "duration_estimate": 35,
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/qwen-image"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/qwen-image-trainer",
          "version": "1.0.0",
          "description": "The OpenAPI schema for the fal-ai/qwen-image-trainer queue.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/qwen-image-trainer",
            "category": "training",
            "thumbnailUrl": "https://fal.media/files/kangaroo/Ezdr45OqUN2jaBP8tBuqL_d7bb3b0fadd54124b9884975b7e2f626.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/qwen-image-trainer",
            "documentationUrl": "https://fal.ai/models/fal-ai/qwen-image-trainer/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "QwenImageTrainerInput": {
              "title": "PublicInput",
              "type": "object",
              "properties": {
                "steps": {
                  "description": "Total number of training steps to perform. Default is 4000.",
                  "type": "integer",
                  "minimum": 1,
                  "maximum": 8000,
                  "title": "Steps",
                  "default": 1000
                },
                "image_data_url": {
                  "title": "Image Data Url",
                  "type": "string",
                  "description": "\n        URL to zip archive with images for training. The archive should contain images and corresponding text files with captions.\n        Each text file should have the same name as the image file it corresponds to (e.g., image1.jpg and image1.txt).\n        If text files are missing for some images, you can provide a trigger_phrase to automatically create them.\n        Supported image formats: PNG, JPG, JPEG, WEBP.\n        Try to use at least 10 images, although more is better.\n    "
                },
                "learning_rate": {
                  "minimum": 0.000001,
                  "maximum": 0.01,
                  "type": "number",
                  "title": "Learning Rate",
                  "description": "Learning rate for training. Default is 5e-4",
                  "default": 0.0005
                },
                "trigger_phrase": {
                  "title": "Trigger Phrase",
                  "type": "string",
                  "description": "Default caption to use for images that don't have corresponding text files. If provided, missing .txt files will be created automatically.",
                  "default": ""
                }
              },
              "x-fal-order-properties": [
                "image_data_url",
                "steps",
                "learning_rate",
                "trigger_phrase"
              ],
              "required": [
                "image_data_url"
              ]
            },
            "QwenImageTrainerOutput": {
              "title": "Output",
              "type": "object",
              "properties": {
                "lora_file": {
                  "title": "Lora File",
                  "description": "URL to the trained LoRA weights file.",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                },
                "config_file": {
                  "title": "Config File",
                  "description": "URL to the training configuration file.",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                }
              },
              "x-fal-order-properties": [
                "lora_file",
                "config_file"
              ],
              "required": [
                "lora_file",
                "config_file"
              ]
            },
            "File": {
              "title": "File",
              "type": "object",
              "properties": {
                "file_size": {
                  "examples": [
                    4404019
                  ],
                  "title": "File Size",
                  "type": "integer",
                  "description": "The size of the file in bytes."
                },
                "file_name": {
                  "examples": [
                    "z9RV14K95DvU.png"
                  ],
                  "title": "File Name",
                  "type": "string",
                  "description": "The name of the file. It will be auto-generated if not provided."
                },
                "content_type": {
                  "examples": [
                    "image/png"
                  ],
                  "title": "Content Type",
                  "type": "string",
                  "description": "The mime type of the file."
                },
                "url": {
                  "title": "Url",
                  "type": "string",
                  "description": "The URL where the file can be downloaded from."
                },
                "file_data": {
                  "format": "binary",
                  "title": "File Data",
                  "type": "string",
                  "description": "File data"
                }
              },
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size",
                "file_data"
              ],
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/qwen-image-trainer/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/qwen-image-trainer/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/qwen-image-trainer": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/QwenImageTrainerInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/qwen-image-trainer/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QwenImageTrainerOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/wan-22-image-trainer",
      "metadata": {
        "display_name": "Wan 2.2 14B Image Trainer",
        "category": "training",
        "description": "Wan 2.2 text to image LoRA trainer. Fine-tune Wan 2.2 for subjects and styles with unprecedented detail.",
        "status": "active",
        "tags": [
          "lora",
          "personalization"
        ],
        "updated_at": "2026-01-26T21:43:05.770Z",
        "is_favorited": false,
        "thumbnail_url": "https://fal.media/files/koala/1VUig6knsJ9-DAf8eRzBQ_5a0e3e33bbbf4d869ec368fa31f8700e.jpg",
        "model_url": "https://fal.run/fal-ai/wan-22-image-trainer",
        "license_type": "commercial",
        "date": "2025-08-11T05:09:18.685Z",
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/wan/v2.2-a14b/text-to-image/lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/wan-22-image-trainer",
          "version": "1.0.0",
          "description": "Wan 2.2 text to image LoRA trainer. Fine-tune Wan 2.2 for subjects and styles with unprecedented detail.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/wan-22-image-trainer",
            "category": "training",
            "thumbnailUrl": "https://fal.media/files/koala/1VUig6knsJ9-DAf8eRzBQ_5a0e3e33bbbf4d869ec368fa31f8700e.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/wan-22-image-trainer",
            "documentationUrl": "https://fal.ai/models/fal-ai/wan-22-image-trainer/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "Wan22ImageTrainerInput": {
              "x-fal-order-properties": [
                "training_data_url",
                "trigger_phrase",
                "include_synthetic_captions",
                "use_face_detection",
                "use_face_cropping",
                "use_masks",
                "steps",
                "learning_rate",
                "is_style"
              ],
              "type": "object",
              "properties": {
                "trigger_phrase": {
                  "description": "Trigger phrase for the model.",
                  "type": "string",
                  "title": "Trigger Phrase"
                },
                "use_masks": {
                  "examples": [
                    true
                  ],
                  "description": "Whether to use masks for the training data.",
                  "type": "boolean",
                  "title": "Use Masks",
                  "default": true
                },
                "learning_rate": {
                  "description": "Learning rate for training.",
                  "type": "number",
                  "examples": [
                    0.0007
                  ],
                  "title": "Learning Rate",
                  "minimum": 0.000001,
                  "maximum": 0.1,
                  "multipleOf": 0.000001,
                  "default": 0.0007
                },
                "use_face_cropping": {
                  "examples": [
                    false
                  ],
                  "description": "Whether to use face cropping for the training data. When enabled, images will be cropped to the face before resizing.",
                  "type": "boolean",
                  "title": "Use Face Cropping",
                  "default": false
                },
                "training_data_url": {
                  "description": "URL to the training data.",
                  "type": "string",
                  "title": "Training Data URL"
                },
                "steps": {
                  "description": "Number of training steps.",
                  "type": "integer",
                  "minimum": 10,
                  "title": "Number of Steps",
                  "examples": [
                    1000
                  ],
                  "maximum": 6000,
                  "default": 1000
                },
                "include_synthetic_captions": {
                  "description": "Whether to include synthetic captions.",
                  "type": "boolean",
                  "title": "Include Synthetic Captions",
                  "default": false
                },
                "is_style": {
                  "examples": [
                    false
                  ],
                  "description": "Whether the training data is style data. If true, face specific options like masking and face detection will be disabled.",
                  "type": "boolean",
                  "title": "Is Style",
                  "default": false
                },
                "use_face_detection": {
                  "examples": [
                    true
                  ],
                  "description": "Whether to use face detection for the training data. When enabled, images will use the center of the face as the center of the image when resizing.",
                  "type": "boolean",
                  "title": "Use Face Detection",
                  "default": true
                }
              },
              "title": "BasicInput",
              "required": [
                "training_data_url",
                "trigger_phrase"
              ]
            },
            "Wan22ImageTrainerOutput": {
              "x-fal-order-properties": [
                "diffusers_lora_file",
                "high_noise_lora",
                "config_file"
              ],
              "type": "object",
              "properties": {
                "config_file": {
                  "description": "Config file helping inference endpoints after training.",
                  "title": "Config File",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                },
                "high_noise_lora": {
                  "description": "High noise LoRA file.",
                  "title": "High Noise LoRA",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                },
                "diffusers_lora_file": {
                  "description": "Low noise LoRA file.",
                  "title": "Low Noise LoRA",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                }
              },
              "title": "WanTrainerResponse",
              "required": [
                "diffusers_lora_file",
                "high_noise_lora",
                "config_file"
              ]
            },
            "File": {
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size",
                "file_data"
              ],
              "type": "object",
              "properties": {
                "file_size": {
                  "examples": [
                    4404019
                  ],
                  "description": "The size of the file in bytes.",
                  "type": "integer",
                  "title": "File Size"
                },
                "file_name": {
                  "examples": [
                    "z9RV14K95DvU.png"
                  ],
                  "description": "The name of the file. It will be auto-generated if not provided.",
                  "type": "string",
                  "title": "File Name"
                },
                "content_type": {
                  "examples": [
                    "image/png"
                  ],
                  "description": "The mime type of the file.",
                  "type": "string",
                  "title": "Content Type"
                },
                "url": {
                  "description": "The URL where the file can be downloaded from.",
                  "type": "string",
                  "title": "Url"
                },
                "file_data": {
                  "format": "binary",
                  "description": "File data",
                  "type": "string",
                  "title": "File Data"
                }
              },
              "title": "File",
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/wan-22-image-trainer/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/wan-22-image-trainer/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/wan-22-image-trainer": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/Wan22ImageTrainerInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/wan-22-image-trainer/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/Wan22ImageTrainerOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/wan-trainer/t2v",
      "metadata": {
        "display_name": "Wan-2.1 LoRA Trainer",
        "category": "training",
        "description": "Train custom LoRAs for Wan-2.1 T2V 1.3B",
        "status": "active",
        "tags": [
          "lora",
          "training"
        ],
        "updated_at": "2026-01-26T21:43:28.626Z",
        "is_favorited": false,
        "thumbnail_url": "https://fal.media/files/monkey/ZQ0YvNuW1FVoX7wvAU5uE_0590d28948af442dbb20bd581085f8c3.jpg",
        "model_url": "https://fal.run/fal-ai/wan-trainer/t2v",
        "license_type": "commercial",
        "date": "2025-06-11T00:35:31.207Z",
        "group": {
          "key": "wan-trainer",
          "label": "T2V 1.3B"
        },
        "highlighted": false,
        "kind": "training",
        "pinned": false
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/wan-trainer/t2v",
          "version": "1.0.0",
          "description": "The OpenAPI schema for the fal-ai/wan-trainer/t2v queue.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/wan-trainer/t2v",
            "category": "training",
            "thumbnailUrl": "https://fal.media/files/monkey/ZQ0YvNuW1FVoX7wvAU5uE_0590d28948af442dbb20bd581085f8c3.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/wan-trainer/t2v",
            "documentationUrl": "https://fal.ai/models/fal-ai/wan-trainer/t2v/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "WanTrainerT2vInput": {
              "title": "Input",
              "type": "object",
              "properties": {
                "number_of_steps": {
                  "minimum": 1,
                  "maximum": 20000,
                  "type": "integer",
                  "title": "Number Of Steps",
                  "description": "The number of steps to train for.",
                  "default": 400
                },
                "training_data_url": {
                  "title": "Training Data URL",
                  "type": "string",
                  "description": "URL to zip archive with images of a consistent style. Try to use at least 10 images and/or videos, although more is better.\n\n        In addition to images the archive can contain text files with captions. Each text file should have the same name as the image/video file it corresponds to."
                },
                "trigger_phrase": {
                  "title": "Trigger Phrase",
                  "type": "string",
                  "description": "The phrase that will trigger the model to generate an image.",
                  "default": ""
                },
                "learning_rate": {
                  "minimum": 0.000001,
                  "maximum": 1,
                  "type": "number",
                  "title": "Learning Rate",
                  "description": "The rate at which the model learns. Higher values can lead to faster training, but over-fitting.",
                  "default": 0.0002
                },
                "auto_scale_input": {
                  "examples": [
                    true
                  ],
                  "title": "Auto-Scale Input",
                  "type": "boolean",
                  "description": "If true, the input will be automatically scale the video to 81 frames at 16fps.",
                  "default": false
                }
              },
              "x-fal-order-properties": [
                "training_data_url",
                "number_of_steps",
                "learning_rate",
                "trigger_phrase",
                "auto_scale_input"
              ],
              "required": [
                "training_data_url"
              ]
            },
            "WanTrainerT2vOutput": {
              "title": "Output",
              "type": "object",
              "properties": {
                "lora_file": {
                  "title": "Lora File",
                  "description": "URL to the trained LoRA weights.",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                },
                "config_file": {
                  "title": "Config File",
                  "description": "Configuration used for setting up the inference endpoints.",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                }
              },
              "x-fal-order-properties": [
                "lora_file",
                "config_file"
              ],
              "required": [
                "lora_file",
                "config_file"
              ]
            },
            "File": {
              "title": "File",
              "type": "object",
              "properties": {
                "file_size": {
                  "examples": [
                    4404019
                  ],
                  "title": "File Size",
                  "type": "integer",
                  "description": "The size of the file in bytes."
                },
                "file_name": {
                  "examples": [
                    "z9RV14K95DvU.png"
                  ],
                  "title": "File Name",
                  "type": "string",
                  "description": "The name of the file. It will be auto-generated if not provided."
                },
                "content_type": {
                  "examples": [
                    "image/png"
                  ],
                  "title": "Content Type",
                  "type": "string",
                  "description": "The mime type of the file."
                },
                "url": {
                  "title": "Url",
                  "type": "string",
                  "description": "The URL where the file can be downloaded from."
                },
                "file_data": {
                  "format": "binary",
                  "title": "File Data",
                  "type": "string",
                  "description": "File data"
                }
              },
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size",
                "file_data"
              ],
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/wan-trainer/t2v/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/wan-trainer/t2v/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/wan-trainer/t2v": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/WanTrainerT2vInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/wan-trainer/t2v/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/WanTrainerT2vOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/wan-trainer/t2v-14b",
      "metadata": {
        "display_name": "Wan-2.1 LoRA Trainer",
        "category": "training",
        "description": "Train custom LoRAs for Wan-2.1 T2V 14B",
        "status": "active",
        "tags": [
          "lora",
          "training"
        ],
        "updated_at": "2026-01-26T21:43:28.756Z",
        "is_favorited": false,
        "thumbnail_url": "https://fal.media/files/penguin/BtZ-j-cWvM_WqOtQGdjLj_a10682239ded4738a4e23ffc2a4ddeb4.jpg",
        "model_url": "https://fal.run/fal-ai/wan-trainer/t2v-14b",
        "license_type": "commercial",
        "date": "2025-06-11T00:34:42.291Z",
        "group": {
          "key": "wan-trainer",
          "label": "T2V 14B"
        },
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/wan-t2v-lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/wan-trainer/t2v-14b",
          "version": "1.0.0",
          "description": "The OpenAPI schema for the fal-ai/wan-trainer/t2v-14b queue.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/wan-trainer/t2v-14b",
            "category": "training",
            "thumbnailUrl": "https://fal.media/files/penguin/BtZ-j-cWvM_WqOtQGdjLj_a10682239ded4738a4e23ffc2a4ddeb4.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/wan-trainer/t2v-14b",
            "documentationUrl": "https://fal.ai/models/fal-ai/wan-trainer/t2v-14b/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "WanTrainerT2v14bInput": {
              "title": "Input",
              "type": "object",
              "properties": {
                "number_of_steps": {
                  "minimum": 1,
                  "maximum": 20000,
                  "type": "integer",
                  "title": "Number Of Steps",
                  "description": "The number of steps to train for.",
                  "default": 400
                },
                "training_data_url": {
                  "title": "Training Data URL",
                  "type": "string",
                  "description": "URL to zip archive with images of a consistent style. Try to use at least 10 images and/or videos, although more is better.\n\n        In addition to images the archive can contain text files with captions. Each text file should have the same name as the image/video file it corresponds to."
                },
                "trigger_phrase": {
                  "title": "Trigger Phrase",
                  "type": "string",
                  "description": "The phrase that will trigger the model to generate an image.",
                  "default": ""
                },
                "learning_rate": {
                  "minimum": 0.000001,
                  "maximum": 1,
                  "type": "number",
                  "title": "Learning Rate",
                  "description": "The rate at which the model learns. Higher values can lead to faster training, but over-fitting.",
                  "default": 0.0002
                },
                "auto_scale_input": {
                  "examples": [
                    true
                  ],
                  "title": "Auto-Scale Input",
                  "type": "boolean",
                  "description": "If true, the input will be automatically scale the video to 81 frames at 16fps.",
                  "default": false
                }
              },
              "x-fal-order-properties": [
                "training_data_url",
                "number_of_steps",
                "learning_rate",
                "trigger_phrase",
                "auto_scale_input"
              ],
              "required": [
                "training_data_url"
              ]
            },
            "WanTrainerT2v14bOutput": {
              "title": "Output",
              "type": "object",
              "properties": {
                "lora_file": {
                  "title": "Lora File",
                  "description": "URL to the trained LoRA weights.",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                },
                "config_file": {
                  "title": "Config File",
                  "description": "Configuration used for setting up the inference endpoints.",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                }
              },
              "x-fal-order-properties": [
                "lora_file",
                "config_file"
              ],
              "required": [
                "lora_file",
                "config_file"
              ]
            },
            "File": {
              "title": "File",
              "type": "object",
              "properties": {
                "file_size": {
                  "examples": [
                    4404019
                  ],
                  "title": "File Size",
                  "type": "integer",
                  "description": "The size of the file in bytes."
                },
                "file_name": {
                  "examples": [
                    "z9RV14K95DvU.png"
                  ],
                  "title": "File Name",
                  "type": "string",
                  "description": "The name of the file. It will be auto-generated if not provided."
                },
                "content_type": {
                  "examples": [
                    "image/png"
                  ],
                  "title": "Content Type",
                  "type": "string",
                  "description": "The mime type of the file."
                },
                "url": {
                  "title": "Url",
                  "type": "string",
                  "description": "The URL where the file can be downloaded from."
                },
                "file_data": {
                  "format": "binary",
                  "title": "File Data",
                  "type": "string",
                  "description": "File data"
                }
              },
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size",
                "file_data"
              ],
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/wan-trainer/t2v-14b/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/wan-trainer/t2v-14b/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/wan-trainer/t2v-14b": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/WanTrainerT2v14bInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/wan-trainer/t2v-14b/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/WanTrainerT2v14bOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/wan-trainer/i2v-720p",
      "metadata": {
        "display_name": "Wan-2.1 LoRA Trainer",
        "category": "training",
        "description": "Train custom LoRAs for Wan-2.1 I2V 720P",
        "status": "active",
        "tags": [
          "lora",
          "training"
        ],
        "updated_at": "2026-01-26T21:43:28.884Z",
        "is_favorited": false,
        "thumbnail_url": "https://fal.media/files/panda/R1H5KbqWR_DIyysIpr271_e73fd3a6acde48209bc152f277959385.jpg",
        "model_url": "https://fal.run/fal-ai/wan-trainer/i2v-720p",
        "license_type": "commercial",
        "date": "2025-06-11T00:33:08.714Z",
        "group": {
          "key": "wan-trainer",
          "label": "I2V 14B 720P"
        },
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/wan-i2v-lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/wan-trainer/i2v-720p",
          "version": "1.0.0",
          "description": "The OpenAPI schema for the fal-ai/wan-trainer/i2v-720p queue.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/wan-trainer/i2v-720p",
            "category": "training",
            "thumbnailUrl": "https://fal.media/files/panda/R1H5KbqWR_DIyysIpr271_e73fd3a6acde48209bc152f277959385.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/wan-trainer/i2v-720p",
            "documentationUrl": "https://fal.ai/models/fal-ai/wan-trainer/i2v-720p/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "WanTrainerI2v720pInput": {
              "title": "Input",
              "type": "object",
              "properties": {
                "number_of_steps": {
                  "minimum": 1,
                  "maximum": 20000,
                  "type": "integer",
                  "title": "Number Of Steps",
                  "description": "The number of steps to train for.",
                  "default": 400
                },
                "training_data_url": {
                  "title": "Training Data URL",
                  "type": "string",
                  "description": "URL to zip archive with images of a consistent style. Try to use at least 10 images and/or videos, although more is better.\n\n        In addition to images the archive can contain text files with captions. Each text file should have the same name as the image/video file it corresponds to."
                },
                "trigger_phrase": {
                  "title": "Trigger Phrase",
                  "type": "string",
                  "description": "The phrase that will trigger the model to generate an image.",
                  "default": ""
                },
                "learning_rate": {
                  "minimum": 0.000001,
                  "maximum": 1,
                  "type": "number",
                  "title": "Learning Rate",
                  "description": "The rate at which the model learns. Higher values can lead to faster training, but over-fitting.",
                  "default": 0.0002
                },
                "auto_scale_input": {
                  "examples": [
                    true
                  ],
                  "title": "Auto-Scale Input",
                  "type": "boolean",
                  "description": "If true, the input will be automatically scale the video to 81 frames at 16fps.",
                  "default": false
                }
              },
              "x-fal-order-properties": [
                "training_data_url",
                "number_of_steps",
                "learning_rate",
                "trigger_phrase",
                "auto_scale_input"
              ],
              "required": [
                "training_data_url"
              ]
            },
            "WanTrainerI2v720pOutput": {
              "title": "Output",
              "type": "object",
              "properties": {
                "lora_file": {
                  "title": "Lora File",
                  "description": "URL to the trained LoRA weights.",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                },
                "config_file": {
                  "title": "Config File",
                  "description": "Configuration used for setting up the inference endpoints.",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                }
              },
              "x-fal-order-properties": [
                "lora_file",
                "config_file"
              ],
              "required": [
                "lora_file",
                "config_file"
              ]
            },
            "File": {
              "title": "File",
              "type": "object",
              "properties": {
                "file_size": {
                  "examples": [
                    4404019
                  ],
                  "title": "File Size",
                  "type": "integer",
                  "description": "The size of the file in bytes."
                },
                "file_name": {
                  "examples": [
                    "z9RV14K95DvU.png"
                  ],
                  "title": "File Name",
                  "type": "string",
                  "description": "The name of the file. It will be auto-generated if not provided."
                },
                "content_type": {
                  "examples": [
                    "image/png"
                  ],
                  "title": "Content Type",
                  "type": "string",
                  "description": "The mime type of the file."
                },
                "url": {
                  "title": "Url",
                  "type": "string",
                  "description": "The URL where the file can be downloaded from."
                },
                "file_data": {
                  "format": "binary",
                  "title": "File Data",
                  "type": "string",
                  "description": "File data"
                }
              },
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size",
                "file_data"
              ],
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/wan-trainer/i2v-720p/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/wan-trainer/i2v-720p/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/wan-trainer/i2v-720p": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/WanTrainerI2v720pInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/wan-trainer/i2v-720p/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/WanTrainerI2v720pOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/wan-trainer/flf2v-720p",
      "metadata": {
        "display_name": "Wan-2.1 LoRA Trainer",
        "category": "training",
        "description": "Train custom LoRAs for Wan-2.1 FLF2V 720P",
        "status": "active",
        "tags": [
          "lora",
          "training"
        ],
        "updated_at": "2026-01-26T21:43:29.096Z",
        "is_favorited": false,
        "thumbnail_url": "https://fal.media/files/elephant/GRWFeDBLFXvbTF9b0lmJf_e269b3bf7ba147d3b56b0ee7b6e36439.jpg",
        "model_url": "https://fal.run/fal-ai/wan-trainer/flf2v-720p",
        "license_type": "commercial",
        "date": "2025-06-11T00:29:37.017Z",
        "group": {
          "key": "wan-trainer",
          "label": "FLF2V 14B 720P"
        },
        "highlighted": false,
        "kind": "training",
        "pinned": false
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/wan-trainer/flf2v-720p",
          "version": "1.0.0",
          "description": "The OpenAPI schema for the fal-ai/wan-trainer/flf2v-720p queue.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/wan-trainer/flf2v-720p",
            "category": "training",
            "thumbnailUrl": "https://fal.media/files/elephant/GRWFeDBLFXvbTF9b0lmJf_e269b3bf7ba147d3b56b0ee7b6e36439.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/wan-trainer/flf2v-720p",
            "documentationUrl": "https://fal.ai/models/fal-ai/wan-trainer/flf2v-720p/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "WanTrainerFlf2v720pInput": {
              "title": "Input",
              "type": "object",
              "properties": {
                "number_of_steps": {
                  "minimum": 1,
                  "maximum": 20000,
                  "type": "integer",
                  "title": "Number Of Steps",
                  "description": "The number of steps to train for.",
                  "default": 400
                },
                "training_data_url": {
                  "title": "Training Data URL",
                  "type": "string",
                  "description": "URL to zip archive with images of a consistent style. Try to use at least 10 images and/or videos, although more is better.\n\n        In addition to images the archive can contain text files with captions. Each text file should have the same name as the image/video file it corresponds to."
                },
                "trigger_phrase": {
                  "title": "Trigger Phrase",
                  "type": "string",
                  "description": "The phrase that will trigger the model to generate an image.",
                  "default": ""
                },
                "learning_rate": {
                  "minimum": 0.000001,
                  "maximum": 1,
                  "type": "number",
                  "title": "Learning Rate",
                  "description": "The rate at which the model learns. Higher values can lead to faster training, but over-fitting.",
                  "default": 0.0002
                },
                "auto_scale_input": {
                  "examples": [
                    true
                  ],
                  "title": "Auto-Scale Input",
                  "type": "boolean",
                  "description": "If true, the input will be automatically scale the video to 81 frames at 16fps.",
                  "default": false
                }
              },
              "x-fal-order-properties": [
                "training_data_url",
                "number_of_steps",
                "learning_rate",
                "trigger_phrase",
                "auto_scale_input"
              ],
              "required": [
                "training_data_url"
              ]
            },
            "WanTrainerFlf2v720pOutput": {
              "title": "Output",
              "type": "object",
              "properties": {
                "lora_file": {
                  "title": "Lora File",
                  "description": "URL to the trained LoRA weights.",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                },
                "config_file": {
                  "title": "Config File",
                  "description": "Configuration used for setting up the inference endpoints.",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                }
              },
              "x-fal-order-properties": [
                "lora_file",
                "config_file"
              ],
              "required": [
                "lora_file",
                "config_file"
              ]
            },
            "File": {
              "title": "File",
              "type": "object",
              "properties": {
                "file_size": {
                  "examples": [
                    4404019
                  ],
                  "title": "File Size",
                  "type": "integer",
                  "description": "The size of the file in bytes."
                },
                "file_name": {
                  "examples": [
                    "z9RV14K95DvU.png"
                  ],
                  "title": "File Name",
                  "type": "string",
                  "description": "The name of the file. It will be auto-generated if not provided."
                },
                "content_type": {
                  "examples": [
                    "image/png"
                  ],
                  "title": "Content Type",
                  "type": "string",
                  "description": "The mime type of the file."
                },
                "url": {
                  "title": "Url",
                  "type": "string",
                  "description": "The URL where the file can be downloaded from."
                },
                "file_data": {
                  "format": "binary",
                  "title": "File Data",
                  "type": "string",
                  "description": "File data"
                }
              },
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size",
                "file_data"
              ],
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/wan-trainer/flf2v-720p/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/wan-trainer/flf2v-720p/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/wan-trainer/flf2v-720p": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/WanTrainerFlf2v720pInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/wan-trainer/flf2v-720p/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/WanTrainerFlf2v720pOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/ltx-video-trainer",
      "metadata": {
        "display_name": "LTX Video Trainer",
        "category": "training",
        "description": "Train LTX Video 0.9.7 for custom styles and effects.",
        "status": "active",
        "tags": [
          "ltx-video",
          "fine-tuning"
        ],
        "updated_at": "2026-01-26T21:43:46.136Z",
        "is_favorited": false,
        "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Training-3.jpg",
        "model_url": "https://fal.run/fal-ai/ltx-video-trainer",
        "license_type": "commercial",
        "date": "2025-05-08T19:29:59.104Z",
        "highlighted": false,
        "kind": "training",
        "duration_estimate": 20,
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/ltx-video-lora/image-to-video"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/ltx-video-trainer",
          "version": "1.0.0",
          "description": "The OpenAPI schema for the fal-ai/ltx-video-trainer queue.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/ltx-video-trainer",
            "category": "training",
            "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training-3.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/ltx-video-trainer",
            "documentationUrl": "https://fal.ai/models/fal-ai/ltx-video-trainer/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "LtxVideoTrainerInput": {
              "x-fal-order-properties": [
                "training_data_url",
                "rank",
                "number_of_steps",
                "number_of_frames",
                "frame_rate",
                "resolution",
                "aspect_ratio",
                "learning_rate",
                "trigger_phrase",
                "auto_scale_input",
                "split_input_into_scenes",
                "split_input_duration_threshold",
                "validation",
                "validation_negative_prompt",
                "validation_number_of_frames",
                "validation_resolution",
                "validation_aspect_ratio",
                "validation_reverse"
              ],
              "type": "object",
              "properties": {
                "number_of_steps": {
                  "description": "The number of steps to train for.",
                  "type": "integer",
                  "minimum": 100,
                  "maximum": 20000,
                  "title": "Number Of Steps",
                  "examples": [
                    1000
                  ],
                  "step": 100,
                  "default": 1000
                },
                "frame_rate": {
                  "description": "The target frames per second for the video.",
                  "type": "integer",
                  "minimum": 8,
                  "maximum": 60,
                  "title": "Frame Rate",
                  "examples": [
                    25
                  ],
                  "default": 25
                },
                "learning_rate": {
                  "description": "The rate at which the model learns. Higher values can lead to faster training, but over-fitting.",
                  "type": "number",
                  "minimum": 0.000001,
                  "maximum": 1,
                  "title": "Learning Rate",
                  "examples": [
                    0.0002
                  ],
                  "step": 0.0001,
                  "default": 0.0002
                },
                "validation": {
                  "description": "A list of validation prompts to use during training. When providing an image, _all_ validation inputs must have an image.",
                  "type": "array",
                  "maxItems": 2,
                  "title": "Validation",
                  "items": {
                    "$ref": "#/components/schemas/Validation"
                  },
                  "default": []
                },
                "number_of_frames": {
                  "description": "The number of frames to use for training. This is the number of frames per second multiplied by the number of seconds.",
                  "type": "integer",
                  "minimum": 25,
                  "maximum": 121,
                  "title": "Number Of Frames",
                  "examples": [
                    81
                  ],
                  "default": 81
                },
                "validation_reverse": {
                  "description": "If true, the validation videos will be reversed. This is useful for effects that are learned in reverse and then applied in reverse.",
                  "type": "boolean",
                  "title": "Validation Reverse",
                  "default": false
                },
                "training_data_url": {
                  "description": "URL to zip archive with videos or images. Try to use at least 10 files, although more is better.\n\n        **Supported video formats:** .mp4, .mov, .avi, .mkv\n        **Supported image formats:** .png, .jpg, .jpeg\n\n        Note: The dataset must contain ONLY videos OR ONLY images - mixed datasets are not supported.\n\n        The archive can also contain text files with captions. Each text file should have the same name as the media file it corresponds to.",
                  "type": "string",
                  "title": "Training Data Url"
                },
                "split_input_duration_threshold": {
                  "description": "The duration threshold in seconds. If a video is longer than this, it will be split into scenes. If you provide captions for a split video, the caption will be applied to each scene. If you do not provide captions, scenes will be auto-captioned.",
                  "type": "number",
                  "minimum": 1,
                  "maximum": 60,
                  "title": "Split Input Duration Threshold",
                  "examples": [
                    30
                  ],
                  "default": 30
                },
                "rank": {
                  "enum": [
                    8,
                    16,
                    32,
                    64,
                    128
                  ],
                  "description": "The rank of the LoRA.",
                  "type": "integer",
                  "title": "Rank",
                  "examples": [
                    128
                  ],
                  "default": 128
                },
                "aspect_ratio": {
                  "enum": [
                    "16:9",
                    "1:1",
                    "9:16"
                  ],
                  "description": "The aspect ratio to use for training. This is the aspect ratio of the video.",
                  "type": "string",
                  "title": "Aspect Ratio",
                  "examples": [
                    "1:1"
                  ],
                  "default": "1:1"
                },
                "trigger_phrase": {
                  "examples": [
                    ""
                  ],
                  "description": "The phrase that will trigger the model to generate an image.",
                  "type": "string",
                  "title": "Trigger Phrase",
                  "default": ""
                },
                "resolution": {
                  "enum": [
                    "low",
                    "medium",
                    "high"
                  ],
                  "description": "The resolution to use for training. This is the resolution of the video.",
                  "type": "string",
                  "title": "Resolution",
                  "examples": [
                    "medium"
                  ],
                  "default": "medium"
                },
                "split_input_into_scenes": {
                  "examples": [
                    true
                  ],
                  "description": "If true, videos above a certain duration threshold will be split into scenes. If you provide captions for a split video, the caption will be applied to each scene. If you do not provide captions, scenes will be auto-captioned. This option has no effect on image datasets.",
                  "type": "boolean",
                  "title": "Split Input Into Scenes",
                  "default": true
                },
                "validation_resolution": {
                  "enum": [
                    "low",
                    "medium",
                    "high"
                  ],
                  "description": "The resolution to use for validation.",
                  "type": "string",
                  "title": "Validation Resolution",
                  "examples": [
                    "high"
                  ],
                  "default": "high"
                },
                "validation_number_of_frames": {
                  "description": "The number of frames to use for validation.",
                  "type": "integer",
                  "minimum": 8,
                  "maximum": 121,
                  "title": "Validation Number Of Frames",
                  "examples": [
                    81
                  ],
                  "default": 81
                },
                "validation_aspect_ratio": {
                  "enum": [
                    "16:9",
                    "1:1",
                    "9:16"
                  ],
                  "description": "The aspect ratio to use for validation.",
                  "type": "string",
                  "title": "Validation Aspect Ratio",
                  "examples": [
                    "1:1"
                  ],
                  "default": "1:1"
                },
                "validation_negative_prompt": {
                  "description": "A negative prompt to use for validation.",
                  "type": "string",
                  "title": "Validation Negative Prompt",
                  "default": "blurry, low quality, bad quality, out of focus"
                },
                "auto_scale_input": {
                  "examples": [
                    false
                  ],
                  "description": "If true, videos will be automatically scaled to the target frame count and fps. This option has no effect on image datasets.",
                  "type": "boolean",
                  "title": "Auto Scale Input",
                  "default": false
                }
              },
              "title": "Input",
              "required": [
                "training_data_url"
              ]
            },
            "LtxVideoTrainerOutput": {
              "x-fal-order-properties": [
                "video",
                "lora_file",
                "config_file"
              ],
              "type": "object",
              "properties": {
                "lora_file": {
                  "description": "URL to the trained LoRA weights.",
                  "$ref": "#/components/schemas/File"
                },
                "config_file": {
                  "description": "Configuration used for setting up the inference endpoints.",
                  "$ref": "#/components/schemas/File"
                },
                "video": {
                  "anyOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The URL to the validations video."
                }
              },
              "title": "TrainingOutput",
              "required": [
                "video",
                "lora_file",
                "config_file"
              ]
            },
            "Validation": {
              "x-fal-order-properties": [
                "prompt",
                "image_url"
              ],
              "type": "object",
              "properties": {
                "prompt": {
                  "description": "The prompt to use for validation.",
                  "type": "string",
                  "title": "Prompt"
                },
                "image_url": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "An image to use for image-to-video validation. If provided for one validation, _all_ validation inputs must have an image.",
                  "title": "Image Url"
                }
              },
              "title": "Validation",
              "required": [
                "prompt"
              ]
            },
            "File": {
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size"
              ],
              "type": "object",
              "properties": {
                "file_size": {
                  "anyOf": [
                    {
                      "type": "integer"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The size of the file in bytes.",
                  "title": "File Size",
                  "examples": [
                    4404019
                  ]
                },
                "file_name": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The name of the file. It will be auto-generated if not provided.",
                  "title": "File Name",
                  "examples": [
                    "z9RV14K95DvU.png"
                  ]
                },
                "content_type": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "description": "The mime type of the file.",
                  "title": "Content Type",
                  "examples": [
                    "image/png"
                  ]
                },
                "url": {
                  "description": "The URL where the file can be downloaded from.",
                  "type": "string",
                  "title": "Url"
                }
              },
              "title": "File",
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/ltx-video-trainer/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/ltx-video-trainer/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/ltx-video-trainer": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/LtxVideoTrainerInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/ltx-video-trainer/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/LtxVideoTrainerOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/recraft/v3/create-style",
      "metadata": {
        "display_name": "Recraft V3 Create Style",
        "category": "training",
        "description": "Recraft V3 Create Style is capable of creating unique styles for Recraft V3 based on your images.",
        "status": "active",
        "tags": [
          "style",
          "vector",
          "personalization"
        ],
        "updated_at": "2026-01-26T21:43:46.636Z",
        "is_favorited": false,
        "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/recraft-v3-create-style.webp",
        "model_url": "https://fal.run/fal-ai/recraft/v3/create-style",
        "license_type": "commercial",
        "date": "2025-05-07T12:54:56.466Z",
        "group": {
          "key": "fal-ai/recraft/v3",
          "label": "Create Style"
        },
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/recraft/v3/text-to-image",
          "fal-ai/recraft/v3/image-to-image"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/recraft/v3/create-style",
          "version": "1.0.0",
          "description": "The OpenAPI schema for the fal-ai/recraft/v3/create-style queue.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/recraft/v3/create-style",
            "category": "training",
            "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/recraft-v3-create-style.webp",
            "playgroundUrl": "https://fal.ai/models/fal-ai/recraft/v3/create-style",
            "documentationUrl": "https://fal.ai/models/fal-ai/recraft/v3/create-style/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "RecraftV3CreateStyleInput": {
              "title": "StyleReferenceInput",
              "type": "object",
              "properties": {
                "images_data_url": {
                  "title": "Images Data Url",
                  "type": "string",
                  "description": "URL to zip archive with images, use PNG format. Maximum 5 images are allowed."
                },
                "base_style": {
                  "enum": [
                    "any",
                    "realistic_image",
                    "digital_illustration",
                    "vector_illustration",
                    "realistic_image/b_and_w",
                    "realistic_image/hard_flash",
                    "realistic_image/hdr",
                    "realistic_image/natural_light",
                    "realistic_image/studio_portrait",
                    "realistic_image/enterprise",
                    "realistic_image/motion_blur",
                    "realistic_image/evening_light",
                    "realistic_image/faded_nostalgia",
                    "realistic_image/forest_life",
                    "realistic_image/mystic_naturalism",
                    "realistic_image/natural_tones",
                    "realistic_image/organic_calm",
                    "realistic_image/real_life_glow",
                    "realistic_image/retro_realism",
                    "realistic_image/retro_snapshot",
                    "realistic_image/urban_drama",
                    "realistic_image/village_realism",
                    "realistic_image/warm_folk",
                    "digital_illustration/pixel_art",
                    "digital_illustration/hand_drawn",
                    "digital_illustration/grain",
                    "digital_illustration/infantile_sketch",
                    "digital_illustration/2d_art_poster",
                    "digital_illustration/handmade_3d",
                    "digital_illustration/hand_drawn_outline",
                    "digital_illustration/engraving_color",
                    "digital_illustration/2d_art_poster_2",
                    "digital_illustration/antiquarian",
                    "digital_illustration/bold_fantasy",
                    "digital_illustration/child_book",
                    "digital_illustration/child_books",
                    "digital_illustration/cover",
                    "digital_illustration/crosshatch",
                    "digital_illustration/digital_engraving",
                    "digital_illustration/expressionism",
                    "digital_illustration/freehand_details",
                    "digital_illustration/grain_20",
                    "digital_illustration/graphic_intensity",
                    "digital_illustration/hard_comics",
                    "digital_illustration/long_shadow",
                    "digital_illustration/modern_folk",
                    "digital_illustration/multicolor",
                    "digital_illustration/neon_calm",
                    "digital_illustration/noir",
                    "digital_illustration/nostalgic_pastel",
                    "digital_illustration/outline_details",
                    "digital_illustration/pastel_gradient",
                    "digital_illustration/pastel_sketch",
                    "digital_illustration/pop_art",
                    "digital_illustration/pop_renaissance",
                    "digital_illustration/street_art",
                    "digital_illustration/tablet_sketch",
                    "digital_illustration/urban_glow",
                    "digital_illustration/urban_sketching",
                    "digital_illustration/vanilla_dreams",
                    "digital_illustration/young_adult_book",
                    "digital_illustration/young_adult_book_2",
                    "vector_illustration/bold_stroke",
                    "vector_illustration/chemistry",
                    "vector_illustration/colored_stencil",
                    "vector_illustration/contour_pop_art",
                    "vector_illustration/cosmics",
                    "vector_illustration/cutout",
                    "vector_illustration/depressive",
                    "vector_illustration/editorial",
                    "vector_illustration/emotional_flat",
                    "vector_illustration/infographical",
                    "vector_illustration/marker_outline",
                    "vector_illustration/mosaic",
                    "vector_illustration/naivector",
                    "vector_illustration/roundish_flat",
                    "vector_illustration/segmented_colors",
                    "vector_illustration/sharp_contrast",
                    "vector_illustration/thin",
                    "vector_illustration/vector_photo",
                    "vector_illustration/vivid_shapes",
                    "vector_illustration/engraving",
                    "vector_illustration/line_art",
                    "vector_illustration/line_circuit",
                    "vector_illustration/linocut"
                  ],
                  "title": "Base Style",
                  "type": "string",
                  "description": "The base style of the generated images, this topic is covered above.",
                  "default": "digital_illustration"
                }
              },
              "x-fal-order-properties": [
                "images_data_url",
                "base_style"
              ],
              "required": [
                "images_data_url"
              ]
            },
            "RecraftV3CreateStyleOutput": {
              "title": "StyleReferenceOutput",
              "type": "object",
              "properties": {
                "style_id": {
                  "format": "uuid4",
                  "title": "Style Id",
                  "type": "string",
                  "description": "The ID of the created style, this ID can be used to reference the style in the future."
                }
              },
              "x-fal-order-properties": [
                "style_id"
              ],
              "required": [
                "style_id"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/recraft/v3/create-style/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/recraft/v3/create-style/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/recraft/v3/create-style": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/RecraftV3CreateStyleInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/recraft/v3/create-style/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/RecraftV3CreateStyleOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/turbo-flux-trainer",
      "metadata": {
        "display_name": "Turbo Flux Trainer",
        "category": "training",
        "description": "A blazing fast FLUX dev LoRA trainer for subjects and styles.",
        "status": "active",
        "tags": [],
        "updated_at": "2026-01-26T21:43:55.386Z",
        "is_favorited": false,
        "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Training-4.jpg",
        "model_url": "https://fal.run/fal-ai/turbo-flux-trainer",
        "license_type": "commercial",
        "date": "2025-04-17T17:40:19.122Z",
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/flux-lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/turbo-flux-trainer",
          "version": "1.0.0",
          "description": "A blazing fast FLUX dev LoRA trainer for subjects and styles.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/turbo-flux-trainer",
            "category": "training",
            "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/fal/Training-4.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/turbo-flux-trainer",
            "documentationUrl": "https://fal.ai/models/fal-ai/turbo-flux-trainer/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "TurboFluxTrainerInput": {
              "title": "Input",
              "type": "object",
              "properties": {
                "images_data_url": {
                  "title": "Images Data Url",
                  "type": "string",
                  "description": "\n        URL to zip archive with images of a consistent style. Try to use at least 10 images, although more is better.\n        "
                },
                "trigger_phrase": {
                  "title": "Trigger Phrase",
                  "type": "string",
                  "description": "Trigger phrase to be used in the captions. If None, a trigger word will not be used.\n        If no captions are provide the trigger_work will be used instead of captions. If captions are provided, the trigger word will replace the `[trigger]` string in the captions.\n        ",
                  "default": "ohwx"
                },
                "steps": {
                  "description": "Number of steps to train the LoRA on.",
                  "type": "integer",
                  "minimum": 1,
                  "maximum": 10000,
                  "title": "Steps",
                  "examples": [
                    1000
                  ],
                  "default": 1000
                },
                "learning_rate": {
                  "description": "Learning rate for the training.",
                  "type": "number",
                  "minimum": 1e-7,
                  "maximum": 0.01,
                  "title": "Learning Rate",
                  "default": 0.00115
                },
                "training_style": {
                  "enum": [
                    "subject",
                    "style"
                  ],
                  "title": "Training Style",
                  "type": "string",
                  "description": "Training style to use.",
                  "default": "subject"
                },
                "face_crop": {
                  "title": "Face Crop",
                  "type": "boolean",
                  "description": "Whether to try to detect the face and crop the images to the face.",
                  "default": true
                }
              },
              "x-fal-order-properties": [
                "images_data_url",
                "trigger_phrase",
                "steps",
                "learning_rate",
                "training_style",
                "face_crop"
              ],
              "required": [
                "images_data_url"
              ]
            },
            "TurboFluxTrainerOutput": {
              "title": "Output",
              "type": "object",
              "properties": {
                "config_file": {
                  "title": "Config File",
                  "description": "URL to the trained diffusers config file.",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                },
                "diffusers_lora_file": {
                  "title": "Diffusers Lora File",
                  "description": "URL to the trained diffusers lora weights.",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                }
              },
              "x-fal-order-properties": [
                "diffusers_lora_file",
                "config_file"
              ],
              "required": [
                "diffusers_lora_file",
                "config_file"
              ]
            },
            "File": {
              "title": "File",
              "type": "object",
              "properties": {
                "file_size": {
                  "examples": [
                    4404019
                  ],
                  "title": "File Size",
                  "type": "integer",
                  "description": "The size of the file in bytes."
                },
                "file_name": {
                  "examples": [
                    "z9RV14K95DvU.png"
                  ],
                  "title": "File Name",
                  "type": "string",
                  "description": "The name of the file. It will be auto-generated if not provided."
                },
                "content_type": {
                  "examples": [
                    "image/png"
                  ],
                  "title": "Content Type",
                  "type": "string",
                  "description": "The mime type of the file."
                },
                "url": {
                  "title": "Url",
                  "type": "string",
                  "description": "The URL where the file can be downloaded from."
                },
                "file_data": {
                  "format": "binary",
                  "title": "File Data",
                  "type": "string",
                  "description": "File data"
                }
              },
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size",
                "file_data"
              ],
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/turbo-flux-trainer/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/turbo-flux-trainer/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/turbo-flux-trainer": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/TurboFluxTrainerInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/turbo-flux-trainer/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/TurboFluxTrainerOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/wan-trainer",
      "metadata": {
        "display_name": "Wan-2.1 LoRA Trainer",
        "category": "training",
        "description": "Train custom LoRAs for Wan-2.1 I2V 480P",
        "status": "active",
        "tags": [
          "lora",
          "training"
        ],
        "updated_at": "2026-01-26T21:44:00.452Z",
        "is_favorited": false,
        "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/wan-trainer.png",
        "model_url": "https://fal.run/fal-ai/wan-trainer",
        "license_type": "commercial",
        "date": "2025-03-24T17:02:37.214Z",
        "group": {
          "key": "wan-trainer",
          "label": "I2V 14B 480P"
        },
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/wan-i2v-lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/wan-trainer",
          "version": "1.0.0",
          "description": "The OpenAPI schema for the fal-ai/wan-trainer queue.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/wan-trainer",
            "category": "training",
            "thumbnailUrl": "https://storage.googleapis.com/falserverless/gallery/wan-trainer.png",
            "playgroundUrl": "https://fal.ai/models/fal-ai/wan-trainer",
            "documentationUrl": "https://fal.ai/models/fal-ai/wan-trainer/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "WanTrainerInput": {
              "title": "Input",
              "type": "object",
              "properties": {
                "number_of_steps": {
                  "minimum": 1,
                  "maximum": 20000,
                  "type": "integer",
                  "title": "Number Of Steps",
                  "description": "The number of steps to train for.",
                  "default": 400
                },
                "training_data_url": {
                  "title": "Training Data URL",
                  "type": "string",
                  "description": "URL to zip archive with images of a consistent style. Try to use at least 10 images and/or videos, although more is better.\n\n        In addition to images the archive can contain text files with captions. Each text file should have the same name as the image/video file it corresponds to."
                },
                "trigger_phrase": {
                  "title": "Trigger Phrase",
                  "type": "string",
                  "description": "The phrase that will trigger the model to generate an image.",
                  "default": ""
                },
                "learning_rate": {
                  "minimum": 0.000001,
                  "maximum": 1,
                  "type": "number",
                  "title": "Learning Rate",
                  "description": "The rate at which the model learns. Higher values can lead to faster training, but over-fitting.",
                  "default": 0.0002
                },
                "auto_scale_input": {
                  "examples": [
                    true
                  ],
                  "title": "Auto-Scale Input",
                  "type": "boolean",
                  "description": "If true, the input will be automatically scale the video to 81 frames at 16fps.",
                  "default": false
                }
              },
              "x-fal-order-properties": [
                "training_data_url",
                "number_of_steps",
                "learning_rate",
                "trigger_phrase",
                "auto_scale_input"
              ],
              "required": [
                "training_data_url"
              ]
            },
            "WanTrainerOutput": {
              "title": "Output",
              "type": "object",
              "properties": {
                "lora_file": {
                  "title": "Lora File",
                  "description": "URL to the trained LoRA weights.",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                },
                "config_file": {
                  "title": "Config File",
                  "description": "Configuration used for setting up the inference endpoints.",
                  "allOf": [
                    {
                      "$ref": "#/components/schemas/File"
                    }
                  ]
                }
              },
              "x-fal-order-properties": [
                "lora_file",
                "config_file"
              ],
              "required": [
                "lora_file",
                "config_file"
              ]
            },
            "File": {
              "title": "File",
              "type": "object",
              "properties": {
                "file_size": {
                  "examples": [
                    4404019
                  ],
                  "title": "File Size",
                  "type": "integer",
                  "description": "The size of the file in bytes."
                },
                "file_name": {
                  "examples": [
                    "z9RV14K95DvU.png"
                  ],
                  "title": "File Name",
                  "type": "string",
                  "description": "The name of the file. It will be auto-generated if not provided."
                },
                "content_type": {
                  "examples": [
                    "image/png"
                  ],
                  "title": "Content Type",
                  "type": "string",
                  "description": "The mime type of the file."
                },
                "url": {
                  "title": "Url",
                  "type": "string",
                  "description": "The URL where the file can be downloaded from."
                },
                "file_data": {
                  "format": "binary",
                  "title": "File Data",
                  "type": "string",
                  "description": "File data"
                }
              },
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size",
                "file_data"
              ],
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/wan-trainer/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/wan-trainer/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/wan-trainer": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/WanTrainerInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/wan-trainer/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/WanTrainerOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    },
    {
      "endpoint_id": "fal-ai/hunyuan-video-lora-training",
      "metadata": {
        "display_name": "Train Hunyuan LoRA",
        "category": "training",
        "description": "Train Hunyuan Video lora on people, objects, characters and more!",
        "status": "active",
        "tags": [
          "lora",
          "personalization"
        ],
        "updated_at": "2026-01-26T21:44:31.230Z",
        "is_favorited": false,
        "thumbnail_url": "https://storage.googleapis.com/fal_cdn/Fal_Visuals_V1_014.jpg",
        "model_url": "https://fal.run/fal-ai/hunyuan-video-lora-training",
        "license_type": "commercial",
        "date": "2025-01-14T00:00:00.000Z",
        "highlighted": false,
        "kind": "training",
        "pinned": false,
        "inference_endpoint_ids": [
          "fal-ai/hunyuan-video-lora"
        ]
      },
      "openapi": {
        "openapi": "3.0.4",
        "info": {
          "title": "Queue OpenAPI for fal-ai/hunyuan-video-lora-training",
          "version": "1.0.0",
          "description": "The OpenAPI schema for the fal-ai/hunyuan-video-lora-training queue.",
          "x-fal-metadata": {
            "endpointId": "fal-ai/hunyuan-video-lora-training",
            "category": "training",
            "thumbnailUrl": "https://storage.googleapis.com/fal_cdn/Fal_Visuals_V1_014.jpg",
            "playgroundUrl": "https://fal.ai/models/fal-ai/hunyuan-video-lora-training",
            "documentationUrl": "https://fal.ai/models/fal-ai/hunyuan-video-lora-training/api"
          }
        },
        "components": {
          "securitySchemes": {
            "apiKeyAuth": {
              "type": "apiKey",
              "in": "header",
              "name": "Authorization",
              "description": "Fal Key"
            }
          },
          "schemas": {
            "QueueStatus": {
              "type": "object",
              "properties": {
                "status": {
                  "type": "string",
                  "enum": [
                    "IN_QUEUE",
                    "IN_PROGRESS",
                    "COMPLETED"
                  ]
                },
                "request_id": {
                  "type": "string",
                  "description": "The request id."
                },
                "response_url": {
                  "type": "string",
                  "description": "The response url."
                },
                "status_url": {
                  "type": "string",
                  "description": "The status url."
                },
                "cancel_url": {
                  "type": "string",
                  "description": "The cancel url."
                },
                "logs": {
                  "type": "object",
                  "description": "The logs.",
                  "additionalProperties": true
                },
                "metrics": {
                  "type": "object",
                  "description": "The metrics.",
                  "additionalProperties": true
                },
                "queue_position": {
                  "type": "integer",
                  "description": "The queue position."
                }
              },
              "required": [
                "status",
                "request_id"
              ]
            },
            "HunyuanVideoLoraTrainingInput": {
              "title": "PublicInput",
              "type": "object",
              "properties": {
                "trigger_word": {
                  "title": "Trigger Word",
                  "type": "string",
                  "description": "The trigger word to use.",
                  "default": ""
                },
                "images_data_url": {
                  "title": "Images Data Url",
                  "type": "string",
                  "description": "\n        URL to zip archive with images. Try to use at least 4 images in general the more the better.\n\n        In addition to images the archive can contain text files with captions. Each text file should have the same name as the image file it corresponds to.\n    "
                },
                "steps": {
                  "description": "Number of steps to train the LoRA on.",
                  "type": "integer",
                  "minimum": 1,
                  "maximum": 5000,
                  "examples": [
                    1000
                  ],
                  "title": "Steps"
                },
                "data_archive_format": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "Data Archive Format",
                  "description": "The format of the archive. If not specified, the format will be inferred from the URL.",
                  "nullable": true
                },
                "learning_rate": {
                  "title": "Learning Rate",
                  "type": "number",
                  "description": "Learning rate to use for training.",
                  "default": 0.0001
                },
                "do_caption": {
                  "title": "Do Caption",
                  "type": "boolean",
                  "description": "Whether to generate captions for the images.",
                  "default": true
                }
              },
              "x-fal-order-properties": [
                "images_data_url",
                "steps",
                "trigger_word",
                "learning_rate",
                "do_caption",
                "data_archive_format"
              ],
              "required": [
                "images_data_url",
                "steps"
              ]
            },
            "HunyuanVideoLoraTrainingOutput": {
              "title": "Output",
              "type": "object",
              "properties": {
                "config_file": {
                  "description": "URL to the lora configuration file.",
                  "$ref": "#/components/schemas/File"
                },
                "diffusers_lora_file": {
                  "description": "URL to the trained diffusers lora weights.",
                  "$ref": "#/components/schemas/File"
                }
              },
              "x-fal-order-properties": [
                "diffusers_lora_file",
                "config_file"
              ],
              "required": [
                "diffusers_lora_file",
                "config_file"
              ]
            },
            "File": {
              "title": "File",
              "type": "object",
              "properties": {
                "file_size": {
                  "anyOf": [
                    {
                      "type": "integer"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "File Size",
                  "description": "The size of the file in bytes.",
                  "examples": [
                    4404019
                  ]
                },
                "file_name": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "File Name",
                  "description": "The name of the file. It will be auto-generated if not provided.",
                  "examples": [
                    "z9RV14K95DvU.png"
                  ]
                },
                "content_type": {
                  "anyOf": [
                    {
                      "type": "string"
                    },
                    {
                      "type": "null"
                    }
                  ],
                  "title": "Content Type",
                  "description": "The mime type of the file.",
                  "examples": [
                    "image/png"
                  ]
                },
                "url": {
                  "title": "Url",
                  "type": "string",
                  "description": "The URL where the file can be downloaded from."
                }
              },
              "x-fal-order-properties": [
                "url",
                "content_type",
                "file_name",
                "file_size"
              ],
              "required": [
                "url"
              ]
            }
          }
        },
        "paths": {
          "/fal-ai/hunyuan-video-lora-training/requests/{request_id}/status": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                },
                {
                  "name": "logs",
                  "in": "query",
                  "required": false,
                  "schema": {
                    "type": "number",
                    "description": "Whether to include logs (`1`) in the response or not (`0`)."
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/hunyuan-video-lora-training/requests/{request_id}/cancel": {
            "put": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "The request was cancelled.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "type": "object",
                        "properties": {
                          "success": {
                            "type": "boolean",
                            "description": "Whether the request was cancelled successfully."
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/hunyuan-video-lora-training": {
            "post": {
              "requestBody": {
                "required": true,
                "content": {
                  "application/json": {
                    "schema": {
                      "$ref": "#/components/schemas/HunyuanVideoLoraTrainingInput"
                    }
                  }
                }
              },
              "responses": {
                "200": {
                  "description": "The request status.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/QueueStatus"
                      }
                    }
                  }
                }
              }
            }
          },
          "/fal-ai/hunyuan-video-lora-training/requests/{request_id}": {
            "get": {
              "parameters": [
                {
                  "name": "request_id",
                  "in": "path",
                  "required": true,
                  "schema": {
                    "type": "string",
                    "description": "Request ID"
                  }
                }
              ],
              "responses": {
                "200": {
                  "description": "Result of the request.",
                  "content": {
                    "application/json": {
                      "schema": {
                        "$ref": "#/components/schemas/HunyuanVideoLoraTrainingOutput"
                      }
                    }
                  }
                }
              }
            }
          }
        },
        "servers": [
          {
            "url": "https://queue.fal.run"
          }
        ],
        "security": [
          {
            "apiKeyAuth": []
          }
        ]
      }
    }
  ]
}