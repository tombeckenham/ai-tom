// This file is auto-generated by @hey-api/openapi-ts

import { z } from 'zod'

/**
 * UsageInfo
 */
export const zSchemaUsageInfo = z.object({
  prompt_tokens: z.optional(z.int()),
  total_tokens: z.optional(z.int()).default(0),
  completion_tokens: z.optional(z.int()),
  cost: z.number(),
})

/**
 * VideoOutput
 */
export const zSchemaRouterVideoOutput = z.object({
  usage: z.optional(zSchemaUsageInfo),
  output: z.string().register(z.globalRegistry, {
    description: 'Generated output from video processing',
  }),
})

/**
 * VideoInput
 */
export const zSchemaRouterVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Prompt to be used for the video processing',
  }),
  video_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'List of URLs or data URIs of video files to process. Supported formats: mp4, mpeg, mov, webm. For Google Gemini on AI Studio, YouTube links are also supported. Mutually exclusive with video_url.',
    }),
  ),
  system_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'System prompt to provide context or instructions to the model',
    }),
  ),
  reasoning: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Should reasoning be the part of the final answer.',
      }),
    )
    .default(false),
  model: z.string().register(z.globalRegistry, {
    description:
      'Name of the model to use. Charged based on actual token usage.',
  }),
  max_tokens: z.optional(
    z.int().gte(1).register(z.globalRegistry, {
      description:
        "This sets the upper limit for the number of tokens the model can generate in response. It won't produce more than this limit. The maximum value is the context length minus the prompt length.",
    }),
  ),
  temperature: z
    .optional(
      z.number().gte(0).lte(2).register(z.globalRegistry, {
        description:
          "This setting influences the variety in the model's responses. Lower values lead to more predictable and typical responses, while higher values encourage more diverse and less common responses. At 0, the model always gives the same response for a given input.",
      }),
    )
    .default(1),
})

/**
 * VideoOutput
 */
export const zSchemaRouterVideoEnterpriseOutput = z.object({
  usage: z.optional(zSchemaUsageInfo),
  output: z.string().register(z.globalRegistry, {
    description: 'Generated output from video processing',
  }),
})

/**
 * VideoEnterpriseInput
 */
export const zSchemaRouterVideoEnterpriseInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Prompt to be used for the video processing',
  }),
  video_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'List of URLs or data URIs of video files to process. Supported formats: mp4, mpeg, mov, webm. For Google Gemini on AI Studio, YouTube links are also supported. Mutually exclusive with video_url.',
    }),
  ),
  system_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'System prompt to provide context or instructions to the model',
    }),
  ),
  reasoning: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Should reasoning be the part of the final answer.',
      }),
    )
    .default(false),
  model: z.string().register(z.globalRegistry, {
    description:
      'Name of the model to use. Charged based on actual token usage.',
  }),
  max_tokens: z.optional(
    z.int().gte(1).register(z.globalRegistry, {
      description:
        "This sets the upper limit for the number of tokens the model can generate in response. It won't produce more than this limit. The maximum value is the context length minus the prompt length.",
    }),
  ),
  temperature: z
    .optional(
      z.number().gte(0).lte(2).register(z.globalRegistry, {
        description:
          "This setting influences the variety in the model's responses. Lower values lead to more predictable and typical responses, while higher values encourage more diverse and less common responses. At 0, the model always gives the same response for a given input.",
      }),
    )
    .default(1),
})

/**
 * AITextDetectionOutput
 */
export const zSchemaAiDetectorDetectTextOutput = z.object({
  latency: z.number(),
  verdict: z.string(),
  is_ai_generated: z.boolean(),
  confidence: z.number(),
})

/**
 * TextDetectionInput
 */
export const zSchemaAiDetectorDetectTextInput = z.object({
  text: z.string().min(1).max(20000).register(z.globalRegistry, {
    description: 'Text content to analyze for AI generation.',
  }),
})

/**
 * DiarizationSegment
 */
export const zSchemaDiarizationSegment = z.object({
  timestamp: z.tuple([z.unknown(), z.unknown()]).register(z.globalRegistry, {
    description: 'Start and end timestamp of the segment',
  }),
  speaker: z.string().register(z.globalRegistry, {
    description: 'Speaker ID of the segment',
  }),
})

/**
 * WhisperChunk
 */
export const zSchemaWhisperChunk = z.object({
  text: z.string().register(z.globalRegistry, {
    description: 'Transcription of the chunk',
  }),
  timestamp: z.tuple([z.unknown(), z.unknown()]).register(z.globalRegistry, {
    description: 'Start and end timestamp of the chunk',
  }),
  speaker: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'Speaker ID of the chunk. Only present if diarization is enabled.',
    }),
  ),
})

/**
 * WhisperOutput
 */
export const zSchemaWhisperOutput = z.object({
  text: z.string().register(z.globalRegistry, {
    description: 'Transcription of the audio file',
  }),
  inferred_languages: z
    .array(
      z.enum([
        'af',
        'am',
        'ar',
        'as',
        'az',
        'ba',
        'be',
        'bg',
        'bn',
        'bo',
        'br',
        'bs',
        'ca',
        'cs',
        'cy',
        'da',
        'de',
        'el',
        'en',
        'es',
        'et',
        'eu',
        'fa',
        'fi',
        'fo',
        'fr',
        'gl',
        'gu',
        'ha',
        'haw',
        'he',
        'hi',
        'hr',
        'ht',
        'hu',
        'hy',
        'id',
        'is',
        'it',
        'ja',
        'jw',
        'ka',
        'kk',
        'km',
        'kn',
        'ko',
        'la',
        'lb',
        'ln',
        'lo',
        'lt',
        'lv',
        'mg',
        'mi',
        'mk',
        'ml',
        'mn',
        'mr',
        'ms',
        'mt',
        'my',
        'ne',
        'nl',
        'nn',
        'no',
        'oc',
        'pa',
        'pl',
        'ps',
        'pt',
        'ro',
        'ru',
        'sa',
        'sd',
        'si',
        'sk',
        'sl',
        'sn',
        'so',
        'sq',
        'sr',
        'su',
        'sv',
        'sw',
        'ta',
        'te',
        'tg',
        'th',
        'tk',
        'tl',
        'tr',
        'tt',
        'uk',
        'ur',
        'uz',
        'vi',
        'yi',
        'yo',
        'zh',
      ]),
    )
    .register(z.globalRegistry, {
      description:
        'List of languages that the audio file is inferred to be. Defaults to null.',
    }),
  chunks: z.optional(
    z.array(zSchemaWhisperChunk).register(z.globalRegistry, {
      description: 'Timestamp chunks of the audio file',
    }),
  ),
  diarization_segments: z
    .array(zSchemaDiarizationSegment)
    .register(z.globalRegistry, {
      description:
        'Speaker diarization segments of the audio file. Only present if diarization is enabled.',
    }),
})

/**
 * WhisperInput
 */
export const zSchemaWhisperInput = z.object({
  version: z.optional(
    z.enum(['3']).register(z.globalRegistry, {
      description:
        'Version of the model to use. All of the models are the Whisper large variant.',
    }),
  ),
  batch_size: z.optional(z.int().gte(1).lte(64)).default(64),
  language: z.optional(
    z
      .enum([
        'af',
        'am',
        'ar',
        'as',
        'az',
        'ba',
        'be',
        'bg',
        'bn',
        'bo',
        'br',
        'bs',
        'ca',
        'cs',
        'cy',
        'da',
        'de',
        'el',
        'en',
        'es',
        'et',
        'eu',
        'fa',
        'fi',
        'fo',
        'fr',
        'gl',
        'gu',
        'ha',
        'haw',
        'he',
        'hi',
        'hr',
        'ht',
        'hu',
        'hy',
        'id',
        'is',
        'it',
        'ja',
        'jw',
        'ka',
        'kk',
        'km',
        'kn',
        'ko',
        'la',
        'lb',
        'ln',
        'lo',
        'lt',
        'lv',
        'mg',
        'mi',
        'mk',
        'ml',
        'mn',
        'mr',
        'ms',
        'mt',
        'my',
        'ne',
        'nl',
        'nn',
        'no',
        'oc',
        'pa',
        'pl',
        'ps',
        'pt',
        'ro',
        'ru',
        'sa',
        'sd',
        'si',
        'sk',
        'sl',
        'sn',
        'so',
        'sq',
        'sr',
        'su',
        'sv',
        'sw',
        'ta',
        'te',
        'tg',
        'th',
        'tk',
        'tl',
        'tr',
        'tt',
        'uk',
        'ur',
        'uz',
        'vi',
        'yi',
        'yo',
        'zh',
      ])
      .register(z.globalRegistry, {
        description:
          '\n        Language of the audio file. If set to null, the language will be\n        automatically detected. Defaults to null.\n\n        If translate is selected as the task, the audio will be translated to\n        English, regardless of the language selected.\n        ',
      }),
  ),
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Prompt to use for generation. Defaults to an empty string.',
      }),
    )
    .default(''),
  num_speakers: z.optional(z.union([z.int().gte(1), z.null()])),
  task: z.optional(
    z.enum(['transcribe', 'translate']).register(z.globalRegistry, {
      description:
        'Task to perform on the audio file. Either transcribe or translate.',
    }),
  ),
  chunk_level: z.optional(
    z.enum(['none', 'segment', 'word']).register(z.globalRegistry, {
      description:
        'Level of the chunks to return. Either none, segment or word. `none` would imply that all of the audio will be transcribed without the timestamp tokens, we suggest to switch to `none` if you are not satisfied with the transcription quality, since it will usually improve the quality of the results. Switching to `none` will also provide minor speed ups in the transcription due to less amount of generated tokens. Notice that setting to none will produce **a single chunk with the whole transcription**.',
    }),
  ),
  audio_url: z.union([z.string(), z.string()]),
  diarize: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to diarize the audio file. Defaults to false. Setting to true will add costs proportional to diarization inference time.',
      }),
    )
    .default(false),
})

/**
 * WhisperOutput
 */
export const zSchemaWizperOutput = z.object({
  text: z.string().register(z.globalRegistry, {
    description: 'Transcription of the audio file',
  }),
  languages: z
    .array(
      z.enum([
        'af',
        'am',
        'ar',
        'as',
        'az',
        'ba',
        'be',
        'bg',
        'bn',
        'bo',
        'br',
        'bs',
        'ca',
        'cs',
        'cy',
        'da',
        'de',
        'el',
        'en',
        'es',
        'et',
        'eu',
        'fa',
        'fi',
        'fo',
        'fr',
        'gl',
        'gu',
        'ha',
        'haw',
        'he',
        'hi',
        'hr',
        'ht',
        'hu',
        'hy',
        'id',
        'is',
        'it',
        'ja',
        'jw',
        'ka',
        'kk',
        'km',
        'kn',
        'ko',
        'la',
        'lb',
        'ln',
        'lo',
        'lt',
        'lv',
        'mg',
        'mi',
        'mk',
        'ml',
        'mn',
        'mr',
        'ms',
        'mt',
        'my',
        'ne',
        'nl',
        'nn',
        'no',
        'oc',
        'pa',
        'pl',
        'ps',
        'pt',
        'ro',
        'ru',
        'sa',
        'sd',
        'si',
        'sk',
        'sl',
        'sn',
        'so',
        'sq',
        'sr',
        'su',
        'sv',
        'sw',
        'ta',
        'te',
        'tg',
        'th',
        'tk',
        'tl',
        'tr',
        'tt',
        'uk',
        'ur',
        'uz',
        'vi',
        'yi',
        'yo',
        'zh',
      ]),
    )
    .register(z.globalRegistry, {
      description:
        'List of languages that the audio file is inferred to be. Defaults to null.',
    }),
  chunks: z.array(zSchemaWhisperChunk).register(z.globalRegistry, {
    description: 'Timestamp chunks of the audio file',
  }),
})

/**
 * WhisperInput
 */
export const zSchemaWizperInput = z.object({
  language: z.optional(
    z.union([
      z.enum([
        'af',
        'am',
        'ar',
        'as',
        'az',
        'ba',
        'be',
        'bg',
        'bn',
        'bo',
        'br',
        'bs',
        'ca',
        'cs',
        'cy',
        'da',
        'de',
        'el',
        'en',
        'es',
        'et',
        'eu',
        'fa',
        'fi',
        'fo',
        'fr',
        'gl',
        'gu',
        'ha',
        'haw',
        'he',
        'hi',
        'hr',
        'ht',
        'hu',
        'hy',
        'id',
        'is',
        'it',
        'ja',
        'jw',
        'ka',
        'kk',
        'km',
        'kn',
        'ko',
        'la',
        'lb',
        'ln',
        'lo',
        'lt',
        'lv',
        'mg',
        'mi',
        'mk',
        'ml',
        'mn',
        'mr',
        'ms',
        'mt',
        'my',
        'ne',
        'nl',
        'nn',
        'no',
        'oc',
        'pa',
        'pl',
        'ps',
        'pt',
        'ro',
        'ru',
        'sa',
        'sd',
        'si',
        'sk',
        'sl',
        'sn',
        'so',
        'sq',
        'sr',
        'su',
        'sv',
        'sw',
        'ta',
        'te',
        'tg',
        'th',
        'tk',
        'tl',
        'tr',
        'tt',
        'uk',
        'ur',
        'uz',
        'vi',
        'yi',
        'yo',
        'zh',
      ]),
      z.unknown(),
    ]),
  ),
  version: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Version of the model to use. All of the models are the Whisper large variant.',
      }),
    )
    .default('3'),
  max_segment_len: z
    .optional(
      z.int().gte(10).lte(29).register(z.globalRegistry, {
        description:
          'Maximum speech segment duration in seconds before splitting.',
      }),
    )
    .default(29),
  task: z.optional(
    z.enum(['transcribe', 'translate']).register(z.globalRegistry, {
      description:
        'Task to perform on the audio file. Either transcribe or translate.',
    }),
  ),
  chunk_level: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Level of the chunks to return.',
      }),
    )
    .default('segment'),
  audio_url: z.union([z.string(), z.string()]),
  merge_chunks: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to merge consecutive chunks. When enabled, chunks are merged if their combined duration does not exceed max_segment_len.',
      }),
    )
    .default(true),
})

/**
 * TranscriptionWord
 */
export const zSchemaTranscriptionWord = z.object({
  text: z.string().register(z.globalRegistry, {
    description: 'The transcribed word or audio event',
  }),
  start: z.union([z.number(), z.unknown()]),
  type: z.string().register(z.globalRegistry, {
    description: 'Type of element (word, spacing, or audio_event)',
  }),
  end: z.union([z.number(), z.unknown()]),
  speaker_id: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * TranscriptionOutput
 */
export const zSchemaElevenlabsSpeechToTextOutput = z.object({
  text: z.string().register(z.globalRegistry, {
    description: 'The full transcribed text',
  }),
  language_probability: z.number().register(z.globalRegistry, {
    description: 'Confidence in language detection',
  }),
  language_code: z.string().register(z.globalRegistry, {
    description: 'Detected or specified language code',
  }),
  words: z.array(zSchemaTranscriptionWord).register(z.globalRegistry, {
    description: 'Word-level transcription details',
  }),
})

/**
 * SpeechToTextRequest
 */
export const zSchemaElevenlabsSpeechToTextInput = z.object({
  language_code: z.optional(z.union([z.string(), z.unknown()])),
  audio_url: z.union([z.string(), z.string()]),
  diarize: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to annotate who is speaking',
      }),
    )
    .default(true),
  tag_audio_events: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Tag audio events like laughter, applause, etc.',
      }),
    )
    .default(true),
})

/**
 * SpeechOutput
 */
export const zSchemaSpeechToTextOutput = z.object({
  partial: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Indicates if this is a partial (in-progress) transcript',
      }),
    )
    .default(false),
  output: z.string().register(z.globalRegistry, {
    description: 'The partial or final transcription output from Canary',
  }),
})

/**
 * SpeechInput
 */
export const zSchemaSpeechToTextInput = z.object({
  audio_url: z.union([z.string(), z.string()]),
  use_pnc: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use Canary's built-in punctuation & capitalization",
      }),
    )
    .default(true),
})

export const zSchemaSpeechToTextStreamOutput = z.unknown()

/**
 * SpeechInput
 */
export const zSchemaSpeechToTextStreamInput = z.object({
  audio_url: z.union([z.string(), z.string()]),
  use_pnc: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use Canary's built-in punctuation & capitalization",
      }),
    )
    .default(true),
})

export const zSchemaSpeechToTextTurboStreamOutput = z.unknown()

/**
 * SpeechInput
 */
export const zSchemaSpeechToTextTurboStreamInput = z.object({
  audio_url: z.union([z.string(), z.string()]),
  use_pnc: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use Canary's built-in punctuation & capitalization",
      }),
    )
    .default(true),
})

/**
 * SpeechOutput
 */
export const zSchemaSpeechToTextTurboOutput = z.object({
  partial: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Indicates if this is a partial (in-progress) transcript',
      }),
    )
    .default(false),
  output: z.string().register(z.globalRegistry, {
    description: 'The partial or final transcription output from Canary',
  }),
})

/**
 * SpeechInput
 */
export const zSchemaSpeechToTextTurboInput = z.object({
  audio_url: z.union([z.string(), z.string()]),
  use_pnc: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use Canary's built-in punctuation & capitalization",
      }),
    )
    .default(true),
})

/**
 * Output
 */
export const zSchemaSmartTurnOutput = z.object({
  prediction: z.int().register(z.globalRegistry, {
    description: 'The predicted turn type. 1 for Complete, 0 for Incomplete.',
  }),
  probability: z.number().register(z.globalRegistry, {
    description: 'The probability of the predicted turn type.',
  }),
  metrics: z.record(z.string(), z.unknown()).register(z.globalRegistry, {
    description: 'The metrics of the inference.',
  }),
})

/**
 * SmartTurnInput
 */
export const zSchemaSmartTurnInput = z.object({
  audio_url: z.union([z.string(), z.string()]),
})

/**
 * TranscriptionOutputV2
 */
export const zSchemaElevenlabsSpeechToTextScribeV2Output = z.object({
  text: z.string().register(z.globalRegistry, {
    description: 'The full transcribed text',
  }),
  language_probability: z.number().register(z.globalRegistry, {
    description: 'Confidence in language detection',
  }),
  language_code: z.string().register(z.globalRegistry, {
    description: 'Detected or specified language code',
  }),
  words: z.array(zSchemaTranscriptionWord).register(z.globalRegistry, {
    description: 'Word-level transcription details',
  }),
})

/**
 * SpeechToTextRequestScribeV2
 */
export const zSchemaElevenlabsSpeechToTextScribeV2Input = z.object({
  keyterms: z
    .optional(
      z.array(z.string()).max(100).register(z.globalRegistry, {
        description:
          'Words or sentences to bias the model towards transcribing. Up to 100 keyterms, max 50 characters each. Adds 30% premium over base transcription price.',
      }),
    )
    .default([]),
  audio_url: z.union([z.string(), z.string()]),
  diarize: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to annotate who is speaking',
      }),
    )
    .default(true),
  language_code: z.optional(z.union([z.string(), z.unknown()])),
  tag_audio_events: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Tag audio events like laughter, applause, etc.',
      }),
    )
    .default(true),
})

/**
 * SpeechTimestamp
 */
export const zSchemaSpeechTimestamp = z.object({
  end: z.number().register(z.globalRegistry, {
    description: 'The end time of the speech in seconds.',
  }),
  start: z.number().register(z.globalRegistry, {
    description: 'The start time of the speech in seconds.',
  }),
})

/**
 * SileroVADOutput
 */
export const zSchemaSileroVadOutput = z.object({
  has_speech: z.boolean().register(z.globalRegistry, {
    description: 'Whether the audio has speech.',
  }),
  timestamps: z.array(zSchemaSpeechTimestamp).register(z.globalRegistry, {
    description: 'The speech timestamps.',
  }),
})

/**
 * SileroVADInput
 */
export const zSchemaSileroVadInput = z.object({
  audio_url: z.union([z.string(), z.string()]),
})

/**
 * SpeechOutput
 */
export const zSchemaNemotronAsrOutput = z.object({
  partial: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'True if this is an intermediate result during streaming.',
      }),
    )
    .default(false),
  output: z.string().register(z.globalRegistry, {
    description: 'The transcribed text from the audio.',
  }),
})

/**
 * SpeechInput
 */
export const zSchemaNemotronAsrInput = z.object({
  acceleration: z.optional(
    z.enum(['none', 'low', 'medium', 'high']).register(z.globalRegistry, {
      description:
        "Controls the speed/accuracy trade-off. 'none' = best accuracy (1.12s chunks, ~7.16% WER), 'low' = balanced (0.56s chunks, ~7.22% WER), 'medium' = faster (0.16s chunks, ~7.84% WER), 'high' = fastest (0.08s chunks, ~8.53% WER).",
    }),
  ),
  audio_url: z.union([z.string(), z.string()]),
})

export const zSchemaNemotronAsrStreamOutput = z.unknown()

/**
 * SpeechInput
 */
export const zSchemaNemotronAsrStreamInput = z.object({
  acceleration: z.optional(
    z.enum(['none', 'low', 'medium', 'high']).register(z.globalRegistry, {
      description:
        "Controls the speed/accuracy trade-off. 'none' = best accuracy (1.12s chunks, ~7.16% WER), 'low' = balanced (0.56s chunks, ~7.22% WER), 'medium' = faster (0.16s chunks, ~7.84% WER), 'high' = fastest (0.08s chunks, ~8.53% WER).",
    }),
  ),
  audio_url: z.union([z.string(), z.string()]),
})

export const zSchemaQueueStatus = z.object({
  status: z.enum(['IN_QUEUE', 'IN_PROGRESS', 'COMPLETED']),
  request_id: z.string().register(z.globalRegistry, {
    description: 'The request id.',
  }),
  response_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The response url.',
    }),
  ),
  status_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The status url.',
    }),
  ),
  cancel_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The cancel url.',
    }),
  ),
  logs: z.optional(
    z.record(z.string(), z.unknown()).register(z.globalRegistry, {
      description: 'The logs.',
    }),
  ),
  metrics: z.optional(
    z.record(z.string(), z.unknown()).register(z.globalRegistry, {
      description: 'The metrics.',
    }),
  ),
  queue_position: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The queue position.',
    }),
  ),
})

export const zGetFalAiNemotronAsrStreamRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiNemotronAsrStreamRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiNemotronAsrStreamRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiNemotronAsrStreamRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiNemotronAsrStreamData = z.object({
  body: zSchemaNemotronAsrStreamInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiNemotronAsrStreamResponse = zSchemaQueueStatus

export const zGetFalAiNemotronAsrStreamRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiNemotronAsrStreamRequestsByRequestIdResponse =
  zSchemaNemotronAsrStreamOutput

export const zGetFalAiNemotronAsrRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiNemotronAsrRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiNemotronAsrRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiNemotronAsrRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiNemotronAsrData = z.object({
  body: zSchemaNemotronAsrInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiNemotronAsrResponse = zSchemaQueueStatus

export const zGetFalAiNemotronAsrRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiNemotronAsrRequestsByRequestIdResponse =
  zSchemaNemotronAsrOutput

export const zGetFalAiSileroVadRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiSileroVadRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSileroVadRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiSileroVadRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSileroVadData = z.object({
  body: zSchemaSileroVadInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSileroVadResponse = zSchemaQueueStatus

export const zGetFalAiSileroVadRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSileroVadRequestsByRequestIdResponse =
  zSchemaSileroVadOutput

export const zGetFalAiElevenlabsSpeechToTextScribeV2RequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiElevenlabsSpeechToTextScribeV2RequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiElevenlabsSpeechToTextScribeV2RequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiElevenlabsSpeechToTextScribeV2RequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiElevenlabsSpeechToTextScribeV2Data = z.object({
  body: zSchemaElevenlabsSpeechToTextScribeV2Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiElevenlabsSpeechToTextScribeV2Response =
  zSchemaQueueStatus

export const zGetFalAiElevenlabsSpeechToTextScribeV2RequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiElevenlabsSpeechToTextScribeV2RequestsByRequestIdResponse =
  zSchemaElevenlabsSpeechToTextScribeV2Output

export const zGetFalAiSmartTurnRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiSmartTurnRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSmartTurnRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiSmartTurnRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSmartTurnData = z.object({
  body: zSchemaSmartTurnInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSmartTurnResponse = zSchemaQueueStatus

export const zGetFalAiSmartTurnRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSmartTurnRequestsByRequestIdResponse =
  zSchemaSmartTurnOutput

export const zGetFalAiSpeechToTextTurboRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiSpeechToTextTurboRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSpeechToTextTurboRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiSpeechToTextTurboRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSpeechToTextTurboData = z.object({
  body: zSchemaSpeechToTextTurboInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSpeechToTextTurboResponse = zSchemaQueueStatus

export const zGetFalAiSpeechToTextTurboRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSpeechToTextTurboRequestsByRequestIdResponse =
  zSchemaSpeechToTextTurboOutput

export const zGetFalAiSpeechToTextTurboStreamRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiSpeechToTextTurboStreamRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSpeechToTextTurboStreamRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiSpeechToTextTurboStreamRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiSpeechToTextTurboStreamData = z.object({
  body: zSchemaSpeechToTextTurboStreamInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSpeechToTextTurboStreamResponse = zSchemaQueueStatus

export const zGetFalAiSpeechToTextTurboStreamRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiSpeechToTextTurboStreamRequestsByRequestIdResponse =
  zSchemaSpeechToTextTurboStreamOutput

export const zGetFalAiSpeechToTextStreamRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiSpeechToTextStreamRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSpeechToTextStreamRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiSpeechToTextStreamRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSpeechToTextStreamData = z.object({
  body: zSchemaSpeechToTextStreamInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSpeechToTextStreamResponse = zSchemaQueueStatus

export const zGetFalAiSpeechToTextStreamRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSpeechToTextStreamRequestsByRequestIdResponse =
  zSchemaSpeechToTextStreamOutput

export const zGetFalAiSpeechToTextRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiSpeechToTextRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSpeechToTextRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiSpeechToTextRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSpeechToTextData = z.object({
  body: zSchemaSpeechToTextInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSpeechToTextResponse = zSchemaQueueStatus

export const zGetFalAiSpeechToTextRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSpeechToTextRequestsByRequestIdResponse =
  zSchemaSpeechToTextOutput

export const zGetFalAiElevenlabsSpeechToTextRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiElevenlabsSpeechToTextRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiElevenlabsSpeechToTextRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiElevenlabsSpeechToTextRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiElevenlabsSpeechToTextData = z.object({
  body: zSchemaElevenlabsSpeechToTextInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiElevenlabsSpeechToTextResponse = zSchemaQueueStatus

export const zGetFalAiElevenlabsSpeechToTextRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiElevenlabsSpeechToTextRequestsByRequestIdResponse =
  zSchemaElevenlabsSpeechToTextOutput

export const zGetFalAiWizperRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWizperRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWizperRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWizperRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWizperData = z.object({
  body: zSchemaWizperInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWizperResponse = zSchemaQueueStatus

export const zGetFalAiWizperRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWizperRequestsByRequestIdResponse = zSchemaWizperOutput

export const zGetFalAiWhisperRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWhisperRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWhisperRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWhisperRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWhisperData = z.object({
  body: zSchemaWhisperInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWhisperResponse = zSchemaQueueStatus

export const zGetFalAiWhisperRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWhisperRequestsByRequestIdResponse = zSchemaWhisperOutput

export const zGetHalfMoonAiAiDetectorDetectTextRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetHalfMoonAiAiDetectorDetectTextRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutHalfMoonAiAiDetectorDetectTextRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutHalfMoonAiAiDetectorDetectTextRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostHalfMoonAiAiDetectorDetectTextData = z.object({
  body: zSchemaAiDetectorDetectTextInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostHalfMoonAiAiDetectorDetectTextResponse = zSchemaQueueStatus

export const zGetHalfMoonAiAiDetectorDetectTextRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetHalfMoonAiAiDetectorDetectTextRequestsByRequestIdResponse =
  zSchemaAiDetectorDetectTextOutput

export const zGetOpenrouterRouterVideoEnterpriseRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetOpenrouterRouterVideoEnterpriseRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutOpenrouterRouterVideoEnterpriseRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutOpenrouterRouterVideoEnterpriseRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostOpenrouterRouterVideoEnterpriseData = z.object({
  body: zSchemaRouterVideoEnterpriseInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostOpenrouterRouterVideoEnterpriseResponse = zSchemaQueueStatus

export const zGetOpenrouterRouterVideoEnterpriseRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetOpenrouterRouterVideoEnterpriseRequestsByRequestIdResponse =
  zSchemaRouterVideoEnterpriseOutput

export const zGetOpenrouterRouterVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetOpenrouterRouterVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutOpenrouterRouterVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutOpenrouterRouterVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostOpenrouterRouterVideoData = z.object({
  body: zSchemaRouterVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostOpenrouterRouterVideoResponse = zSchemaQueueStatus

export const zGetOpenrouterRouterVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetOpenrouterRouterVideoRequestsByRequestIdResponse =
  zSchemaRouterVideoOutput
