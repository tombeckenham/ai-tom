// This file is auto-generated by @hey-api/openapi-ts

import { z } from 'zod'

export const zFile = z.object({
  url: z.url(),
  content_type: z.optional(z.string()),
  file_name: z.optional(z.string()),
  file_size: z.optional(z.int()),
})

export const zQueueStatus = z.object({
  status: z.enum(['IN_PROGRESS', 'COMPLETED', 'FAILED']),
  response_url: z.optional(z.url()),
})

/**
 * VibeVoice0_5bInput
 *
 * Input schema for VibeVoice-0.5b TTS generation
 */
export const zVibevoice05bInput = z
  .object({
    script: z.string().max(90000).register(z.globalRegistry, {
      description: 'The script to convert to speech.',
    }),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'Random seed for reproducible generation.',
      }),
    ),
    speaker: z
      .enum(['Frank', 'Wayne', 'Carter', 'Emma', 'Grace', 'Mike'])
      .register(z.globalRegistry, {
        description: 'Voice to use for speaking.',
      }),
    cfg_scale: z
      .optional(
        z.number().gte(1).lte(2).register(z.globalRegistry, {
          description:
            'CFG (Classifier-Free Guidance) scale for generation. Higher values increase adherence to text.',
        }),
      )
      .default(1.3),
  })
  .register(z.globalRegistry, {
    description: 'Input schema for VibeVoice-0.5b TTS generation',
  })

/**
 * File
 */
export const zFalAiVibevoice05bFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * VibeVoice_0_5BOutput
 *
 * Output schema for VibeVoice-0.5b TTS generation
 */
export const zVibevoice05bOutput = z
  .object({
    duration: z.number().register(z.globalRegistry, {
      description: 'Duration of the generated audio in seconds',
    }),
    rtf: z.number().register(z.globalRegistry, {
      description:
        'Real-time factor (generation_time / audio_duration). Lower is better.',
    }),
    sample_rate: z.int().register(z.globalRegistry, {
      description: 'Sample rate of the generated audio',
    }),
    generation_time: z.number().register(z.globalRegistry, {
      description: 'Time taken to generate the audio in seconds',
    }),
    audio: zFalAiVibevoice05bFile,
  })
  .register(z.globalRegistry, {
    description: 'Output schema for VibeVoice-0.5b TTS generation',
  })

/**
 * ChatterboxTurboRequest
 */
export const zChatterboxTextToSpeechTurboInput = z.object({
  text: z.string().register(z.globalRegistry, {
    description:
      'The text to be converted to speech. You can add paralinguistic tags: [clear throat], [sigh], [shush], [cough], [groan], [sniff], [gasp], [chuckle], [laugh]',
  }),
  voice: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Preset voice to use for synthesis. Choose from available voices or provide a custom audio URL.',
      }),
    )
    .default('lucy'),
  audio_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'Optional URL to a custom audio file (5-10 seconds) for voice cloning. If provided, this overrides the preset voice selection.',
    }),
  ),
  temperature: z
    .optional(
      z.number().gte(0.05).lte(2).register(z.globalRegistry, {
        description:
          'Temperature for generation. Higher values create more varied speech patterns.',
      }),
    )
    .default(0.8),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducible results. Set to 0 for random generation.',
    }),
  ),
})

/**
 * File
 */
export const zFalAiChatterboxTextToSpeechTurboFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ChatterboxTurboOutput
 */
export const zChatterboxTextToSpeechTurboOutput = z.object({
  audio: zFalAiChatterboxTextToSpeechTurboFile,
})

/**
 * MayaVoiceBatchInput
 *
 * Input schema for batch Maya-1-Voice TTS generation
 */
export const zMayaBatchInput = z
  .object({
    repetition_penalty: z
      .optional(
        z.number().gte(1).lte(2).register(z.globalRegistry, {
          description: 'Repetition penalty for all generations.',
        }),
      )
      .default(1.1),
    top_p: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description: 'Nucleus sampling parameter for all generations.',
        }),
      )
      .default(0.9),
    output_format: z.optional(
      z.enum(['wav', 'mp3']).register(z.globalRegistry, {
        description: 'Output audio format for all generated speech files',
      }),
    ),
    texts: z.array(z.string()).min(1).max(100).register(z.globalRegistry, {
      description:
        'List of texts to synthesize into speech. You can embed emotion tags in each text using the format <emotion_name>.',
    }),
    prompts: z.array(z.string()).min(1).max(100).register(z.globalRegistry, {
      description:
        'List of voice descriptions for each text. Must match the length of texts list. Each describes the voice/character attributes.',
    }),
    max_tokens: z
      .optional(
        z.int().gte(28).lte(4000).register(z.globalRegistry, {
          description: 'Maximum SNAC tokens per generation.',
        }),
      )
      .default(2000),
    temperature: z
      .optional(
        z.number().gte(0).lte(2).register(z.globalRegistry, {
          description: 'Sampling temperature for all generations.',
        }),
      )
      .default(0.4),
    sample_rate: z.optional(
      z.enum(['48 kHz', '24 kHz']).register(z.globalRegistry, {
        description:
          'Output audio sample rate for all generations. 48 kHz provides higher quality, 24 kHz is faster.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Input schema for batch Maya-1-Voice TTS generation',
  })

/**
 * File
 */
export const zFalAiMayaBatchFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * MayaVoiceBatchOutput
 *
 * Output schema for batch Maya-1-Voice TTS generation
 */
export const zMayaBatchOutput = z
  .object({
    average_rtf: z.number().register(z.globalRegistry, {
      description: 'Average real-time factor across all generations',
    }),
    sample_rate: z.string().register(z.globalRegistry, {
      description: 'Sample rate of all generated audio files',
    }),
    total_generation_time: z.number().register(z.globalRegistry, {
      description: 'Total time taken to generate all audio files in seconds',
    }),
    audios: z.array(zFalAiMayaBatchFile).register(z.globalRegistry, {
      description: 'List of generated audio files',
    }),
    durations: z.array(z.number()).register(z.globalRegistry, {
      description: 'Duration of each generated audio in seconds',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Output schema for batch Maya-1-Voice TTS generation',
  })

/**
 * MayaVoiceStreamingInput
 *
 * Input schema for Maya-1-Voice streaming TTS generation
 */
export const zMayaStreamInput = z
  .object({
    repetition_penalty: z
      .optional(
        z.number().gte(1).lte(2).register(z.globalRegistry, {
          description:
            'Penalty for repeating tokens. Higher values reduce repetition artifacts.',
        }),
      )
      .default(1.1),
    prompt: z.string().max(500).register(z.globalRegistry, {
      description:
        'Description of the voice/character. Includes attributes like age, accent, pitch, timbre, pacing, tone, and intensity. See examples for format.',
    }),
    top_p: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            'Nucleus sampling parameter. Controls diversity of token selection.',
        }),
      )
      .default(0.9),
    text: z.string().max(5000).register(z.globalRegistry, {
      description:
        "The text to synthesize into speech. You can embed emotion tags anywhere in the text using the format <emotion_name>. Available emotions: laugh, laugh_harder, sigh, chuckle, gasp, angry, excited, whisper, cry, scream, sing, snort, exhale, gulp, giggle, sarcastic, curious. Example: 'Hello world! <excited> This is amazing!' or 'I can't believe this <sigh> happened again.'",
    }),
    output_format: z.optional(
      z.enum(['mp3', 'wav', 'pcm']).register(z.globalRegistry, {
        description:
          "Output audio format. 'mp3' for browser-playable audio, 'wav' for uncompressed audio, 'pcm' for raw PCM (lowest latency, requires client-side decoding).",
      }),
    ),
    max_tokens: z
      .optional(
        z.int().gte(28).lte(4000).register(z.globalRegistry, {
          description:
            'Maximum number of SNAC tokens to generate (7 tokens per frame). Controls maximum audio length.',
        }),
      )
      .default(2000),
    temperature: z
      .optional(
        z.number().gte(0).lte(2).register(z.globalRegistry, {
          description:
            'Sampling temperature. Lower values (0.2-0.5) produce more stable/consistent audio. Higher values add variation.',
        }),
      )
      .default(0.4),
    sample_rate: z.optional(
      z.enum(['48 kHz', '24 kHz']).register(z.globalRegistry, {
        description:
          'Output audio sample rate. 48 kHz uses upsampling for higher quality audio, 24 kHz is native SNAC output (faster, lower latency).',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Input schema for Maya-1-Voice streaming TTS generation',
  })

export const zMayaStreamOutput = z.unknown()

/**
 * MayaVoiceInput
 *
 * Input schema for Maya-1-Voice TTS generation
 */
export const zMayaInput = z
  .object({
    repetition_penalty: z
      .optional(
        z.number().gte(1).lte(2).register(z.globalRegistry, {
          description:
            'Penalty for repeating tokens. Higher values reduce repetition artifacts.',
        }),
      )
      .default(1.1),
    prompt: z.string().max(500).register(z.globalRegistry, {
      description:
        'Description of the voice/character. Includes attributes like age, accent, pitch, timbre, pacing, tone, and intensity. See examples for format.',
    }),
    top_p: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            'Nucleus sampling parameter. Controls diversity of token selection.',
        }),
      )
      .default(0.9),
    text: z.string().max(5000).register(z.globalRegistry, {
      description:
        "The text to synthesize into speech. You can embed emotion tags anywhere in the text using the format <emotion_name>. Available emotions: laugh, laugh_harder, sigh, chuckle, gasp, angry, excited, whisper, cry, scream, sing, snort, exhale, gulp, giggle, sarcastic, curious. Example: 'Hello world! <excited> This is amazing!' or 'I can't believe this <sigh> happened again.'",
    }),
    output_format: z.optional(
      z.enum(['wav', 'mp3']).register(z.globalRegistry, {
        description: 'Output audio format for the generated speech',
      }),
    ),
    max_tokens: z
      .optional(
        z.int().gte(28).lte(4000).register(z.globalRegistry, {
          description:
            'Maximum number of SNAC tokens to generate (7 tokens per frame). Controls maximum audio length.',
        }),
      )
      .default(2000),
    temperature: z
      .optional(
        z.number().gte(0).lte(2).register(z.globalRegistry, {
          description:
            'Sampling temperature. Lower values (0.2-0.5) produce more stable/consistent audio. Higher values add variation.',
        }),
      )
      .default(0.4),
    sample_rate: z.optional(
      z.enum(['48 kHz', '24 kHz']).register(z.globalRegistry, {
        description:
          'Output audio sample rate. 48 kHz provides higher quality audio, 24 kHz is faster.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Input schema for Maya-1-Voice TTS generation',
  })

/**
 * File
 */
export const zFalAiMayaFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * MayaVoiceOutput
 *
 * Output schema for Maya-1-Voice TTS generation
 */
export const zMayaOutput = z
  .object({
    rtf: z.number().register(z.globalRegistry, {
      description:
        'Real-time factor (generation_time / audio_duration). Lower is better.',
    }),
    duration: z.number().register(z.globalRegistry, {
      description: 'Duration of the generated audio in seconds',
    }),
    sample_rate: z.string().register(z.globalRegistry, {
      description: 'Sample rate of the generated audio',
    }),
    generation_time: z.number().register(z.globalRegistry, {
      description: 'Time taken to generate the audio in seconds',
    }),
    audio: zFalAiMayaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output schema for Maya-1-Voice TTS generation',
  })

/**
 * PronunciationDict
 */
export const zPronunciationDict = z.object({
  tone_list: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "List of pronunciation replacements in format ['text/(pronunciation)', ...]. For Chinese, tones are 1-5. Example: ['燕少飞/(yan4)(shao3)(fei1)']",
    }),
  ),
})

/**
 * VoiceSetting
 */
export const zVoiceSetting = z.object({
  speed: z
    .optional(
      z.number().gte(0.5).lte(2).register(z.globalRegistry, {
        description: 'Speech speed (0.5-2.0)',
      }),
    )
    .default(1),
  vol: z
    .optional(
      z.number().gte(0.01).lte(10).register(z.globalRegistry, {
        description: 'Volume (0-10)',
      }),
    )
    .default(1),
  voice_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Predefined voice ID to use for synthesis',
      }),
    )
    .default('Wise_Woman'),
  pitch: z
    .optional(
      z.int().gte(-12).lte(12).register(z.globalRegistry, {
        description: 'Voice pitch (-12 to 12)',
      }),
    )
    .default(0),
  english_normalization: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Enables English text normalization to improve number reading performance, with a slight increase in latency',
      }),
    )
    .default(false),
  emotion: z.optional(
    z
      .enum([
        'happy',
        'sad',
        'angry',
        'fearful',
        'disgusted',
        'surprised',
        'neutral',
      ])
      .register(z.globalRegistry, {
        description: 'Emotion of the generated speech',
      }),
  ),
})

/**
 * LoudnessNormalizationSetting
 */
export const zLoudnessNormalizationSetting = z.object({
  enabled: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable loudness normalization for the audio',
      }),
    )
    .default(true),
  target_loudness: z
    .optional(
      z.number().gte(-70).lte(-10).register(z.globalRegistry, {
        description: 'Target loudness in LUFS (default -18.0)',
      }),
    )
    .default(-18),
  target_range: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description: 'Target loudness range in LU (default 8.0)',
      }),
    )
    .default(8),
  target_peak: z
    .optional(
      z.number().gte(-3).lte(0).register(z.globalRegistry, {
        description: 'Target peak level in dBTP (default -0.5).',
      }),
    )
    .default(-0.5),
})

/**
 * AudioSetting
 */
export const zAudioSetting = z.object({
  format: z.optional(
    z.enum(['mp3', 'pcm', 'flac']).register(z.globalRegistry, {
      description: 'Audio format',
    }),
  ),
  sample_rate: z.optional(
    z
      .union([
        z.literal(8000),
        z.literal(16000),
        z.literal(22050),
        z.literal(24000),
        z.literal(32000),
        z.literal(44100),
      ])
      .register(z.globalRegistry, {
        description: 'Sample rate of generated audio',
      }),
  ),
  channel: z.optional(
    z.union([z.literal(1), z.literal(2)]).register(z.globalRegistry, {
      description: 'Number of audio channels (1=mono, 2=stereo)',
    }),
  ),
  bitrate: z.optional(
    z
      .union([
        z.literal(32000),
        z.literal(64000),
        z.literal(128000),
        z.literal(256000),
      ])
      .register(z.globalRegistry, {
        description: 'Bitrate of generated audio',
      }),
  ),
})

/**
 * TextToSpeechTurbo26Request
 */
export const zMinimaxSpeech26TurboInput = z.object({
  prompt: z.string().min(1).max(10000).register(z.globalRegistry, {
    description:
      'Text to convert to speech. Paragraph breaks should be marked with newline characters. **NOTE**: You can customize speech pauses by adding markers in the form `<#x#>`, where `x` is the pause duration in seconds. Valid range: `[0.01, 99.99]`, up to two decimal places. Pause markers must be placed between speakable text segments and cannot be used consecutively.',
  }),
  language_boost: z.optional(
    z
      .enum([
        'Chinese',
        'Chinese,Yue',
        'English',
        'Arabic',
        'Russian',
        'Spanish',
        'French',
        'Portuguese',
        'German',
        'Turkish',
        'Dutch',
        'Ukrainian',
        'Vietnamese',
        'Indonesian',
        'Japanese',
        'Italian',
        'Korean',
        'Thai',
        'Polish',
        'Romanian',
        'Greek',
        'Czech',
        'Finnish',
        'Hindi',
        'Bulgarian',
        'Danish',
        'Hebrew',
        'Malay',
        'Slovak',
        'Swedish',
        'Croatian',
        'Hungarian',
        'Norwegian',
        'Slovenian',
        'Catalan',
        'Nynorsk',
        'Afrikaans',
        'auto',
      ])
      .register(z.globalRegistry, {
        description: 'Enhance recognition of specified languages and dialects',
      }),
  ),
  output_format: z.optional(
    z.enum(['url', 'hex']).register(z.globalRegistry, {
      description: 'Format of the output content (non-streaming only)',
    }),
  ),
  pronunciation_dict: z.optional(zPronunciationDict),
  voice_setting: z.optional(zVoiceSetting),
  normalization_setting: z.optional(zLoudnessNormalizationSetting),
  audio_setting: z.optional(zAudioSetting),
})

/**
 * File
 */
export const zFalAiMinimaxSpeech26TurboFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * TextToSpeechTurbo26Output
 */
export const zMinimaxSpeech26TurboOutput = z.object({
  duration_ms: z.int().register(z.globalRegistry, {
    description: 'Duration of the audio in milliseconds',
  }),
  audio: zFalAiMinimaxSpeech26TurboFile,
})

/**
 * PronunciationDict
 */
export const zFalAiMinimaxSpeech26HdPronunciationDict = z.object({
  tone_list: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "List of pronunciation replacements in format ['text/(pronunciation)', ...]. For Chinese, tones are 1-5. Example: ['燕少飞/(yan4)(shao3)(fei1)']",
    }),
  ),
})

/**
 * VoiceSetting
 */
export const zFalAiMinimaxSpeech26HdVoiceSetting = z.object({
  speed: z
    .optional(
      z.number().gte(0.5).lte(2).register(z.globalRegistry, {
        description: 'Speech speed (0.5-2.0)',
      }),
    )
    .default(1),
  vol: z
    .optional(
      z.number().gte(0.01).lte(10).register(z.globalRegistry, {
        description: 'Volume (0-10)',
      }),
    )
    .default(1),
  voice_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Predefined voice ID to use for synthesis',
      }),
    )
    .default('Wise_Woman'),
  pitch: z
    .optional(
      z.int().gte(-12).lte(12).register(z.globalRegistry, {
        description: 'Voice pitch (-12 to 12)',
      }),
    )
    .default(0),
  english_normalization: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Enables English text normalization to improve number reading performance, with a slight increase in latency',
      }),
    )
    .default(false),
  emotion: z.optional(
    z
      .enum([
        'happy',
        'sad',
        'angry',
        'fearful',
        'disgusted',
        'surprised',
        'neutral',
      ])
      .register(z.globalRegistry, {
        description: 'Emotion of the generated speech',
      }),
  ),
})

/**
 * LoudnessNormalizationSetting
 */
export const zFalAiMinimaxSpeech26HdLoudnessNormalizationSetting = z.object({
  enabled: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable loudness normalization for the audio',
      }),
    )
    .default(true),
  target_loudness: z
    .optional(
      z.number().gte(-70).lte(-10).register(z.globalRegistry, {
        description: 'Target loudness in LUFS (default -18.0)',
      }),
    )
    .default(-18),
  target_range: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description: 'Target loudness range in LU (default 8.0)',
      }),
    )
    .default(8),
  target_peak: z
    .optional(
      z.number().gte(-3).lte(0).register(z.globalRegistry, {
        description: 'Target peak level in dBTP (default -0.5).',
      }),
    )
    .default(-0.5),
})

/**
 * AudioSetting
 */
export const zFalAiMinimaxSpeech26HdAudioSetting = z.object({
  format: z.optional(
    z.enum(['mp3', 'pcm', 'flac']).register(z.globalRegistry, {
      description: 'Audio format',
    }),
  ),
  sample_rate: z.optional(
    z
      .union([
        z.literal(8000),
        z.literal(16000),
        z.literal(22050),
        z.literal(24000),
        z.literal(32000),
        z.literal(44100),
      ])
      .register(z.globalRegistry, {
        description: 'Sample rate of generated audio',
      }),
  ),
  channel: z.optional(
    z.union([z.literal(1), z.literal(2)]).register(z.globalRegistry, {
      description: 'Number of audio channels (1=mono, 2=stereo)',
    }),
  ),
  bitrate: z.optional(
    z
      .union([
        z.literal(32000),
        z.literal(64000),
        z.literal(128000),
        z.literal(256000),
      ])
      .register(z.globalRegistry, {
        description: 'Bitrate of generated audio',
      }),
  ),
})

/**
 * TextToSpeechHD26Request
 */
export const zMinimaxSpeech26HdInput = z.object({
  prompt: z.string().min(1).max(10000).register(z.globalRegistry, {
    description:
      'Text to convert to speech. Paragraph breaks should be marked with newline characters. **NOTE**: You can customize speech pauses by adding markers in the form `<#x#>`, where `x` is the pause duration in seconds. Valid range: `[0.01, 99.99]`, up to two decimal places. Pause markers must be placed between speakable text segments and cannot be used consecutively.',
  }),
  language_boost: z.optional(
    z
      .enum([
        'Chinese',
        'Chinese,Yue',
        'English',
        'Arabic',
        'Russian',
        'Spanish',
        'French',
        'Portuguese',
        'German',
        'Turkish',
        'Dutch',
        'Ukrainian',
        'Vietnamese',
        'Indonesian',
        'Japanese',
        'Italian',
        'Korean',
        'Thai',
        'Polish',
        'Romanian',
        'Greek',
        'Czech',
        'Finnish',
        'Hindi',
        'Bulgarian',
        'Danish',
        'Hebrew',
        'Malay',
        'Slovak',
        'Swedish',
        'Croatian',
        'Hungarian',
        'Norwegian',
        'Slovenian',
        'Catalan',
        'Nynorsk',
        'Afrikaans',
        'auto',
      ])
      .register(z.globalRegistry, {
        description: 'Enhance recognition of specified languages and dialects',
      }),
  ),
  output_format: z.optional(
    z.enum(['url', 'hex']).register(z.globalRegistry, {
      description: 'Format of the output content (non-streaming only)',
    }),
  ),
  pronunciation_dict: z.optional(zFalAiMinimaxSpeech26HdPronunciationDict),
  voice_setting: z.optional(zFalAiMinimaxSpeech26HdVoiceSetting),
  normalization_setting: z.optional(
    zFalAiMinimaxSpeech26HdLoudnessNormalizationSetting,
  ),
  audio_setting: z.optional(zFalAiMinimaxSpeech26HdAudioSetting),
})

/**
 * File
 */
export const zFalAiMinimaxSpeech26HdFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * TextToSpeechHD26Output
 */
export const zMinimaxSpeech26HdOutput = z.object({
  duration_ms: z.int().register(z.globalRegistry, {
    description: 'Duration of the audio in milliseconds',
  }),
  audio: zFalAiMinimaxSpeech26HdFile,
})

/**
 * EmotionalStrengths
 */
export const zEmotionalStrengths = z.object({
  afraid: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Strength of fear emotion',
      }),
    )
    .default(0),
  calm: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Strength of calm emotion',
      }),
    )
    .default(0),
  disgusted: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Strength of disgust emotion',
      }),
    )
    .default(0),
  angry: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Strength of anger emotion',
      }),
    )
    .default(0),
  sad: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Strength of sadness emotion',
      }),
    )
    .default(0),
  melancholic: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Strength of melancholic emotion',
      }),
    )
    .default(0),
  surprised: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Strength of surprise emotion',
      }),
    )
    .default(0),
  happy: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Strength of happiness emotion',
      }),
    )
    .default(0),
})

/**
 * IndexTTS2Input
 */
export const zIndexTts2TextToSpeechInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The speech prompt to generate',
  }),
  emotional_strengths: z.optional(zEmotionalStrengths),
  strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the emotional style transfer. Higher values result in stronger emotional influence.',
      }),
    )
    .default(1),
  emotional_audio_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The emotional reference audio file to extract the style from.',
    }),
  ),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'The audio file to generate the speech from.',
  }),
  emotion_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The emotional prompt to influence the emotional style. Must be used together with should_use_prompt_for_emotion.',
    }),
  ),
  should_use_prompt_for_emotion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use the `prompt` to calculate emotional strengths, if enabled it will overwrite the `emotional_strengths` values. If `emotion_prompt` is provided, it will be used to instead of `prompt` to extract the emotional style.',
      }),
    )
    .default(false),
})

/**
 * File
 */
export const zFalAiIndexTts2TextToSpeechFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * IndexTTS2Output
 */
export const zIndexTts2TextToSpeechOutput = z.object({
  audio: zFalAiIndexTts2TextToSpeechFile,
})

/**
 * TTSInput
 */
export const zKlingVideoV1TtsInput = z.object({
  text: z.string().max(500).register(z.globalRegistry, {
    description: 'The text to be converted to speech',
  }),
  voice_id: z.optional(
    z
      .enum([
        'genshin_vindi2',
        'zhinen_xuesheng',
        'AOT',
        'ai_shatang',
        'genshin_klee2',
        'genshin_kirara',
        'ai_kaiya',
        'oversea_male1',
        'ai_chenjiahao_712',
        'girlfriend_4_speech02',
        'chat1_female_new-3',
        'chat_0407_5-1',
        'cartoon-boy-07',
        'uk_boy1',
        'cartoon-girl-01',
        'PeppaPig_platform',
        'ai_huangzhong_712',
        'ai_huangyaoshi_712',
        'ai_laoguowang_712',
        'chengshu_jiejie',
        'you_pingjing',
        'calm_story1',
        'uk_man2',
        'laopopo_speech02',
        'heainainai_speech02',
        'reader_en_m-v1',
        'commercial_lady_en_f-v1',
        'tiyuxi_xuedi',
        'tiexin_nanyou',
        'girlfriend_1_speech02',
        'girlfriend_2_speech02',
        'zhuxi_speech02',
        'uk_oldman3',
        'dongbeilaotie_speech02',
        'chongqingxiaohuo_speech02',
        'chuanmeizi_speech02',
        'chaoshandashu_speech02',
        'ai_taiwan_man2_speech02',
        'xianzhanggui_speech02',
        'tianjinjiejie_speech02',
        'diyinnansang_DB_CN_M_04-v2',
        'yizhipiannan-v1',
        'guanxiaofang-v2',
        'tianmeixuemei-v1',
        'daopianyansang-v1',
        'mengwa-v1',
      ])
      .register(z.globalRegistry, {
        description: 'The voice ID to use for speech synthesis',
      }),
  ),
  voice_speed: z
    .optional(
      z.number().gte(0.8).lte(2).register(z.globalRegistry, {
        description: 'Rate of speech',
      }),
    )
    .default(1),
})

/**
 * File
 */
export const zFalAiKlingVideoV1TtsFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * TTSOutput
 */
export const zKlingVideoV1TtsOutput = z.object({
  audio: zFalAiKlingVideoV1TtsFile,
})

/**
 * ChatterboxMultilingualRequest
 */
export const zChatterboxTextToSpeechMultilingualInput = z.object({
  text: z.string().max(300).register(z.globalRegistry, {
    description:
      'The text to be converted to speech (maximum 300 characters). Supports 23 languages including English, French, German, Spanish, Italian, Portuguese, Hindi, Arabic, Chinese, Japanese, Korean, and more.',
  }),
  custom_audio_language: z.optional(
    z
      .enum([
        'english',
        'arabic',
        'danish',
        'german',
        'greek',
        'spanish',
        'finnish',
        'french',
        'hebrew',
        'hindi',
        'italian',
        'japanese',
        'korean',
        'malay',
        'dutch',
        'norwegian',
        'polish',
        'portuguese',
        'russian',
        'swedish',
        'swahili',
        'turkish',
        'chinese',
      ])
      .register(z.globalRegistry, {
        description:
          'If using a custom audio URL, specify the language of the audio here. Ignored if voice is not a custom url.',
      }),
  ),
  exaggeration: z
    .optional(
      z.number().gte(0.25).lte(2).register(z.globalRegistry, {
        description:
          'Controls speech expressiveness and emotional intensity (0.25-2.0). 0.5 is neutral, higher values increase expressiveness. Extreme values may be unstable.',
      }),
    )
    .default(0.5),
  voice: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Language code for synthesis. In case using custom please provide audio url and select custom_audio_language. ',
      }),
    )
    .default('english'),
  temperature: z
    .optional(
      z.number().gte(0.05).lte(5).register(z.globalRegistry, {
        description:
          'Controls randomness and variation in generation (0.05-5.0). Higher values create more varied speech patterns.',
      }),
    )
    .default(0.8),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducible results. Set to 0 for random generation, or provide a specific number for consistent outputs.',
    }),
  ),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Configuration/pace weight controlling generation guidance (0.0-1.0). Use 0.0 for language transfer to mitigate accent inheritance.',
      }),
    )
    .default(0.5),
})

/**
 * File
 */
export const zFalAiChatterboxTextToSpeechMultilingualFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ChatterboxMultilingualOutput
 */
export const zChatterboxTextToSpeechMultilingualOutput = z.object({
  audio: zFalAiChatterboxTextToSpeechMultilingualFile,
})

/**
 * VibeVoiceSpeaker
 */
export const zVibeVoiceSpeaker = z.object({
  preset: z.optional(
    z
      .enum([
        'Alice [EN]',
        'Carter [EN]',
        'Frank [EN]',
        'Mary [EN] (Background Music)',
        'Maya [EN]',
        'Anchen [ZH] (Background Music)',
        'Bowen [ZH]',
        'Xinran [ZH]',
      ])
      .register(z.globalRegistry, {
        description:
          'Default voice preset to use for the speaker. Not used if `audio_url` is provided.',
      }),
  ),
  audio_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'URL to a voice sample audio file. If provided, `preset` will be ignored.',
    }),
  ),
})

/**
 * VibeVoice7bInput
 *
 * Input schema for VibeVoice-7b TTS generation
 */
export const zVibevoice7bInput = z
  .object({
    script: z.string().max(30000).register(z.globalRegistry, {
      description:
        "The script to convert to speech. Can be formatted with 'Speaker X:' prefixes for multi-speaker dialogues.",
    }),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'Random seed for reproducible generation.',
      }),
    ),
    speakers: z.array(zVibeVoiceSpeaker).register(z.globalRegistry, {
      description:
        'List of speakers to use for the script. If not provided, will be inferred from the script or voice samples.',
    }),
    cfg_scale: z
      .optional(
        z.number().gte(1).lte(2).register(z.globalRegistry, {
          description:
            'CFG (Classifier-Free Guidance) scale for generation. Higher values increase adherence to text.',
        }),
      )
      .default(1.3),
  })
  .register(z.globalRegistry, {
    description: 'Input schema for VibeVoice-7b TTS generation',
  })

/**
 * File
 */
export const zFalAiVibevoice7bFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * VibeVoiceOutput
 *
 * Output schema for VibeVoice TTS generation
 */
export const zVibevoice7bOutput = z
  .object({
    duration: z.number().register(z.globalRegistry, {
      description: 'Duration of the generated audio in seconds',
    }),
    rtf: z.number().register(z.globalRegistry, {
      description:
        'Real-time factor (generation_time / audio_duration). Lower is better.',
    }),
    sample_rate: z.int().register(z.globalRegistry, {
      description: 'Sample rate of the generated audio',
    }),
    generation_time: z.number().register(z.globalRegistry, {
      description: 'Time taken to generate the audio in seconds',
    }),
    audio: zFalAiVibevoice7bFile,
  })
  .register(z.globalRegistry, {
    description: 'Output schema for VibeVoice TTS generation',
  })

/**
 * VibeVoiceSpeaker
 */
export const zFalAiVibevoiceVibeVoiceSpeaker = z.object({
  preset: z.optional(
    z
      .enum([
        'Alice [EN]',
        'Carter [EN]',
        'Frank [EN]',
        'Mary [EN] (Background Music)',
        'Maya [EN]',
        'Anchen [ZH] (Background Music)',
        'Bowen [ZH]',
        'Xinran [ZH]',
      ])
      .register(z.globalRegistry, {
        description:
          'Default voice preset to use for the speaker. Not used if `audio_url` is provided.',
      }),
  ),
  audio_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'URL to a voice sample audio file. If provided, `preset` will be ignored.',
    }),
  ),
})

/**
 * VibeVoiceInput
 *
 * Input schema for VibeVoice TTS generation
 */
export const zVibevoiceInput = z
  .object({
    script: z.string().max(90000).register(z.globalRegistry, {
      description:
        "The script to convert to speech. Can be formatted with 'Speaker X:' prefixes for multi-speaker dialogues.",
    }),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'Random seed for reproducible generation.',
      }),
    ),
    speakers: z
      .array(zFalAiVibevoiceVibeVoiceSpeaker)
      .register(z.globalRegistry, {
        description:
          'List of speakers to use for the script. If not provided, will be inferred from the script or voice samples.',
      }),
    cfg_scale: z
      .optional(
        z.number().gte(1).lte(2).register(z.globalRegistry, {
          description:
            'CFG (Classifier-Free Guidance) scale for generation. Higher values increase adherence to text.',
        }),
      )
      .default(1.3),
  })
  .register(z.globalRegistry, {
    description: 'Input schema for VibeVoice TTS generation',
  })

/**
 * File
 */
export const zFalAiVibevoiceFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * VibeVoiceOutput
 *
 * Output schema for VibeVoice TTS generation
 */
export const zVibevoiceOutput = z
  .object({
    duration: z.number().register(z.globalRegistry, {
      description: 'Duration of the generated audio in seconds',
    }),
    rtf: z.number().register(z.globalRegistry, {
      description:
        'Real-time factor (generation_time / audio_duration). Lower is better.',
    }),
    sample_rate: z.int().register(z.globalRegistry, {
      description: 'Sample rate of the generated audio',
    }),
    generation_time: z.number().register(z.globalRegistry, {
      description: 'Time taken to generate the audio in seconds',
    }),
    audio: zFalAiVibevoiceFile,
  })
  .register(z.globalRegistry, {
    description: 'Output schema for VibeVoice TTS generation',
  })

/**
 * VoiceSetting
 */
export const zFalAiMinimaxPreviewSpeech25HdVoiceSetting = z.object({
  speed: z
    .optional(
      z.number().gte(0.5).lte(2).register(z.globalRegistry, {
        description: 'Speech speed (0.5-2.0)',
      }),
    )
    .default(1),
  vol: z
    .optional(
      z.number().gte(0.01).lte(10).register(z.globalRegistry, {
        description: 'Volume (0-10)',
      }),
    )
    .default(1),
  voice_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Predefined voice ID to use for synthesis',
      }),
    )
    .default('Wise_Woman'),
  pitch: z
    .optional(
      z.int().gte(-12).lte(12).register(z.globalRegistry, {
        description: 'Voice pitch (-12 to 12)',
      }),
    )
    .default(0),
  english_normalization: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Enables English text normalization to improve number reading performance, with a slight increase in latency',
      }),
    )
    .default(false),
  emotion: z.optional(
    z
      .enum([
        'happy',
        'sad',
        'angry',
        'fearful',
        'disgusted',
        'surprised',
        'neutral',
      ])
      .register(z.globalRegistry, {
        description: 'Emotion of the generated speech',
      }),
  ),
})

/**
 * PronunciationDict
 */
export const zFalAiMinimaxPreviewSpeech25HdPronunciationDict = z.object({
  tone_list: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "List of pronunciation replacements in format ['text/(pronunciation)', ...]. For Chinese, tones are 1-5. Example: ['燕少飞/(yan4)(shao3)(fei1)']",
    }),
  ),
})

/**
 * AudioSetting
 */
export const zFalAiMinimaxPreviewSpeech25HdAudioSetting = z.object({
  format: z.optional(
    z.enum(['mp3', 'pcm', 'flac']).register(z.globalRegistry, {
      description: 'Audio format',
    }),
  ),
  sample_rate: z.optional(
    z
      .union([
        z.literal(8000),
        z.literal(16000),
        z.literal(22050),
        z.literal(24000),
        z.literal(32000),
        z.literal(44100),
      ])
      .register(z.globalRegistry, {
        description: 'Sample rate of generated audio',
      }),
  ),
  channel: z.optional(
    z.union([z.literal(1), z.literal(2)]).register(z.globalRegistry, {
      description: 'Number of audio channels (1=mono, 2=stereo)',
    }),
  ),
  bitrate: z.optional(
    z
      .union([
        z.literal(32000),
        z.literal(64000),
        z.literal(128000),
        z.literal(256000),
      ])
      .register(z.globalRegistry, {
        description: 'Bitrate of generated audio',
      }),
  ),
})

/**
 * TextToSpeechHDv25Request
 */
export const zMinimaxPreviewSpeech25HdInput = z.object({
  text: z.string().min(1).max(5000).register(z.globalRegistry, {
    description:
      'Text to convert to speech (max 5000 characters, minimum 1 non-whitespace character)',
  }),
  language_boost: z.optional(
    z
      .enum([
        'Persian',
        'Filipino',
        'Tamil',
        'Chinese',
        'Chinese,Yue',
        'English',
        'Arabic',
        'Russian',
        'Spanish',
        'French',
        'Portuguese',
        'German',
        'Turkish',
        'Dutch',
        'Ukrainian',
        'Vietnamese',
        'Indonesian',
        'Japanese',
        'Italian',
        'Korean',
        'Thai',
        'Polish',
        'Romanian',
        'Greek',
        'Czech',
        'Finnish',
        'Hindi',
        'Bulgarian',
        'Danish',
        'Hebrew',
        'Malay',
        'Slovak',
        'Swedish',
        'Croatian',
        'Hungarian',
        'Norwegian',
        'Slovenian',
        'Catalan',
        'Nynorsk',
        'Afrikaans',
        'auto',
      ])
      .register(z.globalRegistry, {
        description: 'Enhance recognition of specified languages and dialects',
      }),
  ),
  voice_setting: z.optional(zFalAiMinimaxPreviewSpeech25HdVoiceSetting),
  output_format: z.optional(
    z.enum(['url', 'hex']).register(z.globalRegistry, {
      description: 'Format of the output content (non-streaming only)',
    }),
  ),
  pronunciation_dict: z.optional(
    zFalAiMinimaxPreviewSpeech25HdPronunciationDict,
  ),
  audio_setting: z.optional(zFalAiMinimaxPreviewSpeech25HdAudioSetting),
})

/**
 * File
 */
export const zFalAiMinimaxPreviewSpeech25HdFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * TextToSpeechOutput
 */
export const zMinimaxPreviewSpeech25HdOutput = z.object({
  duration_ms: z.int().register(z.globalRegistry, {
    description: 'Duration of the audio in milliseconds',
  }),
  audio: zFalAiMinimaxPreviewSpeech25HdFile,
})

/**
 * VoiceSetting
 */
export const zFalAiMinimaxPreviewSpeech25TurboVoiceSetting = z.object({
  speed: z
    .optional(
      z.number().gte(0.5).lte(2).register(z.globalRegistry, {
        description: 'Speech speed (0.5-2.0)',
      }),
    )
    .default(1),
  vol: z
    .optional(
      z.number().gte(0.01).lte(10).register(z.globalRegistry, {
        description: 'Volume (0-10)',
      }),
    )
    .default(1),
  voice_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Predefined voice ID to use for synthesis',
      }),
    )
    .default('Wise_Woman'),
  pitch: z
    .optional(
      z.int().gte(-12).lte(12).register(z.globalRegistry, {
        description: 'Voice pitch (-12 to 12)',
      }),
    )
    .default(0),
  english_normalization: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Enables English text normalization to improve number reading performance, with a slight increase in latency',
      }),
    )
    .default(false),
  emotion: z.optional(
    z
      .enum([
        'happy',
        'sad',
        'angry',
        'fearful',
        'disgusted',
        'surprised',
        'neutral',
      ])
      .register(z.globalRegistry, {
        description: 'Emotion of the generated speech',
      }),
  ),
})

/**
 * PronunciationDict
 */
export const zFalAiMinimaxPreviewSpeech25TurboPronunciationDict = z.object({
  tone_list: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "List of pronunciation replacements in format ['text/(pronunciation)', ...]. For Chinese, tones are 1-5. Example: ['燕少飞/(yan4)(shao3)(fei1)']",
    }),
  ),
})

/**
 * AudioSetting
 */
export const zFalAiMinimaxPreviewSpeech25TurboAudioSetting = z.object({
  format: z.optional(
    z.enum(['mp3', 'pcm', 'flac']).register(z.globalRegistry, {
      description: 'Audio format',
    }),
  ),
  sample_rate: z.optional(
    z
      .union([
        z.literal(8000),
        z.literal(16000),
        z.literal(22050),
        z.literal(24000),
        z.literal(32000),
        z.literal(44100),
      ])
      .register(z.globalRegistry, {
        description: 'Sample rate of generated audio',
      }),
  ),
  channel: z.optional(
    z.union([z.literal(1), z.literal(2)]).register(z.globalRegistry, {
      description: 'Number of audio channels (1=mono, 2=stereo)',
    }),
  ),
  bitrate: z.optional(
    z
      .union([
        z.literal(32000),
        z.literal(64000),
        z.literal(128000),
        z.literal(256000),
      ])
      .register(z.globalRegistry, {
        description: 'Bitrate of generated audio',
      }),
  ),
})

/**
 * TextToSpeechTurbov25Request
 */
export const zMinimaxPreviewSpeech25TurboInput = z.object({
  text: z.string().min(1).max(5000).register(z.globalRegistry, {
    description:
      'Text to convert to speech (max 5000 characters, minimum 1 non-whitespace character)',
  }),
  language_boost: z.optional(
    z
      .enum([
        'Persian',
        'Filipino',
        'Tamil',
        'Chinese',
        'Chinese,Yue',
        'English',
        'Arabic',
        'Russian',
        'Spanish',
        'French',
        'Portuguese',
        'German',
        'Turkish',
        'Dutch',
        'Ukrainian',
        'Vietnamese',
        'Indonesian',
        'Japanese',
        'Italian',
        'Korean',
        'Thai',
        'Polish',
        'Romanian',
        'Greek',
        'Czech',
        'Finnish',
        'Hindi',
        'Bulgarian',
        'Danish',
        'Hebrew',
        'Malay',
        'Slovak',
        'Swedish',
        'Croatian',
        'Hungarian',
        'Norwegian',
        'Slovenian',
        'Catalan',
        'Nynorsk',
        'Afrikaans',
        'auto',
      ])
      .register(z.globalRegistry, {
        description: 'Enhance recognition of specified languages and dialects',
      }),
  ),
  voice_setting: z.optional(zFalAiMinimaxPreviewSpeech25TurboVoiceSetting),
  output_format: z.optional(
    z.enum(['url', 'hex']).register(z.globalRegistry, {
      description: 'Format of the output content (non-streaming only)',
    }),
  ),
  pronunciation_dict: z.optional(
    zFalAiMinimaxPreviewSpeech25TurboPronunciationDict,
  ),
  audio_setting: z.optional(zFalAiMinimaxPreviewSpeech25TurboAudioSetting),
})

/**
 * File
 */
export const zFalAiMinimaxPreviewSpeech25TurboFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * TextToSpeechOutput
 */
export const zMinimaxPreviewSpeech25TurboOutput = z.object({
  duration_ms: z.int().register(z.globalRegistry, {
    description: 'Duration of the audio in milliseconds',
  }),
  audio: zFalAiMinimaxPreviewSpeech25TurboFile,
})

/**
 * VoiceDesignRequest
 */
export const zMinimaxVoiceDesignInput = z.object({
  preview_text: z.string().max(500).register(z.globalRegistry, {
    description:
      'Text for audio preview. Limited to 500 characters. A fee of $30 per 1M characters will be charged for the generation of the preview audio.',
  }),
  prompt: z.string().max(2000).register(z.globalRegistry, {
    description: 'Voice description prompt for generating a personalized voice',
  }),
})

/**
 * File
 */
export const zFalAiMinimaxVoiceDesignFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * VoiceDesignOutput
 */
export const zMinimaxVoiceDesignOutput = z.object({
  custom_voice_id: z.string().register(z.globalRegistry, {
    description: 'The voice_id of the generated voice',
  }),
  audio: zFalAiMinimaxVoiceDesignFile,
})

/**
 * TTSInput
 *
 * Input parameters for the TTS request.
 */
export const zChatterboxhdTextToSpeechInput = z
  .object({
    text: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'Text to synthesize into speech.',
        }),
      )
      .default(
        'My name is Maximus Decimus Meridius, commander of the Armies of the North, General of the Felix Legions and loyal servant to the true emperor, Marcus Aurelius. Father to a murdered son, husband to a murdered wife. And I will have my vengeance, in this life or the next.',
      ),
    exaggeration: z
      .optional(
        z.number().gte(0.25).lte(2).register(z.globalRegistry, {
          description:
            'Controls emotion exaggeration. Range typically 0.25 to 2.0.',
        }),
      )
      .default(0.5),
    high_quality_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'If True, the generated audio will be upscaled to 48kHz. The generation of the audio will take longer, but the quality will be higher. If False, the generated audio will be 24kHz. ',
        }),
      )
      .default(false),
    voice: z.optional(
      z
        .enum([
          'Aurora',
          'Blade',
          'Britney',
          'Carl',
          'Cliff',
          'Richard',
          'Rico',
          'Siobhan',
          'Vicky',
        ])
        .register(z.globalRegistry, {
          description:
            'The voice to use for the TTS request. If neither voice nor audio are provided, a random voice will be used.',
        }),
    ),
    audio_url: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'URL to the audio sample to use as a voice prompt for zero-shot TTS voice cloning. Providing a audio sample will override the voice setting. If neither voice nor audio_url are provided, a random voice will be used.',
      }),
    ),
    temperature: z
      .optional(
        z.number().gte(0.05).lte(5).register(z.globalRegistry, {
          description:
            'Controls the randomness of generation. Range typically 0.05 to 5.',
        }),
      )
      .default(0.8),
    seed: z
      .optional(
        z.int().gte(0).register(z.globalRegistry, {
          description:
            "Useful to control the reproducibility of the generated audio. Assuming all other properties didn't change, a fixed seed should always generate the exact same audio file. Set to 0 for random seed.",
        }),
      )
      .default(0),
    cfg: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            'Classifier-free guidance scale (CFG) controls the conditioning factor. Range typically 0.2 to 1.0. For expressive or dramatic speech, try lower cfg values (e.g. ~0.3) and increase exaggeration to around 0.7 or higher. If the reference speaker has a fast speaking style, lowering cfg to around 0.3 can improve pacing.',
        }),
      )
      .default(0.5),
  })
  .register(z.globalRegistry, {
    description: 'Input parameters for the TTS request.',
  })

/**
 * Audio
 */
export const zAudio = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * TTSOutput
 *
 * Output parameters for the TTS request.
 */
export const zChatterboxhdTextToSpeechOutput = z
  .object({
    audio: zAudio,
  })
  .register(z.globalRegistry, {
    description: 'Output parameters for the TTS request.',
  })

/**
 * ChatterboxRequest
 */
export const zChatterboxTextToSpeechInput = z.object({
  text: z.string().register(z.globalRegistry, {
    description:
      'The text to be converted to speech. You can additionally add the following emotive tags: <laugh>, <chuckle>, <sigh>, <cough>, <sniffle>, <groan>, <yawn>, <gasp>',
  }),
  exaggeration: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Exaggeration factor for the generated speech (0.0 = no exaggeration, 1.0 = maximum exaggeration).',
      }),
    )
    .default(0.25),
  audio_url: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Optional URL to an audio file to use as a reference for the generated speech. If provided, the model will try to match the style and tone of the reference audio.',
      }),
    )
    .default(
      'https://storage.googleapis.com/chatterbox-demo-samples/prompts/male_rickmorty.mp3',
    ),
  temperature: z
    .optional(
      z.number().gte(0.05).lte(2).register(z.globalRegistry, {
        description: 'Temperature for generation (higher = more creative).',
      }),
    )
    .default(0.7),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Useful to control the reproducibility of the generated audio. Assuming all other properties didn't change, a fixed seed should always generate the exact same audio file. Set to 0 for random seed..",
    }),
  ),
  cfg: z.optional(z.number().gte(0.1).lte(1)).default(0.5),
})

export const zChatterboxTextToSpeechOutput = z.unknown()

/**
 * VoiceCloneRequest
 */
export const zMinimaxVoiceCloneInput = z.object({
  model: z.optional(
    z
      .enum([
        'speech-02-hd',
        'speech-02-turbo',
        'speech-01-hd',
        'speech-01-turbo',
      ])
      .register(z.globalRegistry, {
        description:
          'TTS model to use for preview. Options: speech-02-hd, speech-02-turbo, speech-01-hd, speech-01-turbo',
      }),
  ),
  text: z
    .optional(
      z.string().max(1000).register(z.globalRegistry, {
        description:
          'Text to generate a TTS preview with the cloned voice (optional)',
      }),
    )
    .default(
      'Hello, this is a preview of your cloned voice! I hope you like it!',
    ),
  audio_url: z.string().register(z.globalRegistry, {
    description:
      '\n            URL of the input audio file for voice cloning. Should be at least 10 seconds\n            long. To retain the voice permanently, use it with a TTS (text-to-speech)\n            endpoint at least once within 7 days. Otherwise, it will be\n            automatically deleted.\n        ',
  }),
  accuracy: z.optional(
    z.number().gte(0).lte(1).register(z.globalRegistry, {
      description: 'Text validation accuracy threshold (0-1)',
    }),
  ),
  noise_reduction: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable noise reduction for the cloned voice',
      }),
    )
    .default(false),
  need_volume_normalization: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable volume normalization for the cloned voice',
      }),
    )
    .default(false),
})

/**
 * File
 */
export const zFalAiMinimaxVoiceCloneFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * VoiceCloneOutput
 */
export const zMinimaxVoiceCloneOutput = z.object({
  custom_voice_id: z.string().register(z.globalRegistry, {
    description: 'The cloned voice ID for use with TTS',
  }),
  audio: z.optional(zFalAiMinimaxVoiceCloneFile),
})

/**
 * VoiceSetting
 */
export const zFalAiMinimaxSpeech02TurboVoiceSetting = z.object({
  speed: z
    .optional(
      z.number().gte(0.5).lte(2).register(z.globalRegistry, {
        description: 'Speech speed (0.5-2.0)',
      }),
    )
    .default(1),
  vol: z
    .optional(
      z.number().gte(0.01).lte(10).register(z.globalRegistry, {
        description: 'Volume (0-10)',
      }),
    )
    .default(1),
  voice_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Predefined voice ID to use for synthesis',
      }),
    )
    .default('Wise_Woman'),
  pitch: z
    .optional(
      z.int().gte(-12).lte(12).register(z.globalRegistry, {
        description: 'Voice pitch (-12 to 12)',
      }),
    )
    .default(0),
  english_normalization: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Enables English text normalization to improve number reading performance, with a slight increase in latency',
      }),
    )
    .default(false),
  emotion: z.optional(
    z
      .enum([
        'happy',
        'sad',
        'angry',
        'fearful',
        'disgusted',
        'surprised',
        'neutral',
      ])
      .register(z.globalRegistry, {
        description: 'Emotion of the generated speech',
      }),
  ),
})

/**
 * PronunciationDict
 */
export const zFalAiMinimaxSpeech02TurboPronunciationDict = z.object({
  tone_list: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "List of pronunciation replacements in format ['text/(pronunciation)', ...]. For Chinese, tones are 1-5. Example: ['燕少飞/(yan4)(shao3)(fei1)']",
    }),
  ),
})

/**
 * AudioSetting
 */
export const zFalAiMinimaxSpeech02TurboAudioSetting = z.object({
  format: z.optional(
    z.enum(['mp3', 'pcm', 'flac']).register(z.globalRegistry, {
      description: 'Audio format',
    }),
  ),
  sample_rate: z.optional(
    z
      .union([
        z.literal(8000),
        z.literal(16000),
        z.literal(22050),
        z.literal(24000),
        z.literal(32000),
        z.literal(44100),
      ])
      .register(z.globalRegistry, {
        description: 'Sample rate of generated audio',
      }),
  ),
  channel: z.optional(
    z.union([z.literal(1), z.literal(2)]).register(z.globalRegistry, {
      description: 'Number of audio channels (1=mono, 2=stereo)',
    }),
  ),
  bitrate: z.optional(
    z
      .union([
        z.literal(32000),
        z.literal(64000),
        z.literal(128000),
        z.literal(256000),
      ])
      .register(z.globalRegistry, {
        description: 'Bitrate of generated audio',
      }),
  ),
})

/**
 * TextToSpeechTurboRequest
 */
export const zMinimaxSpeech02TurboInput = z.object({
  text: z.string().min(1).max(5000).register(z.globalRegistry, {
    description:
      'Text to convert to speech (max 5000 characters, minimum 1 non-whitespace character)',
  }),
  language_boost: z.optional(
    z
      .enum([
        'Chinese',
        'Chinese,Yue',
        'English',
        'Arabic',
        'Russian',
        'Spanish',
        'French',
        'Portuguese',
        'German',
        'Turkish',
        'Dutch',
        'Ukrainian',
        'Vietnamese',
        'Indonesian',
        'Japanese',
        'Italian',
        'Korean',
        'Thai',
        'Polish',
        'Romanian',
        'Greek',
        'Czech',
        'Finnish',
        'Hindi',
        'Bulgarian',
        'Danish',
        'Hebrew',
        'Malay',
        'Slovak',
        'Swedish',
        'Croatian',
        'Hungarian',
        'Norwegian',
        'Slovenian',
        'Catalan',
        'Nynorsk',
        'Afrikaans',
        'auto',
      ])
      .register(z.globalRegistry, {
        description: 'Enhance recognition of specified languages and dialects',
      }),
  ),
  voice_setting: z.optional(zFalAiMinimaxSpeech02TurboVoiceSetting),
  output_format: z.optional(
    z.enum(['url', 'hex']).register(z.globalRegistry, {
      description: 'Format of the output content (non-streaming only)',
    }),
  ),
  pronunciation_dict: z.optional(zFalAiMinimaxSpeech02TurboPronunciationDict),
  audio_setting: z.optional(zFalAiMinimaxSpeech02TurboAudioSetting),
})

/**
 * File
 */
export const zFalAiMinimaxSpeech02TurboFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * TextToSpeechOutput
 */
export const zMinimaxSpeech02TurboOutput = z.object({
  duration_ms: z.int().register(z.globalRegistry, {
    description: 'Duration of the audio in milliseconds',
  }),
  audio: zFalAiMinimaxSpeech02TurboFile,
})

/**
 * VoiceSetting
 */
export const zFalAiMinimaxSpeech02HdVoiceSetting = z.object({
  speed: z
    .optional(
      z.number().gte(0.5).lte(2).register(z.globalRegistry, {
        description: 'Speech speed (0.5-2.0)',
      }),
    )
    .default(1),
  vol: z
    .optional(
      z.number().gte(0.01).lte(10).register(z.globalRegistry, {
        description: 'Volume (0-10)',
      }),
    )
    .default(1),
  voice_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Predefined voice ID to use for synthesis',
      }),
    )
    .default('Wise_Woman'),
  pitch: z
    .optional(
      z.int().gte(-12).lte(12).register(z.globalRegistry, {
        description: 'Voice pitch (-12 to 12)',
      }),
    )
    .default(0),
  english_normalization: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Enables English text normalization to improve number reading performance, with a slight increase in latency',
      }),
    )
    .default(false),
  emotion: z.optional(
    z
      .enum([
        'happy',
        'sad',
        'angry',
        'fearful',
        'disgusted',
        'surprised',
        'neutral',
      ])
      .register(z.globalRegistry, {
        description: 'Emotion of the generated speech',
      }),
  ),
})

/**
 * PronunciationDict
 */
export const zFalAiMinimaxSpeech02HdPronunciationDict = z.object({
  tone_list: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "List of pronunciation replacements in format ['text/(pronunciation)', ...]. For Chinese, tones are 1-5. Example: ['燕少飞/(yan4)(shao3)(fei1)']",
    }),
  ),
})

/**
 * AudioSetting
 */
export const zFalAiMinimaxSpeech02HdAudioSetting = z.object({
  format: z.optional(
    z.enum(['mp3', 'pcm', 'flac']).register(z.globalRegistry, {
      description: 'Audio format',
    }),
  ),
  sample_rate: z.optional(
    z
      .union([
        z.literal(8000),
        z.literal(16000),
        z.literal(22050),
        z.literal(24000),
        z.literal(32000),
        z.literal(44100),
      ])
      .register(z.globalRegistry, {
        description: 'Sample rate of generated audio',
      }),
  ),
  channel: z.optional(
    z.union([z.literal(1), z.literal(2)]).register(z.globalRegistry, {
      description: 'Number of audio channels (1=mono, 2=stereo)',
    }),
  ),
  bitrate: z.optional(
    z
      .union([
        z.literal(32000),
        z.literal(64000),
        z.literal(128000),
        z.literal(256000),
      ])
      .register(z.globalRegistry, {
        description: 'Bitrate of generated audio',
      }),
  ),
})

/**
 * TextToSpeechHDRequest
 */
export const zMinimaxSpeech02HdInput = z.object({
  text: z.string().min(1).max(5000).register(z.globalRegistry, {
    description:
      'Text to convert to speech (max 5000 characters, minimum 1 non-whitespace character)',
  }),
  language_boost: z.optional(
    z
      .enum([
        'Chinese',
        'Chinese,Yue',
        'English',
        'Arabic',
        'Russian',
        'Spanish',
        'French',
        'Portuguese',
        'German',
        'Turkish',
        'Dutch',
        'Ukrainian',
        'Vietnamese',
        'Indonesian',
        'Japanese',
        'Italian',
        'Korean',
        'Thai',
        'Polish',
        'Romanian',
        'Greek',
        'Czech',
        'Finnish',
        'Hindi',
        'Bulgarian',
        'Danish',
        'Hebrew',
        'Malay',
        'Slovak',
        'Swedish',
        'Croatian',
        'Hungarian',
        'Norwegian',
        'Slovenian',
        'Catalan',
        'Nynorsk',
        'Afrikaans',
        'auto',
      ])
      .register(z.globalRegistry, {
        description: 'Enhance recognition of specified languages and dialects',
      }),
  ),
  voice_setting: z.optional(zFalAiMinimaxSpeech02HdVoiceSetting),
  output_format: z.optional(
    z.enum(['url', 'hex']).register(z.globalRegistry, {
      description: 'Format of the output content (non-streaming only)',
    }),
  ),
  pronunciation_dict: z.optional(zFalAiMinimaxSpeech02HdPronunciationDict),
  audio_setting: z.optional(zFalAiMinimaxSpeech02HdAudioSetting),
})

/**
 * File
 */
export const zFalAiMinimaxSpeech02HdFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * TextToSpeechOutput
 */
export const zMinimaxSpeech02HdOutput = z.object({
  duration_ms: z.int().register(z.globalRegistry, {
    description: 'Duration of the audio in milliseconds',
  }),
  audio: zFalAiMinimaxSpeech02HdFile,
})

/**
 * DiaRequest
 */
export const zDiaTtsInput = z.object({
  text: z.string().register(z.globalRegistry, {
    description: 'The text to be converted to speech.',
  }),
})

/**
 * File
 */
export const zFalAiDiaTtsFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * DiaOutput
 */
export const zDiaTtsOutput = z.object({
  audio: zFalAiDiaTtsFile,
})

/**
 * OrpheusRequest
 */
export const zOrpheusTtsInput = z.object({
  text: z.string().register(z.globalRegistry, {
    description:
      'The text to be converted to speech. You can additionally add the following emotive tags: <laugh>, <chuckle>, <sigh>, <cough>, <sniffle>, <groan>, <yawn>, <gasp>',
  }),
  voice: z.optional(
    z
      .enum(['tara', 'leah', 'jess', 'leo', 'dan', 'mia', 'zac', 'zoe'])
      .register(z.globalRegistry, {
        description: 'Voice ID for the desired voice.',
      }),
  ),
  repetition_penalty: z
    .optional(
      z.number().gte(1.1).lte(2).register(z.globalRegistry, {
        description:
          'Repetition penalty (>= 1.1 required for stable generations).',
      }),
    )
    .default(1.2),
  temperature: z
    .optional(
      z.number().gte(0).lte(2).register(z.globalRegistry, {
        description: 'Temperature for generation (higher = more creative).',
      }),
    )
    .default(0.7),
})

/**
 * File
 */
export const zFalAiOrpheusTtsFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * OrpheusOutput
 */
export const zOrpheusTtsOutput = z.object({
  audio: zFalAiOrpheusTtsFile,
})

/**
 * TextToSpeechRequest
 */
export const zElevenlabsTtsTurboV25Input = z.object({
  stability: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Voice stability (0-1)',
      }),
    )
    .default(0.5),
  next_text: z.optional(z.union([z.string(), z.unknown()])),
  speed: z
    .optional(
      z.number().gte(0.7).lte(1.2).register(z.globalRegistry, {
        description:
          'Speech speed (0.7-1.2). Values below 1.0 slow down the speech, above 1.0 speed it up. Extreme values may affect quality.',
      }),
    )
    .default(1),
  style: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Style exaggeration (0-1)',
      }),
    )
    .default(0),
  text: z.string().min(1).register(z.globalRegistry, {
    description: 'The text to convert to speech',
  }),
  timestamps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to return timestamps for each word in the generated speech',
      }),
    )
    .default(false),
  similarity_boost: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Similarity boost (0-1)',
      }),
    )
    .default(0.75),
  voice: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The voice to use for speech generation',
      }),
    )
    .default('Rachel'),
  language_code: z.optional(z.union([z.string(), z.unknown()])),
  previous_text: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * File
 */
export const zFalAiElevenlabsTtsTurboV25File = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * TTSOutput
 */
export const zElevenlabsTtsTurboV25Output = z.object({
  audio: zFalAiElevenlabsTtsTurboV25File,
  timestamps: z.optional(z.union([z.array(z.unknown()), z.unknown()])),
})
