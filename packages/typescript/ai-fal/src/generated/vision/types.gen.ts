// This file is auto-generated by @hey-api/openapi-ts

export type ClientOptions = {
  baseUrl: `${string}://${string}` | (string & {})
}

export type File = {
  url: string
  content_type?: string
  file_name?: string
  file_size?: number
}

export type QueueStatus = {
  status: 'IN_PROGRESS' | 'COMPLETED' | 'FAILED'
  response_url?: string
}

/**
 * SemanticImageInput
 */
export type SemanticImageInput = {
  /**
   * Hypothesis
   *
   * The hypothesis image to use for the measurement.
   */
  hypothesis: string
  /**
   * Reference
   *
   * The text reference to use for the measurement.
   */
  reference: string
}

/**
 * MultiMeasurementOutput
 */
export type ArbiterImageTextOutput = {
  /**
   * Values
   *
   * The values of the measurements.
   */
  values?: Array<{
    [key: string]:
      | number
      | {
          [key: string]: number
        }
  }>
}

/**
 * ReferenceImageInput
 */
export type ReferenceImageInput = {
  /**
   * Hypothesis
   *
   * The hypothesis image to use for the measurement.
   */
  hypothesis: string
  /**
   * Reference
   *
   * The image to use for the measurement.
   */
  reference: string
}

/**
 * MultiMeasurementOutput
 */
export type ArbiterImageImageOutput = {
  /**
   * Values
   *
   * The values of the measurements.
   */
  values?: Array<{
    [key: string]:
      | number
      | {
          [key: string]: number
        }
  }>
}

/**
 * ImageInput
 */
export type ImageInput = {
  /**
   * Hypothesis
   *
   * The image to use for the measurement.
   */
  hypothesis: string
}

/**
 * MultiMeasurementOutput
 */
export type ArbiterImageOutput = {
  /**
   * Values
   *
   * The values of the measurements.
   */
  values?: Array<{
    [key: string]:
      | number
      | {
          [key: string]: number
        }
  }>
}

/**
 * ImageDetectionInput
 */
export type AiDetectorDetectImageInput = {
  /**
   * Image Url
   *
   * URL pointing to an image to analyze for AI generation.(Max: 3000 characters)
   */
  image_url: string
}

/**
 * AIImageDetectionOutput
 */
export type AiDetectorDetectImageOutput = {
  /**
   * Latency
   */
  latency: number
  /**
   * Verdict
   */
  verdict: string
  /**
   * Is Ai Generated
   */
  is_ai_generated: boolean
  /**
   * Confidence
   */
  confidence: number
}

/**
 * SAM3EmbeddingInput
 */
export type Sam3ImageEmbedInput = {
  /**
   * Image Url
   *
   * URL of the image to embed.
   */
  image_url: string
}

/**
 * SAM3EmbeddingOutput
 */
export type Sam3ImageEmbedOutput = {
  /**
   * Embedding B64
   *
   * Embedding of the image
   */
  embedding_b64: string
}

/**
 * VisionInput
 */
export type RouterVisionInput = {
  /**
   * Prompt
   *
   * Prompt to be used for the image
   */
  prompt: string
  /**
   * System Prompt
   *
   * System prompt to provide context or instructions to the model
   */
  system_prompt?: string
  /**
   * Reasoning
   *
   * Should reasoning be the part of the final answer.
   */
  reasoning?: boolean
  /**
   * Model
   *
   * Name of the model to use. Charged based on actual token usage.
   */
  model: string
  /**
   * Max Tokens
   *
   * This sets the upper limit for the number of tokens the model can generate in response. It won't produce more than this limit. The maximum value is the context length minus the prompt length.
   */
  max_tokens?: number
  /**
   * Temperature
   *
   * This setting influences the variety in the model's responses. Lower values lead to more predictable and typical responses, while higher values encourage more diverse and less common responses. At 0, the model always gives the same response for a given input.
   */
  temperature?: number
  /**
   * Image Urls
   *
   * List of image URLs to be processed
   */
  image_urls: Array<string>
}

/**
 * VisionOutput
 */
export type RouterVisionOutput = {
  /**
   * Usage
   *
   * Token usage information
   */
  usage?: UsageInfo
  /**
   * Output
   *
   * Generated output
   */
  output: string
}

/**
 * UsageInfo
 */
export type UsageInfo = {
  /**
   * Prompt Tokens
   */
  prompt_tokens?: number
  /**
   * Total Tokens
   */
  total_tokens?: number
  /**
   * Completion Tokens
   */
  completion_tokens?: number
  /**
   * Cost
   */
  cost: number
}

/**
 * MoondreamDetectInput
 */
export type Moondream3PreviewDetectInput = {
  /**
   * Prompt
   *
   * Object to be detected in the image
   */
  prompt: string
  /**
   * Preview
   *
   * Whether to preview the output
   */
  preview?: boolean
  /**
   * Image URL
   *
   * URL of the image to be processed
   *
   * Max width: 7000px, Max height: 7000px, Timeout: 20.0s
   */
  image_url: string
}

/**
 * MoondreamDetectOutput
 */
export type Moondream3PreviewDetectOutput = {
  /**
   * Finish Reason
   *
   * Reason for finishing the output generation
   */
  finish_reason: string
  /**
   * Image
   *
   * Image with bounding boxes drawn around detected objects
   */
  image?: ImageFile
  /**
   * Objects
   *
   * List of detected objects with their bounding boxes
   */
  objects: Array<Object>
  /**
   * Usage Info
   *
   * Usage information for the request
   */
  usage_info: FalAiMoondream3PreviewDetectUsageInfo
}

/**
 * ImageFile
 */
export type ImageFile = {
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Object
 */
export type Object = {
  /**
   * Y Min
   *
   * Top boundary of detection box in normalized format (0 to 1)
   */
  y_min: number
  /**
   * X Max
   *
   * Right boundary of detection box in normalized format (0 to 1)
   */
  x_max: number
  /**
   * X Min
   *
   * Left boundary of detection box in normalized format (0 to 1)
   */
  x_min: number
  /**
   * Y Max
   *
   * Bottom boundary of detection box in normalized format (0 to 1)
   */
  y_max: number
}

/**
 * UsageInfo
 */
export type FalAiMoondream3PreviewDetectUsageInfo = {
  /**
   * Output Tokens
   *
   * Number of output tokens generated
   */
  output_tokens: number
  /**
   * Decode Time Ms
   *
   * Time taken for decoding in milliseconds
   */
  decode_time_ms: number
  /**
   * Input Tokens
   *
   * Number of input tokens processed
   */
  input_tokens: number
  /**
   * Ttft Ms
   *
   * Time to first token in milliseconds
   */
  ttft_ms: number
  /**
   * Prefill Time Ms
   *
   * Time taken for prefill in milliseconds
   */
  prefill_time_ms: number
}

/**
 * MoondreamPointInput
 */
export type Moondream3PreviewPointInput = {
  /**
   * Prompt
   *
   * Object to be located in the image
   */
  prompt: string
  /**
   * Preview
   *
   * Whether to preview the output
   */
  preview?: boolean
  /**
   * Image URL
   *
   * URL of the image to be processed
   *
   * Max width: 7000px, Max height: 7000px, Timeout: 20.0s
   */
  image_url: string
}

/**
 * MoondreamPointOutput
 */
export type Moondream3PreviewPointOutput = {
  /**
   * Points
   *
   * List of points marking the detected objects
   */
  points: Array<Point>
  /**
   * Finish Reason
   *
   * Reason for finishing the output generation
   */
  finish_reason: string
  /**
   * Image
   *
   * Image with points drawn on detected objects
   */
  image?: FalAiMoondream3PreviewPointImageFile
  /**
   * Usage Info
   *
   * Usage information for the request
   */
  usage_info: FalAiMoondream3PreviewPointUsageInfo
}

/**
 * Point
 */
export type Point = {
  /**
   * Y
   *
   * Y coordinate of the point in normalized format (0 to 1)
   */
  y: number
  /**
   * X
   *
   * X coordinate of the point in normalized format (0 to 1)
   */
  x: number
}

/**
 * ImageFile
 */
export type FalAiMoondream3PreviewPointImageFile = {
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * UsageInfo
 */
export type FalAiMoondream3PreviewPointUsageInfo = {
  /**
   * Output Tokens
   *
   * Number of output tokens generated
   */
  output_tokens: number
  /**
   * Decode Time Ms
   *
   * Time taken for decoding in milliseconds
   */
  decode_time_ms: number
  /**
   * Input Tokens
   *
   * Number of input tokens processed
   */
  input_tokens: number
  /**
   * Ttft Ms
   *
   * Time to first token in milliseconds
   */
  ttft_ms: number
  /**
   * Prefill Time Ms
   *
   * Time taken for prefill in milliseconds
   */
  prefill_time_ms: number
}

/**
 * MoondreamQueryInput
 */
export type Moondream3PreviewQueryInput = {
  /**
   * Prompt
   *
   * Query to be asked in the image
   */
  prompt: string
  /**
   * Top P
   *
   * Nucleus sampling probability mass to use, between 0 and 1.
   */
  top_p?: number
  /**
   * Temperature
   *
   * Sampling temperature to use, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If not set, defaults to 0.
   */
  temperature?: number
  /**
   * Reasoning
   *
   * Whether to include detailed reasoning behind the answer
   */
  reasoning?: boolean
  /**
   * Image URL
   *
   * URL of the image to be processed
   *
   * Max width: 7000px, Max height: 7000px, Timeout: 20.0s
   */
  image_url: string
}

/**
 * MoondreamQueryOutput
 */
export type Moondream3PreviewQueryOutput = {
  /**
   * Finish Reason
   *
   * Reason for finishing the output generation
   */
  finish_reason: string
  /**
   * Reasoning
   *
   * Detailed reasoning behind the answer, if enabled
   */
  reasoning?: string
  /**
   * Output
   *
   * Answer to the query about the image
   */
  output: string
  /**
   * Usage Info
   *
   * Usage information for the request
   */
  usage_info: FalAiMoondream3PreviewQueryUsageInfo
}

/**
 * UsageInfo
 */
export type FalAiMoondream3PreviewQueryUsageInfo = {
  /**
   * Output Tokens
   *
   * Number of output tokens generated
   */
  output_tokens: number
  /**
   * Decode Time Ms
   *
   * Time taken for decoding in milliseconds
   */
  decode_time_ms: number
  /**
   * Input Tokens
   *
   * Number of input tokens processed
   */
  input_tokens: number
  /**
   * Ttft Ms
   *
   * Time to first token in milliseconds
   */
  ttft_ms: number
  /**
   * Prefill Time Ms
   *
   * Time taken for prefill in milliseconds
   */
  prefill_time_ms: number
}

/**
 * MoondreamCaptionInput
 */
export type Moondream3PreviewCaptionInput = {
  /**
   * Top P
   *
   * Nucleus sampling probability mass to use, between 0 and 1.
   */
  top_p?: number
  /**
   * Length
   *
   * Length of the caption to generate
   */
  length?: 'short' | 'normal' | 'long'
  /**
   * Temperature
   *
   * Sampling temperature to use, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If not set, defaults to 0.
   */
  temperature?: number
  /**
   * Image URL
   *
   * URL of the image to be processed
   *
   * Max width: 7000px, Max height: 7000px, Timeout: 20.0s
   */
  image_url: string
}

/**
 * MoondreamCaptionOutput
 */
export type Moondream3PreviewCaptionOutput = {
  /**
   * Finish Reason
   *
   * Reason for finishing the output generation
   */
  finish_reason: string
  /**
   * Output
   *
   * Generated caption for the image
   */
  output: string
  /**
   * Usage Info
   *
   * Usage information for the request
   */
  usage_info: FalAiMoondream3PreviewCaptionUsageInfo
}

/**
 * UsageInfo
 */
export type FalAiMoondream3PreviewCaptionUsageInfo = {
  /**
   * Output Tokens
   *
   * Number of output tokens generated
   */
  output_tokens: number
  /**
   * Decode Time Ms
   *
   * Time taken for decoding in milliseconds
   */
  decode_time_ms: number
  /**
   * Input Tokens
   *
   * Number of input tokens processed
   */
  input_tokens: number
  /**
   * Ttft Ms
   *
   * Time to first token in milliseconds
   */
  ttft_ms: number
  /**
   * Prefill Time Ms
   *
   * Time taken for prefill in milliseconds
   */
  prefill_time_ms: number
}

export type Isaac01OpenaiV1ChatCompletionsOutput = unknown

/**
 * VisionInput
 */
export type Isaac01Input = {
  /**
   * Prompt
   *
   * Prompt to be used for the image
   */
  prompt: string
  /**
   * Response Style
   *
   *
   * Response style to be used for the image.
   *
   * - text: Model will output text. Good for descriptions and captioning.
   * - box: Model will output a combination of text and bounding boxes. Good for
   * localization.
   * - point: Model will output a combination of text and points. Good for counting many
   * objects.
   * - polygon: Model will output a combination of text and polygons. Good for granular
   * segmentation.
   *
   */
  response_style?: 'text' | 'box' | 'point' | 'polygon'
  /**
   * Image Url
   *
   * Image URL to be processed
   */
  image_url: string
}

/**
 * ChatOutput
 */
export type Isaac01Output = {
  /**
   * Usage information
   */
  usage?: CompletionUsage | unknown
  /**
   * Error
   *
   * Error message if an error occurred
   */
  error?: string | unknown
  /**
   * Partial
   *
   * Whether the output is partial
   */
  partial?: boolean
  /**
   * Output
   *
   * Generated output
   */
  output: string
}

/**
 * CompletionUsage
 */
export type CompletionUsage = {
  /**
   * Completion Tokens
   *
   * Number of tokens in the completion
   */
  completion_tokens: number
  /**
   * Total Tokens
   *
   * Total tokens used
   */
  total_tokens: number
  /**
   * Prompt Tokens
   *
   * Number of tokens in the prompt
   */
  prompt_tokens: number
}

/**
 * NSFWInput
 */
export type XAilabNsfwInput = {
  /**
   * Image Urls
   *
   * List of image URLs to check. If more than 10 images are provided, only the first 10 will be checked.
   */
  image_urls: Array<string>
}

/**
 * NSFWOutput
 */
export type XAilabNsfwOutput = {
  /**
   * Has Nsfw Concepts
   *
   * List of booleans indicating if the image has an NSFW concept
   */
  has_nsfw_concepts: Array<boolean>
}

/**
 * VideoUnderstandingInput
 */
export type VideoUnderstandingInput = {
  /**
   * Detailed Analysis
   *
   * Whether to request a more detailed analysis of the video
   */
  detailed_analysis?: boolean
  /**
   * Video Url
   *
   * URL of the video to analyze
   */
  video_url: string
  /**
   * Prompt
   *
   * The question or prompt about the video content.
   */
  prompt: string
}

/**
 * VideoUnderstandingOutput
 */
export type VideoUnderstandingOutput = {
  /**
   * Output
   *
   * The analysis of the video content based on the prompt
   */
  output: string
}

/**
 * MoondreamQueryInput
 */
export type Moondream2VisualQueryInput = {
  /**
   * Query
   *
   * Query to be asked in the image
   */
  prompt: string
  /**
   * Image URL
   *
   * URL of the image to be processed
   */
  image_url: string
}

/**
 * MoondreamOutput
 */
export type Moondream2VisualQueryOutput = {
  /**
   * Output
   *
   * Output for the given query
   */
  output: string
}

/**
 * MoondreamInput
 */
export type Moondream2Input = {
  /**
   * Image URL
   *
   * URL of the image to be processed
   */
  image_url: string
}

/**
 * MoondreamOutput
 */
export type Moondream2Output = {
  /**
   * Output
   *
   * Output for the given query
   */
  output: string
}

/**
 * MoondreamObjectInput
 */
export type Moondream2PointObjectDetectionInput = {
  /**
   * Object
   *
   * Object to be detected in the image
   */
  object: string
  /**
   * Image URL
   *
   * URL of the image to be processed
   */
  image_url: string
}

/**
 * MoondreamObjectOutput
 */
export type Moondream2PointObjectDetectionOutput = {
  image: Image
  /**
   * Objects
   *
   * Objects detected in the image
   */
  objects: Array<{
    [key: string]: unknown
  }>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type Image = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * MoondreamObjectInput
 */
export type Moondream2ObjectDetectionInput = {
  /**
   * Object
   *
   * Object to be detected in the image
   */
  object: string
  /**
   * Image URL
   *
   * URL of the image to be processed
   */
  image_url: string
}

/**
 * MoondreamObjectOutput
 */
export type Moondream2ObjectDetectionOutput = {
  image: FalAiMoondream2ObjectDetectionImage
  /**
   * Objects
   *
   * Objects detected in the image
   */
  objects: Array<{
    [key: string]: unknown
  }>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiMoondream2ObjectDetectionImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * ImageInput
 */
export type GotOcrV2Input = {
  /**
   * Do Format
   *
   * Generate the output in formatted mode.
   */
  do_format?: boolean
  /**
   * Multi Page
   *
   * Use provided images to generate a single output.
   */
  multi_page?: boolean
  /**
   * Input Image Urls
   *
   * URL of images.
   */
  input_image_urls?: Array<string>
}

/**
 * ImageChatOutput
 */
export type GotOcrV2Output = {
  /**
   * Output
   *
   * Generated output
   */
  outputs: Array<string>
}

/**
 * BatchQueryInput
 */
export type MoondreamNextBatchInput = {
  /**
   * Prompt
   *
   * Single prompt to apply to all images
   */
  prompt: string
  /**
   * Image URLs
   *
   * List of image URLs to be processed (maximum 32 images)
   */
  images_data_url: string
  /**
   * Max Tokens
   *
   * Maximum number of tokens to generate
   */
  max_tokens?: number
}

/**
 * BatchMoonDreamOutput
 */
export type MoondreamNextBatchOutput = {
  /**
   * Outputs
   *
   * List of generated captions
   */
  outputs: Array<string>
  /**
   * Captions File
   *
   * URL to the generated captions JSON file containing filename-caption pairs.
   */
  captions_file: FalAiMoondreamNextBatchFile
}

/**
 * File
 */
export type FalAiMoondreamNextBatchFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * VideoInput
 */
export type Sa2Va8bVideoInput = {
  /**
   * Prompt
   *
   * Prompt to be used for the chat completion
   */
  prompt: string
  /**
   * Video Url
   *
   * The URL of the input video.
   */
  video_url: string
  /**
   * Num Frames To Sample
   *
   * Number of frames to sample from the video. If not provided, all frames are sampled.
   */
  num_frames_to_sample?: number
}

/**
 * VideoChatOutput
 */
export type Sa2Va8bVideoOutput = {
  /**
   * Masks
   *
   * Dictionary of label: mask video
   */
  masks: Array<FalAiSa2Va8bVideoFile>
  /**
   * Output
   *
   * Generated output
   */
  output: string
}

/**
 * File
 */
export type FalAiSa2Va8bVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * VideoInput
 */
export type Sa2Va4bVideoInput = {
  /**
   * Prompt
   *
   * Prompt to be used for the chat completion
   */
  prompt: string
  /**
   * Video Url
   *
   * The URL of the input video.
   */
  video_url: string
  /**
   * Num Frames To Sample
   *
   * Number of frames to sample from the video. If not provided, all frames are sampled.
   */
  num_frames_to_sample?: number
}

/**
 * VideoChatOutput
 */
export type Sa2Va4bVideoOutput = {
  /**
   * Masks
   *
   * Dictionary of label: mask video
   */
  masks: Array<FalAiSa2Va4bVideoFile>
  /**
   * Output
   *
   * Generated output
   */
  output: string
}

/**
 * File
 */
export type FalAiSa2Va4bVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageInput
 */
export type Sa2Va4bImageInput = {
  /**
   * Prompt
   *
   * Prompt to be used for the chat completion
   */
  prompt: string
  /**
   * Image Url
   *
   * Url for the Input image.
   */
  image_url: string
}

/**
 * ImageChatOutput
 */
export type Sa2Va4bImageOutput = {
  /**
   * Masks
   *
   * Dictionary of label: mask image
   */
  masks: Array<FalAiSa2Va4bImageImage>
  /**
   * Output
   *
   * Generated output
   */
  output: string
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiSa2Va4bImageImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageInput
 */
export type Sa2Va8bImageInput = {
  /**
   * Prompt
   *
   * Prompt to be used for the chat completion
   */
  prompt: string
  /**
   * Image Url
   *
   * Url for the Input image.
   */
  image_url: string
}

/**
 * ImageChatOutput
 */
export type Sa2Va8bImageOutput = {
  /**
   * Masks
   *
   * Dictionary of label: mask image
   */
  masks: Array<FalAiSa2Va8bImageImage>
  /**
   * Output
   *
   * Generated output
   */
  output: string
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiSa2Va8bImageImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * QueryInput
 */
export type MoondreamNextInput = {
  /**
   * Prompt
   *
   * Prompt for query task
   */
  prompt: string
  /**
   * Task Type
   *
   * Type of task to perform
   */
  task_type?: 'caption' | 'query'
  /**
   * Max Tokens
   *
   * Maximum number of tokens to generate
   */
  max_tokens?: number
  /**
   * Image URL
   *
   * Image URL to be processed
   */
  image_url: string
}

/**
 * MoonDreamOutput
 */
export type MoondreamNextOutput = {
  /**
   * Output
   *
   * Response from the model
   */
  output: string
}

/**
 * ImageWithUserCoordinatesInput
 */
export type Florence2LargeRegionToDescriptionInput = {
  /**
   * Region
   *
   * The user input coordinates
   */
  region: Region
  /**
   * Image Url
   *
   * The URL of the image to be processed.
   */
  image_url: string
}

/**
 * Region
 */
export type Region = {
  /**
   * Y1
   *
   * Y-coordinate of the top-left corner
   */
  y1: number
  /**
   * X2
   *
   * X-coordinate of the bottom-right corner
   */
  x2: number
  /**
   * X1
   *
   * X-coordinate of the top-left corner
   */
  x1: number
  /**
   * Y2
   *
   * Y-coordinate of the bottom-right corner
   */
  y2: number
}

/**
 * TextOutput
 */
export type Florence2LargeRegionToDescriptionOutput = {
  /**
   * Results
   *
   * Results from the model
   */
  results: string
}

/**
 * ImageInput
 */
export type Florence2LargeOcrInput = {
  /**
   * Image Url
   *
   * The URL of the image to be processed.
   */
  image_url: string
}

/**
 * TextOutput
 */
export type Florence2LargeOcrOutput = {
  /**
   * Results
   *
   * Results from the model
   */
  results: string
}

/**
 * ImageInput
 */
export type Florence2LargeMoreDetailedCaptionInput = {
  /**
   * Image Url
   *
   * The URL of the image to be processed.
   */
  image_url: string
}

/**
 * TextOutput
 */
export type Florence2LargeMoreDetailedCaptionOutput = {
  /**
   * Results
   *
   * Results from the model
   */
  results: string
}

/**
 * ImageWithUserCoordinatesInput
 */
export type Florence2LargeRegionToCategoryInput = {
  /**
   * Region
   *
   * The user input coordinates
   */
  region: FalAiFlorence2LargeRegionToCategoryRegion
  /**
   * Image Url
   *
   * The URL of the image to be processed.
   */
  image_url: string
}

/**
 * Region
 */
export type FalAiFlorence2LargeRegionToCategoryRegion = {
  /**
   * Y1
   *
   * Y-coordinate of the top-left corner
   */
  y1: number
  /**
   * X2
   *
   * X-coordinate of the bottom-right corner
   */
  x2: number
  /**
   * X1
   *
   * X-coordinate of the top-left corner
   */
  x1: number
  /**
   * Y2
   *
   * Y-coordinate of the bottom-right corner
   */
  y2: number
}

/**
 * TextOutput
 */
export type Florence2LargeRegionToCategoryOutput = {
  /**
   * Results
   *
   * Results from the model
   */
  results: string
}

/**
 * ImageInput
 */
export type Florence2LargeCaptionInput = {
  /**
   * Image Url
   *
   * The URL of the image to be processed.
   */
  image_url: string
}

/**
 * TextOutput
 */
export type Florence2LargeCaptionOutput = {
  /**
   * Results
   *
   * Results from the model
   */
  results: string
}

/**
 * ImageInput
 */
export type Florence2LargeDetailedCaptionInput = {
  /**
   * Image Url
   *
   * The URL of the image to be processed.
   */
  image_url: string
}

/**
 * TextOutput
 */
export type Florence2LargeDetailedCaptionOutput = {
  /**
   * Results
   *
   * Results from the model
   */
  results: string
}

/**
 * NSFWImageDetectionInput
 */
export type ImageutilsNsfwInput = {
  /**
   * Image Url
   *
   * Input image url.
   */
  image_url: string
}

/**
 * NSFWImageDetectionOutput
 */
export type ImageutilsNsfwOutput = {
  /**
   * Nsfw Probability
   *
   * The probability of the image being NSFW.
   */
  nsfw_probability: number
}

/**
 * BatchedMoondreamInput
 */
export type MoondreamBatchedInput = {
  /**
   * Model ID
   *
   * Model ID to use for inference
   */
  model_id?: 'vikhyatk/moondream2' | 'fal-ai/moondream2-docci'
  /**
   * Repetition Penalty
   *
   * Repetition penalty for sampling
   */
  repetition_penalty?: number
  /**
   * Input prompt & image pairs
   *
   * List of input prompts and image URLs
   */
  inputs: Array<MoondreamInputParam>
  /**
   * Max Tokens
   *
   * Maximum number of new tokens to generate
   */
  max_tokens?: number
  /**
   * Temperature
   *
   * Temperature for sampling
   */
  temperature?: number
  /**
   * Top P
   *
   * Top P for sampling
   */
  top_p?: number
}

/**
 * MoondreamInputParam
 */
export type MoondreamInputParam = {
  /**
   * Prompt
   *
   * Prompt to be used for the image
   */
  prompt?: string
  /**
   * Image URL
   *
   * URL of the image to be processed
   */
  image_url: string
}

/**
 * BatchedMoondreamOutput
 */
export type MoondreamBatchedOutput = {
  /**
   * Filenames
   *
   * Filenames of the images processed
   */
  filenames?: Array<string> | null
  /**
   * Outputs
   *
   * List of generated outputs
   */
  outputs: Array<string>
  /**
   * Partial
   *
   * Whether the output is partial
   */
  partial?: boolean
  /**
   * Timings
   *
   * Timings for different parts of the process
   */
  timings: {
    [key: string]: number
  }
}

/**
 * LLavaInput
 */
export type LlavaNextInput = {
  /**
   * Prompt
   *
   * Prompt to be used for the image
   */
  prompt: string
  /**
   * Top P
   *
   * Top P for sampling
   */
  top_p?: number
  /**
   * Max Tokens
   *
   * Maximum number of tokens to generate
   */
  max_tokens?: number
  /**
   * Temperature
   *
   * Temperature for sampling
   */
  temperature?: number
  /**
   * Image URL
   *
   * URL of the image to be processed
   */
  image_url: string
}

/**
 * LLavaOutput
 */
export type LlavaNextOutput = {
  /**
   * Partial
   *
   * Whether the output is partial
   */
  partial?: boolean
  /**
   * Output
   *
   * Generated output
   */
  output: string
}
