// This file is auto-generated by @hey-api/openapi-ts

import { z } from 'zod'

export const zFile = z.object({
  url: z.url(),
  content_type: z.optional(z.string()),
  file_name: z.optional(z.string()),
  file_size: z.optional(z.int()),
})

export const zQueueStatus = z.object({
  status: z.enum(['IN_PROGRESS', 'COMPLETED', 'FAILED']),
  response_url: z.optional(z.url()),
})

/**
 * SemanticImageInput
 */
export const zSemanticImageInput = z.object({
  hypothesis: z.string().register(z.globalRegistry, {
    description: 'The hypothesis image to use for the measurement.',
  }),
  reference: z.string().register(z.globalRegistry, {
    description: 'The text reference to use for the measurement.',
  }),
})

/**
 * MultiMeasurementOutput
 */
export const zArbiterImageTextOutput = z.object({
  values: z.optional(
    z
      .array(
        z.record(
          z.string(),
          z.union([z.number(), z.record(z.string(), z.number())]),
        ),
      )
      .register(z.globalRegistry, {
        description: 'The values of the measurements.',
      }),
  ),
})

/**
 * ReferenceImageInput
 */
export const zReferenceImageInput = z.object({
  hypothesis: z.string().register(z.globalRegistry, {
    description: 'The hypothesis image to use for the measurement.',
  }),
  reference: z.string().register(z.globalRegistry, {
    description: 'The image to use for the measurement.',
  }),
})

/**
 * MultiMeasurementOutput
 */
export const zArbiterImageImageOutput = z.object({
  values: z.optional(
    z
      .array(
        z.record(
          z.string(),
          z.union([z.number(), z.record(z.string(), z.number())]),
        ),
      )
      .register(z.globalRegistry, {
        description: 'The values of the measurements.',
      }),
  ),
})

/**
 * ImageInput
 */
export const zImageInput = z.object({
  hypothesis: z.string().register(z.globalRegistry, {
    description: 'The image to use for the measurement.',
  }),
})

/**
 * MultiMeasurementOutput
 */
export const zArbiterImageOutput = z.object({
  values: z.optional(
    z
      .array(
        z.record(
          z.string(),
          z.union([z.number(), z.record(z.string(), z.number())]),
        ),
      )
      .register(z.globalRegistry, {
        description: 'The values of the measurements.',
      }),
  ),
})

/**
 * ImageDetectionInput
 */
export const zAiDetectorDetectImageInput = z.object({
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL pointing to an image to analyze for AI generation.(Max: 3000 characters)',
  }),
})

/**
 * AIImageDetectionOutput
 */
export const zAiDetectorDetectImageOutput = z.object({
  latency: z.number(),
  verdict: z.string(),
  is_ai_generated: z.boolean(),
  confidence: z.number(),
})

/**
 * SAM3EmbeddingInput
 */
export const zSam3ImageEmbedInput = z.object({
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to embed.',
  }),
})

/**
 * SAM3EmbeddingOutput
 */
export const zSam3ImageEmbedOutput = z.object({
  embedding_b64: z.string().register(z.globalRegistry, {
    description: 'Embedding of the image',
  }),
})

/**
 * VisionInput
 */
export const zRouterVisionInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Prompt to be used for the image',
  }),
  system_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'System prompt to provide context or instructions to the model',
    }),
  ),
  reasoning: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Should reasoning be the part of the final answer.',
      }),
    )
    .default(false),
  model: z.string().register(z.globalRegistry, {
    description:
      'Name of the model to use. Charged based on actual token usage.',
  }),
  max_tokens: z.optional(
    z.int().gte(1).register(z.globalRegistry, {
      description:
        "This sets the upper limit for the number of tokens the model can generate in response. It won't produce more than this limit. The maximum value is the context length minus the prompt length.",
    }),
  ),
  temperature: z
    .optional(
      z.number().gte(0).lte(2).register(z.globalRegistry, {
        description:
          "This setting influences the variety in the model's responses. Lower values lead to more predictable and typical responses, while higher values encourage more diverse and less common responses. At 0, the model always gives the same response for a given input.",
      }),
    )
    .default(1),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description: 'List of image URLs to be processed',
  }),
})

/**
 * UsageInfo
 */
export const zUsageInfo = z.object({
  prompt_tokens: z.optional(z.int()),
  total_tokens: z.optional(z.int()).default(0),
  completion_tokens: z.optional(z.int()),
  cost: z.number(),
})

/**
 * VisionOutput
 */
export const zRouterVisionOutput = z.object({
  usage: z.optional(zUsageInfo),
  output: z.string().register(z.globalRegistry, {
    description: 'Generated output',
  }),
})

/**
 * MoondreamDetectInput
 */
export const zMoondream3PreviewDetectInput = z.object({
  prompt: z.string().min(1).register(z.globalRegistry, {
    description: 'Object to be detected in the image',
  }),
  preview: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preview the output',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the image to be processed\n\nMax width: 7000px, Max height: 7000px, Timeout: 20.0s',
  }),
})

/**
 * ImageFile
 */
export const zImageFile = z.object({
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Object
 */
export const zObject = z.object({
  y_min: z.number().register(z.globalRegistry, {
    description: 'Top boundary of detection box in normalized format (0 to 1)',
  }),
  x_max: z.number().register(z.globalRegistry, {
    description:
      'Right boundary of detection box in normalized format (0 to 1)',
  }),
  x_min: z.number().register(z.globalRegistry, {
    description: 'Left boundary of detection box in normalized format (0 to 1)',
  }),
  y_max: z.number().register(z.globalRegistry, {
    description:
      'Bottom boundary of detection box in normalized format (0 to 1)',
  }),
})

/**
 * UsageInfo
 */
export const zFalAiMoondream3PreviewDetectUsageInfo = z.object({
  output_tokens: z.int().register(z.globalRegistry, {
    description: 'Number of output tokens generated',
  }),
  decode_time_ms: z.number().register(z.globalRegistry, {
    description: 'Time taken for decoding in milliseconds',
  }),
  input_tokens: z.int().register(z.globalRegistry, {
    description: 'Number of input tokens processed',
  }),
  ttft_ms: z.number().register(z.globalRegistry, {
    description: 'Time to first token in milliseconds',
  }),
  prefill_time_ms: z.number().register(z.globalRegistry, {
    description: 'Time taken for prefill in milliseconds',
  }),
})

/**
 * MoondreamDetectOutput
 */
export const zMoondream3PreviewDetectOutput = z.object({
  finish_reason: z.string().register(z.globalRegistry, {
    description: 'Reason for finishing the output generation',
  }),
  image: z.optional(zImageFile),
  objects: z.array(zObject).register(z.globalRegistry, {
    description: 'List of detected objects with their bounding boxes',
  }),
  usage_info: zFalAiMoondream3PreviewDetectUsageInfo,
})

/**
 * MoondreamPointInput
 */
export const zMoondream3PreviewPointInput = z.object({
  prompt: z.string().min(1).register(z.globalRegistry, {
    description: 'Object to be located in the image',
  }),
  preview: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preview the output',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the image to be processed\n\nMax width: 7000px, Max height: 7000px, Timeout: 20.0s',
  }),
})

/**
 * Point
 */
export const zPoint = z.object({
  y: z.number().register(z.globalRegistry, {
    description: 'Y coordinate of the point in normalized format (0 to 1)',
  }),
  x: z.number().register(z.globalRegistry, {
    description: 'X coordinate of the point in normalized format (0 to 1)',
  }),
})

/**
 * ImageFile
 */
export const zFalAiMoondream3PreviewPointImageFile = z.object({
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * UsageInfo
 */
export const zFalAiMoondream3PreviewPointUsageInfo = z.object({
  output_tokens: z.int().register(z.globalRegistry, {
    description: 'Number of output tokens generated',
  }),
  decode_time_ms: z.number().register(z.globalRegistry, {
    description: 'Time taken for decoding in milliseconds',
  }),
  input_tokens: z.int().register(z.globalRegistry, {
    description: 'Number of input tokens processed',
  }),
  ttft_ms: z.number().register(z.globalRegistry, {
    description: 'Time to first token in milliseconds',
  }),
  prefill_time_ms: z.number().register(z.globalRegistry, {
    description: 'Time taken for prefill in milliseconds',
  }),
})

/**
 * MoondreamPointOutput
 */
export const zMoondream3PreviewPointOutput = z.object({
  points: z.array(zPoint).register(z.globalRegistry, {
    description: 'List of points marking the detected objects',
  }),
  finish_reason: z.string().register(z.globalRegistry, {
    description: 'Reason for finishing the output generation',
  }),
  image: z.optional(zFalAiMoondream3PreviewPointImageFile),
  usage_info: zFalAiMoondream3PreviewPointUsageInfo,
})

/**
 * MoondreamQueryInput
 */
export const zMoondream3PreviewQueryInput = z.object({
  prompt: z.string().min(1).register(z.globalRegistry, {
    description: 'Query to be asked in the image',
  }),
  top_p: z.optional(
    z.number().gte(0).lte(1).register(z.globalRegistry, {
      description: 'Nucleus sampling probability mass to use, between 0 and 1.',
    }),
  ),
  temperature: z.optional(
    z.number().gte(0).lte(1).register(z.globalRegistry, {
      description:
        'Sampling temperature to use, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If not set, defaults to 0.',
    }),
  ),
  reasoning: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to include detailed reasoning behind the answer',
      }),
    )
    .default(true),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the image to be processed\n\nMax width: 7000px, Max height: 7000px, Timeout: 20.0s',
  }),
})

/**
 * UsageInfo
 */
export const zFalAiMoondream3PreviewQueryUsageInfo = z.object({
  output_tokens: z.int().register(z.globalRegistry, {
    description: 'Number of output tokens generated',
  }),
  decode_time_ms: z.number().register(z.globalRegistry, {
    description: 'Time taken for decoding in milliseconds',
  }),
  input_tokens: z.int().register(z.globalRegistry, {
    description: 'Number of input tokens processed',
  }),
  ttft_ms: z.number().register(z.globalRegistry, {
    description: 'Time to first token in milliseconds',
  }),
  prefill_time_ms: z.number().register(z.globalRegistry, {
    description: 'Time taken for prefill in milliseconds',
  }),
})

/**
 * MoondreamQueryOutput
 */
export const zMoondream3PreviewQueryOutput = z.object({
  finish_reason: z.string().register(z.globalRegistry, {
    description: 'Reason for finishing the output generation',
  }),
  reasoning: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'Detailed reasoning behind the answer, if enabled',
    }),
  ),
  output: z.string().register(z.globalRegistry, {
    description: 'Answer to the query about the image',
  }),
  usage_info: zFalAiMoondream3PreviewQueryUsageInfo,
})

/**
 * MoondreamCaptionInput
 */
export const zMoondream3PreviewCaptionInput = z.object({
  top_p: z.optional(
    z.number().gte(0).lte(1).register(z.globalRegistry, {
      description: 'Nucleus sampling probability mass to use, between 0 and 1.',
    }),
  ),
  length: z.optional(
    z.enum(['short', 'normal', 'long']).register(z.globalRegistry, {
      description: 'Length of the caption to generate',
    }),
  ),
  temperature: z.optional(
    z.number().gte(0).lte(1).register(z.globalRegistry, {
      description:
        'Sampling temperature to use, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If not set, defaults to 0.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the image to be processed\n\nMax width: 7000px, Max height: 7000px, Timeout: 20.0s',
  }),
})

/**
 * UsageInfo
 */
export const zFalAiMoondream3PreviewCaptionUsageInfo = z.object({
  output_tokens: z.int().register(z.globalRegistry, {
    description: 'Number of output tokens generated',
  }),
  decode_time_ms: z.number().register(z.globalRegistry, {
    description: 'Time taken for decoding in milliseconds',
  }),
  input_tokens: z.int().register(z.globalRegistry, {
    description: 'Number of input tokens processed',
  }),
  ttft_ms: z.number().register(z.globalRegistry, {
    description: 'Time to first token in milliseconds',
  }),
  prefill_time_ms: z.number().register(z.globalRegistry, {
    description: 'Time taken for prefill in milliseconds',
  }),
})

/**
 * MoondreamCaptionOutput
 */
export const zMoondream3PreviewCaptionOutput = z.object({
  finish_reason: z.string().register(z.globalRegistry, {
    description: 'Reason for finishing the output generation',
  }),
  output: z.string().register(z.globalRegistry, {
    description: 'Generated caption for the image',
  }),
  usage_info: zFalAiMoondream3PreviewCaptionUsageInfo,
})

export const zIsaac01OpenaiV1ChatCompletionsOutput = z.unknown()

/**
 * VisionInput
 */
export const zIsaac01Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Prompt to be used for the image',
  }),
  response_style: z.optional(
    z.enum(['text', 'box', 'point', 'polygon']).register(z.globalRegistry, {
      description:
        '\nResponse style to be used for the image.\n\n- text: Model will output text. Good for descriptions and captioning.\n- box: Model will output a combination of text and bounding boxes. Good for\nlocalization.\n- point: Model will output a combination of text and points. Good for counting many\nobjects.\n- polygon: Model will output a combination of text and polygons. Good for granular\nsegmentation.\n',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Image URL to be processed',
  }),
})

/**
 * CompletionUsage
 */
export const zCompletionUsage = z.object({
  completion_tokens: z.int().register(z.globalRegistry, {
    description: 'Number of tokens in the completion',
  }),
  total_tokens: z.int().register(z.globalRegistry, {
    description: 'Total tokens used',
  }),
  prompt_tokens: z.int().register(z.globalRegistry, {
    description: 'Number of tokens in the prompt',
  }),
})

/**
 * ChatOutput
 */
export const zIsaac01Output = z.object({
  usage: z.optional(z.union([zCompletionUsage, z.unknown()])),
  error: z.optional(z.union([z.string(), z.unknown()])),
  partial: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the output is partial',
      }),
    )
    .default(false),
  output: z.string().register(z.globalRegistry, {
    description: 'Generated output',
  }),
})

/**
 * NSFWInput
 */
export const zXAilabNsfwInput = z.object({
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'List of image URLs to check. If more than 10 images are provided, only the first 10 will be checked.',
  }),
})

/**
 * NSFWOutput
 */
export const zXAilabNsfwOutput = z.object({
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'List of booleans indicating if the image has an NSFW concept',
  }),
})

/**
 * VideoUnderstandingInput
 */
export const zVideoUnderstandingInput = z.object({
  detailed_analysis: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to request a more detailed analysis of the video',
      }),
    )
    .default(false),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the video to analyze',
  }),
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: 'The question or prompt about the video content.',
  }),
})

/**
 * VideoUnderstandingOutput
 */
export const zVideoUnderstandingOutput = z.object({
  output: z.string().register(z.globalRegistry, {
    description: 'The analysis of the video content based on the prompt',
  }),
})

/**
 * MoondreamQueryInput
 */
export const zMoondream2VisualQueryInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Query to be asked in the image',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to be processed',
  }),
})

/**
 * MoondreamOutput
 */
export const zMoondream2VisualQueryOutput = z.object({
  output: z.string().register(z.globalRegistry, {
    description: 'Output for the given query',
  }),
})

/**
 * MoondreamInput
 */
export const zMoondream2Input = z.object({
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to be processed',
  }),
})

/**
 * MoondreamOutput
 */
export const zMoondream2Output = z.object({
  output: z.string().register(z.globalRegistry, {
    description: 'Output for the given query',
  }),
})

/**
 * MoondreamObjectInput
 */
export const zMoondream2PointObjectDetectionInput = z.object({
  object: z.string().register(z.globalRegistry, {
    description: 'Object to be detected in the image',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to be processed',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * MoondreamObjectOutput
 */
export const zMoondream2PointObjectDetectionOutput = z.object({
  image: zImage,
  objects: z
    .array(z.record(z.string(), z.unknown()))
    .register(z.globalRegistry, {
      description: 'Objects detected in the image',
    }),
})

/**
 * MoondreamObjectInput
 */
export const zMoondream2ObjectDetectionInput = z.object({
  object: z.string().register(z.globalRegistry, {
    description: 'Object to be detected in the image',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to be processed',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiMoondream2ObjectDetectionImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * MoondreamObjectOutput
 */
export const zMoondream2ObjectDetectionOutput = z.object({
  image: zFalAiMoondream2ObjectDetectionImage,
  objects: z
    .array(z.record(z.string(), z.unknown()))
    .register(z.globalRegistry, {
      description: 'Objects detected in the image',
    }),
})

/**
 * ImageInput
 */
export const zGotOcrV2Input = z.object({
  do_format: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Generate the output in formatted mode.',
      }),
    )
    .default(false),
  multi_page: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Use provided images to generate a single output.',
      }),
    )
    .default(false),
  input_image_urls: z
    .optional(
      z.array(z.string()).register(z.globalRegistry, {
        description: 'URL of images.',
      }),
    )
    .default([]),
})

/**
 * ImageChatOutput
 */
export const zGotOcrV2Output = z.object({
  outputs: z.array(z.string()).register(z.globalRegistry, {
    description: 'Generated output',
  }),
})

/**
 * BatchQueryInput
 */
export const zMoondreamNextBatchInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Single prompt to apply to all images',
  }),
  images_data_url: z.string().register(z.globalRegistry, {
    description: 'List of image URLs to be processed (maximum 32 images)',
  }),
  max_tokens: z
    .optional(
      z.int().gte(1).lte(512).register(z.globalRegistry, {
        description: 'Maximum number of tokens to generate',
      }),
    )
    .default(64),
})

/**
 * File
 */
export const zFalAiMoondreamNextBatchFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * BatchMoonDreamOutput
 */
export const zMoondreamNextBatchOutput = z.object({
  outputs: z.array(z.string()).register(z.globalRegistry, {
    description: 'List of generated captions',
  }),
  captions_file: zFalAiMoondreamNextBatchFile,
})

/**
 * VideoInput
 */
export const zSa2Va8bVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Prompt to be used for the chat completion',
  }),
  video_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the input video.',
  }),
  num_frames_to_sample: z.optional(
    z.int().gte(1).lte(100).register(z.globalRegistry, {
      description:
        'Number of frames to sample from the video. If not provided, all frames are sampled.',
    }),
  ),
})

/**
 * File
 */
export const zFalAiSa2Va8bVideoFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * VideoChatOutput
 */
export const zSa2Va8bVideoOutput = z.object({
  masks: z.array(zFalAiSa2Va8bVideoFile).register(z.globalRegistry, {
    description: 'Dictionary of label: mask video',
  }),
  output: z.string().register(z.globalRegistry, {
    description: 'Generated output',
  }),
})

/**
 * VideoInput
 */
export const zSa2Va4bVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Prompt to be used for the chat completion',
  }),
  video_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the input video.',
  }),
  num_frames_to_sample: z.optional(
    z.int().gte(1).lte(100).register(z.globalRegistry, {
      description:
        'Number of frames to sample from the video. If not provided, all frames are sampled.',
    }),
  ),
})

/**
 * File
 */
export const zFalAiSa2Va4bVideoFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * VideoChatOutput
 */
export const zSa2Va4bVideoOutput = z.object({
  masks: z.array(zFalAiSa2Va4bVideoFile).register(z.globalRegistry, {
    description: 'Dictionary of label: mask video',
  }),
  output: z.string().register(z.globalRegistry, {
    description: 'Generated output',
  }),
})

/**
 * ImageInput
 */
export const zSa2Va4bImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Prompt to be used for the chat completion',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Url for the Input image.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiSa2Va4bImageImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ImageChatOutput
 */
export const zSa2Va4bImageOutput = z.object({
  masks: z.array(zFalAiSa2Va4bImageImage).register(z.globalRegistry, {
    description: 'Dictionary of label: mask image',
  }),
  output: z.string().register(z.globalRegistry, {
    description: 'Generated output',
  }),
})

/**
 * ImageInput
 */
export const zSa2Va8bImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Prompt to be used for the chat completion',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Url for the Input image.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiSa2Va8bImageImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ImageChatOutput
 */
export const zSa2Va8bImageOutput = z.object({
  masks: z.array(zFalAiSa2Va8bImageImage).register(z.globalRegistry, {
    description: 'Dictionary of label: mask image',
  }),
  output: z.string().register(z.globalRegistry, {
    description: 'Generated output',
  }),
})

/**
 * QueryInput
 */
export const zMoondreamNextInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Prompt for query task',
  }),
  task_type: z.optional(
    z.enum(['caption', 'query']).register(z.globalRegistry, {
      description: 'Type of task to perform',
    }),
  ),
  max_tokens: z
    .optional(
      z.int().gte(1).lte(512).register(z.globalRegistry, {
        description: 'Maximum number of tokens to generate',
      }),
    )
    .default(64),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Image URL to be processed',
  }),
})

/**
 * MoonDreamOutput
 */
export const zMoondreamNextOutput = z.object({
  output: z.string().register(z.globalRegistry, {
    description: 'Response from the model',
  }),
})

/**
 * Region
 */
export const zRegion = z.object({
  y1: z.int().gte(0).lte(999).register(z.globalRegistry, {
    description: 'Y-coordinate of the top-left corner',
  }),
  x2: z.int().gte(0).lte(999).register(z.globalRegistry, {
    description: 'X-coordinate of the bottom-right corner',
  }),
  x1: z.int().gte(0).lte(999).register(z.globalRegistry, {
    description: 'X-coordinate of the top-left corner',
  }),
  y2: z.int().gte(0).lte(999).register(z.globalRegistry, {
    description: 'Y-coordinate of the bottom-right corner',
  }),
})

/**
 * ImageWithUserCoordinatesInput
 */
export const zFlorence2LargeRegionToDescriptionInput = z.object({
  region: zRegion,
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to be processed.',
  }),
})

/**
 * TextOutput
 */
export const zFlorence2LargeRegionToDescriptionOutput = z.object({
  results: z.string().register(z.globalRegistry, {
    description: 'Results from the model',
  }),
})

/**
 * ImageInput
 */
export const zFlorence2LargeOcrInput = z.object({
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to be processed.',
  }),
})

/**
 * TextOutput
 */
export const zFlorence2LargeOcrOutput = z.object({
  results: z.string().register(z.globalRegistry, {
    description: 'Results from the model',
  }),
})

/**
 * ImageInput
 */
export const zFlorence2LargeMoreDetailedCaptionInput = z.object({
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to be processed.',
  }),
})

/**
 * TextOutput
 */
export const zFlorence2LargeMoreDetailedCaptionOutput = z.object({
  results: z.string().register(z.globalRegistry, {
    description: 'Results from the model',
  }),
})

/**
 * Region
 */
export const zFalAiFlorence2LargeRegionToCategoryRegion = z.object({
  y1: z.int().gte(0).lte(999).register(z.globalRegistry, {
    description: 'Y-coordinate of the top-left corner',
  }),
  x2: z.int().gte(0).lte(999).register(z.globalRegistry, {
    description: 'X-coordinate of the bottom-right corner',
  }),
  x1: z.int().gte(0).lte(999).register(z.globalRegistry, {
    description: 'X-coordinate of the top-left corner',
  }),
  y2: z.int().gte(0).lte(999).register(z.globalRegistry, {
    description: 'Y-coordinate of the bottom-right corner',
  }),
})

/**
 * ImageWithUserCoordinatesInput
 */
export const zFlorence2LargeRegionToCategoryInput = z.object({
  region: zFalAiFlorence2LargeRegionToCategoryRegion,
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to be processed.',
  }),
})

/**
 * TextOutput
 */
export const zFlorence2LargeRegionToCategoryOutput = z.object({
  results: z.string().register(z.globalRegistry, {
    description: 'Results from the model',
  }),
})

/**
 * ImageInput
 */
export const zFlorence2LargeCaptionInput = z.object({
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to be processed.',
  }),
})

/**
 * TextOutput
 */
export const zFlorence2LargeCaptionOutput = z.object({
  results: z.string().register(z.globalRegistry, {
    description: 'Results from the model',
  }),
})

/**
 * ImageInput
 */
export const zFlorence2LargeDetailedCaptionInput = z.object({
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to be processed.',
  }),
})

/**
 * TextOutput
 */
export const zFlorence2LargeDetailedCaptionOutput = z.object({
  results: z.string().register(z.globalRegistry, {
    description: 'Results from the model',
  }),
})

/**
 * NSFWImageDetectionInput
 */
export const zImageutilsNsfwInput = z.object({
  image_url: z.string().register(z.globalRegistry, {
    description: 'Input image url.',
  }),
})

/**
 * NSFWImageDetectionOutput
 */
export const zImageutilsNsfwOutput = z.object({
  nsfw_probability: z.number().register(z.globalRegistry, {
    description: 'The probability of the image being NSFW.',
  }),
})

/**
 * MoondreamInputParam
 */
export const zMoondreamInputParam = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Prompt to be used for the image',
      }),
    )
    .default('Describe this image.'),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to be processed',
  }),
})

/**
 * BatchedMoondreamInput
 */
export const zMoondreamBatchedInput = z.object({
  model_id: z.optional(
    z
      .enum(['vikhyatk/moondream2', 'fal-ai/moondream2-docci'])
      .register(z.globalRegistry, {
        description: 'Model ID to use for inference',
      }),
  ),
  repetition_penalty: z
    .optional(
      z.number().gte(1).lte(2).register(z.globalRegistry, {
        description: 'Repetition penalty for sampling',
      }),
    )
    .default(1),
  inputs: z.array(zMoondreamInputParam).register(z.globalRegistry, {
    description: 'List of input prompts and image URLs',
  }),
  max_tokens: z
    .optional(
      z.int().gte(32).lte(1024).register(z.globalRegistry, {
        description: 'Maximum number of new tokens to generate',
      }),
    )
    .default(64),
  temperature: z
    .optional(
      z.number().lte(1).register(z.globalRegistry, {
        description: 'Temperature for sampling',
      }),
    )
    .default(0.2),
  top_p: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Top P for sampling',
      }),
    )
    .default(1),
})

/**
 * BatchedMoondreamOutput
 */
export const zMoondreamBatchedOutput = z.object({
  filenames: z.optional(z.union([z.array(z.string()), z.null()])),
  outputs: z.array(z.string()).register(z.globalRegistry, {
    description: 'List of generated outputs',
  }),
  partial: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the output is partial',
      }),
    )
    .default(false),
  timings: z.record(z.string(), z.number()).register(z.globalRegistry, {
    description: 'Timings for different parts of the process',
  }),
})

/**
 * LLavaInput
 */
export const zLlavaNextInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Prompt to be used for the image',
  }),
  top_p: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Top P for sampling',
      }),
    )
    .default(1),
  max_tokens: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Maximum number of tokens to generate',
      }),
    )
    .default(64),
  temperature: z
    .optional(
      z.number().lte(1).register(z.globalRegistry, {
        description: 'Temperature for sampling',
      }),
    )
    .default(0.2),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to be processed',
  }),
})

/**
 * LLavaOutput
 */
export const zLlavaNextOutput = z.object({
  partial: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the output is partial',
      }),
    )
    .default(false),
  output: z.string().register(z.globalRegistry, {
    description: 'Generated output',
  }),
})
