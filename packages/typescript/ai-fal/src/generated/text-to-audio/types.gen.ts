// This file is auto-generated by @hey-api/openapi-ts

export type ClientOptions = {
  baseUrl: 'https://queue.fal.run' | (string & {})
}

/**
 * Output
 */
export type SchemaStableAudioOutput = {
  audio_file: SchemaFile
}

/**
 * File
 */
export type SchemaFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * Input
 */
export type SchemaStableAudioInput = {
  /**
   * Prompt
   *
   * The prompt to generate audio from
   */
  prompt: string
  /**
   * Steps
   *
   * The number of steps to denoise the audio for
   */
  steps?: number
  /**
   * Seconds Total
   *
   * The duration of the audio clip to generate
   */
  seconds_total?: number
  /**
   * Seconds Start
   *
   * The start point of the audio clip to generate
   */
  seconds_start?: number
}

/**
 * AudioFile
 */
export type SchemaAudioFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   */
  file_name?: string
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
}

/**
 * TTSOutput
 */
export type SchemaF5TtsOutput = {
  audio_url: SchemaAudioFile
}

/**
 * TTSInput
 */
export type SchemaF5TtsInput = {
  /**
   * Reference Text for the Reference Audio
   *
   * The reference text to be used for TTS. If not provided, an ASR (Automatic Speech Recognition) model will be used to generate the reference text.
   */
  ref_text?: string
  /**
   * Remove Silence
   *
   * Whether to remove the silence from the audio file.
   */
  remove_silence?: boolean
  /**
   * Text to be converted to speech
   *
   * The text to be converted to speech.
   */
  gen_text: string
  /**
   * Model Type
   *
   * The name of the model to be used for TTS.
   */
  model_type: 'F5-TTS' | 'E2-TTS'
  /**
   * Reference Audio URL
   *
   * The URL of the reference audio file.
   */
  ref_audio_url: string
}

/**
 * MusicOutput
 */
export type SchemaMinimaxMusicOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: SchemaFile
}

/**
 * TextToMusicRequest
 */
export type SchemaMinimaxMusicInput = {
  /**
   * Prompt
   *
   * Lyrics with optional formatting. You can use a newline to separate each line of lyrics. You can use two newlines to add a pause between lines. You can use double hash marks (##) at the beginning and end of the lyrics to add accompaniment. Maximum 600 characters.
   */
  prompt: string
  /**
   * Reference Audio Url
   *
   * Reference song, should contain music and vocals. Must be a .wav or .mp3 file longer than 15 seconds.
   */
  reference_audio_url: string
}

/**
 * AudioOutput
 */
export type SchemaMmaudioV2TextToAudioOutput = {
  /**
   * Audio
   *
   * The generated audio.
   */
  audio: SchemaFile
}

/**
 * AudioInput
 */
export type SchemaMmaudioV2TextToAudioInput = {
  /**
   * Prompt
   *
   * The prompt to generate the audio for.
   */
  prompt: string
  /**
   * Num Steps
   *
   * The number of steps to generate the audio for.
   */
  num_steps?: number
  /**
   * Duration
   *
   * The duration of the audio to generate.
   */
  duration?: number
  /**
   * Cfg Strength
   *
   * The strength of Classifier Free Guidance.
   */
  cfg_strength?: number
  /**
   * Seed
   *
   * The seed for the random number generator
   */
  seed?: number
  /**
   * Mask Away Clip
   *
   * Whether to mask away the clip.
   */
  mask_away_clip?: boolean
  /**
   * Negative Prompt
   *
   * The negative prompt to generate the audio for.
   */
  negative_prompt?: string
}

/**
 * Output
 */
export type SchemaYueOutput = {
  /**
   * Audio
   *
   * Generated music file.
   */
  audio: SchemaFile
}

/**
 * TextToMusicInput
 */
export type SchemaYueInput = {
  /**
   * Lyrics
   *
   * The prompt to generate an image from. Must have two sections. Sections start with either [chorus] or a [verse].
   */
  lyrics: string
  /**
   * Genres
   *
   * The genres (separated by a space ' ') to guide the music generation.
   */
  genres: string
}

/**
 * ItalianOutput
 */
export type SchemaKokoroItalianOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: SchemaFile
}

/**
 * ItalianRequest
 */
export type SchemaKokoroItalianInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice: 'if_sara' | 'im_nicola'
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number
}

/**
 * ZonosOutput
 */
export type SchemaZonosOutput = {
  /**
   * Audio
   *
   * The generated audio
   */
  audio: SchemaFile
}

/**
 * ZonosInput
 */
export type SchemaZonosInput = {
  /**
   * Prompt
   *
   * The content generated using cloned voice.
   */
  prompt: string
  /**
   * Reference Audio Url
   *
   * The reference audio.
   */
  reference_audio_url: string
}

/**
 * AmEngOutput
 */
export type SchemaKokoroAmericanEnglishOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: SchemaFile
}

/**
 * AmEnglishRequest
 */
export type SchemaKokoroAmericanEnglishInput = {
  /**
   * Prompt
   */
  prompt?: string
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice?:
    | 'af_heart'
    | 'af_alloy'
    | 'af_aoede'
    | 'af_bella'
    | 'af_jessica'
    | 'af_kore'
    | 'af_nicole'
    | 'af_nova'
    | 'af_river'
    | 'af_sarah'
    | 'af_sky'
    | 'am_adam'
    | 'am_echo'
    | 'am_eric'
    | 'am_fenrir'
    | 'am_liam'
    | 'am_michael'
    | 'am_onyx'
    | 'am_puck'
    | 'am_santa'
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number
}

/**
 * JapaneseOutput
 */
export type SchemaKokoroJapaneseOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: SchemaFile
}

/**
 * JapaneseRequest
 */
export type SchemaKokoroJapaneseInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice: 'jf_alpha' | 'jf_gongitsune' | 'jf_nezumi' | 'jf_tebukuro' | 'jm_kumo'
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number
}

/**
 * FrenchOutput
 */
export type SchemaKokoroFrenchOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: SchemaFile
}

/**
 * FrenchRequest
 */
export type SchemaKokoroFrenchInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice: 'ff_siwis'
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number
}

/**
 * BrEngOutput
 */
export type SchemaKokoroBritishEnglishOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: SchemaFile
}

/**
 * BrEnglishRequest
 */
export type SchemaKokoroBritishEnglishInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice:
    | 'bf_alice'
    | 'bf_emma'
    | 'bf_isabella'
    | 'bf_lily'
    | 'bm_daniel'
    | 'bm_fable'
    | 'bm_george'
    | 'bm_lewis'
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number
}

/**
 * BrPortugeseOutput
 */
export type SchemaKokoroBrazilianPortugueseOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: SchemaFile
}

/**
 * BrPortugueseRequest
 */
export type SchemaKokoroBrazilianPortugueseInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice: 'pf_dora' | 'pm_alex' | 'pm_santa'
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number
}

/**
 * SpanishOutput
 */
export type SchemaKokoroSpanishOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: SchemaFile
}

/**
 * SpanishRequest
 */
export type SchemaKokoroSpanishInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice: 'ef_dora' | 'em_alex' | 'em_santa'
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number
}

/**
 * MandarinOutput
 */
export type SchemaKokoroMandarinChineseOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: SchemaFile
}

/**
 * MandarinRequest
 */
export type SchemaKokoroMandarinChineseInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice:
    | 'zf_xiaobei'
    | 'zf_xiaoni'
    | 'zf_xiaoxiao'
    | 'zf_xiaoyi'
    | 'zm_yunjian'
    | 'zm_yunxi'
    | 'zm_yunxia'
    | 'zm_yunyang'
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number
}

/**
 * HindiOutput
 */
export type SchemaKokoroHindiOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: SchemaFile
}

/**
 * HindiRequest
 */
export type SchemaKokoroHindiInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice: 'hf_alpha' | 'hf_beta' | 'hm_omega' | 'hm_psi'
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number
}

/**
 * TTSOutput
 */
export type SchemaElevenlabsTtsMultilingualV2Output = {
  audio: SchemaFile
  /**
   * Timestamps
   *
   * Timestamps for each word in the generated speech. Only returned if `timestamps` is set to True in the request.
   */
  timestamps?: Array<unknown> | unknown
}

/**
 * TextToSpeechRequest
 */
export type SchemaElevenlabsTtsMultilingualV2Input = {
  /**
   * Stability
   *
   * Voice stability (0-1)
   */
  stability?: number
  /**
   * Next Text
   *
   * The text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.
   */
  next_text?: string | unknown
  /**
   * Speed
   *
   * Speech speed (0.7-1.2). Values below 1.0 slow down the speech, above 1.0 speed it up. Extreme values may affect quality.
   */
  speed?: number
  /**
   * Style
   *
   * Style exaggeration (0-1)
   */
  style?: number
  /**
   * Text
   *
   * The text to convert to speech
   */
  text: string
  /**
   * Timestamps
   *
   * Whether to return timestamps for each word in the generated speech
   */
  timestamps?: boolean
  /**
   * Similarity Boost
   *
   * Similarity boost (0-1)
   */
  similarity_boost?: number
  /**
   * Voice
   *
   * The voice to use for speech generation
   */
  voice?: string
  /**
   * Language Code
   *
   * Language code (ISO 639-1) used to enforce a language for the model. An error will be returned if language code is not supported by the model.
   */
  language_code?: string | unknown
  /**
   * Previous Text
   *
   * The text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.
   */
  previous_text?: string | unknown
}

/**
 * Output
 */
export type SchemaDiffrhythmOutput = {
  /**
   * Audio
   *
   * Generated music file.
   */
  audio: SchemaFile
}

/**
 * TextToMusicInput
 */
export type SchemaDiffrhythmInput = {
  /**
   * Lyrics
   *
   * The prompt to generate the song from. Must have two sections. Sections start with either [chorus] or a [verse].
   */
  lyrics: string
  /**
   * CFG Strength
   *
   * The CFG strength to use for the music generation.
   */
  cfg_strength?: number
  /**
   * Reference Audio URL
   *
   * The URL of the reference audio to use for the music generation.
   */
  reference_audio_url?: string
  /**
   * Music Duration
   *
   * The duration of the music to generate.
   */
  music_duration?: '95s' | '285s'
  /**
   * Scheduler
   *
   * The scheduler to use for the music generation.
   */
  scheduler?: 'euler' | 'midpoint' | 'rk4' | 'implicit_adams'
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use for the music generation.
   */
  num_inference_steps?: number
  /**
   * Style Prompt
   *
   * The style prompt to use for the music generation.
   */
  style_prompt?: string
}

/**
 * Speaker
 */
export type SchemaSpeaker = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Audio Url
   */
  audio_url: string
  /**
   * Speaker Id
   */
  speaker_id: number
}

/**
 * Turn
 */
export type SchemaTurn = {
  /**
   * Text
   */
  text: string
  /**
   * Speaker Id
   */
  speaker_id: number
}

/**
 * Output
 */
export type SchemaCsm1bOutput = {
  /**
   * Audio
   *
   * The generated audio.
   */
  audio: SchemaFile | Blob | File
}

/**
 * Input
 */
export type SchemaCsm1bInput = {
  /**
   * Scene
   *
   * The text to generate an audio from.
   */
  scene: Array<SchemaTurn>
  /**
   * Context
   *
   * The context to generate an audio from.
   */
  context?: Array<SchemaSpeaker>
}

/**
 * AudioOutput
 *
 * Example Pydantic model showing how to include a File in the output.
 */
export type SchemaMusicGeneratorOutput = {
  audio_file: SchemaFile
}

/**
 * Input
 */
export type SchemaMusicGeneratorInput = {
  /**
   * Prompt
   *
   * The prompt to generate music from.
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated music in seconds.
   */
  duration: number
}

/**
 * AudioOutput
 *
 * Example Pydantic model showing how to include a File in the output.
 */
export type SchemaSoundEffectsGeneratorOutput = {
  audio_file: SchemaFile
}

/**
 * Input
 */
export type SchemaSoundEffectsGeneratorInput = {
  /**
   * Prompt
   *
   * The prompt to generate SFX.
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated SFX in seconds.
   */
  duration: number
}

/**
 * ACEStepResponse
 */
export type SchemaAceStepOutput = {
  /**
   * Tags
   *
   * The genre tags used in the generation process.
   */
  tags: string
  /**
   * Lyrics
   *
   * The lyrics used in the generation process.
   */
  lyrics: string
  /**
   * Seed
   *
   * The random seed used for the generation process.
   */
  seed: number
  /**
   * Audio
   *
   * The generated audio file.
   */
  audio: SchemaFile
}

/**
 * ACEStepTextToAudioRequest
 */
export type SchemaAceStepInput = {
  /**
   * Number Of Steps
   *
   * Number of steps to generate the audio.
   */
  number_of_steps?: number
  /**
   * Duration
   *
   * The duration of the generated audio in seconds.
   */
  duration?: number
  /**
   * Tags
   *
   * Comma-separated list of genre tags to control the style of the generated audio.
   */
  tags: string
  /**
   * Minimum Guidance Scale
   *
   * Minimum guidance scale for the generation after the decay.
   */
  minimum_guidance_scale?: number
  /**
   * Lyrics
   *
   * Lyrics to be sung in the audio. If not provided or if [inst] or [instrumental] is the content of this field, no lyrics will be sung. Use control structures like [verse], [chorus] and [bridge] to control the structure of the song.
   */
  lyrics?: string
  /**
   * Tag Guidance Scale
   *
   * Tag guidance scale for the generation.
   */
  tag_guidance_scale?: number
  /**
   * Scheduler
   *
   * Scheduler to use for the generation process.
   */
  scheduler?: 'euler' | 'heun'
  /**
   * Guidance Scale
   *
   * Guidance scale for the generation.
   */
  guidance_scale?: number
  /**
   * Guidance Type
   *
   * Type of CFG to use for the generation process.
   */
  guidance_type?: 'cfg' | 'apg' | 'cfg_star'
  /**
   * Lyric Guidance Scale
   *
   * Lyric guidance scale for the generation.
   */
  lyric_guidance_scale?: number
  /**
   * Guidance Interval
   *
   * Guidance interval for the generation. 0.5 means only apply guidance in the middle steps (0.25 * infer_steps to 0.75 * infer_steps)
   */
  guidance_interval?: number
  /**
   * Guidance Interval Decay
   *
   * Guidance interval decay for the generation. Guidance scale will decay from guidance_scale to min_guidance_scale in the interval. 0.0 means no decay.
   */
  guidance_interval_decay?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. If not provided, a random seed will be used.
   */
  seed?: number
  /**
   * Granularity Scale
   *
   * Granularity scale for the generation process. Higher values can reduce artifacts.
   */
  granularity_scale?: number
}

/**
 * ACEStepResponse
 */
export type SchemaAceStepPromptToAudioOutput = {
  /**
   * Tags
   *
   * The genre tags used in the generation process.
   */
  tags: string
  /**
   * Lyrics
   *
   * The lyrics used in the generation process.
   */
  lyrics: string
  /**
   * Seed
   *
   * The random seed used for the generation process.
   */
  seed: number
  /**
   * Audio
   *
   * The generated audio file.
   */
  audio: SchemaFile
}

/**
 * ACEStepPromptToAudioRequest
 */
export type SchemaAceStepPromptToAudioInput = {
  /**
   * Number Of Steps
   *
   * Number of steps to generate the audio.
   */
  number_of_steps?: number
  /**
   * Duration
   *
   * The duration of the generated audio in seconds.
   */
  duration?: number
  /**
   * Prompt
   *
   * Prompt to control the style of the generated audio. This will be used to generate tags and lyrics.
   */
  prompt: string
  /**
   * Minimum Guidance Scale
   *
   * Minimum guidance scale for the generation after the decay.
   */
  minimum_guidance_scale?: number
  /**
   * Tag Guidance Scale
   *
   * Tag guidance scale for the generation.
   */
  tag_guidance_scale?: number
  /**
   * Scheduler
   *
   * Scheduler to use for the generation process.
   */
  scheduler?: 'euler' | 'heun'
  /**
   * Guidance Scale
   *
   * Guidance scale for the generation.
   */
  guidance_scale?: number
  /**
   * Guidance Type
   *
   * Type of CFG to use for the generation process.
   */
  guidance_type?: 'cfg' | 'apg' | 'cfg_star'
  /**
   * Instrumental
   *
   * Whether to generate an instrumental version of the audio.
   */
  instrumental?: boolean
  /**
   * Lyric Guidance Scale
   *
   * Lyric guidance scale for the generation.
   */
  lyric_guidance_scale?: number
  /**
   * Guidance Interval
   *
   * Guidance interval for the generation. 0.5 means only apply guidance in the middle steps (0.25 * infer_steps to 0.75 * infer_steps)
   */
  guidance_interval?: number
  /**
   * Guidance Interval Decay
   *
   * Guidance interval decay for the generation. Guidance scale will decay from guidance_scale to min_guidance_scale in the interval. 0.0 means no decay.
   */
  guidance_interval_decay?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. If not provided, a random seed will be used.
   */
  seed?: number
  /**
   * Granularity Scale
   *
   * Granularity scale for the generation process. Higher values can reduce artifacts.
   */
  granularity_scale?: number
}

/**
 * TextToMusicOutput
 */
export type SchemaLyria2Output = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: SchemaFile
}

/**
 * TextToMusicInput
 */
export type SchemaLyria2Input = {
  /**
   * Prompt
   *
   * The text prompt describing the music you want to generate
   */
  prompt: string
  /**
   * Seed
   *
   * A seed for deterministic generation. If provided, the model will attempt to produce the same audio given the same prompt and other parameters.
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A description of what to exclude from the generated audio
   */
  negative_prompt?: string
}

/**
 * TTSOutput
 */
export type SchemaElevenlabsTtsElevenV3Output = {
  audio: SchemaFile
  /**
   * Timestamps
   *
   * Timestamps for each word in the generated speech. Only returned if `timestamps` is set to True in the request.
   */
  timestamps?: Array<unknown> | unknown
}

/**
 * TextToSpeechRequestV3
 *
 * Request model for eleven_v3 which doesn't support previous_text/next_text
 */
export type SchemaElevenlabsTtsElevenV3Input = {
  /**
   * Stability
   *
   * Voice stability (0-1)
   */
  stability?: number
  /**
   * Speed
   *
   * Speech speed (0.7-1.2). Values below 1.0 slow down the speech, above 1.0 speed it up. Extreme values may affect quality.
   */
  speed?: number
  /**
   * Text
   *
   * The text to convert to speech
   */
  text: string
  /**
   * Style
   *
   * Style exaggeration (0-1)
   */
  style?: number
  /**
   * Timestamps
   *
   * Whether to return timestamps for each word in the generated speech
   */
  timestamps?: boolean
  /**
   * Similarity Boost
   *
   * Similarity boost (0-1)
   */
  similarity_boost?: number
  /**
   * Voice
   *
   * The voice to use for speech generation
   */
  voice?: string
  /**
   * Language Code
   *
   * Language code (ISO 639-1) used to enforce a language for the model.
   */
  language_code?: string | unknown
}

/**
 * GenerateOutput
 */
export type SchemaV2TextToMusicOutput = {
  /**
   * Tags
   *
   * The style tags used for generation.
   */
  tags?: Array<string> | unknown
  /**
   * Seed
   *
   * The seed used for generation. This can be used to generate an identical song by passing the same parameters with this seed in a future request.
   */
  seed: number
  /**
   * Lyrics
   *
   * The lyrics used for generation.
   */
  lyrics?: string | unknown
  /**
   * Audio
   *
   * The generated audio files.
   */
  audio: Array<SchemaFile>
}

/**
 * GenerateInput
 */
export type SchemaV2TextToMusicInput = {
  /**
   * Prompt
   *
   * A description of the track you want to generate. This prompt will be used to automatically generate the tags and lyrics unless you manually set them. For example, if you set prompt and tags, then the prompt will be used to generate only the lyrics.
   */
  prompt?: string | unknown
  /**
   * Lyrics Prompt
   *
   * The lyrics sung in the generated song. An empty string will generate an instrumental track.
   */
  lyrics_prompt?: string | unknown
  /**
   * Tags
   *
   * Tags/styles of the music to generate. You can view a list of all available tags at https://sonauto.ai/tag-explorer.
   */
  tags?: Array<string> | unknown
  /**
   * Prompt Strength
   *
   * Controls how strongly your prompt influences the output. Greater values adhere more to the prompt but sound less natural. (This is CFG.)
   */
  prompt_strength?: number
  /**
   * Output Bit Rate
   *
   * The bit rate to use for mp3 and m4a formats. Not available for other formats.
   */
  output_bit_rate?: 128 | 192 | 256 | 320 | unknown
  /**
   * Num Songs
   *
   * Generating 2 songs costs 1.5x the price of generating 1 song. Also, note that using the same seed may not result in identical songs if the number of songs generated is changed.
   */
  num_songs?: number
  /**
   * Output Format
   */
  output_format?: 'flac' | 'mp3' | 'wav' | 'ogg' | 'm4a'
  /**
   * Bpm
   *
   * The beats per minute of the song. This can be set to an integer or the literal string "auto" to pick a suitable bpm based on the tags. Set bpm to null to not condition the model on bpm information.
   */
  bpm?: number | string | unknown
  /**
   * Balance Strength
   *
   * Greater means more natural vocals. Lower means sharper instrumentals. We recommend 0.7.
   */
  balance_strength?: number
  /**
   * Seed
   *
   * The seed to use for generation. Will pick a random seed if not provided. Repeating a request with identical parameters (must use lyrics and tags, not prompt) and the same seed will generate the same song.
   */
  seed?: number | unknown
}

/**
 * InpaintSection
 */
export type SchemaInpaintSection = {
  /**
   * End
   *
   * End time in seconds of the section to inpaint.
   */
  end: number
  /**
   * Start
   *
   * Start time in seconds of the section to inpaint.
   */
  start: number
}

/**
 * InpaintOutput
 */
export type SchemaV2InpaintOutput = {
  /**
   * Seed
   *
   * The seed used for generation. This can be used to generate an identical song by passing the same parameters with this seed in a future request.
   */
  seed: number
  /**
   * Audio
   *
   * The generated audio files.
   */
  audio: Array<SchemaFile>
}

/**
 * InpaintInput
 */
export type SchemaV2InpaintInput = {
  /**
   * Lyrics Prompt
   *
   * The lyrics sung in the generated song. An empty string will generate an instrumental track.
   */
  lyrics_prompt: string
  /**
   * Tags
   *
   * Tags/styles of the music to generate. You can view a list of all available tags at https://sonauto.ai/tag-explorer.
   */
  tags?: Array<string>
  /**
   * Prompt Strength
   *
   * Controls how strongly your prompt influences the output. Greater values adhere more to the prompt but sound less natural. (This is CFG.)
   */
  prompt_strength?: number
  /**
   * Output Bit Rate
   *
   * The bit rate to use for mp3 and m4a formats. Not available for other formats.
   */
  output_bit_rate?: 128 | 192 | 256 | 320 | unknown
  /**
   * Num Songs
   *
   * Generating 2 songs costs 1.5x the price of generating 1 song. Also, note that using the same seed may not result in identical songs if the number of songs generated is changed.
   */
  num_songs?: number
  /**
   * Output Format
   */
  output_format?: 'flac' | 'mp3' | 'wav' | 'ogg' | 'm4a'
  /**
   * Selection Crop
   *
   * Crop to the selected region
   */
  selection_crop?: boolean
  /**
   * Sections
   *
   * List of sections to inpaint. Currently, only one section is supported so the list length must be 1.
   */
  sections: Array<SchemaInpaintSection>
  /**
   * Balance Strength
   *
   * Greater means more natural vocals. Lower means sharper instrumentals. We recommend 0.7.
   */
  balance_strength?: number
  /**
   * Audio Url
   *
   * The URL of the audio file to alter. Must be a valid publicly accessible URL.
   */
  audio_url: string
  /**
   * Seed
   *
   * The seed to use for generation. Will pick a random seed if not provided. Repeating a request with identical parameters (must use lyrics and tags, not prompt) and the same seed will generate the same song.
   */
  seed?: number | unknown
}

/**
 * SoundEffectOutput
 *
 * Output format for generated sound effects
 */
export type SchemaElevenlabsSoundEffectsV2Output = {
  audio: SchemaFile
}

/**
 * SoundEffectRequestV2
 */
export type SchemaElevenlabsSoundEffectsV2Input = {
  /**
   * Text
   *
   * The text describing the sound effect to generate
   */
  text: string
  /**
   * Loop
   *
   * Whether to create a sound effect that loops smoothly.
   */
  loop?: boolean
  /**
   * Prompt Influence
   *
   * How closely to follow the prompt (0-1). Higher values mean less variation.
   */
  prompt_influence?: number
  /**
   * Output Format
   *
   * Output format of the generated audio. Formatted as codec_sample_rate_bitrate.
   */
  output_format?:
    | 'mp3_22050_32'
    | 'mp3_44100_32'
    | 'mp3_44100_64'
    | 'mp3_44100_96'
    | 'mp3_44100_128'
    | 'mp3_44100_192'
    | 'pcm_8000'
    | 'pcm_16000'
    | 'pcm_22050'
    | 'pcm_24000'
    | 'pcm_44100'
    | 'pcm_48000'
    | 'ulaw_8000'
    | 'alaw_8000'
    | 'opus_48000_32'
    | 'opus_48000_64'
    | 'opus_48000_96'
    | 'opus_48000_128'
    | 'opus_48000_192'
  /**
   * Duration Seconds
   *
   * Duration in seconds (0.5-22). If None, optimal duration will be determined from prompt.
   */
  duration_seconds?: number | unknown
}

/**
 * PronunciationDictionaryLocator
 */
export type SchemaPronunciationDictionaryLocator = {
  /**
   * Version Id
   *
   * The ID of the version of the pronunciation dictionary. If not provided, the latest version will be used.
   */
  version_id?: string | unknown
  /**
   * Pronunciation Dictionary Id
   *
   * The ID of the pronunciation dictionary.
   */
  pronunciation_dictionary_id: string | unknown
}

/**
 * DialogueBlock
 */
export type SchemaDialogueBlock = {
  /**
   * Text
   *
   * The dialogue text
   */
  text: string
  /**
   * Voice
   *
   * The name or the ID of the voice to be used for the generation.
   */
  voice: string
}

/**
 * TextToDialogueOutput
 */
export type SchemaElevenlabsTextToDialogueElevenV3Output = {
  /**
   * Seed
   *
   * Random seed for reproducibility.
   */
  seed: number
  audio: SchemaFile
}

/**
 * TextToDialogueRequest
 */
export type SchemaElevenlabsTextToDialogueElevenV3Input = {
  /**
   * Stability
   *
   * Determines how stable the voice is and the randomness between each generation. Lower values introduce broader emotional range for the voice. Higher values can result in a monotonous voice with limited emotion. Must be one of 0.0, 0.5, 1.0, else it will be rounded to the nearest value.
   */
  stability?: number | unknown
  /**
   * Inputs
   *
   * A list of dialogue inputs, each containing text and a voice ID which will be converted into speech.
   */
  inputs: Array<SchemaDialogueBlock>
  /**
   * Language Code
   *
   * Language code (ISO 639-1) used to enforce a language for the model. An error will be returned if language code is not supported by the model.
   */
  language_code?: string | unknown
  /**
   * Seed
   *
   * Random seed for reproducibility.
   */
  seed?: number | unknown
  /**
   * Use Speaker Boost
   *
   * This setting boosts the similarity to the original speaker. Using this setting requires a slightly higher computational load, which in turn increases latency.
   */
  use_speaker_boost?: boolean | unknown
  /**
   * Pronunciation Dictionary Locators
   *
   * A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request
   */
  pronunciation_dictionary_locators?: Array<SchemaPronunciationDictionaryLocator>
}

/**
 * TextToAudioOutput
 */
export type SchemaStableAudio25TextToAudioOutput = {
  /**
   * Seed
   *
   * The random seed used for generation
   */
  seed: number
  /**
   * Audio
   *
   * The generated audio clip
   */
  audio: SchemaFile
}

/**
 * TextToAudioInput
 */
export type SchemaStableAudio25TextToAudioInput = {
  /**
   * Prompt
   *
   * The prompt to generate audio from
   */
  prompt: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Seconds Total
   *
   * The duration of the audio clip to generate
   */
  seconds_total?: number
  /**
   * Num Inference Steps
   *
   * The number of steps to denoise the audio for
   */
  num_inference_steps?: number
  /**
   * Guidance Scale
   *
   * How strictly the diffusion process adheres to the prompt text (higher values make your audio closer to your prompt).
   */
  guidance_scale?: number
  /**
   * Seed
   */
  seed?: number
}

/**
 * MusicV15Output
 */
export type SchemaMinimaxMusicV15Output = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: SchemaFile
}

/**
 * TextToMusic15Request
 */
export type SchemaMinimaxMusicV15Input = {
  /**
   * Prompt
   *
   * Lyrics, supports [intro][verse][chorus][bridge][outro] sections. 10-600 characters.
   */
  prompt: string
  /**
   * Lyrics Prompt
   *
   * Control music generation. 10-3000 characters.
   */
  lyrics_prompt: string
  /**
   * Audio Setting
   *
   * Audio configuration settings
   */
  audio_setting?: SchemaAudioSetting
}

/**
 * AudioSetting
 */
export type SchemaAudioSetting = {
  /**
   * Format
   *
   * Audio format
   */
  format?: 'mp3' | 'pcm' | 'flac'
  /**
   * Sample Rate
   *
   * Sample rate of generated audio
   */
  sample_rate?: 8000 | 16000 | 22050 | 24000 | 32000 | 44100
  /**
   * Bitrate
   *
   * Bitrate of generated audio
   */
  bitrate?: 32000 | 64000 | 128000 | 256000
}

/**
 * MusicGenerationOutput
 *
 * Output schema for music generation.
 */
export type SchemaMusicGenerationOutput = {
  /**
   * Prompt
   *
   * The processed prompt used for generation
   */
  prompt: string
  /**
   * Metadata
   *
   * Generation metadata including duration, sample rate, and parameters
   */
  metadata: {
    [key: string]: unknown
  }
  audio: SchemaFile
}

/**
 * MusicGenerationInput
 *
 * Input schema for music generation with form controls for the playground.
 */
export type SchemaMusicGenerationInput = {
  /**
   * Prompt
   *
   * Describe the music you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * Length of the generated music in seconds
   */
  duration?: number
  /**
   * Refinement
   *
   * Refinement level - higher values may improve quality but take longer
   */
  refinement?: number
  /**
   * Seed
   *
   * Random seed for reproducible results - leave empty for random generation
   */
  seed?: number | unknown
  /**
   * Negative Prompt
   *
   * Describe what you want to avoid in the music (instruments, styles, moods). Leave blank for none.
   */
  negative_prompt?: string
  /**
   * Creativity
   *
   * Creativity level - higher values allow more creative interpretation of the prompt
   */
  creativity?: number
}

/**
 * SoundEffectGenerationOutput
 *
 * Output schema for sound effect generation.
 */
export type SchemaSoundEffectGenerationOutput = {
  /**
   * Prompt
   *
   * The processed prompt used for generation
   */
  prompt: string
  /**
   * Metadata
   *
   * Generation metadata including duration, sample rate, and parameters
   */
  metadata: {
    [key: string]: unknown
  }
  audio: SchemaFile
}

/**
 * SoundEffectGenerationInput
 *
 * Input schema for sound effect generation with form controls for the playground.
 */
export type SchemaSoundEffectGenerationInput = {
  /**
   * Prompt
   *
   * Describe the sound effect you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * Length of the generated sound effect in seconds
   */
  duration?: number
  /**
   * Refinement
   *
   * Refinement level - Higher values may improve quality but take longer
   */
  refinement?: number
  /**
   * Seed
   *
   * Random seed for reproducible results - leave empty for random generation
   */
  seed?: number | unknown
  /**
   * Negative Prompt
   *
   * Describe the types of sounds you don't want to generate in the output, avoid double-negatives, compare with positive prompts
   */
  negative_prompt?: string
  /**
   * Creativity
   *
   * Creativity level - higher values allow more creative interpretation of the prompt
   */
  creativity?: number
}

/**
 * MusicV15Output
 */
export type SchemaMinimaxMusicV2Output = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: SchemaFile
}

/**
 * TextToMusic20Request
 */
export type SchemaMinimaxMusicV2Input = {
  /**
   * Prompt
   *
   * A description of the music, specifying style, mood, and scenario. 10-300 characters.
   */
  prompt: string
  /**
   * Lyrics Prompt
   *
   * Lyrics of the song. Use n to separate lines. You may add structure tags like [Intro], [Verse], [Chorus], [Bridge], [Outro] to enhance the arrangement. 10-3000 characters.
   */
  lyrics_prompt: string
  /**
   * Audio Setting
   *
   * Audio configuration settings
   */
  audio_setting?: SchemaAudioSetting
}

/**
 * MusicSection
 */
export type SchemaMusicSection = {
  /**
   * Positive Local Styles
   *
   * The styles that should be present in this section.
   */
  positive_local_styles: Array<string>
  /**
   * Lines
   *
   * The lyrics of the section. Each line must be at most 200 characters long.
   */
  lines: Array<string>
  /**
   * Negative Local Styles
   *
   * The styles that should not be present in this section.
   */
  negative_local_styles: Array<string>
  /**
   * Duration Ms
   *
   * The duration of the section in milliseconds. Must be between 3000ms and 120000ms.
   */
  duration_ms: number
  /**
   * Section Name
   *
   * The name of the section. Must be between 1 and 100 characters.
   */
  section_name: string
}

/**
 * MusicCompositionPlan
 */
export type SchemaMusicCompositionPlan = {
  /**
   * Negative Global Styles
   *
   * The styles that should not be present in the entire song.
   */
  negative_global_styles: Array<string>
  /**
   * Sections
   *
   * The sections of the song.
   */
  sections: Array<SchemaMusicSection>
  /**
   * Positive Global Styles
   *
   * The styles that should be present in the entire song.
   */
  positive_global_styles: Array<string>
}

/**
 * MusicOutput
 */
export type SchemaElevenlabsMusicOutput = {
  audio: SchemaFile
}

/**
 * MusicRequest
 *
 * Request format for Elevenlabs Music API
 */
export type SchemaElevenlabsMusicInput = {
  /**
   * Prompt
   *
   * The text prompt describing the music to generate
   */
  prompt?: string | unknown
  /**
   * The composition plan for the music
   */
  composition_plan?: SchemaMusicCompositionPlan | unknown
  /**
   * Music Length Ms
   *
   * The length of the song to generate in milliseconds. Used only in conjunction with prompt. Must be between 3000ms and 600000ms. Optional - if not provided, the model will choose a length based on the prompt.
   */
  music_length_ms?: number | unknown
  /**
   * Output Format
   *
   * Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the Î¼-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.
   */
  output_format?:
    | 'mp3_22050_32'
    | 'mp3_44100_32'
    | 'mp3_44100_64'
    | 'mp3_44100_96'
    | 'mp3_44100_128'
    | 'mp3_44100_192'
    | 'pcm_8000'
    | 'pcm_16000'
    | 'pcm_22050'
    | 'pcm_24000'
    | 'pcm_44100'
    | 'pcm_48000'
    | 'ulaw_8000'
    | 'alaw_8000'
    | 'opus_48000_32'
    | 'opus_48000_64'
    | 'opus_48000_96'
    | 'opus_48000_128'
    | 'opus_48000_192'
  /**
   * Respect Sections Durations
   *
   * Controls how strictly section durations in the composition_plan are enforced. It will only have an effect if it is used with composition_plan. When set to true, the model will precisely respect each section's duration_ms from the plan. When set to false, the model may adjust individual section durations which will generally lead to better generation quality and improved latency, while always preserving the total song duration from the plan.
   */
  respect_sections_durations?: boolean
  /**
   * Force Instrumental
   *
   * If true, guarantees that the generated song will be instrumental. If false, the song may or may not be instrumental depending on the prompt. Can only be used with prompt.
   */
  force_instrumental?: boolean
}

export type SchemaQueueStatus = {
  status: 'IN_QUEUE' | 'IN_PROGRESS' | 'COMPLETED'
  /**
   * The request id.
   */
  request_id: string
  /**
   * The response url.
   */
  response_url?: string
  /**
   * The status url.
   */
  status_url?: string
  /**
   * The cancel url.
   */
  cancel_url?: string
  /**
   * The logs.
   */
  logs?: {
    [key: string]: unknown
  }
  /**
   * The metrics.
   */
  metrics?: {
    [key: string]: unknown
  }
  /**
   * The queue position.
   */
  queue_position?: number
}

export type GetFalAiElevenlabsMusicRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/elevenlabs/music/requests/{request_id}/status'
}

export type GetFalAiElevenlabsMusicRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiElevenlabsMusicRequestsByRequestIdStatusResponse =
  GetFalAiElevenlabsMusicRequestsByRequestIdStatusResponses[keyof GetFalAiElevenlabsMusicRequestsByRequestIdStatusResponses]

export type PutFalAiElevenlabsMusicRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/elevenlabs/music/requests/{request_id}/cancel'
}

export type PutFalAiElevenlabsMusicRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiElevenlabsMusicRequestsByRequestIdCancelResponse =
  PutFalAiElevenlabsMusicRequestsByRequestIdCancelResponses[keyof PutFalAiElevenlabsMusicRequestsByRequestIdCancelResponses]

export type PostFalAiElevenlabsMusicData = {
  body: SchemaElevenlabsMusicInput
  path?: never
  query?: never
  url: '/fal-ai/elevenlabs/music'
}

export type PostFalAiElevenlabsMusicResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiElevenlabsMusicResponse =
  PostFalAiElevenlabsMusicResponses[keyof PostFalAiElevenlabsMusicResponses]

export type GetFalAiElevenlabsMusicRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/elevenlabs/music/requests/{request_id}'
}

export type GetFalAiElevenlabsMusicRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaElevenlabsMusicOutput
}

export type GetFalAiElevenlabsMusicRequestsByRequestIdResponse =
  GetFalAiElevenlabsMusicRequestsByRequestIdResponses[keyof GetFalAiElevenlabsMusicRequestsByRequestIdResponses]

export type GetFalAiMinimaxMusicV2RequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/minimax-music/v2/requests/{request_id}/status'
}

export type GetFalAiMinimaxMusicV2RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiMinimaxMusicV2RequestsByRequestIdStatusResponse =
  GetFalAiMinimaxMusicV2RequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxMusicV2RequestsByRequestIdStatusResponses]

export type PutFalAiMinimaxMusicV2RequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax-music/v2/requests/{request_id}/cancel'
}

export type PutFalAiMinimaxMusicV2RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiMinimaxMusicV2RequestsByRequestIdCancelResponse =
  PutFalAiMinimaxMusicV2RequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxMusicV2RequestsByRequestIdCancelResponses]

export type PostFalAiMinimaxMusicV2Data = {
  body: SchemaMinimaxMusicV2Input
  path?: never
  query?: never
  url: '/fal-ai/minimax-music/v2'
}

export type PostFalAiMinimaxMusicV2Responses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMinimaxMusicV2Response =
  PostFalAiMinimaxMusicV2Responses[keyof PostFalAiMinimaxMusicV2Responses]

export type GetFalAiMinimaxMusicV2RequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax-music/v2/requests/{request_id}'
}

export type GetFalAiMinimaxMusicV2RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaMinimaxMusicV2Output
}

export type GetFalAiMinimaxMusicV2RequestsByRequestIdResponse =
  GetFalAiMinimaxMusicV2RequestsByRequestIdResponses[keyof GetFalAiMinimaxMusicV2RequestsByRequestIdResponses]

export type GetBeatovenSoundEffectGenerationRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/beatoven/sound-effect-generation/requests/{request_id}/status'
}

export type GetBeatovenSoundEffectGenerationRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetBeatovenSoundEffectGenerationRequestsByRequestIdStatusResponse =
  GetBeatovenSoundEffectGenerationRequestsByRequestIdStatusResponses[keyof GetBeatovenSoundEffectGenerationRequestsByRequestIdStatusResponses]

export type PutBeatovenSoundEffectGenerationRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/beatoven/sound-effect-generation/requests/{request_id}/cancel'
}

export type PutBeatovenSoundEffectGenerationRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutBeatovenSoundEffectGenerationRequestsByRequestIdCancelResponse =
  PutBeatovenSoundEffectGenerationRequestsByRequestIdCancelResponses[keyof PutBeatovenSoundEffectGenerationRequestsByRequestIdCancelResponses]

export type PostBeatovenSoundEffectGenerationData = {
  body: SchemaSoundEffectGenerationInput
  path?: never
  query?: never
  url: '/beatoven/sound-effect-generation'
}

export type PostBeatovenSoundEffectGenerationResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostBeatovenSoundEffectGenerationResponse =
  PostBeatovenSoundEffectGenerationResponses[keyof PostBeatovenSoundEffectGenerationResponses]

export type GetBeatovenSoundEffectGenerationRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/beatoven/sound-effect-generation/requests/{request_id}'
}

export type GetBeatovenSoundEffectGenerationRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaSoundEffectGenerationOutput
}

export type GetBeatovenSoundEffectGenerationRequestsByRequestIdResponse =
  GetBeatovenSoundEffectGenerationRequestsByRequestIdResponses[keyof GetBeatovenSoundEffectGenerationRequestsByRequestIdResponses]

export type GetBeatovenMusicGenerationRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/beatoven/music-generation/requests/{request_id}/status'
}

export type GetBeatovenMusicGenerationRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetBeatovenMusicGenerationRequestsByRequestIdStatusResponse =
  GetBeatovenMusicGenerationRequestsByRequestIdStatusResponses[keyof GetBeatovenMusicGenerationRequestsByRequestIdStatusResponses]

export type PutBeatovenMusicGenerationRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/beatoven/music-generation/requests/{request_id}/cancel'
}

export type PutBeatovenMusicGenerationRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutBeatovenMusicGenerationRequestsByRequestIdCancelResponse =
  PutBeatovenMusicGenerationRequestsByRequestIdCancelResponses[keyof PutBeatovenMusicGenerationRequestsByRequestIdCancelResponses]

export type PostBeatovenMusicGenerationData = {
  body: SchemaMusicGenerationInput
  path?: never
  query?: never
  url: '/beatoven/music-generation'
}

export type PostBeatovenMusicGenerationResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostBeatovenMusicGenerationResponse =
  PostBeatovenMusicGenerationResponses[keyof PostBeatovenMusicGenerationResponses]

export type GetBeatovenMusicGenerationRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/beatoven/music-generation/requests/{request_id}'
}

export type GetBeatovenMusicGenerationRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaMusicGenerationOutput
}

export type GetBeatovenMusicGenerationRequestsByRequestIdResponse =
  GetBeatovenMusicGenerationRequestsByRequestIdResponses[keyof GetBeatovenMusicGenerationRequestsByRequestIdResponses]

export type GetFalAiMinimaxMusicV15RequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/minimax-music/v1.5/requests/{request_id}/status'
}

export type GetFalAiMinimaxMusicV15RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiMinimaxMusicV15RequestsByRequestIdStatusResponse =
  GetFalAiMinimaxMusicV15RequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxMusicV15RequestsByRequestIdStatusResponses]

export type PutFalAiMinimaxMusicV15RequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax-music/v1.5/requests/{request_id}/cancel'
}

export type PutFalAiMinimaxMusicV15RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiMinimaxMusicV15RequestsByRequestIdCancelResponse =
  PutFalAiMinimaxMusicV15RequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxMusicV15RequestsByRequestIdCancelResponses]

export type PostFalAiMinimaxMusicV15Data = {
  body: SchemaMinimaxMusicV15Input
  path?: never
  query?: never
  url: '/fal-ai/minimax-music/v1.5'
}

export type PostFalAiMinimaxMusicV15Responses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMinimaxMusicV15Response =
  PostFalAiMinimaxMusicV15Responses[keyof PostFalAiMinimaxMusicV15Responses]

export type GetFalAiMinimaxMusicV15RequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax-music/v1.5/requests/{request_id}'
}

export type GetFalAiMinimaxMusicV15RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaMinimaxMusicV15Output
}

export type GetFalAiMinimaxMusicV15RequestsByRequestIdResponse =
  GetFalAiMinimaxMusicV15RequestsByRequestIdResponses[keyof GetFalAiMinimaxMusicV15RequestsByRequestIdResponses]

export type GetFalAiStableAudio25TextToAudioRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/stable-audio-25/text-to-audio/requests/{request_id}/status'
}

export type GetFalAiStableAudio25TextToAudioRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiStableAudio25TextToAudioRequestsByRequestIdStatusResponse =
  GetFalAiStableAudio25TextToAudioRequestsByRequestIdStatusResponses[keyof GetFalAiStableAudio25TextToAudioRequestsByRequestIdStatusResponses]

export type PutFalAiStableAudio25TextToAudioRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/stable-audio-25/text-to-audio/requests/{request_id}/cancel'
}

export type PutFalAiStableAudio25TextToAudioRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiStableAudio25TextToAudioRequestsByRequestIdCancelResponse =
  PutFalAiStableAudio25TextToAudioRequestsByRequestIdCancelResponses[keyof PutFalAiStableAudio25TextToAudioRequestsByRequestIdCancelResponses]

export type PostFalAiStableAudio25TextToAudioData = {
  body: SchemaStableAudio25TextToAudioInput
  path?: never
  query?: never
  url: '/fal-ai/stable-audio-25/text-to-audio'
}

export type PostFalAiStableAudio25TextToAudioResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiStableAudio25TextToAudioResponse =
  PostFalAiStableAudio25TextToAudioResponses[keyof PostFalAiStableAudio25TextToAudioResponses]

export type GetFalAiStableAudio25TextToAudioRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/stable-audio-25/text-to-audio/requests/{request_id}'
}

export type GetFalAiStableAudio25TextToAudioRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaStableAudio25TextToAudioOutput
}

export type GetFalAiStableAudio25TextToAudioRequestsByRequestIdResponse =
  GetFalAiStableAudio25TextToAudioRequestsByRequestIdResponses[keyof GetFalAiStableAudio25TextToAudioRequestsByRequestIdResponses]

export type GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/elevenlabs/text-to-dialogue/eleven-v3/requests/{request_id}/status'
  }

export type GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdStatusResponse =
  GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdStatusResponses[keyof GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdStatusResponses]

export type PutFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/elevenlabs/text-to-dialogue/eleven-v3/requests/{request_id}/cancel'
  }

export type PutFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdCancelResponse =
  PutFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdCancelResponses[keyof PutFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdCancelResponses]

export type PostFalAiElevenlabsTextToDialogueElevenV3Data = {
  body: SchemaElevenlabsTextToDialogueElevenV3Input
  path?: never
  query?: never
  url: '/fal-ai/elevenlabs/text-to-dialogue/eleven-v3'
}

export type PostFalAiElevenlabsTextToDialogueElevenV3Responses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiElevenlabsTextToDialogueElevenV3Response =
  PostFalAiElevenlabsTextToDialogueElevenV3Responses[keyof PostFalAiElevenlabsTextToDialogueElevenV3Responses]

export type GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/elevenlabs/text-to-dialogue/eleven-v3/requests/{request_id}'
}

export type GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaElevenlabsTextToDialogueElevenV3Output
  }

export type GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdResponse =
  GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdResponses[keyof GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdResponses]

export type GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/elevenlabs/sound-effects/v2/requests/{request_id}/status'
}

export type GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdStatusResponse =
  GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdStatusResponses[keyof GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdStatusResponses]

export type PutFalAiElevenlabsSoundEffectsV2RequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/elevenlabs/sound-effects/v2/requests/{request_id}/cancel'
}

export type PutFalAiElevenlabsSoundEffectsV2RequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiElevenlabsSoundEffectsV2RequestsByRequestIdCancelResponse =
  PutFalAiElevenlabsSoundEffectsV2RequestsByRequestIdCancelResponses[keyof PutFalAiElevenlabsSoundEffectsV2RequestsByRequestIdCancelResponses]

export type PostFalAiElevenlabsSoundEffectsV2Data = {
  body: SchemaElevenlabsSoundEffectsV2Input
  path?: never
  query?: never
  url: '/fal-ai/elevenlabs/sound-effects/v2'
}

export type PostFalAiElevenlabsSoundEffectsV2Responses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiElevenlabsSoundEffectsV2Response =
  PostFalAiElevenlabsSoundEffectsV2Responses[keyof PostFalAiElevenlabsSoundEffectsV2Responses]

export type GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/elevenlabs/sound-effects/v2/requests/{request_id}'
}

export type GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaElevenlabsSoundEffectsV2Output
}

export type GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdResponse =
  GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdResponses[keyof GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdResponses]

export type GetSonautoV2InpaintRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/sonauto/v2/inpaint/requests/{request_id}/status'
}

export type GetSonautoV2InpaintRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetSonautoV2InpaintRequestsByRequestIdStatusResponse =
  GetSonautoV2InpaintRequestsByRequestIdStatusResponses[keyof GetSonautoV2InpaintRequestsByRequestIdStatusResponses]

export type PutSonautoV2InpaintRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/sonauto/v2/inpaint/requests/{request_id}/cancel'
}

export type PutSonautoV2InpaintRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutSonautoV2InpaintRequestsByRequestIdCancelResponse =
  PutSonautoV2InpaintRequestsByRequestIdCancelResponses[keyof PutSonautoV2InpaintRequestsByRequestIdCancelResponses]

export type PostSonautoV2InpaintData = {
  body: SchemaV2InpaintInput
  path?: never
  query?: never
  url: '/sonauto/v2/inpaint'
}

export type PostSonautoV2InpaintResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostSonautoV2InpaintResponse =
  PostSonautoV2InpaintResponses[keyof PostSonautoV2InpaintResponses]

export type GetSonautoV2InpaintRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/sonauto/v2/inpaint/requests/{request_id}'
}

export type GetSonautoV2InpaintRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaV2InpaintOutput
}

export type GetSonautoV2InpaintRequestsByRequestIdResponse =
  GetSonautoV2InpaintRequestsByRequestIdResponses[keyof GetSonautoV2InpaintRequestsByRequestIdResponses]

export type GetSonautoV2TextToMusicRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/sonauto/v2/text-to-music/requests/{request_id}/status'
}

export type GetSonautoV2TextToMusicRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetSonautoV2TextToMusicRequestsByRequestIdStatusResponse =
  GetSonautoV2TextToMusicRequestsByRequestIdStatusResponses[keyof GetSonautoV2TextToMusicRequestsByRequestIdStatusResponses]

export type PutSonautoV2TextToMusicRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/sonauto/v2/text-to-music/requests/{request_id}/cancel'
}

export type PutSonautoV2TextToMusicRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutSonautoV2TextToMusicRequestsByRequestIdCancelResponse =
  PutSonautoV2TextToMusicRequestsByRequestIdCancelResponses[keyof PutSonautoV2TextToMusicRequestsByRequestIdCancelResponses]

export type PostSonautoV2TextToMusicData = {
  body: SchemaV2TextToMusicInput
  path?: never
  query?: never
  url: '/sonauto/v2/text-to-music'
}

export type PostSonautoV2TextToMusicResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostSonautoV2TextToMusicResponse =
  PostSonautoV2TextToMusicResponses[keyof PostSonautoV2TextToMusicResponses]

export type GetSonautoV2TextToMusicRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/sonauto/v2/text-to-music/requests/{request_id}'
}

export type GetSonautoV2TextToMusicRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaV2TextToMusicOutput
}

export type GetSonautoV2TextToMusicRequestsByRequestIdResponse =
  GetSonautoV2TextToMusicRequestsByRequestIdResponses[keyof GetSonautoV2TextToMusicRequestsByRequestIdResponses]

export type GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/elevenlabs/tts/eleven-v3/requests/{request_id}/status'
}

export type GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdStatusResponse =
  GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdStatusResponses[keyof GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdStatusResponses]

export type PutFalAiElevenlabsTtsElevenV3RequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/elevenlabs/tts/eleven-v3/requests/{request_id}/cancel'
}

export type PutFalAiElevenlabsTtsElevenV3RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiElevenlabsTtsElevenV3RequestsByRequestIdCancelResponse =
  PutFalAiElevenlabsTtsElevenV3RequestsByRequestIdCancelResponses[keyof PutFalAiElevenlabsTtsElevenV3RequestsByRequestIdCancelResponses]

export type PostFalAiElevenlabsTtsElevenV3Data = {
  body: SchemaElevenlabsTtsElevenV3Input
  path?: never
  query?: never
  url: '/fal-ai/elevenlabs/tts/eleven-v3'
}

export type PostFalAiElevenlabsTtsElevenV3Responses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiElevenlabsTtsElevenV3Response =
  PostFalAiElevenlabsTtsElevenV3Responses[keyof PostFalAiElevenlabsTtsElevenV3Responses]

export type GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/elevenlabs/tts/eleven-v3/requests/{request_id}'
}

export type GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaElevenlabsTtsElevenV3Output
}

export type GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdResponse =
  GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdResponses[keyof GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdResponses]

export type GetFalAiLyria2RequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/lyria2/requests/{request_id}/status'
}

export type GetFalAiLyria2RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiLyria2RequestsByRequestIdStatusResponse =
  GetFalAiLyria2RequestsByRequestIdStatusResponses[keyof GetFalAiLyria2RequestsByRequestIdStatusResponses]

export type PutFalAiLyria2RequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/lyria2/requests/{request_id}/cancel'
}

export type PutFalAiLyria2RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiLyria2RequestsByRequestIdCancelResponse =
  PutFalAiLyria2RequestsByRequestIdCancelResponses[keyof PutFalAiLyria2RequestsByRequestIdCancelResponses]

export type PostFalAiLyria2Data = {
  body: SchemaLyria2Input
  path?: never
  query?: never
  url: '/fal-ai/lyria2'
}

export type PostFalAiLyria2Responses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLyria2Response =
  PostFalAiLyria2Responses[keyof PostFalAiLyria2Responses]

export type GetFalAiLyria2RequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/lyria2/requests/{request_id}'
}

export type GetFalAiLyria2RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLyria2Output
}

export type GetFalAiLyria2RequestsByRequestIdResponse =
  GetFalAiLyria2RequestsByRequestIdResponses[keyof GetFalAiLyria2RequestsByRequestIdResponses]

export type GetFalAiAceStepPromptToAudioRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ace-step/prompt-to-audio/requests/{request_id}/status'
}

export type GetFalAiAceStepPromptToAudioRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiAceStepPromptToAudioRequestsByRequestIdStatusResponse =
  GetFalAiAceStepPromptToAudioRequestsByRequestIdStatusResponses[keyof GetFalAiAceStepPromptToAudioRequestsByRequestIdStatusResponses]

export type PutFalAiAceStepPromptToAudioRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ace-step/prompt-to-audio/requests/{request_id}/cancel'
}

export type PutFalAiAceStepPromptToAudioRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiAceStepPromptToAudioRequestsByRequestIdCancelResponse =
  PutFalAiAceStepPromptToAudioRequestsByRequestIdCancelResponses[keyof PutFalAiAceStepPromptToAudioRequestsByRequestIdCancelResponses]

export type PostFalAiAceStepPromptToAudioData = {
  body: SchemaAceStepPromptToAudioInput
  path?: never
  query?: never
  url: '/fal-ai/ace-step/prompt-to-audio'
}

export type PostFalAiAceStepPromptToAudioResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiAceStepPromptToAudioResponse =
  PostFalAiAceStepPromptToAudioResponses[keyof PostFalAiAceStepPromptToAudioResponses]

export type GetFalAiAceStepPromptToAudioRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ace-step/prompt-to-audio/requests/{request_id}'
}

export type GetFalAiAceStepPromptToAudioRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaAceStepPromptToAudioOutput
}

export type GetFalAiAceStepPromptToAudioRequestsByRequestIdResponse =
  GetFalAiAceStepPromptToAudioRequestsByRequestIdResponses[keyof GetFalAiAceStepPromptToAudioRequestsByRequestIdResponses]

export type GetFalAiAceStepRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ace-step/requests/{request_id}/status'
}

export type GetFalAiAceStepRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiAceStepRequestsByRequestIdStatusResponse =
  GetFalAiAceStepRequestsByRequestIdStatusResponses[keyof GetFalAiAceStepRequestsByRequestIdStatusResponses]

export type PutFalAiAceStepRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ace-step/requests/{request_id}/cancel'
}

export type PutFalAiAceStepRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiAceStepRequestsByRequestIdCancelResponse =
  PutFalAiAceStepRequestsByRequestIdCancelResponses[keyof PutFalAiAceStepRequestsByRequestIdCancelResponses]

export type PostFalAiAceStepData = {
  body: SchemaAceStepInput
  path?: never
  query?: never
  url: '/fal-ai/ace-step'
}

export type PostFalAiAceStepResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiAceStepResponse =
  PostFalAiAceStepResponses[keyof PostFalAiAceStepResponses]

export type GetFalAiAceStepRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ace-step/requests/{request_id}'
}

export type GetFalAiAceStepRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaAceStepOutput
}

export type GetFalAiAceStepRequestsByRequestIdResponse =
  GetFalAiAceStepRequestsByRequestIdResponses[keyof GetFalAiAceStepRequestsByRequestIdResponses]

export type GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/cassetteai/sound-effects-generator/requests/{request_id}/status'
}

export type GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdStatusResponse =
  GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdStatusResponses[keyof GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdStatusResponses]

export type PutCassetteaiSoundEffectsGeneratorRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/cassetteai/sound-effects-generator/requests/{request_id}/cancel'
}

export type PutCassetteaiSoundEffectsGeneratorRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutCassetteaiSoundEffectsGeneratorRequestsByRequestIdCancelResponse =
  PutCassetteaiSoundEffectsGeneratorRequestsByRequestIdCancelResponses[keyof PutCassetteaiSoundEffectsGeneratorRequestsByRequestIdCancelResponses]

export type PostCassetteaiSoundEffectsGeneratorData = {
  body: SchemaSoundEffectsGeneratorInput
  path?: never
  query?: never
  url: '/cassetteai/sound-effects-generator'
}

export type PostCassetteaiSoundEffectsGeneratorResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostCassetteaiSoundEffectsGeneratorResponse =
  PostCassetteaiSoundEffectsGeneratorResponses[keyof PostCassetteaiSoundEffectsGeneratorResponses]

export type GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/cassetteai/sound-effects-generator/requests/{request_id}'
}

export type GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaSoundEffectsGeneratorOutput
}

export type GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdResponse =
  GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdResponses[keyof GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdResponses]

export type GetCassetteaiMusicGeneratorRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/cassetteai/music-generator/requests/{request_id}/status'
}

export type GetCassetteaiMusicGeneratorRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetCassetteaiMusicGeneratorRequestsByRequestIdStatusResponse =
  GetCassetteaiMusicGeneratorRequestsByRequestIdStatusResponses[keyof GetCassetteaiMusicGeneratorRequestsByRequestIdStatusResponses]

export type PutCassetteaiMusicGeneratorRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/cassetteai/music-generator/requests/{request_id}/cancel'
}

export type PutCassetteaiMusicGeneratorRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutCassetteaiMusicGeneratorRequestsByRequestIdCancelResponse =
  PutCassetteaiMusicGeneratorRequestsByRequestIdCancelResponses[keyof PutCassetteaiMusicGeneratorRequestsByRequestIdCancelResponses]

export type PostCassetteaiMusicGeneratorData = {
  body: SchemaMusicGeneratorInput
  path?: never
  query?: never
  url: '/cassetteai/music-generator'
}

export type PostCassetteaiMusicGeneratorResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostCassetteaiMusicGeneratorResponse =
  PostCassetteaiMusicGeneratorResponses[keyof PostCassetteaiMusicGeneratorResponses]

export type GetCassetteaiMusicGeneratorRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/cassetteai/music-generator/requests/{request_id}'
}

export type GetCassetteaiMusicGeneratorRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaMusicGeneratorOutput
}

export type GetCassetteaiMusicGeneratorRequestsByRequestIdResponse =
  GetCassetteaiMusicGeneratorRequestsByRequestIdResponses[keyof GetCassetteaiMusicGeneratorRequestsByRequestIdResponses]

export type GetFalAiCsm1bRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/csm-1b/requests/{request_id}/status'
}

export type GetFalAiCsm1bRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiCsm1bRequestsByRequestIdStatusResponse =
  GetFalAiCsm1bRequestsByRequestIdStatusResponses[keyof GetFalAiCsm1bRequestsByRequestIdStatusResponses]

export type PutFalAiCsm1bRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/csm-1b/requests/{request_id}/cancel'
}

export type PutFalAiCsm1bRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiCsm1bRequestsByRequestIdCancelResponse =
  PutFalAiCsm1bRequestsByRequestIdCancelResponses[keyof PutFalAiCsm1bRequestsByRequestIdCancelResponses]

export type PostFalAiCsm1bData = {
  body: SchemaCsm1bInput
  path?: never
  query?: never
  url: '/fal-ai/csm-1b'
}

export type PostFalAiCsm1bResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiCsm1bResponse =
  PostFalAiCsm1bResponses[keyof PostFalAiCsm1bResponses]

export type GetFalAiCsm1bRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/csm-1b/requests/{request_id}'
}

export type GetFalAiCsm1bRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaCsm1bOutput
}

export type GetFalAiCsm1bRequestsByRequestIdResponse =
  GetFalAiCsm1bRequestsByRequestIdResponses[keyof GetFalAiCsm1bRequestsByRequestIdResponses]

export type GetFalAiDiffrhythmRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/diffrhythm/requests/{request_id}/status'
}

export type GetFalAiDiffrhythmRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiDiffrhythmRequestsByRequestIdStatusResponse =
  GetFalAiDiffrhythmRequestsByRequestIdStatusResponses[keyof GetFalAiDiffrhythmRequestsByRequestIdStatusResponses]

export type PutFalAiDiffrhythmRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/diffrhythm/requests/{request_id}/cancel'
}

export type PutFalAiDiffrhythmRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiDiffrhythmRequestsByRequestIdCancelResponse =
  PutFalAiDiffrhythmRequestsByRequestIdCancelResponses[keyof PutFalAiDiffrhythmRequestsByRequestIdCancelResponses]

export type PostFalAiDiffrhythmData = {
  body: SchemaDiffrhythmInput
  path?: never
  query?: never
  url: '/fal-ai/diffrhythm'
}

export type PostFalAiDiffrhythmResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiDiffrhythmResponse =
  PostFalAiDiffrhythmResponses[keyof PostFalAiDiffrhythmResponses]

export type GetFalAiDiffrhythmRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/diffrhythm/requests/{request_id}'
}

export type GetFalAiDiffrhythmRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaDiffrhythmOutput
}

export type GetFalAiDiffrhythmRequestsByRequestIdResponse =
  GetFalAiDiffrhythmRequestsByRequestIdResponses[keyof GetFalAiDiffrhythmRequestsByRequestIdResponses]

export type GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/elevenlabs/tts/multilingual-v2/requests/{request_id}/status'
}

export type GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdStatusResponse =
  GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdStatusResponses[keyof GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdStatusResponses]

export type PutFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/elevenlabs/tts/multilingual-v2/requests/{request_id}/cancel'
}

export type PutFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdCancelResponse =
  PutFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdCancelResponses[keyof PutFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdCancelResponses]

export type PostFalAiElevenlabsTtsMultilingualV2Data = {
  body: SchemaElevenlabsTtsMultilingualV2Input
  path?: never
  query?: never
  url: '/fal-ai/elevenlabs/tts/multilingual-v2'
}

export type PostFalAiElevenlabsTtsMultilingualV2Responses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiElevenlabsTtsMultilingualV2Response =
  PostFalAiElevenlabsTtsMultilingualV2Responses[keyof PostFalAiElevenlabsTtsMultilingualV2Responses]

export type GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/elevenlabs/tts/multilingual-v2/requests/{request_id}'
}

export type GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaElevenlabsTtsMultilingualV2Output
}

export type GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdResponse =
  GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdResponses[keyof GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdResponses]

export type GetFalAiKokoroHindiRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kokoro/hindi/requests/{request_id}/status'
}

export type GetFalAiKokoroHindiRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiKokoroHindiRequestsByRequestIdStatusResponse =
  GetFalAiKokoroHindiRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroHindiRequestsByRequestIdStatusResponses]

export type PutFalAiKokoroHindiRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/hindi/requests/{request_id}/cancel'
}

export type PutFalAiKokoroHindiRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiKokoroHindiRequestsByRequestIdCancelResponse =
  PutFalAiKokoroHindiRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroHindiRequestsByRequestIdCancelResponses]

export type PostFalAiKokoroHindiData = {
  body: SchemaKokoroHindiInput
  path?: never
  query?: never
  url: '/fal-ai/kokoro/hindi'
}

export type PostFalAiKokoroHindiResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKokoroHindiResponse =
  PostFalAiKokoroHindiResponses[keyof PostFalAiKokoroHindiResponses]

export type GetFalAiKokoroHindiRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/hindi/requests/{request_id}'
}

export type GetFalAiKokoroHindiRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKokoroHindiOutput
}

export type GetFalAiKokoroHindiRequestsByRequestIdResponse =
  GetFalAiKokoroHindiRequestsByRequestIdResponses[keyof GetFalAiKokoroHindiRequestsByRequestIdResponses]

export type GetFalAiKokoroMandarinChineseRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kokoro/mandarin-chinese/requests/{request_id}/status'
}

export type GetFalAiKokoroMandarinChineseRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiKokoroMandarinChineseRequestsByRequestIdStatusResponse =
  GetFalAiKokoroMandarinChineseRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroMandarinChineseRequestsByRequestIdStatusResponses]

export type PutFalAiKokoroMandarinChineseRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/mandarin-chinese/requests/{request_id}/cancel'
}

export type PutFalAiKokoroMandarinChineseRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiKokoroMandarinChineseRequestsByRequestIdCancelResponse =
  PutFalAiKokoroMandarinChineseRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroMandarinChineseRequestsByRequestIdCancelResponses]

export type PostFalAiKokoroMandarinChineseData = {
  body: SchemaKokoroMandarinChineseInput
  path?: never
  query?: never
  url: '/fal-ai/kokoro/mandarin-chinese'
}

export type PostFalAiKokoroMandarinChineseResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKokoroMandarinChineseResponse =
  PostFalAiKokoroMandarinChineseResponses[keyof PostFalAiKokoroMandarinChineseResponses]

export type GetFalAiKokoroMandarinChineseRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/mandarin-chinese/requests/{request_id}'
}

export type GetFalAiKokoroMandarinChineseRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKokoroMandarinChineseOutput
}

export type GetFalAiKokoroMandarinChineseRequestsByRequestIdResponse =
  GetFalAiKokoroMandarinChineseRequestsByRequestIdResponses[keyof GetFalAiKokoroMandarinChineseRequestsByRequestIdResponses]

export type GetFalAiKokoroSpanishRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kokoro/spanish/requests/{request_id}/status'
}

export type GetFalAiKokoroSpanishRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiKokoroSpanishRequestsByRequestIdStatusResponse =
  GetFalAiKokoroSpanishRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroSpanishRequestsByRequestIdStatusResponses]

export type PutFalAiKokoroSpanishRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/spanish/requests/{request_id}/cancel'
}

export type PutFalAiKokoroSpanishRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiKokoroSpanishRequestsByRequestIdCancelResponse =
  PutFalAiKokoroSpanishRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroSpanishRequestsByRequestIdCancelResponses]

export type PostFalAiKokoroSpanishData = {
  body: SchemaKokoroSpanishInput
  path?: never
  query?: never
  url: '/fal-ai/kokoro/spanish'
}

export type PostFalAiKokoroSpanishResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKokoroSpanishResponse =
  PostFalAiKokoroSpanishResponses[keyof PostFalAiKokoroSpanishResponses]

export type GetFalAiKokoroSpanishRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/spanish/requests/{request_id}'
}

export type GetFalAiKokoroSpanishRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKokoroSpanishOutput
}

export type GetFalAiKokoroSpanishRequestsByRequestIdResponse =
  GetFalAiKokoroSpanishRequestsByRequestIdResponses[keyof GetFalAiKokoroSpanishRequestsByRequestIdResponses]

export type GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kokoro/brazilian-portuguese/requests/{request_id}/status'
}

export type GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdStatusResponse =
  GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdStatusResponses]

export type PutFalAiKokoroBrazilianPortugueseRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/brazilian-portuguese/requests/{request_id}/cancel'
}

export type PutFalAiKokoroBrazilianPortugueseRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKokoroBrazilianPortugueseRequestsByRequestIdCancelResponse =
  PutFalAiKokoroBrazilianPortugueseRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroBrazilianPortugueseRequestsByRequestIdCancelResponses]

export type PostFalAiKokoroBrazilianPortugueseData = {
  body: SchemaKokoroBrazilianPortugueseInput
  path?: never
  query?: never
  url: '/fal-ai/kokoro/brazilian-portuguese'
}

export type PostFalAiKokoroBrazilianPortugueseResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKokoroBrazilianPortugueseResponse =
  PostFalAiKokoroBrazilianPortugueseResponses[keyof PostFalAiKokoroBrazilianPortugueseResponses]

export type GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/brazilian-portuguese/requests/{request_id}'
}

export type GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKokoroBrazilianPortugueseOutput
}

export type GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdResponse =
  GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdResponses[keyof GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdResponses]

export type GetFalAiKokoroBritishEnglishRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kokoro/british-english/requests/{request_id}/status'
}

export type GetFalAiKokoroBritishEnglishRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiKokoroBritishEnglishRequestsByRequestIdStatusResponse =
  GetFalAiKokoroBritishEnglishRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroBritishEnglishRequestsByRequestIdStatusResponses]

export type PutFalAiKokoroBritishEnglishRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/british-english/requests/{request_id}/cancel'
}

export type PutFalAiKokoroBritishEnglishRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiKokoroBritishEnglishRequestsByRequestIdCancelResponse =
  PutFalAiKokoroBritishEnglishRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroBritishEnglishRequestsByRequestIdCancelResponses]

export type PostFalAiKokoroBritishEnglishData = {
  body: SchemaKokoroBritishEnglishInput
  path?: never
  query?: never
  url: '/fal-ai/kokoro/british-english'
}

export type PostFalAiKokoroBritishEnglishResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKokoroBritishEnglishResponse =
  PostFalAiKokoroBritishEnglishResponses[keyof PostFalAiKokoroBritishEnglishResponses]

export type GetFalAiKokoroBritishEnglishRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/british-english/requests/{request_id}'
}

export type GetFalAiKokoroBritishEnglishRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKokoroBritishEnglishOutput
}

export type GetFalAiKokoroBritishEnglishRequestsByRequestIdResponse =
  GetFalAiKokoroBritishEnglishRequestsByRequestIdResponses[keyof GetFalAiKokoroBritishEnglishRequestsByRequestIdResponses]

export type GetFalAiKokoroFrenchRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kokoro/french/requests/{request_id}/status'
}

export type GetFalAiKokoroFrenchRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiKokoroFrenchRequestsByRequestIdStatusResponse =
  GetFalAiKokoroFrenchRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroFrenchRequestsByRequestIdStatusResponses]

export type PutFalAiKokoroFrenchRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/french/requests/{request_id}/cancel'
}

export type PutFalAiKokoroFrenchRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiKokoroFrenchRequestsByRequestIdCancelResponse =
  PutFalAiKokoroFrenchRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroFrenchRequestsByRequestIdCancelResponses]

export type PostFalAiKokoroFrenchData = {
  body: SchemaKokoroFrenchInput
  path?: never
  query?: never
  url: '/fal-ai/kokoro/french'
}

export type PostFalAiKokoroFrenchResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKokoroFrenchResponse =
  PostFalAiKokoroFrenchResponses[keyof PostFalAiKokoroFrenchResponses]

export type GetFalAiKokoroFrenchRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/french/requests/{request_id}'
}

export type GetFalAiKokoroFrenchRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKokoroFrenchOutput
}

export type GetFalAiKokoroFrenchRequestsByRequestIdResponse =
  GetFalAiKokoroFrenchRequestsByRequestIdResponses[keyof GetFalAiKokoroFrenchRequestsByRequestIdResponses]

export type GetFalAiKokoroJapaneseRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kokoro/japanese/requests/{request_id}/status'
}

export type GetFalAiKokoroJapaneseRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiKokoroJapaneseRequestsByRequestIdStatusResponse =
  GetFalAiKokoroJapaneseRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroJapaneseRequestsByRequestIdStatusResponses]

export type PutFalAiKokoroJapaneseRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/japanese/requests/{request_id}/cancel'
}

export type PutFalAiKokoroJapaneseRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiKokoroJapaneseRequestsByRequestIdCancelResponse =
  PutFalAiKokoroJapaneseRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroJapaneseRequestsByRequestIdCancelResponses]

export type PostFalAiKokoroJapaneseData = {
  body: SchemaKokoroJapaneseInput
  path?: never
  query?: never
  url: '/fal-ai/kokoro/japanese'
}

export type PostFalAiKokoroJapaneseResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKokoroJapaneseResponse =
  PostFalAiKokoroJapaneseResponses[keyof PostFalAiKokoroJapaneseResponses]

export type GetFalAiKokoroJapaneseRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/japanese/requests/{request_id}'
}

export type GetFalAiKokoroJapaneseRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKokoroJapaneseOutput
}

export type GetFalAiKokoroJapaneseRequestsByRequestIdResponse =
  GetFalAiKokoroJapaneseRequestsByRequestIdResponses[keyof GetFalAiKokoroJapaneseRequestsByRequestIdResponses]

export type GetFalAiKokoroAmericanEnglishRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kokoro/american-english/requests/{request_id}/status'
}

export type GetFalAiKokoroAmericanEnglishRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiKokoroAmericanEnglishRequestsByRequestIdStatusResponse =
  GetFalAiKokoroAmericanEnglishRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroAmericanEnglishRequestsByRequestIdStatusResponses]

export type PutFalAiKokoroAmericanEnglishRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/american-english/requests/{request_id}/cancel'
}

export type PutFalAiKokoroAmericanEnglishRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiKokoroAmericanEnglishRequestsByRequestIdCancelResponse =
  PutFalAiKokoroAmericanEnglishRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroAmericanEnglishRequestsByRequestIdCancelResponses]

export type PostFalAiKokoroAmericanEnglishData = {
  body: SchemaKokoroAmericanEnglishInput
  path?: never
  query?: never
  url: '/fal-ai/kokoro/american-english'
}

export type PostFalAiKokoroAmericanEnglishResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKokoroAmericanEnglishResponse =
  PostFalAiKokoroAmericanEnglishResponses[keyof PostFalAiKokoroAmericanEnglishResponses]

export type GetFalAiKokoroAmericanEnglishRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/american-english/requests/{request_id}'
}

export type GetFalAiKokoroAmericanEnglishRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKokoroAmericanEnglishOutput
}

export type GetFalAiKokoroAmericanEnglishRequestsByRequestIdResponse =
  GetFalAiKokoroAmericanEnglishRequestsByRequestIdResponses[keyof GetFalAiKokoroAmericanEnglishRequestsByRequestIdResponses]

export type GetFalAiZonosRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/zonos/requests/{request_id}/status'
}

export type GetFalAiZonosRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiZonosRequestsByRequestIdStatusResponse =
  GetFalAiZonosRequestsByRequestIdStatusResponses[keyof GetFalAiZonosRequestsByRequestIdStatusResponses]

export type PutFalAiZonosRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/zonos/requests/{request_id}/cancel'
}

export type PutFalAiZonosRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiZonosRequestsByRequestIdCancelResponse =
  PutFalAiZonosRequestsByRequestIdCancelResponses[keyof PutFalAiZonosRequestsByRequestIdCancelResponses]

export type PostFalAiZonosData = {
  body: SchemaZonosInput
  path?: never
  query?: never
  url: '/fal-ai/zonos'
}

export type PostFalAiZonosResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiZonosResponse =
  PostFalAiZonosResponses[keyof PostFalAiZonosResponses]

export type GetFalAiZonosRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/zonos/requests/{request_id}'
}

export type GetFalAiZonosRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaZonosOutput
}

export type GetFalAiZonosRequestsByRequestIdResponse =
  GetFalAiZonosRequestsByRequestIdResponses[keyof GetFalAiZonosRequestsByRequestIdResponses]

export type GetFalAiKokoroItalianRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kokoro/italian/requests/{request_id}/status'
}

export type GetFalAiKokoroItalianRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiKokoroItalianRequestsByRequestIdStatusResponse =
  GetFalAiKokoroItalianRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroItalianRequestsByRequestIdStatusResponses]

export type PutFalAiKokoroItalianRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/italian/requests/{request_id}/cancel'
}

export type PutFalAiKokoroItalianRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiKokoroItalianRequestsByRequestIdCancelResponse =
  PutFalAiKokoroItalianRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroItalianRequestsByRequestIdCancelResponses]

export type PostFalAiKokoroItalianData = {
  body: SchemaKokoroItalianInput
  path?: never
  query?: never
  url: '/fal-ai/kokoro/italian'
}

export type PostFalAiKokoroItalianResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKokoroItalianResponse =
  PostFalAiKokoroItalianResponses[keyof PostFalAiKokoroItalianResponses]

export type GetFalAiKokoroItalianRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/italian/requests/{request_id}'
}

export type GetFalAiKokoroItalianRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKokoroItalianOutput
}

export type GetFalAiKokoroItalianRequestsByRequestIdResponse =
  GetFalAiKokoroItalianRequestsByRequestIdResponses[keyof GetFalAiKokoroItalianRequestsByRequestIdResponses]

export type GetFalAiYueRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/yue/requests/{request_id}/status'
}

export type GetFalAiYueRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiYueRequestsByRequestIdStatusResponse =
  GetFalAiYueRequestsByRequestIdStatusResponses[keyof GetFalAiYueRequestsByRequestIdStatusResponses]

export type PutFalAiYueRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/yue/requests/{request_id}/cancel'
}

export type PutFalAiYueRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiYueRequestsByRequestIdCancelResponse =
  PutFalAiYueRequestsByRequestIdCancelResponses[keyof PutFalAiYueRequestsByRequestIdCancelResponses]

export type PostFalAiYueData = {
  body: SchemaYueInput
  path?: never
  query?: never
  url: '/fal-ai/yue'
}

export type PostFalAiYueResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiYueResponse =
  PostFalAiYueResponses[keyof PostFalAiYueResponses]

export type GetFalAiYueRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/yue/requests/{request_id}'
}

export type GetFalAiYueRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaYueOutput
}

export type GetFalAiYueRequestsByRequestIdResponse =
  GetFalAiYueRequestsByRequestIdResponses[keyof GetFalAiYueRequestsByRequestIdResponses]

export type GetFalAiMmaudioV2TextToAudioRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/mmaudio-v2/text-to-audio/requests/{request_id}/status'
}

export type GetFalAiMmaudioV2TextToAudioRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiMmaudioV2TextToAudioRequestsByRequestIdStatusResponse =
  GetFalAiMmaudioV2TextToAudioRequestsByRequestIdStatusResponses[keyof GetFalAiMmaudioV2TextToAudioRequestsByRequestIdStatusResponses]

export type PutFalAiMmaudioV2TextToAudioRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/mmaudio-v2/text-to-audio/requests/{request_id}/cancel'
}

export type PutFalAiMmaudioV2TextToAudioRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiMmaudioV2TextToAudioRequestsByRequestIdCancelResponse =
  PutFalAiMmaudioV2TextToAudioRequestsByRequestIdCancelResponses[keyof PutFalAiMmaudioV2TextToAudioRequestsByRequestIdCancelResponses]

export type PostFalAiMmaudioV2TextToAudioData = {
  body: SchemaMmaudioV2TextToAudioInput
  path?: never
  query?: never
  url: '/fal-ai/mmaudio-v2/text-to-audio'
}

export type PostFalAiMmaudioV2TextToAudioResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMmaudioV2TextToAudioResponse =
  PostFalAiMmaudioV2TextToAudioResponses[keyof PostFalAiMmaudioV2TextToAudioResponses]

export type GetFalAiMmaudioV2TextToAudioRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/mmaudio-v2/text-to-audio/requests/{request_id}'
}

export type GetFalAiMmaudioV2TextToAudioRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaMmaudioV2TextToAudioOutput
}

export type GetFalAiMmaudioV2TextToAudioRequestsByRequestIdResponse =
  GetFalAiMmaudioV2TextToAudioRequestsByRequestIdResponses[keyof GetFalAiMmaudioV2TextToAudioRequestsByRequestIdResponses]

export type GetFalAiMinimaxMusicRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/minimax-music/requests/{request_id}/status'
}

export type GetFalAiMinimaxMusicRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiMinimaxMusicRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxMusicRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxMusicRequestsByRequestIdStatusResponses]

export type PutFalAiMinimaxMusicRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax-music/requests/{request_id}/cancel'
}

export type PutFalAiMinimaxMusicRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiMinimaxMusicRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxMusicRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxMusicRequestsByRequestIdCancelResponses]

export type PostFalAiMinimaxMusicData = {
  body: SchemaMinimaxMusicInput
  path?: never
  query?: never
  url: '/fal-ai/minimax-music'
}

export type PostFalAiMinimaxMusicResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMinimaxMusicResponse =
  PostFalAiMinimaxMusicResponses[keyof PostFalAiMinimaxMusicResponses]

export type GetFalAiMinimaxMusicRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax-music/requests/{request_id}'
}

export type GetFalAiMinimaxMusicRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaMinimaxMusicOutput
}

export type GetFalAiMinimaxMusicRequestsByRequestIdResponse =
  GetFalAiMinimaxMusicRequestsByRequestIdResponses[keyof GetFalAiMinimaxMusicRequestsByRequestIdResponses]

export type GetFalAiF5TtsRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/f5-tts/requests/{request_id}/status'
}

export type GetFalAiF5TtsRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiF5TtsRequestsByRequestIdStatusResponse =
  GetFalAiF5TtsRequestsByRequestIdStatusResponses[keyof GetFalAiF5TtsRequestsByRequestIdStatusResponses]

export type PutFalAiF5TtsRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/f5-tts/requests/{request_id}/cancel'
}

export type PutFalAiF5TtsRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiF5TtsRequestsByRequestIdCancelResponse =
  PutFalAiF5TtsRequestsByRequestIdCancelResponses[keyof PutFalAiF5TtsRequestsByRequestIdCancelResponses]

export type PostFalAiF5TtsData = {
  body: SchemaF5TtsInput
  path?: never
  query?: never
  url: '/fal-ai/f5-tts'
}

export type PostFalAiF5TtsResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiF5TtsResponse =
  PostFalAiF5TtsResponses[keyof PostFalAiF5TtsResponses]

export type GetFalAiF5TtsRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/f5-tts/requests/{request_id}'
}

export type GetFalAiF5TtsRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaF5TtsOutput
}

export type GetFalAiF5TtsRequestsByRequestIdResponse =
  GetFalAiF5TtsRequestsByRequestIdResponses[keyof GetFalAiF5TtsRequestsByRequestIdResponses]

export type GetFalAiStableAudioRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/stable-audio/requests/{request_id}/status'
}

export type GetFalAiStableAudioRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiStableAudioRequestsByRequestIdStatusResponse =
  GetFalAiStableAudioRequestsByRequestIdStatusResponses[keyof GetFalAiStableAudioRequestsByRequestIdStatusResponses]

export type PutFalAiStableAudioRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/stable-audio/requests/{request_id}/cancel'
}

export type PutFalAiStableAudioRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiStableAudioRequestsByRequestIdCancelResponse =
  PutFalAiStableAudioRequestsByRequestIdCancelResponses[keyof PutFalAiStableAudioRequestsByRequestIdCancelResponses]

export type PostFalAiStableAudioData = {
  body: SchemaStableAudioInput
  path?: never
  query?: never
  url: '/fal-ai/stable-audio'
}

export type PostFalAiStableAudioResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiStableAudioResponse =
  PostFalAiStableAudioResponses[keyof PostFalAiStableAudioResponses]

export type GetFalAiStableAudioRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/stable-audio/requests/{request_id}'
}

export type GetFalAiStableAudioRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaStableAudioOutput
}

export type GetFalAiStableAudioRequestsByRequestIdResponse =
  GetFalAiStableAudioRequestsByRequestIdResponses[keyof GetFalAiStableAudioRequestsByRequestIdResponses]
