// This file is auto-generated by @hey-api/openapi-ts

export type ClientOptions = {
  baseUrl: `${string}://${string}` | (string & {})
}

export type File = {
  url: string
  content_type?: string
  file_name?: string
  file_size?: number
}

export type QueueStatus = {
  status: 'IN_PROGRESS' | 'COMPLETED' | 'FAILED'
  response_url?: string
}

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export type LoRaInput = {
  /**
   * Path
   *
   * URL, HuggingFace repo ID (owner/repo), or local path to LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   * Scale factor for LoRA application (0.0 to 4.0).
   */
  scale?: number
}

/**
 * Flux2EditImageLoRAOutput
 */
export type Flux2LoraEditOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The edited images
   */
  images: Array<ImageFile>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
}

/**
 * ImageFile
 */
export type ImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Flux2EditImageInput
 */
export type Flux2EditInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the image to generate. The width and height must be between 512 and 2048 pixels.
   */
  image_size?:
    | ImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Acceleration
   *
   * The acceleration level to use for the image generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * Guidance Scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number
  /**
   * Image URLs
   *
   * The URLs of the images for editing. A maximum of 4 images are allowed, if more are provided, only the first 4 will be used.
   */
  image_urls: Array<string>
  /**
   * Enable Prompt Expansion
   *
   * If set to true, the prompt will be expanded for better results.
   */
  enable_prompt_expansion?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type ImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Flux2EditImageOutput
 */
export type Flux2EditOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The edited images
   */
  images: Array<FalAiFlux2EditImageFile>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
}

/**
 * ImageFile
 */
export type FalAiFlux2EditImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Flux2ProImageEditInput
 */
export type Flux2ProEditInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Image Size
   *
   * The size of the generated image. If `auto`, the size will be determined by the model.
   */
  image_size?:
    | FalAiFlux2ProEditImageSize
    | 'auto'
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5'
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * The seed to use for the generation.
   */
  seed?: number
  /**
   * Image URLs
   *
   * List of URLs of input images for editing
   */
  image_urls: Array<string>
}

/**
 * ImageSize
 */
export type FalAiFlux2ProEditImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Flux2ProEditOutput
 */
export type Flux2ProEditOutput = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<FalAiFlux2ProEditImageFile>
  /**
   * Seed
   *
   * The seed used for the generation.
   */
  seed: number
}

/**
 * ImageFile
 */
export type FalAiFlux2ProEditImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * BaseImageToInput
 */
export type FluxDevImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Strength
   *
   * The strength of the initial image. Higher strength values are better for this model.
   */
  strength?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * Output
 */
export type FluxDevImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<Image>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type Image = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * Input
 */
export type AuraSrInput = {
  /**
   * Overlapping Tiles
   *
   * Whether to use overlapping tiles for upscaling. Setting this to true helps remove seams but doubles the inference time.
   */
  overlapping_tiles?: boolean
  /**
   * Checkpoint
   *
   * Checkpoint to use for upscaling. More coming soon.
   */
  checkpoint?: 'v1' | 'v2'
  /**
   * Upscaling Factor (Xs)
   *
   * Upscaling factor. More coming soon.
   */
  upscaling_factor?: 4
  /**
   * Image URL
   *
   * URL of the image to upscale.
   */
  image_url: string
}

/**
 * Output
 */
export type AuraSrOutput = {
  /**
   * Image
   *
   * Upscaled image
   */
  image: FalAiAuraSrImage
  /**
   * Timings
   *
   * Timings for each step in the pipeline.
   */
  timings: {
    [key: string]: number
  }
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiAuraSrImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Input
 */
export type ClarityUpscalerInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt?: string
  /**
   * Resemblance
   *
   *
   * The resemblance of the upscaled image to the original image. The higher the resemblance, the more the model will try to keep the original image.
   * Refers to the strength of the ControlNet.
   *
   */
  resemblance?: number
  /**
   * Creativity
   *
   *
   * The creativity of the model. The higher the creativity, the more the model will deviate from the prompt.
   * Refers to the denoise strength of the sampling.
   *
   */
  creativity?: number
  /**
   * Image Url
   *
   * The URL of the image to upscale.
   */
  image_url: string
  /**
   * Upscale Factor
   *
   * The upscale factor
   */
  upscale_factor?: number
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number | unknown
  /**
   * Negative Prompt
   *
   * The negative prompt to use. Use it to address details that you don't want in the image.
   */
  negative_prompt?: string
  /**
   * Enable Safety Checker
   *
   * If set to false, the safety checker will be disabled.
   */
  enable_safety_checker?: boolean
}

/**
 * Output
 */
export type ClarityUpscalerOutput = {
  /**
   * The URL of the generated image.
   */
  image: FalAiClarityUpscalerImage
  /**
   * Seed
   *
   * The seed used to generate the image.
   */
  seed: number
  /**
   * Timings
   *
   * The timings of the different steps in the workflow.
   */
  timings: {
    [key: string]: number
  }
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiClarityUpscalerImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * FaceSwapInputImage
 *
 * Input schema for image â†” image face swap
 */
export type AiFaceSwapFaceswapimageInput = {
  /**
   * Source Face Url
   *
   * Source face image
   */
  source_face_url: string
  /**
   * Target Image Url
   *
   * Target image URL
   */
  target_image_url: string
}

/**
 * FaceFusionImageOutput
 *
 * FaceFusion output payload when image content is generated
 */
export type AiFaceSwapFaceswapimageOutput = {
  image: HalfMoonAiAiFaceSwapFaceswapimageImage
  /**
   * Processing Time Ms
   *
   * Optional processing duration in milliseconds
   */
  processing_time_ms?: number | unknown
}

/**
 * Image
 *
 * Represents an image file.
 */
export type HalfMoonAiAiFaceSwapFaceswapimageImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * ReplaceObjectInput
 */
export type FiboEditReplaceObjectByTextInput = {
  /**
   * Instruction
   *
   * The full natural language command describing what to replace.
   */
  instruction: string
  /**
   * Image Url
   *
   * The source image.
   */
  image_url: string
}

/**
 * FiboEditExtraEPOutputModel
 */
export type FiboEditReplaceObjectByTextOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<BriaFiboEditReplaceObjectByTextImage>
  image: BriaFiboEditReplaceObjectByTextImage
  /**
   * Structured Instruction
   *
   * Current instruction.
   */
  structured_instruction: {
    [key: string]: unknown
  }
}

/**
 * Image
 *
 * Represents an image file.
 */
export type BriaFiboEditReplaceObjectByTextImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * SketchColoredImageInput
 */
export type FiboEditSketchToColoredImageInput = {
  /**
   * Image Url
   *
   * The source image.
   */
  image_url: string
}

/**
 * FiboEditExtraEPOutputModel
 */
export type FiboEditSketchToColoredImageOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<BriaFiboEditSketchToColoredImageImage>
  image: BriaFiboEditSketchToColoredImageImage
  /**
   * Structured Instruction
   *
   * Current instruction.
   */
  structured_instruction: {
    [key: string]: unknown
  }
}

/**
 * Image
 *
 * Represents an image file.
 */
export type BriaFiboEditSketchToColoredImageImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * RestoreInput
 */
export type FiboEditRestoreInput = {
  /**
   * Image Url
   *
   * The source image.
   */
  image_url: string
}

/**
 * FiboEditExtraEPOutputModel
 */
export type FiboEditRestoreOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<BriaFiboEditRestoreImage>
  image: BriaFiboEditRestoreImage
  /**
   * Structured Instruction
   *
   * Current instruction.
   */
  structured_instruction: {
    [key: string]: unknown
  }
}

/**
 * Image
 *
 * Represents an image file.
 */
export type BriaFiboEditRestoreImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * ReseasonInput
 */
export type FiboEditReseasonInput = {
  /**
   * Season
   *
   * The desired season.
   */
  season: 'spring' | 'summer' | 'autumn' | 'winter'
  /**
   * Image Url
   *
   * The source image.
   */
  image_url: string
}

/**
 * FiboEditExtraEPOutputModel
 */
export type FiboEditReseasonOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<BriaFiboEditReseasonImage>
  image: BriaFiboEditReseasonImage
  /**
   * Structured Instruction
   *
   * Current instruction.
   */
  structured_instruction: {
    [key: string]: unknown
  }
}

/**
 * Image
 *
 * Represents an image file.
 */
export type BriaFiboEditReseasonImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * RelightInput
 */
export type FiboEditRelightInput = {
  /**
   * Light Type
   *
   * The quality/style/time of day.
   */
  light_type:
    | 'midday'
    | 'blue hour light'
    | 'low-angle sunlight'
    | 'sunrise light'
    | 'spotlight on subject'
    | 'overcast light'
    | 'soft overcast daylight lighting'
    | 'cloud-filtered lighting'
    | 'fog-diffused lighting'
    | 'moonlight lighting'
    | 'starlight nighttime'
    | 'soft bokeh lighting'
    | 'harsh studio lighting'
  /**
   * Light Direction
   *
   * Where the light comes from.
   */
  light_direction: 'front' | 'side' | 'bottom' | 'top-down' | unknown
  /**
   * Image Url
   *
   * The source image.
   */
  image_url: string
}

/**
 * FiboEditExtraEPOutputModel
 */
export type FiboEditRelightOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<BriaFiboEditRelightImage>
  image: BriaFiboEditRelightImage
  /**
   * Structured Instruction
   *
   * Current instruction.
   */
  structured_instruction: {
    [key: string]: unknown
  }
}

/**
 * Image
 *
 * Represents an image file.
 */
export type BriaFiboEditRelightImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * RestyletInput
 */
export type FiboEditRestyleInput = {
  /**
   * Style
   *
   * Select the desired artistic style for the output image.
   */
  style:
    | '3D Render'
    | 'Cubism'
    | 'Oil Painting'
    | 'Anime'
    | 'Cartoon'
    | 'Coloring Book'
    | 'Retro Ad'
    | 'Pop Art Halftone'
    | 'Vector Art'
    | 'Story Board'
    | 'Art Nouveau'
    | 'Cross Etching'
    | 'Wood Cut'
  /**
   * Image Url
   *
   * The source image.
   */
  image_url: string
}

/**
 * FiboEditExtraEPOutputModel
 */
export type FiboEditRestyleOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<BriaFiboEditRestyleImage>
  image: BriaFiboEditRestyleImage
  /**
   * Structured Instruction
   *
   * Current instruction.
   */
  structured_instruction: {
    [key: string]: unknown
  }
}

/**
 * Image
 *
 * Represents an image file.
 */
export type BriaFiboEditRestyleImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * RewriteTextInput
 */
export type FiboEditRewriteTextInput = {
  /**
   * New Text
   *
   * The new text string to appear in the image.
   */
  new_text: string
  /**
   * Image Url
   *
   * The source image.
   */
  image_url: string
}

/**
 * FiboEditExtraEPOutputModel
 */
export type FiboEditRewriteTextOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<BriaFiboEditRewriteTextImage>
  image: BriaFiboEditRewriteTextImage
  /**
   * Structured Instruction
   *
   * Current instruction.
   */
  structured_instruction: {
    [key: string]: unknown
  }
}

/**
 * Image
 *
 * Represents an image file.
 */
export type BriaFiboEditRewriteTextImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * EraseByTextInput
 */
export type FiboEditEraseByTextInput = {
  /**
   * Object Name
   *
   * The name of the object to remove.
   */
  object_name: string
  /**
   * Image Url
   *
   * The source image.
   */
  image_url: string
}

/**
 * FiboEditExtraEPOutputModel
 */
export type FiboEditEraseByTextOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<BriaFiboEditEraseByTextImage>
  image: BriaFiboEditEraseByTextImage
  /**
   * Structured Instruction
   *
   * Current instruction.
   */
  structured_instruction: {
    [key: string]: unknown
  }
}

/**
 * Image
 *
 * Represents an image file.
 */
export type BriaFiboEditEraseByTextImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * FiboEditInputModel
 */
export type FiboEditEditInput = {
  /**
   * Steps Num
   *
   * Number of inference steps.
   */
  steps_num?: number
  /**
   * Instruction
   *
   * Instruction for image editing.
   */
  instruction?: string | unknown
  /**
   * Image Url
   *
   * Reference image (file or URL).
   */
  image_url?: string | unknown
  /**
   * Sync Mode
   *
   * If true, returns the image directly in the response (increases latency).
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * Guidance scale for text.
   */
  guidance_scale?: number | number
  /**
   * Seed
   *
   * Random seed for reproducibility.
   */
  seed?: number
  /**
   * Mask Url
   *
   * Mask image (file or URL). Optional
   */
  mask_url?: string | unknown
  /**
   * Negative Prompt
   *
   * Negative prompt for image generation.
   */
  negative_prompt?: string
  /**
   * The structured prompt to generate an image from.
   */
  structured_instruction?: StructuredInstruction | unknown
}

/**
 * StructuredInstruction
 */
export type StructuredInstruction = {
  /**
   * Background Setting
   *
   * The background setting of the image to be generated.
   */
  background_setting?: string | unknown
  /**
   * Artistic Style
   *
   * The artistic style of the image to be generated.
   */
  artistic_style?: string | unknown
  /**
   * The aesthetics of the image to be generated.
   */
  aesthetics?: Aesthetics | unknown
  /**
   * Text Render
   *
   * A list of text to be rendered in the image.
   */
  text_render?: Array<unknown> | unknown
  /**
   * Objects
   *
   * A list of objects in the image to be generated, along with their attributes and relationships to other objects in the image.
   */
  objects?: Array<PromptObject> | unknown
  /**
   * Context
   *
   * The context of the image to be generated.
   */
  context?: string | unknown
  /**
   * The photographic characteristics of the image to be generated.
   */
  photographic_characteristics?: PhotographicCharacteristics | unknown
  /**
   * Style Medium
   *
   * The style medium of the image to be generated.
   */
  style_medium?: string | unknown
  /**
   * The lighting of the image to be generated.
   */
  lighting?: Lighting | unknown
  /**
   * Short Description
   *
   * A short description of the image to be generated.
   */
  short_description?: string | unknown
  /**
   * Edit Instruction
   *
   * The edit instruction for the image.
   */
  edit_instruction?: string | unknown
}

/**
 * Aesthetics
 */
export type Aesthetics = {
  /**
   * Composition
   *
   * The composition of the image to be generated.
   */
  composition?: string | unknown
  /**
   * Mood Atmosphere
   *
   * The mood and atmosphere of the image to be generated.
   */
  mood_atmosphere?: string | unknown
  /**
   * Color Scheme
   *
   * The color scheme of the image to be generated.
   */
  color_scheme?: string | unknown
}

/**
 * PromptObject
 */
export type PromptObject = {
  /**
   * Relative Size
   *
   * The relative size of the object in the image.
   */
  relative_size?: string | unknown
  /**
   * Description
   *
   * A description of the object to be generated.
   */
  description?: string | unknown
  /**
   * Skin Tone And Texture
   *
   * The skin tone and texture of the object in the image.
   */
  skin_tone_and_texture?: string | unknown
  /**
   * Appearance Details
   *
   * The appearance details of the object.
   */
  appearance_details?: string | unknown
  /**
   * Number Of Objects
   *
   * The number of objects in the image.
   */
  number_of_objects?: number | unknown
  /**
   * Expression
   *
   * The expression of the object in the image.
   */
  expression?: string | unknown
  /**
   * Pose
   *
   * The pose of the object in the image.
   */
  pose?: string | unknown
  /**
   * Shape And Color
   *
   * The shape and color of the object.
   */
  shape_and_color?: string | unknown
  /**
   * Relationship
   *
   * The relationship of the object to other objects in the image.
   */
  relationship: string
  /**
   * Texture
   *
   * The texture of the object.
   */
  texture?: string | unknown
  /**
   * Gender
   *
   * The gender of the object in the image.
   */
  gender?: string | unknown
  /**
   * Clothing
   *
   * The clothing of the object in the image.
   */
  clothing?: string | unknown
  /**
   * Location
   *
   * The location of the object in the image.
   */
  location?: string | unknown
  /**
   * Orientation
   *
   * The orientation of the object in the image.
   */
  orientation?: string | unknown
  /**
   * Action
   *
   * The action of the object in the image.
   */
  action?: string | unknown
}

/**
 * PhotographicCharacteristics
 */
export type PhotographicCharacteristics = {
  /**
   * Focus
   *
   * The focus in the image to be generated.
   */
  focus?: string | unknown
  /**
   * Lens Focal Length
   *
   * The focal length of the lens in the image to be generated.
   */
  lens_focal_length?: string | unknown
  /**
   * Camera Angle
   *
   * The angle of the camera in the image to be generated.
   */
  camera_angle?: string | unknown
  /**
   * Depth Of Field
   *
   * The depth of field in the image to be generated.
   */
  depth_of_field?: string | unknown
}

/**
 * Lighting
 */
export type Lighting = {
  /**
   * Shadows
   *
   * The shadows in the image to be generated.
   */
  shadows?: string | unknown
  /**
   * Conditions
   *
   * The conditions of the lighting in the image to be generated.
   */
  conditions?: string | unknown
  /**
   * Direction
   *
   * The direction of the lighting in the image to be generated.
   */
  direction?: string | unknown
}

/**
 * FiboEditOutputModel
 */
export type FiboEditEditOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<BriaFiboEditEditImage>
  image: BriaFiboEditEditImage
  /**
   * Structured Instruction
   *
   * Current instruction.
   */
  structured_instruction: {
    [key: string]: unknown
  }
}

/**
 * Image
 *
 * Represents an image file.
 */
export type BriaFiboEditEditImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * AddObjectByTextInput
 */
export type FiboEditAddObjectByTextInput = {
  /**
   * Instruction
   *
   * The full natural language command describing what to add and where.
   */
  instruction: string
  /**
   * Image Url
   *
   * The source image.
   */
  image_url: string
}

/**
 * FiboEditExtraEPOutputModel
 */
export type FiboEditAddObjectByTextOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<BriaFiboEditAddObjectByTextImage>
  image: BriaFiboEditAddObjectByTextImage
  /**
   * Structured Instruction
   *
   * Current instruction.
   */
  structured_instruction: {
    [key: string]: unknown
  }
}

/**
 * Image
 *
 * Represents an image file.
 */
export type BriaFiboEditAddObjectByTextImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * BlendingInput
 */
export type FiboEditBlendInput = {
  /**
   * Instruction
   *
   * Instruct what elements you would like to blend in your image.
   */
  instruction: string
  /**
   * Image Url
   *
   * The source image.
   */
  image_url: string
}

/**
 * FiboEditExtraEPOutputModel
 */
export type FiboEditBlendOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<BriaFiboEditBlendImage>
  image: BriaFiboEditBlendImage
  /**
   * Structured Instruction
   *
   * Current instruction.
   */
  structured_instruction: {
    [key: string]: unknown
  }
}

/**
 * Image
 *
 * Represents an image file.
 */
export type BriaFiboEditBlendImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * ColorizeInput
 */
export type FiboEditColorizeInput = {
  /**
   * Color
   *
   * Select the color palette or aesthetic for the output image
   */
  color:
    | 'contemporary color'
    | 'vivid color'
    | 'black and white colors'
    | 'sepia vintage'
  /**
   * Image Url
   *
   * The source image.
   */
  image_url: string
}

/**
 * FiboEditExtraEPOutputModel
 */
export type FiboEditColorizeOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<BriaFiboEditColorizeImage>
  image: BriaFiboEditColorizeImage
  /**
   * Structured Instruction
   *
   * Current instruction.
   */
  structured_instruction: {
    [key: string]: unknown
  }
}

/**
 * Image
 *
 * Represents an image file.
 */
export type BriaFiboEditColorizeImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * LoRAInput
 */
export type FalAiFlux2KleinLoRaInput = {
  /**
   * Path
   *
   * URL, HuggingFace repo ID (owner/repo), or local path to LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   * Scale factor for LoRA application (0.0 to 4.0).
   */
  scale?: number
}

/**
 * KleinT2IOutput
 */
export type Flux2Klein9bBaseEditLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated images
   */
  images: Array<FalAiFlux2Klein9bBaseEditLoraImageFile>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * ImageFile
 */
export type FalAiFlux2Klein9bBaseEditLoraImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * LoRAInput
 */
export type FalAiFlux2Klein4bBaseEditLoraFalAiFlux2KleinLoRaInput = {
  /**
   * Path
   *
   * URL, HuggingFace repo ID (owner/repo), or local path to LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   * Scale factor for LoRA application (0.0 to 4.0).
   */
  scale?: number
}

/**
 * KleinT2IOutput
 */
export type Flux2Klein4bBaseEditLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated images
   */
  images: Array<FalAiFlux2Klein4bBaseEditLoraImageFile>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * ImageFile
 */
export type FalAiFlux2Klein4bBaseEditLoraImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Klein4BBaseEditInput
 */
export type Flux2Klein4bBaseEditInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, uses the input image size.
   */
  image_size?:
    | FalAiFlux2Klein4bBaseEditImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Acceleration
   *
   * The acceleration level to use for image generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Guidance Scale
   *
   * Guidance scale for classifier-free guidance.
   */
  guidance_scale?: number
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI. Output is not stored when this is True.
   */
  sync_mode?: boolean
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Image URLs
   *
   * The URLs of the images for editing. A maximum of 4 images are allowed.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * Negative prompt for classifier-free guidance. Describes what to avoid in the image.
   */
  negative_prompt?: string
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number
}

/**
 * ImageSize
 */
export type FalAiFlux2Klein4bBaseEditImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Klein4BBaseEditOutput
 */
export type Flux2Klein4bBaseEditOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The edited images
   */
  images: Array<FalAiFlux2Klein4bBaseEditImageFile>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * ImageFile
 */
export type FalAiFlux2Klein4bBaseEditImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Klein9BEditImageInput
 */
export type Flux2Klein9bBaseEditInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, uses the input image size.
   */
  image_size?:
    | FalAiFlux2Klein9bBaseEditImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Acceleration
   *
   * The acceleration level to use for image generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Guidance Scale
   *
   * Guidance scale for classifier-free guidance.
   */
  guidance_scale?: number
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI. Output is not stored when this is True.
   */
  sync_mode?: boolean
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Image URLs
   *
   * The URLs of the images for editing. A maximum of 4 images are allowed.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * Negative prompt for classifier-free guidance. Describes what to avoid in the image.
   */
  negative_prompt?: string
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number
}

/**
 * ImageSize
 */
export type FalAiFlux2Klein9bBaseEditImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Klein9BBaseEditOutput
 */
export type Flux2Klein9bBaseEditOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The edited images
   */
  images: Array<FalAiFlux2Klein9bBaseEditImageFile>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * ImageFile
 */
export type FalAiFlux2Klein9bBaseEditImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * KleinDistilledEditInput
 */
export type Flux2Klein4bEditInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, uses the input image size.
   */
  image_size?:
    | FalAiFlux2Klein4bEditImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI. Output is not stored when this is True.
   */
  sync_mode?: boolean
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Image URLs
   *
   * The URLs of the images for editing. A maximum of 4 images are allowed.
   */
  image_urls: Array<string>
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number
}

/**
 * ImageSize
 */
export type FalAiFlux2Klein4bEditImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Klein4BDistilledEditOutput
 */
export type Flux2Klein4bEditOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The edited images
   */
  images: Array<FalAiFlux2Klein4bEditImageFile>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * ImageFile
 */
export type FalAiFlux2Klein4bEditImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Klein9BDistilledEditInput
 */
export type Flux2Klein9bEditInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, uses the input image size.
   */
  image_size?:
    | FalAiFlux2Klein9bEditImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI. Output is not stored when this is True.
   */
  sync_mode?: boolean
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Image URLs
   *
   * The URLs of the images for editing. A maximum of 4 images are allowed.
   */
  image_urls: Array<string>
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number
}

/**
 * ImageSize
 */
export type FalAiFlux2Klein9bEditImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Klein9BDistilledEditOutput
 */
export type Flux2Klein9bEditOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The edited images
   */
  images: Array<FalAiFlux2Klein9bEditImageFile>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * ImageFile
 */
export type FalAiFlux2Klein9bEditImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * GlmImageToImageInput
 */
export type GlmImageImageToImageInput = {
  /**
   * Prompt
   *
   * Text prompt for image generation.
   */
  prompt: string
  /**
   * Num Images
   *
   * Number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * Output image size.
   */
  image_size?:
    | FalAiGlmImageImageToImageImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | 'portrait_3_2'
    | 'landscape_3_2'
    | 'portrait_hd'
    | 'landscape_hd'
  /**
   * Enable Safety Checker
   *
   * Enable NSFW safety checking on the generated images.
   */
  enable_safety_checker?: boolean
  /**
   * Output Format
   *
   * Output image format.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Sync Mode
   *
   * If True, the image will be returned as a base64 data URI instead of a URL.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * Classifier-free guidance scale. Higher values make the model follow the prompt more closely.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. The same seed with the same prompt will produce the same image.
   */
  seed?: number
  /**
   * Image Urls
   *
   * URL(s) of the condition image(s) for image-to-image generation. Supports up to 4 URLs for multi-image references.
   */
  image_urls: Array<string>
  /**
   * Enable Prompt Expansion
   *
   * If True, the prompt will be enhanced using an LLM for more detailed and higher quality results.
   */
  enable_prompt_expansion?: boolean
  /**
   * Num Inference Steps
   *
   * Number of diffusion denoising steps. More steps generally produce higher quality images.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiGlmImageImageToImageImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * GlmImageToImageOutput
 */
export type GlmImageImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * List of URLs to the generated images.
   */
  images: Array<FalAiGlmImageImageToImageImage>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
}

/**
 * Image
 */
export type FalAiGlmImageImageToImageImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * MultipleAnglesInput
 *
 * Input model for Multiple Angles endpoint - Camera control with precise adjustments using <sks> trigger word.
 * Prompt is built automatically from slider values.
 */
export type QwenImageEdit2511MultipleAnglesInput = {
  /**
   * Acceleration
   *
   * Acceleration level for image generation.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the input image will be used.
   */
  image_size?:
    | FalAiQwenImageEdit2511MultipleAnglesImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Horizontal Angle (Azimuth Â°)
   *
   * Horizontal rotation angle around the object in degrees. 0Â°=front view, 90Â°=right side, 180Â°=back view, 270Â°=left side, 360Â°=front view again.
   */
  horizontal_angle?: number
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale.
   */
  guidance_scale?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Image URLs
   *
   * The URL of the image to adjust camera angle for.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Zoom (Distance)
   *
   * Camera zoom/distance. 0=wide shot (far away), 5=medium shot (normal), 10=close-up (very close).
   */
  zoom?: number
  /**
   * Vertical Angle (Elevation Â°)
   *
   * Vertical camera angle in degrees. -30Â°=low-angle shot (looking up), 0Â°=eye-level, 30Â°=elevated, 60Â°=high-angle, 90Â°=bird's-eye view (looking down).
   */
  vertical_angle?: number
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the camera control effect.
   */
  lora_scale?: number
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Additional Prompt
   *
   * Additional text to append to the automatically generated prompt.
   */
  additional_prompt?: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI.
   */
  sync_mode?: boolean
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * Random seed for reproducibility.
   */
  seed?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEdit2511MultipleAnglesImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * MultipleAnglesOutput
 *
 * Output model for Multiple Angles endpoint
 */
export type QwenImageEdit2511MultipleAnglesOutput = {
  /**
   * Prompt
   *
   * The constructed prompt used for generation
   */
  prompt: string
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<FalAiQwenImageEdit2511MultipleAnglesImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiQwenImageEdit2511MultipleAnglesImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * EditImageLoraInput
 */
export type QwenImageEdit2511LoraInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image with.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If None, uses the input image dimensions.
   */
  image_size?:
    | FalAiQwenImageEdit2511LoraImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI.
   */
  sync_mode?: boolean
  /**
   * Loras
   *
   * The LoRAs to use for the image generation. You can use up to 3 LoRAs and they will be merged together to generate the final image.
   */
  loras?: Array<LoraWeight>
  /**
   * Guidance Scale
   *
   * The guidance scale to use for the image generation.
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Image URLs
   *
   * The URLs of the images to edit.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt to generate an image from.
   */
  negative_prompt?: string
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEdit2511LoraImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * LoraWeight
 */
export type LoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
}

/**
 * ImageToImageOutput
 */
export type QwenImageEdit2511LoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiQwenImageEdit2511LoraImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiQwenImageEdit2511LoraImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * ArchStyleInput
 */
export type AiHomeStyleInput = {
  /**
   * Input Image Url
   *
   * URL of the image to do architectural styling
   */
  input_image_url: string
  /**
   * Input Image Strength
   *
   * Strength of the input image
   */
  input_image_strength?: number
  /**
   * Additional Elements
   *
   * Additional elements to include in the options above (e.g., plants, lighting)
   */
  additional_elements?: string | unknown
  /**
   * Output Format
   *
   * The format of the generated image. Choose from: 'jpeg' or 'png'.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Style
   *
   * Style for furniture and decor
   */
  style:
    | 'minimalistic-interior'
    | 'farmhouse-interior'
    | 'luxury-interior'
    | 'modern-interior'
    | 'zen-interior'
    | 'mid century-interior'
    | 'airbnb-interior'
    | 'cozy-interior'
    | 'rustic-interior'
    | 'christmas-interior'
    | 'bohemian-interior'
    | 'tropical-interior'
    | 'industrial-interior'
    | 'japanese-interior'
    | 'vintage-interior'
    | 'loft-interior'
    | 'halloween-interior'
    | 'soho-interior'
    | 'baroque-interior'
    | 'kids room-interior'
    | 'girls room-interior'
    | 'boys room-interior'
    | 'scandinavian-interior'
    | 'french country-interior'
    | 'mediterranean-interior'
    | 'cyberpunk-interior'
    | 'hot pink-interior'
    | 'biophilic-interior'
    | 'ancient egypt-interior'
    | 'pixel-interior'
    | 'art deco-interior'
    | 'modern-exterior'
    | 'minimalistic-exterior'
    | 'farmhouse-exterior'
    | 'cozy-exterior'
    | 'luxury-exterior'
    | 'colonial-exterior'
    | 'zen-exterior'
    | 'asian-exterior'
    | 'creepy-exterior'
    | 'airstone-exterior'
    | 'ancient greek-exterior'
    | 'art deco-exterior'
    | 'brutalist-exterior'
    | 'christmas lights-exterior'
    | 'contemporary-exterior'
    | 'cottage-exterior'
    | 'dutch colonial-exterior'
    | 'federal colonial-exterior'
    | 'fire-exterior'
    | 'french provincial-exterior'
    | 'full glass-exterior'
    | 'georgian colonial-exterior'
    | 'gothic-exterior'
    | 'greek revival-exterior'
    | 'ice-exterior'
    | 'italianate-exterior'
    | 'mediterranean-exterior'
    | 'midcentury-exterior'
    | 'middle eastern-exterior'
    | 'minecraft-exterior'
    | 'morocco-exterior'
    | 'neoclassical-exterior'
    | 'spanish-exterior'
    | 'tudor-exterior'
    | 'underwater-exterior'
    | 'winter-exterior'
    | 'yard lighting-exterior'
  /**
   * Architecture Type
   *
   * Type of architecture for appropriate furniture selection
   */
  architecture_type:
    | 'living room-interior'
    | 'bedroom-interior'
    | 'kitchen-interior'
    | 'dining room-interior'
    | 'bathroom-interior'
    | 'laundry room-interior'
    | 'home office-interior'
    | 'study room-interior'
    | 'dorm room-interior'
    | 'coffee shop-interior'
    | 'gaming room-interior'
    | 'restaurant-interior'
    | 'office-interior'
    | 'attic-interior'
    | 'toilet-interior'
    | 'other-interior'
    | 'house-exterior'
    | 'villa-exterior'
    | 'backyard-exterior'
    | 'courtyard-exterior'
    | 'ranch-exterior'
    | 'office-exterior'
    | 'retail-exterior'
    | 'tower-exterior'
    | 'apartment-exterior'
    | 'school-exterior'
    | 'museum-exterior'
    | 'commercial-exterior'
    | 'residential-exterior'
    | 'other-exterior'
  /**
   * Color Palette
   *
   * Color palette for furniture and decor
   */
  color_palette:
    | 'surprise me'
    | 'golden beige'
    | 'refined blues'
    | 'dusky elegance'
    | 'emerald charm'
    | 'crimson luxury'
    | 'golden sapphire'
    | 'soft pastures'
    | 'candy sky'
    | 'peach meadow'
    | 'muted sands'
    | 'ocean breeze'
    | 'frosted pastels'
    | 'spring bloom'
    | 'gentle horizon'
    | 'seaside breeze'
    | 'azure coast'
    | 'golden shore'
    | 'mediterranean gem'
    | 'ocean serenity'
    | 'serene blush'
    | 'muted horizon'
    | 'pastel shores'
    | 'dusky calm'
    | 'woodland retreat'
    | 'meadow glow'
    | 'forest canopy'
    | 'riverbank calm'
    | 'earthy tones'
    | 'earthy neutrals'
    | 'arctic mist'
    | 'aqua drift'
    | 'blush bloom'
    | 'coral haze'
    | 'retro rust'
    | 'autumn glow'
    | 'rustic charm'
    | 'vintage sage'
    | 'faded plum'
    | 'electric lime'
    | 'violet pulse'
    | 'neon sorbet'
    | 'aqua glow'
    | 'fluorescent sunset'
    | 'lavender bloom'
    | 'petal fresh'
    | 'meadow light'
    | 'sunny pastures'
    | 'frosted mauve'
    | 'snowy hearth'
    | 'icy blues'
    | 'winter twilight'
    | 'earthy hues'
    | 'stone balance'
    | 'neutral sands'
    | 'slate shades'
  /**
   * Style Image Url
   *
   * URL of the style image, optional. If given, other parameters are ignored
   */
  style_image_url?: string | unknown
  /**
   * Custom Prompt
   *
   * Custom prompt for architectural editing, it overrides above options when used
   */
  custom_prompt?: string
  /**
   * Enhanced Rendering
   *
   * It gives better rendering quality with more processing time, additional cost is 0.01 USD per image
   */
  enhanced_rendering?: boolean | unknown
}

/**
 * ArchStyleOutput
 */
export type AiHomeStyleOutput = {
  image: HalfMoonAiAiHomeStyleImage
  /**
   * Status
   *
   * Status message with processing details
   */
  status: string
}

/**
 * Image
 *
 * Represents an image file.
 */
export type HalfMoonAiAiHomeStyleImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * ArchEditInput
 */
export type AiHomeEditInput = {
  /**
   * Input Image Url
   *
   * URL of the image to do architectural editing
   */
  input_image_url: string
  /**
   * Editing Type
   *
   * Type of editing. Structural editing only edits structural elements such as windows, walls etc. Virtual staging edits your furniture. Both do full editing including structural and furniture
   */
  editing_type: 'structural editing' | 'virtual staging' | 'both'
  /**
   * Style
   *
   * Style for furniture and decor
   */
  style:
    | 'minimalistic-interior'
    | 'farmhouse-interior'
    | 'luxury-interior'
    | 'modern-interior'
    | 'zen-interior'
    | 'mid century-interior'
    | 'airbnb-interior'
    | 'cozy-interior'
    | 'rustic-interior'
    | 'christmas-interior'
    | 'bohemian-interior'
    | 'tropical-interior'
    | 'industrial-interior'
    | 'japanese-interior'
    | 'vintage-interior'
    | 'loft-interior'
    | 'halloween-interior'
    | 'soho-interior'
    | 'baroque-interior'
    | 'kids room-interior'
    | 'girls room-interior'
    | 'boys room-interior'
    | 'scandinavian-interior'
    | 'french country-interior'
    | 'mediterranean-interior'
    | 'cyberpunk-interior'
    | 'hot pink-interior'
    | 'biophilic-interior'
    | 'ancient egypt-interior'
    | 'pixel-interior'
    | 'art deco-interior'
    | 'modern-exterior'
    | 'minimalistic-exterior'
    | 'farmhouse-exterior'
    | 'cozy-exterior'
    | 'luxury-exterior'
    | 'colonial-exterior'
    | 'zen-exterior'
    | 'asian-exterior'
    | 'creepy-exterior'
    | 'airstone-exterior'
    | 'ancient greek-exterior'
    | 'art deco-exterior'
    | 'brutalist-exterior'
    | 'christmas lights-exterior'
    | 'contemporary-exterior'
    | 'cottage-exterior'
    | 'dutch colonial-exterior'
    | 'federal colonial-exterior'
    | 'fire-exterior'
    | 'french provincial-exterior'
    | 'full glass-exterior'
    | 'georgian colonial-exterior'
    | 'gothic-exterior'
    | 'greek revival-exterior'
    | 'ice-exterior'
    | 'italianate-exterior'
    | 'mediterranean-exterior'
    | 'midcentury-exterior'
    | 'middle eastern-exterior'
    | 'minecraft-exterior'
    | 'morocco-exterior'
    | 'neoclassical-exterior'
    | 'spanish-exterior'
    | 'tudor-exterior'
    | 'underwater-exterior'
    | 'winter-exterior'
    | 'yard lighting-exterior'
  /**
   * Additional Elements
   *
   * Additional elements to include in the options above (e.g., plants, lighting)
   */
  additional_elements?: string | unknown
  /**
   * Output Format
   *
   * The format of the generated image. Choose from: 'jpeg' or 'png'.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Architecture Type
   *
   * Type of architecture for appropriate furniture selection
   */
  architecture_type:
    | 'living room-interior'
    | 'bedroom-interior'
    | 'kitchen-interior'
    | 'dining room-interior'
    | 'bathroom-interior'
    | 'laundry room-interior'
    | 'home office-interior'
    | 'study room-interior'
    | 'dorm room-interior'
    | 'coffee shop-interior'
    | 'gaming room-interior'
    | 'restaurant-interior'
    | 'office-interior'
    | 'attic-interior'
    | 'toilet-interior'
    | 'other-interior'
    | 'house-exterior'
    | 'villa-exterior'
    | 'backyard-exterior'
    | 'courtyard-exterior'
    | 'ranch-exterior'
    | 'office-exterior'
    | 'retail-exterior'
    | 'tower-exterior'
    | 'apartment-exterior'
    | 'school-exterior'
    | 'museum-exterior'
    | 'commercial-exterior'
    | 'residential-exterior'
    | 'other-exterior'
  /**
   * Color Palette
   *
   * Color palette for furniture and decor
   */
  color_palette:
    | 'surprise me'
    | 'golden beige'
    | 'refined blues'
    | 'dusky elegance'
    | 'emerald charm'
    | 'crimson luxury'
    | 'golden sapphire'
    | 'soft pastures'
    | 'candy sky'
    | 'peach meadow'
    | 'muted sands'
    | 'ocean breeze'
    | 'frosted pastels'
    | 'spring bloom'
    | 'gentle horizon'
    | 'seaside breeze'
    | 'azure coast'
    | 'golden shore'
    | 'mediterranean gem'
    | 'ocean serenity'
    | 'serene blush'
    | 'muted horizon'
    | 'pastel shores'
    | 'dusky calm'
    | 'woodland retreat'
    | 'meadow glow'
    | 'forest canopy'
    | 'riverbank calm'
    | 'earthy tones'
    | 'earthy neutrals'
    | 'arctic mist'
    | 'aqua drift'
    | 'blush bloom'
    | 'coral haze'
    | 'retro rust'
    | 'autumn glow'
    | 'rustic charm'
    | 'vintage sage'
    | 'faded plum'
    | 'electric lime'
    | 'violet pulse'
    | 'neon sorbet'
    | 'aqua glow'
    | 'fluorescent sunset'
    | 'lavender bloom'
    | 'petal fresh'
    | 'meadow light'
    | 'sunny pastures'
    | 'frosted mauve'
    | 'snowy hearth'
    | 'icy blues'
    | 'winter twilight'
    | 'earthy hues'
    | 'stone balance'
    | 'neutral sands'
    | 'slate shades'
  /**
   * Custom Prompt
   *
   * Custom prompt for architectural editing, it overrides above options when used
   */
  custom_prompt?: string
}

/**
 * ArchEditOutput
 */
export type AiHomeEditOutput = {
  image: HalfMoonAiAiHomeEditImage
  /**
   * Status
   *
   * Status message with processing details
   */
  status: string
}

/**
 * Image
 *
 * Represents an image file.
 */
export type HalfMoonAiAiHomeEditImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export type FalAiQwenImageLayeredLoraLoRaInput = {
  /**
   * Path
   *
   * URL, HuggingFace repo ID (owner/repo) to lora weights.
   */
  path: string
  /**
   * Scale
   *
   * Scale factor for LoRA application (0.0 to 4.0).
   */
  scale?: number
}

/**
 * QwenImageLayeredOutput
 */
export type QwenImageLayeredLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used to generate the image.
   */
  prompt?: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiQwenImageLayeredLoraImageFile>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * ImageFile
 */
export type FalAiQwenImageLayeredLoraImageFile = {
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageEditInput
 *
 * Input for Wan 2.6 image editing with reference images (enable_interleave=false)
 */
export type V26ImageToImageInput = {
  /**
   * Prompt
   *
   * Text prompt describing the desired image. Supports Chinese and English. Max 2000 characters. Example: 'Generate an image using the style of image 1 and background of image 2'.
   */
  prompt: string
  /**
   * Num Images
   *
   * Number of images to generate (1-4). Directly affects billing cost.
   */
  num_images?: number
  /**
   * Image Size
   *
   * Output image size. Use presets like 'square_hd', 'landscape_16_9', 'portrait_9_16', or specify exact dimensions with ImageSize(width=1280, height=720). Total pixels must be between 768*768 and 1280*1280.
   */
  image_size?:
    | WanV26ImageToImageImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Enable Prompt Expansion
   *
   * Enable LLM prompt optimization. Significantly improves results for simple prompts but adds 3-4 seconds processing time.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility (0-2147483647). Same seed produces more consistent results.
   */
  seed?: number
  /**
   * Image Urls
   *
   * Reference images for editing (1-3 images required). Order matters: reference as 'image 1', 'image 2', 'image 3' in prompt. Resolution: 384-5000px each dimension. Max size: 10MB each. Formats: JPEG, JPG, PNG (no alpha), BMP, WEBP.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * Content to avoid in the generated image. Max 500 characters.
   */
  negative_prompt?: string
  /**
   * Enable Safety Checker
   *
   * Enable content moderation for input and output.
   */
  enable_safety_checker?: boolean
}

/**
 * ImageSize
 */
export type WanV26ImageToImageImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * ImageEditOutput
 *
 * Output for Wan 2.6 image editing
 */
export type V26ImageToImageOutput = {
  /**
   * Images
   *
   * Generated images in PNG format
   */
  images: Array<WanV26ImageToImageFile>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * File
 */
export type WanV26ImageToImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * EditImageInput
 */
export type QwenImageEdit2511Input = {
  /**
   * Prompt
   *
   * The prompt to edit the image with.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If None, uses the input image dimensions.
   */
  image_size?:
    | FalAiQwenImageEdit2511ImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The guidance scale to use for the image generation.
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Image URLs
   *
   * The URLs of the images to edit.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt to generate an image from.
   */
  negative_prompt?: string
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEdit2511ImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * ImageToImageOutput
 */
export type QwenImageEdit2511Output = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiQwenImageEdit2511Image>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiQwenImageEdit2511Image = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * TextToImageInput
 */
export type QwenImageLayeredInput = {
  /**
   * Prompt
   *
   * A caption for the input image.
   */
  prompt?: string
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Num Layers
   *
   * The number of layers to generate.
   */
  num_layers?: number
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'png' | 'webp'
  /**
   * Image URL
   *
   * The URL of the input image.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Guidance Scale
   *
   * The guidance scale to use for the image generation.
   */
  guidance_scale?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to generate an image from.
   */
  negative_prompt?: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
}

/**
 * QwenImageLayeredOutput
 */
export type QwenImageLayeredOutput = {
  /**
   * Prompt
   *
   * The prompt used to generate the image.
   */
  prompt?: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiQwenImageLayeredImageFile>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * ImageFile
 */
export type FalAiQwenImageLayeredImageFile = {
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export type FalAiZImageTurboInpaintLoraLoRaInput = {
  /**
   * Path
   *
   * URL, HuggingFace repo ID (owner/repo) to lora weights.
   */
  path: string
  /**
   * Scale
   *
   * Scale factor for LoRA application (0.0 to 4.0).
   */
  scale?: number
}

/**
 * ZImageTurboInpaintOutput
 */
export type ZImageTurboInpaintLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiZImageTurboInpaintLoraImageFile>
  /**
   * Timings
   *
   * The timings of the generation process.
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   * Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.
   */
  seed: number
}

/**
 * ImageFile
 */
export type FalAiZImageTurboInpaintLoraImageFile = {
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ZImageTurboInpaintInput
 */
export type ZImageTurboInpaintInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiZImageTurboInpaintImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | 'auto'
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Mask Image URL
   *
   * URL of Mask for Inpaint generation.
   */
  mask_image_url: string
  /**
   * Control End
   *
   * The end of the controlnet conditioning.
   */
  control_end?: number
  /**
   * Control Start
   *
   * The start of the controlnet conditioning.
   */
  control_start?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Image URL
   *
   * URL of Image for Inpaint generation.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Strength
   *
   * The strength of the inpaint conditioning.
   */
  strength?: number
  /**
   * Control Scale
   *
   * The scale of the controlnet conditioning.
   */
  control_scale?: number
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. Note: this will increase the price by 0.0025 credits per request.
   */
  enable_prompt_expansion?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
}

/**
 * ImageSize
 */
export type FalAiZImageTurboInpaintImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * ZImageTurboInpaintOutput
 */
export type ZImageTurboInpaintOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiZImageTurboInpaintImageFile>
  /**
   * Timings
   *
   * The timings of the generation process.
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   * Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.
   */
  seed: number
}

/**
 * ImageFile
 */
export type FalAiZImageTurboInpaintImageFile = {
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Flux2FlashEditImageInput
 */
export type Flux2FlashEditInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the image to generate. The width and height must be between 512 and 2048 pixels.
   */
  image_size?:
    | FalAiFlux2FlashEditImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * Guidance Scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number
  /**
   * Image URLs
   *
   * The URLs of the images for editing. A maximum of 4 images are allowed, if more are provided, only the first 4 will be used.
   */
  image_urls: Array<string>
  /**
   * Enable Prompt Expansion
   *
   * If set to true, the prompt will be expanded for better results.
   */
  enable_prompt_expansion?: boolean
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
}

/**
 * ImageSize
 */
export type FalAiFlux2FlashEditImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Flux2FlashEditImageOutput
 */
export type Flux2FlashEditOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The edited images
   */
  images: Array<FalAiFlux2FlashEditImageFile>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
}

/**
 * ImageFile
 */
export type FalAiFlux2FlashEditImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * EditImageRequest
 */
export type GptImage15EditInput = {
  /**
   * Input Fidelity
   *
   * Input fidelity for the generated image
   */
  input_fidelity?: 'low' | 'high'
  /**
   * Number of Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * Aspect ratio for the generated image
   */
  image_size?: 'auto' | '1024x1024' | '1536x1024' | '1024x1536'
  /**
   * Prompt
   *
   * The prompt for image generation
   */
  prompt: string
  /**
   * Quality
   *
   * Quality for the generated image
   */
  quality?: 'low' | 'medium' | 'high'
  /**
   * Output Format
   *
   * Output format for the images
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Background
   *
   * Background for the generated image
   */
  background?: 'auto' | 'transparent' | 'opaque'
  /**
   * Mask Image URL
   *
   * The URL of the mask image to use for the generation. This indicates what part of the image to edit.
   */
  mask_image_url?: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Image URLs
   *
   * The URLs of the images to use as a reference for the generation.
   */
  image_urls: Array<string>
}

/**
 * EditImageResponse
 */
export type GptImage15EditOutput = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<FalAiGptImage15EditImageFile>
}

/**
 * ImageFile
 */
export type FalAiGptImage15EditImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Flux2TurboEditImageInput
 */
export type Flux2TurboEditInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the image to generate. The width and height must be between 512 and 2048 pixels.
   */
  image_size?:
    | FalAiFlux2TurboEditImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * Guidance Scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number
  /**
   * Image URLs
   *
   * The URLs of the images for editing. A maximum of 4 images are allowed, if more are provided, only the first 4 will be used.
   */
  image_urls: Array<string>
  /**
   * Enable Prompt Expansion
   *
   * If set to true, the prompt will be expanded for better results.
   */
  enable_prompt_expansion?: boolean
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
}

/**
 * ImageSize
 */
export type FalAiFlux2TurboEditImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Flux2TurboEditImageOutput
 */
export type Flux2TurboEditOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The edited images
   */
  images: Array<FalAiFlux2TurboEditImageFile>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
}

/**
 * ImageFile
 */
export type FalAiFlux2TurboEditImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Flux2MaxImageEditInput
 */
export type Flux2MaxEditInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Image Size
   *
   * The size of the generated image. If `auto`, the size will be determined by the model.
   */
  image_size?:
    | FalAiFlux2MaxEditImageSize
    | 'auto'
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5'
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * The seed to use for the generation.
   */
  seed?: number
  /**
   * Image URLs
   *
   * List of URLs of input images for editing
   */
  image_urls: Array<string>
}

/**
 * ImageSize
 */
export type FalAiFlux2MaxEditImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Flux2MaxEditOutput
 */
export type Flux2MaxEditOutput = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<FalAiFlux2MaxEditImageFile>
  /**
   * Seed
   *
   * The seed used for the generation.
   */
  seed: number
}

/**
 * ImageFile
 */
export type FalAiFlux2MaxEditImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * MultiFluxIDInput
 *
 * Input schema for multi mode generation
 */
export type AiBabyAndAgingGeneratorMultiInput = {
  /**
   * Prompt
   *
   * Text prompt to guide the image generation
   */
  prompt?: string
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image
   */
  image_size?:
    | HalfMoonAiAiBabyAndAgingGeneratorMultiImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Father Weight
   *
   * Weight of the father's influence in multi mode generation
   */
  father_weight?: number
  /**
   * Mother Image Urls
   *
   * List of mother images for multi mode
   */
  mother_image_urls: Array<string>
  /**
   * Output Format
   *
   * The format of the generated image. Choose from: 'jpeg' or 'png'.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Age Group
   *
   * Age group for the generated image. Choose from: 'baby' (0-12 months), 'toddler' (1-3 years), 'preschool' (3-5 years), 'gradeschooler' (6-12 years), 'teen' (13-19 years), 'adult' (20-40 years), 'mid' (40-60 years), 'senior' (60+ years).
   */
  age_group:
    | 'baby'
    | 'toddler'
    | 'preschool'
    | 'gradeschooler'
    | 'teen'
    | 'adult'
    | 'mid'
    | 'senior'
  /**
   * Gender
   *
   * Gender for the generated image. Choose from: 'male' or 'female'.
   */
  gender: 'male' | 'female'
  /**
   * Father Image Urls
   *
   * List of father images for multi mode
   */
  father_image_urls: Array<string>
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed will be used
   */
  seed?: number | unknown
}

/**
 * ImageSize
 */
export type HalfMoonAiAiBabyAndAgingGeneratorMultiImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * FluxMultiIDOutput
 */
export type AiBabyAndAgingGeneratorMultiOutput = {
  /**
   * Prompt
   *
   * The final prompt used for generation
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info
   */
  images: Array<HalfMoonAiAiBabyAndAgingGeneratorMultiImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type HalfMoonAiAiBabyAndAgingGeneratorMultiImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * SingleFluxIDInput
 *
 * Input schema for single mode generation
 */
export type AiBabyAndAgingGeneratorSingleInput = {
  /**
   * Prompt
   *
   * Text prompt to guide the image generation
   */
  prompt?: string
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image
   */
  image_size?:
    | HalfMoonAiAiBabyAndAgingGeneratorSingleImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Id Image Urls
   *
   * List of ID images for single mode (or general reference images)
   */
  id_image_urls: Array<string>
  /**
   * Output Format
   *
   * The format of the generated image. Choose from: 'jpeg' or 'png'.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Age Group
   *
   * Age group for the generated image. Choose from: 'baby' (0-12 months), 'toddler' (1-3 years), 'preschool' (3-5 years), 'gradeschooler' (6-12 years), 'teen' (13-19 years), 'adult' (20-40 years), 'mid' (40-60 years), 'senior' (60+ years).
   */
  age_group:
    | 'baby'
    | 'toddler'
    | 'preschool'
    | 'gradeschooler'
    | 'teen'
    | 'adult'
    | 'mid'
    | 'senior'
  /**
   * Gender
   *
   * Gender for the generated image. Choose from: 'male' or 'female'.
   */
  gender: 'male' | 'female'
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed will be used
   */
  seed?: number | unknown
}

/**
 * ImageSize
 */
export type HalfMoonAiAiBabyAndAgingGeneratorSingleImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * FluxSingleIDOutput
 */
export type AiBabyAndAgingGeneratorSingleOutput = {
  /**
   * Prompt
   *
   * The final prompt used for generation
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info
   */
  images: Array<HalfMoonAiAiBabyAndAgingGeneratorSingleImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type HalfMoonAiAiBabyAndAgingGeneratorSingleImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * ShirtDesignInput
 *
 * Input model for Shirt Design endpoint - Put designs/graphics on people's shirts
 */
export type QwenImageEdit2509LoraGalleryShirtDesignInput = {
  /**
   * Prompt
   *
   * Describe what design to put on the shirt. The model will apply the design from your input image onto the person's shirt.
   */
  prompt?: string
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | FalAiQwenImageEdit2509LoraGalleryShirtDesignImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown
  /**
   * Image URLs
   *
   * The URLs of the images: first image is the person wearing a shirt, second image is the design/logo to put on the shirt.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEdit2509LoraGalleryShirtDesignImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * ShirtDesignOutput
 */
export type QwenImageEdit2509LoraGalleryShirtDesignOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<FalAiQwenImageEdit2509LoraGalleryShirtDesignImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiQwenImageEdit2509LoraGalleryShirtDesignImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * RemoveLightingInput
 *
 * Input model for Remove Lighting endpoint - Remove existing lighting and apply soft even lighting
 */
export type QwenImageEdit2509LoraGalleryRemoveLightingInput = {
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | FalAiQwenImageEdit2509LoraGalleryRemoveLightingImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown
  /**
   * Image URLs
   *
   * The URL of the image with lighting/shadows to remove.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEdit2509LoraGalleryRemoveLightingImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * RemoveLightingOutput
 */
export type QwenImageEdit2509LoraGalleryRemoveLightingOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<FalAiQwenImageEdit2509LoraGalleryRemoveLightingImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiQwenImageEdit2509LoraGalleryRemoveLightingImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * RemoveElementInput
 *
 * Input model for Remove Element endpoint - Remove/delete elements (objects, people, text) from the image
 */
export type QwenImageEdit2509LoraGalleryRemoveElementInput = {
  /**
   * Prompt
   *
   * Specify what element(s) to remove from the image (objects, people, text, etc.). The model will cleanly remove the element while maintaining consistency of the rest of the image.
   */
  prompt?: string
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | FalAiQwenImageEdit2509LoraGalleryRemoveElementImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown
  /**
   * Image URLs
   *
   * The URL of the image containing elements to remove.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEdit2509LoraGalleryRemoveElementImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * RemoveElementOutput
 */
export type QwenImageEdit2509LoraGalleryRemoveElementOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<FalAiQwenImageEdit2509LoraGalleryRemoveElementImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiQwenImageEdit2509LoraGalleryRemoveElementImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * LightingRestorationInput
 *
 * Input model for Lighting Restoration endpoint - Restore natural lighting by removing harsh shadows and light spots
 */
export type QwenImageEdit2509LoraGalleryLightingRestorationInput = {
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | FalAiQwenImageEdit2509LoraGalleryLightingRestorationImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown
  /**
   * Image URLs
   *
   * The URL of the image to restore lighting for.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEdit2509LoraGalleryLightingRestorationImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * LightingRestorationOutput
 */
export type QwenImageEdit2509LoraGalleryLightingRestorationOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<FalAiQwenImageEdit2509LoraGalleryLightingRestorationImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiQwenImageEdit2509LoraGalleryLightingRestorationImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * IntegrateProductInput
 *
 * Input model for Integrate Product endpoint - Blend and integrate products/elements into backgrounds
 */
export type QwenImageEdit2509LoraGalleryIntegrateProductInput = {
  /**
   * Prompt
   *
   * Describe how to blend and integrate the product/element into the background. The model will automatically correct perspective, lighting and shadows for natural integration.
   */
  prompt?: string
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | FalAiQwenImageEdit2509LoraGalleryIntegrateProductImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown
  /**
   * Image URLs
   *
   * The URL of the image with product to integrate into background.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEdit2509LoraGalleryIntegrateProductImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * IntegrateProductOutput
 */
export type QwenImageEdit2509LoraGalleryIntegrateProductOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<FalAiQwenImageEdit2509LoraGalleryIntegrateProductImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiQwenImageEdit2509LoraGalleryIntegrateProductImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * GroupPhotoInput
 *
 * Input model for Group Photo endpoint - Create composite group photos with vintage/retro style
 */
export type QwenImageEdit2509LoraGalleryGroupPhotoInput = {
  /**
   * Prompt
   *
   * Describe the group photo scene, setting, and style. The model will maintain character consistency and add vintage effects like grain, blur, and retro filters.
   */
  prompt?: string
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | FalAiQwenImageEdit2509LoraGalleryGroupPhotoImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown
  /**
   * Image URLs
   *
   * The URLs of the images to combine into a group photo. Provide 2 or more individual portrait images.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEdit2509LoraGalleryGroupPhotoImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * GroupPhotoOutput
 */
export type QwenImageEdit2509LoraGalleryGroupPhotoOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<FalAiQwenImageEdit2509LoraGalleryGroupPhotoImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiQwenImageEdit2509LoraGalleryGroupPhotoImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * FaceToFullPortraitInput
 *
 * Input model for Face to Full Portrait endpoint - Generate full portrait from a cropped face image
 */
export type QwenImageEdit2509LoraGalleryFaceToFullPortraitInput = {
  /**
   * Prompt
   *
   * Describe the full portrait you want to generate from the face. Include clothing, setting, pose, and style details.
   */
  prompt?: string
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | FalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown
  /**
   * Image URLs
   *
   * The URL of the cropped face image. Provide a close-up face photo.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * FaceToFullPortraitOutput
 */
export type QwenImageEdit2509LoraGalleryFaceToFullPortraitOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<FalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * AddBackgroundInput
 *
 * Input model for Add Background endpoint - Remove white background and add a realistic scene
 */
export type QwenImageEdit2509LoraGalleryAddBackgroundInput = {
  /**
   * Prompt
   *
   * Describe the background/scene you want to add behind the object. The model will remove the white background and add the specified environment.
   */
  prompt?: string
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | FalAiQwenImageEdit2509LoraGalleryAddBackgroundImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown
  /**
   * Image URLs
   *
   * The URLs of the images to edit. Provide an image with a white or clean background.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEdit2509LoraGalleryAddBackgroundImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * AddBackgroundOutput
 */
export type QwenImageEdit2509LoraGalleryAddBackgroundOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<FalAiQwenImageEdit2509LoraGalleryAddBackgroundImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiQwenImageEdit2509LoraGalleryAddBackgroundImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * NextSceneInput
 *
 * Input model for Next Scene endpoint - Create cinematic shot progressions and scene transitions
 */
export type QwenImageEdit2509LoraGalleryNextSceneInput = {
  /**
   * Prompt
   *
   * Describe the camera movement, framing change, or scene transition. Start with 'Next Scene:' for best results. Examples: camera movements (dolly, push-in, pull-back), framing changes (wide to close-up), new elements entering frame.
   */
  prompt?: string
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | FalAiQwenImageEdit2509LoraGalleryNextSceneImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown
  /**
   * Image URLs
   *
   * The URL of the image to create the next scene from.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEdit2509LoraGalleryNextSceneImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * NextSceneOutput
 */
export type QwenImageEdit2509LoraGalleryNextSceneOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<FalAiQwenImageEdit2509LoraGalleryNextSceneImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiQwenImageEdit2509LoraGalleryNextSceneImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * MultipleAnglesInput
 *
 * Input model for Multiple Angles endpoint - Camera control with precise adjustments
 */
export type QwenImageEdit2509LoraGalleryMultipleAnglesInput = {
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | FalAiQwenImageEdit2509LoraGalleryMultipleAnglesImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Wide-Angle Lens
   *
   * Enable wide-angle lens effect
   */
  wide_angle_lens?: boolean
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
  /**
   * Image URLs
   *
   * The URL of the image to adjust camera angle for.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Vertical Angle (Bird â¬„ Worm)
   *
   * Adjust vertical camera angle (-1=bird's-eye view/looking down, 0=neutral, 1=worm's-eye view/looking up)
   */
  vertical_angle?: number
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Move Forward â†’ Close-Up
   *
   * Move camera forward (0=no movement, 10=close-up)
   */
  move_forward?: number
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Rotate Right-Left (degrees Â°)
   *
   * Rotate camera left (positive) or right (negative) in degrees. Positive values rotate left, negative values rotate right.
   */
  rotate_right_left?: number
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the camera control effect.
   */
  lora_scale?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEdit2509LoraGalleryMultipleAnglesImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * MultipleAnglesOutput
 */
export type QwenImageEdit2509LoraGalleryMultipleAnglesOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<FalAiQwenImageEdit2509LoraGalleryMultipleAnglesImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiQwenImageEdit2509LoraGalleryMultipleAnglesImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * BaseQwenEditImagePlusLoRAInput
 */
export type QwenImageEdit2509LoraInput = {
  /**
   * Prompt
   *
   * The prompt to generate the image with
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used to calculate the size of the output image.
   */
  image_size?:
    | FalAiQwenImageEdit2509LoraImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Acceleration
   *
   * Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use up to 3 LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<FalAiQwenImageEdit2509LoraLoraWeight>
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Guidance scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Image URLs
   *
   * The URLs of the images to edit.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEdit2509LoraImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * LoraWeight
 */
export type FalAiQwenImageEdit2509LoraLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
}

/**
 * QwenImageOutput
 */
export type QwenImageEdit2509LoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiQwenImageEdit2509LoraImage>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
}

/**
 * Image
 */
export type FalAiQwenImageEdit2509LoraImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * BaseQwenEditImagePlusInput
 */
export type QwenImageEdit2509Input = {
  /**
   * Prompt
   *
   * The prompt to generate the image with
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiQwenImageEdit2509ImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Acceleration
   *
   * Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Guidance scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Image URLs
   *
   * The URLs of the images to edit.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEdit2509ImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * QwenImageOutput
 */
export type QwenImageEdit2509Output = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiQwenImageEdit2509Image>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
}

/**
 * Image
 */
export type FalAiQwenImageEdit2509Image = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * LightingRestorationInput
 *
 * Input model for Lighting Restoration endpoint - Restore natural lighting by removing harsh shadows and light spots
 */
export type QwenImageEditPlusLoraGalleryLightingRestorationInput = {
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | FalAiQwenImageEditPlusLoraGalleryLightingRestorationImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown
  /**
   * Image URLs
   *
   * The URL of the image to restore lighting for.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEditPlusLoraGalleryLightingRestorationImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * LightingRestorationOutput
 */
export type QwenImageEditPlusLoraGalleryLightingRestorationOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<FalAiQwenImageEditPlusLoraGalleryLightingRestorationImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiQwenImageEditPlusLoraGalleryLightingRestorationImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * MoondreamSegementationInput
 */
export type Moondream3PreviewSegmentInput = {
  /**
   * Spatial References
   *
   * Spatial references to guide the segmentation. By feeding in references you can help the segmentation process. Must be either list of Point object with x and y members, or list of arrays containing either 2 floats (x,y) or 4 floats (x1,y1,x2,y2).
   * **NOTE**: You can also use the [**point endpoint**](https://fal.ai/models/fal-ai/moondream3-preview/point) to get points for the objects, and pass them in here.
   */
  spatial_references?: Array<Point | Array<number>>
  /**
   * Settings
   *
   * Sampling settings for the segmentation model
   */
  settings?: SegmentSamplingSettings
  /**
   * Object
   *
   * Object to be segmented in the image
   */
  object: string
  /**
   * Preview
   *
   * Whether to preview the output and return a binary mask of the image
   */
  preview?: boolean
  /**
   * Image URL
   *
   * URL of the image to be processed
   *
   * Max width: 7000px, Max height: 7000px, Timeout: 20.0s
   */
  image_url: string
}

/**
 * SegmentSamplingSettings
 */
export type SegmentSamplingSettings = {
  /**
   * Top P
   *
   * Nucleus sampling probability mass to use, between 0 and 1.
   */
  top_p?: number
  /**
   * Max Tokens
   *
   * Maximum number of tokens to generate.
   */
  max_tokens?: number
  /**
   * Temperature
   *
   * Sampling temperature to use. Higher values will make the output more random, while lower values will make it more focused and deterministic.
   */
  temperature?: number
}

/**
 * MoondreamSegementationOutput
 */
export type Moondream3PreviewSegmentOutput = {
  /**
   * Finish Reason
   *
   * Reason for finishing the output generation
   */
  finish_reason: string
  /**
   * Image
   *
   * Segmentation mask image. If no object detected or preview not requested, will be null.
   */
  image?: FalAiMoondream3PreviewSegmentImageFile
  /**
   * Bbox
   *
   * Bounding box of the segmented object. If not detected, will be null.
   */
  bbox?: Object
  /**
   * Path
   *
   * SVG path data representing the segmentation mask. If not detected, will be null.
   */
  path?: string
  /**
   * Usage Info
   *
   * Usage information for the request
   */
  usage_info: UsageInfo
}

/**
 * ImageFile
 */
export type FalAiMoondream3PreviewSegmentImageFile = {
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Object
 */
export type Object = {
  /**
   * Y Min
   *
   * Top boundary of detection box in normalized format (0 to 1)
   */
  y_min: number
  /**
   * X Max
   *
   * Right boundary of detection box in normalized format (0 to 1)
   */
  x_max: number
  /**
   * X Min
   *
   * Left boundary of detection box in normalized format (0 to 1)
   */
  x_min: number
  /**
   * Y Max
   *
   * Bottom boundary of detection box in normalized format (0 to 1)
   */
  y_max: number
}

/**
 * UsageInfo
 */
export type UsageInfo = {
  /**
   * Output Tokens
   *
   * Number of output tokens generated
   */
  output_tokens: number
  /**
   * Decode Time Ms
   *
   * Time taken for decoding in milliseconds
   */
  decode_time_ms: number
  /**
   * Input Tokens
   *
   * Number of input tokens processed
   */
  input_tokens: number
  /**
   * Ttft Ms
   *
   * Time to first token in milliseconds
   */
  ttft_ms: number
  /**
   * Prefill Time Ms
   *
   * Time taken for prefill in milliseconds
   */
  prefill_time_ms: number
}

/**
 * Placeholder for missing schema Point (referenced but not defined in source OpenAPI spec)
 */
export type Point = {
  [key: string]: unknown
}

/**
 * ImageToImageInput
 */
export type StepxEdit2Input = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Enable Reflection Mode
   *
   * Enable reflection mode. Reviews outputs, corrects unintended changes, and determines when editing is complete.
   */
  enable_reflection_mode?: boolean
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The image URL to generate an image from. Needs to match the dimensions of the mask.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * True CFG scale
   *
   *
   * The true CFG scale. Controls how closely the model follows the prompt.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform. Recommended: 50.
   */
  num_inference_steps?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
  /**
   * Enable Thinking Mode
   *
   * Enable thinking mode. Uses multimodal language model knowledge to interpret abstract editing instructions.
   */
  enable_thinking_mode?: boolean
}

/**
 * ImageOutput
 */
export type StepxEdit2Output = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Best Info
   *
   * Reflection analysis (only available when reflection mode is enabled).
   */
  best_info?: Array<{
    [key: string]: unknown
  }>
  /**
   * Images
   *
   * The generated images
   */
  images: Array<FalAiStepxEdit2Image>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Reformat Prompt
   *
   * The model's interpretation of your instruction (only available when thinking mode is enabled).
   */
  reformat_prompt?: string
  /**
   * Think Info
   *
   * Reasoning process details (only available when thinking mode is enabled).
   */
  think_info?: Array<string>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiStepxEdit2Image = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export type FalAiZImageTurboControlnetLoraLoRaInput = {
  /**
   * Path
   *
   * URL, HuggingFace repo ID (owner/repo) to lora weights.
   */
  path: string
  /**
   * Scale
   *
   * Scale factor for LoRA application (0.0 to 4.0).
   */
  scale?: number
}

/**
 * ZImageTurboControlNetOutput
 */
export type ZImageTurboControlnetLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiZImageTurboControlnetLoraImageFile>
  /**
   * Timings
   *
   * The timings of the generation process.
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   * Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.
   */
  seed: number
}

/**
 * ImageFile
 */
export type FalAiZImageTurboControlnetLoraImageFile = {
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ZImageTurboControlNetInput
 */
export type ZImageTurboControlnetInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiZImageTurboControlnetImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | 'auto'
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Control End
   *
   * The end of the controlnet conditioning.
   */
  control_end?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Control Start
   *
   * The start of the controlnet conditioning.
   */
  control_start?: number
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Image URL
   *
   * URL of Image for ControlNet generation.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Control Scale
   *
   * The scale of the controlnet conditioning.
   */
  control_scale?: number
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. Note: this will increase the price by 0.0025 credits per request.
   */
  enable_prompt_expansion?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
  /**
   * Preprocess
   *
   * What kind of preprocessing to apply to the image, if any.
   */
  preprocess?: 'none' | 'canny' | 'depth' | 'pose'
}

/**
 * ImageSize
 */
export type FalAiZImageTurboControlnetImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * ZImageTurboControlNetOutput
 */
export type ZImageTurboControlnetOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiZImageTurboControlnetImageFile>
  /**
   * Timings
   *
   * The timings of the generation process.
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   * Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.
   */
  seed: number
}

/**
 * ImageFile
 */
export type FalAiZImageTurboControlnetImageFile = {
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export type FalAiZImageTurboImageToImageLoraLoRaInput = {
  /**
   * Path
   *
   * URL, HuggingFace repo ID (owner/repo) to lora weights.
   */
  path: string
  /**
   * Scale
   *
   * Scale factor for LoRA application (0.0 to 4.0).
   */
  scale?: number
}

/**
 * ZImageTurboImageToImageOutput
 */
export type ZImageTurboImageToImageLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiZImageTurboImageToImageLoraImageFile>
  /**
   * Timings
   *
   * The timings of the generation process.
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   * Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.
   */
  seed: number
}

/**
 * ImageFile
 */
export type FalAiZImageTurboImageToImageLoraImageFile = {
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ZImageTurboImageToImageInput
 */
export type ZImageTurboImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiZImageTurboImageToImageImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | 'auto'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Image URL
   *
   * URL of Image for Image-to-Image generation.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Strength
   *
   * The strength of the image-to-image conditioning.
   */
  strength?: number
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. Note: this will increase the price by 0.0025 credits per request.
   */
  enable_prompt_expansion?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
}

/**
 * ImageSize
 */
export type FalAiZImageTurboImageToImageImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * ZImageTurboImageToImageOutput
 */
export type ZImageTurboImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiZImageTurboImageToImageImageFile>
  /**
   * Timings
   *
   * The timings of the generation process.
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   * Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.
   */
  seed: number
}

/**
 * ImageFile
 */
export type FalAiZImageTurboImageToImageImageFile = {
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * EditImageInput
 */
export type LongcatImageEditInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image with.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Image URL
   *
   * The URL of the image to edit.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Guidance Scale
   *
   * The guidance scale to use for the image generation.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
}

/**
 * ImageToImageOutput
 */
export type LongcatImageEditOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiLongcatImageEditImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiLongcatImageEditImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * SeedDream45EditInput
 */
export type BytedanceSeedreamV45EditInput = {
  /**
   * Prompt
   *
   * The text prompt used to edit the image
   */
  prompt: string
  /**
   * Num Images
   *
   * Number of separate model generations to be run with the prompt.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. Width and height must be between 1920 and 4096, or total number of pixels must be between 2560*1440 and 4096*4096.
   */
  image_size?:
    | FalAiBytedanceSeedreamV45EditImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | 'auto_2K'
    | 'auto_4K'
  /**
   * Max Images
   *
   * If set to a number greater than one, enables multi-image generation. The model will potentially return up to `max_images` images every generation, and in total, `num_images` generations will be carried out. In total, the number of images generated will be between `num_images` and `max_images*num_images`. The total number of images (image inputs + image outputs) must not exceed 15
   */
  max_images?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * Random seed to control the stochasticity of image generation.
   */
  seed?: number
  /**
   * Image URLs
   *
   * List of URLs of input images for editing. Presently, up to 10 image inputs are allowed. If over 10 images are sent, only the last 10 will be used.
   */
  image_urls: Array<string>
}

/**
 * ImageSize
 */
export type FalAiBytedanceSeedreamV45EditImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * SeedDream45EditOutput
 */
export type BytedanceSeedreamV45EditOutput = {
  /**
   * Images
   *
   * Generated images
   */
  images: Array<FalAiBytedanceSeedreamV45EditImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiBytedanceSeedreamV45EditImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ReferenceToImageRequest
 */
export type ViduQ2ReferenceToImageInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 1500 characters
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the output video
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Reference Image Urls
   *
   * URLs of the reference images to use for consistent subject appearance
   */
  reference_image_urls: Array<string>
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number
}

/**
 * ReferenceToImageOutput
 */
export type ViduQ2ReferenceToImageOutput = {
  /**
   * Image
   *
   * The edited image
   */
  image: FalAiViduQ2ReferenceToImageImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiViduQ2ReferenceToImageImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * OmniImageElementInput
 */
export type OmniImageElementInput = {
  /**
   * Reference Image Urls
   *
   * Additional reference images from different angles. 1-3 images supported. At least one image is required.
   */
  reference_image_urls?: Array<string>
  /**
   * Frontal Image Url
   *
   * The frontal image of the element (main view).
   */
  frontal_image_url: string
}

/**
 * OmniImageOutput
 */
export type KlingImageO1Output = {
  /**
   * Images
   *
   * Generated images
   */
  images: Array<FalAiKlingImageO1Image>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiKlingImageO1Image = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * VirtualTryonInput
 *
 * Input model for Virtual Try-on endpoint - Generate virtual try-on images
 */
export type Flux2LoraGalleryVirtualTryonInput = {
  /**
   * Prompt
   *
   * The prompt to generate a virtual try-on image.
   */
  prompt: string
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the input image will be used.
   */
  image_size?:
    | FalAiFlux2LoraGalleryVirtualTryonImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Lora Scale
   *
   * The strength of the virtual try-on effect.
   */
  lora_scale?: number
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown
  /**
   * Image URLs
   *
   * The URLs of the images for virtual try-on. Provide person image and clothing image.
   */
  image_urls: Array<string>
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiFlux2LoraGalleryVirtualTryonImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * VirtualTryonOutput
 */
export type Flux2LoraGalleryVirtualTryonOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation
   */
  prompt: string
  /**
   * Images
   *
   * The generated virtual try-on images
   */
  images: Array<FalAiFlux2LoraGalleryVirtualTryonImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiFlux2LoraGalleryVirtualTryonImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * MultipleAnglesInput
 *
 * Input model for Multiple Angles endpoint - Camera control with precise adjustments using <sks> trigger word. Prompt is built automatically from slider values.
 */
export type Flux2LoraGalleryMultipleAnglesInput = {
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the input image will be used.
   */
  image_size?:
    | FalAiFlux2LoraGalleryMultipleAnglesImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Acceleration
   *
   * Acceleration level for image generation.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Horizontal Angle (Azimuth Â°)
   *
   * Horizontal rotation angle around the object in degrees. 0Â°=front view, 90Â°=right side, 180Â°=back view, 270Â°=left side, 360Â°=front view again.
   */
  horizontal_angle?: number
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale.
   */
  guidance_scale?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Image URLs
   *
   * The URL of the image to adjust camera angle for.
   */
  image_urls: Array<string>
  /**
   * Zoom (Distance)
   *
   * Camera zoom/distance. 0=wide shot (far away), 5=medium shot (normal), 10=close-up (very close).
   */
  zoom?: number
  /**
   * Vertical Angle (Elevation Â°)
   *
   * Vertical camera angle in degrees. 0Â°=eye-level shot, 30Â°=elevated shot, 60Â°=high-angle shot (looking down from above).
   */
  vertical_angle?: number
  /**
   * Num Images
   *
   * Number of images to generate.
   */
  num_images?: number
  /**
   * Lora Scale
   *
   * The strength of the multiple angles effect.
   */
  lora_scale?: number
  /**
   * Output Format
   *
   * The format of the output image.
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Sync Mode
   *
   * If True, the media will be returned as a data URI.
   */
  sync_mode?: boolean
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * Random seed for reproducibility.
   */
  seed?: number | unknown
}

/**
 * ImageSize
 */
export type FalAiFlux2LoraGalleryMultipleAnglesImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * MultipleAnglesOutput
 */
export type Flux2LoraGalleryMultipleAnglesOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation
   */
  prompt: string
  /**
   * Images
   *
   * The generated images with multiple camera angles
   */
  images: Array<FalAiFlux2LoraGalleryMultipleAnglesImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiFlux2LoraGalleryMultipleAnglesImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * FaceToFullPortraitInput
 *
 * Input model for Face to Full Portrait endpoint - Generate full portrait from face
 */
export type Flux2LoraGalleryFaceToFullPortraitInput = {
  /**
   * Prompt
   *
   * The prompt describing the full portrait to generate from the face.
   */
  prompt?: string
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the input image will be used.
   */
  image_size?:
    | FalAiFlux2LoraGalleryFaceToFullPortraitImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Lora Scale
   *
   * The strength of the face to full portrait effect.
   */
  lora_scale?: number
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown
  /**
   * Image URLs
   *
   * The URL of the cropped face image.
   */
  image_urls: Array<string>
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiFlux2LoraGalleryFaceToFullPortraitImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * FaceToFullPortraitOutput
 */
export type Flux2LoraGalleryFaceToFullPortraitOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation
   */
  prompt: string
  /**
   * Images
   *
   * The generated full portrait images from face
   */
  images: Array<FalAiFlux2LoraGalleryFaceToFullPortraitImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiFlux2LoraGalleryFaceToFullPortraitImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * ApartmentStagingInput
 *
 * Input model for Apartment Staging endpoint - Furnish rooms
 */
export type Flux2LoraGalleryApartmentStagingInput = {
  /**
   * Prompt
   *
   * The prompt to generate a furnished room. Use 'furnish this room' for best results.
   */
  prompt: string
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the input image will be used.
   */
  image_size?:
    | FalAiFlux2LoraGalleryApartmentStagingImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Lora Scale
   *
   * The strength of the apartment staging effect.
   */
  lora_scale?: number
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown
  /**
   * Image URLs
   *
   * The URL of the empty room image to furnish.
   */
  image_urls: Array<string>
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiFlux2LoraGalleryApartmentStagingImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * ApartmentStagingOutput
 */
export type Flux2LoraGalleryApartmentStagingOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation
   */
  prompt: string
  /**
   * Images
   *
   * The generated furnished room images
   */
  images: Array<FalAiFlux2LoraGalleryApartmentStagingImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiFlux2LoraGalleryApartmentStagingImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * AddBackgroundInput
 *
 * Input model for Add Background endpoint - Add background to images
 */
export type Flux2LoraGalleryAddBackgroundInput = {
  /**
   * Prompt
   *
   * The prompt describing the background to add. Must start with 'Add Background' followed by your description.
   */
  prompt?: string
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the input image will be used.
   */
  image_size?:
    | FalAiFlux2LoraGalleryAddBackgroundImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Lora Scale
   *
   * The strength of the add background effect.
   */
  lora_scale?: number
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown
  /**
   * Image URLs
   *
   * The URLs of the images. Provide an image with a white or clean background.
   */
  image_urls: Array<string>
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiFlux2LoraGalleryAddBackgroundImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * AddBackgroundOutput
 */
export type Flux2LoraGalleryAddBackgroundOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation
   */
  prompt: string
  /**
   * Images
   *
   * The generated images with added background
   */
  images: Array<FalAiFlux2LoraGalleryAddBackgroundImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiFlux2LoraGalleryAddBackgroundImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * CrystalUpscaleInput
 */
export type CrystalUpscalerInput = {
  /**
   * Creativity
   *
   * Creativity level for upscaling
   */
  creativity?: number
  /**
   * Scale Factor
   *
   * Scale factor
   */
  scale_factor?: number
  /**
   * Image Url
   *
   * URL to the input image
   */
  image_url: string
}

/**
 * CrystalUpscaleOutput
 */
export type CrystalUpscalerOutput = {
  /**
   * Images
   *
   * List of upscaled images
   */
  images: Array<ClarityaiCrystalUpscalerImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type ClarityaiCrystalUpscalerImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Flux2FlexImageEditInput
 */
export type Flux2FlexEditInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Guidance Scale
   *
   * The guidance scale to use for the generation.
   */
  guidance_scale?: number
  /**
   * Image Size
   *
   * The size of the generated image. If `auto`, the size will be determined by the model.
   */
  image_size?:
    | FalAiFlux2FlexEditImageSize
    | 'auto'
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5'
  /**
   * Enable Prompt Expansion
   *
   * Whether to expand the prompt using the model's own knowledge.
   */
  enable_prompt_expansion?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Image URLs
   *
   * List of URLs of input images for editing
   */
  image_urls: Array<string>
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * The seed to use for the generation.
   */
  seed?: number
}

/**
 * ImageSize
 */
export type FalAiFlux2FlexEditImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Flux2FlexEditOutput
 */
export type Flux2FlexEditOutput = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<FalAiFlux2FlexEditImageFile>
  /**
   * Seed
   *
   * The seed used for the generation.
   */
  seed: number
}

/**
 * ImageFile
 */
export type FalAiFlux2FlexEditImageFile = {
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ChronoEditLoRAInput
 *
 * ChronoEdit input with optional custom LoRAs.
 */
export type ChronoEditLoraInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string
  /**
   * Loras
   *
   * Optional additional LoRAs to merge for this request (max 3).
   */
  loras?: Array<ChronoLoraWeight>
  /**
   * Turbo Mode
   *
   * Enable turbo mode to use for faster inference.
   */
  turbo_mode?: boolean
  /**
   * Enable Temporal Reasoning
   *
   * Whether to enable temporal reasoning.
   */
  enable_temporal_reasoning?: boolean
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Guidance Scale
   *
   * The guidance scale for the inference.
   */
  guidance_scale?: number
  /**
   * Resolution
   *
   * The resolution of the output image.
   */
  resolution?: '480p' | '720p'
  /**
   * Output Format
   *
   * The format of the output image.
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Number of Temporal Reasoning Steps
   *
   * The number of temporal reasoning steps to perform.
   */
  num_temporal_reasoning_steps?: number
  /**
   * Sync Mode
   *
   * Whether to return the image in sync mode.
   */
  sync_mode?: boolean
  /**
   * Image URL
   *
   * The image to edit.
   */
  image_url: string
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The seed for the inference.
   */
  seed?: number
}

/**
 * ChronoLoraWeight
 */
export type ChronoLoraWeight = {
  /**
   * Path
   *
   * URL or path to the LoRA weights (Safetensors).
   */
  path: string
  /**
   * Scale
   *
   * Scale factor controlling LoRA strength.
   */
  scale?: number
}

/**
 * ChronoEditOutput
 *
 * Unified output model for all ChronoEdit operations
 */
export type ChronoEditLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for the inference.
   */
  prompt: string
  /**
   * Images
   *
   * The edited image.
   */
  images: Array<FalAiChronoEditLoraImageFile>
  /**
   * Seed
   *
   * The seed for the inference.
   */
  seed: number
}

/**
 * ImageFile
 */
export type FalAiChronoEditLoraImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ChronoEditPaintBrushInput
 *
 * Input for paintbrush mode
 */
export type ChronoEditLoraGalleryPaintbrushInput = {
  /**
   * Prompt
   *
   * Describe how to transform the sketched regions.
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the output image.
   */
  resolution?: '480p' | '720p'
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA adapter.
   */
  lora_scale?: number
  /**
   * Output Format
   *
   * The format of the output image.
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Image Url
   *
   * The image to edit.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * Whether to return the image in sync mode.
   */
  sync_mode?: boolean
  /**
   * Turbo Mode
   *
   * Enable turbo mode to use faster inference.
   */
  turbo_mode?: boolean
  /**
   * Loras
   *
   * Optional additional LoRAs to merge (max 3).
   */
  loras?: Array<FalAiChronoEditLoraGalleryPaintbrushChronoLoraWeight>
  /**
   * Guidance Scale
   *
   * Classifier-free guidance scale.
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of denoising steps to run.
   */
  num_inference_steps?: number
  /**
   * Mask Url
   *
   * Optional mask image where black areas indicate regions to sketch/paint.
   */
  mask_url?: string
  /**
   * Seed
   *
   * The seed for the inference.
   */
  seed?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
}

/**
 * ChronoLoraWeight
 */
export type FalAiChronoEditLoraGalleryPaintbrushChronoLoraWeight = {
  /**
   * Path
   *
   * URL or path to the LoRA weights (Safetensors).
   */
  path: string
  /**
   * Scale
   *
   * Scale factor controlling LoRA strength.
   */
  scale?: number
}

/**
 * ChronoEditOutput
 *
 * Unified output model for all ChronoEdit operations
 */
export type ChronoEditLoraGalleryPaintbrushOutput = {
  /**
   * Prompt
   *
   * The prompt used for the inference.
   */
  prompt: string
  /**
   * Images
   *
   * The edited image.
   */
  images: Array<FalAiChronoEditLoraGalleryPaintbrushImageFile>
  /**
   * Seed
   *
   * The seed for the inference.
   */
  seed: number
}

/**
 * ImageFile
 */
export type FalAiChronoEditLoraGalleryPaintbrushImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ChronoEditUpscalerInput
 *
 * Input for upscaler mode
 */
export type ChronoEditLoraGalleryUpscalerInput = {
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA adapter.
   */
  lora_scale?: number
  /**
   * Output Format
   *
   * The format of the output image.
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Image Url
   *
   * The image to upscale.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * Whether to return the image in sync mode.
   */
  sync_mode?: boolean
  /**
   * Loras
   *
   * Optional additional LoRAs to merge (max 3).
   */
  loras?: Array<FalAiChronoEditLoraGalleryUpscalerChronoLoraWeight>
  /**
   * Upscale Factor
   *
   * Target scale factor for the output resolution.
   */
  upscale_factor?: number
  /**
   * Guidance Scale
   *
   * The guidance scale for the inference.
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for the upscaling pass.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The seed for the inference.
   */
  seed?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
}

/**
 * ChronoLoraWeight
 */
export type FalAiChronoEditLoraGalleryUpscalerChronoLoraWeight = {
  /**
   * Path
   *
   * URL or path to the LoRA weights (Safetensors).
   */
  path: string
  /**
   * Scale
   *
   * Scale factor controlling LoRA strength.
   */
  scale?: number
}

/**
 * ChronoEditOutput
 *
 * Unified output model for all ChronoEdit operations
 */
export type ChronoEditLoraGalleryUpscalerOutput = {
  /**
   * Prompt
   *
   * The prompt used for the inference.
   */
  prompt: string
  /**
   * Images
   *
   * The edited image.
   */
  images: Array<FalAiChronoEditLoraGalleryUpscalerImageFile>
  /**
   * Seed
   *
   * The seed for the inference.
   */
  seed: number
}

/**
 * ImageFile
 */
export type FalAiChronoEditLoraGalleryUpscalerImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * SAM3ImageInput
 */
export type Sam3ImageRleInput = {
  /**
   * Prompt
   *
   * Text prompt for segmentation
   */
  prompt?: string
  /**
   * Include Boxes
   *
   * Whether to include bounding boxes for each mask (when available).
   */
  include_boxes?: boolean
  /**
   * Box Prompts
   *
   * Box prompt coordinates (x_min, y_min, x_max, y_max). Multiple boxes supported - use object_id to group boxes for the same object or leave empty for separate objects.
   */
  box_prompts?: Array<BoxPrompt>
  /**
   * Return Multiple Masks
   *
   * If True, upload and return multiple generated masks as defined by `max_masks`.
   */
  return_multiple_masks?: boolean
  /**
   * Image Url
   *
   * URL of the image to be segmented
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If True, the media will be returned as a data URI.
   */
  sync_mode?: boolean
  /**
   * Point Prompts
   *
   * List of point prompts
   */
  point_prompts?: Array<PointPrompt>
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Max Masks
   *
   * Maximum number of masks to return when `return_multiple_masks` is enabled.
   */
  max_masks?: number
  /**
   * Include Scores
   *
   * Whether to include mask confidence scores.
   */
  include_scores?: boolean
  /**
   * Apply Mask
   *
   * Apply the mask on the image.
   */
  apply_mask?: boolean
  /**
   * Text Prompt
   *
   * [DEPRECATED] Use 'prompt' instead. Kept for backward compatibility.
   *
   * @deprecated
   */
  text_prompt?: string
}

/**
 * BoxPrompt
 */
export type BoxPrompt = {
  /**
   * Y Min
   *
   * Y Min Coordinate of the box
   */
  y_min?: number
  /**
   * Object Id
   *
   * Optional object identifier. Boxes sharing an object id refine the same object.
   */
  object_id?: number
  /**
   * Frame Index
   *
   * The frame index to interact with.
   */
  frame_index?: number
  /**
   * X Max
   *
   * X Max Coordinate of the box
   */
  x_max?: number
  /**
   * X Min
   *
   * X Min Coordinate of the box
   */
  x_min?: number
  /**
   * Y Max
   *
   * Y Max Coordinate of the box
   */
  y_max?: number
}

/**
 * PointPrompt
 */
export type PointPrompt = {
  /**
   * Y
   *
   * Y Coordinate of the prompt
   */
  y?: number
  /**
   * X
   *
   * X Coordinate of the prompt
   */
  x?: number
  /**
   * Object Id
   *
   * Optional object identifier. Prompts sharing an object id refine the same object.
   */
  object_id?: number
  /**
   * Frame Index
   *
   * The frame index to interact with.
   */
  frame_index?: number
  /**
   * Label
   *
   * 1 for foreground, 0 for background
   */
  label?: 0 | 1
}

/**
 * SAM3RLEOutput
 */
export type Sam3ImageRleOutput = {
  /**
   * Rle
   *
   * Run Length Encoding of the mask.
   */
  rle: string | Array<string>
  /**
   * Metadata
   *
   * Per-mask metadata when multiple RLEs are returned.
   */
  metadata?: Array<MaskMetadata>
  /**
   * Scores
   *
   * Per-mask confidence scores when requested.
   */
  scores?: Array<number>
  /**
   * Boundingbox Frames Zip
   *
   * Zip file containing per-frame bounding box overlays.
   */
  boundingbox_frames_zip?: FalAiSam3ImageRleFile
  /**
   * Boxes
   *
   * Per-mask normalized bounding boxes [cx, cy, w, h] when requested.
   */
  boxes?: Array<Array<number>>
}

/**
 * MaskMetadata
 */
export type MaskMetadata = {
  /**
   * Box
   *
   * Bounding box for the mask in normalized cxcywh coordinates.
   */
  box?: Array<number>
  /**
   * Score
   *
   * Score for this mask.
   */
  score?: number
  /**
   * Index
   *
   * Index of the mask inside the model output.
   */
  index: number
}

/**
 * File
 */
export type FalAiSam3ImageRleFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * SAM3ImageInput
 */
export type Sam3ImageInput = {
  /**
   * Prompt
   *
   * Text prompt for segmentation
   */
  prompt?: string
  /**
   * Include Boxes
   *
   * Whether to include bounding boxes for each mask (when available).
   */
  include_boxes?: boolean
  /**
   * Box Prompts
   *
   * Box prompt coordinates (x_min, y_min, x_max, y_max). Multiple boxes supported - use object_id to group boxes for the same object or leave empty for separate objects.
   */
  box_prompts?: Array<FalAiSam3ImageBoxPrompt>
  /**
   * Return Multiple Masks
   *
   * If True, upload and return multiple generated masks as defined by `max_masks`.
   */
  return_multiple_masks?: boolean
  /**
   * Image Url
   *
   * URL of the image to be segmented
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If True, the media will be returned as a data URI.
   */
  sync_mode?: boolean
  /**
   * Point Prompts
   *
   * List of point prompts
   */
  point_prompts?: Array<FalAiSam3ImagePointPrompt>
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Max Masks
   *
   * Maximum number of masks to return when `return_multiple_masks` is enabled.
   */
  max_masks?: number
  /**
   * Include Scores
   *
   * Whether to include mask confidence scores.
   */
  include_scores?: boolean
  /**
   * Apply Mask
   *
   * Apply the mask on the image.
   */
  apply_mask?: boolean
  /**
   * Text Prompt
   *
   * [DEPRECATED] Use 'prompt' instead. Kept for backward compatibility.
   *
   * @deprecated
   */
  text_prompt?: string
}

/**
 * BoxPrompt
 */
export type FalAiSam3ImageBoxPrompt = {
  /**
   * Y Min
   *
   * Y Min Coordinate of the box
   */
  y_min?: number
  /**
   * Object Id
   *
   * Optional object identifier. Boxes sharing an object id refine the same object.
   */
  object_id?: number
  /**
   * Frame Index
   *
   * The frame index to interact with.
   */
  frame_index?: number
  /**
   * X Max
   *
   * X Max Coordinate of the box
   */
  x_max?: number
  /**
   * X Min
   *
   * X Min Coordinate of the box
   */
  x_min?: number
  /**
   * Y Max
   *
   * Y Max Coordinate of the box
   */
  y_max?: number
}

/**
 * PointPrompt
 */
export type FalAiSam3ImagePointPrompt = {
  /**
   * Y
   *
   * Y Coordinate of the prompt
   */
  y?: number
  /**
   * X
   *
   * X Coordinate of the prompt
   */
  x?: number
  /**
   * Object Id
   *
   * Optional object identifier. Prompts sharing an object id refine the same object.
   */
  object_id?: number
  /**
   * Frame Index
   *
   * The frame index to interact with.
   */
  frame_index?: number
  /**
   * Label
   *
   * 1 for foreground, 0 for background
   */
  label?: 0 | 1
}

/**
 * SAM3ImageOutput
 */
export type Sam3ImageOutput = {
  /**
   * Image
   *
   * Primary segmented mask preview.
   */
  image?: FalAiSam3ImageImage
  /**
   * Metadata
   *
   * Per-mask metadata including scores and boxes.
   */
  metadata?: Array<FalAiSam3ImageMaskMetadata>
  /**
   * Masks
   *
   * Segmented mask images.
   */
  masks: Array<FalAiSam3ImageImage>
  /**
   * Scores
   *
   * Per-mask confidence scores when requested.
   */
  scores?: Array<number>
  /**
   * Boxes
   *
   * Per-mask normalized bounding boxes [cx, cy, w, h] when requested.
   */
  boxes?: Array<Array<number>>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiSam3ImageImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * MaskMetadata
 */
export type FalAiSam3ImageMaskMetadata = {
  /**
   * Box
   *
   * Bounding box for the mask in normalized cxcywh coordinates.
   */
  box?: Array<number>
  /**
   * Score
   *
   * Score for this mask.
   */
  score?: number
  /**
   * Index
   *
   * Index of the mask inside the model output.
   */
  index: number
}

/**
 * NanoBananaImageToImageInput
 */
export type Gemini3ProImagePreviewEditInput = {
  /**
   * Prompt
   *
   * The prompt for image editing.
   */
  prompt: string
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Enable Web Search
   *
   * Enable web search for the image generation task. This will allow the model to use the latest information from the web to generate the image.
   */
  enable_web_search?: boolean
  /**
   * Resolution
   *
   * The resolution of the image to generate.
   */
  resolution?: '1K' | '2K' | '4K'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | 'auto'
    | '21:9'
    | '16:9'
    | '3:2'
    | '4:3'
    | '5:4'
    | '1:1'
    | '4:5'
    | '3:4'
    | '2:3'
    | '9:16'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Image URLs
   *
   * The URLs of the images to use for image-to-image generation or image editing.
   */
  image_urls: Array<string>
  /**
   * Limit Generations
   *
   * Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate.
   */
  limit_generations?: boolean
}

/**
 * NanoBananaImageToImageOutput
 */
export type Gemini3ProImagePreviewEditOutput = {
  /**
   * Images
   *
   * The edited images.
   */
  images: Array<FalAiGemini3ProImagePreviewEditImageFile>
  /**
   * Description
   *
   * The description of the generated images.
   */
  description: string
}

/**
 * ImageFile
 */
export type FalAiGemini3ProImagePreviewEditImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * NanoBananaImageToImageInput
 */
export type NanoBananaProEditInput = {
  /**
   * Prompt
   *
   * The prompt for image editing.
   */
  prompt: string
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Enable Web Search
   *
   * Enable web search for the image generation task. This will allow the model to use the latest information from the web to generate the image.
   */
  enable_web_search?: boolean
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | 'auto'
    | '21:9'
    | '16:9'
    | '3:2'
    | '4:3'
    | '5:4'
    | '1:1'
    | '4:5'
    | '3:4'
    | '2:3'
    | '9:16'
  /**
   * Resolution
   *
   * The resolution of the image to generate.
   */
  resolution?: '1K' | '2K' | '4K'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Image URLs
   *
   * The URLs of the images to use for image-to-image generation or image editing.
   */
  image_urls: Array<string>
  /**
   * Limit Generations
   *
   * Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate.
   */
  limit_generations?: boolean
}

/**
 * NanoBananaImageToImageOutput
 */
export type NanoBananaProEditOutput = {
  /**
   * Images
   *
   * The edited images.
   */
  images: Array<FalAiNanoBananaProEditImageFile>
  /**
   * Description
   *
   * The description of the generated images.
   */
  description: string
}

/**
 * ImageFile
 */
export type FalAiNanoBananaProEditImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * MultipleAnglesInput
 *
 * Input model for Multiple Angles endpoint - Camera control with precise adjustments
 */
export type QwenImageEditPlusLoraGalleryMultipleAnglesInput = {
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | FalAiQwenImageEditPlusLoraGalleryMultipleAnglesImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Wide-Angle Lens
   *
   * Enable wide-angle lens effect
   */
  wide_angle_lens?: boolean
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
  /**
   * Image URLs
   *
   * The URL of the image to adjust camera angle for.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Vertical Angle (Bird â¬„ Worm)
   *
   * Adjust vertical camera angle (-1=bird's-eye view/looking down, 0=neutral, 1=worm's-eye view/looking up)
   */
  vertical_angle?: number
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Move Forward â†’ Close-Up
   *
   * Move camera forward (0=no movement, 10=close-up)
   */
  move_forward?: number
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Rotate Right-Left (degrees Â°)
   *
   * Rotate camera left (positive) or right (negative) in degrees. Positive values rotate left, negative values rotate right.
   */
  rotate_right_left?: number
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the camera control effect.
   */
  lora_scale?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEditPlusLoraGalleryMultipleAnglesImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * MultipleAnglesOutput
 */
export type QwenImageEditPlusLoraGalleryMultipleAnglesOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<FalAiQwenImageEditPlusLoraGalleryMultipleAnglesImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiQwenImageEditPlusLoraGalleryMultipleAnglesImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * ShirtDesignInput
 *
 * Input model for Shirt Design endpoint - Put designs/graphics on people's shirts
 */
export type QwenImageEditPlusLoraGalleryShirtDesignInput = {
  /**
   * Prompt
   *
   * Describe what design to put on the shirt. The model will apply the design from your input image onto the person's shirt.
   */
  prompt?: string
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | FalAiQwenImageEditPlusLoraGalleryShirtDesignImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown
  /**
   * Image URLs
   *
   * The URLs of the images: first image is the person wearing a shirt, second image is the design/logo to put on the shirt.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEditPlusLoraGalleryShirtDesignImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * ShirtDesignOutput
 */
export type QwenImageEditPlusLoraGalleryShirtDesignOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<FalAiQwenImageEditPlusLoraGalleryShirtDesignImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiQwenImageEditPlusLoraGalleryShirtDesignImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * RemoveLightingInput
 *
 * Input model for Remove Lighting endpoint - Remove existing lighting and apply soft even lighting
 */
export type QwenImageEditPlusLoraGalleryRemoveLightingInput = {
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | FalAiQwenImageEditPlusLoraGalleryRemoveLightingImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown
  /**
   * Image URLs
   *
   * The URL of the image with lighting/shadows to remove.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEditPlusLoraGalleryRemoveLightingImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * RemoveLightingOutput
 */
export type QwenImageEditPlusLoraGalleryRemoveLightingOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<FalAiQwenImageEditPlusLoraGalleryRemoveLightingImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiQwenImageEditPlusLoraGalleryRemoveLightingImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * RemoveElementInput
 *
 * Input model for Remove Element endpoint - Remove/delete elements (objects, people, text) from the image
 */
export type QwenImageEditPlusLoraGalleryRemoveElementInput = {
  /**
   * Prompt
   *
   * Specify what element(s) to remove from the image (objects, people, text, etc.). The model will cleanly remove the element while maintaining consistency of the rest of the image.
   */
  prompt?: string
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | FalAiQwenImageEditPlusLoraGalleryRemoveElementImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown
  /**
   * Image URLs
   *
   * The URL of the image containing elements to remove.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEditPlusLoraGalleryRemoveElementImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * RemoveElementOutput
 */
export type QwenImageEditPlusLoraGalleryRemoveElementOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<FalAiQwenImageEditPlusLoraGalleryRemoveElementImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiQwenImageEditPlusLoraGalleryRemoveElementImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * NextSceneInput
 *
 * Input model for Next Scene endpoint - Create cinematic shot progressions and scene transitions
 */
export type QwenImageEditPlusLoraGalleryNextSceneInput = {
  /**
   * Prompt
   *
   * Describe the camera movement, framing change, or scene transition. Start with 'Next Scene:' for best results. Examples: camera movements (dolly, push-in, pull-back), framing changes (wide to close-up), new elements entering frame.
   */
  prompt?: string
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | FalAiQwenImageEditPlusLoraGalleryNextSceneImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown
  /**
   * Image URLs
   *
   * The URL of the image to create the next scene from.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEditPlusLoraGalleryNextSceneImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * NextSceneOutput
 */
export type QwenImageEditPlusLoraGalleryNextSceneOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<FalAiQwenImageEditPlusLoraGalleryNextSceneImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiQwenImageEditPlusLoraGalleryNextSceneImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * IntegrateProductInput
 *
 * Input model for Integrate Product endpoint - Blend and integrate products/elements into backgrounds
 */
export type QwenImageEditPlusLoraGalleryIntegrateProductInput = {
  /**
   * Prompt
   *
   * Describe how to blend and integrate the product/element into the background. The model will automatically correct perspective, lighting and shadows for natural integration.
   */
  prompt?: string
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | FalAiQwenImageEditPlusLoraGalleryIntegrateProductImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown
  /**
   * Image URLs
   *
   * The URL of the image with product to integrate into background.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEditPlusLoraGalleryIntegrateProductImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * IntegrateProductOutput
 */
export type QwenImageEditPlusLoraGalleryIntegrateProductOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<FalAiQwenImageEditPlusLoraGalleryIntegrateProductImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiQwenImageEditPlusLoraGalleryIntegrateProductImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * GroupPhotoInput
 *
 * Input model for Group Photo endpoint - Create composite group photos with vintage/retro style
 */
export type QwenImageEditPlusLoraGalleryGroupPhotoInput = {
  /**
   * Prompt
   *
   * Describe the group photo scene, setting, and style. The model will maintain character consistency and add vintage effects like grain, blur, and retro filters.
   */
  prompt?: string
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | FalAiQwenImageEditPlusLoraGalleryGroupPhotoImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown
  /**
   * Image URLs
   *
   * The URLs of the images to combine into a group photo. Provide 2 or more individual portrait images.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEditPlusLoraGalleryGroupPhotoImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * GroupPhotoOutput
 */
export type QwenImageEditPlusLoraGalleryGroupPhotoOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<FalAiQwenImageEditPlusLoraGalleryGroupPhotoImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiQwenImageEditPlusLoraGalleryGroupPhotoImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * FaceToFullPortraitInput
 *
 * Input model for Face to Full Portrait endpoint - Generate full portrait from a cropped face image
 */
export type QwenImageEditPlusLoraGalleryFaceToFullPortraitInput = {
  /**
   * Prompt
   *
   * Describe the full portrait you want to generate from the face. Include clothing, setting, pose, and style details.
   */
  prompt?: string
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | FalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown
  /**
   * Image URLs
   *
   * The URL of the cropped face image. Provide a close-up face photo.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * FaceToFullPortraitOutput
 */
export type QwenImageEditPlusLoraGalleryFaceToFullPortraitOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<FalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * AddBackgroundInput
 *
 * Input model for Add Background endpoint - Remove white background and add a realistic scene
 */
export type QwenImageEditPlusLoraGalleryAddBackgroundInput = {
  /**
   * Prompt
   *
   * Describe the background/scene you want to add behind the object. The model will remove the white background and add the specified environment.
   */
  prompt?: string
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | FalAiQwenImageEditPlusLoraGalleryAddBackgroundImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown
  /**
   * Image URLs
   *
   * The URLs of the images to edit. Provide an image with a white or clean background.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEditPlusLoraGalleryAddBackgroundImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * AddBackgroundOutput
 */
export type QwenImageEditPlusLoraGalleryAddBackgroundOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<FalAiQwenImageEditPlusLoraGalleryAddBackgroundImage>
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiQwenImageEditPlusLoraGalleryAddBackgroundImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * ReveRemixInput
 *
 * Input for Reve image remixing
 */
export type ReveFastRemixInput = {
  /**
   * Prompt
   *
   * The text description of the desired image. May include XML img tags like <img>0</img> to refer to specific images by their index in the image_urls list.
   */
  prompt: string
  /**
   * Number of Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Aspect Ratio
   *
   * The desired aspect ratio of the generated image. If not provided, will be smartly chosen by the model.
   */
  aspect_ratio?: '16:9' | '9:16' | '3:2' | '2:3' | '4:3' | '3:4' | '1:1'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Reference Image URLs
   *
   * List of URLs of reference images. Must provide between 1 and 6 images (inclusive). Each image must be less than 10 MB. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.
   */
  image_urls: Array<string>
  /**
   * Output Format
   *
   * Output format for the generated image.
   */
  output_format?: 'png' | 'jpeg' | 'webp'
}

/**
 * ReveRemixOutput
 *
 * Output for Reve image remixing
 */
export type ReveFastRemixOutput = {
  /**
   * Images
   *
   * The remixed images
   */
  images: Array<FalAiReveFastRemixImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiReveFastRemixImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ReveFastEditInput
 *
 * Input for Reve fast image editing
 */
export type ReveFastEditInput = {
  /**
   * Prompt
   *
   * The text description of how to edit the provided image.
   */
  prompt: string
  /**
   * Number of Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Output Format
   *
   * Output format for the generated image.
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Reference Image URL
   *
   * URL of the reference image to edit. Must be publicly accessible or base64 data URI. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.
   */
  image_url: string
}

/**
 * ReveFastEditOutput
 *
 * Output for Reve fast image editing
 */
export type ReveFastEditOutput = {
  /**
   * Images
   *
   * The edited images
   */
  images: Array<FalAiReveFastEditImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiReveFastEditImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * OutpaintInput
 */
export type ImageAppsV2OutpaintInput = {
  /**
   * Prompt
   *
   * Optional prompt to guide the outpainting. If provided, it will be appended to the base outpaint instruction. Example: 'with a beautiful sunset in the background'
   */
  prompt?: string
  /**
   * Expand Right
   *
   * Number of pixels to add as black margin on the right side (0-700).
   */
  expand_right?: number
  /**
   * Num Images
   *
   * Number of images to generate.
   */
  num_images?: number
  /**
   * Zoom Out Percentage
   *
   * Percentage to zoom out the image. If set, the image will be scaled down by this percentage and black margins will be added to maintain original size. Example: 50 means the image will be 50% of original size with black margins filling the rest.
   */
  zoom_out_percentage?: number
  /**
   * Output Format
   *
   * The format of the output image.
   */
  output_format?: 'png' | 'jpeg' | 'jpg' | 'webp'
  /**
   * Image Url
   *
   * Image URL to outpaint
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If True, the function will wait for the image to be generated and uploaded before returning the response. If False, the function will return immediately and the image will be generated asynchronously.
   */
  sync_mode?: boolean
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Expand Left
   *
   * Number of pixels to add as black margin on the left side (0-700).
   */
  expand_left?: number
  /**
   * Expand Bottom
   *
   * Number of pixels to add as black margin on the bottom side (0-700).
   */
  expand_bottom?: number
  /**
   * Expand Top
   *
   * Number of pixels to add as black margin on the top side (0-700).
   */
  expand_top?: number
}

/**
 * OutpaintOutput
 */
export type ImageAppsV2OutpaintOutput = {
  /**
   * Images
   *
   * Outpainted image with extended scene
   */
  images: Array<FalAiImageAppsV2OutpaintImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageAppsV2OutpaintImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * Input
 */
export type FluxVisionUpscalerInput = {
  /**
   * Guidance
   *
   * CFG/guidance scale (1-4). Controls how closely the model follows the prompt.
   */
  guidance?: number
  /**
   * Creativity
   *
   * The creativity of the model. The higher the creativity, the more the model will deviate from the original. Refers to the denoise strength of the sampling.
   */
  creativity?: number
  /**
   * Image Url
   *
   * The URL of the image to upscale.
   */
  image_url: string
  /**
   * Upscale Factor
   *
   * The upscale factor (1-4x).
   */
  upscale_factor?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * The seed to use for the upscale. If not provided, a random seed will be used.
   */
  seed?: number | unknown
  /**
   * Steps
   *
   * Number of inference steps (4-50).
   */
  steps?: number
}

/**
 * Output
 */
export type FluxVisionUpscalerOutput = {
  /**
   * The URL of the generated image.
   */
  image: FalAiFluxVisionUpscalerImage
  /**
   * Caption
   *
   * The VLM-generated caption describing the upscaled image.
   */
  caption: string
  /**
   * Seed
   *
   * The seed used to generate the image.
   */
  seed: number
  /**
   * Timings
   *
   * The timings of the different steps in the workflow.
   */
  timings: {
    [key: string]: number
  }
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiFluxVisionUpscalerImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * Emu35ImageEditInput
 */
export type Emu35ImageEditImageInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the output image.
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the output image.
   */
  aspect_ratio?:
    | 'auto'
    | '21:9'
    | '16:9'
    | '4:3'
    | '3:2'
    | '1:1'
    | '2:3'
    | '3:4'
    | '9:16'
    | '9:21'
  /**
   * Output Format
   *
   * The format of the output image.
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Image URL
   *
   * The image to edit.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * Whether to return the image in sync mode.
   */
  sync_mode?: boolean
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * The seed for the inference.
   */
  seed?: number
}

/**
 * Emu35EditOutput
 */
export type Emu35ImageEditImageOutput = {
  /**
   * Images
   *
   * The edited image.
   */
  images: Array<FalAiEmu35ImageEditImageImageFile>
  /**
   * Seed
   *
   * The seed for the inference.
   */
  seed: number
}

/**
 * ImageFile
 */
export type FalAiEmu35ImageEditImageImageFile = {
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ChronoEditInput
 *
 * Input model for ChronoEdit standard editing operations
 */
export type ChronoEditInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the output image.
   */
  resolution?: '480p' | '720p'
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Output Format
   *
   * The format of the output image.
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Image URL
   *
   * The image to edit.
   */
  image_url: string
  /**
   * Turbo Mode
   *
   * Enable turbo mode to use for faster inference.
   */
  turbo_mode?: boolean
  /**
   * Number of Temporal Reasoning Steps
   *
   * The number of temporal reasoning steps to perform.
   */
  num_temporal_reasoning_steps?: number
  /**
   * Sync Mode
   *
   * Whether to return the image in sync mode.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The guidance scale for the inference.
   */
  guidance_scale?: number
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Enable Temporal Reasoning
   *
   * Whether to enable temporal reasoning.
   */
  enable_temporal_reasoning?: boolean
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * The seed for the inference.
   */
  seed?: number
}

/**
 * ChronoEditOutput
 *
 * Unified output model for all ChronoEdit operations
 */
export type ChronoEditOutput = {
  /**
   * Prompt
   *
   * The prompt used for the inference.
   */
  prompt: string
  /**
   * Images
   *
   * The edited image.
   */
  images: Array<FalAiChronoEditImageFile>
  /**
   * Seed
   *
   * The seed for the inference.
   */
  seed: number
}

/**
 * ImageFile
 */
export type FalAiChronoEditImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * EditImageRequestMini
 */
export type GptImage1MiniEditInput = {
  /**
   * Prompt
   *
   * The prompt for image generation
   */
  prompt: string
  /**
   * Number of Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * Aspect ratio for the generated image
   */
  image_size?: 'auto' | '1024x1024' | '1536x1024' | '1024x1536'
  /**
   * Background
   *
   * Background for the generated image
   */
  background?: 'auto' | 'transparent' | 'opaque'
  /**
   * Quality
   *
   * Quality for the generated image
   */
  quality?: 'auto' | 'low' | 'medium' | 'high'
  /**
   * Output Format
   *
   * Output format for the images
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Image URLs
   *
   * The URLs of the images to use as a reference for the generation.
   */
  image_urls: Array<string>
}

/**
 * EditImageResponseMini
 */
export type GptImage1MiniEditOutput = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<FalAiGptImage1MiniEditImageFile>
}

/**
 * ImageFile
 */
export type FalAiGptImage1MiniEditImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ReveRemixInput
 *
 * Input for Reve image remixing
 */
export type ReveRemixInput = {
  /**
   * Prompt
   *
   * The text description of the desired image. May include XML img tags like <img>0</img> to refer to specific images by their index in the image_urls list.
   */
  prompt: string
  /**
   * Number of Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Aspect Ratio
   *
   * The desired aspect ratio of the generated image. If not provided, will be smartly chosen by the model.
   */
  aspect_ratio?: '16:9' | '9:16' | '3:2' | '2:3' | '4:3' | '3:4' | '1:1'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Reference Image URLs
   *
   * List of URLs of reference images. Must provide between 1 and 6 images (inclusive). Each image must be less than 10 MB. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.
   */
  image_urls: Array<string>
  /**
   * Output Format
   *
   * Output format for the generated image.
   */
  output_format?: 'png' | 'jpeg' | 'webp'
}

/**
 * ReveRemixOutput
 *
 * Output for Reve image remixing
 */
export type ReveRemixOutput = {
  /**
   * Images
   *
   * The remixed images
   */
  images: Array<FalAiReveRemixImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiReveRemixImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ReveEditInput
 *
 * Input for Reve image editing
 */
export type ReveEditInput = {
  /**
   * Prompt
   *
   * The text description of how to edit the provided image.
   */
  prompt: string
  /**
   * Number of Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Output Format
   *
   * Output format for the generated image.
   */
  output_format?: 'png' | 'jpeg' | 'webp'
  /**
   * Reference Image URL
   *
   * URL of the reference image to edit. Must be publicly accessible or base64 data URI. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.
   */
  image_url: string
}

/**
 * ReveEditOutput
 *
 * Output for Reve image editing
 */
export type ReveEditOutput = {
  /**
   * Images
   *
   * The edited images
   */
  images: Array<FalAiReveEditImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiReveEditImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Image2PixelInput
 */
export type Image2PixelInput = {
  /**
   * Cleanup Morph
   *
   * Apply morphological operations to remove noise.
   */
  cleanup_morph?: boolean
  /**
   * Auto Color Detect
   *
   * Enable automatic detection of optimal number of colors.
   */
  auto_color_detect?: boolean
  /**
   * Alpha Threshold
   *
   * Alpha binarization threshold (0-255).
   */
  alpha_threshold?: number
  /**
   * Snap Grid
   *
   * Align output to the pixel grid.
   */
  snap_grid?: boolean
  /**
   * Fixed Palette
   *
   * Optional fixed color palette as hex strings (e.g., ['#000000', '#ffffff']).
   */
  fixed_palette?: Array<string>
  /**
   * Scale
   *
   * Force a specific pixel scale. If None, auto-detect.
   */
  scale?: number
  /**
   * Cleanup Jaggy
   *
   * Remove isolated diagonal pixels (jaggy edge cleanup).
   */
  cleanup_jaggy?: boolean
  /**
   * Trim Borders
   *
   * Trim borders of the image.
   */
  trim_borders?: boolean
  /**
   * Background Tolerance
   *
   * Background tolerance (0-255).
   */
  background_tolerance?: number
  /**
   * Detect Method
   *
   * Scale detection method to use.
   */
  detect_method?: 'auto' | 'runs' | 'edge'
  /**
   * Transparent Background
   *
   * Remove background of the image. This will check for contiguous color regions from the edges after correction and make them transparent.
   */
  transparent_background?: boolean
  /**
   * Downscale Method
   *
   * Downscaling method to produce the pixel-art output.
   */
  downscale_method?:
    | 'dominant'
    | 'median'
    | 'mode'
    | 'mean'
    | 'content-adaptive'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Image Url
   *
   * The image URL to process into improved pixel art
   */
  image_url: string
  /**
   * Background Mode
   *
   * Controls where to flood-fill from when removing the background.
   */
  background_mode?: 'edges' | 'corners' | 'midpoints'
  /**
   * Max Colors
   *
   * Maximum number of colors in the output palette. Set None to disable limit.
   */
  max_colors?: number
  /**
   * Dominant Color Threshold
   *
   * Dominant color threshold (0.0-1.0).
   */
  dominant_color_threshold?: number
}

/**
 * Image2PixelOutput
 */
export type Image2PixelOutput = {
  /**
   * Images
   *
   * The processed pixel-art image (PNG) and the scaled image (PNG).
   */
  images: Array<FalAiImage2PixelImageFile>
  /**
   * Num Colors
   *
   * The number of colors in the processed media.
   */
  num_colors: number
  /**
   * Palette
   *
   * The palette of the processed media.
   */
  palette: Array<string>
  /**
   * Pixel Scale
   *
   * The detected pixel scale of the input.
   */
  pixel_scale: number
}

/**
 * ImageFile
 */
export type FalAiImage2PixelImageFile = {
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * DreamOmni2Request
 */
export type Dreamomni2EditInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string
  /**
   * You can use only with to 2 images.
   *
   * List of URLs of input images for editing.
   */
  image_urls: Array<string>
}

/**
 * DreamOmni2Response
 */
export type Dreamomni2EditOutput = {
  /**
   * Image
   *
   * Generated image
   */
  image: FalAiDreamomni2EditImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiDreamomni2EditImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * BaseQwenEditImagePlusLoRAInput
 */
export type QwenImageEditPlusLoraInput = {
  /**
   * Prompt
   *
   * The prompt to generate the image with
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used to calculate the size of the output image.
   */
  image_size?:
    | FalAiQwenImageEditPlusLoraImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Acceleration
   *
   * Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use up to 3 LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<FalAiQwenImageEditPlusLoraLoraWeight>
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Guidance scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Image URLs
   *
   * The URLs of the images to edit.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEditPlusLoraImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * LoraWeight
 */
export type FalAiQwenImageEditPlusLoraLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
}

/**
 * QwenImageOutput
 */
export type QwenImageEditPlusLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiQwenImageEditPlusLoraImage>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
}

/**
 * Image
 */
export type FalAiQwenImageEditPlusLoraImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * LucidFluxRequest
 */
export type LucidfluxInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string
  /**
   * Guidance
   *
   * The guidance to use for the diffusion process.
   */
  guidance?: number
  /**
   * Target Height
   *
   * The height of the output image.
   */
  target_height?: number
  /**
   * Image URL
   *
   * The URL of the image to edit.
   */
  image_url: string
  /**
   * Target Width
   *
   * The width of the output image.
   */
  target_width?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * Seed used for random number generation
   */
  seed?: number
}

/**
 * LucidFluxResponse
 */
export type LucidfluxOutput = {
  /**
   * Image
   *
   * Generated image
   */
  image: FalAiLucidfluxImage
  /**
   * Seed
   *
   * Seed used for random number generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiLucidfluxImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * BaseQwenEditImg2ImgInput
 */
export type QwenImageEditImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate the image with
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiQwenImageEditImageToImageImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Acceleration
   *
   * Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The URL of the image to edit.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Strength
   *
   * Strength of the image-to-image transformation. Lower values preserve more of the original image.
   */
  strength?: number
  /**
   * Guidance scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
}

/**
 * ImageSize
 */
export type FalAiQwenImageEditImageToImageImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * QwenImageOutput
 */
export type QwenImageEditImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiQwenImageEditImageToImageImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiQwenImageEditImageToImageImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * ImageToImageInput
 *
 * Input for image editing
 */
export type Wan25PreviewImageToImageInput = {
  /**
   * Prompt
   *
   * The text prompt describing how to edit the image. Max 2000 characters.
   */
  prompt: string
  /**
   * Num Images
   *
   * Number of images to generate. Values from 1 to 4.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. Width and height must be between 384 and 1440 pixels.
   */
  image_size?:
    | FalAiWan25PreviewImageToImageImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Image Urls
   *
   * URLs of images to edit. For single-image editing, provide 1 URL. For multi-reference generation, provide up to 2 URLs. If more than 2 URLs are provided, only the first 2 will be used.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * Negative prompt to describe content to avoid. Max 500 characters.
   */
  negative_prompt?: string
}

/**
 * ImageSize
 */
export type FalAiWan25PreviewImageToImageImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * ImageToImageOutput
 *
 * Output for image editing
 */
export type Wan25PreviewImageToImageOutput = {
  /**
   * Images
   *
   * The edited images
   */
  images: Array<FalAiWan25PreviewImageToImageImageFile>
  /**
   * Seeds
   *
   * The seeds used for each generated image
   */
  seeds: Array<number>
  /**
   * Actual Prompt
   *
   * The original prompt (prompt expansion is not available for image editing)
   */
  actual_prompt?: string
}

/**
 * ImageFile
 */
export type FalAiWan25PreviewImageToImageImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * BaseQwenEditImagePlusInput
 */
export type QwenImageEditPlusInput = {
  /**
   * Prompt
   *
   * The prompt to generate the image with
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiQwenImageEditPlusImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Acceleration
   *
   * Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Guidance scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Image URLs
   *
   * The URLs of the images to edit.
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEditPlusImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * QwenImageOutput
 */
export type QwenImageEditPlusOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiQwenImageEditPlusImage>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
}

/**
 * Image
 */
export type FalAiQwenImageEditPlusImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * SeedVRImageInput
 */
export type SeedvrUpscaleImageInput = {
  /**
   * Upscale Mode
   *
   * The mode to use for the upscale. If 'target', the upscale factor will be calculated based on the target resolution. If 'factor', the upscale factor will be used directly.
   */
  upscale_mode?: 'target' | 'factor'
  /**
   * Noise Scale
   *
   * The noise scale to use for the generation process.
   */
  noise_scale?: number
  /**
   * Target Resolution
   *
   * The target resolution to upscale to when `upscale_mode` is `target`.
   */
  target_resolution?: '720p' | '1080p' | '1440p' | '2160p'
  /**
   * Output Format
   *
   * The format of the output image.
   */
  output_format?: 'png' | 'jpg' | 'webp'
  /**
   * Image Url
   *
   * The input image to be processed
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Upscale Factor
   *
   * Upscaling factor to be used. Will multiply the dimensions with this factor when `upscale_mode` is `factor`.
   */
  upscale_factor?: number
  /**
   * Seed
   *
   * The random seed used for the generation process.
   */
  seed?: number
}

/**
 * SeedVRImageOutput
 */
export type SeedvrUpscaleImageOutput = {
  /**
   * Image
   *
   * Upscaled image file after processing
   */
  image: FalAiSeedvrUpscaleImageImageFile
  /**
   * Seed
   *
   * The random seed used for the generation process.
   */
  seed: number
}

/**
 * ImageFile
 */
export type FalAiSeedvrUpscaleImageImageFile = {
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ProductHoldingInput
 */
export type ImageAppsV2ProductHoldingInput = {
  aspect_ratio?: AspectRatio
  /**
   * Product Image Url
   *
   * Image URL of the product to be held by the person
   */
  product_image_url: string
  /**
   * Person Image Url
   *
   * Image URL of the person who will hold the product
   */
  person_image_url: string
}

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export type AspectRatio = {
  /**
   * Ratio
   *
   * Aspect ratio for 4K resolution output
   */
  ratio?: '1:1' | '16:9' | '9:16' | '4:3' | '3:4'
}

/**
 * ProductHoldingOutput
 */
export type ImageAppsV2ProductHoldingOutput = {
  /**
   * Images
   *
   * Person holding the product naturally
   */
  images: Array<FalAiImageAppsV2ProductHoldingImage>
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageAppsV2ProductHoldingImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * ProductPhotographyInput
 */
export type ImageAppsV2ProductPhotographyInput = {
  aspect_ratio?: FalAiImageAppsV2ProductPhotographyAspectRatio
  /**
   * Product Image Url
   *
   * Image URL of the product to create professional studio photography
   */
  product_image_url: string
}

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export type FalAiImageAppsV2ProductPhotographyAspectRatio = {
  /**
   * Ratio
   *
   * Aspect ratio for 4K resolution output
   */
  ratio?: '1:1' | '16:9' | '9:16' | '4:3' | '3:4'
}

/**
 * ProductPhotographyOutput
 */
export type ImageAppsV2ProductPhotographyOutput = {
  /**
   * Images
   *
   * Professional studio product photography
   */
  images: Array<FalAiImageAppsV2ProductPhotographyImage>
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageAppsV2ProductPhotographyImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * VirtualTryOnInput
 */
export type ImageAppsV2VirtualTryOnInput = {
  /**
   * Preserve Pose
   */
  preserve_pose?: boolean
  aspect_ratio?: FalAiImageAppsV2VirtualTryOnAspectRatio
  /**
   * Clothing Image Url
   *
   * Clothing photo URL
   */
  clothing_image_url: string
  /**
   * Person Image Url
   *
   * Person photo URL
   */
  person_image_url: string
}

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export type FalAiImageAppsV2VirtualTryOnAspectRatio = {
  /**
   * Ratio
   *
   * Aspect ratio for 4K resolution output
   */
  ratio?: '1:1' | '16:9' | '9:16' | '4:3' | '3:4'
}

/**
 * VirtualTryOnOutput
 */
export type ImageAppsV2VirtualTryOnOutput = {
  /**
   * Images
   *
   * Person wearing the virtual clothing
   */
  images: Array<FalAiImageAppsV2VirtualTryOnImage>
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageAppsV2VirtualTryOnImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * TextureTransformInput
 */
export type ImageAppsV2TextureTransformInput = {
  /**
   * Target Texture
   */
  target_texture?:
    | 'cotton'
    | 'denim'
    | 'wool'
    | 'felt'
    | 'wood'
    | 'leather'
    | 'velvet'
    | 'stone'
    | 'marble'
    | 'ceramic'
    | 'concrete'
    | 'brick'
    | 'clay'
    | 'foam'
    | 'glass'
    | 'metal'
    | 'silk'
    | 'fabric'
    | 'crystal'
    | 'rubber'
    | 'plastic'
    | 'lace'
  aspect_ratio?: FalAiImageAppsV2TextureTransformAspectRatio
  /**
   * Image Url
   *
   * Image URL for texture transformation
   */
  image_url: string
}

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export type FalAiImageAppsV2TextureTransformAspectRatio = {
  /**
   * Ratio
   *
   * Aspect ratio for 4K resolution output
   */
  ratio?: '1:1' | '16:9' | '9:16' | '4:3' | '3:4'
}

/**
 * TextureTransformOutput
 */
export type ImageAppsV2TextureTransformOutput = {
  /**
   * Images
   *
   * Image with transformed texture
   */
  images: Array<FalAiImageAppsV2TextureTransformImage>
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageAppsV2TextureTransformImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * RelightingInput
 */
export type ImageAppsV2RelightingInput = {
  aspect_ratio?: FalAiImageAppsV2RelightingAspectRatio
  /**
   * Lighting Style
   */
  lighting_style?:
    | 'natural'
    | 'studio'
    | 'golden_hour'
    | 'blue_hour'
    | 'dramatic'
    | 'soft'
    | 'hard'
    | 'backlight'
    | 'side_light'
    | 'front_light'
    | 'rim_light'
    | 'sunset'
    | 'sunrise'
    | 'neon'
    | 'candlelight'
    | 'moonlight'
    | 'spotlight'
    | 'ambient'
  /**
   * Image Url
   *
   * Image URL for relighting
   */
  image_url: string
}

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export type FalAiImageAppsV2RelightingAspectRatio = {
  /**
   * Ratio
   *
   * Aspect ratio for 4K resolution output
   */
  ratio?: '1:1' | '16:9' | '9:16' | '4:3' | '3:4'
}

/**
 * RelightingOutput
 */
export type ImageAppsV2RelightingOutput = {
  /**
   * Images
   *
   * Image with new lighting
   */
  images: Array<FalAiImageAppsV2RelightingImage>
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageAppsV2RelightingImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * StyleTransferInput
 */
export type ImageAppsV2StyleTransferInput = {
  /**
   * Target Style
   */
  target_style?:
    | 'anime_character'
    | 'cartoon_3d'
    | 'hand_drawn_animation'
    | 'cyberpunk_future'
    | 'anime_game_style'
    | 'comic_book_animation'
    | 'animated_series'
    | 'cartoon_animation'
    | 'lofi_aesthetic'
    | 'cottagecore'
    | 'dark_academia'
    | 'y2k'
    | 'vaporwave'
    | 'liminal_space'
    | 'weirdcore'
    | 'dreamcore'
    | 'synthwave'
    | 'outrun'
    | 'photorealistic'
    | 'hyperrealistic'
    | 'digital_art'
    | 'concept_art'
    | 'impressionist'
    | 'anime'
    | 'pixel_art'
    | 'claymation'
  aspect_ratio?: FalAiImageAppsV2StyleTransferAspectRatio
  /**
   * Style Reference Image Url
   *
   * Optional reference image URL. When provided, the style will be inferred from this image instead of the selected preset style.
   */
  style_reference_image_url?: string | unknown
  /**
   * Image Url
   *
   * Image URL for style transfer
   */
  image_url: string
}

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export type FalAiImageAppsV2StyleTransferAspectRatio = {
  /**
   * Ratio
   *
   * Aspect ratio for 4K resolution output
   */
  ratio?: '1:1' | '16:9' | '9:16' | '4:3' | '3:4'
}

/**
 * StyleTransferOutput
 */
export type ImageAppsV2StyleTransferOutput = {
  /**
   * Images
   *
   * Image with transferred style
   */
  images: Array<FalAiImageAppsV2StyleTransferImage>
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageAppsV2StyleTransferImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * PhotoRestorationInput
 */
export type ImageAppsV2PhotoRestorationInput = {
  /**
   * Enhance Resolution
   */
  enhance_resolution?: boolean
  aspect_ratio?: FalAiImageAppsV2PhotoRestorationAspectRatio
  /**
   * Remove Scratches
   */
  remove_scratches?: boolean
  /**
   * Fix Colors
   */
  fix_colors?: boolean
  /**
   * Image Url
   *
   * Old or damaged photo URL to restore
   */
  image_url: string
}

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export type FalAiImageAppsV2PhotoRestorationAspectRatio = {
  /**
   * Ratio
   *
   * Aspect ratio for 4K resolution output
   */
  ratio?: '1:1' | '16:9' | '9:16' | '4:3' | '3:4'
}

/**
 * PhotoRestorationOutput
 */
export type ImageAppsV2PhotoRestorationOutput = {
  /**
   * Images
   *
   * Restored photo
   */
  images: Array<FalAiImageAppsV2PhotoRestorationImage>
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageAppsV2PhotoRestorationImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * PortraitInput
 */
export type ImageAppsV2PortraitEnhanceInput = {
  aspect_ratio?: FalAiImageAppsV2PortraitEnhanceAspectRatio
  /**
   * Image Url
   *
   * Portrait image URL to enhance
   */
  image_url: string
}

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export type FalAiImageAppsV2PortraitEnhanceAspectRatio = {
  /**
   * Ratio
   *
   * Aspect ratio for 4K resolution output
   */
  ratio?: '1:1' | '16:9' | '9:16' | '4:3' | '3:4'
}

/**
 * PortraitOutput
 */
export type ImageAppsV2PortraitEnhanceOutput = {
  /**
   * Images
   *
   * Enhanced portrait
   */
  images: Array<FalAiImageAppsV2PortraitEnhanceImage>
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageAppsV2PortraitEnhanceImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * PhotographyEffectsInput
 */
export type ImageAppsV2PhotographyEffectsInput = {
  /**
   * Effect Type
   */
  effect_type?:
    | 'film'
    | 'vintage_film'
    | 'portrait_photography'
    | 'fashion_photography'
    | 'street_photography'
    | 'sepia_tone'
    | 'film_grain'
    | 'light_leaks'
    | 'vignette_effect'
    | 'instant_camera'
    | 'golden_hour'
    | 'dramatic_lighting'
    | 'soft_focus'
    | 'bokeh_effect'
    | 'high_contrast'
    | 'double_exposure'
  aspect_ratio?: FalAiImageAppsV2PhotographyEffectsAspectRatio
  /**
   * Image Url
   *
   * Image URL for photography effects
   */
  image_url: string
}

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export type FalAiImageAppsV2PhotographyEffectsAspectRatio = {
  /**
   * Ratio
   *
   * Aspect ratio for 4K resolution output
   */
  ratio?: '1:1' | '16:9' | '9:16' | '4:3' | '3:4'
}

/**
 * PhotographyEffectsOutput
 */
export type ImageAppsV2PhotographyEffectsOutput = {
  /**
   * Images
   *
   * Image with photography effects
   */
  images: Array<FalAiImageAppsV2PhotographyEffectsImage>
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageAppsV2PhotographyEffectsImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * PerspectiveInput
 */
export type ImageAppsV2PerspectiveInput = {
  aspect_ratio?: FalAiImageAppsV2PerspectiveAspectRatio
  /**
   * Target Perspective
   */
  target_perspective?:
    | 'front'
    | 'left_side'
    | 'right_side'
    | 'back'
    | 'top_down'
    | 'bottom_up'
    | 'birds_eye'
    | 'three_quarter_left'
    | 'three_quarter_right'
  /**
   * Image Url
   *
   * Image URL for perspective change
   */
  image_url: string
}

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export type FalAiImageAppsV2PerspectiveAspectRatio = {
  /**
   * Ratio
   *
   * Aspect ratio for 4K resolution output
   */
  ratio?: '1:1' | '16:9' | '9:16' | '4:3' | '3:4'
}

/**
 * PerspectiveOutput
 */
export type ImageAppsV2PerspectiveOutput = {
  /**
   * Images
   *
   * Image with changed perspective
   */
  images: Array<FalAiImageAppsV2PerspectiveImage>
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageAppsV2PerspectiveImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * ObjectRemovalInput
 */
export type ImageAppsV2ObjectRemovalInput = {
  aspect_ratio?: FalAiImageAppsV2ObjectRemovalAspectRatio
  /**
   * Object To Remove
   *
   * Object to remove
   */
  object_to_remove: string
  /**
   * Image Url
   *
   * Image URL containing object to remove
   */
  image_url: string
}

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export type FalAiImageAppsV2ObjectRemovalAspectRatio = {
  /**
   * Ratio
   *
   * Aspect ratio for 4K resolution output
   */
  ratio?: '1:1' | '16:9' | '9:16' | '4:3' | '3:4'
}

/**
 * ObjectRemovalOutput
 */
export type ImageAppsV2ObjectRemovalOutput = {
  /**
   * Images
   *
   * Image with object removed
   */
  images: Array<FalAiImageAppsV2ObjectRemovalImage>
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageAppsV2ObjectRemovalImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * HeadshotInput
 */
export type ImageAppsV2HeadshotPhotoInput = {
  aspect_ratio?: FalAiImageAppsV2HeadshotPhotoAspectRatio
  /**
   * Background Style
   */
  background_style?: 'professional' | 'corporate' | 'clean' | 'gradient'
  /**
   * Image Url
   *
   * Portrait image URL to convert to professional headshot
   */
  image_url: string
}

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export type FalAiImageAppsV2HeadshotPhotoAspectRatio = {
  /**
   * Ratio
   *
   * Aspect ratio for 4K resolution output
   */
  ratio?: '1:1' | '16:9' | '9:16' | '4:3' | '3:4'
}

/**
 * HeadshotOutput
 */
export type ImageAppsV2HeadshotPhotoOutput = {
  /**
   * Images
   *
   * Professional headshot image
   */
  images: Array<FalAiImageAppsV2HeadshotPhotoImage>
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageAppsV2HeadshotPhotoImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * HairChangeInput
 */
export type ImageAppsV2HairChangeInput = {
  /**
   * Target Hairstyle
   */
  target_hairstyle?:
    | 'short_hair'
    | 'medium_long_hair'
    | 'long_hair'
    | 'curly_hair'
    | 'wavy_hair'
    | 'high_ponytail'
    | 'bun'
    | 'bob_cut'
    | 'pixie_cut'
    | 'braids'
    | 'straight_hair'
    | 'afro'
    | 'dreadlocks'
    | 'buzz_cut'
    | 'mohawk'
    | 'bangs'
    | 'side_part'
    | 'middle_part'
  aspect_ratio?: FalAiImageAppsV2HairChangeAspectRatio
  /**
   * Hair Color
   */
  hair_color?:
    | 'black'
    | 'dark_brown'
    | 'light_brown'
    | 'blonde'
    | 'platinum_blonde'
    | 'red'
    | 'auburn'
    | 'gray'
    | 'silver'
    | 'blue'
    | 'green'
    | 'purple'
    | 'pink'
    | 'rainbow'
    | 'natural'
    | 'highlights'
    | 'ombre'
    | 'balayage'
  /**
   * Image Url
   *
   * Portrait image URL for hair change
   */
  image_url: string
}

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export type FalAiImageAppsV2HairChangeAspectRatio = {
  /**
   * Ratio
   *
   * Aspect ratio for 4K resolution output
   */
  ratio?: '1:1' | '16:9' | '9:16' | '4:3' | '3:4'
}

/**
 * HairChangeOutput
 */
export type ImageAppsV2HairChangeOutput = {
  /**
   * Images
   *
   * Portrait with changed hair
   */
  images: Array<FalAiImageAppsV2HairChangeImage>
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageAppsV2HairChangeImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * ExpressionChangeInput
 */
export type ImageAppsV2ExpressionChangeInput = {
  aspect_ratio?: FalAiImageAppsV2ExpressionChangeAspectRatio
  /**
   * Target Expression
   */
  target_expression?:
    | 'smile'
    | 'surprise'
    | 'glare'
    | 'panic'
    | 'shyness'
    | 'laugh'
    | 'cry'
    | 'angry'
    | 'sad'
    | 'happy'
    | 'excited'
    | 'shocked'
    | 'confused'
    | 'focused'
    | 'dreamy'
    | 'serious'
    | 'playful'
    | 'mysterious'
    | 'confident'
    | 'thoughtful'
  /**
   * Image Url
   *
   * Portrait image URL for expression change
   */
  image_url: string
}

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export type FalAiImageAppsV2ExpressionChangeAspectRatio = {
  /**
   * Ratio
   *
   * Aspect ratio for 4K resolution output
   */
  ratio?: '1:1' | '16:9' | '9:16' | '4:3' | '3:4'
}

/**
 * ExpressionChangeOutput
 */
export type ImageAppsV2ExpressionChangeOutput = {
  /**
   * Images
   *
   * Portrait with changed expression
   */
  images: Array<FalAiImageAppsV2ExpressionChangeImage>
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageAppsV2ExpressionChangeImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * CityTeleportInput
 */
export type ImageAppsV2CityTeleportInput = {
  /**
   * City Image Url
   *
   * Optional city background image URL. When provided, the person will be blended into this custom scene.
   */
  city_image_url?: string | unknown
  aspect_ratio?: FalAiImageAppsV2CityTeleportAspectRatio
  /**
   * City Name
   *
   * City name (used when city_image_url is not provided)
   */
  city_name: string
  /**
   * Photo Shot
   *
   * Type of photo shot
   */
  photo_shot?:
    | 'extreme_close_up'
    | 'close_up'
    | 'medium_close_up'
    | 'medium_shot'
    | 'medium_long_shot'
    | 'long_shot'
    | 'extreme_long_shot'
    | 'full_body'
  /**
   * Camera Angle
   *
   * Camera angle for the shot
   */
  camera_angle?:
    | 'eye_level'
    | 'low_angle'
    | 'high_angle'
    | 'dutch_angle'
    | 'birds_eye_view'
    | 'worms_eye_view'
    | 'overhead'
    | 'side_angle'
  /**
   * Person Image Url
   *
   * Person photo URL
   */
  person_image_url: string
}

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export type FalAiImageAppsV2CityTeleportAspectRatio = {
  /**
   * Ratio
   *
   * Aspect ratio for 4K resolution output
   */
  ratio?: '1:1' | '16:9' | '9:16' | '4:3' | '3:4'
}

/**
 * CityTeleportOutput
 */
export type ImageAppsV2CityTeleportOutput = {
  /**
   * Images
   *
   * Person teleported to city location
   */
  images: Array<FalAiImageAppsV2CityTeleportImage>
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageAppsV2CityTeleportImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * AgeModifyInput
 */
export type ImageAppsV2AgeModifyInput = {
  /**
   * Image Url
   *
   * Portrait image URL for age modification
   */
  image_url: string
  aspect_ratio?: FalAiImageAppsV2AgeModifyAspectRatio
  /**
   * Preserve Identity
   */
  preserve_identity?: boolean
  /**
   * Target Age
   */
  target_age?: number
}

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export type FalAiImageAppsV2AgeModifyAspectRatio = {
  /**
   * Ratio
   *
   * Aspect ratio for 4K resolution output
   */
  ratio?: '1:1' | '16:9' | '9:16' | '4:3' | '3:4'
}

/**
 * AgeModifyOutput
 */
export type ImageAppsV2AgeModifyOutput = {
  /**
   * Images
   *
   * Portrait with modified age
   */
  images: Array<FalAiImageAppsV2AgeModifyImage>
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageAppsV2AgeModifyImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * MakeupApplicationInput
 */
export type ImageAppsV2MakeupApplicationInput = {
  aspect_ratio?: FalAiImageAppsV2MakeupApplicationAspectRatio
  /**
   * Intensity
   */
  intensity?: 'light' | 'medium' | 'heavy' | 'dramatic'
  /**
   * Makeup Style
   */
  makeup_style?:
    | 'natural'
    | 'glamorous'
    | 'smoky_eyes'
    | 'bold_lips'
    | 'no_makeup'
    | 'remove_makeup'
    | 'dramatic'
    | 'bridal'
    | 'professional'
    | 'korean_style'
    | 'artistic'
  /**
   * Image Url
   *
   * Portrait image URL for makeup application
   */
  image_url: string
}

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export type FalAiImageAppsV2MakeupApplicationAspectRatio = {
  /**
   * Ratio
   *
   * Aspect ratio for 4K resolution output
   */
  ratio?: '1:1' | '16:9' | '9:16' | '4:3' | '3:4'
}

/**
 * MakeupApplicationOutput
 */
export type ImageAppsV2MakeupApplicationOutput = {
  /**
   * Images
   *
   * Portrait with applied makeup
   */
  images: Array<FalAiImageAppsV2MakeupApplicationImage>
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageAppsV2MakeupApplicationImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * BaseQwenEditInpaintImageInput
 */
export type QwenImageEditInpaintInput = {
  /**
   * Prompt
   *
   * The prompt to generate the image with
   */
  prompt: string
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiQwenImageEditInpaintImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Acceleration
   *
   * Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Guidance scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The URL of the image to edit.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Strength
   *
   * Strength of noising process for inpainting
   */
  strength?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Mask URL
   *
   * The URL of the mask for inpainting
   */
  mask_url: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageEditInpaintImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * QwenImageInpaintOutput
 */
export type QwenImageEditInpaintOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiQwenImageEditInpaintImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiQwenImageEditInpaintImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * BaseSRPOImageToInput
 */
export type FluxSrpoImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Strength
   *
   * The strength of the initial image. Higher strength values are better for this model.
   */
  strength?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * Output
 */
export type FluxSrpoImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxSrpoImageToImageImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFluxSrpoImageToImageImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * BaseSRPOFlux1ImageToInput
 */
export type Flux1SrpoImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Strength
   *
   * The strength of the initial image. Higher strength values are better for this model.
   */
  strength?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
}

/**
 * Output
 */
export type Flux1SrpoImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFlux1SrpoImageToImageImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFlux1SrpoImageToImageImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * BaseQwenEditImageLoRAInput
 */
export type QwenImageEditLoraInput = {
  /**
   * Prompt
   *
   * The prompt to generate the image with
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiQwenImageEditLoraImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Acceleration
   *
   * Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The URL of the image to edit.
   */
  image_url: string
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use up to 3 LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<FalAiQwenImageEditLoraLoraWeight>
  /**
   * Guidance scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
}

/**
 * ImageSize
 */
export type FalAiQwenImageEditLoraImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * LoraWeight
 */
export type FalAiQwenImageEditLoraLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
}

/**
 * QwenImageOutput
 */
export type QwenImageEditLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiQwenImageEditLoraImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiQwenImageEditLoraImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * ReferenceToImageRequest
 */
export type ViduReferenceToImageInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 1500 characters
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the output video
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Reference Image Urls
   *
   * URLs of the reference images to use for consistent subject appearance
   */
  reference_image_urls: Array<string>
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number
}

/**
 * ReferenceToImageOutput
 */
export type ViduReferenceToImageOutput = {
  /**
   * Image
   *
   * The edited image
   */
  image: FalAiViduReferenceToImageImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiViduReferenceToImageImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * SeedDream4EditInput
 */
export type BytedanceSeedreamV4EditInput = {
  /**
   * Prompt
   *
   * The text prompt used to edit the image
   */
  prompt: string
  /**
   * Num Images
   *
   * Number of separate model generations to be run with the prompt.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. The minimum total image area is 921600 pixels. Failing this, the image size will be adjusted to by scaling it up, while maintaining the aspect ratio.
   */
  image_size?:
    | FalAiBytedanceSeedreamV4EditImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | 'auto'
    | 'auto_2K'
    | 'auto_4K'
  /**
   * Enhance Prompt Mode
   *
   * The mode to use for enhancing prompt enhancement. Standard mode provides higher quality results but takes longer to generate. Fast mode provides average quality results but takes less time to generate.
   */
  enhance_prompt_mode?: 'standard' | 'fast'
  /**
   * Max Images
   *
   * If set to a number greater than one, enables multi-image generation. The model will potentially return up to `max_images` images every generation, and in total, `num_images` generations will be carried out. In total, the number of images generated will be between `num_images` and `max_images*num_images`. The total number of images (image inputs + image outputs) must not exceed 15
   */
  max_images?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * Random seed to control the stochasticity of image generation.
   */
  seed?: number
  /**
   * Image URLs
   *
   * List of URLs of input images for editing. Presently, up to 10 image inputs are allowed. If over 10 images are sent, only the last 10 will be used.
   */
  image_urls: Array<string>
}

/**
 * ImageSize
 */
export type FalAiBytedanceSeedreamV4EditImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * SeedDream4EditOutput
 */
export type BytedanceSeedreamV4EditOutput = {
  /**
   * Images
   *
   * Generated images
   */
  images: Array<FalAiBytedanceSeedreamV4EditImage>
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiBytedanceSeedreamV4EditImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * WanI2IRequest
 */
export type WanV22A14bImageToImageInput = {
  /**
   * Prompt
   *
   * The text prompt to guide image generation.
   */
  prompt: string
  /**
   * Shift
   */
  shift?: number
  /**
   * Acceleration
   *
   * Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Image Size
   */
  image_size?:
    | FalAiWanV22A14bImageToImageImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Guidance Scale
   *
   * Classifier-free guidance scale.
   */
  guidance_scale?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, input data will be checked for safety before processing.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Image Format
   *
   * The format of the output image.
   */
  image_format?: 'png' | 'jpeg'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated image. If 'auto', the aspect ratio will be determined automatically based on the input image.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16' | '1:1'
  /**
   * Enable Output Safety Checker
   *
   * If set to true, output video will be checked for safety after generation.
   */
  enable_output_safety_checker?: boolean
  /**
   * Image URL
   *
   * URL of the input image.
   */
  image_url: string
  /**
   * Strength
   *
   * Denoising strength. 1.0 = fully remake; 0.0 = preserve original.
   */
  strength?: number
  /**
   * Guidance Scale (2nd Stage)
   *
   * Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.
   */
  guidance_scale_2?: number
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number | unknown
  /**
   * Number of Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiWanV22A14bImageToImageImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * WanI2IResponse
 */
export type WanV22A14bImageToImageOutput = {
  /**
   * Prompt
   *
   * The text prompt used for image generation.
   */
  prompt?: string
  image: FalAiWanV22A14bImageToImageFile
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
}

/**
 * File
 */
export type FalAiWanV22A14bImageToImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * USOInputImage
 */
export type UsoInput = {
  /**
   * Prompt
   *
   * Text prompt for generation. Can be empty for pure style transfer.
   */
  prompt?: string
  /**
   * Number of Images
   *
   * Number of images to generate in parallel.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiUsoImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Output Format
   *
   * Output image format. PNG preserves transparency, JPEG is smaller.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Keep Input Size
   *
   * Preserve the layout and dimensions of the input content image. Useful for style transfer.
   */
  keep_size?: boolean
  /**
   * Reference Images
   *
   * List of image URLs in order: [content_image, style_image, extra_style_image].
   */
  input_image_urls: Array<string>
  /**
   * Sync Mode
   *
   * If true, wait for generation and upload before returning. Increases latency but provides immediate access to images.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale (CFG)
   *
   * How closely to follow the prompt. Higher values stick closer to the prompt.
   */
  guidance_scale?: number
  /**
   * Inference Steps
   *
   * Number of denoising steps. More steps can improve quality but increase generation time.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * Random seed for reproducible generation. Use same seed for consistent results.
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * What you don't want in the image. Use it to exclude unwanted elements, styles, or artifacts.
   */
  negative_prompt?: string
  /**
   * Safety Checker
   *
   * Enable NSFW content detection and filtering.
   */
  enable_safety_checker?: boolean
}

/**
 * ImageSize
 */
export type FalAiUsoImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * USOOutputImage
 */
export type UsoOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation
   */
  prompt: string
  /**
   * Images
   *
   * The generated images with applied style and/or subject customization
   */
  images: Array<FalAiUsoImage>
  /**
   * Timings
   *
   * Performance timings for different stages
   */
  timings: {
    [key: string]: unknown
  }
  /**
   * Has Nsfw Concepts
   *
   * NSFW detection results for each generated image
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiUsoImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * NanoBananaImageToImageInput
 */
export type Gemini25FlashImageEditInput = {
  /**
   * Prompt
   *
   * The prompt for image editing.
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | 'auto'
    | '21:9'
    | '16:9'
    | '3:2'
    | '4:3'
    | '5:4'
    | '1:1'
    | '4:5'
    | '3:4'
    | '2:3'
    | '9:16'
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Image URLs
   *
   * The URLs of the images to use for image-to-image generation or image editing.
   */
  image_urls: Array<string>
  /**
   * Limit Generations
   *
   * Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate.
   */
  limit_generations?: boolean
}

/**
 * NanoBananaImageToImageOutput
 */
export type Gemini25FlashImageEditOutput = {
  /**
   * Images
   *
   * The edited images.
   */
  images: Array<FalAiGemini25FlashImageEditImageFile>
  /**
   * Description
   *
   * The description of the generated images.
   */
  description: string
}

/**
 * ImageFile
 */
export type FalAiGemini25FlashImageEditImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * QwenImageI2IInput
 */
export type QwenImageImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate the image with
   */
  prompt: string
  /**
   * Acceleration
   *
   * Acceleration level for image generation. Options: 'none', 'regular', 'high'. Higher acceleration increases speed. 'regular' balances speed and quality. 'high' is recommended for images without text.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Image Size
   *
   * The size of the generated image. By default, we will use the provided image for determining the image_size.
   */
  image_size?:
    | FalAiQwenImageImageToImageImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use up to 3 LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<FalAiQwenImageImageToImageLoraWeight>
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Guidance scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Use Turbo
   *
   * Enable turbo mode for faster generation with high quality. When enabled, uses optimized settings (10 steps, CFG=1.2).
   */
  use_turbo?: boolean
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image Url
   *
   * The reference image to guide the generation.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Strength
   *
   * Denoising strength. 1.0 = fully remake; 0.0 = preserve original.
   */
  strength?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
}

/**
 * ImageSize
 */
export type FalAiQwenImageImageToImageImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * LoraWeight
 */
export type FalAiQwenImageImageToImageLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
}

/**
 * QwenImageI2IOutput
 */
export type QwenImageImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiQwenImageImageToImageImage>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
}

/**
 * Image
 */
export type FalAiQwenImageImageToImageImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * InputModel
 */
export type Reimagine32Input = {
  /**
   * Prompt
   *
   * Prompt for image generation.
   */
  prompt: string
  /**
   * Depth Preprocess
   *
   * Depth image preprocess.
   */
  depth_preprocess?: boolean
  /**
   * Canny Preprocess
   *
   * Canny image preprocess.
   */
  canny_preprocess?: boolean
  /**
   * Depth Image Url
   *
   * Depth control image (file or URL).
   */
  depth_image_url?: string | unknown
  /**
   * Guidance Scale
   *
   * Guidance scale for text.
   */
  guidance_scale?: number
  /**
   * Canny Image Url
   *
   * Canny edge control image (file or URL).
   */
  canny_image_url?: string | unknown
  /**
   * Negative Prompt
   *
   * Negative prompt for image generation.
   */
  negative_prompt?: string
  /**
   * Depth Scale
   *
   * Depth control strength (0.0 to 1.0).
   */
  depth_scale?: number
  /**
   * Aspect Ratio
   *
   * Aspect ratio. Options: 1:1, 2:3, 3:2, 3:4, 4:3, 4:5, 5:4, 9:16, 16:9
   */
  aspect_ratio?:
    | '1:1'
    | '2:3'
    | '3:2'
    | '3:4'
    | '4:3'
    | '4:5'
    | '5:4'
    | '9:16'
    | '16:9'
  /**
   * Sync Mode
   *
   * If true, returns the image directly in the response (increases latency).
   */
  sync_mode?: boolean
  /**
   * Prompt Enhancer
   *
   * Whether to improve the prompt.
   */
  prompt_enhancer?: boolean
  /**
   * Truncate Prompt
   *
   * Whether to truncate the prompt.
   */
  truncate_prompt?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility.
   */
  seed?: number
  /**
   * Canny Scale
   *
   * Canny edge control strength (0.0 to 1.0).
   */
  canny_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps.
   */
  num_inference_steps?: number
}

/**
 * OutputModel
 */
export type Reimagine32Output = {
  image: BriaReimagine32Image
}

/**
 * Image
 *
 * Represents an image file.
 */
export type BriaReimagine32Image = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * NanoBananaImageToImageInput
 */
export type NanoBananaEditInput = {
  /**
   * Prompt
   *
   * The prompt for image editing.
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | 'auto'
    | '21:9'
    | '16:9'
    | '3:2'
    | '4:3'
    | '5:4'
    | '1:1'
    | '4:5'
    | '3:4'
    | '2:3'
    | '9:16'
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Image URLs
   *
   * The URLs of the images to use for image-to-image generation or image editing.
   */
  image_urls: Array<string>
  /**
   * Limit Generations
   *
   * Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate.
   */
  limit_generations?: boolean
}

/**
 * NanoBananaImageToImageOutput
 */
export type NanoBananaEditOutput = {
  /**
   * Images
   *
   * The edited images.
   */
  images: Array<FalAiNanoBananaEditImageFile>
  /**
   * Description
   *
   * The description of the generated images.
   */
  description: string
}

/**
 * ImageFile
 */
export type FalAiNanoBananaEditImageFile = {
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * NextStepEditRequest
 */
export type Nextstep1Input = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string
  /**
   * Negative Prompt
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   *
   */
  negative_prompt: string
  /**
   * Image URL
   *
   * The URL of the image to edit.
   */
  image_url: string
}

/**
 * NextStepResponse
 */
export type Nextstep1Output = {
  /**
   * Image
   *
   * Generated image
   */
  image: {
    /**
     * File Size
     *
     * The size of the file in bytes.
     */
    file_size?: number | unknown
    /**
     * Height
     *
     * The height of the image in pixels.
     */
    height?: number | unknown
    /**
     * File Name
     *
     * The name of the file. It will be auto-generated if not provided.
     */
    file_name?: string | unknown
    /**
     * Content Type
     *
     * The mime type of the file.
     */
    content_type?: string | unknown
    /**
     * Url
     *
     * The URL where the file can be downloaded from.
     */
    url: string
    /**
     * Width
     *
     * The width of the image in pixels.
     */
    width?: number | unknown
  }
  /**
   * Seed
   *
   * Seed used for random number generation
   */
  seed: number
}

/**
 * BaseQwenEditImageInput
 */
export type QwenImageEditInput = {
  /**
   * Prompt
   *
   * The prompt to generate the image with
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiQwenImageEditImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Acceleration
   *
   * Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The URL of the image to edit.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Guidance scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
}

/**
 * ImageSize
 */
export type FalAiQwenImageEditImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * QwenImageOutput
 */
export type QwenImageEditOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiQwenImageEditImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiQwenImageEditImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * CharacterEditInputV3
 */
export type IdeogramCharacterEditInput = {
  /**
   * Prompt
   *
   * The prompt to fill the masked part of the image.
   */
  prompt: string
  /**
   * Style
   *
   * The style type to generate with. Cannot be used with style_codes.
   */
  style?: 'AUTO' | 'REALISTIC' | 'FICTION'
  /**
   * Expand Prompt
   *
   * Determine if MagicPrompt should be used in generating the request or not.
   */
  expand_prompt?: boolean
  /**
   * Rendering Speed
   *
   * The rendering speed to use.
   */
  rendering_speed?: 'TURBO' | 'BALANCED' | 'QUALITY'
  /**
   * Reference Mask Urls
   *
   * A set of masks to apply to the character references. Currently only 1 mask is supported, rest will be ignored. (maximum total size 10MB across all character references). The masks should be in JPEG, PNG or WebP format
   */
  reference_mask_urls?: Array<string>
  /**
   * Reference Image Urls
   *
   * A set of images to use as character references. Currently only 1 image is supported, rest will be ignored. (maximum total size 10MB across all character references). The images should be in JPEG, PNG or WebP format
   */
  reference_image_urls: Array<string>
  /**
   * Image Urls
   *
   * A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format
   */
  image_urls?: Array<string> | unknown
  /**
   * Num Images
   *
   * Number of images to generate.
   */
  num_images?: number
  /**
   * Image URL
   *
   * The image URL to generate an image from. MUST have the exact same dimensions (width and height) as the mask image.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)
   */
  color_palette?: ColorPalette | unknown
  /**
   * Style Codes
   *
   * A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style
   */
  style_codes?: Array<string> | unknown
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown
  /**
   * Mask URL
   *
   * The mask URL to inpaint the image. MUST have the exact same dimensions (width and height) as the input image.
   */
  mask_url: string
}

/**
 * ColorPalette
 */
export type ColorPalette = {
  /**
   * Members
   *
   * A list of color palette members that define the color palette
   */
  members?: Array<ColorPaletteMember> | unknown
  /**
   * Name
   *
   * A color palette preset value
   */
  name?:
    | 'EMBER'
    | 'FRESH'
    | 'JUNGLE'
    | 'MAGIC'
    | 'MELON'
    | 'MOSAIC'
    | 'PASTEL'
    | 'ULTRAMARINE'
    | unknown
}

/**
 * ColorPaletteMember
 */
export type ColorPaletteMember = {
  /**
   * Color Weight
   *
   * The weight of the color in the color palette
   */
  color_weight?: number | unknown
  rgb: RgbColor
}

/**
 * RGBColor
 */
export type RgbColor = {
  /**
   * R
   *
   * Red color value
   */
  r?: number
  /**
   * B
   *
   * Blue color value
   */
  b?: number
  /**
   * G
   *
   * Green color value
   */
  g?: number
}

/**
 * CharacterEditOutputV3
 */
export type IdeogramCharacterEditOutput = {
  /**
   * Images
   */
  images: Array<FalAiIdeogramCharacterEditFile>
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number
}

/**
 * File
 */
export type FalAiIdeogramCharacterEditFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * BaseCharacterInputV3
 */
export type IdeogramCharacterInput = {
  /**
   * Prompt
   *
   * The prompt to fill the masked part of the image.
   */
  prompt: string
  /**
   * Image Size
   *
   * The resolution of the generated image
   */
  image_size?:
    | FalAiIdeogramCharacterImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Style
   *
   * The style type to generate with. Cannot be used with style_codes.
   */
  style?: 'AUTO' | 'REALISTIC' | 'FICTION'
  /**
   * Expand Prompt
   *
   * Determine if MagicPrompt should be used in generating the request or not.
   */
  expand_prompt?: boolean
  /**
   * Rendering Speed
   *
   * The rendering speed to use.
   */
  rendering_speed?: 'TURBO' | 'BALANCED' | 'QUALITY'
  /**
   * Reference Mask Urls
   *
   * A set of masks to apply to the character references. Currently only 1 mask is supported, rest will be ignored. (maximum total size 10MB across all character references). The masks should be in JPEG, PNG or WebP format
   */
  reference_mask_urls?: Array<string>
  /**
   * Reference Image Urls
   *
   * A set of images to use as character references. Currently only 1 image is supported, rest will be ignored. (maximum total size 10MB across all character references). The images should be in JPEG, PNG or WebP format
   */
  reference_image_urls: Array<string>
  /**
   * Image Urls
   *
   * A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format
   */
  image_urls?: Array<string> | unknown
  /**
   * Negative Prompt
   *
   * Description of what to exclude from an image. Descriptions in the prompt take precedence to descriptions in the negative prompt.
   */
  negative_prompt?: string
  /**
   * Num Images
   *
   * Number of images to generate.
   */
  num_images?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)
   */
  color_palette?: FalAiIdeogramCharacterColorPalette | unknown
  /**
   * Style Codes
   *
   * A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style
   */
  style_codes?: Array<string> | unknown
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown
}

/**
 * ImageSize
 */
export type FalAiIdeogramCharacterImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * ColorPalette
 */
export type FalAiIdeogramCharacterColorPalette = {
  /**
   * Members
   *
   * A list of color palette members that define the color palette
   */
  members?: Array<FalAiIdeogramCharacterColorPaletteMember> | unknown
  /**
   * Name
   *
   * A color palette preset value
   */
  name?:
    | 'EMBER'
    | 'FRESH'
    | 'JUNGLE'
    | 'MAGIC'
    | 'MELON'
    | 'MOSAIC'
    | 'PASTEL'
    | 'ULTRAMARINE'
    | unknown
}

/**
 * ColorPaletteMember
 */
export type FalAiIdeogramCharacterColorPaletteMember = {
  /**
   * Color Weight
   *
   * The weight of the color in the color palette
   */
  color_weight?: number | unknown
  rgb: FalAiIdeogramCharacterRgbColor
}

/**
 * RGBColor
 */
export type FalAiIdeogramCharacterRgbColor = {
  /**
   * R
   *
   * Red color value
   */
  r?: number
  /**
   * B
   *
   * Blue color value
   */
  b?: number
  /**
   * G
   *
   * Green color value
   */
  g?: number
}

/**
 * CharacterOutputV3
 */
export type IdeogramCharacterOutput = {
  /**
   * Images
   */
  images: Array<FalAiIdeogramCharacterFile>
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number
}

/**
 * File
 */
export type FalAiIdeogramCharacterFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * CharacterRemixInputV3
 */
export type IdeogramCharacterRemixInput = {
  /**
   * Prompt
   *
   * The prompt to remix the image with
   */
  prompt: string
  /**
   * Image Size
   *
   * The resolution of the generated image
   */
  image_size?:
    | FalAiIdeogramCharacterRemixImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Style
   *
   * The style type to generate with. Cannot be used with style_codes.
   */
  style?: 'AUTO' | 'REALISTIC' | 'FICTION'
  /**
   * Expand Prompt
   *
   * Determine if MagicPrompt should be used in generating the request or not.
   */
  expand_prompt?: boolean
  /**
   * Rendering Speed
   *
   * The rendering speed to use.
   */
  rendering_speed?: 'TURBO' | 'BALANCED' | 'QUALITY'
  /**
   * Reference Mask Urls
   *
   * A set of masks to apply to the character references. Currently only 1 mask is supported, rest will be ignored. (maximum total size 10MB across all character references). The masks should be in JPEG, PNG or WebP format
   */
  reference_mask_urls?: Array<string>
  /**
   * Reference Image Urls
   *
   * A set of images to use as character references. Currently only 1 image is supported, rest will be ignored. (maximum total size 10MB across all character references). The images should be in JPEG, PNG or WebP format
   */
  reference_image_urls: Array<string>
  /**
   * Image Urls
   *
   * A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format
   */
  image_urls?: Array<string> | unknown
  /**
   * Negative Prompt
   *
   * Description of what to exclude from an image. Descriptions in the prompt take precedence to descriptions in the negative prompt.
   */
  negative_prompt?: string
  /**
   * Num Images
   *
   * Number of images to generate.
   */
  num_images?: number
  /**
   * Image URL
   *
   * The image URL to remix
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)
   */
  color_palette?: FalAiIdeogramCharacterRemixColorPalette | unknown
  /**
   * Style Codes
   *
   * A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style
   */
  style_codes?: Array<string> | unknown
  /**
   * Strength
   *
   * Strength of the input image in the remix
   */
  strength?: number
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown
}

/**
 * ImageSize
 */
export type FalAiIdeogramCharacterRemixImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * ColorPalette
 */
export type FalAiIdeogramCharacterRemixColorPalette = {
  /**
   * Members
   *
   * A list of color palette members that define the color palette
   */
  members?: Array<FalAiIdeogramCharacterRemixColorPaletteMember> | unknown
  /**
   * Name
   *
   * A color palette preset value
   */
  name?:
    | 'EMBER'
    | 'FRESH'
    | 'JUNGLE'
    | 'MAGIC'
    | 'MELON'
    | 'MOSAIC'
    | 'PASTEL'
    | 'ULTRAMARINE'
    | unknown
}

/**
 * ColorPaletteMember
 */
export type FalAiIdeogramCharacterRemixColorPaletteMember = {
  /**
   * Color Weight
   *
   * The weight of the color in the color palette
   */
  color_weight?: number | unknown
  rgb: FalAiIdeogramCharacterRemixRgbColor
}

/**
 * RGBColor
 */
export type FalAiIdeogramCharacterRemixRgbColor = {
  /**
   * R
   *
   * Red color value
   */
  r?: number
  /**
   * B
   *
   * Blue color value
   */
  b?: number
  /**
   * G
   *
   * Green color value
   */
  g?: number
}

/**
 * CharacterRemixOutputV3
 */
export type IdeogramCharacterRemixOutput = {
  /**
   * Images
   */
  images: Array<FalAiIdeogramCharacterRemixFile>
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number
}

/**
 * File
 */
export type FalAiIdeogramCharacterRemixFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * InpaintInput
 */
export type FluxKreaLoraInpaintingInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate. This is always set to 1 for streaming output.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiFluxKreaLoraInpaintingImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image Url
   *
   * URL of image to use for inpainting. or img2img
   */
  image_url: string
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<FalAiFluxKreaLoraInpaintingLoraWeight>
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Strength
   *
   * The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.
   */
  strength?: number
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Mask Url
   *
   *
   * The mask to area to Inpaint in.
   *
   */
  mask_url: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
}

/**
 * ImageSize
 */
export type FalAiFluxKreaLoraInpaintingImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * LoraWeight
 */
export type FalAiFluxKreaLoraInpaintingLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
}

/**
 * Output
 */
export type FluxKreaLoraInpaintingOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxKreaLoraInpaintingImage>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
}

/**
 * Image
 */
export type FalAiFluxKreaLoraInpaintingImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * ImageToImageInput
 */
export type FluxKreaLoraImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate. This is always set to 1 for streaming output.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiFluxKreaLoraImageToImageImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image Url
   *
   * URL of image to use for inpainting. or img2img
   */
  image_url: string
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<FalAiFluxKreaLoraImageToImageLoraWeight>
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Strength
   *
   * The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.
   */
  strength?: number
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
}

/**
 * ImageSize
 */
export type FalAiFluxKreaLoraImageToImageImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * LoraWeight
 */
export type FalAiFluxKreaLoraImageToImageLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
}

/**
 * Output
 */
export type FluxKreaLoraImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxKreaLoraImageToImageImage>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
}

/**
 * Image
 */
export type FalAiFluxKreaLoraImageToImageImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * BaseKreaImageToInput
 */
export type FluxKreaImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Strength
   *
   * The strength of the initial image. Higher strength values are better for this model.
   */
  strength?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * Output
 */
export type FluxKreaImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxKreaImageToImageImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFluxKreaImageToImageImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * BaseKreaReduxInput
 */
export type FluxKreaReduxInput = {
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiFluxKreaReduxImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiFluxKreaReduxImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * KreaReduxOutput
 */
export type FluxKreaReduxOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<FalAiFluxKreaReduxImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFluxKreaReduxImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * BaseKreaFlux1ImageToInput
 */
export type Flux1KreaImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Strength
   *
   * The strength of the initial image. Higher strength values are better for this model.
   */
  strength?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
}

/**
 * KreaOutput
 */
export type Flux1KreaImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<FalAiFlux1KreaImageToImageImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFlux1KreaImageToImageImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * BaseKreaFlux1ReduxInput
 */
export type Flux1KreaReduxInput = {
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiFlux1KreaReduxImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
}

/**
 * ImageSize
 */
export type FalAiFlux1KreaReduxImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * KreaReduxOutput
 */
export type Flux1KreaReduxOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<FalAiFlux1KreaReduxImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFlux1KreaReduxImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * BaseKontextInpaintInput
 */
export type FluxKontextLoraInpaintInput = {
  /**
   * Prompt
   *
   * The prompt for the image to image task.
   */
  prompt: string
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Reference Image URL
   *
   * The URL of the reference image for inpainting.
   */
  reference_image_url: string
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<FalAiFluxKontextLoraInpaintLoraWeight>
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The URL of the image to be inpainted.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Strength
   *
   * The strength of the initial image. Higher strength values are better for this model.
   */
  strength?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Image URL
   *
   * The URL of the mask for inpainting.
   */
  mask_url: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
}

/**
 * LoraWeight
 */
export type FalAiFluxKontextLoraInpaintLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
}

/**
 * KontextInpaintOutput
 */
export type FluxKontextLoraInpaintOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxKontextLoraInpaintImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFluxKontextLoraInpaintImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * ImageToPanoramaRequest
 */
export type HunyuanWorldInput = {
  /**
   * Prompt
   *
   * The prompt to use for the panorama generation.
   */
  prompt: string
  /**
   * Image Url
   *
   * The URL of the image to convert to a panorama.
   */
  image_url: string
}

/**
 * ImageToPanoramaResponse
 */
export type HunyuanWorldOutput = {
  /**
   * Image
   *
   * The generated panorama image.
   */
  image: FalAiHunyuanWorldImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiHunyuanWorldImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * RetouchInput
 *
 * Input model for retouch endpoint.
 */
export type ImageEditingRetouchInput = {
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number
  /**
   * Image URL
   *
   * URL of the image to retouch.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
}

/**
 * RetouchOutput
 */
export type ImageEditingRetouchOutput = {
  /**
   * Images
   */
  images: Array<FalAiImageEditingRetouchImage>
  /**
   * Seed
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageEditingRetouchImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * BaseInput
 */
export type HidreamE11Input = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt?: string
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Guidance Scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your initial image when looking for a related image to show you.
   *
   */
  image_guidance_scale?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * URL of an input image to edit.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Target Image Description
   *
   * The description of the target image after your edits have been made. Leave this blank to allow the model to use its own imagination.
   */
  target_image_description?: string
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
}

/**
 * Output
 */
export type HidreamE11Output = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiHidreamE11Image>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiHidreamE11Image = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * RIFEImageInput
 */
export type RifeInput = {
  /**
   * Output Format
   *
   * The format of the output images. Only applicable if output_type is 'images'.
   */
  output_format?: 'png' | 'jpeg'
  /**
   * Frames Per Second
   *
   * Frames per second for the output video. Only applicable if output_type is 'video'.
   */
  fps?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Include End
   *
   * Whether to include the end image in the output.
   */
  include_end?: boolean
  /**
   * Include Start
   *
   * Whether to include the start image in the output.
   */
  include_start?: boolean
  /**
   * Number of Frames
   *
   * The number of frames to generate between the input images.
   */
  num_frames?: number
  /**
   * End Image URL
   *
   * The URL of the second image to use as the ending point for interpolation.
   */
  end_image_url: string
  /**
   * Output Type
   *
   * The type of output to generate; either individual images or a video.
   */
  output_type?: 'images' | 'video'
  /**
   * Start Image URL
   *
   * The URL of the first image to use as the starting point for interpolation.
   */
  start_image_url: string
}

/**
 * RIFEImageOutput
 */
export type RifeOutput = {
  /**
   * Images
   *
   * The generated frames as individual images.
   */
  images?: Array<FalAiRifeImage>
  /**
   * Video
   *
   * The generated video file, if output_type is 'video'.
   */
  video?: FalAiRifeFile
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiRifeImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * File
 */
export type FalAiRifeFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * FILMImageInput
 */
export type FilmInput = {
  /**
   * Video Write Mode
   *
   * The write mode of the output video. Only applicable if output_type is 'video'.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Number of Frames
   *
   * The number of frames to generate between the input images.
   */
  num_frames?: number
  /**
   * Include Start
   *
   * Whether to include the start image in the output.
   */
  include_start?: boolean
  /**
   * Video Quality
   *
   * The quality of the output video. Only applicable if output_type is 'video'.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Include End
   *
   * Whether to include the end image in the output.
   */
  include_end?: boolean
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Frames Per Second
   *
   * Frames per second for the output video. Only applicable if output_type is 'video'.
   */
  fps?: number
  /**
   * Start Image URL
   *
   * The URL of the first image to use as the starting point for interpolation.
   */
  start_image_url: string
  /**
   * End Image URL
   *
   * The URL of the second image to use as the ending point for interpolation.
   */
  end_image_url: string
  /**
   * Image Format
   *
   * The format of the output images. Only applicable if output_type is 'images'.
   */
  image_format?: 'png' | 'jpeg'
  /**
   * Output Type
   *
   * The type of output to generate; either individual images or a video.
   */
  output_type?: 'images' | 'video'
}

/**
 * FILMImageOutput
 */
export type FilmOutput = {
  /**
   * Images
   *
   * The generated frames as individual images.
   */
  images?: Array<FalAiFilmImageFile>
  /**
   * Video
   *
   * The generated video file, if output_type is 'video'.
   */
  video?: VideoFile
}

/**
 * ImageFile
 */
export type FalAiFilmImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * VideoFile
 */
export type VideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number
  /**
   * Height
   *
   * The height of the video
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the video
   */
  width?: number
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Input
 */
export type CalligrapherInput = {
  /**
   * Use Context
   *
   * Whether to prepend context reference to the input
   */
  use_context?: boolean
  /**
   * Num Images
   *
   * How many images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * Target image size for generation
   */
  image_size?:
    | FalAiCalligrapherImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Auto Mask Generation
   *
   * Whether to automatically generate mask from detected text
   */
  auto_mask_generation?: boolean
  /**
   * Reference Image Url
   *
   * Optional base64 reference image for style
   */
  reference_image_url?: string
  /**
   * Source Image Url
   *
   * Base64-encoded source image with drawn mask layers
   */
  source_image_url: string
  /**
   * Prompt
   *
   * Text prompt to inpaint or customize
   */
  prompt: string
  /**
   * Mask Image Url
   *
   * Base64-encoded mask image (optional if using auto_mask_generation)
   */
  mask_image_url?: string
  /**
   * Source Text
   *
   * Source text to replace (if empty, masks all detected text)
   */
  source_text?: string
  /**
   * Num Inference Steps
   *
   * Number of inference steps (1-100)
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * Random seed for reproducibility
   */
  seed?: number
  /**
   * Cfg Scale
   *
   * Guidance or strength scale for the model
   */
  cfg_scale?: number
}

/**
 * ImageSize
 */
export type FalAiCalligrapherImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Output
 */
export type CalligrapherOutput = {
  /**
   * Images
   */
  images: Array<FalAiCalligrapherImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiCalligrapherImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ReimagineInput
 */
export type BriaReimagineInput = {
  /**
   * Prompt
   *
   * The prompt you would like to use to generate images.
   */
  prompt: string
  /**
   * Num Results
   *
   * How many images you would like to generate. When using any Guidance Method, Value is set to 1.
   */
  num_results?: number
  /**
   * Structure Ref Influence
   *
   * The influence of the structure reference on the generated image.
   */
  structure_ref_influence?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Fast
   *
   * Whether to use the fast model
   */
  fast?: boolean
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Num Inference Steps
   *
   * The number of iterations the model goes through to refine the generated image. This parameter is optional.
   */
  num_inference_steps?: number
  /**
   * Structure Image Url
   *
   * The URL of the structure reference image. Use "" to leave empty. Accepted formats are jpeg, jpg, png, webp.
   */
  structure_image_url?: string
}

/**
 * ReimagineOutput
 */
export type BriaReimagineOutput = {
  /**
   * Images
   *
   * The generated images
   */
  images: Array<FalAiBriaReimagineImage>
  /**
   * Seed
   *
   * Seed value used for generation.
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiBriaReimagineImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * RealismInput
 *
 * Input model for realism enhancement endpoint.
 */
export type ImageEditingRealismInput = {
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number
  /**
   * Image URL
   *
   * URL of the image to enhance with realism details.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
}

/**
 * RealismOutput
 */
export type ImageEditingRealismOutput = {
  /**
   * Images
   */
  images: Array<FalAiImageEditingRealismImage>
  /**
   * Seed
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageEditingRealismImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * VignetteInput
 */
export type PostProcessingVignetteInput = {
  /**
   * Vignette Strength
   *
   * Vignette strength
   */
  vignette_strength?: number
  /**
   * Image Url
   *
   * URL of image to process
   */
  image_url: string
}

/**
 * VignetteOutput
 */
export type PostProcessingVignetteOutput = {
  /**
   * Images
   *
   * The processed images with vignette effect
   */
  images: Array<FalAiPostProcessingVignetteImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiPostProcessingVignetteImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * SolarizeInput
 */
export type PostProcessingSolarizeInput = {
  /**
   * Solarize Threshold
   *
   * Solarize threshold
   */
  solarize_threshold?: number
  /**
   * Image Url
   *
   * URL of image to process
   */
  image_url: string
}

/**
 * SolarizeOutput
 */
export type PostProcessingSolarizeOutput = {
  /**
   * Images
   *
   * The processed images with solarize effect
   */
  images: Array<FalAiPostProcessingSolarizeImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiPostProcessingSolarizeImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * SharpenInput
 */
export type PostProcessingSharpenInput = {
  /**
   * Sharpen Mode
   *
   * Type of sharpening to apply
   */
  sharpen_mode?: 'basic' | 'smart' | 'cas'
  /**
   * Sharpen Alpha
   *
   * Sharpen strength (for basic mode)
   */
  sharpen_alpha?: number
  /**
   * Noise Radius
   *
   * Noise radius for smart sharpen
   */
  noise_radius?: number
  /**
   * Sharpen Radius
   *
   * Sharpen radius (for basic mode)
   */
  sharpen_radius?: number
  /**
   * Image Url
   *
   * URL of image to process
   */
  image_url: string
  /**
   * Smart Sharpen Strength
   *
   * Smart sharpen strength
   */
  smart_sharpen_strength?: number
  /**
   * Cas Amount
   *
   * CAS sharpening amount
   */
  cas_amount?: number
  /**
   * Preserve Edges
   *
   * Edge preservation factor
   */
  preserve_edges?: number
  /**
   * Smart Sharpen Ratio
   *
   * Smart sharpen blend ratio
   */
  smart_sharpen_ratio?: number
}

/**
 * SharpenOutput
 */
export type PostProcessingSharpenOutput = {
  /**
   * Images
   *
   * The processed images with sharpen effect
   */
  images: Array<FalAiPostProcessingSharpenImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiPostProcessingSharpenImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ParabolizeInput
 */
export type PostProcessingParabolizeInput = {
  /**
   * Parabolize Coeff
   *
   * Parabolize coefficient
   */
  parabolize_coeff?: number
  /**
   * Vertex Y
   *
   * Vertex Y position
   */
  vertex_y?: number
  /**
   * Vertex X
   *
   * Vertex X position
   */
  vertex_x?: number
  /**
   * Image Url
   *
   * URL of image to process
   */
  image_url: string
}

/**
 * ParabolizeOutput
 */
export type PostProcessingParabolizeOutput = {
  /**
   * Images
   *
   * The processed images with parabolize effect
   */
  images: Array<FalAiPostProcessingParabolizeImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiPostProcessingParabolizeImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * GrainInput
 */
export type PostProcessingGrainInput = {
  /**
   * Grain Style
   *
   * Style of film grain to apply
   */
  grain_style?:
    | 'modern'
    | 'analog'
    | 'kodak'
    | 'fuji'
    | 'cinematic'
    | 'newspaper'
  /**
   * Grain Intensity
   *
   * Film grain intensity
   */
  grain_intensity?: number
  /**
   * Grain Scale
   *
   * Film grain scale
   */
  grain_scale?: number
  /**
   * Image Url
   *
   * URL of image to process
   */
  image_url: string
}

/**
 * GrainOutput
 */
export type PostProcessingGrainOutput = {
  /**
   * Images
   *
   * The processed images with grain effect
   */
  images: Array<FalAiPostProcessingGrainImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiPostProcessingGrainImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * DodgeBurnInput
 */
export type PostProcessingDodgeBurnInput = {
  /**
   * Dodge Burn Mode
   *
   * Dodge and burn mode
   */
  dodge_burn_mode?:
    | 'dodge'
    | 'burn'
    | 'dodge_and_burn'
    | 'burn_and_dodge'
    | 'color_dodge'
    | 'color_burn'
    | 'linear_dodge'
    | 'linear_burn'
  /**
   * Dodge Burn Intensity
   *
   * Dodge and burn intensity
   */
  dodge_burn_intensity?: number
  /**
   * Image Url
   *
   * URL of image to process
   */
  image_url: string
}

/**
 * DodgeBurnOutput
 */
export type PostProcessingDodgeBurnOutput = {
  /**
   * Images
   *
   * The processed images with dodge and burn effect
   */
  images: Array<FalAiPostProcessingDodgeBurnImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiPostProcessingDodgeBurnImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * DissolveInput
 */
export type PostProcessingDissolveInput = {
  /**
   * Dissolve Factor
   *
   * Dissolve blend factor
   */
  dissolve_factor?: number
  /**
   * Dissolve Image Url
   *
   * URL of second image for dissolve
   */
  dissolve_image_url: string
  /**
   * Image Url
   *
   * URL of image to process
   */
  image_url: string
}

/**
 * DissolveOutput
 */
export type PostProcessingDissolveOutput = {
  /**
   * Images
   *
   * The processed images with dissolve effect
   */
  images: Array<FalAiPostProcessingDissolveImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiPostProcessingDissolveImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * DesaturateInput
 */
export type PostProcessingDesaturateInput = {
  /**
   * Desaturate Method
   *
   * Desaturation method
   */
  desaturate_method?:
    | 'luminance (Rec.709)'
    | 'luminance (Rec.601)'
    | 'average'
    | 'lightness'
  /**
   * Desaturate Factor
   *
   * Desaturation factor
   */
  desaturate_factor?: number
  /**
   * Image Url
   *
   * URL of image to process
   */
  image_url: string
}

/**
 * DesaturateOutput
 */
export type PostProcessingDesaturateOutput = {
  /**
   * Images
   *
   * The processed images with desaturation effect
   */
  images: Array<FalAiPostProcessingDesaturateImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiPostProcessingDesaturateImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ColorTintInput
 */
export type PostProcessingColorTintInput = {
  /**
   * Tint Strength
   *
   * Tint strength
   */
  tint_strength?: number
  /**
   * Tint Mode
   *
   * Tint color mode
   */
  tint_mode?:
    | 'sepia'
    | 'red'
    | 'green'
    | 'blue'
    | 'cyan'
    | 'magenta'
    | 'yellow'
    | 'purple'
    | 'orange'
    | 'warm'
    | 'cool'
    | 'lime'
    | 'navy'
    | 'vintage'
    | 'rose'
    | 'teal'
    | 'maroon'
    | 'peach'
    | 'lavender'
    | 'olive'
  /**
   * Image Url
   *
   * URL of image to process
   */
  image_url: string
}

/**
 * ColorTintOutput
 */
export type PostProcessingColorTintOutput = {
  /**
   * Images
   *
   * The processed images with color tint effect
   */
  images: Array<FalAiPostProcessingColorTintImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiPostProcessingColorTintImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ColorCorrectionInput
 */
export type PostProcessingColorCorrectionInput = {
  /**
   * Gamma
   *
   * Gamma adjustment
   */
  gamma?: number
  /**
   * Saturation
   *
   * Saturation adjustment
   */
  saturation?: number
  /**
   * Temperature
   *
   * Color temperature adjustment
   */
  temperature?: number
  /**
   * Brightness
   *
   * Brightness adjustment
   */
  brightness?: number
  /**
   * Contrast
   *
   * Contrast adjustment
   */
  contrast?: number
  /**
   * Image Url
   *
   * URL of image to process
   */
  image_url: string
}

/**
 * ColorCorrectionOutput
 */
export type PostProcessingColorCorrectionOutput = {
  /**
   * Images
   *
   * The processed images with color correction
   */
  images: Array<FalAiPostProcessingColorCorrectionImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiPostProcessingColorCorrectionImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ChromaticAberrationInput
 */
export type PostProcessingChromaticAberrationInput = {
  /**
   * Blue Shift
   *
   * Blue channel shift amount
   */
  blue_shift?: number
  /**
   * Red Shift
   *
   * Red channel shift amount
   */
  red_shift?: number
  /**
   * Green Direction
   *
   * Green channel shift direction
   */
  green_direction?: 'horizontal' | 'vertical'
  /**
   * Blue Direction
   *
   * Blue channel shift direction
   */
  blue_direction?: 'horizontal' | 'vertical'
  /**
   * Red Direction
   *
   * Red channel shift direction
   */
  red_direction?: 'horizontal' | 'vertical'
  /**
   * Image Url
   *
   * URL of image to process
   */
  image_url: string
  /**
   * Green Shift
   *
   * Green channel shift amount
   */
  green_shift?: number
}

/**
 * ChromaticAberrationOutput
 */
export type PostProcessingChromaticAberrationOutput = {
  /**
   * Images
   *
   * The processed images with chromatic aberration effect
   */
  images: Array<FalAiPostProcessingChromaticAberrationImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiPostProcessingChromaticAberrationImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * BlurInput
 */
export type PostProcessingBlurInput = {
  /**
   * Blur Sigma
   *
   * Sigma for Gaussian blur
   */
  blur_sigma?: number
  /**
   * Blur Radius
   *
   * Blur radius
   */
  blur_radius?: number
  /**
   * Blur Type
   *
   * Type of blur to apply
   */
  blur_type?: 'gaussian' | 'kuwahara'
  /**
   * Image Url
   *
   * URL of image to process
   */
  image_url: string
}

/**
 * BlurOutput
 */
export type PostProcessingBlurOutput = {
  /**
   * Images
   *
   * The processed images with blur effect
   */
  images: Array<FalAiPostProcessingBlurImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiPostProcessingBlurImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * YouTubeThumbnailsInput
 *
 * Input model for YouTube thumbnails endpoint.
 */
export type ImageEditingYoutubeThumbnailsInput = {
  /**
   * Thumbnail Text
   *
   * The text to include in the YouTube thumbnail.
   */
  prompt?: string
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number
  /**
   * Image URL
   *
   * URL of the image to convert to YouTube thumbnail style.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
}

/**
 * YouTubeThumbnailsOutput
 */
export type ImageEditingYoutubeThumbnailsOutput = {
  /**
   * Images
   */
  images: Array<FalAiImageEditingYoutubeThumbnailsImage>
  /**
   * Seed
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageEditingYoutubeThumbnailsImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageUpscaleRequest
 */
export type TopazUpscaleImageInput = {
  /**
   * Face Enhancement Creativity
   *
   * Creativity level for face enhancement. 0.0 means no creativity, 1.0 means maximum creativity. Ignored if face ehnancement is disabled.
   */
  face_enhancement_creativity?: number
  /**
   * Face Enhancement Strength
   *
   * Strength of the face enhancement. 0.0 means no enhancement, 1.0 means maximum enhancement. Ignored if face ehnancement is disabled.
   */
  face_enhancement_strength?: number
  /**
   * Output Format
   *
   * Output format of the upscaled image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Face Enhancement
   *
   * Whether to apply face enhancement to the image.
   */
  face_enhancement?: boolean
  /**
   * Subject Detection
   *
   * Subject detection mode for the image enhancement.
   */
  subject_detection?: 'All' | 'Foreground' | 'Background'
  /**
   * Model
   *
   * Model to use for image enhancement.
   */
  model?:
    | 'Low Resolution V2'
    | 'Standard V2'
    | 'CGI'
    | 'High Fidelity V2'
    | 'Text Refine'
    | 'Recovery'
    | 'Redefine'
    | 'Recovery V2'
  /**
   * Image Url
   *
   * Url of the image to be upscaled
   */
  image_url: string
  /**
   * Upscale Factor
   *
   * Factor to upscale the video by (e.g. 2.0 doubles width and height)
   */
  upscale_factor?: number
  /**
   * Crop To Fill
   */
  crop_to_fill?: boolean
}

/**
 * ImageUpscaleOutput
 */
export type TopazUpscaleImageOutput = {
  /**
   * Image
   *
   * The upscaled image.
   */
  image: FalAiTopazUpscaleImageFile
}

/**
 * File
 */
export type FalAiTopazUpscaleImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * BroccoliHaircutInput
 *
 * Input model for broccoli haircut endpoint.
 */
export type ImageEditingBroccoliHaircutInput = {
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number
  /**
   * Image URL
   *
   * URL of the image to apply broccoli haircut style.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
}

/**
 * BroccoliHaircutOutput
 */
export type ImageEditingBroccoliHaircutOutput = {
  /**
   * Images
   */
  images: Array<FalAiImageEditingBroccoliHaircutImage>
  /**
   * Seed
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageEditingBroccoliHaircutImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * WojakStyleInput
 *
 * Input model for wojak style endpoint.
 */
export type ImageEditingWojakStyleInput = {
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number
  /**
   * Image URL
   *
   * URL of the image to convert to wojak style.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
}

/**
 * WojakStyleOutput
 */
export type ImageEditingWojakStyleOutput = {
  /**
   * Images
   */
  images: Array<FalAiImageEditingWojakStyleImage>
  /**
   * Seed
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageEditingWojakStyleImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * PlushieStyleInput
 *
 * Input model for plushie style endpoint.
 */
export type ImageEditingPlushieStyleInput = {
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number
  /**
   * Image URL
   *
   * URL of the image to convert to plushie style.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.
   */
  sync_mode?: boolean
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean
}

/**
 * PlushieStyleOutput
 */
export type ImageEditingPlushieStyleOutput = {
  /**
   * Images
   */
  images: Array<FalAiImageEditingPlushieStyleImage>
  /**
   * Seed
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageEditingPlushieStyleImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * BaseKontextEditInput
 */
export type FluxKontextLoraInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Resolution Mode
   *
   *
   * Determines how the output resolution is set for image editing.
   * - `auto`: The model selects an optimal resolution from a predefined set that best matches the input image's aspect ratio. This is the recommended setting for most use cases as it's what the model was trained on.
   * - `match_input`: The model will attempt to use the same resolution as the input image. The resolution will be adjusted to be compatible with the model's requirements (e.g. dimensions must be multiples of 16 and within supported limits).
   * Apart from these, a few aspect ratios are also supported.
   *
   */
  resolution_mode?:
    | 'auto'
    | 'match_input'
    | '1:1'
    | '16:9'
    | '21:9'
    | '3:2'
    | '2:3'
    | '4:5'
    | '5:4'
    | '3:4'
    | '4:3'
    | '9:16'
    | '9:21'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The URL of the image to edit.
   *
   * Max width: 14142px, Max height: 14142px, Timeout: 20s
   */
  image_url: string
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<FalAiFluxKontextLoraLoraWeight>
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
}

/**
 * LoraWeight
 */
export type FalAiFluxKontextLoraLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
}

/**
 * KontextEditOutput
 */
export type FluxKontextLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxKontextLoraImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFluxKontextLoraImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * V16Input
 */
export type FashnTryonV16Input = {
  /**
   * Model Image
   *
   * URL or base64 of the model image
   */
  model_image: string
  /**
   * Moderation Level
   *
   * Content moderation level for garment images. 'none' disables moderation, 'permissive' blocks only explicit content, 'conservative' also blocks underwear and swimwear.
   */
  moderation_level?: 'none' | 'permissive' | 'conservative'
  /**
   * Garment Photo Type
   *
   * Specifies the type of garment photo to optimize internal parameters for better performance. 'model' is for photos of garments on a model, 'flat-lay' is for flat-lay or ghost mannequin images, and 'auto' attempts to automatically detect the photo type.
   */
  garment_photo_type?: 'auto' | 'model' | 'flat-lay'
  /**
   * Garment Image
   *
   * URL or base64 of the garment image
   */
  garment_image: string
  /**
   * Category
   *
   * Category of the garment to try-on. 'auto' will attempt to automatically detect the category of the garment.
   */
  category?: 'tops' | 'bottoms' | 'one-pieces' | 'auto'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Segmentation Free
   *
   * Disables human parsing on the model image.
   */
  segmentation_free?: boolean
  /**
   * Num Samples
   *
   * Number of images to generate in a single run. Image generation has a random element in it, so trying multiple images at once increases the chances of getting a good result.
   */
  num_samples?: number
  /**
   * Mode
   *
   * Specifies the mode of operation. 'performance' mode is faster but may sacrifice quality, 'balanced' mode is a balance between speed and quality, and 'quality' mode is slower but produces higher quality results.
   */
  mode?: 'performance' | 'balanced' | 'quality'
  /**
   * Seed
   *
   * Sets random operations to a fixed state. Use the same seed to reproduce results with the same inputs, or different seed to force different results.
   */
  seed?: number
  /**
   * Output Format
   *
   * Output format of the generated images. 'png' is highest quality, while 'jpeg' is faster
   */
  output_format?: 'png' | 'jpeg'
}

/**
 * V16Output
 */
export type FashnTryonV16Output = {
  /**
   * Images
   */
  images: Array<FalAiFashnTryonV16File>
}

/**
 * File
 */
export type FalAiFashnTryonV16File = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Input
 */
export type ChainOfZoomInput = {
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean
  /**
   * Center Y
   *
   * Y coordinate of zoom center (0-1)
   */
  center_y?: number
  /**
   * Scale
   *
   * Zoom scale in powers of 2
   */
  scale?: number
  /**
   * Center X
   *
   * X coordinate of zoom center (0-1)
   */
  center_x?: number
  /**
   * User Prompt
   *
   * Additional prompt text to guide the zoom enhancement
   */
  user_prompt?: string
  /**
   * Image Url
   *
   * Input image to zoom into
   */
  image_url: string
}

/**
 * Output
 */
export type ChainOfZoomOutput = {
  /**
   * Images
   *
   * List of intermediate images
   */
  images: Array<FalAiChainOfZoomImage>
  /**
   * Zoom Center
   *
   * Center coordinates used for zoom
   */
  zoom_center: Array<number>
  /**
   * Scale
   *
   * Actual linear zoom scale applied
   */
  scale: number
}

/**
 * Image
 */
export type FalAiChainOfZoomImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * Input
 */
export type PasdInput = {
  /**
   * Conditioning Scale
   *
   * ControlNet conditioning scale (0.1-1.0)
   */
  conditioning_scale?: number
  /**
   * Prompt
   *
   * Additional prompt to guide super-resolution
   */
  prompt?: string
  /**
   * Image Url
   *
   * Input image to super-resolve
   */
  image_url: string
  /**
   * Steps
   *
   * Number of inference steps (10-50)
   */
  steps?: number
  /**
   * Scale
   *
   * Upscaling factor (1-4x)
   */
  scale?: number
  /**
   * Guidance Scale
   *
   * Guidance scale for diffusion (1.0-20.0)
   */
  guidance_scale?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to avoid unwanted artifacts
   */
  negative_prompt?: string
}

/**
 * Output
 */
export type PasdOutput = {
  /**
   * Images
   *
   * The generated super-resolved images
   */
  images: Array<FalAiPasdImage>
  /**
   * Timings
   *
   * Timing information for different processing stages
   */
  timings?: {
    [key: string]: number
  }
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiPasdImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * BboxInput
 */
export type ObjectRemovalBboxInput = {
  /**
   * Model
   */
  model?: 'low_quality' | 'medium_quality' | 'high_quality' | 'best_quality'
  /**
   * Mask Expansion
   *
   * Amount of pixels to expand the mask by. Range: 0-50
   */
  mask_expansion?: number
  /**
   * Box Prompts
   *
   * List of bounding box coordinates to erase (only one box prompt is supported)
   */
  box_prompts?: Array<BBoxPromptBase>
  /**
   * Image Url
   *
   * The URL of the image to remove objects from.
   */
  image_url: string
}

/**
 * BBoxPromptBase
 */
export type BBoxPromptBase = {
  /**
   * Y Min
   *
   * Y Min Coordinate of the box (0-1)
   */
  y_min?: number
  /**
   * X Max
   *
   * X Max Coordinate of the prompt (0-1)
   */
  x_max?: number
  /**
   * X Min
   *
   * X Min Coordinate of the box (0-1)
   */
  x_min?: number
  /**
   * Y Max
   *
   * Y Max Coordinate of the prompt (0-1)
   */
  y_max?: number
}

/**
 * Output
 */
export type ObjectRemovalBboxOutput = {
  /**
   * Images
   *
   * The generated images with objects removed.
   */
  images: Array<FalAiObjectRemovalBboxImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiObjectRemovalBboxImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * MaskInput
 */
export type ObjectRemovalMaskInput = {
  /**
   * Model
   */
  model?: 'low_quality' | 'medium_quality' | 'high_quality' | 'best_quality'
  /**
   * Mask Expansion
   *
   * Amount of pixels to expand the mask by. Range: 0-50
   */
  mask_expansion?: number
  /**
   * Mask Url
   *
   * The URL of the mask image. White pixels (255) indicate areas to remove.
   */
  mask_url: string
  /**
   * Image Url
   *
   * The URL of the image to remove objects from.
   */
  image_url: string
}

/**
 * Output
 */
export type ObjectRemovalMaskOutput = {
  /**
   * Images
   *
   * The generated images with objects removed.
   */
  images: Array<FalAiObjectRemovalMaskImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiObjectRemovalMaskImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * PromptInput
 */
export type ObjectRemovalInput = {
  /**
   * Prompt
   *
   * Text description of the object to remove.
   */
  prompt: string
  /**
   * Mask Expansion
   *
   * Amount of pixels to expand the mask by. Range: 0-50
   */
  mask_expansion?: number
  /**
   * Model
   */
  model?: 'low_quality' | 'medium_quality' | 'high_quality' | 'best_quality'
  /**
   * Image Url
   *
   * The URL of the image to remove objects from.
   */
  image_url: string
}

/**
 * Output
 */
export type ObjectRemovalOutput = {
  /**
   * Images
   *
   * The generated images with objects removed.
   */
  images: Array<FalAiObjectRemovalImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiObjectRemovalImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * VectorizeInput
 */
export type RecraftVectorizeInput = {
  /**
   * Image Url
   *
   * The URL of the image to be vectorized. Must be in PNG, JPG or WEBP format, less than 5 MB in size, have resolution less than 16 MP and max dimension less than 4096 pixels, min dimension more than 256 pixels.
   */
  image_url: string
}

/**
 * VectorizeOutput
 */
export type RecraftVectorizeOutput = {
  /**
   * Image
   *
   * The vectorized image.
   */
  image: FalAiRecraftVectorizeFile
}

/**
 * File
 */
export type FalAiRecraftVectorizeFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * FrameInput
 */
export type FfmpegApiExtractFrameInput = {
  /**
   * Video Url
   *
   * URL of the video file to use as the video track
   */
  video_url: string
  /**
   * Frame Type
   *
   * Type of frame to extract: first, middle, or last frame of the video
   */
  frame_type?: 'first' | 'middle' | 'last'
}

/**
 * FrameOutput
 */
export type FfmpegApiExtractFrameOutput = {
  /**
   * Images
   */
  images: Array<FalAiFfmpegApiExtractFrameImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiFfmpegApiExtractFrameImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * ModifyImageRequest
 */
export type LumaPhotonFlashModifyInput = {
  /**
   * Prompt
   *
   * Instruction for modifying the image
   */
  prompt?: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the reframed image
   */
  aspect_ratio: '1:1' | '16:9' | '9:16' | '4:3' | '3:4' | '21:9' | '9:21'
  /**
   * Strength
   *
   * The strength of the initial image. Higher strength values are corresponding to more influence of the initial image on the output.
   */
  strength: number
  /**
   * Image Url
   *
   * URL of the input image to reframe
   */
  image_url: string
}

/**
 * T2IOutput
 */
export type LumaPhotonFlashModifyOutput = {
  /**
   * Images
   *
   * The generated image
   */
  images: Array<FalAiLumaPhotonFlashModifyFile>
}

/**
 * File
 */
export type FalAiLumaPhotonFlashModifyFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ModifyImageRequest
 */
export type LumaPhotonModifyInput = {
  /**
   * Prompt
   *
   * Instruction for modifying the image
   */
  prompt?: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the reframed image
   */
  aspect_ratio: '1:1' | '16:9' | '9:16' | '4:3' | '3:4' | '21:9' | '9:21'
  /**
   * Strength
   *
   * The strength of the initial image. Higher strength values are corresponding to more influence of the initial image on the output.
   */
  strength: number
  /**
   * Image Url
   *
   * URL of the input image to reframe
   */
  image_url: string
}

/**
 * T2IOutput
 */
export type LumaPhotonModifyOutput = {
  /**
   * Images
   *
   * The generated image
   */
  images: Array<FalAiLumaPhotonModifyFile>
}

/**
 * File
 */
export type FalAiLumaPhotonModifyFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ReframeInput
 */
export type ImageEditingReframeInput = {
  /**
   * Aspect Ratio
   *
   * The desired aspect ratio for the reframed image.
   */
  aspect_ratio?:
    | '21:9'
    | '16:9'
    | '4:3'
    | '3:2'
    | '1:1'
    | '2:3'
    | '3:4'
    | '9:16'
    | '9:21'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * URL of the old or damaged photo to restore.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5' | '6'
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
}

/**
 * ReframeOutput
 */
export type ImageEditingReframeOutput = {
  /**
   * Images
   */
  images: Array<FalAiImageEditingReframeImage>
  /**
   * Seed
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageEditingReframeImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * BabyVersionInput
 *
 * Input model for baby version endpoint.
 */
export type ImageEditingBabyVersionInput = {
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | '21:9'
    | '16:9'
    | '4:3'
    | '3:2'
    | '1:1'
    | '2:3'
    | '3:4'
    | '9:16'
    | '9:21'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * URL of the image to transform into a baby version.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5' | '6'
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
}

/**
 * BabyVersionOutput
 */
export type ImageEditingBabyVersionOutput = {
  /**
   * Images
   */
  images: Array<FalAiImageEditingBabyVersionImage>
  /**
   * Seed
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageEditingBabyVersionImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ReframeImageRequest
 */
export type LumaPhotonFlashReframeInput = {
  /**
   * Prompt
   *
   * Optional prompt for reframing
   */
  prompt?: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the reframed image
   */
  aspect_ratio: '1:1' | '16:9' | '9:16' | '4:3' | '3:4' | '21:9' | '9:21'
  /**
   * Y Start
   *
   * Start Y coordinate for reframing
   */
  y_start?: number
  /**
   * X End
   *
   * End X coordinate for reframing
   */
  x_end?: number
  /**
   * Y End
   *
   * End Y coordinate for reframing
   */
  y_end?: number
  /**
   * Grid Position Y
   *
   * Y position of the grid for reframing
   */
  grid_position_y?: number
  /**
   * Image Url
   *
   * URL of the input image to reframe
   */
  image_url: string
  /**
   * Grid Position X
   *
   * X position of the grid for reframing
   */
  grid_position_x?: number
  /**
   * X Start
   *
   * Start X coordinate for reframing
   */
  x_start?: number
}

/**
 * T2IOutput
 */
export type LumaPhotonFlashReframeOutput = {
  /**
   * Images
   *
   * The generated image
   */
  images: Array<FalAiLumaPhotonFlashReframeFile>
}

/**
 * File
 */
export type FalAiLumaPhotonFlashReframeFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ReframeImageRequest
 */
export type LumaPhotonReframeInput = {
  /**
   * Prompt
   *
   * Optional prompt for reframing
   */
  prompt?: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the reframed image
   */
  aspect_ratio: '1:1' | '16:9' | '9:16' | '4:3' | '3:4' | '21:9' | '9:21'
  /**
   * Y Start
   *
   * Start Y coordinate for reframing
   */
  y_start?: number
  /**
   * X End
   *
   * End X coordinate for reframing
   */
  x_end?: number
  /**
   * Y End
   *
   * End Y coordinate for reframing
   */
  y_end?: number
  /**
   * Grid Position Y
   *
   * Y position of the grid for reframing
   */
  grid_position_y?: number
  /**
   * Image Url
   *
   * URL of the input image to reframe
   */
  image_url: string
  /**
   * Grid Position X
   *
   * X position of the grid for reframing
   */
  grid_position_x?: number
  /**
   * X Start
   *
   * Start X coordinate for reframing
   */
  x_start?: number
}

/**
 * T2IOutput
 */
export type LumaPhotonReframeOutput = {
  /**
   * Images
   *
   * The generated image
   */
  images: Array<FalAiLumaPhotonReframeFile>
}

/**
 * File
 */
export type FalAiLumaPhotonReframeFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * SchnellFlux1ReduxInput
 */
export type Flux1SchnellReduxInput = {
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiFlux1SchnellReduxImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown
}

/**
 * ImageSize
 */
export type FalAiFlux1SchnellReduxImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Output
 */
export type Flux1SchnellReduxOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFlux1SchnellReduxImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFlux1SchnellReduxImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * BaseFlux1ReduxInput
 */
export type Flux1DevReduxInput = {
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiFlux1DevReduxImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
}

/**
 * ImageSize
 */
export type FalAiFlux1DevReduxImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Output
 */
export type Flux1DevReduxOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFlux1DevReduxImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFlux1DevReduxImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * BaseFlux1ImageToInput
 */
export type Flux1DevImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Strength
   *
   * The strength of the initial image. Higher strength values are better for this model.
   */
  strength?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
}

/**
 * Output
 */
export type Flux1DevImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFlux1DevImageToImageImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFlux1DevImageToImageImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * TextRemovalInput
 *
 * Input model for text removal endpoint.
 */
export type ImageEditingTextRemovalInput = {
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | '21:9'
    | '16:9'
    | '4:3'
    | '3:2'
    | '1:1'
    | '2:3'
    | '3:4'
    | '9:16'
    | '9:21'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * URL of the image containing text to be removed.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5' | '6'
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
}

/**
 * TextRemovalOutput
 */
export type ImageEditingTextRemovalOutput = {
  /**
   * Images
   */
  images: Array<FalAiImageEditingTextRemovalImage>
  /**
   * Seed
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageEditingTextRemovalImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * PhotoRestorationInput
 *
 * Input model for photo restoration endpoint.
 */
export type ImageEditingPhotoRestorationInput = {
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | '21:9'
    | '16:9'
    | '4:3'
    | '3:2'
    | '1:1'
    | '2:3'
    | '3:4'
    | '9:16'
    | '9:21'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * URL of the old or damaged photo to restore.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5' | '6'
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
}

/**
 * PhotoRestorationOutput
 */
export type ImageEditingPhotoRestorationOutput = {
  /**
   * Images
   */
  images: Array<FalAiImageEditingPhotoRestorationImage>
  /**
   * Seed
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageEditingPhotoRestorationImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * WeatherEffectInput
 */
export type ImageEditingWeatherEffectInput = {
  /**
   * Weather Effect
   *
   * The weather effect to apply.
   */
  prompt?: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | '21:9'
    | '16:9'
    | '4:3'
    | '3:2'
    | '1:1'
    | '2:3'
    | '3:4'
    | '9:16'
    | '9:21'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5' | '6'
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
}

/**
 * WeatherEffectOutput
 */
export type ImageEditingWeatherEffectOutput = {
  /**
   * Images
   */
  images: Array<FalAiImageEditingWeatherEffectImage>
  /**
   * Seed
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageEditingWeatherEffectImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TimeOfDayInput
 */
export type ImageEditingTimeOfDayInput = {
  /**
   * Time of Day
   *
   * The time of day to transform the scene to.
   */
  prompt?: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | '21:9'
    | '16:9'
    | '4:3'
    | '3:2'
    | '1:1'
    | '2:3'
    | '3:4'
    | '9:16'
    | '9:21'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5' | '6'
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
}

/**
 * TimeOfDayOutput
 */
export type ImageEditingTimeOfDayOutput = {
  /**
   * Images
   */
  images: Array<FalAiImageEditingTimeOfDayImage>
  /**
   * Seed
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageEditingTimeOfDayImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * StyleTransferInput
 */
export type ImageEditingStyleTransferInput = {
  /**
   * Style Prompt
   *
   * The artistic style to apply.
   */
  prompt?: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | '21:9'
    | '16:9'
    | '4:3'
    | '3:2'
    | '1:1'
    | '2:3'
    | '3:4'
    | '9:16'
    | '9:21'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5' | '6'
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
}

/**
 * StyleTransferOutput
 */
export type ImageEditingStyleTransferOutput = {
  /**
   * Images
   */
  images: Array<FalAiImageEditingStyleTransferImage>
  /**
   * Seed
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageEditingStyleTransferImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * SceneCompositionInput
 */
export type ImageEditingSceneCompositionInput = {
  /**
   * Scene Description
   *
   * Describe the scene where you want to place the subject.
   */
  prompt?: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | '21:9'
    | '16:9'
    | '4:3'
    | '3:2'
    | '1:1'
    | '2:3'
    | '3:4'
    | '9:16'
    | '9:21'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5' | '6'
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
}

/**
 * SceneCompositionOutput
 */
export type ImageEditingSceneCompositionOutput = {
  /**
   * Images
   */
  images: Array<FalAiImageEditingSceneCompositionImage>
  /**
   * Seed
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageEditingSceneCompositionImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * BaseInput
 */
export type ImageEditingProfessionalPhotoInput = {
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | '21:9'
    | '16:9'
    | '4:3'
    | '3:2'
    | '1:1'
    | '2:3'
    | '3:4'
    | '9:16'
    | '9:21'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5' | '6'
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
}

/**
 * ProfessionalPhotoOutput
 */
export type ImageEditingProfessionalPhotoOutput = {
  /**
   * Images
   */
  images: Array<FalAiImageEditingProfessionalPhotoImage>
  /**
   * Seed
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageEditingProfessionalPhotoImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ObjectRemovalInput
 */
export type ImageEditingObjectRemovalInput = {
  /**
   * Objects to Remove
   *
   * Specify which objects to remove from the image.
   */
  prompt?: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | '21:9'
    | '16:9'
    | '4:3'
    | '3:2'
    | '1:1'
    | '2:3'
    | '3:4'
    | '9:16'
    | '9:21'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5' | '6'
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
}

/**
 * ObjectRemovalOutput
 */
export type ImageEditingObjectRemovalOutput = {
  /**
   * Images
   */
  images: Array<FalAiImageEditingObjectRemovalImage>
  /**
   * Seed
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageEditingObjectRemovalImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * HairChangeInput
 */
export type ImageEditingHairChangeInput = {
  /**
   * Hair Style Prompt
   *
   * The desired hair style to apply.
   */
  prompt?: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | '21:9'
    | '16:9'
    | '4:3'
    | '3:2'
    | '1:1'
    | '2:3'
    | '3:4'
    | '9:16'
    | '9:21'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5' | '6'
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
}

/**
 * HairChangeOutput
 */
export type ImageEditingHairChangeOutput = {
  /**
   * Images
   */
  images: Array<FalAiImageEditingHairChangeImage>
  /**
   * Seed
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageEditingHairChangeImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * BaseInput
 */
export type ImageEditingFaceEnhancementInput = {
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | '21:9'
    | '16:9'
    | '4:3'
    | '3:2'
    | '1:1'
    | '2:3'
    | '3:4'
    | '9:16'
    | '9:21'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5' | '6'
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
}

/**
 * FaceEnhancementOutput
 */
export type ImageEditingFaceEnhancementOutput = {
  /**
   * Images
   */
  images: Array<FalAiImageEditingFaceEnhancementImage>
  /**
   * Seed
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageEditingFaceEnhancementImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ExpressionChangeInput
 */
export type ImageEditingExpressionChangeInput = {
  /**
   * Expression Prompt
   *
   * The desired facial expression to apply.
   */
  prompt?: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | '21:9'
    | '16:9'
    | '4:3'
    | '3:2'
    | '1:1'
    | '2:3'
    | '3:4'
    | '9:16'
    | '9:21'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5' | '6'
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
}

/**
 * ExpressionChangeOutput
 */
export type ImageEditingExpressionChangeOutput = {
  /**
   * Images
   */
  images: Array<FalAiImageEditingExpressionChangeImage>
  /**
   * Seed
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageEditingExpressionChangeImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * BaseInput
 */
export type ImageEditingColorCorrectionInput = {
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | '21:9'
    | '16:9'
    | '4:3'
    | '3:2'
    | '1:1'
    | '2:3'
    | '3:4'
    | '9:16'
    | '9:21'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5' | '6'
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
}

/**
 * ColorCorrectionOutput
 */
export type ImageEditingColorCorrectionOutput = {
  /**
   * Images
   */
  images: Array<FalAiImageEditingColorCorrectionImage>
  /**
   * Seed
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageEditingColorCorrectionImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * BaseInput
 */
export type ImageEditingCartoonifyInput = {
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | '21:9'
    | '16:9'
    | '4:3'
    | '3:2'
    | '1:1'
    | '2:3'
    | '3:4'
    | '9:16'
    | '9:21'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5' | '6'
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
}

/**
 * CartoonifyOutput
 */
export type ImageEditingCartoonifyOutput = {
  /**
   * Images
   */
  images: Array<FalAiImageEditingCartoonifyImage>
  /**
   * Seed
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageEditingCartoonifyImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * BackgroundChangeInput
 */
export type ImageEditingBackgroundChangeInput = {
  /**
   * Background Prompt
   *
   * The desired background to apply.
   */
  prompt?: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | '21:9'
    | '16:9'
    | '4:3'
    | '3:2'
    | '1:1'
    | '2:3'
    | '3:4'
    | '9:16'
    | '9:21'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5' | '6'
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
}

/**
 * BackgroundChangeOutput
 */
export type ImageEditingBackgroundChangeOutput = {
  /**
   * Images
   */
  images: Array<FalAiImageEditingBackgroundChangeImage>
  /**
   * Seed
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageEditingBackgroundChangeImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * AgeProgressionInput
 */
export type ImageEditingAgeProgressionInput = {
  /**
   * Age Change
   *
   * The age change to apply.
   */
  prompt?: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | '21:9'
    | '16:9'
    | '4:3'
    | '3:2'
    | '1:1'
    | '2:3'
    | '3:4'
    | '9:16'
    | '9:21'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5' | '6'
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number
}

/**
 * AgeProgressionOutput
 */
export type ImageEditingAgeProgressionOutput = {
  /**
   * Images
   */
  images: Array<FalAiImageEditingAgeProgressionImage>
  /**
   * Seed
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageEditingAgeProgressionImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * FluxKontextMultiInput
 */
export type FluxProKontextMaxMultiInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | '21:9'
    | '16:9'
    | '4:3'
    | '3:2'
    | '1:1'
    | '2:3'
    | '3:4'
    | '9:16'
    | '9:21'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5' | '6'
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_urls: Array<string>
  /**
   * Enhance Prompt
   *
   * Whether to enhance the prompt for better results.
   */
  enhance_prompt?: boolean
}

/**
 * Output
 */
export type FluxProKontextMaxMultiOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<RegistryImageFastSdxlModelsImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type RegistryImageFastSdxlModelsImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * FluxKontextMultiInput
 */
export type FluxProKontextMultiInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | '21:9'
    | '16:9'
    | '4:3'
    | '3:2'
    | '1:1'
    | '2:3'
    | '3:4'
    | '9:16'
    | '9:21'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5' | '6'
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_urls: Array<string>
  /**
   * Enhance Prompt
   *
   * Whether to enhance the prompt for better results.
   */
  enhance_prompt?: boolean
}

/**
 * Output
 */
export type FluxProKontextMultiOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxProKontextMultiRegistryImageFastSdxlModelsImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFluxProKontextMultiRegistryImageFastSdxlModelsImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * FluxKontextInput
 */
export type FluxProKontextMaxInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | '21:9'
    | '16:9'
    | '4:3'
    | '3:2'
    | '1:1'
    | '2:3'
    | '3:4'
    | '9:16'
    | '9:21'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5' | '6'
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Enhance Prompt
   *
   * Whether to enhance the prompt for better results.
   */
  enhance_prompt?: boolean
}

/**
 * FluxKontextOutput
 */
export type FluxProKontextMaxOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalToolkitImageImageImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalToolkitImageImageImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * BaseKontextEditInput
 */
export type FluxKontextDevInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string
  /**
   * Resolution Mode
   *
   *
   * Determines how the output resolution is set for image editing.
   * - `auto`: The model selects an optimal resolution from a predefined set that best matches the input image's aspect ratio. This is the recommended setting for most use cases as it's what the model was trained on.
   * - `match_input`: The model will attempt to use the same resolution as the input image. The resolution will be adjusted to be compatible with the model's requirements (e.g. dimensions must be multiples of 16 and within supported limits).
   * Apart from these, a few aspect ratios are also supported.
   *
   */
  resolution_mode?:
    | 'auto'
    | 'match_input'
    | '1:1'
    | '16:9'
    | '21:9'
    | '3:2'
    | '2:3'
    | '4:5'
    | '5:4'
    | '3:4'
    | '4:3'
    | '9:16'
    | '9:21'
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Output Format
   *
   * Output format
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The URL of the image to edit.
   */
  image_url: string
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * KontextEditOutput
 */
export type FluxKontextDevOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxKontextDevImage>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
}

/**
 * Image
 */
export type FalAiFluxKontextDevImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * FluxKontextInput
 */
export type FluxProKontextInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | '21:9'
    | '16:9'
    | '4:3'
    | '3:2'
    | '1:1'
    | '2:3'
    | '3:4'
    | '9:16'
    | '9:21'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5' | '6'
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Enhance Prompt
   *
   * Whether to enhance the prompt for better results.
   */
  enhance_prompt?: boolean
}

/**
 * FluxKontextOutput
 */
export type FluxProKontextOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxProKontextFalToolkitImageImageImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiFluxProKontextFalToolkitImageImageImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageEditInput
 */
export type BagelEditInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image with.
   */
  prompt: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * The seed to use for the generation.
   */
  seed?: number
  /**
   * Use Thought
   *
   * Whether to use thought tokens for generation. If set to true, the model will "think" to potentially improve generation quality. Increases generation time and increases the cost by 20%.
   */
  use_thought?: boolean
  /**
   * Image Url
   *
   * The image to edit.
   */
  image_url: string
}

/**
 * ImageEditOutput
 */
export type BagelEditOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The edited images.
   */
  images: Array<FalAiBagelEditImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiBagelEditImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageInput
 */
export type RembgEnhanceInput = {
  /**
   * Image Url
   *
   * URL of the input image
   */
  image_url: string
}

/**
 * ImageOutput
 */
export type RembgEnhanceOutput = {
  image: SmoretalkAiRembgEnhanceFile
}

/**
 * File
 */
export type SmoretalkAiRembgEnhanceFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * UpscaleInput
 */
export type RecraftUpscaleCreativeInput = {
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Image Url
   *
   * The URL of the image to be upscaled. Must be in PNG format.
   */
  image_url: string
}

/**
 * UpscaleOutput
 */
export type RecraftUpscaleCreativeOutput = {
  /**
   * Image
   *
   * The upscaled image.
   */
  image: FalAiRecraftUpscaleCreativeFile
}

/**
 * File
 */
export type FalAiRecraftUpscaleCreativeFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * UpscaleInput
 */
export type RecraftUpscaleCrispInput = {
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Image Url
   *
   * The URL of the image to be upscaled. Must be in PNG format.
   */
  image_url: string
}

/**
 * UpscaleOutput
 */
export type RecraftUpscaleCrispOutput = {
  /**
   * Image
   *
   * The upscaled image.
   */
  image: FalAiRecraftUpscaleCrispFile
}

/**
 * File
 */
export type FalAiRecraftUpscaleCrispFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToImageInput
 */
export type RecraftV3ImageToImageInput = {
  /**
   * Prompt
   *
   * A text description of areas to change.
   */
  prompt: string
  /**
   * Style
   *
   * The style of the generated images. Vector images cost 2X as much.
   */
  style?:
    | 'any'
    | 'realistic_image'
    | 'digital_illustration'
    | 'vector_illustration'
    | 'realistic_image/b_and_w'
    | 'realistic_image/hard_flash'
    | 'realistic_image/hdr'
    | 'realistic_image/natural_light'
    | 'realistic_image/studio_portrait'
    | 'realistic_image/enterprise'
    | 'realistic_image/motion_blur'
    | 'realistic_image/evening_light'
    | 'realistic_image/faded_nostalgia'
    | 'realistic_image/forest_life'
    | 'realistic_image/mystic_naturalism'
    | 'realistic_image/natural_tones'
    | 'realistic_image/organic_calm'
    | 'realistic_image/real_life_glow'
    | 'realistic_image/retro_realism'
    | 'realistic_image/retro_snapshot'
    | 'realistic_image/urban_drama'
    | 'realistic_image/village_realism'
    | 'realistic_image/warm_folk'
    | 'digital_illustration/pixel_art'
    | 'digital_illustration/hand_drawn'
    | 'digital_illustration/grain'
    | 'digital_illustration/infantile_sketch'
    | 'digital_illustration/2d_art_poster'
    | 'digital_illustration/handmade_3d'
    | 'digital_illustration/hand_drawn_outline'
    | 'digital_illustration/engraving_color'
    | 'digital_illustration/2d_art_poster_2'
    | 'digital_illustration/antiquarian'
    | 'digital_illustration/bold_fantasy'
    | 'digital_illustration/child_book'
    | 'digital_illustration/child_books'
    | 'digital_illustration/cover'
    | 'digital_illustration/crosshatch'
    | 'digital_illustration/digital_engraving'
    | 'digital_illustration/expressionism'
    | 'digital_illustration/freehand_details'
    | 'digital_illustration/grain_20'
    | 'digital_illustration/graphic_intensity'
    | 'digital_illustration/hard_comics'
    | 'digital_illustration/long_shadow'
    | 'digital_illustration/modern_folk'
    | 'digital_illustration/multicolor'
    | 'digital_illustration/neon_calm'
    | 'digital_illustration/noir'
    | 'digital_illustration/nostalgic_pastel'
    | 'digital_illustration/outline_details'
    | 'digital_illustration/pastel_gradient'
    | 'digital_illustration/pastel_sketch'
    | 'digital_illustration/pop_art'
    | 'digital_illustration/pop_renaissance'
    | 'digital_illustration/street_art'
    | 'digital_illustration/tablet_sketch'
    | 'digital_illustration/urban_glow'
    | 'digital_illustration/urban_sketching'
    | 'digital_illustration/vanilla_dreams'
    | 'digital_illustration/young_adult_book'
    | 'digital_illustration/young_adult_book_2'
    | 'vector_illustration/bold_stroke'
    | 'vector_illustration/chemistry'
    | 'vector_illustration/colored_stencil'
    | 'vector_illustration/contour_pop_art'
    | 'vector_illustration/cosmics'
    | 'vector_illustration/cutout'
    | 'vector_illustration/depressive'
    | 'vector_illustration/editorial'
    | 'vector_illustration/emotional_flat'
    | 'vector_illustration/infographical'
    | 'vector_illustration/marker_outline'
    | 'vector_illustration/mosaic'
    | 'vector_illustration/naivector'
    | 'vector_illustration/roundish_flat'
    | 'vector_illustration/segmented_colors'
    | 'vector_illustration/sharp_contrast'
    | 'vector_illustration/thin'
    | 'vector_illustration/vector_photo'
    | 'vector_illustration/vivid_shapes'
    | 'vector_illustration/engraving'
    | 'vector_illustration/line_art'
    | 'vector_illustration/line_circuit'
    | 'vector_illustration/linocut'
  /**
   * Style Id
   *
   * The ID of the custom style reference (optional)
   */
  style_id?: string
  /**
   * Image Url
   *
   * The URL of the image to modify. Must be less than 5 MB in size, have resolution less than 16 MP and max dimension less than 4096 pixels.
   */
  image_url: string
  /**
   * Strength
   *
   * Defines the difference with the original image, should lie in [0, 1], where 0 means almost identical, and 1 means miserable similarity
   */
  strength?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Colors
   *
   * An array of preferable colors
   */
  colors?: Array<FalAiRecraftV3ImageToImageRgbColor>
  /**
   * Negative Prompt
   *
   * A text description of undesired elements on an image
   */
  negative_prompt?: string
}

/**
 * RGBColor
 */
export type FalAiRecraftV3ImageToImageRgbColor = {
  /**
   * R
   *
   * Red color value
   */
  r?: number
  /**
   * B
   *
   * Blue color value
   */
  b?: number
  /**
   * G
   *
   * Green color value
   */
  g?: number
}

/**
 * ImageToImageOutput
 */
export type RecraftV3ImageToImageOutput = {
  /**
   * Images
   *
   * The generated images
   */
  images: Array<FalAiRecraftV3ImageToImageFile>
}

/**
 * File
 */
export type FalAiRecraftV3ImageToImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * MiniMaxTextToImageWithReferenceRequest
 */
export type MinimaxImage01SubjectReferenceInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to enable automatic prompt optimization
   */
  prompt_optimizer?: boolean
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated image
   */
  aspect_ratio?:
    | '1:1'
    | '16:9'
    | '4:3'
    | '3:2'
    | '2:3'
    | '3:4'
    | '9:16'
    | '21:9'
  /**
   * Num Images
   *
   * Number of images to generate (1-9)
   */
  num_images?: number
  /**
   * Prompt
   *
   * Text prompt for image generation (max 1500 characters)
   */
  prompt: string
  /**
   * Image Url
   *
   * URL of the subject reference image to use for consistent character appearance
   */
  image_url: string
}

/**
 * MiniMaxTextToImageWithReferenceOutput
 */
export type MinimaxImage01SubjectReferenceOutput = {
  /**
   * Images
   *
   * Generated images
   */
  images: Array<FalAiMinimaxImage01SubjectReferenceFile>
}

/**
 * File
 */
export type FalAiMinimaxImage01SubjectReferenceFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToImageInput
 */
export type HidreamI1FullImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. Setting to None uses the input image's size.
   */
  image_size?:
    | FalAiHidreamI1FullImageToImageImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The image URL to generate an image from.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Loras
   *
   * A list of LoRAs to apply to the model. Each LoRA specifies its path, scale, and optional weight name.
   */
  loras?: Array<FalAiHidreamI1FullImageToImageLoraWeight>
  /**
   * Strength
   *
   * Denoising strength for image-to-image generation.
   */
  strength?: number
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
}

/**
 * ImageSize
 */
export type FalAiHidreamI1FullImageToImageImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * LoraWeight
 */
export type FalAiHidreamI1FullImageToImageLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
  /**
   * Weight Name
   *
   * Name of the LoRA weight. Used only if `path` is a Hugging Face repository, and required only if you have more than 1 safetensors file in the repo.
   */
  weight_name?: string
}

/**
 * Img2ImgOutput
 */
export type HidreamI1FullImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated images
   */
  images: Array<FalAiHidreamI1FullImageToImageImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiHidreamI1FullImageToImageImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * ReframeImageInputV3
 */
export type IdeogramV3ReframeInput = {
  /**
   * Num Images
   *
   * Number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The resolution for the reframed output image
   */
  image_size:
    | FalAiIdeogramV3ReframeImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Style
   *
   * The style type to generate with. Cannot be used with style_codes.
   */
  style?: 'AUTO' | 'GENERAL' | 'REALISTIC' | 'DESIGN' | unknown
  /**
   * Style Preset
   *
   * Style preset for generation. The chosen style preset will guide the generation.
   */
  style_preset?:
    | '80S_ILLUSTRATION'
    | '90S_NOSTALGIA'
    | 'ABSTRACT_ORGANIC'
    | 'ANALOG_NOSTALGIA'
    | 'ART_BRUT'
    | 'ART_DECO'
    | 'ART_POSTER'
    | 'AURA'
    | 'AVANT_GARDE'
    | 'BAUHAUS'
    | 'BLUEPRINT'
    | 'BLURRY_MOTION'
    | 'BRIGHT_ART'
    | 'C4D_CARTOON'
    | 'CHILDRENS_BOOK'
    | 'COLLAGE'
    | 'COLORING_BOOK_I'
    | 'COLORING_BOOK_II'
    | 'CUBISM'
    | 'DARK_AURA'
    | 'DOODLE'
    | 'DOUBLE_EXPOSURE'
    | 'DRAMATIC_CINEMA'
    | 'EDITORIAL'
    | 'EMOTIONAL_MINIMAL'
    | 'ETHEREAL_PARTY'
    | 'EXPIRED_FILM'
    | 'FLAT_ART'
    | 'FLAT_VECTOR'
    | 'FOREST_REVERIE'
    | 'GEO_MINIMALIST'
    | 'GLASS_PRISM'
    | 'GOLDEN_HOUR'
    | 'GRAFFITI_I'
    | 'GRAFFITI_II'
    | 'HALFTONE_PRINT'
    | 'HIGH_CONTRAST'
    | 'HIPPIE_ERA'
    | 'ICONIC'
    | 'JAPANDI_FUSION'
    | 'JAZZY'
    | 'LONG_EXPOSURE'
    | 'MAGAZINE_EDITORIAL'
    | 'MINIMAL_ILLUSTRATION'
    | 'MIXED_MEDIA'
    | 'MONOCHROME'
    | 'NIGHTLIFE'
    | 'OIL_PAINTING'
    | 'OLD_CARTOONS'
    | 'PAINT_GESTURE'
    | 'POP_ART'
    | 'RETRO_ETCHING'
    | 'RIVIERA_POP'
    | 'SPOTLIGHT_80S'
    | 'STYLIZED_RED'
    | 'SURREAL_COLLAGE'
    | 'TRAVEL_POSTER'
    | 'VINTAGE_GEO'
    | 'VINTAGE_POSTER'
    | 'WATERCOLOR'
    | 'WEIRD'
    | 'WOODBLOCK_PRINT'
    | unknown
  /**
   * Rendering Speed
   *
   * The rendering speed to use.
   */
  rendering_speed?: 'TURBO' | 'BALANCED' | 'QUALITY'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)
   */
  color_palette?: FalAiIdeogramV3ReframeColorPalette | unknown
  /**
   * Style Codes
   *
   * A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style
   */
  style_codes?: Array<string> | unknown
  /**
   * Image URL
   *
   * The image URL to reframe
   */
  image_url: string
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown
  /**
   * Image Urls
   *
   * A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format
   */
  image_urls?: Array<string> | unknown
}

/**
 * ImageSize
 */
export type FalAiIdeogramV3ReframeImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * ColorPalette
 */
export type FalAiIdeogramV3ReframeColorPalette = {
  /**
   * Members
   *
   * A list of color palette members that define the color palette
   */
  members?: Array<FalAiIdeogramV3ReframeColorPaletteMember> | unknown
  /**
   * Name
   *
   * A color palette preset value
   */
  name?:
    | 'EMBER'
    | 'FRESH'
    | 'JUNGLE'
    | 'MAGIC'
    | 'MELON'
    | 'MOSAIC'
    | 'PASTEL'
    | 'ULTRAMARINE'
    | unknown
}

/**
 * ColorPaletteMember
 */
export type FalAiIdeogramV3ReframeColorPaletteMember = {
  /**
   * Color Weight
   *
   * The weight of the color in the color palette
   */
  color_weight?: number | unknown
  rgb: FalAiIdeogramV3ReframeRgbColor
}

/**
 * RGBColor
 */
export type FalAiIdeogramV3ReframeRgbColor = {
  /**
   * R
   *
   * Red color value
   */
  r?: number
  /**
   * B
   *
   * Blue color value
   */
  b?: number
  /**
   * G
   *
   * Green color value
   */
  g?: number
}

/**
 * ReframeOutputV3
 */
export type IdeogramV3ReframeOutput = {
  /**
   * Images
   */
  images: Array<FalAiIdeogramV3ReframeFile>
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number
}

/**
 * File
 */
export type FalAiIdeogramV3ReframeFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * ReplaceBackgroundInputV3
 */
export type IdeogramV3ReplaceBackgroundInput = {
  /**
   * Prompt
   *
   * Cyber punk city with neon lights and skyscrappers
   */
  prompt: string
  /**
   * Num Images
   *
   * Number of images to generate.
   */
  num_images?: number
  /**
   * Style
   *
   * The style type to generate with. Cannot be used with style_codes.
   */
  style?: 'AUTO' | 'GENERAL' | 'REALISTIC' | 'DESIGN' | unknown
  /**
   * Style Preset
   *
   * Style preset for generation. The chosen style preset will guide the generation.
   */
  style_preset?:
    | '80S_ILLUSTRATION'
    | '90S_NOSTALGIA'
    | 'ABSTRACT_ORGANIC'
    | 'ANALOG_NOSTALGIA'
    | 'ART_BRUT'
    | 'ART_DECO'
    | 'ART_POSTER'
    | 'AURA'
    | 'AVANT_GARDE'
    | 'BAUHAUS'
    | 'BLUEPRINT'
    | 'BLURRY_MOTION'
    | 'BRIGHT_ART'
    | 'C4D_CARTOON'
    | 'CHILDRENS_BOOK'
    | 'COLLAGE'
    | 'COLORING_BOOK_I'
    | 'COLORING_BOOK_II'
    | 'CUBISM'
    | 'DARK_AURA'
    | 'DOODLE'
    | 'DOUBLE_EXPOSURE'
    | 'DRAMATIC_CINEMA'
    | 'EDITORIAL'
    | 'EMOTIONAL_MINIMAL'
    | 'ETHEREAL_PARTY'
    | 'EXPIRED_FILM'
    | 'FLAT_ART'
    | 'FLAT_VECTOR'
    | 'FOREST_REVERIE'
    | 'GEO_MINIMALIST'
    | 'GLASS_PRISM'
    | 'GOLDEN_HOUR'
    | 'GRAFFITI_I'
    | 'GRAFFITI_II'
    | 'HALFTONE_PRINT'
    | 'HIGH_CONTRAST'
    | 'HIPPIE_ERA'
    | 'ICONIC'
    | 'JAPANDI_FUSION'
    | 'JAZZY'
    | 'LONG_EXPOSURE'
    | 'MAGAZINE_EDITORIAL'
    | 'MINIMAL_ILLUSTRATION'
    | 'MIXED_MEDIA'
    | 'MONOCHROME'
    | 'NIGHTLIFE'
    | 'OIL_PAINTING'
    | 'OLD_CARTOONS'
    | 'PAINT_GESTURE'
    | 'POP_ART'
    | 'RETRO_ETCHING'
    | 'RIVIERA_POP'
    | 'SPOTLIGHT_80S'
    | 'STYLIZED_RED'
    | 'SURREAL_COLLAGE'
    | 'TRAVEL_POSTER'
    | 'VINTAGE_GEO'
    | 'VINTAGE_POSTER'
    | 'WATERCOLOR'
    | 'WEIRD'
    | 'WOODBLOCK_PRINT'
    | unknown
  /**
   * Expand Prompt
   *
   * Determine if MagicPrompt should be used in generating the request or not.
   */
  expand_prompt?: boolean
  /**
   * Rendering Speed
   *
   * The rendering speed to use.
   */
  rendering_speed?: 'TURBO' | 'BALANCED' | 'QUALITY'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)
   */
  color_palette?: FalAiIdeogramV3ReplaceBackgroundColorPalette | unknown
  /**
   * Style Codes
   *
   * A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style
   */
  style_codes?: Array<string> | unknown
  /**
   * Image URL
   *
   * The image URL whose background needs to be replaced
   */
  image_url: string
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown
  /**
   * Image Urls
   *
   * A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format
   */
  image_urls?: Array<string> | unknown
}

/**
 * ColorPalette
 */
export type FalAiIdeogramV3ReplaceBackgroundColorPalette = {
  /**
   * Members
   *
   * A list of color palette members that define the color palette
   */
  members?: Array<FalAiIdeogramV3ReplaceBackgroundColorPaletteMember> | unknown
  /**
   * Name
   *
   * A color palette preset value
   */
  name?:
    | 'EMBER'
    | 'FRESH'
    | 'JUNGLE'
    | 'MAGIC'
    | 'MELON'
    | 'MOSAIC'
    | 'PASTEL'
    | 'ULTRAMARINE'
    | unknown
}

/**
 * ColorPaletteMember
 */
export type FalAiIdeogramV3ReplaceBackgroundColorPaletteMember = {
  /**
   * Color Weight
   *
   * The weight of the color in the color palette
   */
  color_weight?: number | unknown
  rgb: FalAiIdeogramV3ReplaceBackgroundRgbColor
}

/**
 * RGBColor
 */
export type FalAiIdeogramV3ReplaceBackgroundRgbColor = {
  /**
   * R
   *
   * Red color value
   */
  r?: number
  /**
   * B
   *
   * Blue color value
   */
  b?: number
  /**
   * G
   *
   * Green color value
   */
  g?: number
}

/**
 * ReplaceBackgroundOutputV3
 */
export type IdeogramV3ReplaceBackgroundOutput = {
  /**
   * Images
   */
  images: Array<FalAiIdeogramV3ReplaceBackgroundFile>
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number
}

/**
 * File
 */
export type FalAiIdeogramV3ReplaceBackgroundFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * RemixImageInputV3
 */
export type IdeogramV3RemixInput = {
  /**
   * Prompt
   *
   * The prompt to remix the image with
   */
  prompt: string
  /**
   * Image Size
   *
   * The resolution of the generated image
   */
  image_size?:
    | FalAiIdeogramV3RemixImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | unknown
  /**
   * Style
   *
   * The style type to generate with. Cannot be used with style_codes.
   */
  style?: 'AUTO' | 'GENERAL' | 'REALISTIC' | 'DESIGN' | unknown
  /**
   * Expand Prompt
   *
   * Determine if MagicPrompt should be used in generating the request or not.
   */
  expand_prompt?: boolean
  /**
   * Rendering Speed
   *
   * The rendering speed to use.
   */
  rendering_speed?: 'TURBO' | 'BALANCED' | 'QUALITY'
  /**
   * Image Urls
   *
   * A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format
   */
  image_urls?: Array<string> | unknown
  /**
   * Negative Prompt
   *
   * Description of what to exclude from an image. Descriptions in the prompt take precedence to descriptions in the negative prompt.
   */
  negative_prompt?: string
  /**
   * Num Images
   *
   * Number of images to generate.
   */
  num_images?: number
  /**
   * Image URL
   *
   * The image URL to remix
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)
   */
  color_palette?: FalAiIdeogramV3RemixColorPalette | unknown
  /**
   * Strength
   *
   * Strength of the input image in the remix
   */
  strength?: number
  /**
   * Style Codes
   *
   * A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style
   */
  style_codes?: Array<string> | unknown
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown
}

/**
 * ImageSize
 */
export type FalAiIdeogramV3RemixImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * ColorPalette
 */
export type FalAiIdeogramV3RemixColorPalette = {
  /**
   * Members
   *
   * A list of color palette members that define the color palette
   */
  members?: Array<FalAiIdeogramV3RemixColorPaletteMember> | unknown
  /**
   * Name
   *
   * A color palette preset value
   */
  name?:
    | 'EMBER'
    | 'FRESH'
    | 'JUNGLE'
    | 'MAGIC'
    | 'MELON'
    | 'MOSAIC'
    | 'PASTEL'
    | 'ULTRAMARINE'
    | unknown
}

/**
 * ColorPaletteMember
 */
export type FalAiIdeogramV3RemixColorPaletteMember = {
  /**
   * Color Weight
   *
   * The weight of the color in the color palette
   */
  color_weight?: number | unknown
  rgb: FalAiIdeogramV3RemixRgbColor
}

/**
 * RGBColor
 */
export type FalAiIdeogramV3RemixRgbColor = {
  /**
   * R
   *
   * Red color value
   */
  r?: number
  /**
   * B
   *
   * Blue color value
   */
  b?: number
  /**
   * G
   *
   * Green color value
   */
  g?: number
}

/**
 * RemixOutputV3
 */
export type IdeogramV3RemixOutput = {
  /**
   * Images
   */
  images: Array<FalAiIdeogramV3RemixFile>
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number
}

/**
 * File
 */
export type FalAiIdeogramV3RemixFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * EditImageInputV3
 */
export type IdeogramV3EditInput = {
  /**
   * Prompt
   *
   * The prompt to fill the masked part of the image.
   */
  prompt: string
  /**
   * Num Images
   *
   * Number of images to generate.
   */
  num_images?: number
  /**
   * Style Preset
   *
   * Style preset for generation. The chosen style preset will guide the generation.
   */
  style_preset?:
    | '80S_ILLUSTRATION'
    | '90S_NOSTALGIA'
    | 'ABSTRACT_ORGANIC'
    | 'ANALOG_NOSTALGIA'
    | 'ART_BRUT'
    | 'ART_DECO'
    | 'ART_POSTER'
    | 'AURA'
    | 'AVANT_GARDE'
    | 'BAUHAUS'
    | 'BLUEPRINT'
    | 'BLURRY_MOTION'
    | 'BRIGHT_ART'
    | 'C4D_CARTOON'
    | 'CHILDRENS_BOOK'
    | 'COLLAGE'
    | 'COLORING_BOOK_I'
    | 'COLORING_BOOK_II'
    | 'CUBISM'
    | 'DARK_AURA'
    | 'DOODLE'
    | 'DOUBLE_EXPOSURE'
    | 'DRAMATIC_CINEMA'
    | 'EDITORIAL'
    | 'EMOTIONAL_MINIMAL'
    | 'ETHEREAL_PARTY'
    | 'EXPIRED_FILM'
    | 'FLAT_ART'
    | 'FLAT_VECTOR'
    | 'FOREST_REVERIE'
    | 'GEO_MINIMALIST'
    | 'GLASS_PRISM'
    | 'GOLDEN_HOUR'
    | 'GRAFFITI_I'
    | 'GRAFFITI_II'
    | 'HALFTONE_PRINT'
    | 'HIGH_CONTRAST'
    | 'HIPPIE_ERA'
    | 'ICONIC'
    | 'JAPANDI_FUSION'
    | 'JAZZY'
    | 'LONG_EXPOSURE'
    | 'MAGAZINE_EDITORIAL'
    | 'MINIMAL_ILLUSTRATION'
    | 'MIXED_MEDIA'
    | 'MONOCHROME'
    | 'NIGHTLIFE'
    | 'OIL_PAINTING'
    | 'OLD_CARTOONS'
    | 'PAINT_GESTURE'
    | 'POP_ART'
    | 'RETRO_ETCHING'
    | 'RIVIERA_POP'
    | 'SPOTLIGHT_80S'
    | 'STYLIZED_RED'
    | 'SURREAL_COLLAGE'
    | 'TRAVEL_POSTER'
    | 'VINTAGE_GEO'
    | 'VINTAGE_POSTER'
    | 'WATERCOLOR'
    | 'WEIRD'
    | 'WOODBLOCK_PRINT'
    | unknown
  /**
   * Expand Prompt
   *
   * Determine if MagicPrompt should be used in generating the request or not.
   */
  expand_prompt?: boolean
  /**
   * Rendering Speed
   *
   * The rendering speed to use.
   */
  rendering_speed?: 'TURBO' | 'BALANCED' | 'QUALITY'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)
   */
  color_palette?: FalAiIdeogramV3EditColorPalette | unknown
  /**
   * Style Codes
   *
   * A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style
   */
  style_codes?: Array<string> | unknown
  /**
   * Image URL
   *
   * The image URL to generate an image from. MUST have the exact same dimensions (width and height) as the mask image.
   */
  image_url: string
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown
  /**
   * Image Urls
   *
   * A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format
   */
  image_urls?: Array<string> | unknown
  /**
   * Mask URL
   *
   * The mask URL to inpaint the image. MUST have the exact same dimensions (width and height) as the input image.
   */
  mask_url: string
}

/**
 * ColorPalette
 */
export type FalAiIdeogramV3EditColorPalette = {
  /**
   * Members
   *
   * A list of color palette members that define the color palette
   */
  members?: Array<FalAiIdeogramV3EditColorPaletteMember> | unknown
  /**
   * Name
   *
   * A color palette preset value
   */
  name?:
    | 'EMBER'
    | 'FRESH'
    | 'JUNGLE'
    | 'MAGIC'
    | 'MELON'
    | 'MOSAIC'
    | 'PASTEL'
    | 'ULTRAMARINE'
    | unknown
}

/**
 * ColorPaletteMember
 */
export type FalAiIdeogramV3EditColorPaletteMember = {
  /**
   * Color Weight
   *
   * The weight of the color in the color palette
   */
  color_weight?: number | unknown
  rgb: FalAiIdeogramV3EditRgbColor
}

/**
 * RGBColor
 */
export type FalAiIdeogramV3EditRgbColor = {
  /**
   * R
   *
   * Red color value
   */
  r?: number
  /**
   * B
   *
   * Blue color value
   */
  b?: number
  /**
   * G
   *
   * Green color value
   */
  g?: number
}

/**
 * EditOutputV3
 */
export type IdeogramV3EditOutput = {
  /**
   * Images
   */
  images: Array<FalAiIdeogramV3EditFile>
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number
}

/**
 * File
 */
export type FalAiIdeogramV3EditFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * TextToImageInput
 */
export type Step1xEditInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The image URL to generate an image from. Needs to match the dimensions of the mask.
   */
  image_url: string
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageOutput
 */
export type Step1xEditOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated images
   */
  images: Array<FalAiStep1xEditImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiStep1xEditImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Image2SVGInput
 */
export type Image2SvgInput = {
  /**
   * Splice Threshold
   *
   * Splice threshold for joining paths
   */
  splice_threshold?: number
  /**
   * Hierarchical
   *
   * Hierarchical mode: stacked or cutout
   */
  hierarchical?: 'stacked' | 'cutout'
  /**
   * Color Precision
   *
   * Color quantization level
   */
  color_precision?: number
  /**
   * Colormode
   *
   * Choose between color or binary (black and white) output
   */
  colormode?: 'color' | 'binary'
  /**
   * Max Iterations
   *
   * Maximum number of iterations for optimization
   */
  max_iterations?: number
  /**
   * Length Threshold
   *
   * Length threshold for curves/lines
   */
  length_threshold?: number
  /**
   * Image Url
   *
   * The image to convert to SVG
   */
  image_url: string
  /**
   * Mode
   *
   * Mode: spline (curved) or polygon (straight lines)
   */
  mode?: 'spline' | 'polygon'
  /**
   * Corner Threshold
   *
   * Corner detection threshold in degrees
   */
  corner_threshold?: number
  /**
   * Path Precision
   *
   * Decimal precision for path coordinates
   */
  path_precision?: number
  /**
   * Filter Speckle
   *
   * Filter out small speckles and noise
   */
  filter_speckle?: number
  /**
   * Layer Difference
   *
   * Layer difference threshold for hierarchical mode
   */
  layer_difference?: number
}

/**
 * Image2SVGOutput
 */
export type Image2SvgOutput = {
  /**
   * Images
   *
   * The converted SVG file
   */
  images: Array<FalAiImage2SvgFile>
}

/**
 * File
 */
export type FalAiImage2SvgFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * UNOInput
 */
export type UnoInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   *
   * The size of the generated image. You can choose between some presets or custom height and width
   * that **must be multiples of 8**.
   *
   */
  image_size?:
    | FalAiUnoImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Input Image Urls
   *
   * URL of images to use while generating the image.
   */
  input_image_urls: Array<string>
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * Random seed for reproducible generation. If set none, a random seed will be used.
   */
  seed?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
}

/**
 * ImageSize
 */
export type FalAiUnoImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * UNOOutput
 */
export type UnoOutput = {
  /**
   * Prompt
   *
   * The prompt used to generate the image.
   */
  prompt: string
  /**
   * Images
   *
   * The URLs of the generated images.
   */
  images: Array<FalAiUnoImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiUnoImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * EditImageRequest
 */
export type GptImage1EditImageInput = {
  /**
   * Prompt
   *
   * The prompt for image generation
   */
  prompt: string
  /**
   * Number of Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * Aspect ratio for the generated image
   */
  image_size?: 'auto' | '1024x1024' | '1536x1024' | '1024x1536'
  /**
   * Background
   *
   * Background for the generated image
   */
  background?: 'auto' | 'transparent' | 'opaque'
  /**
   * Quality
   *
   * Quality for the generated image
   */
  quality?: 'auto' | 'low' | 'medium' | 'high'
  /**
   * Output Format
   *
   * Output format for the images
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Input Fidelity
   *
   * Input fidelity for the generated image
   */
  input_fidelity?: 'low' | 'high'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Image URLs
   *
   * The URLs of the images to use as a reference for the generation.
   */
  image_urls: Array<string>
}

/**
 * EditImageResponse
 */
export type GptImage1EditImageOutput = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<FalAiGptImage1EditImageImageFile>
}

/**
 * ImageFile
 */
export type FalAiGptImage1EditImageImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * InpaintInput
 */
export type JuggernautFluxLoraInpaintingInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | RundiffusionFalJuggernautFluxLoraInpaintingImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image Url
   *
   * URL of image to use for inpainting. or img2img
   */
  image_url: string
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<RundiffusionFalJuggernautFluxLoraInpaintingLoraWeight>
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean
  /**
   * Strength
   *
   * The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.
   */
  strength?: number
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Mask Url
   *
   *
   * The mask to area to Inpaint in.
   *
   */
  mask_url: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
}

/**
 * ImageSize
 */
export type RundiffusionFalJuggernautFluxLoraInpaintingImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * LoraWeight
 */
export type RundiffusionFalJuggernautFluxLoraInpaintingLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
}

/**
 * Output
 */
export type JuggernautFluxLoraInpaintingOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<RundiffusionFalJuggernautFluxLoraInpaintingImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type RundiffusionFalJuggernautFluxLoraInpaintingImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * Input
 */
export type FashnTryonV15Input = {
  /**
   * Model Image
   *
   * URL or base64 of the model image
   */
  model_image: string
  /**
   * Moderation Level
   *
   * Content moderation level for garment images. 'none' disables moderation, 'permissive' blocks only explicit content, 'conservative' also blocks underwear and swimwear.
   */
  moderation_level?: 'none' | 'permissive' | 'conservative'
  /**
   * Garment Photo Type
   *
   * Specifies the type of garment photo to optimize internal parameters for better performance. 'model' is for photos of garments on a model, 'flat-lay' is for flat-lay or ghost mannequin images, and 'auto' attempts to automatically detect the photo type.
   */
  garment_photo_type?: 'auto' | 'model' | 'flat-lay'
  /**
   * Garment Image
   *
   * URL or base64 of the garment image
   */
  garment_image: string
  /**
   * Category
   *
   * Category of the garment to try-on. 'auto' will attempt to automatically detect the category of the garment.
   */
  category?: 'tops' | 'bottoms' | 'one-pieces' | 'auto'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Segmentation Free
   *
   * Disables human parsing on the model image.
   */
  segmentation_free?: boolean
  /**
   * Num Samples
   *
   * Number of images to generate in a single run. Image generation has a random element in it, so trying multiple images at once increases the chances of getting a good result.
   */
  num_samples?: number
  /**
   * Mode
   *
   * Specifies the mode of operation. 'performance' mode is faster but may sacrifice quality, 'balanced' mode is a balance between speed and quality, and 'quality' mode is slower but produces higher quality results.
   */
  mode?: 'performance' | 'balanced' | 'quality'
  /**
   * Seed
   *
   * Sets random operations to a fixed state. Use the same seed to reproduce results with the same inputs, or different seed to force different results.
   */
  seed?: number
  /**
   * Output Format
   *
   * Output format of the generated images. 'png' is highest quality, while 'jpeg' is faster
   */
  output_format?: 'png' | 'jpeg'
}

/**
 * Output
 */
export type FashnTryonV15Output = {
  /**
   * Images
   */
  images: Array<FalAiFashnTryonV15File>
}

/**
 * File
 */
export type FalAiFashnTryonV15File = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * PlushifyInput
 */
export type PlushifyInput = {
  /**
   * Prompt
   *
   * Prompt for the generation. Default is empty which is usually best, but sometimes it can help to add a description of the subject.
   */
  prompt?: string
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Use Cfg Zero
   *
   * Whether to use CFG zero
   */
  use_cfg_zero?: boolean
  /**
   * Image Url
   *
   * URL of the image to apply cartoon style to
   */
  image_url: string
  /**
   * Scale
   *
   * Scale factor for the Cartoon effect
   */
  scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps
   */
  num_inference_steps?: number
  /**
   * Guidance Scale
   *
   * Guidance scale for the generation
   */
  guidance_scale?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * The seed for image generation. Same seed with same parameters will generate same image.
   */
  seed?: number
}

/**
 * Output
 */
export type PlushifyOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiPlushifyImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiPlushifyImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * TextToImageInput
 */
export type InstantCharacterInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiInstantCharacterImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Scale
   *
   * The scale of the subject image. Higher values will make the subject image more prominent in the generated image.
   */
  scale?: number
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The image URL to generate an image from. Needs to match the dimensions of the mask.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
}

/**
 * ImageSize
 */
export type FalAiInstantCharacterImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * ImageOutput
 */
export type InstantCharacterOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated images
   */
  images: Array<FalAiInstantCharacterImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiInstantCharacterImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * CartoonifyInput
 */
export type CartoonifyInput = {
  /**
   * Use Cfg Zero
   *
   * Whether to use CFG zero
   */
  use_cfg_zero?: boolean
  /**
   * Image Url
   *
   * URL of the image to apply Pixar style to
   */
  image_url: string
  /**
   * Guidance Scale
   *
   * Guidance scale for the generation
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps
   */
  num_inference_steps?: number
  /**
   * Scale
   *
   * Scale factor for the Pixar effect
   */
  scale?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * The seed for image generation. Same seed with same parameters will generate same image.
   */
  seed?: number
}

/**
 * Output
 */
export type CartoonifyOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiCartoonifyImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiCartoonifyImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * MaskEraseRequest
 */
export type FinegrainEraserMaskInput = {
  /**
   * Mode
   *
   * Erase quality mode
   */
  mode?: 'express' | 'standard' | 'premium'
  /**
   * Seed
   *
   * Random seed for reproducible generation
   */
  seed?: number
  /**
   * Mask Url
   *
   * URL of the mask image. Should be a binary mask where white (255) indicates areas to erase
   */
  mask_url: string
  /**
   * Image Url
   *
   * URL of the image to edit
   */
  image_url: string
}

/**
 * EraseOutput
 */
export type FinegrainEraserMaskOutput = {
  /**
   * Image
   *
   * The edited image with content erased
   */
  image: FalAiFinegrainEraserMaskFile
  /**
   * Used Seed
   *
   * Seed used for generation
   */
  used_seed: number
}

/**
 * File
 */
export type FalAiFinegrainEraserMaskFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * BBoxEraseRequest
 */
export type FinegrainEraserBboxInput = {
  /**
   * Mode
   *
   * Erase quality mode
   */
  mode?: 'express' | 'standard' | 'premium'
  /**
   * Seed
   *
   * Random seed for reproducible generation
   */
  seed?: number
  /**
   * Box Prompts
   *
   * List of bounding box coordinates to erase (only one box prompt is supported)
   */
  box_prompts: Array<BoxPromptBase>
  /**
   * Image Url
   *
   * URL of the image to edit
   */
  image_url: string
}

/**
 * BoxPromptBase
 */
export type BoxPromptBase = {
  /**
   * Y Min
   *
   * Y Min Coordinate of the box
   */
  y_min?: number
  /**
   * X Max
   *
   * X Max Coordinate of the prompt
   */
  x_max?: number
  /**
   * X Min
   *
   * X Min Coordinate of the box
   */
  x_min?: number
  /**
   * Y Max
   *
   * Y Max Coordinate of the prompt
   */
  y_max?: number
}

/**
 * EraseOutput
 */
export type FinegrainEraserBboxOutput = {
  /**
   * Image
   *
   * The edited image with content erased
   */
  image: FalAiFinegrainEraserBboxFile
  /**
   * Used Seed
   *
   * Seed used for generation
   */
  used_seed: number
}

/**
 * File
 */
export type FalAiFinegrainEraserBboxFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * PromptEraseRequest
 */
export type FinegrainEraserInput = {
  /**
   * Prompt
   *
   * Text description of what to erase
   */
  prompt: string
  /**
   * Mode
   *
   * Erase quality mode
   */
  mode?: 'express' | 'standard' | 'premium'
  /**
   * Seed
   *
   * Random seed for reproducible generation
   */
  seed?: number
  /**
   * Image Url
   *
   * URL of the image to edit
   */
  image_url: string
}

/**
 * EraseOutput
 */
export type FinegrainEraserOutput = {
  /**
   * Image
   *
   * The edited image with content erased
   */
  image: FalAiFinegrainEraserFile
  /**
   * Used Seed
   *
   * Seed used for generation
   */
  used_seed: number
}

/**
 * File
 */
export type FalAiFinegrainEraserFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * StarVectorInput
 */
export type StarVectorInput = {
  /**
   * Seed
   *
   * seed to be used for generation
   */
  seed?: number
  /**
   * Image Url
   *
   * URL of image to be used for relighting
   */
  image_url: string
}

/**
 * StarVectorOutput
 */
export type StarVectorOutput = {
  image: FalAiStarVectorFile
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * File
 */
export type FalAiStarVectorFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * Input
 */
export type GhiblifyInput = {
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * The seed to use for the upscale. If not provided, a random seed will be used.
   */
  seed?: number | unknown
  /**
   * Image Url
   *
   * The URL of the image to upscale.
   */
  image_url: string
}

/**
 * Output
 */
export type GhiblifyOutput = {
  /**
   * The URL of the generated image.
   */
  image: FalAiGhiblifyImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiGhiblifyImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * TheraInput
 */
export type TheraInput = {
  /**
   * Upscale Factor
   *
   * The upscaling factor for the image.
   */
  upscale_factor?: number
  /**
   * Seed
   *
   * Random seed for reproducible generation.
   */
  seed?: number
  /**
   * Backbone
   *
   * Backbone to use for upscaling
   */
  backbone: 'edsr' | 'rdn'
  /**
   * Image Url
   *
   * URL of image to be used for upscaling
   */
  image_url: string
}

/**
 * TheraOutput
 */
export type TheraOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: FalAiTheraImage
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiTheraImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * MixDehazeNetInput
 */
export type MixDehazeNetInput = {
  /**
   * Model
   *
   * Model to be used for dehazing
   */
  model?: 'indoor' | 'outdoor'
  /**
   * Seed
   *
   * seed to be used for generation
   */
  seed?: number
  /**
   * Image Url
   *
   * URL of image to be used for image enhancement
   */
  image_url: string
}

/**
 * MixDehazeNetOutput
 */
export type MixDehazeNetOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: FalAiMixDehazeNetImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiMixDehazeNetImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * GeminiImageRequest
 */
export type GeminiFlashEditInput = {
  /**
   * Prompt
   *
   * The prompt for image generation or editing
   */
  prompt: string
  /**
   * Image Url
   *
   * Optional URL of an input image for editing. If not provided, generates a new image.
   */
  image_url: string
}

/**
 * GeminiImageOutput
 */
export type GeminiFlashEditOutput = {
  /**
   * Description
   *
   * Text description or response from Gemini
   */
  description: string
  image: FalAiGeminiFlashEditImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiGeminiFlashEditImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * GeminiMultiImageRequest
 */
export type GeminiFlashEditMultiInput = {
  /**
   * Prompt
   *
   * The prompt for image generation or editing
   */
  prompt: string
  /**
   * Input Image Urls
   *
   * List of URLs of input images for editing
   */
  input_image_urls: Array<string>
}

/**
 * GeminiImageOutput
 */
export type GeminiFlashEditMultiOutput = {
  /**
   * Description
   *
   * Text description or response from Gemini
   */
  description: string
  image: FalAiGeminiFlashEditMultiImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiGeminiFlashEditMultiImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * WatermarkInput
 */
export type InvisibleWatermarkInput = {
  /**
   * Decode
   *
   * Whether to decode a watermark from the image instead of encoding
   */
  decode?: boolean
  /**
   * Watermark
   *
   * Text to use as watermark (for encoding only)
   */
  watermark?: string
  /**
   * Length
   *
   * Length of watermark bits to decode (required when decode=True)
   */
  length?: number
  /**
   * Image Url
   *
   * URL of image to be watermarked or decoded
   */
  image_url: string
}

/**
 * WatermarkOutput
 */
export type InvisibleWatermarkOutput = {
  /**
   * Image
   *
   * The watermarked image file info (when encoding)
   */
  image?: FalAiInvisibleWatermarkImage
  /**
   * Extracted Watermark
   *
   * The extracted watermark text (when decoding)
   */
  extracted_watermark?: string
  /**
   * Length
   *
   * Length of the watermark bits used (helpful for future decoding)
   */
  length?: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiInvisibleWatermarkImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * DevImageToImageInput
 */
export type JuggernautFluxProImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string
  /**
   * Strength
   *
   * The strength of the initial image. Higher strength values are better for this model.
   */
  strength?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
}

/**
 * Output
 */
export type JuggernautFluxProImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<RundiffusionFalJuggernautFluxProImageToImageImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type RundiffusionFalJuggernautFluxProImageToImageImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * DevImageToImageInput
 */
export type JuggernautFluxBaseImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string
  /**
   * Strength
   *
   * The strength of the initial image. Higher strength values are better for this model.
   */
  strength?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
}

/**
 * Output
 */
export type JuggernautFluxBaseImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<RundiffusionFalJuggernautFluxBaseImageToImageImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type RundiffusionFalJuggernautFluxBaseImageToImageImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * DocResInputDewarp
 */
export type DocresDewarpInput = {
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Image Url
   *
   * URL of image to be used for relighting
   */
  image_url: string
}

/**
 * DocResOutput
 */
export type DocresDewarpOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: FalAiDocresDewarpImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiDocresDewarpImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * DocResInput
 */
export type DocresInput = {
  /**
   * Task
   *
   * Task to perform
   */
  task: 'deshadowing' | 'appearance' | 'deblurring' | 'binarization'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Image Url
   *
   * URL of image to be used for relighting
   */
  image_url: string
}

/**
 * DocResOutput
 */
export type DocresOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: FalAiDocresImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiDocresImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * SwinSrInput
 */
export type Swin2SrInput = {
  /**
   * Task
   *
   * Task to perform
   */
  task?: 'classical_sr' | 'compressed_sr' | 'real_sr'
  /**
   * Seed
   *
   * seed to be used for generation
   */
  seed?: number
  /**
   * Image Url
   *
   * URL of image to be used for image enhancement
   */
  image_url: string
}

/**
 * SwinSrOutput
 */
export type Swin2SrOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: FalAiSwin2SrImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiSwin2SrImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * RemixImageInput
 */
export type IdeogramV2aRemixInput = {
  /**
   * Prompt
   *
   * The prompt to remix the image with
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image
   */
  aspect_ratio?:
    | '10:16'
    | '16:10'
    | '9:16'
    | '16:9'
    | '4:3'
    | '3:4'
    | '1:1'
    | '1:3'
    | '3:1'
    | '3:2'
    | '2:3'
  /**
   * Style
   *
   * The style of the generated image
   */
  style?: 'auto' | 'general' | 'realistic' | 'design' | 'render_3D' | 'anime'
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt with MagicPrompt functionality.
   */
  expand_prompt?: boolean
  /**
   * Image URL
   *
   * The image URL to remix
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Strength
   *
   * Strength of the input image in the remix
   */
  strength?: number
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown
}

/**
 * Output
 */
export type IdeogramV2aRemixOutput = {
  /**
   * Images
   */
  images: Array<FalAiIdeogramV2aRemixFile>
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number
}

/**
 * File
 */
export type FalAiIdeogramV2aRemixFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * RemixImageInput
 */
export type IdeogramV2aTurboRemixInput = {
  /**
   * Prompt
   *
   * The prompt to remix the image with
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image
   */
  aspect_ratio?:
    | '10:16'
    | '16:10'
    | '9:16'
    | '16:9'
    | '4:3'
    | '3:4'
    | '1:1'
    | '1:3'
    | '3:1'
    | '3:2'
    | '2:3'
  /**
   * Style
   *
   * The style of the generated image
   */
  style?: 'auto' | 'general' | 'realistic' | 'design' | 'render_3D' | 'anime'
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt with MagicPrompt functionality.
   */
  expand_prompt?: boolean
  /**
   * Image URL
   *
   * The image URL to remix
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Strength
   *
   * Strength of the input image in the remix
   */
  strength?: number
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown
}

/**
 * Output
 */
export type IdeogramV2aTurboRemixOutput = {
  /**
   * Images
   */
  images: Array<FalAiIdeogramV2aTurboRemixFile>
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number
}

/**
 * File
 */
export type FalAiIdeogramV2aTurboRemixFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * ImageInput
 */
export type EvfSamInput = {
  /**
   * Prompt
   *
   * The prompt to generate segmentation from.
   */
  prompt: string
  /**
   * Use Grounding Dino
   *
   * Use GroundingDINO instead of SAM for segmentation
   */
  use_grounding_dino?: boolean
  /**
   * Semantic Type
   *
   * Enable semantic level segmentation for body parts, background or multi objects
   */
  semantic_type?: boolean
  /**
   * Fill Holes
   *
   * Fill holes in the mask using morphological operations
   */
  fill_holes?: boolean
  /**
   * Expand Mask
   *
   * Expand/dilate the mask by specified pixels
   */
  expand_mask?: number
  /**
   * Mask Only
   *
   * Output only the binary mask instead of masked image
   */
  mask_only?: boolean
  /**
   * Revert Mask
   *
   * Invert the mask (background becomes foreground and vice versa)
   */
  revert_mask?: boolean
  /**
   * Blur Mask
   *
   * Apply Gaussian blur to the mask. Value determines kernel size (must be odd number)
   */
  blur_mask?: number
  /**
   * Negative Prompt
   *
   * Areas to exclude from segmentation (will be subtracted from prompt results)
   */
  negative_prompt?: string
  /**
   * Image Url
   *
   * URL of the input image
   */
  image_url: string
}

/**
 * ImageOutput
 */
export type EvfSamOutput = {
  /**
   * Image
   *
   * The segmented output image
   */
  image: FalAiEvfSamFile
}

/**
 * File
 */
export type FalAiEvfSamFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * DDColorInput
 */
export type DdcolorInput = {
  /**
   * Seed
   *
   * seed to be used for generation
   */
  seed?: number
  /**
   * Image Url
   *
   * URL of image to be used for relighting
   */
  image_url: string
}

/**
 * DDColorOutput
 */
export type DdcolorOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: FalAiDdcolorImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiDdcolorImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * SAM2AutomaticSegmentationInput
 */
export type Sam2AutoSegmentInput = {
  /**
   * Points Per Side
   *
   * Number of points to sample along each side of the image.
   */
  points_per_side?: number
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Min Mask Region Area
   *
   * Minimum area of a mask region.
   */
  min_mask_region_area?: number
  /**
   * Image Url
   *
   * URL of the image to be automatically segmented
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Pred Iou Thresh
   *
   * Threshold for predicted IOU score.
   */
  pred_iou_thresh?: number
  /**
   * Stability Score Thresh
   *
   * Threshold for stability score.
   */
  stability_score_thresh?: number
}

/**
 * SAM2AutomaticSegmentationOutput
 */
export type Sam2AutoSegmentOutput = {
  /**
   * Combined Mask
   *
   * Combined segmentation mask.
   */
  combined_mask: FalAiSam2AutoSegmentImage
  /**
   * Individual Masks
   *
   * Individual segmentation masks.
   */
  individual_masks: Array<FalAiSam2AutoSegmentImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiSam2AutoSegmentImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Input
 */
export type DrctSuperResolutionInput = {
  /**
   * Upscaling Factor (Xs)
   *
   * Upscaling factor.
   */
  upscale_factor?: 4
  /**
   * Image URL
   *
   * URL of the image to upscale.
   */
  image_url: string
}

/**
 * Output
 */
export type DrctSuperResolutionOutput = {
  /**
   * Image
   *
   * Upscaled image
   */
  image: FalAiDrctSuperResolutionImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiDrctSuperResolutionImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * NafnetInputDenoise
 */
export type NafnetDenoiseInput = {
  /**
   * Seed
   *
   * seed to be used for generation
   */
  seed?: number
  /**
   * Image Url
   *
   * URL of image to be used for relighting
   */
  image_url: string
}

/**
 * NafnetOutputDenoise
 */
export type NafnetDenoiseOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: FalAiNafnetDenoiseImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiNafnetDenoiseImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * NafnetInput
 */
export type NafnetDeblurInput = {
  /**
   * Seed
   *
   * seed to be used for generation
   */
  seed?: number
  /**
   * Image Url
   *
   * URL of image to be used for relighting
   */
  image_url: string
}

/**
 * NafnetOutput
 */
export type NafnetDeblurOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: FalAiNafnetDeblurImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiNafnetDeblurImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageProcessingInput
 */
export type PostProcessingInput = {
  /**
   * Blue Shift
   *
   * Blue channel shift amount
   */
  blue_shift?: number
  /**
   * Vertex Y
   *
   * Vertex Y position
   */
  vertex_y?: number
  /**
   * Green Direction
   *
   * Green channel shift direction
   */
  green_direction?: 'horizontal' | 'vertical'
  /**
   * Enable Glow
   *
   * Enable glow effect
   */
  enable_glow?: boolean
  /**
   * Dodge Burn Mode
   *
   * Dodge and burn mode
   */
  dodge_burn_mode?:
    | 'dodge'
    | 'burn'
    | 'dodge_and_burn'
    | 'burn_and_dodge'
    | 'color_dodge'
    | 'color_burn'
    | 'linear_dodge'
    | 'linear_burn'
  /**
   * Glow Intensity
   *
   * Glow intensity
   */
  glow_intensity?: number
  /**
   * Blur Sigma
   *
   * Sigma for Gaussian blur
   */
  blur_sigma?: number
  /**
   * Desaturate Method
   *
   * Desaturation method
   */
  desaturate_method?:
    | 'luminance (Rec.709)'
    | 'luminance (Rec.601)'
    | 'average'
    | 'lightness'
  /**
   * Enable Blur
   *
   * Enable blur effect
   */
  enable_blur?: boolean
  /**
   * Blur Radius
   *
   * Blur radius
   */
  blur_radius?: number
  /**
   * Grain Style
   *
   * Style of film grain to apply
   */
  grain_style?:
    | 'modern'
    | 'analog'
    | 'kodak'
    | 'fuji'
    | 'cinematic'
    | 'newspaper'
  /**
   * Cas Amount
   *
   * CAS sharpening amount
   */
  cas_amount?: number
  /**
   * Gamma
   *
   * Gamma adjustment
   */
  gamma?: number
  /**
   * Tint Mode
   *
   * Tint color mode
   */
  tint_mode?:
    | 'sepia'
    | 'red'
    | 'green'
    | 'blue'
    | 'cyan'
    | 'magenta'
    | 'yellow'
    | 'purple'
    | 'orange'
    | 'warm'
    | 'cool'
    | 'lime'
    | 'navy'
    | 'vintage'
    | 'rose'
    | 'teal'
    | 'maroon'
    | 'peach'
    | 'lavender'
    | 'olive'
  /**
   * Blur Type
   *
   * Type of blur to apply
   */
  blur_type?: 'gaussian' | 'kuwahara'
  /**
   * Enable Vignette
   *
   * Enable vignette effect
   */
  enable_vignette?: boolean
  /**
   * Dissolve Image Url
   *
   * URL of second image for dissolve
   */
  dissolve_image_url?: string
  /**
   * Red Shift
   *
   * Red channel shift amount
   */
  red_shift?: number
  /**
   * Enable Desaturate
   *
   * Enable desaturation effect
   */
  enable_desaturate?: boolean
  /**
   * Grain Intensity
   *
   * Film grain intensity (when enabled)
   */
  grain_intensity?: number
  /**
   * Dodge Burn Intensity
   *
   * Dodge and burn intensity
   */
  dodge_burn_intensity?: number
  /**
   * Smart Sharpen Strength
   *
   * Smart sharpen strength
   */
  smart_sharpen_strength?: number
  /**
   * Red Direction
   *
   * Red channel shift direction
   */
  red_direction?: 'horizontal' | 'vertical'
  /**
   * Image Url
   *
   * URL of image to process
   */
  image_url: string
  /**
   * Vertex X
   *
   * Vertex X position
   */
  vertex_x?: number
  /**
   * Tint Strength
   *
   * Tint strength
   */
  tint_strength?: number
  /**
   * Enable Dissolve
   *
   * Enable dissolve effect
   */
  enable_dissolve?: boolean
  /**
   * Enable Parabolize
   *
   * Enable parabolize effect
   */
  enable_parabolize?: boolean
  /**
   * Enable Grain
   *
   * Enable film grain effect
   */
  enable_grain?: boolean
  /**
   * Solarize Threshold
   *
   * Solarize threshold
   */
  solarize_threshold?: number
  /**
   * Enable Sharpen
   *
   * Enable sharpen effect
   */
  enable_sharpen?: boolean
  /**
   * Enable Dodge Burn
   *
   * Enable dodge and burn effect
   */
  enable_dodge_burn?: boolean
  /**
   * Glow Radius
   *
   * Glow blur radius
   */
  glow_radius?: number
  /**
   * Sharpen Alpha
   *
   * Sharpen strength (for basic mode)
   */
  sharpen_alpha?: number
  /**
   * Enable Color Correction
   *
   * Enable color correction
   */
  enable_color_correction?: boolean
  /**
   * Contrast
   *
   * Contrast adjustment
   */
  contrast?: number
  /**
   * Enable Solarize
   *
   * Enable solarize effect
   */
  enable_solarize?: boolean
  /**
   * Noise Radius
   *
   * Noise radius for smart sharpen
   */
  noise_radius?: number
  /**
   * Grain Scale
   *
   * Film grain scale (when enabled)
   */
  grain_scale?: number
  /**
   * Temperature
   *
   * Color temperature adjustment
   */
  temperature?: number
  /**
   * Brightness
   *
   * Brightness adjustment
   */
  brightness?: number
  /**
   * Blue Direction
   *
   * Blue channel shift direction
   */
  blue_direction?: 'horizontal' | 'vertical'
  /**
   * Dissolve Factor
   *
   * Dissolve blend factor
   */
  dissolve_factor?: number
  /**
   * Sharpen Mode
   *
   * Type of sharpening to apply
   */
  sharpen_mode?: 'basic' | 'smart' | 'cas'
  /**
   * Vignette Strength
   *
   * Vignette strength (when enabled)
   */
  vignette_strength?: number
  /**
   * Sharpen Radius
   *
   * Sharpen radius (for basic mode)
   */
  sharpen_radius?: number
  /**
   * Parabolize Coeff
   *
   * Parabolize coefficient
   */
  parabolize_coeff?: number
  /**
   * Saturation
   *
   * Saturation adjustment
   */
  saturation?: number
  /**
   * Enable Tint
   *
   * Enable color tint effect
   */
  enable_tint?: boolean
  /**
   * Green Shift
   *
   * Green channel shift amount
   */
  green_shift?: number
  /**
   * Preserve Edges
   *
   * Edge preservation factor
   */
  preserve_edges?: number
  /**
   * Desaturate Factor
   *
   * Desaturation factor
   */
  desaturate_factor?: number
  /**
   * Smart Sharpen Ratio
   *
   * Smart sharpen blend ratio
   */
  smart_sharpen_ratio?: number
  /**
   * Enable Chromatic
   *
   * Enable chromatic aberration
   */
  enable_chromatic?: boolean
}

/**
 * ProcessedOutput
 */
export type PostProcessingOutput = {
  /**
   * Images
   *
   * The processed images
   */
  images: Array<FalAiPostProcessingImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiPostProcessingImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * FlowEditInput
 */
export type FloweditInput = {
  /**
   * Source Guidance scale (CFG)
   *
   * Guidance scale for the source.
   */
  src_guidance_scale?: number
  /**
   * N Min
   *
   * Minimum step for improved style edits
   */
  n_min?: number
  /**
   * N Max
   *
   * Control the strength of the edit
   */
  n_max?: number
  /**
   * Image Url
   *
   * URL of image to be used for relighting
   */
  image_url: string
  /**
   * Source Prompt
   *
   * Prompt of the image to be used.
   */
  source_prompt: string
  /**
   * Target Guidance scale (CFG)
   *
   * Guidance scale for target.
   */
  tar_guidance_scale?: number
  /**
   * Target Prompt
   *
   * Prompt of the image to be made.
   */
  target_prompt: string
  /**
   * Seed
   *
   * Random seed for reproducible generation. If set none, a random seed will be used.
   */
  seed?: number
  /**
   * Steps
   *
   * Steps for which the model should run.
   */
  num_inference_steps?: number
  /**
   * N Avg
   *
   * Average step count
   */
  n_avg?: number
}

/**
 * FlowEditOutput
 */
export type FloweditOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: FalAiFloweditImage
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiFloweditImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToImageInput
 */
export type FluxControlLoraCannyImageToImageInput = {
  /**
   * Control Lora Strength
   *
   * The strength of the control lora.
   */
  control_lora_strength?: number
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiFluxControlLoraCannyImageToImageImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<FalAiFluxControlLoraCannyImageToImageLoraWeight>
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image Url
   *
   * URL of image to use for inpainting. or img2img
   */
  image_url: string
  /**
   * Strength
   *
   * The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.
   */
  strength?: number
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Control Lora Image Url
   *
   *
   * The image to use for control lora. This is used to control the style of the generated image.
   *
   */
  control_lora_image_url?: string
}

/**
 * ImageSize
 */
export type FalAiFluxControlLoraCannyImageToImageImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * LoraWeight
 */
export type FalAiFluxControlLoraCannyImageToImageLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
}

/**
 * Output
 */
export type FluxControlLoraCannyImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxControlLoraCannyImageToImageImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFluxControlLoraCannyImageToImageImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * ImageToImageInput
 */
export type FluxControlLoraDepthImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Control Lora Strength
   *
   * The strength of the control lora.
   */
  control_lora_strength?: number
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiFluxControlLoraDepthImageToImageImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<FalAiFluxControlLoraDepthImageToImageLoraWeight>
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image Url
   *
   * URL of image to use for inpainting. or img2img
   */
  image_url: string
  /**
   * Strength
   *
   * The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.
   */
  strength?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Control Lora Image Url
   *
   *
   * The image to use for control lora. This is used to control the style of the generated image.
   *
   */
  control_lora_image_url: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
}

/**
 * ImageSize
 */
export type FalAiFluxControlLoraDepthImageToImageImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * LoraWeight
 */
export type FalAiFluxControlLoraDepthImageToImageLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
}

/**
 * Output
 */
export type FluxControlLoraDepthImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxControlLoraDepthImageToImageImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFluxControlLoraDepthImageToImageImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * Ben2InputImage
 */
export type BenV2ImageInput = {
  /**
   * Seed
   *
   * Random seed for reproducible generation.
   */
  seed?: number
  /**
   * Image Url
   *
   * URL of image to be used for background removal
   */
  image_url: string
}

/**
 * Ben2OutputImage
 */
export type BenV2ImageOutput = {
  /**
   * Image
   *
   * The output image after background removal.
   */
  image: FalAiBenV2ImageImage
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiBenV2ImageImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * UpscaleImageInput
 */
export type IdeogramUpscaleInput = {
  /**
   * Prompt
   *
   * The prompt to upscale the image with
   */
  prompt?: string | unknown
  /**
   * Detail
   *
   * The detail of the upscaled image
   */
  detail?: number
  /**
   * Resemblance
   *
   * The resemblance of the upscaled image to the original image
   */
  resemblance?: number
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt with MagicPrompt functionality.
   */
  expand_prompt?: boolean
  /**
   * Image URL
   *
   * The image URL to upscale
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown
}

/**
 * UpscaleOutput
 */
export type IdeogramUpscaleOutput = {
  /**
   * Images
   */
  images: Array<FalAiIdeogramUpscaleFile>
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number
}

/**
 * File
 */
export type FalAiIdeogramUpscaleFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * CodeformerInput
 */
export type CodeformerInput = {
  /**
   * Aligned
   *
   * Should faces etc should be aligned.
   */
  aligned?: boolean
  /**
   * Image Url
   *
   * URL of image to be used for relighting
   */
  image_url: string
  /**
   * Upscale Factor
   *
   * Upscaling factor
   */
  upscale_factor?: number
  /**
   * Fidelity
   *
   * Weight of the fidelity factor.
   */
  fidelity?: number
  /**
   * Face Upscale
   *
   * Should faces be upscaled
   */
  face_upscale?: boolean
  /**
   * Only Center Face
   *
   * Should only center face be restored
   */
  only_center_face?: boolean
  /**
   * Seed
   *
   * Random seed for reproducible generation.
   */
  seed?: number
}

/**
 * ConformerOutput
 */
export type CodeformerOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: FalAiCodeformerImage
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiCodeformerImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TryOnRequest
 */
export type KlingV15KolorsVirtualTryOnInput = {
  /**
   * Garment Image Url
   *
   * Url to the garment image.
   */
  garment_image_url: string
  /**
   * Sync Mode
   *
   * If true, the function will return the image in the response.
   */
  sync_mode?: boolean
  /**
   * Human Image Url
   *
   * Url for the human image.
   */
  human_image_url: string
}

/**
 * TryOnOutput
 */
export type KlingV15KolorsVirtualTryOnOutput = {
  /**
   * Image
   *
   * The output image.
   */
  image: FalAiKlingV15KolorsVirtualTryOnImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiKlingV15KolorsVirtualTryOnImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * CannyInput
 */
export type FluxLoraCannyInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiFluxLoraCannyImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image Url
   *
   * URL of image to use for canny input
   */
  image_url: string
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<FalAiFluxLoraCannyLoraWeight>
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
}

/**
 * ImageSize
 */
export type FalAiFluxLoraCannyImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * LoraWeight
 */
export type FalAiFluxLoraCannyLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
}

/**
 * Output
 */
export type FluxLoraCannyOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxLoraCannyImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFluxLoraCannyImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * FluxProFillFinetunedInput
 */
export type FluxProV1FillFinetunedInput = {
  /**
   * Prompt
   *
   * The prompt to fill the masked part of the image.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Fine-tune Strength
   *
   *
   * Controls finetune influence.
   * Increase this value if your target concept isn't showing up strongly enough.
   * The optimal setting depends on your finetune and prompt
   *
   */
  finetune_strength: number
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Fine-tune ID
   *
   * References your specific model
   */
  finetune_id: string
  /**
   * Image URL
   *
   * The image URL to generate an image from. Needs to match the dimensions of the mask.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5' | '6'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Mask URL
   *
   * The mask URL to inpaint the image. Needs to match the dimensions of the input image.
   */
  mask_url: string
  /**
   * Enhance Prompt
   *
   * Whether to enhance the prompt for better results.
   */
  enhance_prompt?: boolean
}

/**
 * Output
 */
export type FluxProV1FillFinetunedOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxProV1FillFinetunedRegistryImageFastSdxlModelsImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFluxProV1FillFinetunedRegistryImageFastSdxlModelsImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * DetectionInput
 */
export type MoondreamNextDetectionInput = {
  /**
   * Detection Prompt
   *
   * Text description of what to detect
   */
  detection_prompt: string
  /**
   * Use Ensemble
   *
   * Whether to use ensemble for gaze detection
   */
  use_ensemble?: boolean
  /**
   * Task Type
   *
   * Type of detection to perform
   */
  task_type: 'bbox_detection' | 'point_detection' | 'gaze_detection'
  /**
   * Show Visualization
   *
   * Whether to show visualization for detection
   */
  show_visualization?: boolean
  /**
   * Combine Points
   *
   * Whether to combine points into a single point for point detection. This has no effect for bbox detection or gaze detection.
   */
  combine_points?: boolean
  /**
   * Image URL
   *
   * Image URL to be processed
   */
  image_url: string
}

/**
 * DetectionOutput
 */
export type MoondreamNextDetectionOutput = {
  /**
   * Output Image
   *
   * Output image with detection visualization
   */
  image?: FalAiMoondreamNextDetectionImage
  /**
   * Text Output
   *
   * Detection results as text
   */
  text_output: string
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiMoondreamNextDetectionImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageExpansionInput
 */
export type BriaExpandInput = {
  /**
   * Prompt
   *
   * Text on which you wish to base the image expansion. This parameter is optional. Bria currently supports prompts in English only, excluding special characters.
   */
  prompt?: string
  /**
   * Aspect Ratio
   *
   * The desired aspect ratio of the final image. Will be used over original_image_size and original_image_location if provided.
   */
  aspect_ratio?:
    | '1:1'
    | '2:3'
    | '3:2'
    | '3:4'
    | '4:3'
    | '4:5'
    | '5:4'
    | '9:16'
    | '16:9'
  /**
   * Original Image Location
   *
   * The desired location of the original image, inside the full canvas. Provide the location of the upper left corner of the original image. The location can also be outside the canvas (the original image will be cropped). Will be ignored if aspect_ratio is provided.
   */
  original_image_location?: Array<number>
  /**
   * Image Url
   *
   * The URL of the input image.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Original Image Size
   *
   * The desired size of the original image, inside the full canvas. Ensure that the ratio of input image foreground or main subject to the canvas area is greater than 15% to achieve optimal results. Will be ignored if aspect_ratio is provided.
   */
  original_image_size?: Array<number>
  /**
   * Canvas Size
   *
   * The desired size of the final image, after the expansion. should have an area of less than 5000x5000 pixels.
   */
  canvas_size: Array<number>
  /**
   * Seed
   *
   * You can choose whether you want your generated expension to be random or predictable. You can recreate the same result in the future by using the seed value of a result from the response. You can exclude this parameter if you are not interested in recreating your results. This parameter is optional.
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * The negative prompt you would like to use to generate images.
   */
  negative_prompt?: string
}

/**
 * ImageExpansionOutput
 */
export type BriaExpandOutput = {
  /**
   * Image
   *
   * The generated image
   */
  image: FalAiBriaExpandImage
  /**
   * Seed
   *
   * Seed value used for generation.
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiBriaExpandImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * GenFillInput
 */
export type BriaGenfillInput = {
  /**
   * Prompt
   *
   * The prompt you would like to use to generate images.
   */
  prompt: string
  /**
   * Num Images
   *
   * Number of Images to generate.
   */
  num_images?: number
  /**
   * Image Url
   *
   * Input Image to erase from
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Mask Url
   *
   * The URL of the binary mask image that represents the area that will be cleaned.
   */
  mask_url: string
  /**
   * Negative Prompt
   *
   * The negative prompt you would like to use to generate images.
   */
  negative_prompt?: string
}

/**
 * GenFillOutput
 */
export type BriaGenfillOutput = {
  /**
   * Images
   *
   * Generated Images
   */
  images: Array<FalAiBriaGenfillImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiBriaGenfillImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * EraserInput
 */
export type BriaEraserInput = {
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Preserve Alpha
   *
   *
   * If set to true, attempts to preserve the alpha channel of the input image.
   *
   */
  preserve_alpha?: boolean
  /**
   * Mask Url
   *
   * The URL of the binary mask image that represents the area that will be cleaned.
   */
  mask_url: string
  /**
   * Mask Type
   *
   * You can use this parameter to specify the type of the input mask from the list. 'manual' opttion should be used in cases in which the mask had been generated by a user (e.g. with a brush tool), and 'automatic' mask type should be used when mask had been generated by an algorithm like 'SAM'.
   */
  mask_type?: 'manual' | 'automatic'
  /**
   * Image Url
   *
   * Input Image to erase from
   */
  image_url: string
}

/**
 * EraserOutput
 */
export type BriaEraserOutput = {
  /**
   * Image
   *
   * The generated image
   */
  image: FalAiBriaEraserImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiBriaEraserImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * BGReplaceInput
 */
export type BriaBackgroundReplaceInput = {
  /**
   * Ref Image Url
   *
   * The URL of the reference image to be used for generating the new background. Use "" to leave empty. Either ref_image_url or bg_prompt has to be provided but not both. If both ref_image_url and ref_image_file are provided, ref_image_url will be used. Accepted formats are jpeg, jpg, png, webp.
   */
  ref_image_url?: string
  /**
   * Num Images
   *
   * Number of Images to generate.
   */
  num_images?: number
  /**
   * Prompt
   *
   * The prompt you would like to use to generate images.
   */
  prompt?: string
  /**
   * Refine Prompt
   *
   * Whether to refine prompt
   */
  refine_prompt?: boolean
  /**
   * Image Url
   *
   * Input Image to erase from
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Fast
   *
   * Whether to use the fast model
   */
  fast?: boolean
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * The negative prompt you would like to use to generate images.
   */
  negative_prompt?: string
}

/**
 * BGReplaceOutput
 */
export type BriaBackgroundReplaceOutput = {
  /**
   * Images
   *
   * The generated images
   */
  images: Array<FalAiBriaBackgroundReplaceImage>
  /**
   * Seed
   *
   * Seed value used for generation.
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiBriaBackgroundReplaceImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageFillInput
 */
export type ImageFillInput = {
  /**
   * In Context Fill
   *
   * Uses the provided fill image in context with the base image to fill in more faithfully. Will increase price.
   */
  in_context_fill?: boolean
  /**
   * Use Prompt
   *
   * Whether to use the prompt as well in the generation, along with the redux image.
   */
  use_prompt?: boolean
  /**
   * Fill Image Url
   *
   * URLs of images to be filled into the masked area.
   */
  fill_image_url?: Array<string> | string
}

/**
 * Output
 */
export type FluxLoraFillOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxLoraFillImage>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
}

/**
 * Image
 */
export type FalAiFluxLoraFillImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * ProductShotInput
 */
export type BriaProductShotInput = {
  /**
   * Ref Image Url
   *
   * The URL of the reference image to be used for generating the new scene or background for the product shot. Use "" to leave empty.Either ref_image_url or scene_description has to be provided but not both. If both ref_image_url and ref_image_file are provided, ref_image_url will be used. Accepted formats are jpeg, jpg, png, webp.
   */
  ref_image_url?: string
  /**
   * Num Results
   *
   * The number of lifestyle product shots you would like to generate. You will get num_results x 10 results when placement_type=automatic and according to the number of required placements x num_results if placement_type=manual_placement.
   */
  num_results?: number
  /**
   * Manual Placement Selection
   *
   * If you've selected placement_type=manual_placement, you should use this parameter to specify which placements/positions you would like to use from the list. You can select more than one placement in one request.
   */
  manual_placement_selection?:
    | 'upper_left'
    | 'upper_right'
    | 'bottom_left'
    | 'bottom_right'
    | 'right_center'
    | 'left_center'
    | 'upper_center'
    | 'bottom_center'
    | 'center_vertical'
    | 'center_horizontal'
  /**
   * Padding Values
   *
   * The desired padding in pixels around the product, when using placement_type=manual_padding. The order of the values is [left, right, top, bottom]. For optimal results, the total number of pixels, including padding, should be around 1,000,000. It is recommended to first use the product cutout API, get the cutout and understand the size of the result, and then define the required padding and use the cutout as an input for this API.
   */
  padding_values?: Array<number>
  /**
   * Shot Size
   *
   * The desired size of the final product shot. For optimal results, the total number of pixels should be around 1,000,000. This parameter is only relevant when placement_type=automatic or placement_type=manual_placement.
   */
  shot_size?: Array<number>
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Placement Type
   *
   * This parameter allows you to control the positioning of the product in the image. Choosing 'original' will preserve the original position of the product in the image. Choosing 'automatic' will generate results with the 10 recommended positions for the product. Choosing 'manual_placement' will allow you to select predefined positions (using the parameter 'manual_placement_selection'). Selecting 'manual_padding' will allow you to control the position and size of the image by defining the desired padding in pixels around the product.
   */
  placement_type?:
    | 'original'
    | 'automatic'
    | 'manual_placement'
    | 'manual_padding'
  /**
   * Original Quality
   *
   * This flag is only relevant when placement_type=original. If true, the output image retains the original input image's size; otherwise, the image is scaled to 1 megapixel (1MP) while preserving its aspect ratio.
   */
  original_quality?: boolean
  /**
   * Fast
   *
   * Whether to use the fast model
   */
  fast?: boolean
  /**
   * Image Url
   *
   * The URL of the product shot to be placed in a lifestyle shot. If both image_url and image_file are provided, image_url will be used. Accepted formats are jpeg, jpg, png, webp. Maximum file size 12MB.
   */
  image_url: string
  /**
   * Scene Description
   *
   * Text description of the new scene or background for the provided product shot. Bria currently supports prompts in English only, excluding special characters.
   */
  scene_description?: string
  /**
   * Optimize Description
   *
   * Whether to optimize the scene description
   */
  optimize_description?: boolean
}

/**
 * ProductShotOutput
 */
export type BriaProductShotOutput = {
  /**
   * Images
   *
   * The generated images
   */
  images: Array<FalAiBriaProductShotImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiBriaProductShotImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * BGRemoveInput
 */
export type BriaBackgroundRemoveInput = {
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Image Url
   *
   * Input Image to erase from
   */
  image_url: string
}

/**
 * BGRemoveOutput
 */
export type BriaBackgroundRemoveOutput = {
  /**
   * Image
   *
   * The generated image
   */
  image: FalAiBriaBackgroundRemoveImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiBriaBackgroundRemoveImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * CATVTONInput
 */
export type CatVtonInput = {
  /**
   * Garment Image Url
   *
   * Url to the garment image.
   */
  garment_image_url: string
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiCatVtonImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Human Image Url
   *
   * Url for the human image.
   */
  human_image_url: string
  /**
   * Cloth Type
   *
   *
   * Type of the Cloth to be tried on.
   *
   * Options:
   * upper: Upper body cloth
   * lower: Lower body cloth
   * overall: Full body cloth
   * inner: Inner cloth, like T-shirt inside a jacket
   * outer: Outer cloth, like a jacket over a T-shirt
   *
   */
  cloth_type: 'upper' | 'lower' | 'overall' | 'inner' | 'outer'
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same input given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
}

/**
 * ImageSize
 */
export type FalAiCatVtonImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * CATVTONOutput
 */
export type CatVtonOutput = {
  /**
   * Image
   *
   * The output image.
   */
  image: FalAiCatVtonImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiCatVtonImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * PoseTransferInput
 */
export type LeffaPoseTransferInput = {
  /**
   * Pose Image Url
   *
   * Url for the human image.
   */
  pose_image_url: string
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your input when generating the image.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same input given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Person Image Url
   *
   * Url to the garment image.
   */
  person_image_url: string
}

/**
 * PoseTransferOutput
 */
export type LeffaPoseTransferOutput = {
  /**
   * Image
   *
   * The output image.
   */
  image: FalAiLeffaPoseTransferImage
  /**
   * Seed
   *
   * The seed for the inference.
   */
  seed: number
  /**
   * Has Nsfw Concepts
   *
   * Whether the image contains NSFW concepts.
   */
  has_nsfw_concepts: boolean
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiLeffaPoseTransferImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * VTONInput
 */
export type LeffaVirtualTryonInput = {
  /**
   * Garment Image Url
   *
   * Url to the garment image.
   */
  garment_image_url: string
  /**
   * Human Image Url
   *
   * Url for the human image.
   */
  human_image_url: string
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean
  /**
   * Garment Type
   *
   * The type of the garment used for virtual try-on.
   */
  garment_type: 'upper_body' | 'lower_body' | 'dresses'
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your input when generating the image.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same input given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
}

/**
 * VTONOutput
 */
export type LeffaVirtualTryonOutput = {
  /**
   * Image
   *
   * The output image.
   */
  image: FalAiLeffaVirtualTryonImage
  /**
   * Seed
   *
   * The seed for the inference.
   */
  seed: number
  /**
   * Has Nsfw Concepts
   *
   * Whether the image contains NSFW concepts.
   */
  has_nsfw_concepts: boolean
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiLeffaVirtualTryonImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * EditImageInput
 */
export type IdeogramV2EditInput = {
  /**
   * Prompt
   *
   * The prompt to fill the masked part of the image.
   */
  prompt: string
  /**
   * Style
   *
   * The style of the generated image
   */
  style?: 'auto' | 'general' | 'realistic' | 'design' | 'render_3D' | 'anime'
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt with MagicPrompt functionality.
   */
  expand_prompt?: boolean
  /**
   * Image URL
   *
   * The image URL to generate an image from. Needs to match the dimensions of the mask.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown
  /**
   * Mask URL
   *
   * The mask URL to inpaint the image. Needs to match the dimensions of the input image.
   */
  mask_url: string
}

/**
 * Output
 */
export type IdeogramV2EditOutput = {
  /**
   * Images
   */
  images: Array<FalAiIdeogramV2EditFile>
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number
}

/**
 * File
 */
export type FalAiIdeogramV2EditFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * RemixImageInput
 */
export type IdeogramV2TurboRemixInput = {
  /**
   * Prompt
   *
   * The prompt to remix the image with
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image
   */
  aspect_ratio?:
    | '10:16'
    | '16:10'
    | '9:16'
    | '16:9'
    | '4:3'
    | '3:4'
    | '1:1'
    | '1:3'
    | '3:1'
    | '3:2'
    | '2:3'
  /**
   * Style
   *
   * The style of the generated image
   */
  style?: 'auto' | 'general' | 'realistic' | 'design' | 'render_3D' | 'anime'
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt with MagicPrompt functionality.
   */
  expand_prompt?: boolean
  /**
   * Image URL
   *
   * The image URL to remix
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Strength
   *
   * Strength of the input image in the remix
   */
  strength?: number
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown
}

/**
 * Output
 */
export type IdeogramV2TurboRemixOutput = {
  /**
   * Images
   */
  images: Array<FalAiIdeogramV2TurboRemixFile>
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number
}

/**
 * File
 */
export type FalAiIdeogramV2TurboRemixFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * EditImageInput
 */
export type IdeogramV2TurboEditInput = {
  /**
   * Prompt
   *
   * The prompt to fill the masked part of the image.
   */
  prompt: string
  /**
   * Style
   *
   * The style of the generated image
   */
  style?: 'auto' | 'general' | 'realistic' | 'design' | 'render_3D' | 'anime'
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt with MagicPrompt functionality.
   */
  expand_prompt?: boolean
  /**
   * Image URL
   *
   * The image URL to generate an image from. Needs to match the dimensions of the mask.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown
  /**
   * Mask URL
   *
   * The mask URL to inpaint the image. Needs to match the dimensions of the input image.
   */
  mask_url: string
}

/**
 * Output
 */
export type IdeogramV2TurboEditOutput = {
  /**
   * Images
   */
  images: Array<FalAiIdeogramV2TurboEditFile>
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number
}

/**
 * File
 */
export type FalAiIdeogramV2TurboEditFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * RemixImageInput
 */
export type IdeogramV2RemixInput = {
  /**
   * Prompt
   *
   * The prompt to remix the image with
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image
   */
  aspect_ratio?:
    | '10:16'
    | '16:10'
    | '9:16'
    | '16:9'
    | '4:3'
    | '3:4'
    | '1:1'
    | '1:3'
    | '3:1'
    | '3:2'
    | '2:3'
  /**
   * Style
   *
   * The style of the generated image
   */
  style?: 'auto' | 'general' | 'realistic' | 'design' | 'render_3D' | 'anime'
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt with MagicPrompt functionality.
   */
  expand_prompt?: boolean
  /**
   * Image URL
   *
   * The image URL to remix
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Strength
   *
   * Strength of the input image in the remix
   */
  strength?: number
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown
}

/**
 * Output
 */
export type IdeogramV2RemixOutput = {
  /**
   * Images
   */
  images: Array<FalAiIdeogramV2RemixFile>
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number
}

/**
 * File
 */
export type FalAiIdeogramV2RemixFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * SchnellReduxInput
 */
export type FluxSchnellReduxInput = {
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiFluxSchnellReduxImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiFluxSchnellReduxImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Output
 */
export type FluxSchnellReduxOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxSchnellReduxImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFluxSchnellReduxImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * FluxProRedux
 */
export type FluxProV11ReduxInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt?: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiFluxProV11ReduxImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The image URL to generate an image from. Needs to match the dimensions of the mask.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5' | '6'
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Enhance Prompt
   *
   * Whether to enhance the prompt for better results.
   */
  enhance_prompt?: boolean
}

/**
 * ImageSize
 */
export type FalAiFluxProV11ReduxImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Output
 */
export type FluxProV11ReduxOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxProV11ReduxRegistryImageFastSdxlModelsImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFluxProV11ReduxRegistryImageFastSdxlModelsImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * BaseReduxInput
 */
export type FluxDevReduxInput = {
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiFluxDevReduxImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiFluxDevReduxImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Output
 */
export type FluxDevReduxOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxDevReduxImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFluxDevReduxImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * DepthInput
 */
export type FluxLoraDepthInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate. This is always set to 1 for streaming output.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiFluxLoraDepthImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image Url
   *
   * URL of image to use for depth input
   */
  image_url: string
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<FalAiFluxLoraDepthLoraWeight>
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
}

/**
 * ImageSize
 */
export type FalAiFluxLoraDepthImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * LoraWeight
 */
export type FalAiFluxLoraDepthLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
}

/**
 * Output
 */
export type FluxLoraDepthOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxLoraDepthImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFluxLoraDepthImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * FluxProUltraTextToImageInputRedux
 */
export type FluxProV11UltraReduxInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt?: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | '21:9'
    | '16:9'
    | '4:3'
    | '3:2'
    | '1:1'
    | '2:3'
    | '3:4'
    | '9:16'
    | '9:21'
    | string
  /**
   * Enhance Prompt
   *
   * Whether to enhance the prompt for better results.
   */
  enhance_prompt?: boolean
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The image URL to generate an image from. Needs to match the dimensions of the mask.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5' | '6'
  /**
   * Image Prompt Strength
   *
   * The strength of the image prompt, between 0 and 1.
   */
  image_prompt_strength?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Raw
   *
   * Generate less processed, more natural-looking images.
   */
  raw?: boolean
}

/**
 * Output
 */
export type FluxProV11UltraReduxOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxProV11UltraReduxRegistryImageFastSdxlModelsImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFluxProV11UltraReduxRegistryImageFastSdxlModelsImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * FluxProFillInput
 */
export type FluxProV1FillInput = {
  /**
   * Prompt
   *
   * The prompt to fill the masked part of the image.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image URL
   *
   * The image URL to generate an image from. Needs to match the dimensions of the mask.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: '1' | '2' | '3' | '4' | '5' | '6'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Mask URL
   *
   * The mask URL to inpaint the image. Needs to match the dimensions of the input image.
   */
  mask_url: string
  /**
   * Enhance Prompt
   *
   * Whether to enhance the prompt for better results.
   */
  enhance_prompt?: boolean
}

/**
 * Output
 */
export type FluxProV1FillOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxProV1FillRegistryImageFastSdxlModelsImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFluxProV1FillRegistryImageFastSdxlModelsImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * KolorsImg2ImgInput
 */
export type KolorsImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiKolorsImageToImageImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image Url
   *
   * URL of image to use for image to image
   */
  image_url: string
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and
   * uploaded before returning the response. This will increase the latency of
   * the function but it allows you to get the image directly in the response
   * without going through the CDN.
   *
   */
  sync_mode?: boolean
  /**
   * Scheduler
   *
   * The scheduler to use for the model.
   */
  scheduler?:
    | 'EulerDiscreteScheduler'
    | 'EulerAncestralDiscreteScheduler'
    | 'DPMSolverMultistepScheduler'
    | 'DPMSolverMultistepScheduler_SDE_karras'
    | 'UniPCMultistepScheduler'
    | 'DEISMultistepScheduler'
  /**
   * Strength
   *
   * The strength to use for image-to-image. 1.0 is completely remakes the image while 0.0 preserves the original.
   */
  strength?: number
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show
   * you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * Seed
   */
  seed?: number
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small
   * details (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
  /**
   * Enable Safety Checker
   *
   * Enable safety checker.
   */
  enable_safety_checker?: boolean
}

/**
 * ImageSize
 */
export type FalAiKolorsImageToImageImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Output
 */
export type KolorsImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiKolorsImageToImageImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiKolorsImageToImageImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * BaseInput
 */
export type IclightV2Input = {
  /**
   * Initial Latent
   *
   *
   * Provide lighting conditions for the model
   *
   */
  initial_latent?: 'None' | 'Left' | 'Right' | 'Top' | 'Bottom'
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiIclightV2ImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Background Threshold
   *
   * Threshold for the background removal algorithm. A high threshold will produce sharper masks. Note: This parameter is currently deprecated and has no effect on the output.
   */
  background_threshold?: number
  /**
   * Mask Image Url
   *
   * URL of mask to be used for ic-light conditioning image
   */
  mask_image_url?: string
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Lowres Denoise
   *
   * Strength for low-resolution pass.
   */
  lowres_denoise?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * Negative Prompt for the image
   */
  negative_prompt?: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Hr Downscale
   */
  hr_downscale?: number
  /**
   * Image Url
   *
   * URL of image to be used for relighting
   */
  image_url: string
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean
  /**
   * Highres Denoise
   *
   * Strength for high-resolution pass. Only used if enable_hr_fix is True.
   */
  highres_denoise?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Enable Hr Fix
   *
   * Use HR fix
   */
  enable_hr_fix?: boolean
  /**
   * Cfg
   *
   * The real classifier-free-guidance scale for the generation.
   */
  cfg?: number
}

/**
 * ImageSize
 */
export type FalAiIclightV2ImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Output
 */
export type IclightV2Output = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiIclightV2Image>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiIclightV2Image = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * DiffInput
 */
export type FluxDifferentialDiffusionInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image URL
   *
   * URL of image to use as initial image.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Strength
   *
   * The strength to use for image-to-image. 1.0 is completely remakes the image while 0.0 preserves the original.
   */
  strength?: number
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Change Map URL
   *
   * URL of change map.
   */
  change_map_image_url: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * Output
 */
export type FluxDifferentialDiffusionOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxDifferentialDiffusionImage>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
}

/**
 * Image
 */
export type FalAiFluxDifferentialDiffusionImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * FluxPulidInput
 */
export type FluxPulidInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Id Weight
   *
   * The weight of the ID loss.
   */
  id_weight?: number
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiFluxPulidImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Start Step
   *
   * The number of steps to start the CFG from.
   */
  start_step?: number
  /**
   * Reference Image URL
   *
   * URL of image to use for inpainting.
   */
  reference_image_url: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Max Sequence Length
   *
   * The maximum sequence length for the model.
   */
  max_sequence_length?: '128' | '256' | '512'
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * The prompt to generate an image from.
   */
  negative_prompt?: string
  /**
   * True Cfg
   *
   * The weight of the CFG loss.
   */
  true_cfg?: number
}

/**
 * ImageSize
 */
export type FalAiFluxPulidImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Output
 */
export type FluxPulidOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxPulidImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFluxPulidImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * InputV2
 */
export type BirefnetV2Input = {
  /**
   * Operating Resolution
   *
   * The resolution to operate on. The higher the resolution, the more accurate the output will be for high res input images. The '2304x2304' option is only available for the 'General Use (Dynamic)' model.
   */
  operating_resolution?: '1024x1024' | '2048x2048' | '2304x2304'
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'webp' | 'png' | 'gif'
  /**
   * Image Url
   *
   * URL of the image to remove background from
   */
  image_url: string
  /**
   * Model
   *
   *
   * Model to use for background removal.
   * The 'General Use (Light)' model is the original model used in the BiRefNet repository.
   * The 'General Use (Light 2K)' model is the original model used in the BiRefNet repository but trained with 2K images.
   * The 'General Use (Heavy)' model is a slower but more accurate model.
   * The 'Matting' model is a model trained specifically for matting images.
   * The 'Portrait' model is a model trained specifically for portrait images.
   * The 'General Use (Dynamic)' model supports dynamic resolutions from 256x256 to 2304x2304.
   * The 'General Use (Light)' model is recommended for most use cases.
   *
   * The corresponding models are as follows:
   * - 'General Use (Light)': BiRefNet
   * - 'General Use (Light 2K)': BiRefNet_lite-2K
   * - 'General Use (Heavy)': BiRefNet_lite
   * - 'Matting': BiRefNet-matting
   * - 'Portrait': BiRefNet-portrait
   * - 'General Use (Dynamic)': BiRefNet_dynamic
   *
   */
  model?:
    | 'General Use (Light)'
    | 'General Use (Light 2K)'
    | 'General Use (Heavy)'
    | 'Matting'
    | 'Portrait'
    | 'General Use (Dynamic)'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Output Mask
   *
   * Whether to output the mask used to remove the background
   */
  output_mask?: boolean
  /**
   * Refine Foreground
   *
   * Whether to refine the foreground using the estimated mask
   */
  refine_foreground?: boolean
}

/**
 * Output
 */
export type BirefnetV2Output = {
  /**
   * Image
   *
   * Image with background removed
   */
  image: FalAiBirefnetV2ImageFile
  /**
   * Mask Image
   *
   * Mask used to remove the background
   */
  mask_image?: FalAiBirefnetV2ImageFile
}

/**
 * ImageFile
 */
export type FalAiBirefnetV2ImageFile = {
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * LivePortraitImageInput
 */
export type LivePortraitImageInput = {
  /**
   * Smile
   *
   * Amount to smile
   */
  smile?: number
  /**
   * Eyebrow
   *
   * Amount to raise or lower eyebrows
   */
  eyebrow?: number
  /**
   * Rotate Roll
   *
   * Amount to rotate the face in roll
   */
  rotate_roll?: number
  /**
   * Wink
   *
   * Amount to wink
   */
  wink?: number
  /**
   * Rotate Pitch
   *
   * Amount to rotate the face in pitch
   */
  rotate_pitch?: number
  /**
   * Blink
   *
   * Amount to blink the eyes
   */
  blink?: number
  /**
   * Dsize
   *
   * Size of the output image.
   */
  dsize?: number
  /**
   * Vy Ratio
   *
   * Vertical offset ratio for face crop. Positive values move up, negative values move down.
   */
  vy_ratio?: number
  /**
   * Scale
   *
   * Scaling factor for the face crop.
   */
  scale?: number
  /**
   * Pupil X
   *
   * Amount to move pupils horizontally
   */
  pupil_x?: number
  /**
   * Flag Pasteback
   *
   * Whether to paste-back/stitch the animated face cropping from the face-cropping space to the original image space.
   */
  flag_pasteback?: boolean
  /**
   * Eee
   *
   * Amount to shape mouth in 'eee' position
   */
  eee?: number
  /**
   * Enable Safety Checker
   *
   *
   * Whether to enable the safety checker. If enabled, the model will check if the input image contains a face before processing it.
   * The safety checker will process the input image
   *
   */
  enable_safety_checker?: boolean
  /**
   * Vx Ratio
   *
   * Horizontal offset ratio for face crop.
   */
  vx_ratio?: number
  /**
   * Pupil Y
   *
   * Amount to move pupils vertically
   */
  pupil_y?: number
  /**
   * Output Format
   *
   * Output format
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Rotate Yaw
   *
   * Amount to rotate the face in yaw
   */
  rotate_yaw?: number
  /**
   * Flag Do Rot
   *
   * Whether to conduct the rotation when flag_do_crop is True.
   */
  flag_do_rot?: boolean
  /**
   * Woo
   *
   * Amount to shape mouth in 'woo' position
   */
  woo?: number
  /**
   * Aaa
   *
   * Amount to open mouth in 'aaa' shape
   */
  aaa?: number
  /**
   * Image Url
   *
   * URL of the image to be animated
   */
  image_url: string
  /**
   * Flag Do Crop
   *
   * Whether to crop the source portrait to the face-cropping space.
   */
  flag_do_crop?: boolean
  /**
   * Flag Lip Zero
   *
   * Whether to set the lip to closed state before animation. Only takes effect when flag_eye_retargeting and flag_lip_retargeting are False.
   */
  flag_lip_zero?: boolean
}

/**
 * LivePortraitImageOutput
 */
export type LivePortraitImageOutput = {
  /**
   * Image
   *
   * The generated image file.
   */
  image: FalAiLivePortraitImageImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiLivePortraitImageImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ControlNetUnionInput
 */
export type ControlNetUnionInput = {
  /**
   * Conditioning Scale
   *
   *
   * The scale of the control net weight. This is used to scale the control net weight
   * before merging it with the base model.
   *
   */
  conditioning_scale?: number
  /**
   * Mask Threshold
   *
   * Threshold for mask.
   */
  mask_threshold?: number
  /**
   * End Percentage
   *
   *
   * The percentage of the image to end applying the controlnet in terms of the total timesteps.
   *
   */
  end_percentage?: number
  /**
   * Mask Image Url
   *
   * URL of the mask for the control image.
   */
  mask_image_url?: string | null
  /**
   * Control Image Url
   *
   * URL of the image to be used as the control image.
   */
  control_image_url: string
  /**
   * Control Mode
   *
   * Control Mode for Flux Controlnet Union. Supported values are:
   * - canny: Uses the edges for guided generation.
   * - tile: Uses the tiles for guided generation.
   * - depth: Utilizes a grayscale depth map for guided generation.
   * - blur: Adds a blur to the image.
   * - pose: Uses the pose of the image for guided generation.
   * - gray: Converts the image to grayscale.
   * - low-quality: Converts the image to a low-quality image.
   */
  control_mode:
    | 'canny'
    | 'tile'
    | 'depth'
    | 'blur'
    | 'pose'
    | 'gray'
    | 'low-quality'
  /**
   * Start Percentage
   *
   *
   * The percentage of the image to start applying the controlnet in terms of the total timesteps.
   *
   */
  start_percentage?: number
}

/**
 * Output
 */
export type FluxGeneralRfInversionOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxGeneralRfInversionImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFluxGeneralRfInversionImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * HEDInput
 */
export type ImagePreprocessorsHedInput = {
  /**
   * Safe
   *
   * Whether to use the safe version of the HED detector
   */
  safe?: boolean
  /**
   * Scribble
   *
   * Whether to use the scribble version of the HED detector
   */
  scribble?: boolean
  /**
   * Image Url
   *
   * URL of the image to process
   */
  image_url: string
}

/**
 * HEDOutput
 */
export type ImagePreprocessorsHedOutput = {
  image: FalAiImagePreprocessorsHedImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImagePreprocessorsHedImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * ScribbleInput
 */
export type ImagePreprocessorsScribbleInput = {
  /**
   * Model
   *
   * The model to use for the Scribble detector
   */
  model?: 'HED' | 'PiDi'
  /**
   * Safe
   *
   * Whether to use the safe version of the Scribble detector
   */
  safe?: boolean
  /**
   * Image Url
   *
   * URL of the image to process
   */
  image_url: string
}

/**
 * ScribbleOutput
 */
export type ImagePreprocessorsScribbleOutput = {
  image: FalAiImagePreprocessorsScribbleImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImagePreprocessorsScribbleImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * DepthAnythingV2Input
 */
export type ImagePreprocessorsDepthAnythingV2Input = {
  /**
   * Image Url
   *
   * URL of the image to process
   */
  image_url: string
}

/**
 * DepthAnythingV2Output
 */
export type ImagePreprocessorsDepthAnythingV2Output = {
  image: FalAiImagePreprocessorsDepthAnythingV2Image
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImagePreprocessorsDepthAnythingV2Image = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * ZoeInput
 */
export type ImagePreprocessorsZoeInput = {
  /**
   * Image Url
   *
   * URL of the image to process
   */
  image_url: string
}

/**
 * ZoeOutput
 */
export type ImagePreprocessorsZoeOutput = {
  image: FalAiImagePreprocessorsZoeImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImagePreprocessorsZoeImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * TeeDInput
 */
export type ImagePreprocessorsTeedInput = {
  /**
   * Image Url
   *
   * URL of the image to process
   */
  image_url: string
}

/**
 * TeeDOutput
 */
export type ImagePreprocessorsTeedOutput = {
  image: FalAiImagePreprocessorsTeedImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImagePreprocessorsTeedImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * MLSDInput
 */
export type ImagePreprocessorsMlsdInput = {
  /**
   * Distance Threshold
   *
   * Distance threshold for the MLSD detector
   */
  distance_threshold?: number
  /**
   * Score Threshold
   *
   * Score threshold for the MLSD detector
   */
  score_threshold?: number
  /**
   * Image Url
   *
   * URL of the image to process
   */
  image_url: string
}

/**
 * MLSDOutput
 */
export type ImagePreprocessorsMlsdOutput = {
  image: FalAiImagePreprocessorsMlsdImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImagePreprocessorsMlsdImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * LineartInput
 */
export type ImagePreprocessorsLineartInput = {
  /**
   * Coarse
   *
   * Whether to use the coarse model
   */
  coarse?: boolean
  /**
   * Image Url
   *
   * URL of the image to process
   */
  image_url: string
}

/**
 * LineartOutput
 */
export type ImagePreprocessorsLineartOutput = {
  image: FalAiImagePreprocessorsLineartImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImagePreprocessorsLineartImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * SamInput
 */
export type ImagePreprocessorsSamInput = {
  /**
   * Image Url
   *
   * URL of the image to process
   */
  image_url: string
}

/**
 * SamOutput
 */
export type ImagePreprocessorsSamOutput = {
  image: FalAiImagePreprocessorsSamImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImagePreprocessorsSamImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * MiDaSInput
 */
export type ImagePreprocessorsMidasInput = {
  /**
   * A
   *
   * A parameter for the MiDaS detector
   */
  a?: number
  /**
   * Background Threshold
   *
   * Background threshold for the MiDaS detector
   */
  background_threshold?: number
  /**
   * Image Url
   *
   * URL of the image to process
   */
  image_url: string
}

/**
 * MiDaSOutput
 */
export type ImagePreprocessorsMidasOutput = {
  normal_map: FalAiImagePreprocessorsMidasImage
  depth_map: FalAiImagePreprocessorsMidasImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImagePreprocessorsMidasImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * PiDiInput
 */
export type ImagePreprocessorsPidiInput = {
  /**
   * Safe
   *
   * Whether to use the safe version of the Pidi detector
   */
  safe?: boolean
  /**
   * Apply Filter
   *
   * Whether to apply the filter to the image.
   */
  apply_filter?: boolean
  /**
   * Scribble
   *
   * Whether to use the scribble version of the Pidi detector
   */
  scribble?: boolean
  /**
   * Image Url
   *
   * URL of the image to process
   */
  image_url: string
}

/**
 * PiDiOutput
 */
export type ImagePreprocessorsPidiOutput = {
  image: FalAiImagePreprocessorsPidiImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImagePreprocessorsPidiImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * SAM2ImageInput
 */
export type Sam2ImageInput = {
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png' | 'webp'
  /**
   * Prompts
   *
   * List of prompts to segment the image
   */
  prompts?: Array<FalAiSam2ImagePointPrompt>
  /**
   * Box Prompts
   *
   * Coordinates for boxes
   */
  box_prompts?: Array<FalAiSam2ImageBoxPrompt>
  /**
   * Apply Mask
   *
   * Apply the mask on the image.
   */
  apply_mask?: boolean
  /**
   * Image Url
   *
   * URL of the image to be segmented
   */
  image_url: string
}

/**
 * PointPrompt
 */
export type FalAiSam2ImagePointPrompt = {
  /**
   * Y
   *
   * Y Coordinate of the prompt
   */
  y?: number
  /**
   * Label
   *
   * Label of the prompt. 1 for foreground, 0 for background
   */
  label?: 0 | 1
  /**
   * Frame Index
   *
   * The frame index to interact with.
   */
  frame_index?: number
  /**
   * X
   *
   * X Coordinate of the prompt
   */
  x?: number
}

/**
 * BoxPrompt
 */
export type FalAiSam2ImageBoxPrompt = {
  /**
   * Y Min
   *
   * Y Min Coordinate of the box
   */
  y_min?: number
  /**
   * Frame Index
   *
   * The frame index to interact with.
   */
  frame_index?: number
  /**
   * X Max
   *
   * X Max Coordinate of the prompt
   */
  x_max?: number
  /**
   * X Min
   *
   * X Min Coordinate of the box
   */
  x_min?: number
  /**
   * Y Max
   *
   * Y Max Coordinate of the prompt
   */
  y_max?: number
}

/**
 * SAM2ImageOutput
 */
export type Sam2ImageOutput = {
  /**
   * Image
   *
   * Segmented image.
   */
  image: FalAiSam2ImageImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiSam2ImageImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ControlNetUnionInput
 */
export type FalAiFluxGeneralImageToImageControlNetUnionInput = {
  /**
   * Conditioning Scale
   *
   *
   * The scale of the control net weight. This is used to scale the control net weight
   * before merging it with the base model.
   *
   */
  conditioning_scale?: number
  /**
   * Mask Threshold
   *
   * Threshold for mask.
   */
  mask_threshold?: number
  /**
   * End Percentage
   *
   *
   * The percentage of the image to end applying the controlnet in terms of the total timesteps.
   *
   */
  end_percentage?: number
  /**
   * Mask Image Url
   *
   * URL of the mask for the control image.
   */
  mask_image_url?: string | null
  /**
   * Control Image Url
   *
   * URL of the image to be used as the control image.
   */
  control_image_url: string
  /**
   * Control Mode
   *
   * Control Mode for Flux Controlnet Union. Supported values are:
   * - canny: Uses the edges for guided generation.
   * - tile: Uses the tiles for guided generation.
   * - depth: Utilizes a grayscale depth map for guided generation.
   * - blur: Adds a blur to the image.
   * - pose: Uses the pose of the image for guided generation.
   * - gray: Converts the image to grayscale.
   * - low-quality: Converts the image to a low-quality image.
   */
  control_mode:
    | 'canny'
    | 'tile'
    | 'depth'
    | 'blur'
    | 'pose'
    | 'gray'
    | 'low-quality'
  /**
   * Start Percentage
   *
   *
   * The percentage of the image to start applying the controlnet in terms of the total timesteps.
   *
   */
  start_percentage?: number
}

/**
 * Output
 */
export type FluxGeneralImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxGeneralImageToImageImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFluxGeneralImageToImageImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * ControlNetUnionInput
 */
export type FalAiFluxGeneralInpaintingControlNetUnionInput = {
  /**
   * Conditioning Scale
   *
   *
   * The scale of the control net weight. This is used to scale the control net weight
   * before merging it with the base model.
   *
   */
  conditioning_scale?: number
  /**
   * Mask Threshold
   *
   * Threshold for mask.
   */
  mask_threshold?: number
  /**
   * End Percentage
   *
   *
   * The percentage of the image to end applying the controlnet in terms of the total timesteps.
   *
   */
  end_percentage?: number
  /**
   * Mask Image Url
   *
   * URL of the mask for the control image.
   */
  mask_image_url?: string | null
  /**
   * Control Image Url
   *
   * URL of the image to be used as the control image.
   */
  control_image_url: string
  /**
   * Control Mode
   *
   * Control Mode for Flux Controlnet Union. Supported values are:
   * - canny: Uses the edges for guided generation.
   * - tile: Uses the tiles for guided generation.
   * - depth: Utilizes a grayscale depth map for guided generation.
   * - blur: Adds a blur to the image.
   * - pose: Uses the pose of the image for guided generation.
   * - gray: Converts the image to grayscale.
   * - low-quality: Converts the image to a low-quality image.
   */
  control_mode:
    | 'canny'
    | 'tile'
    | 'depth'
    | 'blur'
    | 'pose'
    | 'gray'
    | 'low-quality'
  /**
   * Start Percentage
   *
   *
   * The percentage of the image to start applying the controlnet in terms of the total timesteps.
   *
   */
  start_percentage?: number
}

/**
 * Output
 */
export type FluxGeneralInpaintingOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxGeneralInpaintingImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFluxGeneralInpaintingImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * ControlNetUnionInput
 */
export type FalAiFluxGeneralDifferentialDiffusionControlNetUnionInput = {
  /**
   * Conditioning Scale
   *
   *
   * The scale of the control net weight. This is used to scale the control net weight
   * before merging it with the base model.
   *
   */
  conditioning_scale?: number
  /**
   * Mask Threshold
   *
   * Threshold for mask.
   */
  mask_threshold?: number
  /**
   * End Percentage
   *
   *
   * The percentage of the image to end applying the controlnet in terms of the total timesteps.
   *
   */
  end_percentage?: number
  /**
   * Mask Image Url
   *
   * URL of the mask for the control image.
   */
  mask_image_url?: string | null
  /**
   * Control Image Url
   *
   * URL of the image to be used as the control image.
   */
  control_image_url: string
  /**
   * Control Mode
   *
   * Control Mode for Flux Controlnet Union. Supported values are:
   * - canny: Uses the edges for guided generation.
   * - tile: Uses the tiles for guided generation.
   * - depth: Utilizes a grayscale depth map for guided generation.
   * - blur: Adds a blur to the image.
   * - pose: Uses the pose of the image for guided generation.
   * - gray: Converts the image to grayscale.
   * - low-quality: Converts the image to a low-quality image.
   */
  control_mode:
    | 'canny'
    | 'tile'
    | 'depth'
    | 'blur'
    | 'pose'
    | 'gray'
    | 'low-quality'
  /**
   * Start Percentage
   *
   *
   * The percentage of the image to start applying the controlnet in terms of the total timesteps.
   *
   */
  start_percentage?: number
}

/**
 * Output
 */
export type FluxGeneralDifferentialDiffusionOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxGeneralDifferentialDiffusionImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFluxGeneralDifferentialDiffusionImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * ImageToImageInput
 */
export type FluxLoraImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Num Images
   *
   * The number of images to generate. This is always set to 1 for streaming output.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiFluxLoraImageToImageImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: 'jpeg' | 'png'
  /**
   * Image Url
   *
   * URL of image to use for inpainting. or img2img
   */
  image_url: string
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<FalAiFluxLoraImageToImageLoraWeight>
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Strength
   *
   * The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.
   */
  strength?: number
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
}

/**
 * ImageSize
 */
export type FalAiFluxLoraImageToImageImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * LoraWeight
 */
export type FalAiFluxLoraImageToImageLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
}

/**
 * Output
 */
export type FluxLoraImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFluxLoraImageToImageImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFluxLoraImageToImageImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * InpaintingControlNetUnionInput
 */
export type SdxlControlnetUnionInpaintingInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string
  /**
   * Depth Preprocess
   *
   * Whether to preprocess the depth image.
   */
  depth_preprocess?: boolean
  /**
   * Image Size
   *
   * The size of the generated image. Leave it none to automatically infer from the control image.
   */
  image_size?:
    | FalAiSdxlControlnetUnionInpaintingImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | null
  /**
   * Normal Image Url
   *
   * The URL of the control image.
   */
  normal_image_url?: string
  /**
   * Embeddings
   *
   * The list of embeddings to use.
   */
  embeddings?: Array<Embedding>
  /**
   * Teed Image Url
   *
   * The URL of the control image.
   */
  teed_image_url?: string
  /**
   * Loras
   *
   * The list of LoRA weights to use.
   */
  loras?: Array<FalAiSdxlControlnetUnionInpaintingLoraWeight>
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Canny Image Url
   *
   * The URL of the control image.
   */
  canny_image_url?: string
  /**
   * Segmentation Preprocess
   *
   * Whether to preprocess the segmentation image.
   */
  segmentation_preprocess?: boolean
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: 'jpeg' | 'png'
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Mask Url
   *
   * The URL of the mask to use for inpainting.
   */
  mask_url: string
  /**
   * Segmentation Image Url
   *
   * The URL of the control image.
   */
  segmentation_image_url?: string
  /**
   * Openpose Image Url
   *
   * The URL of the control image.
   */
  openpose_image_url?: string
  /**
   * Canny Preprocess
   *
   * Whether to preprocess the canny image.
   */
  canny_preprocess?: boolean
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean
  /**
   * Depth Image Url
   *
   * The URL of the control image.
   */
  depth_image_url?: string
  /**
   * Normal Preprocess
   *
   * Whether to preprocess the normal image.
   */
  normal_preprocess?: boolean
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
  /**
   * Teed Preprocess
   *
   * Whether to preprocess the teed image.
   */
  teed_preprocess?: boolean
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Controlnet Conditioning Scale
   *
   * The scale of the controlnet conditioning.
   */
  controlnet_conditioning_scale?: number
  /**
   * Strength
   *
   * determines how much the generated image resembles the initial image
   */
  strength?: number
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: 'v1' | 'v2'
  /**
   * Openpose Preprocess
   *
   * Whether to preprocess the openpose image.
   */
  openpose_preprocess?: boolean
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiSdxlControlnetUnionInpaintingImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Embedding
 */
export type Embedding = {
  /**
   * Tokens
   *
   * The list of tokens to use for the embedding.
   */
  tokens?: Array<string>
  /**
   * Path
   *
   * URL or the path to the embedding weights.
   */
  path: string
}

/**
 * LoraWeight
 */
export type FalAiSdxlControlnetUnionInpaintingLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights. Or HF model name.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
  /**
   * Force
   *
   * If set to true, the embedding will be forced to be used.
   */
  force?: boolean
}

/**
 * Output
 */
export type SdxlControlnetUnionInpaintingOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiSdxlControlnetUnionInpaintingImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiSdxlControlnetUnionInpaintingImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * ImageToImageControlNetUnionInput
 */
export type SdxlControlnetUnionImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string
  /**
   * Depth Preprocess
   *
   * Whether to preprocess the depth image.
   */
  depth_preprocess?: boolean
  /**
   * Image Size
   *
   * The size of the generated image. Leave it none to automatically infer from the control image.
   */
  image_size?:
    | FalAiSdxlControlnetUnionImageToImageImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | null
  /**
   * Normal Image Url
   *
   * The URL of the control image.
   */
  normal_image_url?: string
  /**
   * Embeddings
   *
   * The list of embeddings to use.
   */
  embeddings?: Array<FalAiSdxlControlnetUnionImageToImageEmbedding>
  /**
   * Teed Image Url
   *
   * The URL of the control image.
   */
  teed_image_url?: string
  /**
   * Loras
   *
   * The list of LoRA weights to use.
   */
  loras?: Array<FalAiSdxlControlnetUnionImageToImageLoraWeight>
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Canny Image Url
   *
   * The URL of the control image.
   */
  canny_image_url?: string
  /**
   * Segmentation Preprocess
   *
   * Whether to preprocess the segmentation image.
   */
  segmentation_preprocess?: boolean
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: 'jpeg' | 'png'
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Segmentation Image Url
   *
   * The URL of the control image.
   */
  segmentation_image_url?: string
  /**
   * Openpose Image Url
   *
   * The URL of the control image.
   */
  openpose_image_url?: string
  /**
   * Canny Preprocess
   *
   * Whether to preprocess the canny image.
   */
  canny_preprocess?: boolean
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean
  /**
   * Depth Image Url
   *
   * The URL of the control image.
   */
  depth_image_url?: string
  /**
   * Normal Preprocess
   *
   * Whether to preprocess the normal image.
   */
  normal_preprocess?: boolean
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Preserve Aspect Ratio
   *
   *
   * If set to true, the aspect ratio of the generated image will be preserved even
   * if the image size is too large. However, if the image is not a multiple of 32
   * in width or height, it will be resized to the nearest multiple of 32. By default,
   * this snapping to the nearest multiple of 32 will not preserve the aspect ratio.
   * Set crop_output to True, to crop the output to the proper aspect ratio
   * after generating.
   *
   */
  preserve_aspect_ratio?: boolean
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
  /**
   * Crop Output
   *
   *
   * If set to true, the output cropped to the proper aspect ratio after generating.
   *
   */
  crop_output?: boolean
  /**
   * Teed Preprocess
   *
   * Whether to preprocess the teed image.
   */
  teed_preprocess?: boolean
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Controlnet Conditioning Scale
   *
   * The scale of the controlnet conditioning.
   */
  controlnet_conditioning_scale?: number
  /**
   * Strength
   *
   * determines how much the generated image resembles the initial image
   */
  strength?: number
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: 'v1' | 'v2'
  /**
   * Openpose Preprocess
   *
   * Whether to preprocess the openpose image.
   */
  openpose_preprocess?: boolean
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiSdxlControlnetUnionImageToImageImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Embedding
 */
export type FalAiSdxlControlnetUnionImageToImageEmbedding = {
  /**
   * Tokens
   *
   * The list of tokens to use for the embedding.
   */
  tokens?: Array<string>
  /**
   * Path
   *
   * URL or the path to the embedding weights.
   */
  path: string
}

/**
 * LoraWeight
 */
export type FalAiSdxlControlnetUnionImageToImageLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights. Or HF model name.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
  /**
   * Force
   *
   * If set to true, the embedding will be forced to be used.
   */
  force?: boolean
}

/**
 * Output
 */
export type SdxlControlnetUnionImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiSdxlControlnetUnionImageToImageImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiSdxlControlnetUnionImageToImageImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * Era3DInput
 */
export type Era3dInput = {
  /**
   * Cfg
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  cfg?: number
  /**
   * Background Removal
   *
   * Background removal
   */
  background_removal?: boolean
  /**
   * Steps
   *
   * Number of steps to run the model for
   */
  steps?: number
  /**
   * Crop Size
   *
   * Size of the image to crop to
   */
  crop_size?: number
  /**
   * Seed
   *
   * Seed for random number generation
   */
  seed?: number
  /**
   * Image Url
   *
   * URL of the image to remove background from
   */
  image_url: string
}

/**
 * Era3DOutput
 */
export type Era3dOutput = {
  /**
   * Images
   *
   * Images with background removed
   */
  images: Array<FalAiEra3dImage>
  /**
   * Seed
   *
   * Seed used for random number generation
   */
  seed: number
  /**
   * Normal Images
   *
   * Normal images with background removed
   */
  normal_images: Array<FalAiEra3dImage>
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiEra3dImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown
}

/**
 * ImageWithTextInput
 */
export type Florence2LargeReferringExpressionSegmentationInput = {
  /**
   * Text Input
   *
   * Text input for the task
   */
  text_input: string
  /**
   * Image Url
   *
   * The URL of the image to be processed.
   */
  image_url: string
}

/**
 * PolygonOutput
 */
export type PolygonOutput = {
  /**
   * Polygons
   *
   * List of polygons
   */
  polygons: Array<Polygon>
}

/**
 * Polygon
 */
export type Polygon = {
  /**
   * Points
   *
   * List of points
   */
  points: Array<{
    [key: string]: number
  }>
  /**
   * Label
   *
   * Label of the polygon
   */
  label: string
}

/**
 * ImageInput
 */
export type Florence2LargeDenseRegionCaptionInput = {
  /**
   * Image Url
   *
   * The URL of the image to be processed.
   */
  image_url: string
}

/**
 * BoundingBoxOutputWithLabels
 */
export type Florence2LargeDenseRegionCaptionOutput = {
  /**
   * Image
   *
   * Processed image
   */
  image?: FalAiFlorence2LargeDenseRegionCaptionImage
  /**
   * Results
   *
   * Results from the model
   */
  results: BoundingBoxes
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiFlorence2LargeDenseRegionCaptionImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * BoundingBoxes
 */
export type BoundingBoxes = {
  /**
   * Bboxes
   *
   * List of bounding boxes
   */
  bboxes: Array<BoundingBox>
}

/**
 * BoundingBox
 */
export type BoundingBox = {
  /**
   * Y
   *
   * Y-coordinate of the top-left corner
   */
  y: number
  /**
   * Label
   *
   * Label of the bounding box
   */
  label: string
  /**
   * H
   *
   * Height of the bounding box
   */
  h: number
  /**
   * W
   *
   * Width of the bounding box
   */
  w: number
  /**
   * X
   *
   * X-coordinate of the top-left corner
   */
  x: number
}

/**
 * ImageInput
 */
export type Florence2LargeObjectDetectionInput = {
  /**
   * Image Url
   *
   * The URL of the image to be processed.
   */
  image_url: string
}

/**
 * BoundingBoxOutputWithLabels
 */
export type Florence2LargeObjectDetectionOutput = {
  /**
   * Image
   *
   * Processed image
   */
  image?: FalAiFlorence2LargeObjectDetectionImage
  /**
   * Results
   *
   * Results from the model
   */
  results: FalAiFlorence2LargeObjectDetectionBoundingBoxes
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiFlorence2LargeObjectDetectionImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * BoundingBoxes
 */
export type FalAiFlorence2LargeObjectDetectionBoundingBoxes = {
  /**
   * Bboxes
   *
   * List of bounding boxes
   */
  bboxes: Array<FalAiFlorence2LargeObjectDetectionBoundingBox>
}

/**
 * BoundingBox
 */
export type FalAiFlorence2LargeObjectDetectionBoundingBox = {
  /**
   * Y
   *
   * Y-coordinate of the top-left corner
   */
  y: number
  /**
   * Label
   *
   * Label of the bounding box
   */
  label: string
  /**
   * H
   *
   * Height of the bounding box
   */
  h: number
  /**
   * W
   *
   * Width of the bounding box
   */
  w: number
  /**
   * X
   *
   * X-coordinate of the top-left corner
   */
  x: number
}

/**
 * ImageWithTextInput
 */
export type Florence2LargeOpenVocabularyDetectionInput = {
  /**
   * Text Input
   *
   * Text input for the task
   */
  text_input: string
  /**
   * Image Url
   *
   * The URL of the image to be processed.
   */
  image_url: string
}

/**
 * BoundingBoxOutputWithLabels
 */
export type Florence2LargeOpenVocabularyDetectionOutput = {
  /**
   * Image
   *
   * Processed image
   */
  image?: FalAiFlorence2LargeOpenVocabularyDetectionImage
  /**
   * Results
   *
   * Results from the model
   */
  results: FalAiFlorence2LargeOpenVocabularyDetectionBoundingBoxes
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiFlorence2LargeOpenVocabularyDetectionImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * BoundingBoxes
 */
export type FalAiFlorence2LargeOpenVocabularyDetectionBoundingBoxes = {
  /**
   * Bboxes
   *
   * List of bounding boxes
   */
  bboxes: Array<FalAiFlorence2LargeOpenVocabularyDetectionBoundingBox>
}

/**
 * BoundingBox
 */
export type FalAiFlorence2LargeOpenVocabularyDetectionBoundingBox = {
  /**
   * Y
   *
   * Y-coordinate of the top-left corner
   */
  y: number
  /**
   * Label
   *
   * Label of the bounding box
   */
  label: string
  /**
   * H
   *
   * Height of the bounding box
   */
  h: number
  /**
   * W
   *
   * Width of the bounding box
   */
  w: number
  /**
   * X
   *
   * X-coordinate of the top-left corner
   */
  x: number
}

/**
 * ImageWithTextInput
 */
export type Florence2LargeCaptionToPhraseGroundingInput = {
  /**
   * Text Input
   *
   * Text input for the task
   */
  text_input: string
  /**
   * Image Url
   *
   * The URL of the image to be processed.
   */
  image_url: string
}

/**
 * BoundingBoxOutputWithLabels
 */
export type Florence2LargeCaptionToPhraseGroundingOutput = {
  /**
   * Image
   *
   * Processed image
   */
  image?: FalAiFlorence2LargeCaptionToPhraseGroundingImage
  /**
   * Results
   *
   * Results from the model
   */
  results: FalAiFlorence2LargeCaptionToPhraseGroundingBoundingBoxes
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiFlorence2LargeCaptionToPhraseGroundingImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * BoundingBoxes
 */
export type FalAiFlorence2LargeCaptionToPhraseGroundingBoundingBoxes = {
  /**
   * Bboxes
   *
   * List of bounding boxes
   */
  bboxes: Array<FalAiFlorence2LargeCaptionToPhraseGroundingBoundingBox>
}

/**
 * BoundingBox
 */
export type FalAiFlorence2LargeCaptionToPhraseGroundingBoundingBox = {
  /**
   * Y
   *
   * Y-coordinate of the top-left corner
   */
  y: number
  /**
   * Label
   *
   * Label of the bounding box
   */
  label: string
  /**
   * H
   *
   * Height of the bounding box
   */
  h: number
  /**
   * W
   *
   * Width of the bounding box
   */
  w: number
  /**
   * X
   *
   * X-coordinate of the top-left corner
   */
  x: number
}

/**
 * ImageInput
 */
export type Florence2LargeOcrWithRegionInput = {
  /**
   * Image Url
   *
   * The URL of the image to be processed.
   */
  image_url: string
}

/**
 * OCRBoundingBoxOutputWithLabels
 */
export type Florence2LargeOcrWithRegionOutput = {
  /**
   * Image
   *
   * Processed image
   */
  image?: FalAiFlorence2LargeOcrWithRegionImage
  /**
   * Results
   *
   * Results from the model
   */
  results: OcrBoundingBox
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiFlorence2LargeOcrWithRegionImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * OCRBoundingBox
 */
export type OcrBoundingBox = {
  /**
   * Quad Boxes
   *
   * List of quadrilateral boxes
   */
  quad_boxes: Array<OcrBoundingBoxSingle>
}

/**
 * OCRBoundingBoxSingle
 */
export type OcrBoundingBoxSingle = {
  /**
   * Y
   *
   * Y-coordinate of the top-left corner
   */
  y: number
  /**
   * Label
   *
   * Label of the bounding box
   */
  label: string
  /**
   * H
   *
   * Height of the bounding box
   */
  h: number
  /**
   * W
   *
   * Width of the bounding box
   */
  w: number
  /**
   * X
   *
   * X-coordinate of the top-left corner
   */
  x: number
}

/**
 * ImageInput
 */
export type Florence2LargeRegionProposalInput = {
  /**
   * Image Url
   *
   * The URL of the image to be processed.
   */
  image_url: string
}

/**
 * BoundingBoxOutputWithLabels
 */
export type Florence2LargeRegionProposalOutput = {
  /**
   * Image
   *
   * Processed image
   */
  image?: FalAiFlorence2LargeRegionProposalImage
  /**
   * Results
   *
   * Results from the model
   */
  results: FalAiFlorence2LargeRegionProposalBoundingBoxes
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiFlorence2LargeRegionProposalImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * BoundingBoxes
 */
export type FalAiFlorence2LargeRegionProposalBoundingBoxes = {
  /**
   * Bboxes
   *
   * List of bounding boxes
   */
  bboxes: Array<FalAiFlorence2LargeRegionProposalBoundingBox>
}

/**
 * BoundingBox
 */
export type FalAiFlorence2LargeRegionProposalBoundingBox = {
  /**
   * Y
   *
   * Y-coordinate of the top-left corner
   */
  y: number
  /**
   * Label
   *
   * Label of the bounding box
   */
  label: string
  /**
   * H
   *
   * Height of the bounding box
   */
  h: number
  /**
   * W
   *
   * Width of the bounding box
   */
  w: number
  /**
   * X
   *
   * X-coordinate of the top-left corner
   */
  x: number
}

/**
 * ImageWithUserCoordinatesInput
 */
export type Florence2LargeRegionToSegmentationInput = {
  /**
   * Region
   *
   * The user input coordinates
   */
  region: Region
  /**
   * Image Url
   *
   * The URL of the image to be processed.
   */
  image_url: string
}

/**
 * Region
 */
export type Region = {
  /**
   * Y1
   *
   * Y-coordinate of the top-left corner
   */
  y1: number
  /**
   * X2
   *
   * X-coordinate of the bottom-right corner
   */
  x2: number
  /**
   * X1
   *
   * X-coordinate of the top-left corner
   */
  x1: number
  /**
   * Y2
   *
   * Y-coordinate of the bottom-right corner
   */
  y2: number
}

/**
 * PolygonOutput
 */
export type FalAiFlorence2LargeRegionToSegmentationPolygonOutput = {
  /**
   * Polygons
   *
   * List of polygons
   */
  polygons: Array<FalAiFlorence2LargeRegionToSegmentationPolygon>
}

/**
 * Polygon
 */
export type FalAiFlorence2LargeRegionToSegmentationPolygon = {
  /**
   * Points
   *
   * List of points
   */
  points: Array<{
    [key: string]: number
  }>
  /**
   * Label
   *
   * Label of the polygon
   */
  label: string
}

/**
 * ImageToImageInput
 */
export type StableDiffusionV3MediumImageToImageInput = {
  /**
   * Enhance Prompt
   *
   * If set to true, prompt will be upsampled with more details.
   */
  prompt_expansion?: boolean
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Size
   *
   * The size of the generated image. Defaults to the conditioning image's size.
   */
  image_size?:
    | FalAiStableDiffusionV3MediumImageToImageImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | null
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string
  /**
   * Image URL
   *
   * The image URL to generate an image from.
   */
  image_url: string
  /**
   * Strength
   *
   * The strength of the image-to-image transformation.
   */
  strength?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to generate an image from.
   */
  negative_prompt?: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
}

/**
 * ImageSize
 */
export type FalAiStableDiffusionV3MediumImageToImageImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * SD3Output
 */
export type StableDiffusionV3MediumImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiStableDiffusionV3MediumImageToImageImage>
  /**
   * Number of Images
   *
   * The number of images generated.
   */
  num_images: number
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiStableDiffusionV3MediumImageToImageImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * DWPoseInput
 */
export type DwposeInput = {
  /**
   * Draw Mode
   *
   * Mode of drawing the pose on the image. Options are: 'full-pose', 'body-pose', 'face-pose', 'hand-pose', 'face-hand-mask', 'face-mask', 'hand-mask'.
   */
  draw_mode?:
    | 'full-pose'
    | 'body-pose'
    | 'face-pose'
    | 'hand-pose'
    | 'face-hand-mask'
    | 'face-mask'
    | 'hand-mask'
  /**
   * Image Url
   *
   * URL of the image to be processed
   */
  image_url: string
}

/**
 * DWPoseOutput
 */
export type DwposeOutput = {
  /**
   * Image
   *
   * The predicted pose image
   */
  image: FalAiDwposeImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiDwposeImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TextToImageControlNetInput
 */
export type Sd15DepthControlnetInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string
  /**
   * Image Size
   *
   * The size of the generated image. Leave it none to automatically infer from the control image.
   */
  image_size?:
    | FalAiSd15DepthControlnetImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | null
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean
  /**
   * Loras
   *
   * The list of LoRA weights to use.
   */
  loras?: Array<FalAiSd15DepthControlnetLoraWeight>
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Controlnet Conditioning Scale
   *
   * The scale of the controlnet conditioning.
   */
  controlnet_conditioning_scale?: number
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean
  /**
   * Control Image Url
   *
   * The URL of the control image.
   */
  control_image_url: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Enable Deep Cache
   *
   *
   * If set to true, DeepCache will be enabled. TBD
   *
   */
  enable_deep_cache?: boolean
}

/**
 * ImageSize
 */
export type FalAiSd15DepthControlnetImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * LoraWeight
 */
export type FalAiSd15DepthControlnetLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights. Or HF model name.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
}

/**
 * Output
 */
export type Sd15DepthControlnetOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiSd15DepthControlnetImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiSd15DepthControlnetImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * CCSRInput
 */
export type CcsrInput = {
  /**
   * Color Fix Type
   *
   * Type of color correction for samples.
   */
  color_fix_type?: 'none' | 'wavelet' | 'adain'
  /**
   * Tile Diffusion Size
   *
   * Size of patch.
   */
  tile_diffusion_size?: number
  /**
   * Tile Vae Decoder Size
   *
   * Size of VAE patch.
   */
  tile_vae_decoder_size?: number
  /**
   * Tile Vae Encoder Size
   *
   * Size of latent image
   */
  tile_vae_encoder_size?: number
  /**
   * T Min
   *
   * The starting point of uniform sampling strategy.
   */
  t_min?: number
  /**
   * Image Url
   *
   * The URL or data URI of the image to upscale.
   */
  image_url: string
  /**
   * Tile Diffusion Stride
   *
   * Stride of sliding patch.
   */
  tile_diffusion_stride?: number
  /**
   * Tile Vae
   *
   * If specified, a patch-based sampling strategy will be used for VAE decoding.
   */
  tile_vae?: boolean
  /**
   * Scale
   *
   * The scale of the output image. The higher the scale, the bigger the output image will be.
   */
  scale?: number
  /**
   * Seed
   *
   * Seed for reproducibility. Different seeds will make slightly different results.
   */
  seed?: number
  /**
   * T Max
   *
   * The ending point of uniform sampling strategy.
   */
  t_max?: number
  /**
   * Steps
   *
   * The number of steps to run the model for. The higher the number the better the quality and longer it will take to generate.
   */
  steps?: number
  /**
   * Tile Diffusion
   *
   * If specified, a patch-based sampling strategy will be used for sampling.
   */
  tile_diffusion?: 'none' | 'mix' | 'gaussian'
}

/**
 * CCSROutput
 */
export type CcsrOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: FalAiCcsrImage
  /**
   * Seed
   *
   * The seed used for the generation.
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiCcsrImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * OmniZeroInput
 */
export type OmniZeroInput = {
  /**
   * Prompt
   *
   * Prompt to guide the image generation.
   */
  prompt: string
  /**
   * Identity Image Url
   *
   * Identity image url.
   */
  identity_image_url: string
  /**
   * Identity Strength
   *
   * Identity strength.
   */
  identity_strength?: number
  /**
   * Number Of Images
   *
   * Number of images.
   */
  number_of_images?: number
  /**
   * Guidance Scale
   *
   * Guidance scale.
   */
  guidance_scale?: number
  /**
   * Image Strength
   *
   * Image strength.
   */
  image_strength?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to guide the image generation.
   */
  negative_prompt?: string
  /**
   * Composition Image Url
   *
   * Composition image url.
   */
  composition_image_url: string
  /**
   * Depth Strength
   *
   * Depth strength.
   */
  depth_strength?: number
  /**
   * Composition Strength
   *
   * Composition strength.
   */
  composition_strength?: number
  /**
   * Image Url
   *
   * Input image url.
   */
  image_url: string
  /**
   * Style Image Url
   *
   * Style image url.
   */
  style_image_url: string
  /**
   * Face Strength
   *
   * Face strength.
   */
  face_strength?: number
  /**
   * Style Strength
   *
   * Style strength.
   */
  style_strength?: number
  /**
   * Seed
   *
   * Seed.
   */
  seed?: number
}

/**
 * OmniZeroOutput
 */
export type OmniZeroOutput = {
  /**
   * Image
   *
   * The generated image.
   */
  image: FalAiOmniZeroImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiOmniZeroImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * IpAdapterFaceIdInput
 */
export type IpAdapterFaceIdInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string
  /**
   * Face Image Url
   *
   * An image of a face to match. If an image with a size of 640x640 is not provided, it will be scaled and cropped to that size.
   */
  face_image_url?: string
  /**
   * Width
   *
   *
   * The width of the generated image.
   *
   */
  width?: number
  /**
   * Face Id Det Size
   *
   *
   * The size of the face detection model. The higher the number the more accurate
   * the detection will be but it will also take longer to run. The higher the number the more
   * likely it will fail to find a face as well. Lower it if you are having trouble
   * finding a face in the image.
   *
   */
  face_id_det_size?: number
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
  /**
   * Height
   *
   *
   * The height of the generated image.
   *
   */
  height?: number
  /**
   * Num Samples
   *
   *
   * The number of samples for face id. The more samples the better the image will
   * be but it will also take longer to generate. Default is 4.
   *
   */
  num_samples?: number
  /**
   * Base Sdxl Model Repo
   *
   * The URL to the base SDXL model. Default is SG161222/RealVisXL_V3.0
   */
  base_sdxl_model_repo?: string
  /**
   * Base 1 5 Model Repo
   *
   * The URL to the base 1.5 model. Default is SG161222/Realistic_Vision_V4.0_noVAE
   */
  base_1_5_model_repo?: string
  /**
   * Num Inference Steps
   *
   *
   * The number of inference steps to use for generating the image. The more steps
   * the better the image will be but it will also take longer to generate.
   *
   */
  num_inference_steps?: number
  /**
   * Model Type
   *
   * The model type to use. 1_5 is the default and is recommended for most use cases.
   */
  model_type?:
    | '1_5-v1'
    | '1_5-v1-plus'
    | '1_5-v2-plus'
    | 'SDXL-v1'
    | 'SDXL-v2-plus'
    | '1_5-auraface-v1'
  /**
   * Face Images Data Url
   *
   *
   * URL to zip archive with images of faces. The images embedding will be averaged to
   * create a more accurate face id.
   *
   */
  face_images_data_url?: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
}

/**
 * IpAdapterFaceIdOutput
 */
export type IpAdapterFaceIdOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: FalAiIpAdapterFaceIdImage
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiIpAdapterFaceIdImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TimestepsInput
 */
export type TimestepsInput = {
  /**
   * Method
   *
   *
   * The method to use for the timesteps. If set to 'array', the timesteps will be set based
   * on the provided timesteps schedule in the `array` field.
   * Defaults to 'default' which means the scheduler will use the `num_inference_steps` parameter.
   *
   */
  method?: 'default' | 'array'
  /**
   * Array
   *
   *
   * Timesteps schedule to be used if 'custom' method is selected.
   *
   */
  array?: Array<number>
}

/**
 * OutputParameters
 */
export type LoraInpaintOutput = {
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiLoraInpaintImage>
  /**
   * Debug Latents
   *
   * The latents saved for debugging.
   */
  debug_latents?: FalAiLoraInpaintFile
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Debug Per Pass Latents
   *
   * The latents saved for debugging per pass.
   */
  debug_per_pass_latents?: FalAiLoraInpaintFile
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiLoraInpaintImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * File
 */
export type FalAiLoraInpaintFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TimestepsInput
 */
export type FalAiLoraImageToImageTimestepsInput = {
  /**
   * Method
   *
   *
   * The method to use for the timesteps. If set to 'array', the timesteps will be set based
   * on the provided timesteps schedule in the `array` field.
   * Defaults to 'default' which means the scheduler will use the `num_inference_steps` parameter.
   *
   */
  method?: 'default' | 'array'
  /**
   * Array
   *
   *
   * Timesteps schedule to be used if 'custom' method is selected.
   *
   */
  array?: Array<number>
}

/**
 * OutputParameters
 */
export type LoraImageToImageOutput = {
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiLoraImageToImageImage>
  /**
   * Debug Latents
   *
   * The latents saved for debugging.
   */
  debug_latents?: FalAiLoraImageToImageFile
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Debug Per Pass Latents
   *
   * The latents saved for debugging per pass.
   */
  debug_per_pass_latents?: FalAiLoraImageToImageFile
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiLoraImageToImageImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * File
 */
export type FalAiLoraImageToImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToImageInput
 */
export type FastSdxlImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiFastSdxlImageToImageImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Embeddings
   *
   * The list of embeddings to use.
   */
  embeddings?: Array<FalAiFastSdxlImageToImageEmbedding>
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean
  /**
   * Loras
   *
   * The list of LoRA weights to use.
   */
  loras?: Array<FalAiFastSdxlImageToImageLoraWeight>
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Preserve Aspect Ratio
   *
   *
   * If set to true, the aspect ratio of the generated image will be preserved even
   * if the image size is too large. However, if the image is not a multiple of 32
   * in width or height, it will be resized to the nearest multiple of 32. By default,
   * this snapping to the nearest multiple of 32 will not preserve the aspect ratio.
   * Set crop_output to True, to crop the output to the proper aspect ratio
   * after generating.
   *
   */
  preserve_aspect_ratio?: boolean
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
  /**
   * Crop Output
   *
   *
   * If set to true, the output cropped to the proper aspect ratio after generating.
   *
   */
  crop_output?: boolean
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: 'jpeg' | 'png'
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string
  /**
   * Strength
   *
   * determines how much the generated image resembles the initial image
   */
  strength?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: 'v1' | 'v2'
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiFastSdxlImageToImageImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Embedding
 */
export type FalAiFastSdxlImageToImageEmbedding = {
  /**
   * Tokens
   *
   * The list of tokens to use for the embedding.
   */
  tokens?: Array<string>
  /**
   * Path
   *
   * URL or the path to the embedding weights.
   */
  path: string
}

/**
 * LoraWeight
 */
export type FalAiFastSdxlImageToImageLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights. Or HF model name.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
  /**
   * Force
   *
   * If set to true, the embedding will be forced to be used.
   */
  force?: boolean
}

/**
 * Output
 */
export type FastSdxlImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFastSdxlImageToImageImage>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
}

/**
 * Image
 */
export type FalAiFastSdxlImageToImageImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * InpaintingInput
 */
export type FastSdxlInpaintingInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiFastSdxlInpaintingImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Embeddings
   *
   * The list of embeddings to use.
   */
  embeddings?: Array<FalAiFastSdxlInpaintingEmbedding>
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean
  /**
   * Loras
   *
   * The list of LoRA weights to use.
   */
  loras?: Array<FalAiFastSdxlInpaintingLoraWeight>
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: 'jpeg' | 'png'
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string
  /**
   * Strength
   *
   * determines how much the generated image resembles the initial image
   */
  strength?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: 'v1' | 'v2'
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Mask Url
   *
   * The URL of the mask to use for inpainting.
   */
  mask_url: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
}

/**
 * ImageSize
 */
export type FalAiFastSdxlInpaintingImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Embedding
 */
export type FalAiFastSdxlInpaintingEmbedding = {
  /**
   * Tokens
   *
   * The list of tokens to use for the embedding.
   */
  tokens?: Array<string>
  /**
   * Path
   *
   * URL or the path to the embedding weights.
   */
  path: string
}

/**
 * LoraWeight
 */
export type FalAiFastSdxlInpaintingLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights. Or HF model name.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
  /**
   * Force
   *
   * If set to true, the embedding will be forced to be used.
   */
  force?: boolean
}

/**
 * Output
 */
export type FastSdxlInpaintingOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFastSdxlInpaintingImage>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
}

/**
 * Image
 */
export type FalAiFastSdxlInpaintingImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * FaceToStickerInput
 */
export type FaceToStickerInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string
  /**
   * Enable Safety Checker
   *
   * If set to false, the safety checker will be disabled.
   */
  enable_safety_checker?: boolean
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiFaceToStickerImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * IP adapter weight
   *
   * The weight of the IP adapter.
   */
  ip_adapter_weight?: number
  /**
   * Image Url
   *
   * URL of the video.
   */
  image_url: string
  /**
   * Upscale steps
   *
   * The number of steps to use for upscaling. Only used if `upscale` is `true`.
   */
  upscale_steps?: number
  /**
   * Instant ID strength
   *
   * The strength of the instant ID.
   */
  instant_id_strength?: number
  /**
   * Upscale
   *
   * Whether to upscale the image 2x.
   */
  upscale?: boolean
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Number of inference steps
   *
   *
   * Increasing the amount of steps tells Stable Diffusion that it should take more steps
   * to generate your final result which can increase the amount of detail in your image.
   *
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
  /**
   * IP adapter noise
   *
   * The amount of noise to add to the IP adapter.
   */
  ip_adapter_noise?: number
}

/**
 * ImageSize
 */
export type FalAiFaceToStickerImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * FaceToStickerOutput
 */
export type FaceToStickerOutput = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<FalAiFaceToStickerImage>
  /**
   * Sticker Image
   *
   * The generated face sticker image.
   */
  sticker_image: FalAiFaceToStickerImage
  /**
   * Sticker Image Background Removed
   *
   * The generated face sticker image with the background removed.
   */
  sticker_image_background_removed: FalAiFaceToStickerImage
  /**
   * Seed
   *
   * Seed used during the inference.
   */
  seed: number
  /**
   * Has Nsfw Concepts
   *
   *
   * Whether the generated images contain NSFW concepts.
   * The key is the image type and the value is a boolean.
   *
   */
  has_nsfw_concepts: {
    [key: string]: boolean
  }
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiFaceToStickerImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * PhotoMakerInput
 */
export type PhotomakerInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string
  /**
   * Number of images
   *
   *
   * Number of images to generate in one request. Note that the higher the batch size,
   * the longer it will take to generate the images.
   *
   */
  num_images?: number
  /**
   * Style strength (in %)
   */
  style_strength?: number
  /**
   * Style
   */
  style?:
    | '(No style)'
    | 'Cinematic'
    | 'Disney Character'
    | 'Digital Art'
    | 'Photographic'
    | 'Fantasy art'
    | 'Neonpunk'
    | 'Enhance'
    | 'Comic book'
    | 'Lowpoly'
    | 'Line art'
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Image Archive Url
   *
   * The URL of the image archive containing the images you want to use.
   */
  image_archive_url: string
  /**
   * Initial Image Url
   *
   * Optional initial image for img2img
   */
  initial_image_url?: string
  /**
   * Number of inference steps
   *
   *
   * Increasing the amount of steps tells Stable Diffusion that it should take more steps
   * to generate your final result which can increase the amount of detail in your image.
   *
   */
  num_inference_steps?: number
  /**
   * Initial Image Strength
   *
   * How much noise to add to the latent image. O for no noise, 1 for maximum noise.
   */
  initial_image_strength?: number
  /**
   * Base Pipeline
   *
   * The base pipeline to use for generating the image.
   */
  base_pipeline?: 'photomaker' | 'photomaker-style'
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
}

/**
 * PhotoMakerOutput
 */
export type PhotomakerOutput = {
  /**
   * Images
   */
  images: Array<FalAiPhotomakerImage>
  /**
   * Seed
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiPhotomakerImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
}

/**
 * CreativeUpscalerInput
 */
export type CreativeUpscalerInput = {
  /**
   * Shape Preservation
   *
   * How much to preserve the shape of the original image
   */
  shape_preservation?: number
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results. If no prompt is provide BLIP2 will be used to generate a prompt.
   */
  prompt?: string | null
  /**
   * Additional Embedding Url
   *
   * The URL to the additional embeddings to use for the upscaling. Default is None
   */
  additional_embedding_url?: string
  /**
   * Enable Safety Checks
   *
   *
   * If set to true, the resulting image will be checked whether it includes any
   * potentially unsafe content. If it does, it will be replaced with a black
   * image.
   *
   */
  enable_safety_checks?: boolean
  /**
   * Additional Lora Url
   *
   * The URL to the additional LORA model to use for the upscaling. Default is None
   */
  additional_lora_url?: string
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Scale
   *
   * The scale of the output image. The higher the scale, the bigger the output image will be.
   */
  scale?: number
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
  /**
   * Skip Ccsr
   *
   *
   * If set to true, the image will not be processed by the CCSR model before
   * being processed by the creativity model.
   *
   */
  skip_ccsr?: boolean
  /**
   * Additional Lora Scale
   *
   * The scale of the additional LORA model to use for the upscaling. Default is 1.0
   */
  additional_lora_scale?: number
  /**
   * Detail
   *
   * How much detail to add
   */
  detail?: number
  /**
   * Base Model Url
   *
   * The URL to the base model to use for the upscaling
   */
  base_model_url?: string
  /**
   * Image Url
   *
   * The image to upscale.
   */
  image_url: string
  /**
   * Creativity
   *
   * How much the output can deviate from the original
   */
  creativity?: number
  /**
   * Override Size Limits
   *
   *
   * Allow for large uploads that could take a very long time.
   *
   */
  override_size_limits?: boolean
  /**
   * Prompt Suffix
   *
   * The suffix to add to the prompt. This is useful to add a common ending to all prompts such as 'high quality' etc or embedding tokens.
   */
  prompt_suffix?: string
  /**
   * Num Inference Steps
   *
   *
   * The number of inference steps to use for generating the image. The more steps
   * the better the image will be but it will also take longer to generate.
   *
   */
  num_inference_steps?: number
  /**
   * Model Type
   *
   * The type of model to use for the upscaling. Default is SD_1_5
   */
  model_type?: 'SD_1_5' | 'SDXL'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
}

/**
 * CreativeUpscalerOutput
 */
export type CreativeUpscalerOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: FalAiCreativeUpscalerImage
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiCreativeUpscalerImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Input
 */
export type BirefnetInput = {
  /**
   * Operating Resolution
   *
   * The resolution to operate on. The higher the resolution, the more accurate the output will be for high res input images.
   */
  operating_resolution?: '1024x1024' | '2048x2048'
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: 'webp' | 'png' | 'gif'
  /**
   * Image Url
   *
   * URL of the image to remove background from
   */
  image_url: string
  /**
   * Model
   *
   *
   * Model to use for background removal.
   * The 'General Use (Light)' model is the original model used in the BiRefNet repository.
   * The 'General Use (Heavy)' model is a slower but more accurate model.
   * The 'Portrait' model is a model trained specifically for portrait images.
   * The 'General Use (Light)' model is recommended for most use cases.
   *
   * The corresponding models are as follows:
   * - 'General Use (Light)': BiRefNet-DIS_ep580.pth
   * - 'General Use (Heavy)': BiRefNet-massive-epoch_240.pth
   * - 'Portrait': BiRefNet-portrait-TR_P3M_10k-epoch_120.pth
   *
   */
  model?: 'General Use (Light)' | 'General Use (Heavy)' | 'Portrait'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Output Mask
   *
   * Whether to output the mask used to remove the background
   */
  output_mask?: boolean
  /**
   * Refine Foreground
   *
   * Whether to refine the foreground using the estimated mask
   */
  refine_foreground?: boolean
}

/**
 * Output
 */
export type BirefnetOutput = {
  /**
   * Image
   *
   * Image with background removed
   */
  image: FalAiBirefnetImageFile
  /**
   * Mask Image
   *
   * Mask used to remove the background
   */
  mask_image?: FalAiBirefnetImageFile
}

/**
 * ImageFile
 */
export type FalAiBirefnetImageFile = {
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToImageLightningInput
 */
export type FastLightningSdxlImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiFastLightningSdxlImageToImageImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Embeddings
   *
   * The list of embeddings to use.
   */
  embeddings?: Array<FalAiFastLightningSdxlImageToImageEmbedding>
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean
  /**
   * Guidance Rescale
   *
   * The rescale factor for the CFG.
   */
  guidance_rescale?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Preserve Aspect Ratio
   *
   *
   * If set to true, the aspect ratio of the generated image will be preserved even
   * if the image size is too large. However, if the image is not a multiple of 32
   * in width or height, it will be resized to the nearest multiple of 32. By default,
   * this snapping to the nearest multiple of 32 will not preserve the aspect ratio.
   * Set crop_output to True, to crop the output to the proper aspect ratio
   * after generating.
   *
   */
  preserve_aspect_ratio?: boolean
  /**
   * Crop Output
   *
   *
   * If set to true, the output cropped to the proper aspect ratio after generating.
   *
   */
  crop_output?: boolean
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: 'jpeg' | 'png'
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string
  /**
   * Strength
   *
   * determines how much the generated image resembles the initial image
   */
  strength?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: 'v1' | 'v2'
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: '1' | '2' | '4' | '8'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
}

/**
 * ImageSize
 */
export type FalAiFastLightningSdxlImageToImageImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Embedding
 */
export type FalAiFastLightningSdxlImageToImageEmbedding = {
  /**
   * Tokens
   *
   * The list of tokens to use for the embedding.
   */
  tokens?: Array<string>
  /**
   * Path
   *
   * URL or the path to the embedding weights.
   */
  path: string
}

/**
 * Output
 */
export type FastLightningSdxlImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFastLightningSdxlImageToImageImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFastLightningSdxlImageToImageImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * InpaintingPlaygroundv25Input
 */
export type PlaygroundV25InpaintingInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiPlaygroundV25InpaintingImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Embeddings
   *
   * The list of embeddings to use.
   */
  embeddings?: Array<FalAiPlaygroundV25InpaintingEmbedding>
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean
  /**
   * Guidance Rescale
   *
   * The rescale factor for the CFG.
   */
  guidance_rescale?: number
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: 'jpeg' | 'png'
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string
  /**
   * Strength
   *
   * determines how much the generated image resembles the initial image
   */
  strength?: number
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: 'v1' | 'v2'
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Mask Url
   *
   * The URL of the mask to use for inpainting.
   */
  mask_url: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiPlaygroundV25InpaintingImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Embedding
 */
export type FalAiPlaygroundV25InpaintingEmbedding = {
  /**
   * Tokens
   *
   * The list of tokens to use for the embedding.
   */
  tokens?: Array<string>
  /**
   * Path
   *
   * URL or the path to the embedding weights.
   */
  path: string
}

/**
 * Output
 */
export type PlaygroundV25InpaintingOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiPlaygroundV25InpaintingImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiPlaygroundV25InpaintingImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * ImageToImagePlaygroundv25Input
 */
export type PlaygroundV25ImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiPlaygroundV25ImageToImageImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Embeddings
   *
   * The list of embeddings to use.
   */
  embeddings?: Array<FalAiPlaygroundV25ImageToImageEmbedding>
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean
  /**
   * Guidance Rescale
   *
   * The rescale factor for the CFG.
   */
  guidance_rescale?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Preserve Aspect Ratio
   *
   *
   * If set to true, the aspect ratio of the generated image will be preserved even
   * if the image size is too large. However, if the image is not a multiple of 32
   * in width or height, it will be resized to the nearest multiple of 32. By default,
   * this snapping to the nearest multiple of 32 will not preserve the aspect ratio.
   * Set crop_output to True, to crop the output to the proper aspect ratio
   * after generating.
   *
   */
  preserve_aspect_ratio?: boolean
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
  /**
   * Crop Output
   *
   *
   * If set to true, the output cropped to the proper aspect ratio after generating.
   *
   */
  crop_output?: boolean
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: 'jpeg' | 'png'
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string
  /**
   * Strength
   *
   * determines how much the generated image resembles the initial image
   */
  strength?: number
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: 'v1' | 'v2'
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiPlaygroundV25ImageToImageImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Embedding
 */
export type FalAiPlaygroundV25ImageToImageEmbedding = {
  /**
   * Tokens
   *
   * The list of tokens to use for the embedding.
   */
  tokens?: Array<string>
  /**
   * Path
   *
   * URL or the path to the embedding weights.
   */
  path: string
}

/**
 * Output
 */
export type PlaygroundV25ImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiPlaygroundV25ImageToImageImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiPlaygroundV25ImageToImageImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * InpaintingLightningInput
 */
export type FastLightningSdxlInpaintingInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiFastLightningSdxlInpaintingImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Embeddings
   *
   * The list of embeddings to use.
   */
  embeddings?: Array<FalAiFastLightningSdxlInpaintingEmbedding>
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean
  /**
   * Guidance Rescale
   *
   * The rescale factor for the CFG.
   */
  guidance_rescale?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: 'jpeg' | 'png'
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string
  /**
   * Strength
   *
   * determines how much the generated image resembles the initial image
   */
  strength?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: 'v1' | 'v2'
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: '1' | '2' | '4' | '8'
  /**
   * Mask Url
   *
   * The URL of the mask to use for inpainting.
   */
  mask_url: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
}

/**
 * ImageSize
 */
export type FalAiFastLightningSdxlInpaintingImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Embedding
 */
export type FalAiFastLightningSdxlInpaintingEmbedding = {
  /**
   * Tokens
   *
   * The list of tokens to use for the embedding.
   */
  tokens?: Array<string>
  /**
   * Path
   *
   * URL or the path to the embedding weights.
   */
  path: string
}

/**
 * Output
 */
export type FastLightningSdxlInpaintingOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFastLightningSdxlInpaintingImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFastLightningSdxlInpaintingImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * InpaintingLCMInput
 */
export type FastLcmDiffusionInpaintingInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiFastLcmDiffusionInpaintingImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean
  /**
   * Guidance Rescale
   *
   * The rescale factor for the CFG.
   */
  guidance_rescale?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: 'jpeg' | 'png'
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string
  /**
   * Strength
   *
   * determines how much the generated image resembles the initial image
   */
  strength?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: 'v1' | 'v2'
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Mask Url
   *
   * The URL of the mask to use for inpainting.
   */
  mask_url: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Model Name
   *
   * The name of the model to use.
   */
  model_name?:
    | 'stabilityai/stable-diffusion-xl-base-1.0'
    | 'runwayml/stable-diffusion-v1-5'
}

/**
 * ImageSize
 */
export type FalAiFastLcmDiffusionInpaintingImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Output
 */
export type FastLcmDiffusionInpaintingOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFastLcmDiffusionInpaintingImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFastLcmDiffusionInpaintingImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * ImageToImageLCMInput
 */
export type FastLcmDiffusionImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | FalAiFastLcmDiffusionImageToImageImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean
  /**
   * Guidance Rescale
   *
   * The rescale factor for the CFG.
   */
  guidance_rescale?: number
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Preserve Aspect Ratio
   *
   *
   * If set to true, the aspect ratio of the generated image will be preserved even
   * if the image size is too large. However, if the image is not a multiple of 32
   * in width or height, it will be resized to the nearest multiple of 32. By default,
   * this snapping to the nearest multiple of 32 will not preserve the aspect ratio.
   * Set crop_output to True, to crop the output to the proper aspect ratio
   * after generating.
   *
   */
  preserve_aspect_ratio?: boolean
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
  /**
   * Crop Output
   *
   *
   * If set to true, the output cropped to the proper aspect ratio after generating.
   *
   */
  crop_output?: boolean
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: 'jpeg' | 'png'
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Model Name
   *
   * The name of the model to use.
   */
  model_name?:
    | 'stabilityai/stable-diffusion-xl-base-1.0'
    | 'runwayml/stable-diffusion-v1-5'
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: 'v1' | 'v2'
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Strength
   *
   * determines how much the generated image resembles the initial image
   */
  strength?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
}

/**
 * ImageSize
 */
export type FalAiFastLcmDiffusionImageToImageImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Output
 */
export type FastLcmDiffusionImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFastLcmDiffusionImageToImageImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFastLcmDiffusionImageToImageImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * DepthMapInput
 */
export type ImageutilsDepthInput = {
  /**
   * Bg Th
   *
   * bg_th
   */
  bg_th?: number
  /**
   * A
   *
   * a
   */
  a?: number
  /**
   * Depth And Normal
   *
   * depth_and_normal
   */
  depth_and_normal?: boolean
  /**
   * Image Url
   *
   * Input image url.
   */
  image_url: string
}

/**
 * DepthMapOutput
 */
export type ImageutilsDepthOutput = {
  /**
   * Image
   *
   * The depth map.
   */
  image: FalAiImageutilsDepthImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageutilsDepthImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * RetoucherInput
 */
export type RetoucherInput = {
  /**
   * Seed
   *
   * Seed for reproducibility. Different seeds will make slightly different results.
   */
  seed?: number
  /**
   * Image Url
   *
   * The URL of the image to be retouched.
   */
  image_url: string
}

/**
 * RetoucherOutput
 */
export type RetoucherOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: FalAiRetoucherImage
  /**
   * Seed
   *
   * The seed used for the generation.
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiRetoucherImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * MarigoldDepthMapInput
 */
export type ImageutilsMarigoldDepthInput = {
  /**
   * Ensemble Size
   *
   * Number of predictions to average over. Defaults to `10`. The higher the number, the more accurate the result, but the slower the inference.
   */
  ensemble_size?: number
  /**
   * Num Inference Steps
   *
   * Number of denoising steps. Defaults to `10`. The higher the number, the more accurate the result, but the slower the inference.
   */
  num_inference_steps?: number
  /**
   * Processing Res
   *
   * Maximum processing resolution. Defaults `0` which means it uses the size of the input image.
   */
  processing_res?: number
  /**
   * Image Url
   *
   * Input image url.
   */
  image_url: string
}

/**
 * MarigoldDepthMapOutput
 */
export type ImageutilsMarigoldDepthOutput = {
  /**
   * Image
   *
   * The depth map.
   */
  image: FalAiImageutilsMarigoldDepthImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageutilsMarigoldDepthImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * InputModel
 */
export type PulidInput = {
  /**
   * Prompt
   *
   * Prompt to generate the face from
   */
  prompt: string
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number
  /**
   * Image Size
   *
   * Size of the generated image
   */
  image_size?:
    | FalAiPulidImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Id Scale
   *
   * ID scale
   */
  id_scale?: number
  /**
   * Mode
   *
   * Mode of generation
   */
  mode?: 'fidelity' | 'extreme style'
  /**
   * Id Mix
   *
   * if you want to mix two ID image, please turn this on, otherwise, turn this off
   */
  id_mix?: boolean
  /**
   * Guidance Scale
   *
   * Guidance scale
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of steps to take
   */
  num_inference_steps?: number
  /**
   * Reference Images
   *
   * List of reference faces, ideally 4 images.
   */
  reference_images: Array<ReferenceFace>
  /**
   * Negative Prompt
   *
   * Negative prompt to generate the face from
   */
  negative_prompt?: string
  /**
   * Seed
   *
   * Random seed for reproducibility
   */
  seed?: number
}

/**
 * ImageSize
 */
export type FalAiPulidImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * ReferenceFace
 */
export type ReferenceFace = {
  /**
   * Image Url
   *
   * URL of the reference face image
   */
  image_url: string
}

/**
 * OutputModel
 */
export type PulidOutput = {
  /**
   * Images
   *
   * List of generated images
   */
  images: Array<FalAiPulidImage>
  /**
   * Seed
   *
   * Random seed used for reproducibility
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiPulidImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * InpaintingControlNetInput
 */
export type FastSdxlControlnetCannyInpaintingInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string
  /**
   * Image Size
   *
   * The size of the generated image. Leave it none to automatically infer from the control image.
   */
  image_size?:
    | FalAiFastSdxlControlnetCannyInpaintingImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | null
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean
  /**
   * Loras
   *
   * The list of LoRA weights to use.
   */
  loras?: Array<FalAiFastSdxlControlnetCannyInpaintingLoraWeight>
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Controlnet Conditioning Scale
   *
   * The scale of the controlnet conditioning.
   */
  controlnet_conditioning_scale?: number
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string
  /**
   * Strength
   *
   * determines how much the generated image resembles the initial image
   */
  strength?: number
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean
  /**
   * Control Image Url
   *
   * The URL of the control image.
   */
  control_image_url: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Mask Url
   *
   * The URL of the mask to use for inpainting.
   */
  mask_url: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
}

/**
 * ImageSize
 */
export type FalAiFastSdxlControlnetCannyInpaintingImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * LoraWeight
 */
export type FalAiFastSdxlControlnetCannyInpaintingLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights. Or HF model name.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
}

/**
 * Output
 */
export type FastSdxlControlnetCannyInpaintingOutput = {
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFastSdxlControlnetCannyInpaintingImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFastSdxlControlnetCannyInpaintingImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * ImageToImageControlNetInput
 */
export type FastSdxlControlnetCannyImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string
  /**
   * Image Size
   *
   * The size of the generated image. Leave it none to automatically infer from the control image.
   */
  image_size?:
    | FalAiFastSdxlControlnetCannyImageToImageImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
    | null
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean
  /**
   * Loras
   *
   * The list of LoRA weights to use.
   */
  loras?: Array<FalAiFastSdxlControlnetCannyImageToImageLoraWeight>
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number
  /**
   * Controlnet Conditioning Scale
   *
   * The scale of the controlnet conditioning.
   */
  controlnet_conditioning_scale?: number
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string
  /**
   * Strength
   *
   * determines how much the generated image resembles the initial image
   */
  strength?: number
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean
  /**
   * Control Image Url
   *
   * The URL of the control image.
   */
  control_image_url: string
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
}

/**
 * ImageSize
 */
export type FalAiFastSdxlControlnetCannyImageToImageImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * LoraWeight
 */
export type FalAiFastSdxlControlnetCannyImageToImageLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights. Or HF model name.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
}

/**
 * Output
 */
export type FastSdxlControlnetCannyImageToImageOutput = {
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiFastSdxlControlnetCannyImageToImageImage>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 */
export type FalAiFastSdxlControlnetCannyImageToImageImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * LCMI2IInput
 */
export type LcmSd15I2iInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string
  /**
   * Num Images
   *
   *
   * The number of images to generate. The function will return a list of images
   * with the same prompt and negative prompt but different seeds.
   *
   */
  num_images?: number
  /**
   * Image Url
   *
   * The image to use as a base.
   */
  image_url: string
  /**
   * Strength
   *
   * The strength of the image.
   */
  strength?: number
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean
  /**
   * Enable Safety Checks
   *
   *
   * If set to true, the resulting image will be checked whether it includes any
   * potentially unsafe content. If it does, it will be replaced with a black
   * image.
   *
   */
  enable_safety_checks?: boolean
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
  /**
   * Num Inference Steps
   *
   *
   * The number of inference steps to use for generating the image. The more steps
   * the better the image will be but it will also take longer to generate.
   *
   */
  num_inference_steps?: number
}

/**
 * LCMOutput
 */
export type LcmSd15I2iOutput = {
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalAiLcmSd15I2iImage>
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
  /**
   * Num Inference Steps
   *
   *
   * Number of inference steps used to generate the image. It will be the same value of the one passed in the
   * input or the default one in case none was passed.
   *
   */
  num_inference_steps?: number
  /**
   * Nsfw Content Detected
   *
   *
   * A list of booleans indicating whether the generated image contains any
   * potentially unsafe content. If the safety check is disabled, this field
   * will have a false for each generated image.
   *
   */
  nsfw_content_detected: Array<boolean>
}

/**
 * Image
 */
export type FalAiLcmSd15I2iImage = {
  /**
   * Height
   */
  height: number
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
  /**
   * Width
   */
  width: number
}

/**
 * InpaintInput
 */
export type InpaintInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string
  /**
   * Image Url
   *
   * Input image for img2img or inpaint mode
   */
  image_url: string
  /**
   * Model Name
   *
   * URL or HuggingFace ID of the base model to generate the image.
   */
  model_name: string
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Number of inference steps
   *
   *
   * Increasing the amount of steps tells Stable Diffusion that it should take more steps
   * to generate your final result which can increase the amount of detail in your image.
   *
   */
  num_inference_steps?: number
  /**
   * Mask Url
   *
   * Input mask for inpaint mode. Black areas will be preserved, white areas will be inpainted.
   */
  mask_url: string
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
}

/**
 * InpaintOutput
 */
export type InpaintOutput = {
  /**
   * Image
   *
   * The generated image files info.
   */
  image: FalAiInpaintImage
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiInpaintImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * UpscaleInput
 */
export type EsrganInput = {
  /**
   * Model
   *
   * Model to use for upscaling
   */
  model?:
    | 'RealESRGAN_x4plus'
    | 'RealESRGAN_x2plus'
    | 'RealESRGAN_x4plus_anime_6B'
    | 'RealESRGAN_x4_v3'
    | 'RealESRGAN_x4_wdn_v3'
    | 'RealESRGAN_x4_anime_v3'
  /**
   * Face
   *
   * Upscaling a face
   */
  face?: boolean
  /**
   * Scale
   *
   * Rescaling factor
   */
  scale?: number
  /**
   * Tile
   *
   * Tile size. Default is 0, that is no tile. When encountering the out-of-GPU-memory issue, please specify it, e.g., 400 or 200
   */
  tile?: number
  /**
   * Output Format
   *
   * Output image format (png or jpeg)
   */
  output_format?: 'png' | 'jpeg'
  /**
   * Image Url
   *
   * Url to input image
   */
  image_url: string
}

/**
 * UpscaleOutput
 */
export type EsrganOutput = {
  /**
   * Image
   *
   * Upscaled image
   */
  image: FalAiEsrganImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiEsrganImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * RemoveBackgroundInput
 */
export type ImageutilsRembgInput = {
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Crop To Bbox
   *
   *
   * If set to true, the resulting image be cropped to a bounding box around the subject
   *
   */
  crop_to_bbox?: boolean
  /**
   * Image Url
   *
   * Input image url.
   */
  image_url: string
}

/**
 * RemoveBackgroundOutput
 */
export type ImageutilsRembgOutput = {
  /**
   * Image
   *
   * Background removed image.
   */
  image: FalAiImageutilsRembgImage
}

/**
 * Image
 *
 * Represents an image file.
 */
export type FalAiImageutilsRembgImage = {
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}
