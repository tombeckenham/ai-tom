// This file is auto-generated by @hey-api/openapi-ts

import { z } from 'zod'

export const zFile = z.object({
  url: z.url(),
  content_type: z.optional(z.string()),
  file_name: z.optional(z.string()),
  file_size: z.optional(z.int()),
})

export const zQueueStatus = z.object({
  status: z.enum(['IN_PROGRESS', 'COMPLETED', 'FAILED']),
  response_url: z.optional(z.url()),
})

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export const zLoRaInput = z
  .object({
    path: z.string().register(z.globalRegistry, {
      description:
        'URL, HuggingFace repo ID (owner/repo), or local path to LoRA weights.',
    }),
    scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description: 'Scale factor for LoRA application (0.0 to 4.0).',
        }),
      )
      .default(1),
  })
  .register(z.globalRegistry, {
    description: 'LoRA weight configuration.',
  })

/**
 * ImageFile
 */
export const zImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Flux2EditImageLoRAOutput
 */
export const zFlux2LoraEditOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zImageFile).register(z.globalRegistry, {
    description: 'The edited images',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * ImageSize
 */
export const zImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Flux2EditImageInput
 */
export const zFlux2EditInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to edit the image.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use for the image generation.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          'Guidance Scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(2.5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The seed to use for the generation. If not provided, a random seed will be used.',
    }),
  ),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'The URLs of the images for editing. A maximum of 4 images are allowed, if more are provided, only the first 4 will be used.',
  }),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded for better results.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(4).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
})

/**
 * ImageFile
 */
export const zFalAiFlux2EditImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Flux2EditImageOutput
 */
export const zFlux2EditOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFlux2EditImageFile).register(z.globalRegistry, {
    description: 'The edited images',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * ImageSize
 */
export const zFalAiFlux2ProEditImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Flux2ProImageEditInput
 */
export const zFlux2ProEditInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiFlux2ProEditImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for the generation.',
    }),
  ),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description: 'List of URLs of input images for editing',
  }),
})

/**
 * ImageFile
 */
export const zFalAiFlux2ProEditImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Flux2ProEditOutput
 */
export const zFlux2ProEditOutput = z.object({
  images: z.array(zFalAiFlux2ProEditImageFile).register(z.globalRegistry, {
    description: 'The generated images.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the generation.',
  }),
})

/**
 * BaseImageToInput
 */
export const zFluxDevImageToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        'The speed of the generation. The higher the speed, the faster the generation.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to generate an image from.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the initial image. Higher strength values are better for this model.',
      }),
    )
    .default(0.95),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(10).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(40),
})

/**
 * Image
 */
export const zImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxDevImageToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * Input
 */
export const zAuraSrInput = z.object({
  overlapping_tiles: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use overlapping tiles for upscaling. Setting this to true helps remove seams but doubles the inference time.',
      }),
    )
    .default(false),
  checkpoint: z.optional(
    z.enum(['v1', 'v2']).register(z.globalRegistry, {
      description: 'Checkpoint to use for upscaling. More coming soon.',
    }),
  ),
  upscaling_factor: z.optional(
    z.literal(4).register(z.globalRegistry, {
      description: 'Upscaling factor. More coming soon.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to upscale.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiAuraSrImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * Output
 */
export const zAuraSrOutput = z.object({
  image: zFalAiAuraSrImage,
  timings: z.record(z.string(), z.number()).register(z.globalRegistry, {
    description: 'Timings for each step in the pipeline.',
  }),
})

/**
 * Input
 */
export const zClarityUpscalerInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'The prompt to use for generating the image. Be as descriptive as possible for best results.',
      }),
    )
    .default('masterpiece, best quality, highres'),
  resemblance: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The resemblance of the upscaled image to the original image. The higher the resemblance, the more the model will try to keep the original image.\n            Refers to the strength of the ControlNet.\n        ',
      }),
    )
    .default(0.6),
  creativity: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The creativity of the model. The higher the creativity, the more the model will deviate from the prompt.\n            Refers to the denoise strength of the sampling.\n        ',
      }),
    )
    .default(0.35),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to upscale.',
  }),
  upscale_factor: z
    .optional(
      z.number().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The upscale factor',
      }),
    )
    .default(2),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(4),
  num_inference_steps: z
    .optional(
      z.int().gte(4).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(18),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "The negative prompt to use. Use it to address details that you don't want in the image.",
      }),
    )
    .default('(worst quality, low quality, normal quality:2)'),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to false, the safety checker will be disabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiClarityUpscalerImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * Output
 */
export const zClarityUpscalerOutput = z.object({
  image: zFalAiClarityUpscalerImage,
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used to generate the image.',
  }),
  timings: z.record(z.string(), z.number()).register(z.globalRegistry, {
    description: 'The timings of the different steps in the workflow.',
  }),
})

/**
 * FaceSwapInputImage
 *
 * Input schema for image ↔ image face swap
 */
export const zAiFaceSwapFaceswapimageInput = z
  .object({
    source_face_url: z.string().register(z.globalRegistry, {
      description: 'Source face image',
    }),
    target_image_url: z.string().register(z.globalRegistry, {
      description: 'Target image URL',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Input schema for image ↔ image face swap',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zHalfMoonAiAiFaceSwapFaceswapimageImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FaceFusionImageOutput
 *
 * FaceFusion output payload when image content is generated
 */
export const zAiFaceSwapFaceswapimageOutput = z
  .object({
    image: zHalfMoonAiAiFaceSwapFaceswapimageImage,
    processing_time_ms: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'FaceFusion output payload when image content is generated',
  })

/**
 * ReplaceObjectInput
 */
export const zFiboEditReplaceObjectByTextInput = z.object({
  instruction: z.string().register(z.globalRegistry, {
    description:
      'The full natural language command describing what to replace.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The source image.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaFiboEditReplaceObjectByTextImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FiboEditExtraEPOutputModel
 */
export const zFiboEditReplaceObjectByTextOutput = z.object({
  images: z
    .optional(
      z
        .array(zBriaFiboEditReplaceObjectByTextImage)
        .register(z.globalRegistry, {
          description: 'Generated images.',
        }),
    )
    .default([]),
  image: zBriaFiboEditReplaceObjectByTextImage,
  structured_instruction: z
    .record(z.string(), z.unknown())
    .register(z.globalRegistry, {
      description: 'Current instruction.',
    }),
})

/**
 * SketchColoredImageInput
 */
export const zFiboEditSketchToColoredImageInput = z.object({
  image_url: z.string().register(z.globalRegistry, {
    description: 'The source image.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaFiboEditSketchToColoredImageImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FiboEditExtraEPOutputModel
 */
export const zFiboEditSketchToColoredImageOutput = z.object({
  images: z
    .optional(
      z
        .array(zBriaFiboEditSketchToColoredImageImage)
        .register(z.globalRegistry, {
          description: 'Generated images.',
        }),
    )
    .default([]),
  image: zBriaFiboEditSketchToColoredImageImage,
  structured_instruction: z
    .record(z.string(), z.unknown())
    .register(z.globalRegistry, {
      description: 'Current instruction.',
    }),
})

/**
 * RestoreInput
 */
export const zFiboEditRestoreInput = z.object({
  image_url: z.string().register(z.globalRegistry, {
    description: 'The source image.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaFiboEditRestoreImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FiboEditExtraEPOutputModel
 */
export const zFiboEditRestoreOutput = z.object({
  images: z
    .optional(
      z.array(zBriaFiboEditRestoreImage).register(z.globalRegistry, {
        description: 'Generated images.',
      }),
    )
    .default([]),
  image: zBriaFiboEditRestoreImage,
  structured_instruction: z
    .record(z.string(), z.unknown())
    .register(z.globalRegistry, {
      description: 'Current instruction.',
    }),
})

/**
 * ReseasonInput
 */
export const zFiboEditReseasonInput = z.object({
  season: z
    .enum(['spring', 'summer', 'autumn', 'winter'])
    .register(z.globalRegistry, {
      description: 'The desired season.',
    }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The source image.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaFiboEditReseasonImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FiboEditExtraEPOutputModel
 */
export const zFiboEditReseasonOutput = z.object({
  images: z
    .optional(
      z.array(zBriaFiboEditReseasonImage).register(z.globalRegistry, {
        description: 'Generated images.',
      }),
    )
    .default([]),
  image: zBriaFiboEditReseasonImage,
  structured_instruction: z
    .record(z.string(), z.unknown())
    .register(z.globalRegistry, {
      description: 'Current instruction.',
    }),
})

/**
 * RelightInput
 */
export const zFiboEditRelightInput = z.object({
  light_type: z
    .enum([
      'midday',
      'blue hour light',
      'low-angle sunlight',
      'sunrise light',
      'spotlight on subject',
      'overcast light',
      'soft overcast daylight lighting',
      'cloud-filtered lighting',
      'fog-diffused lighting',
      'moonlight lighting',
      'starlight nighttime',
      'soft bokeh lighting',
      'harsh studio lighting',
    ])
    .register(z.globalRegistry, {
      description: 'The quality/style/time of day.',
    }),
  light_direction: z.union([
    z.enum(['front', 'side', 'bottom', 'top-down']),
    z.unknown(),
  ]),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The source image.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaFiboEditRelightImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FiboEditExtraEPOutputModel
 */
export const zFiboEditRelightOutput = z.object({
  images: z
    .optional(
      z.array(zBriaFiboEditRelightImage).register(z.globalRegistry, {
        description: 'Generated images.',
      }),
    )
    .default([]),
  image: zBriaFiboEditRelightImage,
  structured_instruction: z
    .record(z.string(), z.unknown())
    .register(z.globalRegistry, {
      description: 'Current instruction.',
    }),
})

/**
 * RestyletInput
 */
export const zFiboEditRestyleInput = z.object({
  style: z
    .enum([
      '3D Render',
      'Cubism',
      'Oil Painting',
      'Anime',
      'Cartoon',
      'Coloring Book',
      'Retro Ad',
      'Pop Art Halftone',
      'Vector Art',
      'Story Board',
      'Art Nouveau',
      'Cross Etching',
      'Wood Cut',
    ])
    .register(z.globalRegistry, {
      description: 'Select the desired artistic style for the output image.',
    }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The source image.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaFiboEditRestyleImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FiboEditExtraEPOutputModel
 */
export const zFiboEditRestyleOutput = z.object({
  images: z
    .optional(
      z.array(zBriaFiboEditRestyleImage).register(z.globalRegistry, {
        description: 'Generated images.',
      }),
    )
    .default([]),
  image: zBriaFiboEditRestyleImage,
  structured_instruction: z
    .record(z.string(), z.unknown())
    .register(z.globalRegistry, {
      description: 'Current instruction.',
    }),
})

/**
 * RewriteTextInput
 */
export const zFiboEditRewriteTextInput = z.object({
  new_text: z.string().register(z.globalRegistry, {
    description: 'The new text string to appear in the image.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The source image.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaFiboEditRewriteTextImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FiboEditExtraEPOutputModel
 */
export const zFiboEditRewriteTextOutput = z.object({
  images: z
    .optional(
      z.array(zBriaFiboEditRewriteTextImage).register(z.globalRegistry, {
        description: 'Generated images.',
      }),
    )
    .default([]),
  image: zBriaFiboEditRewriteTextImage,
  structured_instruction: z
    .record(z.string(), z.unknown())
    .register(z.globalRegistry, {
      description: 'Current instruction.',
    }),
})

/**
 * EraseByTextInput
 */
export const zFiboEditEraseByTextInput = z.object({
  object_name: z.string().register(z.globalRegistry, {
    description: 'The name of the object to remove.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The source image.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaFiboEditEraseByTextImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FiboEditExtraEPOutputModel
 */
export const zFiboEditEraseByTextOutput = z.object({
  images: z
    .optional(
      z.array(zBriaFiboEditEraseByTextImage).register(z.globalRegistry, {
        description: 'Generated images.',
      }),
    )
    .default([]),
  image: zBriaFiboEditEraseByTextImage,
  structured_instruction: z
    .record(z.string(), z.unknown())
    .register(z.globalRegistry, {
      description: 'Current instruction.',
    }),
})

/**
 * Aesthetics
 */
export const zAesthetics = z.object({
  composition: z.optional(z.union([z.string(), z.unknown()])),
  mood_atmosphere: z.optional(z.union([z.string(), z.unknown()])),
  color_scheme: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * PromptObject
 */
export const zPromptObject = z.object({
  relative_size: z.optional(z.union([z.string(), z.unknown()])),
  description: z.optional(z.union([z.string(), z.unknown()])),
  skin_tone_and_texture: z.optional(z.union([z.string(), z.unknown()])),
  appearance_details: z.optional(z.union([z.string(), z.unknown()])),
  number_of_objects: z.optional(z.union([z.int(), z.unknown()])),
  expression: z.optional(z.union([z.string(), z.unknown()])),
  pose: z.optional(z.union([z.string(), z.unknown()])),
  shape_and_color: z.optional(z.union([z.string(), z.unknown()])),
  relationship: z.string().register(z.globalRegistry, {
    description:
      'The relationship of the object to other objects in the image.',
  }),
  texture: z.optional(z.union([z.string(), z.unknown()])),
  gender: z.optional(z.union([z.string(), z.unknown()])),
  clothing: z.optional(z.union([z.string(), z.unknown()])),
  location: z.optional(z.union([z.string(), z.unknown()])),
  orientation: z.optional(z.union([z.string(), z.unknown()])),
  action: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * PhotographicCharacteristics
 */
export const zPhotographicCharacteristics = z.object({
  focus: z.optional(z.union([z.string(), z.unknown()])),
  lens_focal_length: z.optional(z.union([z.string(), z.unknown()])),
  camera_angle: z.optional(z.union([z.string(), z.unknown()])),
  depth_of_field: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * Lighting
 */
export const zLighting = z.object({
  shadows: z.optional(z.union([z.string(), z.unknown()])),
  conditions: z.optional(z.union([z.string(), z.unknown()])),
  direction: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * StructuredInstruction
 */
export const zStructuredInstruction = z.object({
  background_setting: z.optional(z.union([z.string(), z.unknown()])),
  artistic_style: z.optional(z.union([z.string(), z.unknown()])),
  aesthetics: z.optional(z.union([zAesthetics, z.unknown()])),
  text_render: z.optional(z.union([z.array(z.unknown()), z.unknown()])),
  objects: z.optional(z.union([z.array(zPromptObject), z.unknown()])),
  context: z.optional(z.union([z.string(), z.unknown()])),
  photographic_characteristics: z.optional(
    z.union([zPhotographicCharacteristics, z.unknown()]),
  ),
  style_medium: z.optional(z.union([z.string(), z.unknown()])),
  lighting: z.optional(z.union([zLighting, z.unknown()])),
  short_description: z.optional(z.union([z.string(), z.unknown()])),
  edit_instruction: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * FiboEditInputModel
 */
export const zFiboEditEditInput = z.object({
  steps_num: z
    .optional(
      z.int().gte(20).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps.',
      }),
    )
    .default(50),
  instruction: z.optional(z.union([z.string(), z.unknown()])),
  image_url: z.optional(z.union([z.string(), z.unknown()])),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, returns the image directly in the response (increases latency).',
      }),
    )
    .default(false),
  guidance_scale: z.optional(z.union([z.number(), z.int()])),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Random seed for reproducibility.',
      }),
    )
    .default(5555),
  mask_url: z.optional(z.union([z.string(), z.unknown()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for image generation.',
      }),
    )
    .default(''),
  structured_instruction: z.optional(
    z.union([zStructuredInstruction, z.unknown()]),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaFiboEditEditImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FiboEditOutputModel
 */
export const zFiboEditEditOutput = z.object({
  images: z
    .optional(
      z.array(zBriaFiboEditEditImage).register(z.globalRegistry, {
        description: 'Generated images.',
      }),
    )
    .default([]),
  image: zBriaFiboEditEditImage,
  structured_instruction: z
    .record(z.string(), z.unknown())
    .register(z.globalRegistry, {
      description: 'Current instruction.',
    }),
})

/**
 * AddObjectByTextInput
 */
export const zFiboEditAddObjectByTextInput = z.object({
  instruction: z.string().register(z.globalRegistry, {
    description:
      'The full natural language command describing what to add and where.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The source image.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaFiboEditAddObjectByTextImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FiboEditExtraEPOutputModel
 */
export const zFiboEditAddObjectByTextOutput = z.object({
  images: z
    .optional(
      z.array(zBriaFiboEditAddObjectByTextImage).register(z.globalRegistry, {
        description: 'Generated images.',
      }),
    )
    .default([]),
  image: zBriaFiboEditAddObjectByTextImage,
  structured_instruction: z
    .record(z.string(), z.unknown())
    .register(z.globalRegistry, {
      description: 'Current instruction.',
    }),
})

/**
 * BlendingInput
 */
export const zFiboEditBlendInput = z.object({
  instruction: z.string().register(z.globalRegistry, {
    description:
      'Instruct what elements you would like to blend in your image.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The source image.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaFiboEditBlendImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FiboEditExtraEPOutputModel
 */
export const zFiboEditBlendOutput = z.object({
  images: z
    .optional(
      z.array(zBriaFiboEditBlendImage).register(z.globalRegistry, {
        description: 'Generated images.',
      }),
    )
    .default([]),
  image: zBriaFiboEditBlendImage,
  structured_instruction: z
    .record(z.string(), z.unknown())
    .register(z.globalRegistry, {
      description: 'Current instruction.',
    }),
})

/**
 * ColorizeInput
 */
export const zFiboEditColorizeInput = z.object({
  color: z
    .enum([
      'contemporary color',
      'vivid color',
      'black and white colors',
      'sepia vintage',
    ])
    .register(z.globalRegistry, {
      description: 'Select the color palette or aesthetic for the output image',
    }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The source image.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaFiboEditColorizeImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FiboEditExtraEPOutputModel
 */
export const zFiboEditColorizeOutput = z.object({
  images: z
    .optional(
      z.array(zBriaFiboEditColorizeImage).register(z.globalRegistry, {
        description: 'Generated images.',
      }),
    )
    .default([]),
  image: zBriaFiboEditColorizeImage,
  structured_instruction: z
    .record(z.string(), z.unknown())
    .register(z.globalRegistry, {
      description: 'Current instruction.',
    }),
})

/**
 * LoRAInput
 */
export const zFalAiFlux2KleinLoRaInput = z.object({
  path: z.string().register(z.globalRegistry, {
    description:
      'URL, HuggingFace repo ID (owner/repo), or local path to LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description: 'Scale factor for LoRA application (0.0 to 4.0).',
      }),
    )
    .default(1),
})

/**
 * ImageFile
 */
export const zFalAiFlux2Klein9bBaseEditLoraImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * KleinT2IOutput
 */
export const zFlux2Klein9bBaseEditLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFlux2Klein9bBaseEditLoraImageFile)
    .register(z.globalRegistry, {
      description: 'The generated images',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * LoRAInput
 */
export const zFalAiFlux2Klein4bBaseEditLoraFalAiFlux2KleinLoRaInput = z.object({
  path: z.string().register(z.globalRegistry, {
    description:
      'URL, HuggingFace repo ID (owner/repo), or local path to LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description: 'Scale factor for LoRA application (0.0 to 4.0).',
      }),
    )
    .default(1),
})

/**
 * ImageFile
 */
export const zFalAiFlux2Klein4bBaseEditLoraImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * KleinT2IOutput
 */
export const zFlux2Klein4bBaseEditLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFlux2Klein4bBaseEditLoraImageFile)
    .register(z.globalRegistry, {
      description: 'The generated images',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux2Klein4bBaseEditImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Klein4BBaseEditInput
 */
export const zFlux2Klein4bBaseEditInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to edit the image.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFlux2Klein4bBaseEditImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use for image generation.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description: 'Guidance scale for classifier-free guidance.',
      }),
    )
    .default(5),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If `True`, the media will be returned as a data URI. Output is not stored when this is True.',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(4).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'The URLs of the images for editing. A maximum of 4 images are allowed.',
  }),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Negative prompt for classifier-free guidance. Describes what to avoid in the image.',
      }),
    )
    .default(''),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The seed to use for the generation. If not provided, a random seed will be used.',
    }),
  ),
})

/**
 * ImageFile
 */
export const zFalAiFlux2Klein4bBaseEditImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Klein4BBaseEditOutput
 */
export const zFlux2Klein4bBaseEditOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFlux2Klein4bBaseEditImageFile)
    .register(z.globalRegistry, {
      description: 'The edited images',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux2Klein9bBaseEditImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Klein9BEditImageInput
 */
export const zFlux2Klein9bBaseEditInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to edit the image.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFlux2Klein9bBaseEditImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use for image generation.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description: 'Guidance scale for classifier-free guidance.',
      }),
    )
    .default(5),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If `True`, the media will be returned as a data URI. Output is not stored when this is True.',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(4).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'The URLs of the images for editing. A maximum of 4 images are allowed.',
  }),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Negative prompt for classifier-free guidance. Describes what to avoid in the image.',
      }),
    )
    .default(''),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The seed to use for the generation. If not provided, a random seed will be used.',
    }),
  ),
})

/**
 * ImageFile
 */
export const zFalAiFlux2Klein9bBaseEditImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Klein9BBaseEditOutput
 */
export const zFlux2Klein9bBaseEditOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFlux2Klein9bBaseEditImageFile)
    .register(z.globalRegistry, {
      description: 'The edited images',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux2Klein4bEditImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * KleinDistilledEditInput
 */
export const zFlux2Klein4bEditInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to edit the image.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFlux2Klein4bEditImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If `True`, the media will be returned as a data URI. Output is not stored when this is True.',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(4).lte(8).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(4),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'The URLs of the images for editing. A maximum of 4 images are allowed.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The seed to use for the generation. If not provided, a random seed will be used.',
    }),
  ),
})

/**
 * ImageFile
 */
export const zFalAiFlux2Klein4bEditImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Klein4BDistilledEditOutput
 */
export const zFlux2Klein4bEditOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFlux2Klein4bEditImageFile).register(z.globalRegistry, {
    description: 'The edited images',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux2Klein9bEditImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Klein9BDistilledEditInput
 */
export const zFlux2Klein9bEditInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to edit the image.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFlux2Klein9bEditImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If `True`, the media will be returned as a data URI. Output is not stored when this is True.',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(4).lte(8).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(4),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'The URLs of the images for editing. A maximum of 4 images are allowed.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The seed to use for the generation. If not provided, a random seed will be used.',
    }),
  ),
})

/**
 * ImageFile
 */
export const zFalAiFlux2Klein9bEditImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Klein9BDistilledEditOutput
 */
export const zFlux2Klein9bEditOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFlux2Klein9bEditImageFile).register(z.globalRegistry, {
    description: 'The edited images',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiGlmImageImageToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * GlmImageToImageInput
 */
export const zGlmImageImageToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt for image generation.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'Number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiGlmImageImageToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
        'portrait_3_2',
        'landscape_3_2',
        'portrait_hd',
        'landscape_hd',
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable NSFW safety checking on the generated images.',
      }),
    )
    .default(true),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'Output image format.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If True, the image will be returned as a base64 data URI instead of a URL.',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values make the model follow the prompt more closely.',
      }),
    )
    .default(1.5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. The same seed with the same prompt will produce the same image.',
    }),
  ),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'URL(s) of the condition image(s) for image-to-image generation. Supports up to 4 URLs for multi-image references.',
  }),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If True, the prompt will be enhanced using an LLM for more detailed and higher quality results.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(10).lte(100).register(z.globalRegistry, {
        description:
          'Number of diffusion denoising steps. More steps generally produce higher quality images.',
      }),
    )
    .default(30),
})

/**
 * Image
 */
export const zFalAiGlmImageImageToImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * GlmImageToImageOutput
 */
export const zGlmImageImageToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiGlmImageImageToImageImage).register(z.globalRegistry, {
    description: 'List of URLs to the generated images.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2511MultipleAnglesImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * MultipleAnglesInput
 *
 * Input model for Multiple Angles endpoint - Camera control with precise adjustments using <sks> trigger word.
 * Prompt is built automatically from slider values.
 */
export const zQwenImageEdit2511MultipleAnglesInput = z
  .object({
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description: 'Acceleration level for image generation.',
      }),
    ),
    image_size: z.optional(
      z.union([
        zFalAiQwenImageEdit2511MultipleAnglesImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
      ]),
    ),
    horizontal_angle: z
      .optional(
        z.number().gte(0).lte(360).register(z.globalRegistry, {
          description:
            'Horizontal rotation angle around the object in degrees. 0°=front view, 90°=right side, 180°=back view, 270°=left side, 360°=front view again.',
        }),
      )
      .default(0),
    guidance_scale: z
      .optional(
        z.number().gte(1).lte(20).register(z.globalRegistry, {
          description: 'The CFG (Classifier Free Guidance) scale.',
        }),
      )
      .default(4.5),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable the safety checker.',
        }),
      )
      .default(true),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description: 'The URL of the image to adjust camera angle for.',
    }),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt for the generation',
        }),
      )
      .default(''),
    zoom: z
      .optional(
        z.number().gte(0).lte(10).register(z.globalRegistry, {
          description:
            'Camera zoom/distance. 0=wide shot (far away), 5=medium shot (normal), 10=close-up (very close).',
        }),
      )
      .default(5),
    vertical_angle: z
      .optional(
        z.number().gte(-30).lte(90).register(z.globalRegistry, {
          description:
            "Vertical camera angle in degrees. -30°=low-angle shot (looking up), 0°=eye-level, 30°=elevated, 60°=high-angle, 90°=bird's-eye view (looking down).",
        }),
      )
      .default(0),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'The scale factor for the LoRA model. Controls the strength of the camera control effect.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    additional_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'Additional text to append to the automatically generated prompt.',
      }),
    ),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'If `True`, the media will be returned as a data URI.',
        }),
      )
      .default(false),
    num_inference_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(28),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'Random seed for reproducibility.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Multiple Angles endpoint - Camera control with precise adjustments using <sks> trigger word.\nPrompt is built automatically from slider values.',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEdit2511MultipleAnglesImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * MultipleAnglesOutput
 *
 * Output model for Multiple Angles endpoint
 */
export const zQwenImageEdit2511MultipleAnglesOutput = z
  .object({
    prompt: z.string().register(z.globalRegistry, {
      description: 'The constructed prompt used for generation',
    }),
    images: z
      .array(zFalAiQwenImageEdit2511MultipleAnglesImage)
      .register(z.globalRegistry, {
        description: 'The generated/edited images',
      }),
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed used for generation',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Output model for Multiple Angles endpoint',
  })

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2511LoraImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * EditImageLoraInput
 */
export const zQwenImageEdit2511LoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to edit the image with.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiQwenImageEdit2511LoraImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If `True`, the media will be returned as a data URI.',
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zLoraWeight).register(z.globalRegistry, {
        description:
          'The LoRAs to use for the image generation. You can use up to 3 LoRAs and they will be merged together to generate the final image.',
      }),
    )
    .default([]),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description: 'The guidance scale to use for the image generation.',
      }),
    )
    .default(4.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description: 'The URLs of the images to edit.',
  }),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate an image from.',
      }),
    )
    .default(''),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The same seed and the same prompt given to the same version of the model will output the same image every time.',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiQwenImageEdit2511LoraImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * ImageToImageOutput
 */
export const zQwenImageEdit2511LoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiQwenImageEdit2511LoraImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ArchStyleInput
 */
export const zAiHomeStyleInput = z.object({
  input_image_url: z.string().max(512).register(z.globalRegistry, {
    description: 'URL of the image to do architectural styling',
  }),
  input_image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Strength of the input image',
      }),
    )
    .default(0.85),
  additional_elements: z.optional(z.union([z.string().max(200), z.unknown()])),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description:
        "The format of the generated image. Choose from: 'jpeg' or 'png'.",
    }),
  ),
  style: z
    .enum([
      'minimalistic-interior',
      'farmhouse-interior',
      'luxury-interior',
      'modern-interior',
      'zen-interior',
      'mid century-interior',
      'airbnb-interior',
      'cozy-interior',
      'rustic-interior',
      'christmas-interior',
      'bohemian-interior',
      'tropical-interior',
      'industrial-interior',
      'japanese-interior',
      'vintage-interior',
      'loft-interior',
      'halloween-interior',
      'soho-interior',
      'baroque-interior',
      'kids room-interior',
      'girls room-interior',
      'boys room-interior',
      'scandinavian-interior',
      'french country-interior',
      'mediterranean-interior',
      'cyberpunk-interior',
      'hot pink-interior',
      'biophilic-interior',
      'ancient egypt-interior',
      'pixel-interior',
      'art deco-interior',
      'modern-exterior',
      'minimalistic-exterior',
      'farmhouse-exterior',
      'cozy-exterior',
      'luxury-exterior',
      'colonial-exterior',
      'zen-exterior',
      'asian-exterior',
      'creepy-exterior',
      'airstone-exterior',
      'ancient greek-exterior',
      'art deco-exterior',
      'brutalist-exterior',
      'christmas lights-exterior',
      'contemporary-exterior',
      'cottage-exterior',
      'dutch colonial-exterior',
      'federal colonial-exterior',
      'fire-exterior',
      'french provincial-exterior',
      'full glass-exterior',
      'georgian colonial-exterior',
      'gothic-exterior',
      'greek revival-exterior',
      'ice-exterior',
      'italianate-exterior',
      'mediterranean-exterior',
      'midcentury-exterior',
      'middle eastern-exterior',
      'minecraft-exterior',
      'morocco-exterior',
      'neoclassical-exterior',
      'spanish-exterior',
      'tudor-exterior',
      'underwater-exterior',
      'winter-exterior',
      'yard lighting-exterior',
    ])
    .register(z.globalRegistry, {
      description: 'Style for furniture and decor',
    }),
  architecture_type: z
    .enum([
      'living room-interior',
      'bedroom-interior',
      'kitchen-interior',
      'dining room-interior',
      'bathroom-interior',
      'laundry room-interior',
      'home office-interior',
      'study room-interior',
      'dorm room-interior',
      'coffee shop-interior',
      'gaming room-interior',
      'restaurant-interior',
      'office-interior',
      'attic-interior',
      'toilet-interior',
      'other-interior',
      'house-exterior',
      'villa-exterior',
      'backyard-exterior',
      'courtyard-exterior',
      'ranch-exterior',
      'office-exterior',
      'retail-exterior',
      'tower-exterior',
      'apartment-exterior',
      'school-exterior',
      'museum-exterior',
      'commercial-exterior',
      'residential-exterior',
      'other-exterior',
    ])
    .register(z.globalRegistry, {
      description: 'Type of architecture for appropriate furniture selection',
    }),
  color_palette: z
    .enum([
      'surprise me',
      'golden beige',
      'refined blues',
      'dusky elegance',
      'emerald charm',
      'crimson luxury',
      'golden sapphire',
      'soft pastures',
      'candy sky',
      'peach meadow',
      'muted sands',
      'ocean breeze',
      'frosted pastels',
      'spring bloom',
      'gentle horizon',
      'seaside breeze',
      'azure coast',
      'golden shore',
      'mediterranean gem',
      'ocean serenity',
      'serene blush',
      'muted horizon',
      'pastel shores',
      'dusky calm',
      'woodland retreat',
      'meadow glow',
      'forest canopy',
      'riverbank calm',
      'earthy tones',
      'earthy neutrals',
      'arctic mist',
      'aqua drift',
      'blush bloom',
      'coral haze',
      'retro rust',
      'autumn glow',
      'rustic charm',
      'vintage sage',
      'faded plum',
      'electric lime',
      'violet pulse',
      'neon sorbet',
      'aqua glow',
      'fluorescent sunset',
      'lavender bloom',
      'petal fresh',
      'meadow light',
      'sunny pastures',
      'frosted mauve',
      'snowy hearth',
      'icy blues',
      'winter twilight',
      'earthy hues',
      'stone balance',
      'neutral sands',
      'slate shades',
    ])
    .register(z.globalRegistry, {
      description: 'Color palette for furniture and decor',
    }),
  style_image_url: z.optional(z.union([z.string().max(512), z.unknown()])),
  custom_prompt: z
    .optional(
      z.string().max(300).register(z.globalRegistry, {
        description:
          'Custom prompt for architectural editing, it overrides above options when used',
      }),
    )
    .default(''),
  enhanced_rendering: z.optional(z.union([z.boolean(), z.unknown()])),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zHalfMoonAiAiHomeStyleImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ArchStyleOutput
 */
export const zAiHomeStyleOutput = z.object({
  image: zHalfMoonAiAiHomeStyleImage,
  status: z.string().register(z.globalRegistry, {
    description: 'Status message with processing details',
  }),
})

/**
 * ArchEditInput
 */
export const zAiHomeEditInput = z.object({
  input_image_url: z.string().max(512).register(z.globalRegistry, {
    description: 'URL of the image to do architectural editing',
  }),
  editing_type: z
    .enum(['structural editing', 'virtual staging', 'both'])
    .register(z.globalRegistry, {
      description:
        'Type of editing. Structural editing only edits structural elements such as windows, walls etc. Virtual staging edits your furniture. Both do full editing including structural and furniture',
    }),
  style: z
    .enum([
      'minimalistic-interior',
      'farmhouse-interior',
      'luxury-interior',
      'modern-interior',
      'zen-interior',
      'mid century-interior',
      'airbnb-interior',
      'cozy-interior',
      'rustic-interior',
      'christmas-interior',
      'bohemian-interior',
      'tropical-interior',
      'industrial-interior',
      'japanese-interior',
      'vintage-interior',
      'loft-interior',
      'halloween-interior',
      'soho-interior',
      'baroque-interior',
      'kids room-interior',
      'girls room-interior',
      'boys room-interior',
      'scandinavian-interior',
      'french country-interior',
      'mediterranean-interior',
      'cyberpunk-interior',
      'hot pink-interior',
      'biophilic-interior',
      'ancient egypt-interior',
      'pixel-interior',
      'art deco-interior',
      'modern-exterior',
      'minimalistic-exterior',
      'farmhouse-exterior',
      'cozy-exterior',
      'luxury-exterior',
      'colonial-exterior',
      'zen-exterior',
      'asian-exterior',
      'creepy-exterior',
      'airstone-exterior',
      'ancient greek-exterior',
      'art deco-exterior',
      'brutalist-exterior',
      'christmas lights-exterior',
      'contemporary-exterior',
      'cottage-exterior',
      'dutch colonial-exterior',
      'federal colonial-exterior',
      'fire-exterior',
      'french provincial-exterior',
      'full glass-exterior',
      'georgian colonial-exterior',
      'gothic-exterior',
      'greek revival-exterior',
      'ice-exterior',
      'italianate-exterior',
      'mediterranean-exterior',
      'midcentury-exterior',
      'middle eastern-exterior',
      'minecraft-exterior',
      'morocco-exterior',
      'neoclassical-exterior',
      'spanish-exterior',
      'tudor-exterior',
      'underwater-exterior',
      'winter-exterior',
      'yard lighting-exterior',
    ])
    .register(z.globalRegistry, {
      description: 'Style for furniture and decor',
    }),
  additional_elements: z.optional(z.union([z.string().max(200), z.unknown()])),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description:
        "The format of the generated image. Choose from: 'jpeg' or 'png'.",
    }),
  ),
  architecture_type: z
    .enum([
      'living room-interior',
      'bedroom-interior',
      'kitchen-interior',
      'dining room-interior',
      'bathroom-interior',
      'laundry room-interior',
      'home office-interior',
      'study room-interior',
      'dorm room-interior',
      'coffee shop-interior',
      'gaming room-interior',
      'restaurant-interior',
      'office-interior',
      'attic-interior',
      'toilet-interior',
      'other-interior',
      'house-exterior',
      'villa-exterior',
      'backyard-exterior',
      'courtyard-exterior',
      'ranch-exterior',
      'office-exterior',
      'retail-exterior',
      'tower-exterior',
      'apartment-exterior',
      'school-exterior',
      'museum-exterior',
      'commercial-exterior',
      'residential-exterior',
      'other-exterior',
    ])
    .register(z.globalRegistry, {
      description: 'Type of architecture for appropriate furniture selection',
    }),
  color_palette: z
    .enum([
      'surprise me',
      'golden beige',
      'refined blues',
      'dusky elegance',
      'emerald charm',
      'crimson luxury',
      'golden sapphire',
      'soft pastures',
      'candy sky',
      'peach meadow',
      'muted sands',
      'ocean breeze',
      'frosted pastels',
      'spring bloom',
      'gentle horizon',
      'seaside breeze',
      'azure coast',
      'golden shore',
      'mediterranean gem',
      'ocean serenity',
      'serene blush',
      'muted horizon',
      'pastel shores',
      'dusky calm',
      'woodland retreat',
      'meadow glow',
      'forest canopy',
      'riverbank calm',
      'earthy tones',
      'earthy neutrals',
      'arctic mist',
      'aqua drift',
      'blush bloom',
      'coral haze',
      'retro rust',
      'autumn glow',
      'rustic charm',
      'vintage sage',
      'faded plum',
      'electric lime',
      'violet pulse',
      'neon sorbet',
      'aqua glow',
      'fluorescent sunset',
      'lavender bloom',
      'petal fresh',
      'meadow light',
      'sunny pastures',
      'frosted mauve',
      'snowy hearth',
      'icy blues',
      'winter twilight',
      'earthy hues',
      'stone balance',
      'neutral sands',
      'slate shades',
    ])
    .register(z.globalRegistry, {
      description: 'Color palette for furniture and decor',
    }),
  custom_prompt: z
    .optional(
      z.string().max(300).register(z.globalRegistry, {
        description:
          'Custom prompt for architectural editing, it overrides above options when used',
      }),
    )
    .default(''),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zHalfMoonAiAiHomeEditImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ArchEditOutput
 */
export const zAiHomeEditOutput = z.object({
  image: zHalfMoonAiAiHomeEditImage,
  status: z.string().register(z.globalRegistry, {
    description: 'Status message with processing details',
  }),
})

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export const zFalAiQwenImageLayeredLoraLoRaInput = z
  .object({
    path: z.string().register(z.globalRegistry, {
      description: 'URL, HuggingFace repo ID (owner/repo) to lora weights.',
    }),
    scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description: 'Scale factor for LoRA application (0.0 to 4.0).',
        }),
      )
      .default(1),
  })
  .register(z.globalRegistry, {
    description: 'LoRA weight configuration.',
  })

/**
 * ImageFile
 */
export const zFalAiQwenImageLayeredLoraImageFile = z.object({
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * QwenImageLayeredOutput
 */
export const zQwenImageLayeredLoraOutput = z.object({
  prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The prompt used to generate the image.',
    }),
  ),
  images: z
    .array(zFalAiQwenImageLayeredLoraImageFile)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zWanV26ImageToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * ImageEditInput
 *
 * Input for Wan 2.6 image editing with reference images (enable_interleave=false)
 */
export const zV26ImageToImageInput = z
  .object({
    prompt: z.string().min(1).register(z.globalRegistry, {
      description:
        "Text prompt describing the desired image. Supports Chinese and English. Max 2000 characters. Example: 'Generate an image using the style of image 1 and background of image 2'.",
    }),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description:
            'Number of images to generate (1-4). Directly affects billing cost.',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zWanV26ImageToImageImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
      ]),
    ),
    enable_prompt_expansion: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Enable LLM prompt optimization. Significantly improves results for simple prompts but adds 3-4 seconds processing time.',
        }),
      )
      .default(true),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility (0-2147483647). Same seed produces more consistent results.',
      }),
    ),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description:
        "Reference images for editing (1-3 images required). Order matters: reference as 'image 1', 'image 2', 'image 3' in prompt. Resolution: 384-5000px each dimension. Max size: 10MB each. Formats: JPEG, JPG, PNG (no alpha), BMP, WEBP.",
    }),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            'Content to avoid in the generated image. Max 500 characters.',
        }),
      )
      .default(''),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Enable content moderation for input and output.',
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description:
      'Input for Wan 2.6 image editing with reference images (enable_interleave=false)',
  })

/**
 * File
 */
export const zWanV26ImageToImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ImageEditOutput
 *
 * Output for Wan 2.6 image editing
 */
export const zV26ImageToImageOutput = z
  .object({
    images: z.array(zWanV26ImageToImageFile).register(z.globalRegistry, {
      description: 'Generated images in PNG format',
    }),
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed used for generation',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Output for Wan 2.6 image editing',
  })

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2511ImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * EditImageInput
 */
export const zQwenImageEdit2511Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to edit the image with.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiQwenImageEdit2511ImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If `True`, the media will be returned as a data URI.',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description: 'The guidance scale to use for the image generation.',
      }),
    )
    .default(4.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description: 'The URLs of the images to edit.',
  }),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate an image from.',
      }),
    )
    .default(''),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The same seed and the same prompt given to the same version of the model will output the same image every time.',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiQwenImageEdit2511Image = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * ImageToImageOutput
 */
export const zQwenImageEdit2511Output = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiQwenImageEdit2511Image).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * TextToImageInput
 */
export const zQwenImageLayeredInput = z.object({
  prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'A caption for the input image.',
    }),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  num_layers: z
    .optional(
      z.int().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The number of layers to generate.',
      }),
    )
    .default(4),
  output_format: z.optional(
    z.enum(['png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the input image.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description: 'The guidance scale to use for the image generation.',
      }),
    )
    .default(5),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate an image from.',
      }),
    )
    .default(''),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * ImageFile
 */
export const zFalAiQwenImageLayeredImageFile = z.object({
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * QwenImageLayeredOutput
 */
export const zQwenImageLayeredOutput = z.object({
  prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The prompt used to generate the image.',
    }),
  ),
  images: z.array(zFalAiQwenImageLayeredImageFile).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export const zFalAiZImageTurboInpaintLoraLoRaInput = z
  .object({
    path: z.string().register(z.globalRegistry, {
      description: 'URL, HuggingFace repo ID (owner/repo) to lora weights.',
    }),
    scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description: 'Scale factor for LoRA application (0.0 to 4.0).',
        }),
      )
      .default(1),
  })
  .register(z.globalRegistry, {
    description: 'LoRA weight configuration.',
  })

/**
 * ImageFile
 */
export const zFalAiZImageTurboInpaintLoraImageFile = z.object({
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ZImageTurboInpaintOutput
 */
export const zZImageTurboInpaintLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiZImageTurboInpaintLoraImageFile)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()).register(z.globalRegistry, {
    description: 'The timings of the generation process.',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      'Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.',
  }),
})

/**
 * ImageSize
 */
export const zFalAiZImageTurboInpaintImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * ZImageTurboInpaintInput
 */
export const zZImageTurboInpaintInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiZImageTurboInpaintImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
        'auto',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  mask_image_url: z.string().register(z.globalRegistry, {
    description: 'URL of Mask for Inpaint generation.',
  }),
  control_end: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The end of the controlnet conditioning.',
      }),
    )
    .default(0.8),
  control_start: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The start of the controlnet conditioning.',
      }),
    )
    .default(0),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of Image for Inpaint generation.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The strength of the inpaint conditioning.',
      }),
    )
    .default(1),
  control_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The scale of the controlnet conditioning.',
      }),
    )
    .default(0.75),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. Note: this will increase the price by 0.0025 credits per request.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(8),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The same seed and the same prompt given to the same version of the model will output the same image every time.',
    }),
  ),
})

/**
 * ImageFile
 */
export const zFalAiZImageTurboInpaintImageFile = z.object({
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ZImageTurboInpaintOutput
 */
export const zZImageTurboInpaintOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiZImageTurboInpaintImageFile)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()).register(z.globalRegistry, {
    description: 'The timings of the generation process.',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      'Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux2FlashEditImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Flux2FlashEditImageInput
 */
export const zFlux2FlashEditInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to edit the image.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFlux2FlashEditImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          'Guidance Scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(2.5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The seed to use for the generation. If not provided, a random seed will be used.',
    }),
  ),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'The URLs of the images for editing. A maximum of 4 images are allowed, if more are provided, only the first 4 will be used.',
  }),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded for better results.',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * ImageFile
 */
export const zFalAiFlux2FlashEditImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Flux2FlashEditImageOutput
 */
export const zFlux2FlashEditOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFlux2FlashEditImageFile).register(z.globalRegistry, {
    description: 'The edited images',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * EditImageRequest
 */
export const zGptImage15EditInput = z.object({
  input_fidelity: z.optional(
    z.enum(['low', 'high']).register(z.globalRegistry, {
      description: 'Input fidelity for the generated image',
    }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'Number of images to generate',
      }),
    )
    .default(1),
  image_size: z.optional(
    z
      .enum(['auto', '1024x1024', '1536x1024', '1024x1536'])
      .register(z.globalRegistry, {
        description: 'Aspect ratio for the generated image',
      }),
  ),
  prompt: z.string().min(2).register(z.globalRegistry, {
    description: 'The prompt for image generation',
  }),
  quality: z.optional(
    z.enum(['low', 'medium', 'high']).register(z.globalRegistry, {
      description: 'Quality for the generated image',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'Output format for the images',
    }),
  ),
  background: z.optional(
    z.enum(['auto', 'transparent', 'opaque']).register(z.globalRegistry, {
      description: 'Background for the generated image',
    }),
  ),
  mask_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The URL of the mask image to use for the generation. This indicates what part of the image to edit.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'The URLs of the images to use as a reference for the generation.',
  }),
})

/**
 * ImageFile
 */
export const zFalAiGptImage15EditImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * EditImageResponse
 */
export const zGptImage15EditOutput = z.object({
  images: z.array(zFalAiGptImage15EditImageFile).register(z.globalRegistry, {
    description: 'The generated images.',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux2TurboEditImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Flux2TurboEditImageInput
 */
export const zFlux2TurboEditInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to edit the image.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFlux2TurboEditImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          'Guidance Scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(2.5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The seed to use for the generation. If not provided, a random seed will be used.',
    }),
  ),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'The URLs of the images for editing. A maximum of 4 images are allowed, if more are provided, only the first 4 will be used.',
  }),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded for better results.',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * ImageFile
 */
export const zFalAiFlux2TurboEditImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Flux2TurboEditImageOutput
 */
export const zFlux2TurboEditOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFlux2TurboEditImageFile).register(z.globalRegistry, {
    description: 'The edited images',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * ImageSize
 */
export const zFalAiFlux2MaxEditImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Flux2MaxImageEditInput
 */
export const zFlux2MaxEditInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiFlux2MaxEditImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for the generation.',
    }),
  ),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description: 'List of URLs of input images for editing',
  }),
})

/**
 * ImageFile
 */
export const zFalAiFlux2MaxEditImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Flux2MaxEditOutput
 */
export const zFlux2MaxEditOutput = z.object({
  images: z.array(zFalAiFlux2MaxEditImageFile).register(z.globalRegistry, {
    description: 'The generated images.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the generation.',
  }),
})

/**
 * ImageSize
 */
export const zHalfMoonAiAiBabyAndAgingGeneratorMultiImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * MultiFluxIDInput
 *
 * Input schema for multi mode generation
 */
export const zAiBabyAndAgingGeneratorMultiInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'Text prompt to guide the image generation',
        }),
      )
      .default('a newborn baby, well dressed'),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zHalfMoonAiAiBabyAndAgingGeneratorMultiImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
      ]),
    ),
    father_weight: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            "Weight of the father's influence in multi mode generation",
        }),
      )
      .default(0.5),
    mother_image_urls: z.array(z.string()).min(1).register(z.globalRegistry, {
      description: 'List of mother images for multi mode',
    }),
    output_format: z.optional(
      z.enum(['jpeg', 'png']).register(z.globalRegistry, {
        description:
          "The format of the generated image. Choose from: 'jpeg' or 'png'.",
      }),
    ),
    age_group: z
      .enum([
        'baby',
        'toddler',
        'preschool',
        'gradeschooler',
        'teen',
        'adult',
        'mid',
        'senior',
      ])
      .register(z.globalRegistry, {
        description:
          "Age group for the generated image. Choose from: 'baby' (0-12 months), 'toddler' (1-3 years), 'preschool' (3-5 years), 'gradeschooler' (6-12 years), 'teen' (13-19 years), 'adult' (20-40 years), 'mid' (40-60 years), 'senior' (60+ years).",
      }),
    gender: z.enum(['male', 'female']).register(z.globalRegistry, {
      description:
        "Gender for the generated image. Choose from: 'male' or 'female'.",
    }),
    father_image_urls: z.array(z.string()).min(1).register(z.globalRegistry, {
      description: 'List of father images for multi mode',
    }),
    seed: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Input schema for multi mode generation',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zHalfMoonAiAiBabyAndAgingGeneratorMultiImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FluxMultiIDOutput
 */
export const zAiBabyAndAgingGeneratorMultiOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The final prompt used for generation',
  }),
  images: z
    .array(zHalfMoonAiAiBabyAndAgingGeneratorMultiImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zHalfMoonAiAiBabyAndAgingGeneratorSingleImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * SingleFluxIDInput
 *
 * Input schema for single mode generation
 */
export const zAiBabyAndAgingGeneratorSingleInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'Text prompt to guide the image generation',
        }),
      )
      .default('a newborn baby, well dressed'),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zHalfMoonAiAiBabyAndAgingGeneratorSingleImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
      ]),
    ),
    id_image_urls: z.array(z.string()).min(1).register(z.globalRegistry, {
      description:
        'List of ID images for single mode (or general reference images)',
    }),
    output_format: z.optional(
      z.enum(['jpeg', 'png']).register(z.globalRegistry, {
        description:
          "The format of the generated image. Choose from: 'jpeg' or 'png'.",
      }),
    ),
    age_group: z
      .enum([
        'baby',
        'toddler',
        'preschool',
        'gradeschooler',
        'teen',
        'adult',
        'mid',
        'senior',
      ])
      .register(z.globalRegistry, {
        description:
          "Age group for the generated image. Choose from: 'baby' (0-12 months), 'toddler' (1-3 years), 'preschool' (3-5 years), 'gradeschooler' (6-12 years), 'teen' (13-19 years), 'adult' (20-40 years), 'mid' (40-60 years), 'senior' (60+ years).",
      }),
    gender: z.enum(['male', 'female']).register(z.globalRegistry, {
      description:
        "Gender for the generated image. Choose from: 'male' or 'female'.",
    }),
    seed: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Input schema for single mode generation',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zHalfMoonAiAiBabyAndAgingGeneratorSingleImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FluxSingleIDOutput
 */
export const zAiBabyAndAgingGeneratorSingleOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The final prompt used for generation',
  }),
  images: z
    .array(zHalfMoonAiAiBabyAndAgingGeneratorSingleImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2509LoraGalleryShirtDesignImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * ShirtDesignInput
 *
 * Input model for Shirt Design endpoint - Put designs/graphics on people's shirts
 */
export const zQwenImageEdit2509LoraGalleryShirtDesignInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            "Describe what design to put on the shirt. The model will apply the design from your input image onto the person's shirt.",
        }),
      )
      .default('Put this design on their shirt'),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiQwenImageEdit2509LoraGalleryShirtDesignImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
        z.unknown(),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'The scale factor for the LoRA model. Controls the strength of the LoRA effect.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(1),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description:
        'The URLs of the images: first image is the person wearing a shirt, second image is the design/logo to put on the shirt.',
    }),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt for the generation',
        }),
      )
      .default(' '),
    num_inference_steps: z
      .optional(
        z.int().gte(2).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(6),
  })
  .register(z.globalRegistry, {
    description:
      "Input model for Shirt Design endpoint - Put designs/graphics on people's shirts",
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEdit2509LoraGalleryShirtDesignImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ShirtDesignOutput
 */
export const zQwenImageEdit2509LoraGalleryShirtDesignOutput = z.object({
  images: z
    .array(zFalAiQwenImageEdit2509LoraGalleryShirtDesignImage)
    .register(z.globalRegistry, {
      description: 'The generated/edited images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2509LoraGalleryRemoveLightingImageSize =
  z.object({
    height: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The height of the generated image.',
        }),
      )
      .default(512),
    width: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The width of the generated image.',
        }),
      )
      .default(512),
  })

/**
 * RemoveLightingInput
 *
 * Input model for Remove Lighting endpoint - Remove existing lighting and apply soft even lighting
 */
export const zQwenImageEdit2509LoraGalleryRemoveLightingInput = z
  .object({
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiQwenImageEdit2509LoraGalleryRemoveLightingImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
        z.unknown(),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(1),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description: 'The URL of the image with lighting/shadows to remove.',
    }),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt for the generation',
        }),
      )
      .default(' '),
    num_inference_steps: z
      .optional(
        z.int().gte(2).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(6),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Remove Lighting endpoint - Remove existing lighting and apply soft even lighting',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEdit2509LoraGalleryRemoveLightingImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * RemoveLightingOutput
 */
export const zQwenImageEdit2509LoraGalleryRemoveLightingOutput = z.object({
  images: z
    .array(zFalAiQwenImageEdit2509LoraGalleryRemoveLightingImage)
    .register(z.globalRegistry, {
      description: 'The generated/edited images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2509LoraGalleryRemoveElementImageSize =
  z.object({
    height: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The height of the generated image.',
        }),
      )
      .default(512),
    width: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The width of the generated image.',
        }),
      )
      .default(512),
  })

/**
 * RemoveElementInput
 *
 * Input model for Remove Element endpoint - Remove/delete elements (objects, people, text) from the image
 */
export const zQwenImageEdit2509LoraGalleryRemoveElementInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            'Specify what element(s) to remove from the image (objects, people, text, etc.). The model will cleanly remove the element while maintaining consistency of the rest of the image.',
        }),
      )
      .default('Remove the specified element from the scene'),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiQwenImageEdit2509LoraGalleryRemoveElementImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
        z.unknown(),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'The scale factor for the LoRA model. Controls the strength of the LoRA effect.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(1),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description: 'The URL of the image containing elements to remove.',
    }),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt for the generation',
        }),
      )
      .default(' '),
    num_inference_steps: z
      .optional(
        z.int().gte(2).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(6),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Remove Element endpoint - Remove/delete elements (objects, people, text) from the image',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEdit2509LoraGalleryRemoveElementImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * RemoveElementOutput
 */
export const zQwenImageEdit2509LoraGalleryRemoveElementOutput = z.object({
  images: z
    .array(zFalAiQwenImageEdit2509LoraGalleryRemoveElementImage)
    .register(z.globalRegistry, {
      description: 'The generated/edited images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2509LoraGalleryLightingRestorationImageSize =
  z.object({
    height: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The height of the generated image.',
        }),
      )
      .default(512),
    width: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The width of the generated image.',
        }),
      )
      .default(512),
  })

/**
 * LightingRestorationInput
 *
 * Input model for Lighting Restoration endpoint - Restore natural lighting by removing harsh shadows and light spots
 */
export const zQwenImageEdit2509LoraGalleryLightingRestorationInput = z
  .object({
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiQwenImageEdit2509LoraGalleryLightingRestorationImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
        z.unknown(),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(1),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description: 'The URL of the image to restore lighting for.',
    }),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt for the generation',
        }),
      )
      .default(' '),
    num_inference_steps: z
      .optional(
        z.int().gte(2).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(6),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Lighting Restoration endpoint - Restore natural lighting by removing harsh shadows and light spots',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEdit2509LoraGalleryLightingRestorationImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * LightingRestorationOutput
 */
export const zQwenImageEdit2509LoraGalleryLightingRestorationOutput = z.object({
  images: z
    .array(zFalAiQwenImageEdit2509LoraGalleryLightingRestorationImage)
    .register(z.globalRegistry, {
      description: 'The generated/edited images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2509LoraGalleryIntegrateProductImageSize =
  z.object({
    height: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The height of the generated image.',
        }),
      )
      .default(512),
    width: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The width of the generated image.',
        }),
      )
      .default(512),
  })

/**
 * IntegrateProductInput
 *
 * Input model for Integrate Product endpoint - Blend and integrate products/elements into backgrounds
 */
export const zQwenImageEdit2509LoraGalleryIntegrateProductInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            'Describe how to blend and integrate the product/element into the background. The model will automatically correct perspective, lighting and shadows for natural integration.',
        }),
      )
      .default('Blend and integrate the product into the background'),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiQwenImageEdit2509LoraGalleryIntegrateProductImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
        z.unknown(),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'The scale factor for the LoRA model. Controls the strength of the LoRA effect.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(1),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description:
        'The URL of the image with product to integrate into background.',
    }),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt for the generation',
        }),
      )
      .default(' '),
    num_inference_steps: z
      .optional(
        z.int().gte(2).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(6),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Integrate Product endpoint - Blend and integrate products/elements into backgrounds',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEdit2509LoraGalleryIntegrateProductImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * IntegrateProductOutput
 */
export const zQwenImageEdit2509LoraGalleryIntegrateProductOutput = z.object({
  images: z
    .array(zFalAiQwenImageEdit2509LoraGalleryIntegrateProductImage)
    .register(z.globalRegistry, {
      description: 'The generated/edited images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2509LoraGalleryGroupPhotoImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * GroupPhotoInput
 *
 * Input model for Group Photo endpoint - Create composite group photos with vintage/retro style
 */
export const zQwenImageEdit2509LoraGalleryGroupPhotoInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            'Describe the group photo scene, setting, and style. The model will maintain character consistency and add vintage effects like grain, blur, and retro filters.',
        }),
      )
      .default(
        'Two people standing next to each other outside with a landscape background',
      ),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiQwenImageEdit2509LoraGalleryGroupPhotoImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
        z.unknown(),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'The scale factor for the LoRA model. Controls the strength of the LoRA effect.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(1),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description:
        'The URLs of the images to combine into a group photo. Provide 2 or more individual portrait images.',
    }),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt for the generation',
        }),
      )
      .default(' '),
    num_inference_steps: z
      .optional(
        z.int().gte(2).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(6),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Group Photo endpoint - Create composite group photos with vintage/retro style',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEdit2509LoraGalleryGroupPhotoImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * GroupPhotoOutput
 */
export const zQwenImageEdit2509LoraGalleryGroupPhotoOutput = z.object({
  images: z
    .array(zFalAiQwenImageEdit2509LoraGalleryGroupPhotoImage)
    .register(z.globalRegistry, {
      description: 'The generated/edited images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitImageSize =
  z.object({
    height: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The height of the generated image.',
        }),
      )
      .default(512),
    width: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The width of the generated image.',
        }),
      )
      .default(512),
  })

/**
 * FaceToFullPortraitInput
 *
 * Input model for Face to Full Portrait endpoint - Generate full portrait from a cropped face image
 */
export const zQwenImageEdit2509LoraGalleryFaceToFullPortraitInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            'Describe the full portrait you want to generate from the face. Include clothing, setting, pose, and style details.',
        }),
      )
      .default(
        'Photography. A portrait of the person in professional attire with natural lighting',
      ),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
        z.unknown(),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'The scale factor for the LoRA model. Controls the strength of the LoRA effect.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(1),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description:
        'The URL of the cropped face image. Provide a close-up face photo.',
    }),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt for the generation',
        }),
      )
      .default(' '),
    num_inference_steps: z
      .optional(
        z.int().gte(2).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(6),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Face to Full Portrait endpoint - Generate full portrait from a cropped face image',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FaceToFullPortraitOutput
 */
export const zQwenImageEdit2509LoraGalleryFaceToFullPortraitOutput = z.object({
  images: z
    .array(zFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitImage)
    .register(z.globalRegistry, {
      description: 'The generated/edited images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2509LoraGalleryAddBackgroundImageSize =
  z.object({
    height: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The height of the generated image.',
        }),
      )
      .default(512),
    width: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The width of the generated image.',
        }),
      )
      .default(512),
  })

/**
 * AddBackgroundInput
 *
 * Input model for Add Background endpoint - Remove white background and add a realistic scene
 */
export const zQwenImageEdit2509LoraGalleryAddBackgroundInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            'Describe the background/scene you want to add behind the object. The model will remove the white background and add the specified environment.',
        }),
      )
      .default(
        'Remove white background and add a realistic scene behind the object',
      ),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiQwenImageEdit2509LoraGalleryAddBackgroundImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
        z.unknown(),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'The scale factor for the LoRA model. Controls the strength of the LoRA effect.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(1),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description:
        'The URLs of the images to edit. Provide an image with a white or clean background.',
    }),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt for the generation',
        }),
      )
      .default(' '),
    num_inference_steps: z
      .optional(
        z.int().gte(2).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(6),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Add Background endpoint - Remove white background and add a realistic scene',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEdit2509LoraGalleryAddBackgroundImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * AddBackgroundOutput
 */
export const zQwenImageEdit2509LoraGalleryAddBackgroundOutput = z.object({
  images: z
    .array(zFalAiQwenImageEdit2509LoraGalleryAddBackgroundImage)
    .register(z.globalRegistry, {
      description: 'The generated/edited images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2509LoraGalleryNextSceneImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * NextSceneInput
 *
 * Input model for Next Scene endpoint - Create cinematic shot progressions and scene transitions
 */
export const zQwenImageEdit2509LoraGalleryNextSceneInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            "Describe the camera movement, framing change, or scene transition. Start with 'Next Scene:' for best results. Examples: camera movements (dolly, push-in, pull-back), framing changes (wide to close-up), new elements entering frame.",
        }),
      )
      .default(
        'Next Scene: The camera moves forward revealing more of the scene',
      ),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiQwenImageEdit2509LoraGalleryNextSceneImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
        z.unknown(),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'The scale factor for the LoRA model. Controls the strength of the LoRA effect.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(1),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description: 'The URL of the image to create the next scene from.',
    }),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt for the generation',
        }),
      )
      .default(' '),
    num_inference_steps: z
      .optional(
        z.int().gte(2).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(6),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Next Scene endpoint - Create cinematic shot progressions and scene transitions',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEdit2509LoraGalleryNextSceneImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * NextSceneOutput
 */
export const zQwenImageEdit2509LoraGalleryNextSceneOutput = z.object({
  images: z
    .array(zFalAiQwenImageEdit2509LoraGalleryNextSceneImage)
    .register(z.globalRegistry, {
      description: 'The generated/edited images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2509LoraGalleryMultipleAnglesImageSize =
  z.object({
    height: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The height of the generated image.',
        }),
      )
      .default(512),
    width: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The width of the generated image.',
        }),
      )
      .default(512),
  })

/**
 * MultipleAnglesInput
 *
 * Input model for Multiple Angles endpoint - Camera control with precise adjustments
 */
export const zQwenImageEdit2509LoraGalleryMultipleAnglesInput = z
  .object({
    image_size: z.optional(
      z.union([
        zFalAiQwenImageEdit2509LoraGalleryMultipleAnglesImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
        z.unknown(),
      ]),
    ),
    wide_angle_lens: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Enable wide-angle lens effect',
        }),
      )
      .default(false),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(1),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description: 'The URL of the image to adjust camera angle for.',
    }),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt for the generation',
        }),
      )
      .default(' '),
    vertical_angle: z
      .optional(
        z.number().gte(-1).lte(1).register(z.globalRegistry, {
          description:
            "Adjust vertical camera angle (-1=bird's-eye view/looking down, 0=neutral, 1=worm's-eye view/looking up)",
        }),
      )
      .default(0),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    move_forward: z
      .optional(
        z.number().gte(0).lte(10).register(z.globalRegistry, {
          description: 'Move camera forward (0=no movement, 10=close-up)',
        }),
      )
      .default(0),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    rotate_right_left: z
      .optional(
        z.number().gte(-90).lte(90).register(z.globalRegistry, {
          description:
            'Rotate camera left (positive) or right (negative) in degrees. Positive values rotate left, negative values rotate right.',
        }),
      )
      .default(0),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'The scale factor for the LoRA model. Controls the strength of the camera control effect.',
        }),
      )
      .default(1.25),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    num_inference_steps: z
      .optional(
        z.int().gte(2).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(6),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Multiple Angles endpoint - Camera control with precise adjustments',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEdit2509LoraGalleryMultipleAnglesImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * MultipleAnglesOutput
 */
export const zQwenImageEdit2509LoraGalleryMultipleAnglesOutput = z.object({
  images: z
    .array(zFalAiQwenImageEdit2509LoraGalleryMultipleAnglesImage)
    .register(z.globalRegistry, {
      description: 'The generated/edited images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2509LoraImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zFalAiQwenImageEdit2509LoraLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * BaseQwenEditImagePlusLoRAInput
 */
export const zQwenImageEdit2509LoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the image with',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiQwenImageEdit2509LoraImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description:
        "Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.",
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  loras: z
    .optional(
      z
        .array(zFalAiQwenImageEdit2509LoraLoraWeight)
        .register(z.globalRegistry, {
          description:
            '\n            The LoRAs to use for the image generation. You can use up to 3 LoRAs\n            and they will be merged together to generate the final image.\n        ',
        }),
    )
    .default([]),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(4),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description: 'The URLs of the images to edit.',
  }),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt for the generation',
      }),
    )
    .default(' '),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiQwenImageEdit2509LoraImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * QwenImageOutput
 */
export const zQwenImageEdit2509LoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiQwenImageEdit2509LoraImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2509ImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * BaseQwenEditImagePlusInput
 */
export const zQwenImageEdit2509Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the image with',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiQwenImageEdit2509ImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description:
        "Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.",
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(4),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description: 'The URLs of the images to edit.',
  }),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt for the generation',
      }),
    )
    .default(' '),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(100).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(50),
})

/**
 * Image
 */
export const zFalAiQwenImageEdit2509Image = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * QwenImageOutput
 */
export const zQwenImageEdit2509Output = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiQwenImageEdit2509Image).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEditPlusLoraGalleryLightingRestorationImageSize =
  z.object({
    height: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The height of the generated image.',
        }),
      )
      .default(512),
    width: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The width of the generated image.',
        }),
      )
      .default(512),
  })

/**
 * LightingRestorationInput
 *
 * Input model for Lighting Restoration endpoint - Restore natural lighting by removing harsh shadows and light spots
 */
export const zQwenImageEditPlusLoraGalleryLightingRestorationInput = z
  .object({
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiQwenImageEditPlusLoraGalleryLightingRestorationImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
        z.unknown(),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(1),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description: 'The URL of the image to restore lighting for.',
    }),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt for the generation',
        }),
      )
      .default(' '),
    num_inference_steps: z
      .optional(
        z.int().gte(2).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(6),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Lighting Restoration endpoint - Restore natural lighting by removing harsh shadows and light spots',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEditPlusLoraGalleryLightingRestorationImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * LightingRestorationOutput
 */
export const zQwenImageEditPlusLoraGalleryLightingRestorationOutput = z.object({
  images: z
    .array(zFalAiQwenImageEditPlusLoraGalleryLightingRestorationImage)
    .register(z.globalRegistry, {
      description: 'The generated/edited images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * SegmentSamplingSettings
 */
export const zSegmentSamplingSettings = z.object({
  top_p: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Nucleus sampling probability mass to use, between 0 and 1.',
      }),
    )
    .default(1),
  max_tokens: z.optional(
    z.int().gte(1).register(z.globalRegistry, {
      description: 'Maximum number of tokens to generate.',
    }),
  ),
  temperature: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Sampling temperature to use. Higher values will make the output more random, while lower values will make it more focused and deterministic.',
      }),
    )
    .default(1),
})

/**
 * ImageFile
 */
export const zFalAiMoondream3PreviewSegmentImageFile = z.object({
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Object
 */
export const zObject = z.object({
  y_min: z.number().register(z.globalRegistry, {
    description: 'Top boundary of detection box in normalized format (0 to 1)',
  }),
  x_max: z.number().register(z.globalRegistry, {
    description:
      'Right boundary of detection box in normalized format (0 to 1)',
  }),
  x_min: z.number().register(z.globalRegistry, {
    description: 'Left boundary of detection box in normalized format (0 to 1)',
  }),
  y_max: z.number().register(z.globalRegistry, {
    description:
      'Bottom boundary of detection box in normalized format (0 to 1)',
  }),
})

/**
 * UsageInfo
 */
export const zUsageInfo = z.object({
  output_tokens: z.int().register(z.globalRegistry, {
    description: 'Number of output tokens generated',
  }),
  decode_time_ms: z.number().register(z.globalRegistry, {
    description: 'Time taken for decoding in milliseconds',
  }),
  input_tokens: z.int().register(z.globalRegistry, {
    description: 'Number of input tokens processed',
  }),
  ttft_ms: z.number().register(z.globalRegistry, {
    description: 'Time to first token in milliseconds',
  }),
  prefill_time_ms: z.number().register(z.globalRegistry, {
    description: 'Time taken for prefill in milliseconds',
  }),
})

/**
 * MoondreamSegementationOutput
 */
export const zMoondream3PreviewSegmentOutput = z.object({
  finish_reason: z.string().register(z.globalRegistry, {
    description: 'Reason for finishing the output generation',
  }),
  image: z.optional(zFalAiMoondream3PreviewSegmentImageFile),
  bbox: z.optional(zObject),
  path: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'SVG path data representing the segmentation mask. If not detected, will be null.',
    }),
  ),
  usage_info: zUsageInfo,
})

/**
 * Placeholder for missing schema Point (referenced but not defined in source OpenAPI spec)
 */
export const zPoint = z
  .record(z.string(), z.unknown())
  .register(z.globalRegistry, {
    description:
      'Placeholder for missing schema Point (referenced but not defined in source OpenAPI spec)',
  })

/**
 * MoondreamSegementationInput
 */
export const zMoondream3PreviewSegmentInput = z.object({
  spatial_references: z.optional(
    z.array(z.union([zPoint, z.array(z.number())])).register(z.globalRegistry, {
      description:
        'Spatial references to guide the segmentation. By feeding in references you can help the segmentation process. Must be either list of Point object with x and y members, or list of arrays containing either 2 floats (x,y) or 4 floats (x1,y1,x2,y2). \n**NOTE**: You can also use the [**point endpoint**](https://fal.ai/models/fal-ai/moondream3-preview/point) to get points for the objects, and pass them in here.',
    }),
  ),
  settings: z.optional(zSegmentSamplingSettings),
  object: z.string().register(z.globalRegistry, {
    description: 'Object to be segmented in the image',
  }),
  preview: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to preview the output and return a binary mask of the image',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the image to be processed\n\nMax width: 7000px, Max height: 7000px, Timeout: 20.0s',
  }),
})

/**
 * ImageToImageInput
 */
export const zStepxEdit2Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  enable_reflection_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Enable reflection mode. Reviews outputs, corrects unintended changes, and determines when editing is complete.',
      }),
    )
    .default(true),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The image URL to generate an image from. Needs to match the dimensions of the mask.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The true CFG scale. Controls how closely the model follows the prompt.\n        ',
      }),
    )
    .default(6),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(100).register(z.globalRegistry, {
        description:
          'The number of inference steps to perform. Recommended: 50.',
      }),
    )
    .default(50),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  enable_thinking_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Enable thinking mode. Uses multimodal language model knowledge to interpret abstract editing instructions.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zFalAiStepxEdit2Image = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * ImageOutput
 */
export const zStepxEdit2Output = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  best_info: z.optional(
    z.array(z.record(z.string(), z.unknown())).register(z.globalRegistry, {
      description:
        'Reflection analysis (only available when reflection mode is enabled).',
    }),
  ),
  images: z.array(zFalAiStepxEdit2Image).register(z.globalRegistry, {
    description: 'The generated images',
  }),
  timings: z.record(z.string(), z.number()),
  reformat_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        "The model's interpretation of your instruction (only available when thinking mode is enabled).",
    }),
  ),
  think_info: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'Reasoning process details (only available when thinking mode is enabled).',
    }),
  ),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export const zFalAiZImageTurboControlnetLoraLoRaInput = z
  .object({
    path: z.string().register(z.globalRegistry, {
      description: 'URL, HuggingFace repo ID (owner/repo) to lora weights.',
    }),
    scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description: 'Scale factor for LoRA application (0.0 to 4.0).',
        }),
      )
      .default(1),
  })
  .register(z.globalRegistry, {
    description: 'LoRA weight configuration.',
  })

/**
 * ImageFile
 */
export const zFalAiZImageTurboControlnetLoraImageFile = z.object({
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ZImageTurboControlNetOutput
 */
export const zZImageTurboControlnetLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiZImageTurboControlnetLoraImageFile)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()).register(z.globalRegistry, {
    description: 'The timings of the generation process.',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      'Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.',
  }),
})

/**
 * ImageSize
 */
export const zFalAiZImageTurboControlnetImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * ZImageTurboControlNetInput
 */
export const zZImageTurboControlnetInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiZImageTurboControlnetImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
        'auto',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  control_end: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The end of the controlnet conditioning.',
      }),
    )
    .default(0.8),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  control_start: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The start of the controlnet conditioning.',
      }),
    )
    .default(0),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of Image for ControlNet generation.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  control_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The scale of the controlnet conditioning.',
      }),
    )
    .default(0.75),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. Note: this will increase the price by 0.0025 credits per request.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(8),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The same seed and the same prompt given to the same version of the model will output the same image every time.',
    }),
  ),
  preprocess: z.optional(
    z.enum(['none', 'canny', 'depth', 'pose']).register(z.globalRegistry, {
      description: 'What kind of preprocessing to apply to the image, if any.',
    }),
  ),
})

/**
 * ImageFile
 */
export const zFalAiZImageTurboControlnetImageFile = z.object({
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ZImageTurboControlNetOutput
 */
export const zZImageTurboControlnetOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiZImageTurboControlnetImageFile)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()).register(z.globalRegistry, {
    description: 'The timings of the generation process.',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      'Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.',
  }),
})

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export const zFalAiZImageTurboImageToImageLoraLoRaInput = z
  .object({
    path: z.string().register(z.globalRegistry, {
      description: 'URL, HuggingFace repo ID (owner/repo) to lora weights.',
    }),
    scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description: 'Scale factor for LoRA application (0.0 to 4.0).',
        }),
      )
      .default(1),
  })
  .register(z.globalRegistry, {
    description: 'LoRA weight configuration.',
  })

/**
 * ImageFile
 */
export const zFalAiZImageTurboImageToImageLoraImageFile = z.object({
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ZImageTurboImageToImageOutput
 */
export const zZImageTurboImageToImageLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiZImageTurboImageToImageLoraImageFile)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()).register(z.globalRegistry, {
    description: 'The timings of the generation process.',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      'Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.',
  }),
})

/**
 * ImageSize
 */
export const zFalAiZImageTurboImageToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * ZImageTurboImageToImageInput
 */
export const zZImageTurboImageToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  image_size: z.optional(
    z.union([
      zFalAiZImageTurboImageToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
        'auto',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of Image for Image-to-Image generation.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The strength of the image-to-image conditioning.',
      }),
    )
    .default(0.6),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. Note: this will increase the price by 0.0025 credits per request.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(8),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The same seed and the same prompt given to the same version of the model will output the same image every time.',
    }),
  ),
})

/**
 * ImageFile
 */
export const zFalAiZImageTurboImageToImageImageFile = z.object({
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ZImageTurboImageToImageOutput
 */
export const zZImageTurboImageToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiZImageTurboImageToImageImageFile)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()).register(z.globalRegistry, {
    description: 'The timings of the generation process.',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      'Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.',
  }),
})

/**
 * EditImageInput
 */
export const zLongcatImageEditInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to edit the image with.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to edit.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description: 'The guidance scale to use for the image generation.',
      }),
    )
    .default(4.5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiLongcatImageEditImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * ImageToImageOutput
 */
export const zLongcatImageEditOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiLongcatImageEditImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiBytedanceSeedreamV45EditImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * SeedDream45EditInput
 */
export const zBytedanceSeedreamV45EditInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt used to edit the image',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(6).register(z.globalRegistry, {
        description:
          'Number of separate model generations to be run with the prompt.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiBytedanceSeedreamV45EditImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
        'auto_2K',
        'auto_4K',
      ]),
    ]),
  ),
  max_images: z
    .optional(
      z.int().gte(1).lte(6).register(z.globalRegistry, {
        description:
          'If set to a number greater than one, enables multi-image generation. The model will potentially return up to `max_images` images every generation, and in total, `num_images` generations will be carried out. In total, the number of images generated will be between `num_images` and `max_images*num_images`. The total number of images (image inputs + image outputs) must not exceed 15',
      }),
    )
    .default(1),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed to control the stochasticity of image generation.',
    }),
  ),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'List of URLs of input images for editing. Presently, up to 10 image inputs are allowed. If over 10 images are sent, only the last 10 will be used.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBytedanceSeedreamV45EditImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * SeedDream45EditOutput
 */
export const zBytedanceSeedreamV45EditOutput = z.object({
  images: z
    .array(zFalAiBytedanceSeedreamV45EditImage)
    .register(z.globalRegistry, {
      description: 'Generated images',
    }),
})

/**
 * ReferenceToImageRequest
 */
export const zViduQ2ReferenceToImageInput = z.object({
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text prompt for video generation, max 1500 characters',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the output video',
    }),
  ),
  reference_image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'URLs of the reference images to use for consistent subject appearance',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiViduQ2ReferenceToImageImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ReferenceToImageOutput
 */
export const zViduQ2ReferenceToImageOutput = z.object({
  image: zFalAiViduQ2ReferenceToImageImage,
})

/**
 * OmniImageElementInput
 */
export const zOmniImageElementInput = z.object({
  reference_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'Additional reference images from different angles. 1-3 images supported. At least one image is required.',
    }),
  ),
  frontal_image_url: z.string().register(z.globalRegistry, {
    description: 'The frontal image of the element (main view).',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiKlingImageO1Image = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * OmniImageOutput
 */
export const zKlingImageO1Output = z.object({
  images: z.array(zFalAiKlingImageO1Image).register(z.globalRegistry, {
    description: 'Generated images',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux2LoraGalleryVirtualTryonImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * VirtualTryonInput
 *
 * Input model for Virtual Try-on endpoint - Generate virtual try-on images
 */
export const zFlux2LoraGalleryVirtualTryonInput = z
  .object({
    prompt: z.string().register(z.globalRegistry, {
      description: 'The prompt to generate a virtual try-on image.',
    }),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiFlux2LoraGalleryVirtualTryonImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
        z.unknown(),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(2).register(z.globalRegistry, {
          description: 'The strength of the virtual try-on effect.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(2.5),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description:
        'The URLs of the images for virtual try-on. Provide person image and clothing image.',
    }),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    num_inference_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(40),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Virtual Try-on endpoint - Generate virtual try-on images',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlux2LoraGalleryVirtualTryonImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * VirtualTryonOutput
 */
export const zFlux2LoraGalleryVirtualTryonOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation',
  }),
  images: z
    .array(zFalAiFlux2LoraGalleryVirtualTryonImage)
    .register(z.globalRegistry, {
      description: 'The generated virtual try-on images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux2LoraGalleryMultipleAnglesImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * MultipleAnglesInput
 *
 * Input model for Multiple Angles endpoint - Camera control with precise adjustments using <sks> trigger word. Prompt is built automatically from slider values.
 */
export const zFlux2LoraGalleryMultipleAnglesInput = z
  .object({
    image_size: z.optional(
      z.union([
        zFalAiFlux2LoraGalleryMultipleAnglesImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
        z.unknown(),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description: 'Acceleration level for image generation.',
      }),
    ),
    horizontal_angle: z
      .optional(
        z.number().gte(0).lte(360).register(z.globalRegistry, {
          description:
            'Horizontal rotation angle around the object in degrees. 0°=front view, 90°=right side, 180°=back view, 270°=left side, 360°=front view again.',
        }),
      )
      .default(0),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description: 'The CFG (Classifier Free Guidance) scale.',
        }),
      )
      .default(2.5),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable the safety checker.',
        }),
      )
      .default(true),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description: 'The URL of the image to adjust camera angle for.',
    }),
    zoom: z
      .optional(
        z.number().gte(0).lte(10).register(z.globalRegistry, {
          description:
            'Camera zoom/distance. 0=wide shot (far away), 5=medium shot (normal), 10=close-up (very close).',
        }),
      )
      .default(5),
    vertical_angle: z
      .optional(
        z.number().gte(0).lte(60).register(z.globalRegistry, {
          description:
            'Vertical camera angle in degrees. 0°=eye-level shot, 30°=elevated shot, 60°=high-angle shot (looking down from above).',
        }),
      )
      .default(0),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate.',
        }),
      )
      .default(1),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(2).register(z.globalRegistry, {
          description: 'The strength of the multiple angles effect.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image.',
      }),
    ),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'If True, the media will be returned as a data URI.',
        }),
      )
      .default(false),
    num_inference_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(40),
    seed: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Multiple Angles endpoint - Camera control with precise adjustments using <sks> trigger word. Prompt is built automatically from slider values.',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlux2LoraGalleryMultipleAnglesImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * MultipleAnglesOutput
 */
export const zFlux2LoraGalleryMultipleAnglesOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation',
  }),
  images: z
    .array(zFalAiFlux2LoraGalleryMultipleAnglesImage)
    .register(z.globalRegistry, {
      description: 'The generated images with multiple camera angles',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux2LoraGalleryFaceToFullPortraitImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * FaceToFullPortraitInput
 *
 * Input model for Face to Full Portrait endpoint - Generate full portrait from face
 */
export const zFlux2LoraGalleryFaceToFullPortraitInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            'The prompt describing the full portrait to generate from the face.',
        }),
      )
      .default('Face to full portrait'),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiFlux2LoraGalleryFaceToFullPortraitImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
        z.unknown(),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(2).register(z.globalRegistry, {
          description: 'The strength of the face to full portrait effect.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(2.5),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description: 'The URL of the cropped face image.',
    }),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    num_inference_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(40),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Face to Full Portrait endpoint - Generate full portrait from face',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlux2LoraGalleryFaceToFullPortraitImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FaceToFullPortraitOutput
 */
export const zFlux2LoraGalleryFaceToFullPortraitOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation',
  }),
  images: z
    .array(zFalAiFlux2LoraGalleryFaceToFullPortraitImage)
    .register(z.globalRegistry, {
      description: 'The generated full portrait images from face',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux2LoraGalleryApartmentStagingImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * ApartmentStagingInput
 *
 * Input model for Apartment Staging endpoint - Furnish rooms
 */
export const zFlux2LoraGalleryApartmentStagingInput = z
  .object({
    prompt: z.string().register(z.globalRegistry, {
      description:
        "The prompt to generate a furnished room. Use 'furnish this room' for best results.",
    }),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiFlux2LoraGalleryApartmentStagingImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
        z.unknown(),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(2).register(z.globalRegistry, {
          description: 'The strength of the apartment staging effect.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(2.5),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description: 'The URL of the empty room image to furnish.',
    }),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    num_inference_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(40),
  })
  .register(z.globalRegistry, {
    description: 'Input model for Apartment Staging endpoint - Furnish rooms',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlux2LoraGalleryApartmentStagingImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ApartmentStagingOutput
 */
export const zFlux2LoraGalleryApartmentStagingOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation',
  }),
  images: z
    .array(zFalAiFlux2LoraGalleryApartmentStagingImage)
    .register(z.globalRegistry, {
      description: 'The generated furnished room images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux2LoraGalleryAddBackgroundImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * AddBackgroundInput
 *
 * Input model for Add Background endpoint - Add background to images
 */
export const zFlux2LoraGalleryAddBackgroundInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            "The prompt describing the background to add. Must start with 'Add Background' followed by your description.",
        }),
      )
      .default('Add Background forest'),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiFlux2LoraGalleryAddBackgroundImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
        z.unknown(),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(2).register(z.globalRegistry, {
          description: 'The strength of the add background effect.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(2.5),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description:
        'The URLs of the images. Provide an image with a white or clean background.',
    }),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    num_inference_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(40),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Add Background endpoint - Add background to images',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlux2LoraGalleryAddBackgroundImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * AddBackgroundOutput
 */
export const zFlux2LoraGalleryAddBackgroundOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation',
  }),
  images: z
    .array(zFalAiFlux2LoraGalleryAddBackgroundImage)
    .register(z.globalRegistry, {
      description: 'The generated images with added background',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * CrystalUpscaleInput
 */
export const zCrystalUpscalerInput = z.object({
  creativity: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description: 'Creativity level for upscaling',
      }),
    )
    .default(0),
  scale_factor: z
    .optional(
      z.number().gte(1).lte(200).register(z.globalRegistry, {
        description: 'Scale factor',
      }),
    )
    .default(2),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL to the input image',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zClarityaiCrystalUpscalerImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * CrystalUpscaleOutput
 */
export const zCrystalUpscalerOutput = z.object({
  images: z.array(zClarityaiCrystalUpscalerImage).register(z.globalRegistry, {
    description: 'List of upscaled images',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux2FlexEditImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Flux2FlexImageEditInput
 */
export const zFlux2FlexEditInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  guidance_scale: z
    .optional(
      z.number().gte(1.5).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use for the generation.',
      }),
    )
    .default(3.5),
  image_size: z.optional(
    z.union([
      zFalAiFlux2FlexEditImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to expand the prompt using the model's own knowledge.",
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description: 'List of URLs of input images for editing',
  }),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for the generation.',
    }),
  ),
})

/**
 * ImageFile
 */
export const zFalAiFlux2FlexEditImageFile = z.object({
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Flux2FlexEditOutput
 */
export const zFlux2FlexEditOutput = z.object({
  images: z.array(zFalAiFlux2FlexEditImageFile).register(z.globalRegistry, {
    description: 'The generated images.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the generation.',
  }),
})

/**
 * ChronoLoraWeight
 */
export const zChronoLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or path to the LoRA weights (Safetensors).',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description: 'Scale factor controlling LoRA strength.',
      }),
    )
    .default(1),
})

/**
 * ChronoEditLoRAInput
 *
 * ChronoEdit input with optional custom LoRAs.
 */
export const zChronoEditLoraInput = z
  .object({
    prompt: z.string().register(z.globalRegistry, {
      description: 'The prompt to edit the image.',
    }),
    loras: z
      .optional(
        z.array(zChronoLoraWeight).register(z.globalRegistry, {
          description:
            'Optional additional LoRAs to merge for this request (max 3).',
        }),
      )
      .default([]),
    turbo_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Enable turbo mode to use for faster inference.',
        }),
      )
      .default(true),
    enable_temporal_reasoning: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable temporal reasoning.',
        }),
      )
      .default(false),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable the safety checker.',
        }),
      )
      .default(true),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(10).register(z.globalRegistry, {
          description: 'The guidance scale for the inference.',
        }),
      )
      .default(1),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description: 'The resolution of the output image.',
      }),
    ),
    output_format: z.optional(
      z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image.',
      }),
    ),
    num_temporal_reasoning_steps: z
      .optional(
        z.int().gte(2).lte(12).register(z.globalRegistry, {
          description: 'The number of temporal reasoning steps to perform.',
        }),
      )
      .default(8),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to return the image in sync mode.',
        }),
      )
      .default(false),
    image_url: z.string().register(z.globalRegistry, {
      description: 'The image to edit.',
    }),
    enable_prompt_expansion: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable prompt expansion.',
        }),
      )
      .default(true),
    num_inference_steps: z
      .optional(
        z.int().gte(2).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(8),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the inference.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'ChronoEdit input with optional custom LoRAs.',
  })

/**
 * ImageFile
 */
export const zFalAiChronoEditLoraImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ChronoEditOutput
 *
 * Unified output model for all ChronoEdit operations
 */
export const zChronoEditLoraOutput = z
  .object({
    prompt: z.string().register(z.globalRegistry, {
      description: 'The prompt used for the inference.',
    }),
    images: z.array(zFalAiChronoEditLoraImageFile).register(z.globalRegistry, {
      description: 'The edited image.',
    }),
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed for the inference.',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Unified output model for all ChronoEdit operations',
  })

/**
 * ChronoLoraWeight
 */
export const zFalAiChronoEditLoraGalleryPaintbrushChronoLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or path to the LoRA weights (Safetensors).',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description: 'Scale factor controlling LoRA strength.',
      }),
    )
    .default(1),
})

/**
 * ChronoEditPaintBrushInput
 *
 * Input for paintbrush mode
 */
export const zChronoEditLoraGalleryPaintbrushInput = z
  .object({
    prompt: z.string().register(z.globalRegistry, {
      description: 'Describe how to transform the sketched regions.',
    }),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description: 'The resolution of the output image.',
      }),
    ),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(2).register(z.globalRegistry, {
          description: 'The scale factor for the LoRA adapter.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image.',
      }),
    ),
    image_url: z.string().register(z.globalRegistry, {
      description: 'The image to edit.',
    }),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to return the image in sync mode.',
        }),
      )
      .default(false),
    turbo_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Enable turbo mode to use faster inference.',
        }),
      )
      .default(true),
    loras: z
      .optional(
        z
          .array(zFalAiChronoEditLoraGalleryPaintbrushChronoLoraWeight)
          .register(z.globalRegistry, {
            description: 'Optional additional LoRAs to merge (max 3).',
          }),
      )
      .default([]),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(10).register(z.globalRegistry, {
          description: 'Classifier-free guidance scale.',
        }),
      )
      .default(1),
    num_inference_steps: z
      .optional(
        z.int().gte(2).lte(50).register(z.globalRegistry, {
          description: 'Number of denoising steps to run.',
        }),
      )
      .default(8),
    mask_url: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'Optional mask image where black areas indicate regions to sketch/paint.',
      }),
    ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the inference.',
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable the safety checker.',
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description: 'Input for paintbrush mode',
  })

/**
 * ImageFile
 */
export const zFalAiChronoEditLoraGalleryPaintbrushImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ChronoEditOutput
 *
 * Unified output model for all ChronoEdit operations
 */
export const zChronoEditLoraGalleryPaintbrushOutput = z
  .object({
    prompt: z.string().register(z.globalRegistry, {
      description: 'The prompt used for the inference.',
    }),
    images: z
      .array(zFalAiChronoEditLoraGalleryPaintbrushImageFile)
      .register(z.globalRegistry, {
        description: 'The edited image.',
      }),
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed for the inference.',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Unified output model for all ChronoEdit operations',
  })

/**
 * ChronoLoraWeight
 */
export const zFalAiChronoEditLoraGalleryUpscalerChronoLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or path to the LoRA weights (Safetensors).',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description: 'Scale factor controlling LoRA strength.',
      }),
    )
    .default(1),
})

/**
 * ChronoEditUpscalerInput
 *
 * Input for upscaler mode
 */
export const zChronoEditLoraGalleryUpscalerInput = z
  .object({
    lora_scale: z
      .optional(
        z.number().gte(0).lte(2).register(z.globalRegistry, {
          description: 'The scale factor for the LoRA adapter.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image.',
      }),
    ),
    image_url: z.string().register(z.globalRegistry, {
      description: 'The image to upscale.',
    }),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to return the image in sync mode.',
        }),
      )
      .default(false),
    loras: z
      .optional(
        z
          .array(zFalAiChronoEditLoraGalleryUpscalerChronoLoraWeight)
          .register(z.globalRegistry, {
            description: 'Optional additional LoRAs to merge (max 3).',
          }),
      )
      .default([]),
    upscale_factor: z
      .optional(
        z.number().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Target scale factor for the output resolution.',
        }),
      )
      .default(2),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(10).register(z.globalRegistry, {
          description: 'The guidance scale for the inference.',
        }),
      )
      .default(1),
    num_inference_steps: z
      .optional(
        z.int().gte(2).lte(50).register(z.globalRegistry, {
          description: 'Number of inference steps for the upscaling pass.',
        }),
      )
      .default(30),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the inference.',
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable the safety checker.',
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description: 'Input for upscaler mode',
  })

/**
 * ImageFile
 */
export const zFalAiChronoEditLoraGalleryUpscalerImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ChronoEditOutput
 *
 * Unified output model for all ChronoEdit operations
 */
export const zChronoEditLoraGalleryUpscalerOutput = z
  .object({
    prompt: z.string().register(z.globalRegistry, {
      description: 'The prompt used for the inference.',
    }),
    images: z
      .array(zFalAiChronoEditLoraGalleryUpscalerImageFile)
      .register(z.globalRegistry, {
        description: 'The edited image.',
      }),
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed for the inference.',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Unified output model for all ChronoEdit operations',
  })

/**
 * BoxPrompt
 */
export const zBoxPrompt = z.object({
  y_min: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Y Min Coordinate of the box',
    }),
  ),
  object_id: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Optional object identifier. Boxes sharing an object id refine the same object.',
    }),
  ),
  frame_index: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The frame index to interact with.',
    }),
  ),
  x_max: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'X Max Coordinate of the box',
    }),
  ),
  x_min: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'X Min Coordinate of the box',
    }),
  ),
  y_max: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Y Max Coordinate of the box',
    }),
  ),
})

/**
 * PointPrompt
 */
export const zPointPrompt = z.object({
  y: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Y Coordinate of the prompt',
    }),
  ),
  x: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'X Coordinate of the prompt',
    }),
  ),
  object_id: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Optional object identifier. Prompts sharing an object id refine the same object.',
    }),
  ),
  frame_index: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The frame index to interact with.',
    }),
  ),
  label: z.optional(
    z.union([z.literal(0), z.literal(1)]).register(z.globalRegistry, {
      description: '1 for foreground, 0 for background',
    }),
  ),
})

/**
 * SAM3ImageInput
 */
export const zSam3ImageRleInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Text prompt for segmentation',
      }),
    )
    .default('wheel'),
  include_boxes: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to include bounding boxes for each mask (when available).',
      }),
    )
    .default(false),
  box_prompts: z
    .optional(
      z.array(zBoxPrompt).register(z.globalRegistry, {
        description:
          'Box prompt coordinates (x_min, y_min, x_max, y_max). Multiple boxes supported - use object_id to group boxes for the same object or leave empty for separate objects.',
      }),
    )
    .default([]),
  return_multiple_masks: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If True, upload and return multiple generated masks as defined by `max_masks`.',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to be segmented',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If True, the media will be returned as a data URI.',
      }),
    )
    .default(false),
  point_prompts: z
    .optional(
      z.array(zPointPrompt).register(z.globalRegistry, {
        description: 'List of point prompts',
      }),
    )
    .default([]),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  max_masks: z
    .optional(
      z.int().gte(1).lte(32).register(z.globalRegistry, {
        description:
          'Maximum number of masks to return when `return_multiple_masks` is enabled.',
      }),
    )
    .default(3),
  include_scores: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to include mask confidence scores.',
      }),
    )
    .default(false),
  apply_mask: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Apply the mask on the image.',
      }),
    )
    .default(true),
  text_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        "[DEPRECATED] Use 'prompt' instead. Kept for backward compatibility.",
    }),
  ),
})

/**
 * MaskMetadata
 */
export const zMaskMetadata = z.object({
  box: z.optional(
    z.array(z.number()).register(z.globalRegistry, {
      description:
        'Bounding box for the mask in normalized cxcywh coordinates.',
    }),
  ),
  score: z.optional(
    z.number().register(z.globalRegistry, {
      description: 'Score for this mask.',
    }),
  ),
  index: z.int().register(z.globalRegistry, {
    description: 'Index of the mask inside the model output.',
  }),
})

/**
 * File
 */
export const zFalAiSam3ImageRleFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * SAM3RLEOutput
 */
export const zSam3ImageRleOutput = z.object({
  rle: z.union([z.string(), z.array(z.string())]),
  metadata: z.optional(
    z.array(zMaskMetadata).register(z.globalRegistry, {
      description: 'Per-mask metadata when multiple RLEs are returned.',
    }),
  ),
  scores: z.optional(
    z.array(z.number()).register(z.globalRegistry, {
      description: 'Per-mask confidence scores when requested.',
    }),
  ),
  boundingbox_frames_zip: z.optional(zFalAiSam3ImageRleFile),
  boxes: z.optional(
    z.array(z.array(z.number())).register(z.globalRegistry, {
      description:
        'Per-mask normalized bounding boxes [cx, cy, w, h] when requested.',
    }),
  ),
})

/**
 * BoxPrompt
 */
export const zFalAiSam3ImageBoxPrompt = z.object({
  y_min: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Y Min Coordinate of the box',
    }),
  ),
  object_id: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Optional object identifier. Boxes sharing an object id refine the same object.',
    }),
  ),
  frame_index: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The frame index to interact with.',
    }),
  ),
  x_max: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'X Max Coordinate of the box',
    }),
  ),
  x_min: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'X Min Coordinate of the box',
    }),
  ),
  y_max: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Y Max Coordinate of the box',
    }),
  ),
})

/**
 * PointPrompt
 */
export const zFalAiSam3ImagePointPrompt = z.object({
  y: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Y Coordinate of the prompt',
    }),
  ),
  x: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'X Coordinate of the prompt',
    }),
  ),
  object_id: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Optional object identifier. Prompts sharing an object id refine the same object.',
    }),
  ),
  frame_index: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The frame index to interact with.',
    }),
  ),
  label: z.optional(
    z.union([z.literal(0), z.literal(1)]).register(z.globalRegistry, {
      description: '1 for foreground, 0 for background',
    }),
  ),
})

/**
 * SAM3ImageInput
 */
export const zSam3ImageInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Text prompt for segmentation',
      }),
    )
    .default('wheel'),
  include_boxes: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to include bounding boxes for each mask (when available).',
      }),
    )
    .default(false),
  box_prompts: z
    .optional(
      z.array(zFalAiSam3ImageBoxPrompt).register(z.globalRegistry, {
        description:
          'Box prompt coordinates (x_min, y_min, x_max, y_max). Multiple boxes supported - use object_id to group boxes for the same object or leave empty for separate objects.',
      }),
    )
    .default([]),
  return_multiple_masks: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If True, upload and return multiple generated masks as defined by `max_masks`.',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to be segmented',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If True, the media will be returned as a data URI.',
      }),
    )
    .default(false),
  point_prompts: z
    .optional(
      z.array(zFalAiSam3ImagePointPrompt).register(z.globalRegistry, {
        description: 'List of point prompts',
      }),
    )
    .default([]),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  max_masks: z
    .optional(
      z.int().gte(1).lte(32).register(z.globalRegistry, {
        description:
          'Maximum number of masks to return when `return_multiple_masks` is enabled.',
      }),
    )
    .default(3),
  include_scores: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to include mask confidence scores.',
      }),
    )
    .default(false),
  apply_mask: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Apply the mask on the image.',
      }),
    )
    .default(true),
  text_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        "[DEPRECATED] Use 'prompt' instead. Kept for backward compatibility.",
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiSam3ImageImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * MaskMetadata
 */
export const zFalAiSam3ImageMaskMetadata = z.object({
  box: z.optional(
    z.array(z.number()).register(z.globalRegistry, {
      description:
        'Bounding box for the mask in normalized cxcywh coordinates.',
    }),
  ),
  score: z.optional(
    z.number().register(z.globalRegistry, {
      description: 'Score for this mask.',
    }),
  ),
  index: z.int().register(z.globalRegistry, {
    description: 'Index of the mask inside the model output.',
  }),
})

/**
 * SAM3ImageOutput
 */
export const zSam3ImageOutput = z.object({
  image: z.optional(zFalAiSam3ImageImage),
  metadata: z.optional(
    z.array(zFalAiSam3ImageMaskMetadata).register(z.globalRegistry, {
      description: 'Per-mask metadata including scores and boxes.',
    }),
  ),
  masks: z.array(zFalAiSam3ImageImage).register(z.globalRegistry, {
    description: 'Segmented mask images.',
  }),
  scores: z.optional(
    z.array(z.number()).register(z.globalRegistry, {
      description: 'Per-mask confidence scores when requested.',
    }),
  ),
  boxes: z.optional(
    z.array(z.array(z.number())).register(z.globalRegistry, {
      description:
        'Per-mask normalized bounding boxes [cx, cy, w, h] when requested.',
    }),
  ),
})

/**
 * NanoBananaImageToImageInput
 */
export const zGemini3ProImagePreviewEditInput = z.object({
  prompt: z.string().min(3).max(50000).register(z.globalRegistry, {
    description: 'The prompt for image editing.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  enable_web_search: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Enable web search for the image generation task. This will allow the model to use the latest information from the web to generate the image.',
      }),
    )
    .default(false),
  resolution: z.optional(
    z.enum(['1K', '2K', '4K']).register(z.globalRegistry, {
      description: 'The resolution of the image to generate.',
    }),
  ),
  aspect_ratio: z.optional(
    z
      .enum([
        'auto',
        '21:9',
        '16:9',
        '3:2',
        '4:3',
        '5:4',
        '1:1',
        '4:5',
        '3:4',
        '2:3',
        '9:16',
      ])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'The URLs of the images to use for image-to-image generation or image editing.',
  }),
  limit_generations: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate.',
      }),
    )
    .default(false),
})

/**
 * ImageFile
 */
export const zFalAiGemini3ProImagePreviewEditImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * NanoBananaImageToImageOutput
 */
export const zGemini3ProImagePreviewEditOutput = z.object({
  images: z
    .array(zFalAiGemini3ProImagePreviewEditImageFile)
    .register(z.globalRegistry, {
      description: 'The edited images.',
    }),
  description: z.string().register(z.globalRegistry, {
    description: 'The description of the generated images.',
  }),
})

/**
 * NanoBananaImageToImageInput
 */
export const zNanoBananaProEditInput = z.object({
  prompt: z.string().min(3).max(50000).register(z.globalRegistry, {
    description: 'The prompt for image editing.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  enable_web_search: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Enable web search for the image generation task. This will allow the model to use the latest information from the web to generate the image.',
      }),
    )
    .default(false),
  aspect_ratio: z.optional(
    z
      .enum([
        'auto',
        '21:9',
        '16:9',
        '3:2',
        '4:3',
        '5:4',
        '1:1',
        '4:5',
        '3:4',
        '2:3',
        '9:16',
      ])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  resolution: z.optional(
    z.enum(['1K', '2K', '4K']).register(z.globalRegistry, {
      description: 'The resolution of the image to generate.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'The URLs of the images to use for image-to-image generation or image editing.',
  }),
  limit_generations: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate.',
      }),
    )
    .default(false),
})

/**
 * ImageFile
 */
export const zFalAiNanoBananaProEditImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * NanoBananaImageToImageOutput
 */
export const zNanoBananaProEditOutput = z.object({
  images: z.array(zFalAiNanoBananaProEditImageFile).register(z.globalRegistry, {
    description: 'The edited images.',
  }),
  description: z.string().register(z.globalRegistry, {
    description: 'The description of the generated images.',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEditPlusLoraGalleryMultipleAnglesImageSize =
  z.object({
    height: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The height of the generated image.',
        }),
      )
      .default(512),
    width: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The width of the generated image.',
        }),
      )
      .default(512),
  })

/**
 * MultipleAnglesInput
 *
 * Input model for Multiple Angles endpoint - Camera control with precise adjustments
 */
export const zQwenImageEditPlusLoraGalleryMultipleAnglesInput = z
  .object({
    image_size: z.optional(
      z.union([
        zFalAiQwenImageEditPlusLoraGalleryMultipleAnglesImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
        z.unknown(),
      ]),
    ),
    wide_angle_lens: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Enable wide-angle lens effect',
        }),
      )
      .default(false),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(1),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description: 'The URL of the image to adjust camera angle for.',
    }),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt for the generation',
        }),
      )
      .default(' '),
    vertical_angle: z
      .optional(
        z.number().gte(-1).lte(1).register(z.globalRegistry, {
          description:
            "Adjust vertical camera angle (-1=bird's-eye view/looking down, 0=neutral, 1=worm's-eye view/looking up)",
        }),
      )
      .default(0),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    move_forward: z
      .optional(
        z.number().gte(0).lte(10).register(z.globalRegistry, {
          description: 'Move camera forward (0=no movement, 10=close-up)',
        }),
      )
      .default(0),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    rotate_right_left: z
      .optional(
        z.number().gte(-90).lte(90).register(z.globalRegistry, {
          description:
            'Rotate camera left (positive) or right (negative) in degrees. Positive values rotate left, negative values rotate right.',
        }),
      )
      .default(0),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'The scale factor for the LoRA model. Controls the strength of the camera control effect.',
        }),
      )
      .default(1.25),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    num_inference_steps: z
      .optional(
        z.int().gte(2).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(6),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Multiple Angles endpoint - Camera control with precise adjustments',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEditPlusLoraGalleryMultipleAnglesImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * MultipleAnglesOutput
 */
export const zQwenImageEditPlusLoraGalleryMultipleAnglesOutput = z.object({
  images: z
    .array(zFalAiQwenImageEditPlusLoraGalleryMultipleAnglesImage)
    .register(z.globalRegistry, {
      description: 'The generated/edited images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEditPlusLoraGalleryShirtDesignImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * ShirtDesignInput
 *
 * Input model for Shirt Design endpoint - Put designs/graphics on people's shirts
 */
export const zQwenImageEditPlusLoraGalleryShirtDesignInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            "Describe what design to put on the shirt. The model will apply the design from your input image onto the person's shirt.",
        }),
      )
      .default('Put this design on their shirt'),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiQwenImageEditPlusLoraGalleryShirtDesignImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
        z.unknown(),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'The scale factor for the LoRA model. Controls the strength of the LoRA effect.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(1),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description:
        'The URLs of the images: first image is the person wearing a shirt, second image is the design/logo to put on the shirt.',
    }),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt for the generation',
        }),
      )
      .default(' '),
    num_inference_steps: z
      .optional(
        z.int().gte(2).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(6),
  })
  .register(z.globalRegistry, {
    description:
      "Input model for Shirt Design endpoint - Put designs/graphics on people's shirts",
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEditPlusLoraGalleryShirtDesignImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ShirtDesignOutput
 */
export const zQwenImageEditPlusLoraGalleryShirtDesignOutput = z.object({
  images: z
    .array(zFalAiQwenImageEditPlusLoraGalleryShirtDesignImage)
    .register(z.globalRegistry, {
      description: 'The generated/edited images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEditPlusLoraGalleryRemoveLightingImageSize =
  z.object({
    height: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The height of the generated image.',
        }),
      )
      .default(512),
    width: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The width of the generated image.',
        }),
      )
      .default(512),
  })

/**
 * RemoveLightingInput
 *
 * Input model for Remove Lighting endpoint - Remove existing lighting and apply soft even lighting
 */
export const zQwenImageEditPlusLoraGalleryRemoveLightingInput = z
  .object({
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiQwenImageEditPlusLoraGalleryRemoveLightingImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
        z.unknown(),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(1),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description: 'The URL of the image with lighting/shadows to remove.',
    }),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt for the generation',
        }),
      )
      .default(' '),
    num_inference_steps: z
      .optional(
        z.int().gte(2).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(6),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Remove Lighting endpoint - Remove existing lighting and apply soft even lighting',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEditPlusLoraGalleryRemoveLightingImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * RemoveLightingOutput
 */
export const zQwenImageEditPlusLoraGalleryRemoveLightingOutput = z.object({
  images: z
    .array(zFalAiQwenImageEditPlusLoraGalleryRemoveLightingImage)
    .register(z.globalRegistry, {
      description: 'The generated/edited images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEditPlusLoraGalleryRemoveElementImageSize =
  z.object({
    height: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The height of the generated image.',
        }),
      )
      .default(512),
    width: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The width of the generated image.',
        }),
      )
      .default(512),
  })

/**
 * RemoveElementInput
 *
 * Input model for Remove Element endpoint - Remove/delete elements (objects, people, text) from the image
 */
export const zQwenImageEditPlusLoraGalleryRemoveElementInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            'Specify what element(s) to remove from the image (objects, people, text, etc.). The model will cleanly remove the element while maintaining consistency of the rest of the image.',
        }),
      )
      .default('Remove the specified element from the scene'),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiQwenImageEditPlusLoraGalleryRemoveElementImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
        z.unknown(),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'The scale factor for the LoRA model. Controls the strength of the LoRA effect.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(1),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description: 'The URL of the image containing elements to remove.',
    }),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt for the generation',
        }),
      )
      .default(' '),
    num_inference_steps: z
      .optional(
        z.int().gte(2).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(6),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Remove Element endpoint - Remove/delete elements (objects, people, text) from the image',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEditPlusLoraGalleryRemoveElementImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * RemoveElementOutput
 */
export const zQwenImageEditPlusLoraGalleryRemoveElementOutput = z.object({
  images: z
    .array(zFalAiQwenImageEditPlusLoraGalleryRemoveElementImage)
    .register(z.globalRegistry, {
      description: 'The generated/edited images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEditPlusLoraGalleryNextSceneImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * NextSceneInput
 *
 * Input model for Next Scene endpoint - Create cinematic shot progressions and scene transitions
 */
export const zQwenImageEditPlusLoraGalleryNextSceneInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            "Describe the camera movement, framing change, or scene transition. Start with 'Next Scene:' for best results. Examples: camera movements (dolly, push-in, pull-back), framing changes (wide to close-up), new elements entering frame.",
        }),
      )
      .default(
        'Next Scene: The camera moves forward revealing more of the scene',
      ),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiQwenImageEditPlusLoraGalleryNextSceneImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
        z.unknown(),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'The scale factor for the LoRA model. Controls the strength of the LoRA effect.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(1),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description: 'The URL of the image to create the next scene from.',
    }),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt for the generation',
        }),
      )
      .default(' '),
    num_inference_steps: z
      .optional(
        z.int().gte(2).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(6),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Next Scene endpoint - Create cinematic shot progressions and scene transitions',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEditPlusLoraGalleryNextSceneImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * NextSceneOutput
 */
export const zQwenImageEditPlusLoraGalleryNextSceneOutput = z.object({
  images: z
    .array(zFalAiQwenImageEditPlusLoraGalleryNextSceneImage)
    .register(z.globalRegistry, {
      description: 'The generated/edited images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEditPlusLoraGalleryIntegrateProductImageSize =
  z.object({
    height: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The height of the generated image.',
        }),
      )
      .default(512),
    width: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The width of the generated image.',
        }),
      )
      .default(512),
  })

/**
 * IntegrateProductInput
 *
 * Input model for Integrate Product endpoint - Blend and integrate products/elements into backgrounds
 */
export const zQwenImageEditPlusLoraGalleryIntegrateProductInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            'Describe how to blend and integrate the product/element into the background. The model will automatically correct perspective, lighting and shadows for natural integration.',
        }),
      )
      .default('Blend and integrate the product into the background'),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiQwenImageEditPlusLoraGalleryIntegrateProductImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
        z.unknown(),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'The scale factor for the LoRA model. Controls the strength of the LoRA effect.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(1),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description:
        'The URL of the image with product to integrate into background.',
    }),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt for the generation',
        }),
      )
      .default(' '),
    num_inference_steps: z
      .optional(
        z.int().gte(2).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(6),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Integrate Product endpoint - Blend and integrate products/elements into backgrounds',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEditPlusLoraGalleryIntegrateProductImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * IntegrateProductOutput
 */
export const zQwenImageEditPlusLoraGalleryIntegrateProductOutput = z.object({
  images: z
    .array(zFalAiQwenImageEditPlusLoraGalleryIntegrateProductImage)
    .register(z.globalRegistry, {
      description: 'The generated/edited images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEditPlusLoraGalleryGroupPhotoImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * GroupPhotoInput
 *
 * Input model for Group Photo endpoint - Create composite group photos with vintage/retro style
 */
export const zQwenImageEditPlusLoraGalleryGroupPhotoInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            'Describe the group photo scene, setting, and style. The model will maintain character consistency and add vintage effects like grain, blur, and retro filters.',
        }),
      )
      .default(
        'Two people standing next to each other outside with a landscape background',
      ),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiQwenImageEditPlusLoraGalleryGroupPhotoImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
        z.unknown(),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'The scale factor for the LoRA model. Controls the strength of the LoRA effect.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(1),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description:
        'The URLs of the images to combine into a group photo. Provide 2 or more individual portrait images.',
    }),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt for the generation',
        }),
      )
      .default(' '),
    num_inference_steps: z
      .optional(
        z.int().gte(2).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(6),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Group Photo endpoint - Create composite group photos with vintage/retro style',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEditPlusLoraGalleryGroupPhotoImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * GroupPhotoOutput
 */
export const zQwenImageEditPlusLoraGalleryGroupPhotoOutput = z.object({
  images: z
    .array(zFalAiQwenImageEditPlusLoraGalleryGroupPhotoImage)
    .register(z.globalRegistry, {
      description: 'The generated/edited images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitImageSize =
  z.object({
    height: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The height of the generated image.',
        }),
      )
      .default(512),
    width: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The width of the generated image.',
        }),
      )
      .default(512),
  })

/**
 * FaceToFullPortraitInput
 *
 * Input model for Face to Full Portrait endpoint - Generate full portrait from a cropped face image
 */
export const zQwenImageEditPlusLoraGalleryFaceToFullPortraitInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            'Describe the full portrait you want to generate from the face. Include clothing, setting, pose, and style details.',
        }),
      )
      .default(
        'Photography. A portrait of the person in professional attire with natural lighting',
      ),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
        z.unknown(),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'The scale factor for the LoRA model. Controls the strength of the LoRA effect.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(1),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description:
        'The URL of the cropped face image. Provide a close-up face photo.',
    }),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt for the generation',
        }),
      )
      .default(' '),
    num_inference_steps: z
      .optional(
        z.int().gte(2).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(6),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Face to Full Portrait endpoint - Generate full portrait from a cropped face image',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FaceToFullPortraitOutput
 */
export const zQwenImageEditPlusLoraGalleryFaceToFullPortraitOutput = z.object({
  images: z
    .array(zFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitImage)
    .register(z.globalRegistry, {
      description: 'The generated/edited images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEditPlusLoraGalleryAddBackgroundImageSize =
  z.object({
    height: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The height of the generated image.',
        }),
      )
      .default(512),
    width: z
      .optional(
        z.int().lte(14142).register(z.globalRegistry, {
          description: 'The width of the generated image.',
        }),
      )
      .default(512),
  })

/**
 * AddBackgroundInput
 *
 * Input model for Add Background endpoint - Remove white background and add a realistic scene
 */
export const zQwenImageEditPlusLoraGalleryAddBackgroundInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            'Describe the background/scene you want to add behind the object. The model will remove the white background and add the specified environment.',
        }),
      )
      .default(
        'Remove white background and add a realistic scene behind the object',
      ),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiQwenImageEditPlusLoraGalleryAddBackgroundImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
        z.unknown(),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'The scale factor for the LoRA model. Controls the strength of the LoRA effect.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(1),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description:
        'The URLs of the images to edit. Provide an image with a white or clean background.',
    }),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt for the generation',
        }),
      )
      .default(' '),
    num_inference_steps: z
      .optional(
        z.int().gte(2).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(6),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Add Background endpoint - Remove white background and add a realistic scene',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEditPlusLoraGalleryAddBackgroundImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * AddBackgroundOutput
 */
export const zQwenImageEditPlusLoraGalleryAddBackgroundOutput = z.object({
  images: z
    .array(zFalAiQwenImageEditPlusLoraGalleryAddBackgroundImage)
    .register(z.globalRegistry, {
      description: 'The generated/edited images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ReveRemixInput
 *
 * Input for Reve image remixing
 */
export const zReveFastRemixInput = z
  .object({
    prompt: z.string().min(1).max(2560).register(z.globalRegistry, {
      description:
        'The text description of the desired image. May include XML img tags like <img>0</img> to refer to specific images by their index in the image_urls list.',
    }),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    aspect_ratio: z.optional(
      z
        .enum(['16:9', '9:16', '3:2', '2:3', '4:3', '3:4', '1:1'])
        .register(z.globalRegistry, {
          description:
            'The desired aspect ratio of the generated image. If not provided, will be smartly chosen by the model.',
        }),
    ),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        }),
      )
      .default(false),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description:
        'List of URLs of reference images. Must provide between 1 and 6 images (inclusive). Each image must be less than 10 MB. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.',
    }),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'Output format for the generated image.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Input for Reve image remixing',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiReveFastRemixImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ReveRemixOutput
 *
 * Output for Reve image remixing
 */
export const zReveFastRemixOutput = z
  .object({
    images: z.array(zFalAiReveFastRemixImage).register(z.globalRegistry, {
      description: 'The remixed images',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Output for Reve image remixing',
  })

/**
 * ReveFastEditInput
 *
 * Input for Reve fast image editing
 */
export const zReveFastEditInput = z
  .object({
    prompt: z.string().min(1).max(2560).register(z.globalRegistry, {
      description: 'The text description of how to edit the provided image.',
    }),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        }),
      )
      .default(false),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'Output format for the generated image.',
      }),
    ),
    image_url: z.string().register(z.globalRegistry, {
      description:
        'URL of the reference image to edit. Must be publicly accessible or base64 data URI. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Input for Reve fast image editing',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiReveFastEditImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ReveFastEditOutput
 *
 * Output for Reve fast image editing
 */
export const zReveFastEditOutput = z
  .object({
    images: z.array(zFalAiReveFastEditImage).register(z.globalRegistry, {
      description: 'The edited images',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Output for Reve fast image editing',
  })

/**
 * OutpaintInput
 */
export const zImageAppsV2OutpaintInput = z.object({
  prompt: z
    .optional(
      z.string().max(500).register(z.globalRegistry, {
        description:
          "Optional prompt to guide the outpainting. If provided, it will be appended to the base outpaint instruction. Example: 'with a beautiful sunset in the background'",
      }),
    )
    .default(''),
  expand_right: z
    .optional(
      z.int().gte(0).lte(700).register(z.globalRegistry, {
        description:
          'Number of pixels to add as black margin on the right side (0-700).',
      }),
    )
    .default(0),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'Number of images to generate.',
      }),
    )
    .default(1),
  zoom_out_percentage: z
    .optional(
      z.number().gte(0).lte(90).register(z.globalRegistry, {
        description:
          'Percentage to zoom out the image. If set, the image will be scaled down by this percentage and black margins will be added to maintain original size. Example: 50 means the image will be 50% of original size with black margins filling the rest.',
      }),
    )
    .default(20),
  output_format: z.optional(
    z.enum(['png', 'jpeg', 'jpg', 'webp']).register(z.globalRegistry, {
      description: 'The format of the output image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Image URL to outpaint',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If True, the function will wait for the image to be generated and uploaded before returning the response. If False, the function will return immediately and the image will be generated asynchronously.',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  expand_left: z
    .optional(
      z.int().gte(0).lte(700).register(z.globalRegistry, {
        description:
          'Number of pixels to add as black margin on the left side (0-700).',
      }),
    )
    .default(0),
  expand_bottom: z
    .optional(
      z.int().gte(0).lte(700).register(z.globalRegistry, {
        description:
          'Number of pixels to add as black margin on the bottom side (0-700).',
      }),
    )
    .default(400),
  expand_top: z
    .optional(
      z.int().gte(0).lte(700).register(z.globalRegistry, {
        description:
          'Number of pixels to add as black margin on the top side (0-700).',
      }),
    )
    .default(0),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2OutpaintImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * OutpaintOutput
 */
export const zImageAppsV2OutpaintOutput = z.object({
  images: z.array(zFalAiImageAppsV2OutpaintImage).register(z.globalRegistry, {
    description: 'Outpainted image with extended scene',
  }),
})

/**
 * Input
 */
export const zFluxVisionUpscalerInput = z.object({
  guidance: z
    .optional(
      z.number().gte(1).lte(4).register(z.globalRegistry, {
        description:
          'CFG/guidance scale (1-4). Controls how closely the model follows the prompt.',
      }),
    )
    .default(1),
  creativity: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The creativity of the model. The higher the creativity, the more the model will deviate from the original. Refers to the denoise strength of the sampling.',
      }),
    )
    .default(0.3),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to upscale.',
  }),
  upscale_factor: z
    .optional(
      z.number().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The upscale factor (1-4x).',
      }),
    )
    .default(2),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  steps: z
    .optional(
      z.int().gte(4).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps (4-50).',
      }),
    )
    .default(20),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFluxVisionUpscalerImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * Output
 */
export const zFluxVisionUpscalerOutput = z.object({
  image: zFalAiFluxVisionUpscalerImage,
  caption: z.string().register(z.globalRegistry, {
    description: 'The VLM-generated caption describing the upscaled image.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used to generate the image.',
  }),
  timings: z.record(z.string(), z.number()).register(z.globalRegistry, {
    description: 'The timings of the different steps in the workflow.',
  }),
})

/**
 * Emu35ImageEditInput
 */
export const zEmu35ImageEditImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to edit the image.',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description: 'The resolution of the output image.',
    }),
  ),
  aspect_ratio: z.optional(
    z
      .enum([
        'auto',
        '21:9',
        '16:9',
        '4:3',
        '3:2',
        '1:1',
        '2:3',
        '3:4',
        '9:16',
        '9:21',
      ])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the output image.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the output image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The image to edit.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to return the image in sync mode.',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the inference.',
    }),
  ),
})

/**
 * ImageFile
 */
export const zFalAiEmu35ImageEditImageImageFile = z.object({
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Emu35EditOutput
 */
export const zEmu35ImageEditImageOutput = z.object({
  images: z
    .array(zFalAiEmu35ImageEditImageImageFile)
    .register(z.globalRegistry, {
      description: 'The edited image.',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed for the inference.',
  }),
})

/**
 * ChronoEditInput
 *
 * Input model for ChronoEdit standard editing operations
 */
export const zChronoEditInput = z
  .object({
    prompt: z.string().register(z.globalRegistry, {
      description: 'The prompt to edit the image.',
    }),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description: 'The resolution of the output image.',
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable the safety checker.',
        }),
      )
      .default(true),
    output_format: z.optional(
      z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image.',
      }),
    ),
    image_url: z.string().register(z.globalRegistry, {
      description: 'The image to edit.',
    }),
    turbo_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Enable turbo mode to use for faster inference.',
        }),
      )
      .default(true),
    num_temporal_reasoning_steps: z
      .optional(
        z.int().gte(2).lte(12).register(z.globalRegistry, {
          description: 'The number of temporal reasoning steps to perform.',
        }),
      )
      .default(8),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to return the image in sync mode.',
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(10).register(z.globalRegistry, {
          description: 'The guidance scale for the inference.',
        }),
      )
      .default(1),
    num_inference_steps: z
      .optional(
        z.int().gte(2).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(8),
    enable_temporal_reasoning: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable temporal reasoning.',
        }),
      )
      .default(false),
    enable_prompt_expansion: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable prompt expansion.',
        }),
      )
      .default(true),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the inference.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Input model for ChronoEdit standard editing operations',
  })

/**
 * ImageFile
 */
export const zFalAiChronoEditImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ChronoEditOutput
 *
 * Unified output model for all ChronoEdit operations
 */
export const zChronoEditOutput = z
  .object({
    prompt: z.string().register(z.globalRegistry, {
      description: 'The prompt used for the inference.',
    }),
    images: z.array(zFalAiChronoEditImageFile).register(z.globalRegistry, {
      description: 'The edited image.',
    }),
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed for the inference.',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Unified output model for all ChronoEdit operations',
  })

/**
 * EditImageRequestMini
 */
export const zGptImage1MiniEditInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt for image generation',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'Number of images to generate',
      }),
    )
    .default(1),
  image_size: z.optional(
    z
      .enum(['auto', '1024x1024', '1536x1024', '1024x1536'])
      .register(z.globalRegistry, {
        description: 'Aspect ratio for the generated image',
      }),
  ),
  background: z.optional(
    z.enum(['auto', 'transparent', 'opaque']).register(z.globalRegistry, {
      description: 'Background for the generated image',
    }),
  ),
  quality: z.optional(
    z.enum(['auto', 'low', 'medium', 'high']).register(z.globalRegistry, {
      description: 'Quality for the generated image',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'Output format for the images',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'The URLs of the images to use as a reference for the generation.',
  }),
})

/**
 * ImageFile
 */
export const zFalAiGptImage1MiniEditImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * EditImageResponseMini
 */
export const zGptImage1MiniEditOutput = z.object({
  images: z.array(zFalAiGptImage1MiniEditImageFile).register(z.globalRegistry, {
    description: 'The generated images.',
  }),
})

/**
 * ReveRemixInput
 *
 * Input for Reve image remixing
 */
export const zReveRemixInput = z
  .object({
    prompt: z.string().min(1).max(2560).register(z.globalRegistry, {
      description:
        'The text description of the desired image. May include XML img tags like <img>0</img> to refer to specific images by their index in the image_urls list.',
    }),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    aspect_ratio: z.optional(
      z
        .enum(['16:9', '9:16', '3:2', '2:3', '4:3', '3:4', '1:1'])
        .register(z.globalRegistry, {
          description:
            'The desired aspect ratio of the generated image. If not provided, will be smartly chosen by the model.',
        }),
    ),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        }),
      )
      .default(false),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description:
        'List of URLs of reference images. Must provide between 1 and 6 images (inclusive). Each image must be less than 10 MB. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.',
    }),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'Output format for the generated image.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Input for Reve image remixing',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiReveRemixImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ReveRemixOutput
 *
 * Output for Reve image remixing
 */
export const zReveRemixOutput = z
  .object({
    images: z.array(zFalAiReveRemixImage).register(z.globalRegistry, {
      description: 'The remixed images',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Output for Reve image remixing',
  })

/**
 * ReveEditInput
 *
 * Input for Reve image editing
 */
export const zReveEditInput = z
  .object({
    prompt: z.string().min(1).max(2560).register(z.globalRegistry, {
      description: 'The text description of how to edit the provided image.',
    }),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        }),
      )
      .default(false),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'Output format for the generated image.',
      }),
    ),
    image_url: z.string().register(z.globalRegistry, {
      description:
        'URL of the reference image to edit. Must be publicly accessible or base64 data URI. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Input for Reve image editing',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiReveEditImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ReveEditOutput
 *
 * Output for Reve image editing
 */
export const zReveEditOutput = z
  .object({
    images: z.array(zFalAiReveEditImage).register(z.globalRegistry, {
      description: 'The edited images',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Output for Reve image editing',
  })

/**
 * Image2PixelInput
 */
export const zImage2PixelInput = z.object({
  cleanup_morph: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Apply morphological operations to remove noise.',
      }),
    )
    .default(false),
  auto_color_detect: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable automatic detection of optimal number of colors.',
      }),
    )
    .default(false),
  alpha_threshold: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Alpha binarization threshold (0-255).',
      }),
    )
    .default(128),
  snap_grid: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Align output to the pixel grid.',
      }),
    )
    .default(true),
  fixed_palette: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "Optional fixed color palette as hex strings (e.g., ['#000000', '#ffffff']).",
    }),
  ),
  scale: z.optional(
    z.int().gte(1).lte(64).register(z.globalRegistry, {
      description: 'Force a specific pixel scale. If None, auto-detect.',
    }),
  ),
  cleanup_jaggy: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Remove isolated diagonal pixels (jaggy edge cleanup).',
      }),
    )
    .default(false),
  trim_borders: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Trim borders of the image.',
      }),
    )
    .default(false),
  background_tolerance: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Background tolerance (0-255).',
      }),
    )
    .default(0),
  detect_method: z.optional(
    z.enum(['auto', 'runs', 'edge']).register(z.globalRegistry, {
      description: 'Scale detection method to use.',
    }),
  ),
  transparent_background: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Remove background of the image. This will check for contiguous color regions from the edges after correction and make them transparent.',
      }),
    )
    .default(false),
  downscale_method: z.optional(
    z
      .enum(['dominant', 'median', 'mode', 'mean', 'content-adaptive'])
      .register(z.globalRegistry, {
        description: 'Downscaling method to produce the pixel-art output.',
      }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The image URL to process into improved pixel art',
  }),
  background_mode: z.optional(
    z.enum(['edges', 'corners', 'midpoints']).register(z.globalRegistry, {
      description:
        'Controls where to flood-fill from when removing the background.',
    }),
  ),
  max_colors: z
    .optional(
      z.int().gte(1).lte(256).register(z.globalRegistry, {
        description:
          'Maximum number of colors in the output palette. Set None to disable limit.',
      }),
    )
    .default(32),
  dominant_color_threshold: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Dominant color threshold (0.0-1.0).',
      }),
    )
    .default(0.05),
})

/**
 * ImageFile
 */
export const zFalAiImage2PixelImageFile = z.object({
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Image2PixelOutput
 */
export const zImage2PixelOutput = z.object({
  images: z.array(zFalAiImage2PixelImageFile).register(z.globalRegistry, {
    description:
      'The processed pixel-art image (PNG) and the scaled image (PNG).',
  }),
  num_colors: z.int().register(z.globalRegistry, {
    description: 'The number of colors in the processed media.',
  }),
  palette: z.array(z.string()).register(z.globalRegistry, {
    description: 'The palette of the processed media.',
  }),
  pixel_scale: z.int().register(z.globalRegistry, {
    description: 'The detected pixel scale of the input.',
  }),
})

/**
 * DreamOmni2Request
 */
export const zDreamomni2EditInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to edit the image.',
  }),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description: 'List of URLs of input images for editing.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiDreamomni2EditImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * DreamOmni2Response
 */
export const zDreamomni2EditOutput = z.object({
  image: zFalAiDreamomni2EditImage,
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEditPlusLoraImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zFalAiQwenImageEditPlusLoraLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * BaseQwenEditImagePlusLoRAInput
 */
export const zQwenImageEditPlusLoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the image with',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiQwenImageEditPlusLoraImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description:
        "Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.",
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  loras: z
    .optional(
      z
        .array(zFalAiQwenImageEditPlusLoraLoraWeight)
        .register(z.globalRegistry, {
          description:
            '\n            The LoRAs to use for the image generation. You can use up to 3 LoRAs\n            and they will be merged together to generate the final image.\n        ',
        }),
    )
    .default([]),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(4),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description: 'The URLs of the images to edit.',
  }),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt for the generation',
      }),
    )
    .default(' '),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiQwenImageEditPlusLoraImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * QwenImageOutput
 */
export const zQwenImageEditPlusLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiQwenImageEditPlusLoraImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * LucidFluxRequest
 */
export const zLucidfluxInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to edit the image.',
  }),
  guidance: z
    .optional(
      z.number().gte(1).lte(30).register(z.globalRegistry, {
        description: 'The guidance to use for the diffusion process.',
      }),
    )
    .default(4),
  target_height: z
    .optional(
      z.int().gte(512).lte(1024).register(z.globalRegistry, {
        description: 'The height of the output image.',
      }),
    )
    .default(1024),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to edit.',
  }),
  target_width: z
    .optional(
      z.int().gte(512).lte(1024).register(z.globalRegistry, {
        description: 'The width of the output image.',
      }),
    )
    .default(1024),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(50),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Seed used for random number generation',
      }),
    )
    .default(42),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiLucidfluxImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * LucidFluxResponse
 */
export const zLucidfluxOutput = z.object({
  image: zFalAiLucidfluxImage,
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for random number generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEditImageToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * BaseQwenEditImg2ImgInput
 */
export const zQwenImageEditImageToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the image with',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiQwenImageEditImageToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        "Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.",
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to edit.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'Strength of the image-to-image transformation. Lower values preserve more of the original image.',
      }),
    )
    .default(0.94),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(4),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt for the generation',
      }),
    )
    .default(' '),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zFalAiQwenImageEditImageToImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * QwenImageOutput
 */
export const zQwenImageEditImageToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiQwenImageEditImageToImageImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiWan25PreviewImageToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * ImageToImageInput
 *
 * Input for image editing
 */
export const zWan25PreviewImageToImageInput = z
  .object({
    prompt: z.string().min(1).register(z.globalRegistry, {
      description:
        'The text prompt describing how to edit the image. Max 2000 characters.',
    }),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate. Values from 1 to 4.',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiWan25PreviewImageToImageImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
      ]),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'If set to true, the safety checker will be enabled.',
        }),
      )
      .default(true),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    ),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description:
        'URLs of images to edit. For single-image editing, provide 1 URL. For multi-reference generation, provide up to 2 URLs. If more than 2 URLs are provided, only the first 2 will be used.',
    }),
    negative_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'Negative prompt to describe content to avoid. Max 500 characters.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Input for image editing',
  })

/**
 * ImageFile
 */
export const zFalAiWan25PreviewImageToImageImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ImageToImageOutput
 *
 * Output for image editing
 */
export const zWan25PreviewImageToImageOutput = z
  .object({
    images: z
      .array(zFalAiWan25PreviewImageToImageImageFile)
      .register(z.globalRegistry, {
        description: 'The edited images',
      }),
    seeds: z.array(z.int()).register(z.globalRegistry, {
      description: 'The seeds used for each generated image',
    }),
    actual_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The original prompt (prompt expansion is not available for image editing)',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Output for image editing',
  })

/**
 * ImageSize
 */
export const zFalAiQwenImageEditPlusImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * BaseQwenEditImagePlusInput
 */
export const zQwenImageEditPlusInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the image with',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiQwenImageEditPlusImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description:
        "Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.",
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(4),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description: 'The URLs of the images to edit.',
  }),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt for the generation',
      }),
    )
    .default(' '),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(100).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(50),
})

/**
 * Image
 */
export const zFalAiQwenImageEditPlusImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * QwenImageOutput
 */
export const zQwenImageEditPlusOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiQwenImageEditPlusImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * SeedVRImageInput
 */
export const zSeedvrUpscaleImageInput = z.object({
  upscale_mode: z.optional(
    z.enum(['target', 'factor']).register(z.globalRegistry, {
      description:
        "The mode to use for the upscale. If 'target', the upscale factor will be calculated based on the target resolution. If 'factor', the upscale factor will be used directly.",
    }),
  ),
  noise_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The noise scale to use for the generation process.',
      }),
    )
    .default(0.1),
  target_resolution: z.optional(
    z.enum(['720p', '1080p', '1440p', '2160p']).register(z.globalRegistry, {
      description:
        'The target resolution to upscale to when `upscale_mode` is `target`.',
    }),
  ),
  output_format: z.optional(
    z.enum(['png', 'jpg', 'webp']).register(z.globalRegistry, {
      description: 'The format of the output image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The input image to be processed',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  upscale_factor: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Upscaling factor to be used. Will multiply the dimensions with this factor when `upscale_mode` is `factor`.',
      }),
    )
    .default(2),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The random seed used for the generation process.',
    }),
  ),
})

/**
 * ImageFile
 */
export const zFalAiSeedvrUpscaleImageImageFile = z.object({
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * SeedVRImageOutput
 */
export const zSeedvrUpscaleImageOutput = z.object({
  image: zFalAiSeedvrUpscaleImageImageFile,
  seed: z.int().register(z.globalRegistry, {
    description: 'The random seed used for the generation process.',
  }),
})

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zAspectRatio = z
  .object({
    ratio: z.optional(
      z.enum(['1:1', '16:9', '9:16', '4:3', '3:4']).register(z.globalRegistry, {
        description: 'Aspect ratio for 4K resolution output',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Aspect ratio model that calculates 4K resolution dimensions',
  })

/**
 * ProductHoldingInput
 */
export const zImageAppsV2ProductHoldingInput = z.object({
  aspect_ratio: z.optional(zAspectRatio),
  product_image_url: z.string().register(z.globalRegistry, {
    description: 'Image URL of the product to be held by the person',
  }),
  person_image_url: z.string().register(z.globalRegistry, {
    description: 'Image URL of the person who will hold the product',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2ProductHoldingImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ProductHoldingOutput
 */
export const zImageAppsV2ProductHoldingOutput = z.object({
  images: z
    .array(zFalAiImageAppsV2ProductHoldingImage)
    .register(z.globalRegistry, {
      description: 'Person holding the product naturally',
    }),
  inference_time_ms: z.int().register(z.globalRegistry, {
    description: 'Total inference time in milliseconds',
  }),
})

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2ProductPhotographyAspectRatio = z
  .object({
    ratio: z.optional(
      z.enum(['1:1', '16:9', '9:16', '4:3', '3:4']).register(z.globalRegistry, {
        description: 'Aspect ratio for 4K resolution output',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Aspect ratio model that calculates 4K resolution dimensions',
  })

/**
 * ProductPhotographyInput
 */
export const zImageAppsV2ProductPhotographyInput = z.object({
  aspect_ratio: z.optional(zFalAiImageAppsV2ProductPhotographyAspectRatio),
  product_image_url: z.string().register(z.globalRegistry, {
    description:
      'Image URL of the product to create professional studio photography',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2ProductPhotographyImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ProductPhotographyOutput
 */
export const zImageAppsV2ProductPhotographyOutput = z.object({
  images: z
    .array(zFalAiImageAppsV2ProductPhotographyImage)
    .register(z.globalRegistry, {
      description: 'Professional studio product photography',
    }),
  inference_time_ms: z.int().register(z.globalRegistry, {
    description: 'Total inference time in milliseconds',
  }),
})

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2VirtualTryOnAspectRatio = z
  .object({
    ratio: z.optional(
      z.enum(['1:1', '16:9', '9:16', '4:3', '3:4']).register(z.globalRegistry, {
        description: 'Aspect ratio for 4K resolution output',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Aspect ratio model that calculates 4K resolution dimensions',
  })

/**
 * VirtualTryOnInput
 */
export const zImageAppsV2VirtualTryOnInput = z.object({
  preserve_pose: z.optional(z.boolean()).default(true),
  aspect_ratio: z.optional(zFalAiImageAppsV2VirtualTryOnAspectRatio),
  clothing_image_url: z.string().register(z.globalRegistry, {
    description: 'Clothing photo URL',
  }),
  person_image_url: z.string().register(z.globalRegistry, {
    description: 'Person photo URL',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2VirtualTryOnImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * VirtualTryOnOutput
 */
export const zImageAppsV2VirtualTryOnOutput = z.object({
  images: z
    .array(zFalAiImageAppsV2VirtualTryOnImage)
    .register(z.globalRegistry, {
      description: 'Person wearing the virtual clothing',
    }),
  inference_time_ms: z.int().register(z.globalRegistry, {
    description: 'Total inference time in milliseconds',
  }),
})

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2TextureTransformAspectRatio = z
  .object({
    ratio: z.optional(
      z.enum(['1:1', '16:9', '9:16', '4:3', '3:4']).register(z.globalRegistry, {
        description: 'Aspect ratio for 4K resolution output',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Aspect ratio model that calculates 4K resolution dimensions',
  })

/**
 * TextureTransformInput
 */
export const zImageAppsV2TextureTransformInput = z.object({
  target_texture: z.optional(
    z.enum([
      'cotton',
      'denim',
      'wool',
      'felt',
      'wood',
      'leather',
      'velvet',
      'stone',
      'marble',
      'ceramic',
      'concrete',
      'brick',
      'clay',
      'foam',
      'glass',
      'metal',
      'silk',
      'fabric',
      'crystal',
      'rubber',
      'plastic',
      'lace',
    ]),
  ),
  aspect_ratio: z.optional(zFalAiImageAppsV2TextureTransformAspectRatio),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Image URL for texture transformation',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2TextureTransformImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * TextureTransformOutput
 */
export const zImageAppsV2TextureTransformOutput = z.object({
  images: z
    .array(zFalAiImageAppsV2TextureTransformImage)
    .register(z.globalRegistry, {
      description: 'Image with transformed texture',
    }),
  inference_time_ms: z.int().register(z.globalRegistry, {
    description: 'Total inference time in milliseconds',
  }),
})

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2RelightingAspectRatio = z
  .object({
    ratio: z.optional(
      z.enum(['1:1', '16:9', '9:16', '4:3', '3:4']).register(z.globalRegistry, {
        description: 'Aspect ratio for 4K resolution output',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Aspect ratio model that calculates 4K resolution dimensions',
  })

/**
 * RelightingInput
 */
export const zImageAppsV2RelightingInput = z.object({
  aspect_ratio: z.optional(zFalAiImageAppsV2RelightingAspectRatio),
  lighting_style: z.optional(
    z.enum([
      'natural',
      'studio',
      'golden_hour',
      'blue_hour',
      'dramatic',
      'soft',
      'hard',
      'backlight',
      'side_light',
      'front_light',
      'rim_light',
      'sunset',
      'sunrise',
      'neon',
      'candlelight',
      'moonlight',
      'spotlight',
      'ambient',
    ]),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Image URL for relighting',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2RelightingImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * RelightingOutput
 */
export const zImageAppsV2RelightingOutput = z.object({
  images: z.array(zFalAiImageAppsV2RelightingImage).register(z.globalRegistry, {
    description: 'Image with new lighting',
  }),
  inference_time_ms: z.int().register(z.globalRegistry, {
    description: 'Total inference time in milliseconds',
  }),
})

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2StyleTransferAspectRatio = z
  .object({
    ratio: z.optional(
      z.enum(['1:1', '16:9', '9:16', '4:3', '3:4']).register(z.globalRegistry, {
        description: 'Aspect ratio for 4K resolution output',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Aspect ratio model that calculates 4K resolution dimensions',
  })

/**
 * StyleTransferInput
 */
export const zImageAppsV2StyleTransferInput = z.object({
  target_style: z.optional(
    z.enum([
      'anime_character',
      'cartoon_3d',
      'hand_drawn_animation',
      'cyberpunk_future',
      'anime_game_style',
      'comic_book_animation',
      'animated_series',
      'cartoon_animation',
      'lofi_aesthetic',
      'cottagecore',
      'dark_academia',
      'y2k',
      'vaporwave',
      'liminal_space',
      'weirdcore',
      'dreamcore',
      'synthwave',
      'outrun',
      'photorealistic',
      'hyperrealistic',
      'digital_art',
      'concept_art',
      'impressionist',
      'anime',
      'pixel_art',
      'claymation',
    ]),
  ),
  aspect_ratio: z.optional(zFalAiImageAppsV2StyleTransferAspectRatio),
  style_reference_image_url: z.optional(z.union([z.string(), z.unknown()])),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Image URL for style transfer',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2StyleTransferImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * StyleTransferOutput
 */
export const zImageAppsV2StyleTransferOutput = z.object({
  images: z
    .array(zFalAiImageAppsV2StyleTransferImage)
    .register(z.globalRegistry, {
      description: 'Image with transferred style',
    }),
  inference_time_ms: z.int().register(z.globalRegistry, {
    description: 'Total inference time in milliseconds',
  }),
})

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2PhotoRestorationAspectRatio = z
  .object({
    ratio: z.optional(
      z.enum(['1:1', '16:9', '9:16', '4:3', '3:4']).register(z.globalRegistry, {
        description: 'Aspect ratio for 4K resolution output',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Aspect ratio model that calculates 4K resolution dimensions',
  })

/**
 * PhotoRestorationInput
 */
export const zImageAppsV2PhotoRestorationInput = z.object({
  enhance_resolution: z.optional(z.boolean()).default(true),
  aspect_ratio: z.optional(zFalAiImageAppsV2PhotoRestorationAspectRatio),
  remove_scratches: z.optional(z.boolean()).default(true),
  fix_colors: z.optional(z.boolean()).default(true),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Old or damaged photo URL to restore',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2PhotoRestorationImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * PhotoRestorationOutput
 */
export const zImageAppsV2PhotoRestorationOutput = z.object({
  images: z
    .array(zFalAiImageAppsV2PhotoRestorationImage)
    .register(z.globalRegistry, {
      description: 'Restored photo',
    }),
  inference_time_ms: z.int().register(z.globalRegistry, {
    description: 'Total inference time in milliseconds',
  }),
})

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2PortraitEnhanceAspectRatio = z
  .object({
    ratio: z.optional(
      z.enum(['1:1', '16:9', '9:16', '4:3', '3:4']).register(z.globalRegistry, {
        description: 'Aspect ratio for 4K resolution output',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Aspect ratio model that calculates 4K resolution dimensions',
  })

/**
 * PortraitInput
 */
export const zImageAppsV2PortraitEnhanceInput = z.object({
  aspect_ratio: z.optional(zFalAiImageAppsV2PortraitEnhanceAspectRatio),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Portrait image URL to enhance',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2PortraitEnhanceImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * PortraitOutput
 */
export const zImageAppsV2PortraitEnhanceOutput = z.object({
  images: z
    .array(zFalAiImageAppsV2PortraitEnhanceImage)
    .register(z.globalRegistry, {
      description: 'Enhanced portrait',
    }),
  inference_time_ms: z.int().register(z.globalRegistry, {
    description: 'Total inference time in milliseconds',
  }),
})

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2PhotographyEffectsAspectRatio = z
  .object({
    ratio: z.optional(
      z.enum(['1:1', '16:9', '9:16', '4:3', '3:4']).register(z.globalRegistry, {
        description: 'Aspect ratio for 4K resolution output',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Aspect ratio model that calculates 4K resolution dimensions',
  })

/**
 * PhotographyEffectsInput
 */
export const zImageAppsV2PhotographyEffectsInput = z.object({
  effect_type: z.optional(
    z.enum([
      'film',
      'vintage_film',
      'portrait_photography',
      'fashion_photography',
      'street_photography',
      'sepia_tone',
      'film_grain',
      'light_leaks',
      'vignette_effect',
      'instant_camera',
      'golden_hour',
      'dramatic_lighting',
      'soft_focus',
      'bokeh_effect',
      'high_contrast',
      'double_exposure',
    ]),
  ),
  aspect_ratio: z.optional(zFalAiImageAppsV2PhotographyEffectsAspectRatio),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Image URL for photography effects',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2PhotographyEffectsImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * PhotographyEffectsOutput
 */
export const zImageAppsV2PhotographyEffectsOutput = z.object({
  images: z
    .array(zFalAiImageAppsV2PhotographyEffectsImage)
    .register(z.globalRegistry, {
      description: 'Image with photography effects',
    }),
  inference_time_ms: z.int().register(z.globalRegistry, {
    description: 'Total inference time in milliseconds',
  }),
})

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2PerspectiveAspectRatio = z
  .object({
    ratio: z.optional(
      z.enum(['1:1', '16:9', '9:16', '4:3', '3:4']).register(z.globalRegistry, {
        description: 'Aspect ratio for 4K resolution output',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Aspect ratio model that calculates 4K resolution dimensions',
  })

/**
 * PerspectiveInput
 */
export const zImageAppsV2PerspectiveInput = z.object({
  aspect_ratio: z.optional(zFalAiImageAppsV2PerspectiveAspectRatio),
  target_perspective: z.optional(
    z.enum([
      'front',
      'left_side',
      'right_side',
      'back',
      'top_down',
      'bottom_up',
      'birds_eye',
      'three_quarter_left',
      'three_quarter_right',
    ]),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Image URL for perspective change',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2PerspectiveImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * PerspectiveOutput
 */
export const zImageAppsV2PerspectiveOutput = z.object({
  images: z
    .array(zFalAiImageAppsV2PerspectiveImage)
    .register(z.globalRegistry, {
      description: 'Image with changed perspective',
    }),
  inference_time_ms: z.int().register(z.globalRegistry, {
    description: 'Total inference time in milliseconds',
  }),
})

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2ObjectRemovalAspectRatio = z
  .object({
    ratio: z.optional(
      z.enum(['1:1', '16:9', '9:16', '4:3', '3:4']).register(z.globalRegistry, {
        description: 'Aspect ratio for 4K resolution output',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Aspect ratio model that calculates 4K resolution dimensions',
  })

/**
 * ObjectRemovalInput
 */
export const zImageAppsV2ObjectRemovalInput = z.object({
  aspect_ratio: z.optional(zFalAiImageAppsV2ObjectRemovalAspectRatio),
  object_to_remove: z.string().register(z.globalRegistry, {
    description: 'Object to remove',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Image URL containing object to remove',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2ObjectRemovalImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ObjectRemovalOutput
 */
export const zImageAppsV2ObjectRemovalOutput = z.object({
  images: z
    .array(zFalAiImageAppsV2ObjectRemovalImage)
    .register(z.globalRegistry, {
      description: 'Image with object removed',
    }),
  inference_time_ms: z.int().register(z.globalRegistry, {
    description: 'Total inference time in milliseconds',
  }),
})

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2HeadshotPhotoAspectRatio = z
  .object({
    ratio: z.optional(
      z.enum(['1:1', '16:9', '9:16', '4:3', '3:4']).register(z.globalRegistry, {
        description: 'Aspect ratio for 4K resolution output',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Aspect ratio model that calculates 4K resolution dimensions',
  })

/**
 * HeadshotInput
 */
export const zImageAppsV2HeadshotPhotoInput = z.object({
  aspect_ratio: z.optional(zFalAiImageAppsV2HeadshotPhotoAspectRatio),
  background_style: z.optional(
    z.enum(['professional', 'corporate', 'clean', 'gradient']),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Portrait image URL to convert to professional headshot',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2HeadshotPhotoImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * HeadshotOutput
 */
export const zImageAppsV2HeadshotPhotoOutput = z.object({
  images: z
    .array(zFalAiImageAppsV2HeadshotPhotoImage)
    .register(z.globalRegistry, {
      description: 'Professional headshot image',
    }),
  inference_time_ms: z.int().register(z.globalRegistry, {
    description: 'Total inference time in milliseconds',
  }),
})

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2HairChangeAspectRatio = z
  .object({
    ratio: z.optional(
      z.enum(['1:1', '16:9', '9:16', '4:3', '3:4']).register(z.globalRegistry, {
        description: 'Aspect ratio for 4K resolution output',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Aspect ratio model that calculates 4K resolution dimensions',
  })

/**
 * HairChangeInput
 */
export const zImageAppsV2HairChangeInput = z.object({
  target_hairstyle: z.optional(
    z.enum([
      'short_hair',
      'medium_long_hair',
      'long_hair',
      'curly_hair',
      'wavy_hair',
      'high_ponytail',
      'bun',
      'bob_cut',
      'pixie_cut',
      'braids',
      'straight_hair',
      'afro',
      'dreadlocks',
      'buzz_cut',
      'mohawk',
      'bangs',
      'side_part',
      'middle_part',
    ]),
  ),
  aspect_ratio: z.optional(zFalAiImageAppsV2HairChangeAspectRatio),
  hair_color: z.optional(
    z.enum([
      'black',
      'dark_brown',
      'light_brown',
      'blonde',
      'platinum_blonde',
      'red',
      'auburn',
      'gray',
      'silver',
      'blue',
      'green',
      'purple',
      'pink',
      'rainbow',
      'natural',
      'highlights',
      'ombre',
      'balayage',
    ]),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Portrait image URL for hair change',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2HairChangeImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * HairChangeOutput
 */
export const zImageAppsV2HairChangeOutput = z.object({
  images: z.array(zFalAiImageAppsV2HairChangeImage).register(z.globalRegistry, {
    description: 'Portrait with changed hair',
  }),
  inference_time_ms: z.int().register(z.globalRegistry, {
    description: 'Total inference time in milliseconds',
  }),
})

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2ExpressionChangeAspectRatio = z
  .object({
    ratio: z.optional(
      z.enum(['1:1', '16:9', '9:16', '4:3', '3:4']).register(z.globalRegistry, {
        description: 'Aspect ratio for 4K resolution output',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Aspect ratio model that calculates 4K resolution dimensions',
  })

/**
 * ExpressionChangeInput
 */
export const zImageAppsV2ExpressionChangeInput = z.object({
  aspect_ratio: z.optional(zFalAiImageAppsV2ExpressionChangeAspectRatio),
  target_expression: z.optional(
    z.enum([
      'smile',
      'surprise',
      'glare',
      'panic',
      'shyness',
      'laugh',
      'cry',
      'angry',
      'sad',
      'happy',
      'excited',
      'shocked',
      'confused',
      'focused',
      'dreamy',
      'serious',
      'playful',
      'mysterious',
      'confident',
      'thoughtful',
    ]),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Portrait image URL for expression change',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2ExpressionChangeImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ExpressionChangeOutput
 */
export const zImageAppsV2ExpressionChangeOutput = z.object({
  images: z
    .array(zFalAiImageAppsV2ExpressionChangeImage)
    .register(z.globalRegistry, {
      description: 'Portrait with changed expression',
    }),
  inference_time_ms: z.int().register(z.globalRegistry, {
    description: 'Total inference time in milliseconds',
  }),
})

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2CityTeleportAspectRatio = z
  .object({
    ratio: z.optional(
      z.enum(['1:1', '16:9', '9:16', '4:3', '3:4']).register(z.globalRegistry, {
        description: 'Aspect ratio for 4K resolution output',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Aspect ratio model that calculates 4K resolution dimensions',
  })

/**
 * CityTeleportInput
 */
export const zImageAppsV2CityTeleportInput = z.object({
  city_image_url: z.optional(z.union([z.string(), z.unknown()])),
  aspect_ratio: z.optional(zFalAiImageAppsV2CityTeleportAspectRatio),
  city_name: z.string().register(z.globalRegistry, {
    description: 'City name (used when city_image_url is not provided)',
  }),
  photo_shot: z.optional(
    z
      .enum([
        'extreme_close_up',
        'close_up',
        'medium_close_up',
        'medium_shot',
        'medium_long_shot',
        'long_shot',
        'extreme_long_shot',
        'full_body',
      ])
      .register(z.globalRegistry, {
        description: 'Type of photo shot',
      }),
  ),
  camera_angle: z.optional(
    z
      .enum([
        'eye_level',
        'low_angle',
        'high_angle',
        'dutch_angle',
        'birds_eye_view',
        'worms_eye_view',
        'overhead',
        'side_angle',
      ])
      .register(z.globalRegistry, {
        description: 'Camera angle for the shot',
      }),
  ),
  person_image_url: z.string().register(z.globalRegistry, {
    description: 'Person photo URL',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2CityTeleportImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * CityTeleportOutput
 */
export const zImageAppsV2CityTeleportOutput = z.object({
  images: z
    .array(zFalAiImageAppsV2CityTeleportImage)
    .register(z.globalRegistry, {
      description: 'Person teleported to city location',
    }),
  inference_time_ms: z.int().register(z.globalRegistry, {
    description: 'Total inference time in milliseconds',
  }),
})

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2AgeModifyAspectRatio = z
  .object({
    ratio: z.optional(
      z.enum(['1:1', '16:9', '9:16', '4:3', '3:4']).register(z.globalRegistry, {
        description: 'Aspect ratio for 4K resolution output',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Aspect ratio model that calculates 4K resolution dimensions',
  })

/**
 * AgeModifyInput
 */
export const zImageAppsV2AgeModifyInput = z.object({
  image_url: z.string().register(z.globalRegistry, {
    description: 'Portrait image URL for age modification',
  }),
  aspect_ratio: z.optional(zFalAiImageAppsV2AgeModifyAspectRatio),
  preserve_identity: z.optional(z.boolean()).default(true),
  target_age: z.optional(z.int().gte(6).lte(100)).default(30),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2AgeModifyImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * AgeModifyOutput
 */
export const zImageAppsV2AgeModifyOutput = z.object({
  images: z.array(zFalAiImageAppsV2AgeModifyImage).register(z.globalRegistry, {
    description: 'Portrait with modified age',
  }),
  inference_time_ms: z.int().register(z.globalRegistry, {
    description: 'Total inference time in milliseconds',
  }),
})

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2MakeupApplicationAspectRatio = z
  .object({
    ratio: z.optional(
      z.enum(['1:1', '16:9', '9:16', '4:3', '3:4']).register(z.globalRegistry, {
        description: 'Aspect ratio for 4K resolution output',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Aspect ratio model that calculates 4K resolution dimensions',
  })

/**
 * MakeupApplicationInput
 */
export const zImageAppsV2MakeupApplicationInput = z.object({
  aspect_ratio: z.optional(zFalAiImageAppsV2MakeupApplicationAspectRatio),
  intensity: z.optional(z.enum(['light', 'medium', 'heavy', 'dramatic'])),
  makeup_style: z.optional(
    z.enum([
      'natural',
      'glamorous',
      'smoky_eyes',
      'bold_lips',
      'no_makeup',
      'remove_makeup',
      'dramatic',
      'bridal',
      'professional',
      'korean_style',
      'artistic',
    ]),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Portrait image URL for makeup application',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2MakeupApplicationImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * MakeupApplicationOutput
 */
export const zImageAppsV2MakeupApplicationOutput = z.object({
  images: z
    .array(zFalAiImageAppsV2MakeupApplicationImage)
    .register(z.globalRegistry, {
      description: 'Portrait with applied makeup',
    }),
  inference_time_ms: z.int().register(z.globalRegistry, {
    description: 'Total inference time in milliseconds',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEditInpaintImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * BaseQwenEditInpaintImageInput
 */
export const zQwenImageEditInpaintInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the image with',
  }),
  image_size: z.optional(
    z.union([
      zFalAiQwenImageEditInpaintImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        "Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.",
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(4),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt for the generation',
      }),
    )
    .default(' '),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to edit.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description: 'Strength of noising process for inpainting',
      }),
    )
    .default(0.93),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  mask_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the mask for inpainting',
  }),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(30),
})

/**
 * Image
 */
export const zFalAiQwenImageEditInpaintImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * QwenImageInpaintOutput
 */
export const zQwenImageEditInpaintOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiQwenImageEditInpaintImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * BaseSRPOImageToInput
 */
export const zFluxSrpoImageToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        'The speed of the generation. The higher the speed, the faster the generation.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to generate an image from.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the initial image. Higher strength values are better for this model.',
      }),
    )
    .default(0.95),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ',
      }),
    )
    .default(4.5),
  num_inference_steps: z
    .optional(
      z.int().gte(10).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(40),
})

/**
 * Image
 */
export const zFalAiFluxSrpoImageToImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxSrpoImageToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFluxSrpoImageToImageImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * BaseSRPOFlux1ImageToInput
 */
export const zFlux1SrpoImageToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        'The speed of the generation. The higher the speed, the faster the generation.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to generate an image from.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the initial image. Higher strength values are better for this model.',
      }),
    )
    .default(0.95),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(10).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(40),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ',
      }),
    )
    .default(4.5),
})

/**
 * Image
 */
export const zFalAiFlux1SrpoImageToImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFlux1SrpoImageToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFlux1SrpoImageToImageImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEditLoraImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zFalAiQwenImageEditLoraLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * BaseQwenEditImageLoRAInput
 */
export const zQwenImageEditLoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the image with',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiQwenImageEditLoraImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        "Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.",
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to edit.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zFalAiQwenImageEditLoraLoraWeight).register(z.globalRegistry, {
        description:
          '\n            The LoRAs to use for the image generation. You can use up to 3 LoRAs\n            and they will be merged together to generate the final image.\n        ',
      }),
    )
    .default([]),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(4),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt for the generation',
      }),
    )
    .default(' '),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zFalAiQwenImageEditLoraImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * QwenImageOutput
 */
export const zQwenImageEditLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiQwenImageEditLoraImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ReferenceToImageRequest
 */
export const zViduReferenceToImageInput = z.object({
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text prompt for video generation, max 1500 characters',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the output video',
    }),
  ),
  reference_image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'URLs of the reference images to use for consistent subject appearance',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiViduReferenceToImageImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ReferenceToImageOutput
 */
export const zViduReferenceToImageOutput = z.object({
  image: zFalAiViduReferenceToImageImage,
})

/**
 * ImageSize
 */
export const zFalAiBytedanceSeedreamV4EditImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * SeedDream4EditInput
 */
export const zBytedanceSeedreamV4EditInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt used to edit the image',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(6).register(z.globalRegistry, {
        description:
          'Number of separate model generations to be run with the prompt.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiBytedanceSeedreamV4EditImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
        'auto',
        'auto_2K',
        'auto_4K',
      ]),
    ]),
  ),
  enhance_prompt_mode: z.optional(
    z.enum(['standard', 'fast']).register(z.globalRegistry, {
      description:
        'The mode to use for enhancing prompt enhancement. Standard mode provides higher quality results but takes longer to generate. Fast mode provides average quality results but takes less time to generate.',
    }),
  ),
  max_images: z
    .optional(
      z.int().gte(1).lte(6).register(z.globalRegistry, {
        description:
          'If set to a number greater than one, enables multi-image generation. The model will potentially return up to `max_images` images every generation, and in total, `num_images` generations will be carried out. In total, the number of images generated will be between `num_images` and `max_images*num_images`. The total number of images (image inputs + image outputs) must not exceed 15',
      }),
    )
    .default(1),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed to control the stochasticity of image generation.',
    }),
  ),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'List of URLs of input images for editing. Presently, up to 10 image inputs are allowed. If over 10 images are sent, only the last 10 will be used.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBytedanceSeedreamV4EditImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * SeedDream4EditOutput
 */
export const zBytedanceSeedreamV4EditOutput = z.object({
  images: z
    .array(zFalAiBytedanceSeedreamV4EditImage)
    .register(z.globalRegistry, {
      description: 'Generated images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiWanV22A14bImageToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * WanI2IRequest
 */
export const zWanV22A14bImageToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide image generation.',
  }),
  shift: z.optional(z.number().gte(1).lte(10)).default(2),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  image_size: z.optional(
    z.union([
      zFalAiWanV22A14bImageToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
      z.unknown(),
    ]),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Classifier-free guidance scale.',
      }),
    )
    .default(3.5),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, input data will be checked for safety before processing.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(''),
  image_format: z.optional(
    z.enum(['png', 'jpeg']).register(z.globalRegistry, {
      description: 'The format of the output image.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated image. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, output video will be checked for safety after generation.',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input image.',
  }),
  strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Denoising strength. 1.0 = fully remake; 0.0 = preserve original.',
      }),
    )
    .default(0.5),
  guidance_scale_2: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.',
      }),
    )
    .default(4),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(27),
})

/**
 * File
 */
export const zFalAiWanV22A14bImageToImageFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * WanI2IResponse
 */
export const zWanV22A14bImageToImageOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The text prompt used for image generation.',
      }),
    )
    .default(''),
  image: zFalAiWanV22A14bImageToImageFile,
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
})

/**
 * ImageSize
 */
export const zFalAiUsoImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * USOInputImage
 */
export const zUsoInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Text prompt for generation. Can be empty for pure style transfer.',
      }),
    )
    .default(''),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'Number of images to generate in parallel.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiUsoImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description:
        'Output image format. PNG preserves transparency, JPEG is smaller.',
    }),
  ),
  keep_size: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Preserve the layout and dimensions of the input content image. Useful for style transfer.',
      }),
    )
    .default(false),
  input_image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'List of image URLs in order: [content_image, style_image, extra_style_image].',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, wait for generation and upload before returning. Increases latency but provides immediate access to images.',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'How closely to follow the prompt. Higher values stick closer to the prompt.',
      }),
    )
    .default(4),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description:
          'Number of denoising steps. More steps can improve quality but increase generation time.',
      }),
    )
    .default(28),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducible generation. Use same seed for consistent results.',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "What you don't want in the image. Use it to exclude unwanted elements, styles, or artifacts.",
      }),
    )
    .default(''),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable NSFW content detection and filtering.',
      }),
    )
    .default(true),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiUsoImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * USOOutputImage
 */
export const zUsoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation',
  }),
  images: z.array(zFalAiUsoImage).register(z.globalRegistry, {
    description:
      'The generated images with applied style and/or subject customization',
  }),
  timings: z.record(z.string(), z.unknown()).register(z.globalRegistry, {
    description: 'Performance timings for different stages',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'NSFW detection results for each generated image',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generation',
  }),
})

/**
 * NanoBananaImageToImageInput
 */
export const zGemini25FlashImageEditInput = z.object({
  prompt: z.string().min(3).max(50000).register(z.globalRegistry, {
    description: 'The prompt for image editing.',
  }),
  aspect_ratio: z.optional(
    z
      .enum([
        'auto',
        '21:9',
        '16:9',
        '3:2',
        '4:3',
        '5:4',
        '1:1',
        '4:5',
        '3:4',
        '2:3',
        '9:16',
      ])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'The URLs of the images to use for image-to-image generation or image editing.',
  }),
  limit_generations: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate.',
      }),
    )
    .default(false),
})

/**
 * ImageFile
 */
export const zFalAiGemini25FlashImageEditImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * NanoBananaImageToImageOutput
 */
export const zGemini25FlashImageEditOutput = z.object({
  images: z
    .array(zFalAiGemini25FlashImageEditImageFile)
    .register(z.globalRegistry, {
      description: 'The edited images.',
    }),
  description: z.string().register(z.globalRegistry, {
    description: 'The description of the generated images.',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageImageToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zFalAiQwenImageImageToImageLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * QwenImageI2IInput
 */
export const zQwenImageImageToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the image with',
  }),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        "Acceleration level for image generation. Options: 'none', 'regular', 'high'. Higher acceleration increases speed. 'regular' balances speed and quality. 'high' is recommended for images without text.",
    }),
  ),
  image_size: z.optional(
    z.union([
      zFalAiQwenImageImageToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  loras: z
    .optional(
      z
        .array(zFalAiQwenImageImageToImageLoraWeight)
        .register(z.globalRegistry, {
          description:
            '\n            The LoRAs to use for the image generation. You can use up to 3 LoRAs\n            and they will be merged together to generate the final image.\n        ',
        }),
    )
    .default([]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(2.5),
  use_turbo: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Enable turbo mode for faster generation with high quality. When enabled, uses optimized settings (10 steps, CFG=1.2).',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt for the generation',
      }),
    )
    .default(' '),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The reference image to guide the generation.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Denoising strength. 1.0 = fully remake; 0.0 = preserve original.',
      }),
    )
    .default(0.6),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(250).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiQwenImageImageToImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * QwenImageI2IOutput
 */
export const zQwenImageImageToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiQwenImageImageToImageImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * InputModel
 */
export const zReimagine32Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Prompt for image generation.',
  }),
  depth_preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Depth image preprocess.',
      }),
    )
    .default(true),
  canny_preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Canny image preprocess.',
      }),
    )
    .default(true),
  depth_image_url: z.optional(z.union([z.string(), z.unknown()])),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Guidance scale for text.',
      }),
    )
    .default(5),
  canny_image_url: z.optional(z.union([z.string(), z.unknown()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for image generation.',
      }),
    )
    .default(
      'Logo,Watermark,Ugly,Morbid,Extra fingers,Poorly drawn hands,Mutation,Blurry,Extra limbs,Gross proportions,Missing arms,Mutated hands,Long neck,Duplicate,Mutilated,Mutilated hands,Poorly drawn face,Deformed,Bad anatomy,Cloned face,Malformed limbs,Missing legs,Too many fingers',
    ),
  depth_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Depth control strength (0.0 to 1.0).',
      }),
    )
    .default(0.5),
  aspect_ratio: z.optional(
    z
      .enum(['1:1', '2:3', '3:2', '3:4', '4:3', '4:5', '5:4', '9:16', '16:9'])
      .register(z.globalRegistry, {
        description:
          'Aspect ratio. Options: 1:1, 2:3, 3:2, 3:4, 4:3, 4:5, 5:4, 9:16, 16:9',
      }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, returns the image directly in the response (increases latency).',
      }),
    )
    .default(false),
  prompt_enhancer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to improve the prompt.',
      }),
    )
    .default(true),
  truncate_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to truncate the prompt.',
      }),
    )
    .default(true),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Random seed for reproducibility.',
      }),
    )
    .default(5555),
  canny_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Canny edge control strength (0.0 to 1.0).',
      }),
    )
    .default(0.5),
  num_inference_steps: z
    .optional(
      z.int().gte(20).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps.',
      }),
    )
    .default(30),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaReimagine32Image = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * OutputModel
 */
export const zReimagine32Output = z.object({
  image: zBriaReimagine32Image,
})

/**
 * NanoBananaImageToImageInput
 */
export const zNanoBananaEditInput = z.object({
  prompt: z.string().min(3).max(50000).register(z.globalRegistry, {
    description: 'The prompt for image editing.',
  }),
  aspect_ratio: z.optional(
    z
      .enum([
        'auto',
        '21:9',
        '16:9',
        '3:2',
        '4:3',
        '5:4',
        '1:1',
        '4:5',
        '3:4',
        '2:3',
        '9:16',
      ])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'The URLs of the images to use for image-to-image generation or image editing.',
  }),
  limit_generations: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate.',
      }),
    )
    .default(false),
})

/**
 * ImageFile
 */
export const zFalAiNanoBananaEditImageFile = z.object({
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * NanoBananaImageToImageOutput
 */
export const zNanoBananaEditOutput = z.object({
  images: z.array(zFalAiNanoBananaEditImageFile).register(z.globalRegistry, {
    description: 'The edited images.',
  }),
  description: z.string().register(z.globalRegistry, {
    description: 'The description of the generated images.',
  }),
})

/**
 * NextStepEditRequest
 */
export const zNextstep1Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to edit the image.',
  }),
  negative_prompt: z.string().register(z.globalRegistry, {
    description:
      "The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n        ",
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to edit.',
  }),
})

/**
 * NextStepResponse
 */
export const zNextstep1Output = z.object({
  image: z
    .object({
      file_size: z.optional(z.union([z.int(), z.unknown()])),
      height: z.optional(z.union([z.int(), z.unknown()])),
      file_name: z.optional(z.union([z.string(), z.unknown()])),
      content_type: z.optional(z.union([z.string(), z.unknown()])),
      url: z.string().register(z.globalRegistry, {
        description: 'The URL where the file can be downloaded from.',
      }),
      width: z.optional(z.union([z.int(), z.unknown()])),
    })
    .register(z.globalRegistry, {
      description: 'Generated image',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for random number generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageEditImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * BaseQwenEditImageInput
 */
export const zQwenImageEditInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the image with',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiQwenImageEditImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        "Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.",
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to edit.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(4),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt for the generation',
      }),
    )
    .default(' '),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zFalAiQwenImageEditImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * QwenImageOutput
 */
export const zQwenImageEditOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiQwenImageEditImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * RGBColor
 */
export const zRgbColor = z.object({
  r: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Red color value',
      }),
    )
    .default(0),
  b: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Blue color value',
      }),
    )
    .default(0),
  g: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Green color value',
      }),
    )
    .default(0),
})

/**
 * ColorPaletteMember
 */
export const zColorPaletteMember = z.object({
  color_weight: z.optional(z.union([z.number().gte(0.05).lte(1), z.unknown()])),
  rgb: zRgbColor,
})

/**
 * ColorPalette
 */
export const zColorPalette = z.object({
  members: z.optional(z.union([z.array(zColorPaletteMember), z.unknown()])),
  name: z.optional(
    z.union([
      z.enum([
        'EMBER',
        'FRESH',
        'JUNGLE',
        'MAGIC',
        'MELON',
        'MOSAIC',
        'PASTEL',
        'ULTRAMARINE',
      ]),
      z.unknown(),
    ]),
  ),
})

/**
 * CharacterEditInputV3
 */
export const zIdeogramCharacterEditInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to fill the masked part of the image.',
  }),
  style: z.optional(
    z.enum(['AUTO', 'REALISTIC', 'FICTION']).register(z.globalRegistry, {
      description:
        'The style type to generate with. Cannot be used with style_codes.',
    }),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Determine if MagicPrompt should be used in generating the request or not.',
      }),
    )
    .default(true),
  rendering_speed: z.optional(
    z.enum(['TURBO', 'BALANCED', 'QUALITY']).register(z.globalRegistry, {
      description: 'The rendering speed to use.',
    }),
  ),
  reference_mask_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'A set of masks to apply to the character references. Currently only 1 mask is supported, rest will be ignored. (maximum total size 10MB across all character references). The masks should be in JPEG, PNG or WebP format',
    }),
  ),
  reference_image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'A set of images to use as character references. Currently only 1 image is supported, rest will be ignored. (maximum total size 10MB across all character references). The images should be in JPEG, PNG or WebP format',
  }),
  image_urls: z.optional(z.union([z.array(z.string()), z.unknown()])),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'Number of images to generate.',
      }),
    )
    .default(1),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The image URL to generate an image from. MUST have the exact same dimensions (width and height) as the mask image.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  color_palette: z.optional(z.union([zColorPalette, z.unknown()])),
  style_codes: z.optional(z.union([z.array(z.string()), z.unknown()])),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  mask_url: z.string().register(z.globalRegistry, {
    description:
      'The mask URL to inpaint the image. MUST have the exact same dimensions (width and height) as the input image.',
  }),
})

/**
 * File
 */
export const zFalAiIdeogramCharacterEditFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * CharacterEditOutputV3
 */
export const zIdeogramCharacterEditOutput = z.object({
  images: z.array(zFalAiIdeogramCharacterEditFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for the random number generator',
  }),
})

/**
 * ImageSize
 */
export const zFalAiIdeogramCharacterImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * RGBColor
 */
export const zFalAiIdeogramCharacterRgbColor = z.object({
  r: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Red color value',
      }),
    )
    .default(0),
  b: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Blue color value',
      }),
    )
    .default(0),
  g: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Green color value',
      }),
    )
    .default(0),
})

/**
 * ColorPaletteMember
 */
export const zFalAiIdeogramCharacterColorPaletteMember = z.object({
  color_weight: z.optional(z.union([z.number().gte(0.05).lte(1), z.unknown()])),
  rgb: zFalAiIdeogramCharacterRgbColor,
})

/**
 * ColorPalette
 */
export const zFalAiIdeogramCharacterColorPalette = z.object({
  members: z.optional(
    z.union([z.array(zFalAiIdeogramCharacterColorPaletteMember), z.unknown()]),
  ),
  name: z.optional(
    z.union([
      z.enum([
        'EMBER',
        'FRESH',
        'JUNGLE',
        'MAGIC',
        'MELON',
        'MOSAIC',
        'PASTEL',
        'ULTRAMARINE',
      ]),
      z.unknown(),
    ]),
  ),
})

/**
 * BaseCharacterInputV3
 */
export const zIdeogramCharacterInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to fill the masked part of the image.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiIdeogramCharacterImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
      z.unknown(),
    ]),
  ),
  style: z.optional(
    z.enum(['AUTO', 'REALISTIC', 'FICTION']).register(z.globalRegistry, {
      description:
        'The style type to generate with. Cannot be used with style_codes.',
    }),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Determine if MagicPrompt should be used in generating the request or not.',
      }),
    )
    .default(true),
  rendering_speed: z.optional(
    z.enum(['TURBO', 'BALANCED', 'QUALITY']).register(z.globalRegistry, {
      description: 'The rendering speed to use.',
    }),
  ),
  reference_mask_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'A set of masks to apply to the character references. Currently only 1 mask is supported, rest will be ignored. (maximum total size 10MB across all character references). The masks should be in JPEG, PNG or WebP format',
    }),
  ),
  reference_image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'A set of images to use as character references. Currently only 1 image is supported, rest will be ignored. (maximum total size 10MB across all character references). The images should be in JPEG, PNG or WebP format',
  }),
  image_urls: z.optional(z.union([z.array(z.string()), z.unknown()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Description of what to exclude from an image. Descriptions in the prompt take precedence to descriptions in the negative prompt.',
      }),
    )
    .default(''),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'Number of images to generate.',
      }),
    )
    .default(1),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  color_palette: z.optional(
    z.union([zFalAiIdeogramCharacterColorPalette, z.unknown()]),
  ),
  style_codes: z.optional(z.union([z.array(z.string()), z.unknown()])),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * File
 */
export const zFalAiIdeogramCharacterFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * CharacterOutputV3
 */
export const zIdeogramCharacterOutput = z.object({
  images: z.array(zFalAiIdeogramCharacterFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for the random number generator',
  }),
})

/**
 * ImageSize
 */
export const zFalAiIdeogramCharacterRemixImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * RGBColor
 */
export const zFalAiIdeogramCharacterRemixRgbColor = z.object({
  r: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Red color value',
      }),
    )
    .default(0),
  b: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Blue color value',
      }),
    )
    .default(0),
  g: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Green color value',
      }),
    )
    .default(0),
})

/**
 * ColorPaletteMember
 */
export const zFalAiIdeogramCharacterRemixColorPaletteMember = z.object({
  color_weight: z.optional(z.union([z.number().gte(0.05).lte(1), z.unknown()])),
  rgb: zFalAiIdeogramCharacterRemixRgbColor,
})

/**
 * ColorPalette
 */
export const zFalAiIdeogramCharacterRemixColorPalette = z.object({
  members: z.optional(
    z.union([
      z.array(zFalAiIdeogramCharacterRemixColorPaletteMember),
      z.unknown(),
    ]),
  ),
  name: z.optional(
    z.union([
      z.enum([
        'EMBER',
        'FRESH',
        'JUNGLE',
        'MAGIC',
        'MELON',
        'MOSAIC',
        'PASTEL',
        'ULTRAMARINE',
      ]),
      z.unknown(),
    ]),
  ),
})

/**
 * CharacterRemixInputV3
 */
export const zIdeogramCharacterRemixInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to remix the image with',
  }),
  image_size: z.optional(
    z.union([
      zFalAiIdeogramCharacterRemixImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
      z.unknown(),
    ]),
  ),
  style: z.optional(
    z.enum(['AUTO', 'REALISTIC', 'FICTION']).register(z.globalRegistry, {
      description:
        'The style type to generate with. Cannot be used with style_codes.',
    }),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Determine if MagicPrompt should be used in generating the request or not.',
      }),
    )
    .default(true),
  rendering_speed: z.optional(
    z.enum(['TURBO', 'BALANCED', 'QUALITY']).register(z.globalRegistry, {
      description: 'The rendering speed to use.',
    }),
  ),
  reference_mask_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'A set of masks to apply to the character references. Currently only 1 mask is supported, rest will be ignored. (maximum total size 10MB across all character references). The masks should be in JPEG, PNG or WebP format',
    }),
  ),
  reference_image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'A set of images to use as character references. Currently only 1 image is supported, rest will be ignored. (maximum total size 10MB across all character references). The images should be in JPEG, PNG or WebP format',
  }),
  image_urls: z.optional(z.union([z.array(z.string()), z.unknown()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Description of what to exclude from an image. Descriptions in the prompt take precedence to descriptions in the negative prompt.',
      }),
    )
    .default(''),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'Number of images to generate.',
      }),
    )
    .default(1),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The image URL to remix',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  color_palette: z.optional(
    z.union([zFalAiIdeogramCharacterRemixColorPalette, z.unknown()]),
  ),
  style_codes: z.optional(z.union([z.array(z.string()), z.unknown()])),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description: 'Strength of the input image in the remix',
      }),
    )
    .default(0.8),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * File
 */
export const zFalAiIdeogramCharacterRemixFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * CharacterRemixOutputV3
 */
export const zIdeogramCharacterRemixOutput = z.object({
  images: z.array(zFalAiIdeogramCharacterRemixFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for the random number generator',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFluxKreaLoraInpaintingImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zFalAiFluxKreaLoraInpaintingLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * InpaintInput
 */
export const zFluxKreaLoraInpaintingInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description:
          'The number of images to generate. This is always set to 1 for streaming output.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFluxKreaLoraInpaintingImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to use for inpainting. or img2img',
  }),
  loras: z
    .optional(
      z
        .array(zFalAiFluxKreaLoraInpaintingLoraWeight)
        .register(z.globalRegistry, {
          description:
            '\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ',
        }),
    )
    .default([]),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.',
      }),
    )
    .default(0.85),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(35).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  mask_url: z.string().register(z.globalRegistry, {
    description: '\n            The mask to area to Inpaint in.\n        ',
  }),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiFluxKreaLoraInpaintingImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxKreaLoraInpaintingOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFluxKreaLoraInpaintingImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * ImageSize
 */
export const zFalAiFluxKreaLoraImageToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zFalAiFluxKreaLoraImageToImageLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * ImageToImageInput
 */
export const zFluxKreaLoraImageToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description:
          'The number of images to generate. This is always set to 1 for streaming output.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFluxKreaLoraImageToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to use for inpainting. or img2img',
  }),
  loras: z
    .optional(
      z
        .array(zFalAiFluxKreaLoraImageToImageLoraWeight)
        .register(z.globalRegistry, {
          description:
            '\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ',
        }),
    )
    .default([]),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.',
      }),
    )
    .default(0.85),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(35).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiFluxKreaLoraImageToImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxKreaLoraImageToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFluxKreaLoraImageToImageImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * BaseKreaImageToInput
 */
export const zFluxKreaImageToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        'The speed of the generation. The higher the speed, the faster the generation.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to generate an image from.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the initial image. Higher strength values are better for this model.',
      }),
    )
    .default(0.95),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ',
      }),
    )
    .default(4.5),
  num_inference_steps: z
    .optional(
      z.int().gte(10).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(40),
})

/**
 * Image
 */
export const zFalAiFluxKreaImageToImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxKreaImageToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFluxKreaImageToImageImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFluxKreaReduxImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * BaseKreaReduxInput
 */
export const zFluxKreaReduxInput = z.object({
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFluxKreaReduxImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        'The speed of the generation. The higher the speed, the faster the generation.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to generate an image from.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ',
      }),
    )
    .default(4.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
})

/**
 * Image
 */
export const zFalAiFluxKreaReduxImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * KreaReduxOutput
 */
export const zFluxKreaReduxOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFluxKreaReduxImage).register(z.globalRegistry, {
    description: 'The generated images.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * BaseKreaFlux1ImageToInput
 */
export const zFlux1KreaImageToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        'The speed of the generation. The higher the speed, the faster the generation.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to generate an image from.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the initial image. Higher strength values are better for this model.',
      }),
    )
    .default(0.95),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(10).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(40),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ',
      }),
    )
    .default(4.5),
})

/**
 * Image
 */
export const zFalAiFlux1KreaImageToImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * KreaOutput
 */
export const zFlux1KreaImageToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFlux1KreaImageToImageImage).register(z.globalRegistry, {
    description: 'The generated images.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux1KreaReduxImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * BaseKreaFlux1ReduxInput
 */
export const zFlux1KreaReduxInput = z.object({
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFlux1KreaReduxImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        'The speed of the generation. The higher the speed, the faster the generation.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to generate an image from.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ',
      }),
    )
    .default(4.5),
})

/**
 * Image
 */
export const zFalAiFlux1KreaReduxImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * KreaReduxOutput
 */
export const zFlux1KreaReduxOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFlux1KreaReduxImage).register(z.globalRegistry, {
    description: 'The generated images.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * LoraWeight
 */
export const zFalAiFluxKontextLoraInpaintLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * BaseKontextInpaintInput
 */
export const zFluxKontextLoraInpaintInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt for the image to image task.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        'The speed of the generation. The higher the speed, the faster the generation.',
    }),
  ),
  reference_image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the reference image for inpainting.',
  }),
  loras: z
    .optional(
      z
        .array(zFalAiFluxKontextLoraInpaintLoraWeight)
        .register(z.globalRegistry, {
          description:
            '\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ',
        }),
    )
    .default([]),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(2.5),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to be inpainted.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the initial image. Higher strength values are better for this model.',
      }),
    )
    .default(0.88),
  num_inference_steps: z
    .optional(
      z.int().gte(10).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(30),
  mask_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the mask for inpainting.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiFluxKontextLoraInpaintImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * KontextInpaintOutput
 */
export const zFluxKontextLoraInpaintOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFluxKontextLoraInpaintImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageToPanoramaRequest
 */
export const zHunyuanWorldInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to use for the panorama generation.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to convert to a panorama.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiHunyuanWorldImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ImageToPanoramaResponse
 */
export const zHunyuanWorldOutput = z.object({
  image: zFalAiHunyuanWorldImage,
})

/**
 * RetouchInput
 *
 * Input model for retouch endpoint.
 */
export const zImageEditingRetouchInput = z
  .object({
    lora_scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'The scale factor for the LoRA model. Controls the strength of the LoRA effect.',
        }),
      )
      .default(1),
    image_url: z.string().register(z.globalRegistry, {
      description: 'URL of the image to retouch.',
    }),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.',
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
        }),
      )
      .default(3.5),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'The same seed and the same prompt given to the same version of the model will output the same image every time.',
      }),
    ),
    num_inference_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: 'Number of inference steps for sampling.',
        }),
      )
      .default(30),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description: 'Input model for retouch endpoint.',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingRetouchImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * RetouchOutput
 */
export const zImageEditingRetouchOutput = z.object({
  images: z.array(zFalAiImageEditingRetouchImage),
  seed: z.int(),
})

/**
 * BaseInput
 */
export const zHidreamE11Input = z.object({
  prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The prompt to generate an image from.',
    }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your initial image when looking for a related image to show you.\n        ',
      }),
    )
    .default(2),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of an input image to edit.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(50),
  target_image_description: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The description of the target image after your edits have been made. Leave this blank to allow the model to use its own imagination.',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default('low resolution, blur'),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiHidreamE11Image = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zHidreamE11Output = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiHidreamE11Image).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * RIFEImageInput
 */
export const zRifeInput = z.object({
  output_format: z.optional(
    z.enum(['png', 'jpeg']).register(z.globalRegistry, {
      description:
        "The format of the output images. Only applicable if output_type is 'images'.",
    }),
  ),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description:
          "Frames per second for the output video. Only applicable if output_type is 'video'.",
      }),
    )
    .default(8),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  include_end: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to include the end image in the output.',
      }),
    )
    .default(false),
  include_start: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to include the start image in the output.',
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(1).lte(64).register(z.globalRegistry, {
        description:
          'The number of frames to generate between the input images.',
      }),
    )
    .default(1),
  end_image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the second image to use as the ending point for interpolation.',
  }),
  output_type: z.optional(
    z.enum(['images', 'video']).register(z.globalRegistry, {
      description:
        'The type of output to generate; either individual images or a video.',
    }),
  ),
  start_image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the first image to use as the starting point for interpolation.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiRifeImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * File
 */
export const zFalAiRifeFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * RIFEImageOutput
 */
export const zRifeOutput = z.object({
  images: z
    .optional(
      z.array(zFalAiRifeImage).register(z.globalRegistry, {
        description: 'The generated frames as individual images.',
      }),
    )
    .default([]),
  video: z.optional(zFalAiRifeFile),
})

/**
 * FILMImageInput
 */
export const zFilmInput = z.object({
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description:
        "The write mode of the output video. Only applicable if output_type is 'video'.",
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(1).lte(64).register(z.globalRegistry, {
        description:
          'The number of frames to generate between the input images.',
      }),
    )
    .default(1),
  include_start: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to include the start image in the output.',
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description:
        "The quality of the output video. Only applicable if output_type is 'video'.",
    }),
  ),
  include_end: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to include the end image in the output.',
      }),
    )
    .default(false),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description:
          "Frames per second for the output video. Only applicable if output_type is 'video'.",
      }),
    )
    .default(8),
  start_image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the first image to use as the starting point for interpolation.',
  }),
  end_image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the second image to use as the ending point for interpolation.',
  }),
  image_format: z.optional(
    z.enum(['png', 'jpeg']).register(z.globalRegistry, {
      description:
        "The format of the output images. Only applicable if output_type is 'images'.",
    }),
  ),
  output_type: z.optional(
    z.enum(['images', 'video']).register(z.globalRegistry, {
      description:
        'The type of output to generate; either individual images or a video.',
    }),
  ),
})

/**
 * ImageFile
 */
export const zFalAiFilmImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * VideoFile
 */
export const zVideoFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  duration: z.optional(
    z.number().register(z.globalRegistry, {
      description: 'The duration of the video',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the video',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the video',
    }),
  ),
  fps: z.optional(
    z.number().register(z.globalRegistry, {
      description: 'The FPS of the video',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  num_frames: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The number of frames in the video',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * FILMImageOutput
 */
export const zFilmOutput = z.object({
  images: z
    .optional(
      z.array(zFalAiFilmImageFile).register(z.globalRegistry, {
        description: 'The generated frames as individual images.',
      }),
    )
    .default([]),
  video: z.optional(zVideoFile),
})

/**
 * ImageSize
 */
export const zFalAiCalligrapherImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Input
 */
export const zCalligrapherInput = z.object({
  use_context: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to prepend context reference to the input',
      }),
    )
    .default(true),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'How many images to generate',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiCalligrapherImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  auto_mask_generation: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to automatically generate mask from detected text',
      }),
    )
    .default(false),
  reference_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'Optional base64 reference image for style',
    }),
  ),
  source_image_url: z.string().register(z.globalRegistry, {
    description: 'Base64-encoded source image with drawn mask layers',
  }),
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt to inpaint or customize',
  }),
  mask_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'Base64-encoded mask image (optional if using auto_mask_generation)',
    }),
  ),
  source_text: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Source text to replace (if empty, masks all detected text)',
      }),
    )
    .default(''),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps (1-100)',
      }),
    )
    .default(50),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for reproducibility',
    }),
  ),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(5).register(z.globalRegistry, {
        description: 'Guidance or strength scale for the model',
      }),
    )
    .default(1),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiCalligrapherImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * Output
 */
export const zCalligrapherOutput = z.object({
  images: z.array(zFalAiCalligrapherImage),
})

/**
 * ReimagineInput
 */
export const zBriaReimagineInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt you would like to use to generate images.',
  }),
  num_results: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description:
          'How many images you would like to generate. When using any Guidance Method, Value is set to 1.',
      }),
    )
    .default(1),
  structure_ref_influence: z
    .optional(
      z.number().register(z.globalRegistry, {
        description:
          'The influence of the structure reference on the generated image.',
      }),
    )
    .default(0.75),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  fast: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to use the fast model',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().gte(0).lte(2147483647).register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(20).lte(50).register(z.globalRegistry, {
        description:
          'The number of iterations the model goes through to refine the generated image. This parameter is optional.',
      }),
    )
    .default(30),
  structure_image_url: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'The URL of the structure reference image. Use "" to leave empty. Accepted formats are jpeg, jpg, png, webp.',
      }),
    )
    .default(''),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBriaReimagineImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ReimagineOutput
 */
export const zBriaReimagineOutput = z.object({
  images: z.array(zFalAiBriaReimagineImage).register(z.globalRegistry, {
    description: 'The generated images',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed value used for generation.',
  }),
})

/**
 * RealismInput
 *
 * Input model for realism enhancement endpoint.
 */
export const zImageEditingRealismInput = z
  .object({
    lora_scale: z
      .optional(
        z.number().gte(0).lte(2).register(z.globalRegistry, {
          description:
            'The scale factor for the LoRA model. Controls the strength of the LoRA effect.',
        }),
      )
      .default(0.6),
    image_url: z.string().register(z.globalRegistry, {
      description: 'URL of the image to enhance with realism details.',
    }),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.',
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
        }),
      )
      .default(3.5),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'The same seed and the same prompt given to the same version of the model will output the same image every time.',
      }),
    ),
    num_inference_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: 'Number of inference steps for sampling.',
        }),
      )
      .default(30),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description: 'Input model for realism enhancement endpoint.',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingRealismImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * RealismOutput
 */
export const zImageEditingRealismOutput = z.object({
  images: z.array(zFalAiImageEditingRealismImage),
  seed: z.int(),
})

/**
 * VignetteInput
 */
export const zPostProcessingVignetteInput = z.object({
  vignette_strength: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description: 'Vignette strength',
      }),
    )
    .default(0.5),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to process',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPostProcessingVignetteImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * VignetteOutput
 */
export const zPostProcessingVignetteOutput = z.object({
  images: z
    .array(zFalAiPostProcessingVignetteImage)
    .register(z.globalRegistry, {
      description: 'The processed images with vignette effect',
    }),
})

/**
 * SolarizeInput
 */
export const zPostProcessingSolarizeInput = z.object({
  solarize_threshold: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Solarize threshold',
      }),
    )
    .default(0.5),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to process',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPostProcessingSolarizeImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * SolarizeOutput
 */
export const zPostProcessingSolarizeOutput = z.object({
  images: z
    .array(zFalAiPostProcessingSolarizeImage)
    .register(z.globalRegistry, {
      description: 'The processed images with solarize effect',
    }),
})

/**
 * SharpenInput
 */
export const zPostProcessingSharpenInput = z.object({
  sharpen_mode: z.optional(
    z.enum(['basic', 'smart', 'cas']).register(z.globalRegistry, {
      description: 'Type of sharpening to apply',
    }),
  ),
  sharpen_alpha: z
    .optional(
      z.number().gte(0.1).lte(5).register(z.globalRegistry, {
        description: 'Sharpen strength (for basic mode)',
      }),
    )
    .default(1),
  noise_radius: z
    .optional(
      z.int().gte(1).lte(25).register(z.globalRegistry, {
        description: 'Noise radius for smart sharpen',
      }),
    )
    .default(7),
  sharpen_radius: z
    .optional(
      z.int().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Sharpen radius (for basic mode)',
      }),
    )
    .default(1),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to process',
  }),
  smart_sharpen_strength: z
    .optional(
      z.number().gte(0).lte(25).register(z.globalRegistry, {
        description: 'Smart sharpen strength',
      }),
    )
    .default(5),
  cas_amount: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'CAS sharpening amount',
      }),
    )
    .default(0.8),
  preserve_edges: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Edge preservation factor',
      }),
    )
    .default(0.75),
  smart_sharpen_ratio: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Smart sharpen blend ratio',
      }),
    )
    .default(0.5),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPostProcessingSharpenImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * SharpenOutput
 */
export const zPostProcessingSharpenOutput = z.object({
  images: z.array(zFalAiPostProcessingSharpenImage).register(z.globalRegistry, {
    description: 'The processed images with sharpen effect',
  }),
})

/**
 * ParabolizeInput
 */
export const zPostProcessingParabolizeInput = z.object({
  parabolize_coeff: z
    .optional(
      z.number().gte(-10).lte(10).register(z.globalRegistry, {
        description: 'Parabolize coefficient',
      }),
    )
    .default(1),
  vertex_y: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Vertex Y position',
      }),
    )
    .default(0.5),
  vertex_x: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Vertex X position',
      }),
    )
    .default(0.5),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to process',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPostProcessingParabolizeImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ParabolizeOutput
 */
export const zPostProcessingParabolizeOutput = z.object({
  images: z
    .array(zFalAiPostProcessingParabolizeImage)
    .register(z.globalRegistry, {
      description: 'The processed images with parabolize effect',
    }),
})

/**
 * GrainInput
 */
export const zPostProcessingGrainInput = z.object({
  grain_style: z.optional(
    z
      .enum(['modern', 'analog', 'kodak', 'fuji', 'cinematic', 'newspaper'])
      .register(z.globalRegistry, {
        description: 'Style of film grain to apply',
      }),
  ),
  grain_intensity: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Film grain intensity',
      }),
    )
    .default(0.4),
  grain_scale: z
    .optional(
      z.number().gte(1).lte(100).register(z.globalRegistry, {
        description: 'Film grain scale',
      }),
    )
    .default(10),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to process',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPostProcessingGrainImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * GrainOutput
 */
export const zPostProcessingGrainOutput = z.object({
  images: z.array(zFalAiPostProcessingGrainImage).register(z.globalRegistry, {
    description: 'The processed images with grain effect',
  }),
})

/**
 * DodgeBurnInput
 */
export const zPostProcessingDodgeBurnInput = z.object({
  dodge_burn_mode: z.optional(
    z
      .enum([
        'dodge',
        'burn',
        'dodge_and_burn',
        'burn_and_dodge',
        'color_dodge',
        'color_burn',
        'linear_dodge',
        'linear_burn',
      ])
      .register(z.globalRegistry, {
        description: 'Dodge and burn mode',
      }),
  ),
  dodge_burn_intensity: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Dodge and burn intensity',
      }),
    )
    .default(0.5),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to process',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPostProcessingDodgeBurnImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * DodgeBurnOutput
 */
export const zPostProcessingDodgeBurnOutput = z.object({
  images: z
    .array(zFalAiPostProcessingDodgeBurnImage)
    .register(z.globalRegistry, {
      description: 'The processed images with dodge and burn effect',
    }),
})

/**
 * DissolveInput
 */
export const zPostProcessingDissolveInput = z.object({
  dissolve_factor: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Dissolve blend factor',
      }),
    )
    .default(0.5),
  dissolve_image_url: z.string().register(z.globalRegistry, {
    description: 'URL of second image for dissolve',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to process',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPostProcessingDissolveImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * DissolveOutput
 */
export const zPostProcessingDissolveOutput = z.object({
  images: z
    .array(zFalAiPostProcessingDissolveImage)
    .register(z.globalRegistry, {
      description: 'The processed images with dissolve effect',
    }),
})

/**
 * DesaturateInput
 */
export const zPostProcessingDesaturateInput = z.object({
  desaturate_method: z.optional(
    z
      .enum([
        'luminance (Rec.709)',
        'luminance (Rec.601)',
        'average',
        'lightness',
      ])
      .register(z.globalRegistry, {
        description: 'Desaturation method',
      }),
  ),
  desaturate_factor: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Desaturation factor',
      }),
    )
    .default(1),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to process',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPostProcessingDesaturateImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * DesaturateOutput
 */
export const zPostProcessingDesaturateOutput = z.object({
  images: z
    .array(zFalAiPostProcessingDesaturateImage)
    .register(z.globalRegistry, {
      description: 'The processed images with desaturation effect',
    }),
})

/**
 * ColorTintInput
 */
export const zPostProcessingColorTintInput = z.object({
  tint_strength: z
    .optional(
      z.number().gte(0.1).lte(1).register(z.globalRegistry, {
        description: 'Tint strength',
      }),
    )
    .default(1),
  tint_mode: z.optional(
    z
      .enum([
        'sepia',
        'red',
        'green',
        'blue',
        'cyan',
        'magenta',
        'yellow',
        'purple',
        'orange',
        'warm',
        'cool',
        'lime',
        'navy',
        'vintage',
        'rose',
        'teal',
        'maroon',
        'peach',
        'lavender',
        'olive',
      ])
      .register(z.globalRegistry, {
        description: 'Tint color mode',
      }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to process',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPostProcessingColorTintImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ColorTintOutput
 */
export const zPostProcessingColorTintOutput = z.object({
  images: z
    .array(zFalAiPostProcessingColorTintImage)
    .register(z.globalRegistry, {
      description: 'The processed images with color tint effect',
    }),
})

/**
 * ColorCorrectionInput
 */
export const zPostProcessingColorCorrectionInput = z.object({
  gamma: z
    .optional(
      z.number().gte(0.2).lte(2.2).register(z.globalRegistry, {
        description: 'Gamma adjustment',
      }),
    )
    .default(1),
  saturation: z
    .optional(
      z.number().gte(-100).lte(100).register(z.globalRegistry, {
        description: 'Saturation adjustment',
      }),
    )
    .default(0),
  temperature: z
    .optional(
      z.number().gte(-100).lte(100).register(z.globalRegistry, {
        description: 'Color temperature adjustment',
      }),
    )
    .default(0),
  brightness: z
    .optional(
      z.number().gte(-100).lte(100).register(z.globalRegistry, {
        description: 'Brightness adjustment',
      }),
    )
    .default(0),
  contrast: z
    .optional(
      z.number().gte(-100).lte(100).register(z.globalRegistry, {
        description: 'Contrast adjustment',
      }),
    )
    .default(0),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to process',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPostProcessingColorCorrectionImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ColorCorrectionOutput
 */
export const zPostProcessingColorCorrectionOutput = z.object({
  images: z
    .array(zFalAiPostProcessingColorCorrectionImage)
    .register(z.globalRegistry, {
      description: 'The processed images with color correction',
    }),
})

/**
 * ChromaticAberrationInput
 */
export const zPostProcessingChromaticAberrationInput = z.object({
  blue_shift: z
    .optional(
      z.int().gte(-20).lte(20).register(z.globalRegistry, {
        description: 'Blue channel shift amount',
      }),
    )
    .default(0),
  red_shift: z
    .optional(
      z.int().gte(-20).lte(20).register(z.globalRegistry, {
        description: 'Red channel shift amount',
      }),
    )
    .default(0),
  green_direction: z.optional(
    z.enum(['horizontal', 'vertical']).register(z.globalRegistry, {
      description: 'Green channel shift direction',
    }),
  ),
  blue_direction: z.optional(
    z.enum(['horizontal', 'vertical']).register(z.globalRegistry, {
      description: 'Blue channel shift direction',
    }),
  ),
  red_direction: z.optional(
    z.enum(['horizontal', 'vertical']).register(z.globalRegistry, {
      description: 'Red channel shift direction',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to process',
  }),
  green_shift: z
    .optional(
      z.int().gte(-20).lte(20).register(z.globalRegistry, {
        description: 'Green channel shift amount',
      }),
    )
    .default(0),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPostProcessingChromaticAberrationImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ChromaticAberrationOutput
 */
export const zPostProcessingChromaticAberrationOutput = z.object({
  images: z
    .array(zFalAiPostProcessingChromaticAberrationImage)
    .register(z.globalRegistry, {
      description: 'The processed images with chromatic aberration effect',
    }),
})

/**
 * BlurInput
 */
export const zPostProcessingBlurInput = z.object({
  blur_sigma: z
    .optional(
      z.number().gte(0.1).lte(10).register(z.globalRegistry, {
        description: 'Sigma for Gaussian blur',
      }),
    )
    .default(1),
  blur_radius: z
    .optional(
      z.int().gte(0).lte(31).register(z.globalRegistry, {
        description: 'Blur radius',
      }),
    )
    .default(3),
  blur_type: z.optional(
    z.enum(['gaussian', 'kuwahara']).register(z.globalRegistry, {
      description: 'Type of blur to apply',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to process',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPostProcessingBlurImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * BlurOutput
 */
export const zPostProcessingBlurOutput = z.object({
  images: z.array(zFalAiPostProcessingBlurImage).register(z.globalRegistry, {
    description: 'The processed images with blur effect',
  }),
})

/**
 * YouTubeThumbnailsInput
 *
 * Input model for YouTube thumbnails endpoint.
 */
export const zImageEditingYoutubeThumbnailsInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The text to include in the YouTube thumbnail.',
        }),
      )
      .default('Generate youtube thumbnails'),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'The scale factor for the LoRA model. Controls the strength of the LoRA effect.',
        }),
      )
      .default(0.5),
    image_url: z.string().register(z.globalRegistry, {
      description: 'URL of the image to convert to YouTube thumbnail style.',
    }),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.',
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
        }),
      )
      .default(3.5),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'The same seed and the same prompt given to the same version of the model will output the same image every time.',
      }),
    ),
    num_inference_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: 'Number of inference steps for sampling.',
        }),
      )
      .default(30),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description: 'Input model for YouTube thumbnails endpoint.',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingYoutubeThumbnailsImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * YouTubeThumbnailsOutput
 */
export const zImageEditingYoutubeThumbnailsOutput = z.object({
  images: z.array(zFalAiImageEditingYoutubeThumbnailsImage),
  seed: z.int(),
})

/**
 * ImageUpscaleRequest
 */
export const zTopazUpscaleImageInput = z.object({
  face_enhancement_creativity: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Creativity level for face enhancement. 0.0 means no creativity, 1.0 means maximum creativity. Ignored if face ehnancement is disabled.',
      }),
    )
    .default(0),
  face_enhancement_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Strength of the face enhancement. 0.0 means no enhancement, 1.0 means maximum enhancement. Ignored if face ehnancement is disabled.',
      }),
    )
    .default(0.8),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'Output format of the upscaled image.',
    }),
  ),
  face_enhancement: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to apply face enhancement to the image.',
      }),
    )
    .default(true),
  subject_detection: z.optional(
    z.enum(['All', 'Foreground', 'Background']).register(z.globalRegistry, {
      description: 'Subject detection mode for the image enhancement.',
    }),
  ),
  model: z.optional(
    z
      .enum([
        'Low Resolution V2',
        'Standard V2',
        'CGI',
        'High Fidelity V2',
        'Text Refine',
        'Recovery',
        'Redefine',
        'Recovery V2',
      ])
      .register(z.globalRegistry, {
        description: 'Model to use for image enhancement.',
      }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Url of the image to be upscaled',
  }),
  upscale_factor: z
    .optional(
      z.number().gte(1).lte(4).register(z.globalRegistry, {
        description:
          'Factor to upscale the video by (e.g. 2.0 doubles width and height)',
      }),
    )
    .default(2),
  crop_to_fill: z.optional(z.boolean()).default(false),
})

/**
 * File
 */
export const zFalAiTopazUpscaleImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ImageUpscaleOutput
 */
export const zTopazUpscaleImageOutput = z.object({
  image: zFalAiTopazUpscaleImageFile,
})

/**
 * BroccoliHaircutInput
 *
 * Input model for broccoli haircut endpoint.
 */
export const zImageEditingBroccoliHaircutInput = z
  .object({
    lora_scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'The scale factor for the LoRA model. Controls the strength of the LoRA effect.',
        }),
      )
      .default(1),
    image_url: z.string().register(z.globalRegistry, {
      description: 'URL of the image to apply broccoli haircut style.',
    }),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.',
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
        }),
      )
      .default(3.5),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'The same seed and the same prompt given to the same version of the model will output the same image every time.',
      }),
    ),
    num_inference_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: 'Number of inference steps for sampling.',
        }),
      )
      .default(30),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description: 'Input model for broccoli haircut endpoint.',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingBroccoliHaircutImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * BroccoliHaircutOutput
 */
export const zImageEditingBroccoliHaircutOutput = z.object({
  images: z.array(zFalAiImageEditingBroccoliHaircutImage),
  seed: z.int(),
})

/**
 * WojakStyleInput
 *
 * Input model for wojak style endpoint.
 */
export const zImageEditingWojakStyleInput = z
  .object({
    lora_scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'The scale factor for the LoRA model. Controls the strength of the LoRA effect.',
        }),
      )
      .default(1),
    image_url: z.string().register(z.globalRegistry, {
      description: 'URL of the image to convert to wojak style.',
    }),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.',
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
        }),
      )
      .default(3.5),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'The same seed and the same prompt given to the same version of the model will output the same image every time.',
      }),
    ),
    num_inference_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: 'Number of inference steps for sampling.',
        }),
      )
      .default(30),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description: 'Input model for wojak style endpoint.',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingWojakStyleImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * WojakStyleOutput
 */
export const zImageEditingWojakStyleOutput = z.object({
  images: z.array(zFalAiImageEditingWojakStyleImage),
  seed: z.int(),
})

/**
 * PlushieStyleInput
 *
 * Input model for plushie style endpoint.
 */
export const zImageEditingPlushieStyleInput = z
  .object({
    lora_scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'The scale factor for the LoRA model. Controls the strength of the LoRA effect.',
        }),
      )
      .default(1),
    image_url: z.string().register(z.globalRegistry, {
      description: 'URL of the image to convert to plushie style.',
    }),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.',
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
        }),
      )
      .default(3.5),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'The same seed and the same prompt given to the same version of the model will output the same image every time.',
      }),
    ),
    num_inference_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: 'Number of inference steps for sampling.',
        }),
      )
      .default(30),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description: 'Input model for plushie style endpoint.',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingPlushieStyleImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * PlushieStyleOutput
 */
export const zImageEditingPlushieStyleOutput = z.object({
  images: z.array(zFalAiImageEditingPlushieStyleImage),
  seed: z.int(),
})

/**
 * LoraWeight
 */
export const zFalAiFluxKontextLoraLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * BaseKontextEditInput
 */
export const zFluxKontextLoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to edit the image.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        'The speed of the generation. The higher the speed, the faster the generation.',
    }),
  ),
  resolution_mode: z.optional(
    z
      .enum([
        'auto',
        'match_input',
        '1:1',
        '16:9',
        '21:9',
        '3:2',
        '2:3',
        '4:5',
        '5:4',
        '3:4',
        '4:3',
        '9:16',
        '9:21',
      ])
      .register(z.globalRegistry, {
        description:
          "\n            Determines how the output resolution is set for image editing.\n            - `auto`: The model selects an optimal resolution from a predefined set that best matches the input image's aspect ratio. This is the recommended setting for most use cases as it's what the model was trained on.\n            - `match_input`: The model will attempt to use the same resolution as the input image. The resolution will be adjusted to be compatible with the model's requirements (e.g. dimensions must be multiples of 16 and within supported limits).\n            Apart from these, a few aspect ratios are also supported.\n            ",
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the image to edit.\n\nMax width: 14142px, Max height: 14142px, Timeout: 20s',
  }),
  loras: z
    .optional(
      z.array(zFalAiFluxKontextLoraLoraWeight).register(z.globalRegistry, {
        description:
          '\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ',
      }),
    )
    .default([]),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(2.5),
  num_inference_steps: z
    .optional(
      z.int().gte(10).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(30),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiFluxKontextLoraImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * KontextEditOutput
 */
export const zFluxKontextLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFluxKontextLoraImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * V16Input
 */
export const zFashnTryonV16Input = z.object({
  model_image: z.string().register(z.globalRegistry, {
    description: 'URL or base64 of the model image',
  }),
  moderation_level: z.optional(
    z.enum(['none', 'permissive', 'conservative']).register(z.globalRegistry, {
      description:
        "Content moderation level for garment images. 'none' disables moderation, 'permissive' blocks only explicit content, 'conservative' also blocks underwear and swimwear.",
    }),
  ),
  garment_photo_type: z.optional(
    z.enum(['auto', 'model', 'flat-lay']).register(z.globalRegistry, {
      description:
        "Specifies the type of garment photo to optimize internal parameters for better performance. 'model' is for photos of garments on a model, 'flat-lay' is for flat-lay or ghost mannequin images, and 'auto' attempts to automatically detect the photo type.",
    }),
  ),
  garment_image: z.string().register(z.globalRegistry, {
    description: 'URL or base64 of the garment image',
  }),
  category: z.optional(
    z
      .enum(['tops', 'bottoms', 'one-pieces', 'auto'])
      .register(z.globalRegistry, {
        description:
          "Category of the garment to try-on. 'auto' will attempt to automatically detect the category of the garment.",
      }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  segmentation_free: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Disables human parsing on the model image.',
      }),
    )
    .default(true),
  num_samples: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description:
          'Number of images to generate in a single run. Image generation has a random element in it, so trying multiple images at once increases the chances of getting a good result.',
      }),
    )
    .default(1),
  mode: z.optional(
    z.enum(['performance', 'balanced', 'quality']).register(z.globalRegistry, {
      description:
        "Specifies the mode of operation. 'performance' mode is faster but may sacrifice quality, 'balanced' mode is a balance between speed and quality, and 'quality' mode is slower but produces higher quality results.",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Sets random operations to a fixed state. Use the same seed to reproduce results with the same inputs, or different seed to force different results.',
    }),
  ),
  output_format: z.optional(
    z.enum(['png', 'jpeg']).register(z.globalRegistry, {
      description:
        "Output format of the generated images. 'png' is highest quality, while 'jpeg' is faster",
    }),
  ),
})

/**
 * File
 */
export const zFalAiFashnTryonV16File = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * V16Output
 */
export const zFashnTryonV16Output = z.object({
  images: z.array(zFalAiFashnTryonV16File),
})

/**
 * Input
 */
export const zChainOfZoomInput = z.object({
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  center_y: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Y coordinate of zoom center (0-1)',
      }),
    )
    .default(0.5),
  scale: z
    .optional(
      z.number().gte(1).lte(8).register(z.globalRegistry, {
        description: 'Zoom scale in powers of 2',
      }),
    )
    .default(5),
  center_x: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'X coordinate of zoom center (0-1)',
      }),
    )
    .default(0.5),
  user_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Additional prompt text to guide the zoom enhancement',
      }),
    )
    .default(''),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Input image to zoom into',
  }),
})

/**
 * Image
 */
export const zFalAiChainOfZoomImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zChainOfZoomOutput = z.object({
  images: z.array(zFalAiChainOfZoomImage).register(z.globalRegistry, {
    description: 'List of intermediate images',
  }),
  zoom_center: z.array(z.number()).register(z.globalRegistry, {
    description: 'Center coordinates used for zoom',
  }),
  scale: z.number().register(z.globalRegistry, {
    description: 'Actual linear zoom scale applied',
  }),
})

/**
 * Input
 */
export const zPasdInput = z.object({
  conditioning_scale: z
    .optional(
      z.number().gte(0.1).lte(1).register(z.globalRegistry, {
        description: 'ControlNet conditioning scale (0.1-1.0)',
      }),
    )
    .default(0.8),
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Additional prompt to guide super-resolution',
      }),
    )
    .default(''),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Input image to super-resolve',
  }),
  steps: z
    .optional(
      z.int().gte(10).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps (10-50)',
      }),
    )
    .default(25),
  scale: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'Upscaling factor (1-4x)',
      }),
    )
    .default(2),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description: 'Guidance scale for diffusion (1.0-20.0)',
      }),
    )
    .default(7),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to avoid unwanted artifacts',
      }),
    )
    .default(
      'blurry, dirty, messy, frames, deformed, dotted, noise, raster lines, unclear, lowres, over-smoothed, painting, ai generated',
    ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPasdImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * Output
 */
export const zPasdOutput = z.object({
  images: z.array(zFalAiPasdImage).register(z.globalRegistry, {
    description: 'The generated super-resolved images',
  }),
  timings: z.optional(
    z.record(z.string(), z.number()).register(z.globalRegistry, {
      description: 'Timing information for different processing stages',
    }),
  ),
})

/**
 * BBoxPromptBase
 */
export const zBBoxPromptBase = z.object({
  y_min: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Y Min Coordinate of the box (0-1)',
      }),
    )
    .default(0),
  x_max: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'X Max Coordinate of the prompt (0-1)',
      }),
    )
    .default(0),
  x_min: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'X Min Coordinate of the box (0-1)',
      }),
    )
    .default(0),
  y_max: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Y Max Coordinate of the prompt (0-1)',
      }),
    )
    .default(0),
})

/**
 * BboxInput
 */
export const zObjectRemovalBboxInput = z.object({
  model: z.optional(
    z.enum(['low_quality', 'medium_quality', 'high_quality', 'best_quality']),
  ),
  mask_expansion: z
    .optional(
      z.int().gte(0).lte(50).register(z.globalRegistry, {
        description: 'Amount of pixels to expand the mask by. Range: 0-50',
      }),
    )
    .default(15),
  box_prompts: z
    .optional(
      z.array(zBBoxPromptBase).register(z.globalRegistry, {
        description:
          'List of bounding box coordinates to erase (only one box prompt is supported)',
      }),
    )
    .default([]),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to remove objects from.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiObjectRemovalBboxImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * Output
 */
export const zObjectRemovalBboxOutput = z.object({
  images: z.array(zFalAiObjectRemovalBboxImage).register(z.globalRegistry, {
    description: 'The generated images with objects removed.',
  }),
})

/**
 * MaskInput
 */
export const zObjectRemovalMaskInput = z.object({
  model: z.optional(
    z.enum(['low_quality', 'medium_quality', 'high_quality', 'best_quality']),
  ),
  mask_expansion: z
    .optional(
      z.int().gte(0).lte(50).register(z.globalRegistry, {
        description: 'Amount of pixels to expand the mask by. Range: 0-50',
      }),
    )
    .default(15),
  mask_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the mask image. White pixels (255) indicate areas to remove.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to remove objects from.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiObjectRemovalMaskImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * Output
 */
export const zObjectRemovalMaskOutput = z.object({
  images: z.array(zFalAiObjectRemovalMaskImage).register(z.globalRegistry, {
    description: 'The generated images with objects removed.',
  }),
})

/**
 * PromptInput
 */
export const zObjectRemovalInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text description of the object to remove.',
  }),
  mask_expansion: z
    .optional(
      z.int().gte(0).lte(50).register(z.globalRegistry, {
        description: 'Amount of pixels to expand the mask by. Range: 0-50',
      }),
    )
    .default(15),
  model: z.optional(
    z.enum(['low_quality', 'medium_quality', 'high_quality', 'best_quality']),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to remove objects from.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiObjectRemovalImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * Output
 */
export const zObjectRemovalOutput = z.object({
  images: z.array(zFalAiObjectRemovalImage).register(z.globalRegistry, {
    description: 'The generated images with objects removed.',
  }),
})

/**
 * VectorizeInput
 */
export const zRecraftVectorizeInput = z.object({
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the image to be vectorized. Must be in PNG, JPG or WEBP format, less than 5 MB in size, have resolution less than 16 MP and max dimension less than 4096 pixels, min dimension more than 256 pixels.',
  }),
})

/**
 * File
 */
export const zFalAiRecraftVectorizeFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * VectorizeOutput
 */
export const zRecraftVectorizeOutput = z.object({
  image: zFalAiRecraftVectorizeFile,
})

/**
 * FrameInput
 */
export const zFfmpegApiExtractFrameInput = z.object({
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the video file to use as the video track',
  }),
  frame_type: z.optional(
    z.enum(['first', 'middle', 'last']).register(z.globalRegistry, {
      description:
        'Type of frame to extract: first, middle, or last frame of the video',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFfmpegApiExtractFrameImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FrameOutput
 */
export const zFfmpegApiExtractFrameOutput = z.object({
  images: z.array(zFalAiFfmpegApiExtractFrameImage),
})

/**
 * ModifyImageRequest
 */
export const zLumaPhotonFlashModifyInput = z.object({
  prompt: z.optional(
    z.string().min(3).max(5000).register(z.globalRegistry, {
      description: 'Instruction for modifying the image',
    }),
  ),
  aspect_ratio: z
    .enum(['1:1', '16:9', '9:16', '4:3', '3:4', '21:9', '9:21'])
    .register(z.globalRegistry, {
      description: 'The aspect ratio of the reframed image',
    }),
  strength: z.number().gte(0).lte(1).register(z.globalRegistry, {
    description:
      'The strength of the initial image. Higher strength values are corresponding to more influence of the initial image on the output.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input image to reframe',
  }),
})

/**
 * File
 */
export const zFalAiLumaPhotonFlashModifyFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * T2IOutput
 */
export const zLumaPhotonFlashModifyOutput = z.object({
  images: z.array(zFalAiLumaPhotonFlashModifyFile).register(z.globalRegistry, {
    description: 'The generated image',
  }),
})

/**
 * ModifyImageRequest
 */
export const zLumaPhotonModifyInput = z.object({
  prompt: z.optional(
    z.string().min(3).max(5000).register(z.globalRegistry, {
      description: 'Instruction for modifying the image',
    }),
  ),
  aspect_ratio: z
    .enum(['1:1', '16:9', '9:16', '4:3', '3:4', '21:9', '9:21'])
    .register(z.globalRegistry, {
      description: 'The aspect ratio of the reframed image',
    }),
  strength: z.number().gte(0).lte(1).register(z.globalRegistry, {
    description:
      'The strength of the initial image. Higher strength values are corresponding to more influence of the initial image on the output.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input image to reframe',
  }),
})

/**
 * File
 */
export const zFalAiLumaPhotonModifyFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * T2IOutput
 */
export const zLumaPhotonModifyOutput = z.object({
  images: z.array(zFalAiLumaPhotonModifyFile).register(z.globalRegistry, {
    description: 'The generated image',
  }),
})

/**
 * ReframeInput
 */
export const zImageEditingReframeInput = z.object({
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '3:2', '1:1', '2:3', '3:4', '9:16', '9:21'])
      .register(z.globalRegistry, {
        description: 'The desired aspect ratio for the reframed image.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the old or damaged photo to restore.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.',
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps for sampling.',
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The same seed and the same prompt given to the same version of the model will output the same image every time.',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingReframeImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ReframeOutput
 */
export const zImageEditingReframeOutput = z.object({
  images: z.array(zFalAiImageEditingReframeImage),
  seed: z.int(),
})

/**
 * BabyVersionInput
 *
 * Input model for baby version endpoint.
 */
export const zImageEditingBabyVersionInput = z
  .object({
    aspect_ratio: z.optional(
      z
        .enum([
          '21:9',
          '16:9',
          '4:3',
          '3:2',
          '1:1',
          '2:3',
          '3:4',
          '9:16',
          '9:21',
        ])
        .register(z.globalRegistry, {
          description: 'The aspect ratio of the generated image.',
        }),
    ),
    output_format: z.optional(
      z.enum(['jpeg', 'png']).register(z.globalRegistry, {
        description: 'The format of the generated image.',
      }),
    ),
    image_url: z.string().register(z.globalRegistry, {
      description: 'URL of the image to transform into a baby version.',
    }),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.',
        }),
      )
      .default(false),
    safety_tolerance: z.optional(
      z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
        description:
          'The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.',
      }),
    ),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
        }),
      )
      .default(3.5),
    num_inference_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: 'Number of inference steps for sampling.',
        }),
      )
      .default(30),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'The same seed and the same prompt given to the same version of the model will output the same image every time.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Input model for baby version endpoint.',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingBabyVersionImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * BabyVersionOutput
 */
export const zImageEditingBabyVersionOutput = z.object({
  images: z.array(zFalAiImageEditingBabyVersionImage),
  seed: z.int(),
})

/**
 * ReframeImageRequest
 */
export const zLumaPhotonFlashReframeInput = z.object({
  prompt: z.optional(
    z.string().min(3).max(5000).register(z.globalRegistry, {
      description: 'Optional prompt for reframing',
    }),
  ),
  aspect_ratio: z
    .enum(['1:1', '16:9', '9:16', '4:3', '3:4', '21:9', '9:21'])
    .register(z.globalRegistry, {
      description: 'The aspect ratio of the reframed image',
    }),
  y_start: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Start Y coordinate for reframing',
    }),
  ),
  x_end: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'End X coordinate for reframing',
    }),
  ),
  y_end: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'End Y coordinate for reframing',
    }),
  ),
  grid_position_y: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Y position of the grid for reframing',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input image to reframe',
  }),
  grid_position_x: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'X position of the grid for reframing',
    }),
  ),
  x_start: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Start X coordinate for reframing',
    }),
  ),
})

/**
 * File
 */
export const zFalAiLumaPhotonFlashReframeFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * T2IOutput
 */
export const zLumaPhotonFlashReframeOutput = z.object({
  images: z.array(zFalAiLumaPhotonFlashReframeFile).register(z.globalRegistry, {
    description: 'The generated image',
  }),
})

/**
 * ReframeImageRequest
 */
export const zLumaPhotonReframeInput = z.object({
  prompt: z.optional(
    z.string().min(3).max(5000).register(z.globalRegistry, {
      description: 'Optional prompt for reframing',
    }),
  ),
  aspect_ratio: z
    .enum(['1:1', '16:9', '9:16', '4:3', '3:4', '21:9', '9:21'])
    .register(z.globalRegistry, {
      description: 'The aspect ratio of the reframed image',
    }),
  y_start: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Start Y coordinate for reframing',
    }),
  ),
  x_end: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'End X coordinate for reframing',
    }),
  ),
  y_end: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'End Y coordinate for reframing',
    }),
  ),
  grid_position_y: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Y position of the grid for reframing',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input image to reframe',
  }),
  grid_position_x: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'X position of the grid for reframing',
    }),
  ),
  x_start: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Start X coordinate for reframing',
    }),
  ),
})

/**
 * File
 */
export const zFalAiLumaPhotonReframeFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * T2IOutput
 */
export const zLumaPhotonReframeOutput = z.object({
  images: z.array(zFalAiLumaPhotonReframeFile).register(z.globalRegistry, {
    description: 'The generated image',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux1SchnellReduxImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * SchnellFlux1ReduxInput
 */
export const zFlux1SchnellReduxInput = z.object({
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFlux1SchnellReduxImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        'The speed of the generation. The higher the speed, the faster the generation.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to generate an image from.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(12).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(4),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * Image
 */
export const zFalAiFlux1SchnellReduxImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFlux1SchnellReduxOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFlux1SchnellReduxImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux1DevReduxImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * BaseFlux1ReduxInput
 */
export const zFlux1DevReduxInput = z.object({
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFlux1DevReduxImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        'The speed of the generation. The higher the speed, the faster the generation.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to generate an image from.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ',
      }),
    )
    .default(3.5),
})

/**
 * Image
 */
export const zFalAiFlux1DevReduxImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFlux1DevReduxOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFlux1DevReduxImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * BaseFlux1ImageToInput
 */
export const zFlux1DevImageToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        'The speed of the generation. The higher the speed, the faster the generation.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to generate an image from.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the initial image. Higher strength values are better for this model.',
      }),
    )
    .default(0.95),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(10).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(40),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ',
      }),
    )
    .default(3.5),
})

/**
 * Image
 */
export const zFalAiFlux1DevImageToImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFlux1DevImageToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFlux1DevImageToImageImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * TextRemovalInput
 *
 * Input model for text removal endpoint.
 */
export const zImageEditingTextRemovalInput = z
  .object({
    aspect_ratio: z.optional(
      z
        .enum([
          '21:9',
          '16:9',
          '4:3',
          '3:2',
          '1:1',
          '2:3',
          '3:4',
          '9:16',
          '9:21',
        ])
        .register(z.globalRegistry, {
          description: 'The aspect ratio of the generated image.',
        }),
    ),
    output_format: z.optional(
      z.enum(['jpeg', 'png']).register(z.globalRegistry, {
        description: 'The format of the generated image.',
      }),
    ),
    image_url: z.string().register(z.globalRegistry, {
      description: 'URL of the image containing text to be removed.',
    }),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.',
        }),
      )
      .default(false),
    safety_tolerance: z.optional(
      z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
        description:
          'The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.',
      }),
    ),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
        }),
      )
      .default(3.5),
    num_inference_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: 'Number of inference steps for sampling.',
        }),
      )
      .default(30),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'The same seed and the same prompt given to the same version of the model will output the same image every time.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Input model for text removal endpoint.',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingTextRemovalImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * TextRemovalOutput
 */
export const zImageEditingTextRemovalOutput = z.object({
  images: z.array(zFalAiImageEditingTextRemovalImage),
  seed: z.int(),
})

/**
 * PhotoRestorationInput
 *
 * Input model for photo restoration endpoint.
 */
export const zImageEditingPhotoRestorationInput = z
  .object({
    aspect_ratio: z.optional(
      z
        .enum([
          '21:9',
          '16:9',
          '4:3',
          '3:2',
          '1:1',
          '2:3',
          '3:4',
          '9:16',
          '9:21',
        ])
        .register(z.globalRegistry, {
          description: 'The aspect ratio of the generated image.',
        }),
    ),
    output_format: z.optional(
      z.enum(['jpeg', 'png']).register(z.globalRegistry, {
        description: 'The format of the generated image.',
      }),
    ),
    image_url: z.string().register(z.globalRegistry, {
      description: 'URL of the old or damaged photo to restore.',
    }),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.',
        }),
      )
      .default(false),
    safety_tolerance: z.optional(
      z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
        description:
          'The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.',
      }),
    ),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
        }),
      )
      .default(3.5),
    num_inference_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: 'Number of inference steps for sampling.',
        }),
      )
      .default(30),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'The same seed and the same prompt given to the same version of the model will output the same image every time.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Input model for photo restoration endpoint.',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingPhotoRestorationImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * PhotoRestorationOutput
 */
export const zImageEditingPhotoRestorationOutput = z.object({
  images: z.array(zFalAiImageEditingPhotoRestorationImage),
  seed: z.int(),
})

/**
 * WeatherEffectInput
 */
export const zImageEditingWeatherEffectInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The weather effect to apply.',
      }),
    )
    .default('heavy snowfall'),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '3:2', '1:1', '2:3', '3:4', '9:16', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Image prompt for the omni model.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.',
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps for sampling.',
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The same seed and the same prompt given to the same version of the model will output the same image every time.',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingWeatherEffectImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * WeatherEffectOutput
 */
export const zImageEditingWeatherEffectOutput = z.object({
  images: z.array(zFalAiImageEditingWeatherEffectImage),
  seed: z.int(),
})

/**
 * TimeOfDayInput
 */
export const zImageEditingTimeOfDayInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The time of day to transform the scene to.',
      }),
    )
    .default('golden hour'),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '3:2', '1:1', '2:3', '3:4', '9:16', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Image prompt for the omni model.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.',
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps for sampling.',
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The same seed and the same prompt given to the same version of the model will output the same image every time.',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingTimeOfDayImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * TimeOfDayOutput
 */
export const zImageEditingTimeOfDayOutput = z.object({
  images: z.array(zFalAiImageEditingTimeOfDayImage),
  seed: z.int(),
})

/**
 * StyleTransferInput
 */
export const zImageEditingStyleTransferInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The artistic style to apply.',
      }),
    )
    .default("Van Gogh's Starry Night"),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '3:2', '1:1', '2:3', '3:4', '9:16', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Image prompt for the omni model.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.',
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps for sampling.',
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The same seed and the same prompt given to the same version of the model will output the same image every time.',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingStyleTransferImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * StyleTransferOutput
 */
export const zImageEditingStyleTransferOutput = z.object({
  images: z.array(zFalAiImageEditingStyleTransferImage),
  seed: z.int(),
})

/**
 * SceneCompositionInput
 */
export const zImageEditingSceneCompositionInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Describe the scene where you want to place the subject.',
      }),
    )
    .default('enchanted forest'),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '3:2', '1:1', '2:3', '3:4', '9:16', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Image prompt for the omni model.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.',
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps for sampling.',
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The same seed and the same prompt given to the same version of the model will output the same image every time.',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingSceneCompositionImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * SceneCompositionOutput
 */
export const zImageEditingSceneCompositionOutput = z.object({
  images: z.array(zFalAiImageEditingSceneCompositionImage),
  seed: z.int(),
})

/**
 * BaseInput
 */
export const zImageEditingProfessionalPhotoInput = z.object({
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '3:2', '1:1', '2:3', '3:4', '9:16', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Image prompt for the omni model.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.',
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps for sampling.',
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The same seed and the same prompt given to the same version of the model will output the same image every time.',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingProfessionalPhotoImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ProfessionalPhotoOutput
 */
export const zImageEditingProfessionalPhotoOutput = z.object({
  images: z.array(zFalAiImageEditingProfessionalPhotoImage),
  seed: z.int(),
})

/**
 * ObjectRemovalInput
 */
export const zImageEditingObjectRemovalInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Specify which objects to remove from the image.',
      }),
    )
    .default('background people'),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '3:2', '1:1', '2:3', '3:4', '9:16', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Image prompt for the omni model.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.',
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps for sampling.',
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The same seed and the same prompt given to the same version of the model will output the same image every time.',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingObjectRemovalImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ObjectRemovalOutput
 */
export const zImageEditingObjectRemovalOutput = z.object({
  images: z.array(zFalAiImageEditingObjectRemovalImage),
  seed: z.int(),
})

/**
 * HairChangeInput
 */
export const zImageEditingHairChangeInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The desired hair style to apply.',
      }),
    )
    .default('bald'),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '3:2', '1:1', '2:3', '3:4', '9:16', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Image prompt for the omni model.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.',
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps for sampling.',
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The same seed and the same prompt given to the same version of the model will output the same image every time.',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingHairChangeImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * HairChangeOutput
 */
export const zImageEditingHairChangeOutput = z.object({
  images: z.array(zFalAiImageEditingHairChangeImage),
  seed: z.int(),
})

/**
 * BaseInput
 */
export const zImageEditingFaceEnhancementInput = z.object({
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '3:2', '1:1', '2:3', '3:4', '9:16', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Image prompt for the omni model.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.',
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps for sampling.',
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The same seed and the same prompt given to the same version of the model will output the same image every time.',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingFaceEnhancementImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FaceEnhancementOutput
 */
export const zImageEditingFaceEnhancementOutput = z.object({
  images: z.array(zFalAiImageEditingFaceEnhancementImage),
  seed: z.int(),
})

/**
 * ExpressionChangeInput
 */
export const zImageEditingExpressionChangeInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The desired facial expression to apply.',
      }),
    )
    .default('sad'),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '3:2', '1:1', '2:3', '3:4', '9:16', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Image prompt for the omni model.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.',
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps for sampling.',
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The same seed and the same prompt given to the same version of the model will output the same image every time.',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingExpressionChangeImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ExpressionChangeOutput
 */
export const zImageEditingExpressionChangeOutput = z.object({
  images: z.array(zFalAiImageEditingExpressionChangeImage),
  seed: z.int(),
})

/**
 * BaseInput
 */
export const zImageEditingColorCorrectionInput = z.object({
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '3:2', '1:1', '2:3', '3:4', '9:16', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Image prompt for the omni model.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.',
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps for sampling.',
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The same seed and the same prompt given to the same version of the model will output the same image every time.',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingColorCorrectionImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ColorCorrectionOutput
 */
export const zImageEditingColorCorrectionOutput = z.object({
  images: z.array(zFalAiImageEditingColorCorrectionImage),
  seed: z.int(),
})

/**
 * BaseInput
 */
export const zImageEditingCartoonifyInput = z.object({
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '3:2', '1:1', '2:3', '3:4', '9:16', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Image prompt for the omni model.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.',
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps for sampling.',
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The same seed and the same prompt given to the same version of the model will output the same image every time.',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingCartoonifyImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * CartoonifyOutput
 */
export const zImageEditingCartoonifyOutput = z.object({
  images: z.array(zFalAiImageEditingCartoonifyImage),
  seed: z.int(),
})

/**
 * BackgroundChangeInput
 */
export const zImageEditingBackgroundChangeInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The desired background to apply.',
      }),
    )
    .default('beach sunset with palm trees'),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '3:2', '1:1', '2:3', '3:4', '9:16', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Image prompt for the omni model.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.',
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps for sampling.',
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The same seed and the same prompt given to the same version of the model will output the same image every time.',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingBackgroundChangeImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * BackgroundChangeOutput
 */
export const zImageEditingBackgroundChangeOutput = z.object({
  images: z.array(zFalAiImageEditingBackgroundChangeImage),
  seed: z.int(),
})

/**
 * AgeProgressionInput
 */
export const zImageEditingAgeProgressionInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The age change to apply.',
      }),
    )
    .default('20 years older'),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '3:2', '1:1', '2:3', '3:4', '9:16', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Image prompt for the omni model.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.',
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps for sampling.',
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The same seed and the same prompt given to the same version of the model will output the same image every time.',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingAgeProgressionImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * AgeProgressionOutput
 */
export const zImageEditingAgeProgressionOutput = z.object({
  images: z.array(zFalAiImageEditingAgeProgressionImage),
  seed: z.int(),
})

/**
 * FluxKontextMultiInput
 */
export const zFluxProKontextMaxMultiInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '3:2', '1:1', '2:3', '3:4', '9:16', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description: 'Image prompt for the omni model.',
  }),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enhance the prompt for better results.',
      }),
    )
    .default(false),
})

/**
 * Image
 */
export const zRegistryImageFastSdxlModelsImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxProKontextMaxMultiOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zRegistryImageFastSdxlModelsImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * FluxKontextMultiInput
 */
export const zFluxProKontextMultiInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '3:2', '1:1', '2:3', '3:4', '9:16', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description: 'Image prompt for the omni model.',
  }),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enhance the prompt for better results.',
      }),
    )
    .default(false),
})

/**
 * Image
 */
export const zFalAiFluxProKontextMultiRegistryImageFastSdxlModelsImage =
  z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int(),
  })

/**
 * Output
 */
export const zFluxProKontextMultiOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFluxProKontextMultiRegistryImageFastSdxlModelsImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * FluxKontextInput
 */
export const zFluxProKontextMaxInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '3:2', '1:1', '2:3', '3:4', '9:16', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Image prompt for the omni model.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enhance the prompt for better results.',
      }),
    )
    .default(false),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalToolkitImageImageImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FluxKontextOutput
 */
export const zFluxProKontextMaxOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalToolkitImageImageImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * BaseKontextEditInput
 */
export const zFluxKontextDevInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to edit the image.',
  }),
  resolution_mode: z.optional(
    z
      .enum([
        'auto',
        'match_input',
        '1:1',
        '16:9',
        '21:9',
        '3:2',
        '2:3',
        '4:5',
        '5:4',
        '3:4',
        '4:3',
        '9:16',
        '9:21',
      ])
      .register(z.globalRegistry, {
        description:
          "\n             Determines how the output resolution is set for image editing.\n             - `auto`: The model selects an optimal resolution from a predefined set that best matches the input image's aspect ratio. This is the recommended setting for most use cases as it's what the model was trained on.\n             - `match_input`: The model will attempt to use the same resolution as the input image. The resolution will be adjusted to be compatible with the model's requirements (e.g. dimensions must be multiples of 16 and within supported limits).\n             Apart from these, a few aspect ratios are also supported.\n             ",
      }),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        'The speed of the generation. The higher the speed, the faster the generation.',
    }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'Output format',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to edit.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(2.5),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(10).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
})

/**
 * Image
 */
export const zFalAiFluxKontextDevImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * KontextEditOutput
 */
export const zFluxKontextDevOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFluxKontextDevImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * FluxKontextInput
 */
export const zFluxProKontextInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '3:2', '1:1', '2:3', '3:4', '9:16', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Image prompt for the omni model.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enhance the prompt for better results.',
      }),
    )
    .default(false),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFluxProKontextFalToolkitImageImageImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FluxKontextOutput
 */
export const zFluxProKontextOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFluxProKontextFalToolkitImageImageImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageEditInput
 */
export const zBagelEditInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to edit the image with.',
  }),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for the generation.',
    }),
  ),
  use_thought: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use thought tokens for generation. If set to true, the model will "think" to potentially improve generation quality. Increases generation time and increases the cost by 20%.',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The image to edit.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBagelEditImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ImageEditOutput
 */
export const zBagelEditOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiBagelEditImage).register(z.globalRegistry, {
    description: 'The edited images.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageInput
 */
export const zRembgEnhanceInput = z.object({
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input image',
  }),
})

/**
 * File
 */
export const zSmoretalkAiRembgEnhanceFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * ImageOutput
 */
export const zRembgEnhanceOutput = z.object({
  image: zSmoretalkAiRembgEnhanceFile,
})

/**
 * UpscaleInput
 */
export const zRecraftUpscaleCreativeInput = z.object({
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to be upscaled. Must be in PNG format.',
  }),
})

/**
 * File
 */
export const zFalAiRecraftUpscaleCreativeFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * UpscaleOutput
 */
export const zRecraftUpscaleCreativeOutput = z.object({
  image: zFalAiRecraftUpscaleCreativeFile,
})

/**
 * UpscaleInput
 */
export const zRecraftUpscaleCrispInput = z.object({
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to be upscaled. Must be in PNG format.',
  }),
})

/**
 * File
 */
export const zFalAiRecraftUpscaleCrispFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * UpscaleOutput
 */
export const zRecraftUpscaleCrispOutput = z.object({
  image: zFalAiRecraftUpscaleCrispFile,
})

/**
 * RGBColor
 */
export const zFalAiRecraftV3ImageToImageRgbColor = z.object({
  r: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Red color value',
      }),
    )
    .default(0),
  b: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Blue color value',
      }),
    )
    .default(0),
  g: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Green color value',
      }),
    )
    .default(0),
})

/**
 * ImageToImageInput
 */
export const zRecraftV3ImageToImageInput = z.object({
  prompt: z.string().max(1000).register(z.globalRegistry, {
    description: 'A text description of areas to change.',
  }),
  style: z.optional(
    z
      .enum([
        'any',
        'realistic_image',
        'digital_illustration',
        'vector_illustration',
        'realistic_image/b_and_w',
        'realistic_image/hard_flash',
        'realistic_image/hdr',
        'realistic_image/natural_light',
        'realistic_image/studio_portrait',
        'realistic_image/enterprise',
        'realistic_image/motion_blur',
        'realistic_image/evening_light',
        'realistic_image/faded_nostalgia',
        'realistic_image/forest_life',
        'realistic_image/mystic_naturalism',
        'realistic_image/natural_tones',
        'realistic_image/organic_calm',
        'realistic_image/real_life_glow',
        'realistic_image/retro_realism',
        'realistic_image/retro_snapshot',
        'realistic_image/urban_drama',
        'realistic_image/village_realism',
        'realistic_image/warm_folk',
        'digital_illustration/pixel_art',
        'digital_illustration/hand_drawn',
        'digital_illustration/grain',
        'digital_illustration/infantile_sketch',
        'digital_illustration/2d_art_poster',
        'digital_illustration/handmade_3d',
        'digital_illustration/hand_drawn_outline',
        'digital_illustration/engraving_color',
        'digital_illustration/2d_art_poster_2',
        'digital_illustration/antiquarian',
        'digital_illustration/bold_fantasy',
        'digital_illustration/child_book',
        'digital_illustration/child_books',
        'digital_illustration/cover',
        'digital_illustration/crosshatch',
        'digital_illustration/digital_engraving',
        'digital_illustration/expressionism',
        'digital_illustration/freehand_details',
        'digital_illustration/grain_20',
        'digital_illustration/graphic_intensity',
        'digital_illustration/hard_comics',
        'digital_illustration/long_shadow',
        'digital_illustration/modern_folk',
        'digital_illustration/multicolor',
        'digital_illustration/neon_calm',
        'digital_illustration/noir',
        'digital_illustration/nostalgic_pastel',
        'digital_illustration/outline_details',
        'digital_illustration/pastel_gradient',
        'digital_illustration/pastel_sketch',
        'digital_illustration/pop_art',
        'digital_illustration/pop_renaissance',
        'digital_illustration/street_art',
        'digital_illustration/tablet_sketch',
        'digital_illustration/urban_glow',
        'digital_illustration/urban_sketching',
        'digital_illustration/vanilla_dreams',
        'digital_illustration/young_adult_book',
        'digital_illustration/young_adult_book_2',
        'vector_illustration/bold_stroke',
        'vector_illustration/chemistry',
        'vector_illustration/colored_stencil',
        'vector_illustration/contour_pop_art',
        'vector_illustration/cosmics',
        'vector_illustration/cutout',
        'vector_illustration/depressive',
        'vector_illustration/editorial',
        'vector_illustration/emotional_flat',
        'vector_illustration/infographical',
        'vector_illustration/marker_outline',
        'vector_illustration/mosaic',
        'vector_illustration/naivector',
        'vector_illustration/roundish_flat',
        'vector_illustration/segmented_colors',
        'vector_illustration/sharp_contrast',
        'vector_illustration/thin',
        'vector_illustration/vector_photo',
        'vector_illustration/vivid_shapes',
        'vector_illustration/engraving',
        'vector_illustration/line_art',
        'vector_illustration/line_circuit',
        'vector_illustration/linocut',
      ])
      .register(z.globalRegistry, {
        description:
          'The style of the generated images. Vector images cost 2X as much.',
      }),
  ),
  style_id: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The ID of the custom style reference (optional)',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the image to modify. Must be less than 5 MB in size, have resolution less than 16 MP and max dimension less than 4096 pixels.',
  }),
  strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Defines the difference with the original image, should lie in [0, 1], where 0 means almost identical, and 1 means miserable similarity',
      }),
    )
    .default(0.5),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  colors: z
    .optional(
      z.array(zFalAiRecraftV3ImageToImageRgbColor).register(z.globalRegistry, {
        description: 'An array of preferable colors',
      }),
    )
    .default([]),
  negative_prompt: z.optional(
    z.string().max(1000).register(z.globalRegistry, {
      description: 'A text description of undesired elements on an image',
    }),
  ),
})

/**
 * File
 */
export const zFalAiRecraftV3ImageToImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ImageToImageOutput
 */
export const zRecraftV3ImageToImageOutput = z.object({
  images: z.array(zFalAiRecraftV3ImageToImageFile).register(z.globalRegistry, {
    description: 'The generated images',
  }),
})

/**
 * MiniMaxTextToImageWithReferenceRequest
 */
export const zMinimaxImage01SubjectReferenceInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable automatic prompt optimization',
      }),
    )
    .default(false),
  aspect_ratio: z.optional(
    z
      .enum(['1:1', '16:9', '4:3', '3:2', '2:3', '3:4', '9:16', '21:9'])
      .register(z.globalRegistry, {
        description: 'Aspect ratio of the generated image',
      }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(9).register(z.globalRegistry, {
        description: 'Number of images to generate (1-9)',
      }),
    )
    .default(1),
  prompt: z.string().min(1).max(1500).register(z.globalRegistry, {
    description: 'Text prompt for image generation (max 1500 characters)',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the subject reference image to use for consistent character appearance',
  }),
})

/**
 * File
 */
export const zFalAiMinimaxImage01SubjectReferenceFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * MiniMaxTextToImageWithReferenceOutput
 */
export const zMinimaxImage01SubjectReferenceOutput = z.object({
  images: z
    .array(zFalAiMinimaxImage01SubjectReferenceFile)
    .register(z.globalRegistry, {
      description: 'Generated images',
    }),
})

/**
 * ImageSize
 */
export const zFalAiHidreamI1FullImageToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zFalAiHidreamI1FullImageToImageLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
  weight_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'Name of the LoRA weight. Used only if `path` is a Hugging Face repository, and required only if you have more than 1 safetensors file in the repo.',
    }),
  ),
})

/**
 * ImageToImageInput
 */
export const zHidreamI1FullImageToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiHidreamI1FullImageToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The image URL to generate an image from.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  loras: z
    .optional(
      z
        .array(zFalAiHidreamI1FullImageToImageLoraWeight)
        .register(z.globalRegistry, {
          description:
            'A list of LoRAs to apply to the model. Each LoRA specifies its path, scale, and optional weight name.',
        }),
    )
    .default([]),
  strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Denoising strength for image-to-image generation.',
      }),
    )
    .default(0.75),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(50),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zFalAiHidreamI1FullImageToImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Img2ImgOutput
 */
export const zHidreamI1FullImageToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiHidreamI1FullImageToImageImage)
    .register(z.globalRegistry, {
      description: 'The generated images',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiIdeogramV3ReframeImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * RGBColor
 */
export const zFalAiIdeogramV3ReframeRgbColor = z.object({
  r: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Red color value',
      }),
    )
    .default(0),
  b: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Blue color value',
      }),
    )
    .default(0),
  g: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Green color value',
      }),
    )
    .default(0),
})

/**
 * ColorPaletteMember
 */
export const zFalAiIdeogramV3ReframeColorPaletteMember = z.object({
  color_weight: z.optional(z.union([z.number().gte(0.05).lte(1), z.unknown()])),
  rgb: zFalAiIdeogramV3ReframeRgbColor,
})

/**
 * ColorPalette
 */
export const zFalAiIdeogramV3ReframeColorPalette = z.object({
  members: z.optional(
    z.union([z.array(zFalAiIdeogramV3ReframeColorPaletteMember), z.unknown()]),
  ),
  name: z.optional(
    z.union([
      z.enum([
        'EMBER',
        'FRESH',
        'JUNGLE',
        'MAGIC',
        'MELON',
        'MOSAIC',
        'PASTEL',
        'ULTRAMARINE',
      ]),
      z.unknown(),
    ]),
  ),
})

/**
 * ReframeImageInputV3
 */
export const zIdeogramV3ReframeInput = z.object({
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'Number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.union([
    zFalAiIdeogramV3ReframeImageSize,
    z.enum([
      'square_hd',
      'square',
      'portrait_4_3',
      'portrait_16_9',
      'landscape_4_3',
      'landscape_16_9',
    ]),
  ]),
  style: z.optional(
    z.union([z.enum(['AUTO', 'GENERAL', 'REALISTIC', 'DESIGN']), z.unknown()]),
  ),
  style_preset: z.optional(
    z.union([
      z.enum([
        '80S_ILLUSTRATION',
        '90S_NOSTALGIA',
        'ABSTRACT_ORGANIC',
        'ANALOG_NOSTALGIA',
        'ART_BRUT',
        'ART_DECO',
        'ART_POSTER',
        'AURA',
        'AVANT_GARDE',
        'BAUHAUS',
        'BLUEPRINT',
        'BLURRY_MOTION',
        'BRIGHT_ART',
        'C4D_CARTOON',
        'CHILDRENS_BOOK',
        'COLLAGE',
        'COLORING_BOOK_I',
        'COLORING_BOOK_II',
        'CUBISM',
        'DARK_AURA',
        'DOODLE',
        'DOUBLE_EXPOSURE',
        'DRAMATIC_CINEMA',
        'EDITORIAL',
        'EMOTIONAL_MINIMAL',
        'ETHEREAL_PARTY',
        'EXPIRED_FILM',
        'FLAT_ART',
        'FLAT_VECTOR',
        'FOREST_REVERIE',
        'GEO_MINIMALIST',
        'GLASS_PRISM',
        'GOLDEN_HOUR',
        'GRAFFITI_I',
        'GRAFFITI_II',
        'HALFTONE_PRINT',
        'HIGH_CONTRAST',
        'HIPPIE_ERA',
        'ICONIC',
        'JAPANDI_FUSION',
        'JAZZY',
        'LONG_EXPOSURE',
        'MAGAZINE_EDITORIAL',
        'MINIMAL_ILLUSTRATION',
        'MIXED_MEDIA',
        'MONOCHROME',
        'NIGHTLIFE',
        'OIL_PAINTING',
        'OLD_CARTOONS',
        'PAINT_GESTURE',
        'POP_ART',
        'RETRO_ETCHING',
        'RIVIERA_POP',
        'SPOTLIGHT_80S',
        'STYLIZED_RED',
        'SURREAL_COLLAGE',
        'TRAVEL_POSTER',
        'VINTAGE_GEO',
        'VINTAGE_POSTER',
        'WATERCOLOR',
        'WEIRD',
        'WOODBLOCK_PRINT',
      ]),
      z.unknown(),
    ]),
  ),
  rendering_speed: z.optional(
    z.enum(['TURBO', 'BALANCED', 'QUALITY']).register(z.globalRegistry, {
      description: 'The rendering speed to use.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  color_palette: z.optional(
    z.union([zFalAiIdeogramV3ReframeColorPalette, z.unknown()]),
  ),
  style_codes: z.optional(z.union([z.array(z.string()), z.unknown()])),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The image URL to reframe',
  }),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  image_urls: z.optional(z.union([z.array(z.string()), z.unknown()])),
})

/**
 * File
 */
export const zFalAiIdeogramV3ReframeFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * ReframeOutputV3
 */
export const zIdeogramV3ReframeOutput = z.object({
  images: z.array(zFalAiIdeogramV3ReframeFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for the random number generator',
  }),
})

/**
 * RGBColor
 */
export const zFalAiIdeogramV3ReplaceBackgroundRgbColor = z.object({
  r: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Red color value',
      }),
    )
    .default(0),
  b: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Blue color value',
      }),
    )
    .default(0),
  g: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Green color value',
      }),
    )
    .default(0),
})

/**
 * ColorPaletteMember
 */
export const zFalAiIdeogramV3ReplaceBackgroundColorPaletteMember = z.object({
  color_weight: z.optional(z.union([z.number().gte(0.05).lte(1), z.unknown()])),
  rgb: zFalAiIdeogramV3ReplaceBackgroundRgbColor,
})

/**
 * ColorPalette
 */
export const zFalAiIdeogramV3ReplaceBackgroundColorPalette = z.object({
  members: z.optional(
    z.union([
      z.array(zFalAiIdeogramV3ReplaceBackgroundColorPaletteMember),
      z.unknown(),
    ]),
  ),
  name: z.optional(
    z.union([
      z.enum([
        'EMBER',
        'FRESH',
        'JUNGLE',
        'MAGIC',
        'MELON',
        'MOSAIC',
        'PASTEL',
        'ULTRAMARINE',
      ]),
      z.unknown(),
    ]),
  ),
})

/**
 * ReplaceBackgroundInputV3
 */
export const zIdeogramV3ReplaceBackgroundInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Cyber punk city with neon lights and skyscrappers',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'Number of images to generate.',
      }),
    )
    .default(1),
  style: z.optional(
    z.union([z.enum(['AUTO', 'GENERAL', 'REALISTIC', 'DESIGN']), z.unknown()]),
  ),
  style_preset: z.optional(
    z.union([
      z.enum([
        '80S_ILLUSTRATION',
        '90S_NOSTALGIA',
        'ABSTRACT_ORGANIC',
        'ANALOG_NOSTALGIA',
        'ART_BRUT',
        'ART_DECO',
        'ART_POSTER',
        'AURA',
        'AVANT_GARDE',
        'BAUHAUS',
        'BLUEPRINT',
        'BLURRY_MOTION',
        'BRIGHT_ART',
        'C4D_CARTOON',
        'CHILDRENS_BOOK',
        'COLLAGE',
        'COLORING_BOOK_I',
        'COLORING_BOOK_II',
        'CUBISM',
        'DARK_AURA',
        'DOODLE',
        'DOUBLE_EXPOSURE',
        'DRAMATIC_CINEMA',
        'EDITORIAL',
        'EMOTIONAL_MINIMAL',
        'ETHEREAL_PARTY',
        'EXPIRED_FILM',
        'FLAT_ART',
        'FLAT_VECTOR',
        'FOREST_REVERIE',
        'GEO_MINIMALIST',
        'GLASS_PRISM',
        'GOLDEN_HOUR',
        'GRAFFITI_I',
        'GRAFFITI_II',
        'HALFTONE_PRINT',
        'HIGH_CONTRAST',
        'HIPPIE_ERA',
        'ICONIC',
        'JAPANDI_FUSION',
        'JAZZY',
        'LONG_EXPOSURE',
        'MAGAZINE_EDITORIAL',
        'MINIMAL_ILLUSTRATION',
        'MIXED_MEDIA',
        'MONOCHROME',
        'NIGHTLIFE',
        'OIL_PAINTING',
        'OLD_CARTOONS',
        'PAINT_GESTURE',
        'POP_ART',
        'RETRO_ETCHING',
        'RIVIERA_POP',
        'SPOTLIGHT_80S',
        'STYLIZED_RED',
        'SURREAL_COLLAGE',
        'TRAVEL_POSTER',
        'VINTAGE_GEO',
        'VINTAGE_POSTER',
        'WATERCOLOR',
        'WEIRD',
        'WOODBLOCK_PRINT',
      ]),
      z.unknown(),
    ]),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Determine if MagicPrompt should be used in generating the request or not.',
      }),
    )
    .default(true),
  rendering_speed: z.optional(
    z.enum(['TURBO', 'BALANCED', 'QUALITY']).register(z.globalRegistry, {
      description: 'The rendering speed to use.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  color_palette: z.optional(
    z.union([zFalAiIdeogramV3ReplaceBackgroundColorPalette, z.unknown()]),
  ),
  style_codes: z.optional(z.union([z.array(z.string()), z.unknown()])),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The image URL whose background needs to be replaced',
  }),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  image_urls: z.optional(z.union([z.array(z.string()), z.unknown()])),
})

/**
 * File
 */
export const zFalAiIdeogramV3ReplaceBackgroundFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * ReplaceBackgroundOutputV3
 */
export const zIdeogramV3ReplaceBackgroundOutput = z.object({
  images: z.array(zFalAiIdeogramV3ReplaceBackgroundFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for the random number generator',
  }),
})

/**
 * ImageSize
 */
export const zFalAiIdeogramV3RemixImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * RGBColor
 */
export const zFalAiIdeogramV3RemixRgbColor = z.object({
  r: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Red color value',
      }),
    )
    .default(0),
  b: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Blue color value',
      }),
    )
    .default(0),
  g: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Green color value',
      }),
    )
    .default(0),
})

/**
 * ColorPaletteMember
 */
export const zFalAiIdeogramV3RemixColorPaletteMember = z.object({
  color_weight: z.optional(z.union([z.number().gte(0.05).lte(1), z.unknown()])),
  rgb: zFalAiIdeogramV3RemixRgbColor,
})

/**
 * ColorPalette
 */
export const zFalAiIdeogramV3RemixColorPalette = z.object({
  members: z.optional(
    z.union([z.array(zFalAiIdeogramV3RemixColorPaletteMember), z.unknown()]),
  ),
  name: z.optional(
    z.union([
      z.enum([
        'EMBER',
        'FRESH',
        'JUNGLE',
        'MAGIC',
        'MELON',
        'MOSAIC',
        'PASTEL',
        'ULTRAMARINE',
      ]),
      z.unknown(),
    ]),
  ),
})

/**
 * RemixImageInputV3
 */
export const zIdeogramV3RemixInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to remix the image with',
  }),
  image_size: z.optional(
    z.union([
      zFalAiIdeogramV3RemixImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
      z.unknown(),
    ]),
  ),
  style: z.optional(
    z.union([z.enum(['AUTO', 'GENERAL', 'REALISTIC', 'DESIGN']), z.unknown()]),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Determine if MagicPrompt should be used in generating the request or not.',
      }),
    )
    .default(true),
  rendering_speed: z.optional(
    z.enum(['TURBO', 'BALANCED', 'QUALITY']).register(z.globalRegistry, {
      description: 'The rendering speed to use.',
    }),
  ),
  image_urls: z.optional(z.union([z.array(z.string()), z.unknown()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Description of what to exclude from an image. Descriptions in the prompt take precedence to descriptions in the negative prompt.',
      }),
    )
    .default(''),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'Number of images to generate.',
      }),
    )
    .default(1),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The image URL to remix',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  color_palette: z.optional(
    z.union([zFalAiIdeogramV3RemixColorPalette, z.unknown()]),
  ),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description: 'Strength of the input image in the remix',
      }),
    )
    .default(0.8),
  style_codes: z.optional(z.union([z.array(z.string()), z.unknown()])),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * File
 */
export const zFalAiIdeogramV3RemixFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * RemixOutputV3
 */
export const zIdeogramV3RemixOutput = z.object({
  images: z.array(zFalAiIdeogramV3RemixFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for the random number generator',
  }),
})

/**
 * RGBColor
 */
export const zFalAiIdeogramV3EditRgbColor = z.object({
  r: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Red color value',
      }),
    )
    .default(0),
  b: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Blue color value',
      }),
    )
    .default(0),
  g: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Green color value',
      }),
    )
    .default(0),
})

/**
 * ColorPaletteMember
 */
export const zFalAiIdeogramV3EditColorPaletteMember = z.object({
  color_weight: z.optional(z.union([z.number().gte(0.05).lte(1), z.unknown()])),
  rgb: zFalAiIdeogramV3EditRgbColor,
})

/**
 * ColorPalette
 */
export const zFalAiIdeogramV3EditColorPalette = z.object({
  members: z.optional(
    z.union([z.array(zFalAiIdeogramV3EditColorPaletteMember), z.unknown()]),
  ),
  name: z.optional(
    z.union([
      z.enum([
        'EMBER',
        'FRESH',
        'JUNGLE',
        'MAGIC',
        'MELON',
        'MOSAIC',
        'PASTEL',
        'ULTRAMARINE',
      ]),
      z.unknown(),
    ]),
  ),
})

/**
 * EditImageInputV3
 */
export const zIdeogramV3EditInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to fill the masked part of the image.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'Number of images to generate.',
      }),
    )
    .default(1),
  style_preset: z.optional(
    z.union([
      z.enum([
        '80S_ILLUSTRATION',
        '90S_NOSTALGIA',
        'ABSTRACT_ORGANIC',
        'ANALOG_NOSTALGIA',
        'ART_BRUT',
        'ART_DECO',
        'ART_POSTER',
        'AURA',
        'AVANT_GARDE',
        'BAUHAUS',
        'BLUEPRINT',
        'BLURRY_MOTION',
        'BRIGHT_ART',
        'C4D_CARTOON',
        'CHILDRENS_BOOK',
        'COLLAGE',
        'COLORING_BOOK_I',
        'COLORING_BOOK_II',
        'CUBISM',
        'DARK_AURA',
        'DOODLE',
        'DOUBLE_EXPOSURE',
        'DRAMATIC_CINEMA',
        'EDITORIAL',
        'EMOTIONAL_MINIMAL',
        'ETHEREAL_PARTY',
        'EXPIRED_FILM',
        'FLAT_ART',
        'FLAT_VECTOR',
        'FOREST_REVERIE',
        'GEO_MINIMALIST',
        'GLASS_PRISM',
        'GOLDEN_HOUR',
        'GRAFFITI_I',
        'GRAFFITI_II',
        'HALFTONE_PRINT',
        'HIGH_CONTRAST',
        'HIPPIE_ERA',
        'ICONIC',
        'JAPANDI_FUSION',
        'JAZZY',
        'LONG_EXPOSURE',
        'MAGAZINE_EDITORIAL',
        'MINIMAL_ILLUSTRATION',
        'MIXED_MEDIA',
        'MONOCHROME',
        'NIGHTLIFE',
        'OIL_PAINTING',
        'OLD_CARTOONS',
        'PAINT_GESTURE',
        'POP_ART',
        'RETRO_ETCHING',
        'RIVIERA_POP',
        'SPOTLIGHT_80S',
        'STYLIZED_RED',
        'SURREAL_COLLAGE',
        'TRAVEL_POSTER',
        'VINTAGE_GEO',
        'VINTAGE_POSTER',
        'WATERCOLOR',
        'WEIRD',
        'WOODBLOCK_PRINT',
      ]),
      z.unknown(),
    ]),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Determine if MagicPrompt should be used in generating the request or not.',
      }),
    )
    .default(true),
  rendering_speed: z.optional(
    z.enum(['TURBO', 'BALANCED', 'QUALITY']).register(z.globalRegistry, {
      description: 'The rendering speed to use.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  color_palette: z.optional(
    z.union([zFalAiIdeogramV3EditColorPalette, z.unknown()]),
  ),
  style_codes: z.optional(z.union([z.array(z.string()), z.unknown()])),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The image URL to generate an image from. MUST have the exact same dimensions (width and height) as the mask image.',
  }),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  image_urls: z.optional(z.union([z.array(z.string()), z.unknown()])),
  mask_url: z.string().register(z.globalRegistry, {
    description:
      'The mask URL to inpaint the image. MUST have the exact same dimensions (width and height) as the input image.',
  }),
})

/**
 * File
 */
export const zFalAiIdeogramV3EditFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * EditOutputV3
 */
export const zIdeogramV3EditOutput = z.object({
  images: z.array(zFalAiIdeogramV3EditFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for the random number generator',
  }),
})

/**
 * TextToImageInput
 */
export const zStep1xEditInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The image URL to generate an image from. Needs to match the dimensions of the mask.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(4),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(30),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiStep1xEditImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ImageOutput
 */
export const zStep1xEditOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiStep1xEditImage).register(z.globalRegistry, {
    description: 'The generated images',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * Image2SVGInput
 */
export const zImage2SvgInput = z.object({
  splice_threshold: z
    .optional(
      z.int().gte(0).lte(90).register(z.globalRegistry, {
        description: 'Splice threshold for joining paths',
      }),
    )
    .default(45),
  hierarchical: z.optional(
    z.enum(['stacked', 'cutout']).register(z.globalRegistry, {
      description: 'Hierarchical mode: stacked or cutout',
    }),
  ),
  color_precision: z
    .optional(
      z.int().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Color quantization level',
      }),
    )
    .default(6),
  colormode: z.optional(
    z.enum(['color', 'binary']).register(z.globalRegistry, {
      description: 'Choose between color or binary (black and white) output',
    }),
  ),
  max_iterations: z
    .optional(
      z.int().gte(1).lte(20).register(z.globalRegistry, {
        description: 'Maximum number of iterations for optimization',
      }),
    )
    .default(10),
  length_threshold: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description: 'Length threshold for curves/lines',
      }),
    )
    .default(4),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The image to convert to SVG',
  }),
  mode: z.optional(
    z.enum(['spline', 'polygon']).register(z.globalRegistry, {
      description: 'Mode: spline (curved) or polygon (straight lines)',
    }),
  ),
  corner_threshold: z
    .optional(
      z.int().gte(0).lte(180).register(z.globalRegistry, {
        description: 'Corner detection threshold in degrees',
      }),
    )
    .default(60),
  path_precision: z
    .optional(
      z.int().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Decimal precision for path coordinates',
      }),
    )
    .default(3),
  filter_speckle: z
    .optional(
      z.int().gte(0).lte(20).register(z.globalRegistry, {
        description: 'Filter out small speckles and noise',
      }),
    )
    .default(4),
  layer_difference: z
    .optional(
      z.int().gte(1).lte(32).register(z.globalRegistry, {
        description: 'Layer difference threshold for hierarchical mode',
      }),
    )
    .default(16),
})

/**
 * File
 */
export const zFalAiImage2SvgFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Image2SVGOutput
 */
export const zImage2SvgOutput = z.object({
  images: z.array(zFalAiImage2SvgFile).register(z.globalRegistry, {
    description: 'The converted SVG file',
  }),
})

/**
 * ImageSize
 */
export const zFalAiUnoImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * UNOInput
 */
export const zUnoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiUnoImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  input_image_urls: z.array(z.string()).register(z.globalRegistry, {
    description: 'URL of images to use while generating the image.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducible generation. If set none, a random seed will be used.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiUnoImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * UNOOutput
 */
export const zUnoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used to generate the image.',
  }),
  images: z.array(zFalAiUnoImage).register(z.globalRegistry, {
    description: 'The URLs of the generated images.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * EditImageRequest
 */
export const zGptImage1EditImageInput = z.object({
  prompt: z.string().min(2).register(z.globalRegistry, {
    description: 'The prompt for image generation',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'Number of images to generate',
      }),
    )
    .default(1),
  image_size: z.optional(
    z
      .enum(['auto', '1024x1024', '1536x1024', '1024x1536'])
      .register(z.globalRegistry, {
        description: 'Aspect ratio for the generated image',
      }),
  ),
  background: z.optional(
    z.enum(['auto', 'transparent', 'opaque']).register(z.globalRegistry, {
      description: 'Background for the generated image',
    }),
  ),
  quality: z.optional(
    z.enum(['auto', 'low', 'medium', 'high']).register(z.globalRegistry, {
      description: 'Quality for the generated image',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'Output format for the images',
    }),
  ),
  input_fidelity: z.optional(
    z.enum(['low', 'high']).register(z.globalRegistry, {
      description: 'Input fidelity for the generated image',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'The URLs of the images to use as a reference for the generation.',
  }),
})

/**
 * ImageFile
 */
export const zFalAiGptImage1EditImageImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * EditImageResponse
 */
export const zGptImage1EditImageOutput = z.object({
  images: z
    .array(zFalAiGptImage1EditImageImageFile)
    .register(z.globalRegistry, {
      description: 'The generated images.',
    }),
})

/**
 * ImageSize
 */
export const zRundiffusionFalJuggernautFluxLoraInpaintingImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zRundiffusionFalJuggernautFluxLoraInpaintingLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * InpaintInput
 */
export const zJuggernautFluxLoraInpaintingInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zRundiffusionFalJuggernautFluxLoraInpaintingImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to use for inpainting. or img2img',
  }),
  loras: z
    .optional(
      z
        .array(zRundiffusionFalJuggernautFluxLoraInpaintingLoraWeight)
        .register(z.globalRegistry, {
          description:
            '\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ',
        }),
    )
    .default([]),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.',
      }),
    )
    .default(0.85),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(35).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  mask_url: z.string().register(z.globalRegistry, {
    description: '\n            The mask to area to Inpaint in.\n        ',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zRundiffusionFalJuggernautFluxLoraInpaintingImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zJuggernautFluxLoraInpaintingOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zRundiffusionFalJuggernautFluxLoraInpaintingImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * Input
 */
export const zFashnTryonV15Input = z.object({
  model_image: z.string().register(z.globalRegistry, {
    description: 'URL or base64 of the model image',
  }),
  moderation_level: z.optional(
    z.enum(['none', 'permissive', 'conservative']).register(z.globalRegistry, {
      description:
        "Content moderation level for garment images. 'none' disables moderation, 'permissive' blocks only explicit content, 'conservative' also blocks underwear and swimwear.",
    }),
  ),
  garment_photo_type: z.optional(
    z.enum(['auto', 'model', 'flat-lay']).register(z.globalRegistry, {
      description:
        "Specifies the type of garment photo to optimize internal parameters for better performance. 'model' is for photos of garments on a model, 'flat-lay' is for flat-lay or ghost mannequin images, and 'auto' attempts to automatically detect the photo type.",
    }),
  ),
  garment_image: z.string().register(z.globalRegistry, {
    description: 'URL or base64 of the garment image',
  }),
  category: z.optional(
    z
      .enum(['tops', 'bottoms', 'one-pieces', 'auto'])
      .register(z.globalRegistry, {
        description:
          "Category of the garment to try-on. 'auto' will attempt to automatically detect the category of the garment.",
      }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  segmentation_free: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Disables human parsing on the model image.',
      }),
    )
    .default(true),
  num_samples: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description:
          'Number of images to generate in a single run. Image generation has a random element in it, so trying multiple images at once increases the chances of getting a good result.',
      }),
    )
    .default(1),
  mode: z.optional(
    z.enum(['performance', 'balanced', 'quality']).register(z.globalRegistry, {
      description:
        "Specifies the mode of operation. 'performance' mode is faster but may sacrifice quality, 'balanced' mode is a balance between speed and quality, and 'quality' mode is slower but produces higher quality results.",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Sets random operations to a fixed state. Use the same seed to reproduce results with the same inputs, or different seed to force different results.',
    }),
  ),
  output_format: z.optional(
    z.enum(['png', 'jpeg']).register(z.globalRegistry, {
      description:
        "Output format of the generated images. 'png' is highest quality, while 'jpeg' is faster",
    }),
  ),
})

/**
 * File
 */
export const zFalAiFashnTryonV15File = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Output
 */
export const zFashnTryonV15Output = z.object({
  images: z.array(zFalAiFashnTryonV15File),
})

/**
 * PlushifyInput
 */
export const zPlushifyInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Prompt for the generation. Default is empty which is usually best, but sometimes it can help to add a description of the subject.',
      }),
    )
    .default(''),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'Number of images to generate',
      }),
    )
    .default(1),
  use_cfg_zero: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to use CFG zero',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to apply cartoon style to',
  }),
  scale: z
    .optional(
      z.number().gte(0.1).lte(2).register(z.globalRegistry, {
        description: 'Scale factor for the Cartoon effect',
      }),
    )
    .default(1),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps',
      }),
    )
    .default(28),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description: 'Guidance scale for the generation',
      }),
    )
    .default(3.5),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The seed for image generation. Same seed with same parameters will generate same image.',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiPlushifyImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zPlushifyOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiPlushifyImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiInstantCharacterImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * TextToImageInput
 */
export const zInstantCharacterInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiInstantCharacterImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  scale: z
    .optional(
      z.number().gte(0).lte(2).register(z.globalRegistry, {
        description:
          'The scale of the subject image. Higher values will make the subject image more prominent in the generated image.',
      }),
    )
    .default(1),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The image URL to generate an image from. Needs to match the dimensions of the mask.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiInstantCharacterImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ImageOutput
 */
export const zInstantCharacterOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiInstantCharacterImage).register(z.globalRegistry, {
    description: 'The generated images',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * CartoonifyInput
 */
export const zCartoonifyInput = z.object({
  use_cfg_zero: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to use CFG zero',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to apply Pixar style to',
  }),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description: 'Guidance scale for the generation',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps',
      }),
    )
    .default(28),
  scale: z
    .optional(
      z.number().gte(0.1).lte(2).register(z.globalRegistry, {
        description: 'Scale factor for the Pixar effect',
      }),
    )
    .default(1),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The seed for image generation. Same seed with same parameters will generate same image.',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiCartoonifyImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zCartoonifyOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiCartoonifyImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * MaskEraseRequest
 */
export const zFinegrainEraserMaskInput = z.object({
  mode: z.optional(
    z.enum(['express', 'standard', 'premium']).register(z.globalRegistry, {
      description: 'Erase quality mode',
    }),
  ),
  seed: z.optional(
    z.int().gte(0).lte(999).register(z.globalRegistry, {
      description: 'Random seed for reproducible generation',
    }),
  ),
  mask_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the mask image. Should be a binary mask where white (255) indicates areas to erase',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to edit',
  }),
})

/**
 * File
 */
export const zFalAiFinegrainEraserMaskFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * EraseOutput
 */
export const zFinegrainEraserMaskOutput = z.object({
  image: zFalAiFinegrainEraserMaskFile,
  used_seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generation',
  }),
})

/**
 * BoxPromptBase
 */
export const zBoxPromptBase = z.object({
  y_min: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Y Min Coordinate of the box',
      }),
    )
    .default(0),
  x_max: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'X Max Coordinate of the prompt',
      }),
    )
    .default(0),
  x_min: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'X Min Coordinate of the box',
      }),
    )
    .default(0),
  y_max: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Y Max Coordinate of the prompt',
      }),
    )
    .default(0),
})

/**
 * BBoxEraseRequest
 */
export const zFinegrainEraserBboxInput = z.object({
  mode: z.optional(
    z.enum(['express', 'standard', 'premium']).register(z.globalRegistry, {
      description: 'Erase quality mode',
    }),
  ),
  seed: z.optional(
    z.int().gte(0).lte(999).register(z.globalRegistry, {
      description: 'Random seed for reproducible generation',
    }),
  ),
  box_prompts: z.array(zBoxPromptBase).register(z.globalRegistry, {
    description:
      'List of bounding box coordinates to erase (only one box prompt is supported)',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to edit',
  }),
})

/**
 * File
 */
export const zFalAiFinegrainEraserBboxFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * EraseOutput
 */
export const zFinegrainEraserBboxOutput = z.object({
  image: zFalAiFinegrainEraserBboxFile,
  used_seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generation',
  }),
})

/**
 * PromptEraseRequest
 */
export const zFinegrainEraserInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text description of what to erase',
  }),
  mode: z.optional(
    z.enum(['express', 'standard', 'premium']).register(z.globalRegistry, {
      description: 'Erase quality mode',
    }),
  ),
  seed: z.optional(
    z.int().gte(0).lte(999).register(z.globalRegistry, {
      description: 'Random seed for reproducible generation',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to edit',
  }),
})

/**
 * File
 */
export const zFalAiFinegrainEraserFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * EraseOutput
 */
export const zFinegrainEraserOutput = z.object({
  image: zFalAiFinegrainEraserFile,
  used_seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generation',
  }),
})

/**
 * StarVectorInput
 */
export const zStarVectorInput = z.object({
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'seed to be used for generation',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to be used for relighting',
  }),
})

/**
 * File
 */
export const zFalAiStarVectorFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * StarVectorOutput
 */
export const zStarVectorOutput = z.object({
  image: zFalAiStarVectorFile,
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * Input
 */
export const zGhiblifyInput = z.object({
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to upscale.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiGhiblifyImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * Output
 */
export const zGhiblifyOutput = z.object({
  image: zFalAiGhiblifyImage,
})

/**
 * TheraInput
 */
export const zTheraInput = z.object({
  upscale_factor: z
    .optional(
      z.number().gte(1).lte(6).register(z.globalRegistry, {
        description: 'The upscaling factor for the image.',
      }),
    )
    .default(2),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for reproducible generation.',
    }),
  ),
  backbone: z.enum(['edsr', 'rdn']).register(z.globalRegistry, {
    description: 'Backbone to use for upscaling',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to be used for upscaling',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiTheraImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * TheraOutput
 */
export const zTheraOutput = z.object({
  image: zFalAiTheraImage,
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * MixDehazeNetInput
 */
export const zMixDehazeNetInput = z.object({
  model: z.optional(
    z.enum(['indoor', 'outdoor']).register(z.globalRegistry, {
      description: 'Model to be used for dehazing',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'seed to be used for generation',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to be used for image enhancement',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiMixDehazeNetImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * MixDehazeNetOutput
 */
export const zMixDehazeNetOutput = z.object({
  image: zFalAiMixDehazeNetImage,
})

/**
 * GeminiImageRequest
 */
export const zGeminiFlashEditInput = z.object({
  prompt: z.string().min(3).max(5000).register(z.globalRegistry, {
    description: 'The prompt for image generation or editing',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'Optional URL of an input image for editing. If not provided, generates a new image.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiGeminiFlashEditImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * GeminiImageOutput
 */
export const zGeminiFlashEditOutput = z.object({
  description: z.string().register(z.globalRegistry, {
    description: 'Text description or response from Gemini',
  }),
  image: zFalAiGeminiFlashEditImage,
})

/**
 * GeminiMultiImageRequest
 */
export const zGeminiFlashEditMultiInput = z.object({
  prompt: z.string().min(3).max(5000).register(z.globalRegistry, {
    description: 'The prompt for image generation or editing',
  }),
  input_image_urls: z
    .array(z.string())
    .min(1)
    .max(10)
    .register(z.globalRegistry, {
      description: 'List of URLs of input images for editing',
    }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiGeminiFlashEditMultiImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * GeminiImageOutput
 */
export const zGeminiFlashEditMultiOutput = z.object({
  description: z.string().register(z.globalRegistry, {
    description: 'Text description or response from Gemini',
  }),
  image: zFalAiGeminiFlashEditMultiImage,
})

/**
 * WatermarkInput
 */
export const zInvisibleWatermarkInput = z.object({
  decode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to decode a watermark from the image instead of encoding',
      }),
    )
    .default(false),
  watermark: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Text to use as watermark (for encoding only)',
      }),
    )
    .default('watermark'),
  length: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          'Length of watermark bits to decode (required when decode=True)',
      }),
    )
    .default(0),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to be watermarked or decoded',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiInvisibleWatermarkImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * WatermarkOutput
 */
export const zInvisibleWatermarkOutput = z.object({
  image: z.optional(zFalAiInvisibleWatermarkImage),
  extracted_watermark: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The extracted watermark text (when decoding)',
    }),
  ),
  length: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          'Length of the watermark bits used (helpful for future decoding)',
      }),
    )
    .default(0),
})

/**
 * DevImageToImageInput
 */
export const zJuggernautFluxProImageToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to generate an image from.',
  }),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the initial image. Higher strength values are better for this model.',
      }),
    )
    .default(0.95),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(10).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(40),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zRundiffusionFalJuggernautFluxProImageToImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zJuggernautFluxProImageToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zRundiffusionFalJuggernautFluxProImageToImageImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * DevImageToImageInput
 */
export const zJuggernautFluxBaseImageToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to generate an image from.',
  }),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the initial image. Higher strength values are better for this model.',
      }),
    )
    .default(0.95),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(10).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(40),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zRundiffusionFalJuggernautFluxBaseImageToImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zJuggernautFluxBaseImageToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zRundiffusionFalJuggernautFluxBaseImageToImageImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * DocResInputDewarp
 */
export const zDocresDewarpInput = z.object({
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to be used for relighting',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiDocresDewarpImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * DocResOutput
 */
export const zDocresDewarpOutput = z.object({
  image: zFalAiDocresDewarpImage,
})

/**
 * DocResInput
 */
export const zDocresInput = z.object({
  task: z
    .enum(['deshadowing', 'appearance', 'deblurring', 'binarization'])
    .register(z.globalRegistry, {
      description: 'Task to perform',
    }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to be used for relighting',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiDocresImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * DocResOutput
 */
export const zDocresOutput = z.object({
  image: zFalAiDocresImage,
})

/**
 * SwinSrInput
 */
export const zSwin2SrInput = z.object({
  task: z.optional(
    z
      .enum(['classical_sr', 'compressed_sr', 'real_sr'])
      .register(z.globalRegistry, {
        description: 'Task to perform',
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'seed to be used for generation',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to be used for image enhancement',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiSwin2SrImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * SwinSrOutput
 */
export const zSwin2SrOutput = z.object({
  image: zFalAiSwin2SrImage,
})

/**
 * RemixImageInput
 */
export const zIdeogramV2aRemixInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to remix the image with',
  }),
  aspect_ratio: z.optional(
    z
      .enum([
        '10:16',
        '16:10',
        '9:16',
        '16:9',
        '4:3',
        '3:4',
        '1:1',
        '1:3',
        '3:1',
        '3:2',
        '2:3',
      ])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image',
      }),
  ),
  style: z.optional(
    z
      .enum(['auto', 'general', 'realistic', 'design', 'render_3D', 'anime'])
      .register(z.globalRegistry, {
        description: 'The style of the generated image',
      }),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to expand the prompt with MagicPrompt functionality.',
      }),
    )
    .default(true),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The image URL to remix',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description: 'Strength of the input image in the remix',
      }),
    )
    .default(0.8),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * File
 */
export const zFalAiIdeogramV2aRemixFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * Output
 */
export const zIdeogramV2aRemixOutput = z.object({
  images: z.array(zFalAiIdeogramV2aRemixFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for the random number generator',
  }),
})

/**
 * RemixImageInput
 */
export const zIdeogramV2aTurboRemixInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to remix the image with',
  }),
  aspect_ratio: z.optional(
    z
      .enum([
        '10:16',
        '16:10',
        '9:16',
        '16:9',
        '4:3',
        '3:4',
        '1:1',
        '1:3',
        '3:1',
        '3:2',
        '2:3',
      ])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image',
      }),
  ),
  style: z.optional(
    z
      .enum(['auto', 'general', 'realistic', 'design', 'render_3D', 'anime'])
      .register(z.globalRegistry, {
        description: 'The style of the generated image',
      }),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to expand the prompt with MagicPrompt functionality.',
      }),
    )
    .default(true),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The image URL to remix',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description: 'Strength of the input image in the remix',
      }),
    )
    .default(0.8),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * File
 */
export const zFalAiIdeogramV2aTurboRemixFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * Output
 */
export const zIdeogramV2aTurboRemixOutput = z.object({
  images: z.array(zFalAiIdeogramV2aTurboRemixFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for the random number generator',
  }),
})

/**
 * ImageInput
 */
export const zEvfSamInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate segmentation from.',
  }),
  use_grounding_dino: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Use GroundingDINO instead of SAM for segmentation',
      }),
    )
    .default(false),
  semantic_type: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Enable semantic level segmentation for body parts, background or multi objects',
      }),
    )
    .default(false),
  fill_holes: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Fill holes in the mask using morphological operations',
      }),
    )
    .default(false),
  expand_mask: z
    .optional(
      z.int().gte(0).lte(20).register(z.globalRegistry, {
        description: 'Expand/dilate the mask by specified pixels',
      }),
    )
    .default(0),
  mask_only: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Output only the binary mask instead of masked image',
      }),
    )
    .default(true),
  revert_mask: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Invert the mask (background becomes foreground and vice versa)',
      }),
    )
    .default(false),
  blur_mask: z
    .optional(
      z.int().gte(0).lte(50).register(z.globalRegistry, {
        description:
          'Apply Gaussian blur to the mask. Value determines kernel size (must be odd number)',
      }),
    )
    .default(0),
  negative_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'Areas to exclude from segmentation (will be subtracted from prompt results)',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input image',
  }),
})

/**
 * File
 */
export const zFalAiEvfSamFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ImageOutput
 */
export const zEvfSamOutput = z.object({
  image: zFalAiEvfSamFile,
})

/**
 * DDColorInput
 */
export const zDdcolorInput = z.object({
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'seed to be used for generation',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to be used for relighting',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiDdcolorImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * DDColorOutput
 */
export const zDdcolorOutput = z.object({
  image: zFalAiDdcolorImage,
})

/**
 * SAM2AutomaticSegmentationInput
 */
export const zSam2AutoSegmentInput = z.object({
  points_per_side: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Number of points to sample along each side of the image.',
      }),
    )
    .default(32),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  min_mask_region_area: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Minimum area of a mask region.',
      }),
    )
    .default(100),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to be automatically segmented',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  pred_iou_thresh: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: 'Threshold for predicted IOU score.',
      }),
    )
    .default(0.88),
  stability_score_thresh: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: 'Threshold for stability score.',
      }),
    )
    .default(0.95),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiSam2AutoSegmentImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * SAM2AutomaticSegmentationOutput
 */
export const zSam2AutoSegmentOutput = z.object({
  combined_mask: zFalAiSam2AutoSegmentImage,
  individual_masks: z
    .array(zFalAiSam2AutoSegmentImage)
    .register(z.globalRegistry, {
      description: 'Individual segmentation masks.',
    }),
})

/**
 * Input
 */
export const zDrctSuperResolutionInput = z.object({
  upscale_factor: z.optional(
    z.literal(4).register(z.globalRegistry, {
      description: 'Upscaling factor.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to upscale.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiDrctSuperResolutionImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * Output
 */
export const zDrctSuperResolutionOutput = z.object({
  image: zFalAiDrctSuperResolutionImage,
})

/**
 * NafnetInputDenoise
 */
export const zNafnetDenoiseInput = z.object({
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'seed to be used for generation',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to be used for relighting',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiNafnetDenoiseImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * NafnetOutputDenoise
 */
export const zNafnetDenoiseOutput = z.object({
  image: zFalAiNafnetDenoiseImage,
})

/**
 * NafnetInput
 */
export const zNafnetDeblurInput = z.object({
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'seed to be used for generation',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to be used for relighting',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiNafnetDeblurImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * NafnetOutput
 */
export const zNafnetDeblurOutput = z.object({
  image: zFalAiNafnetDeblurImage,
})

/**
 * ImageProcessingInput
 */
export const zPostProcessingInput = z.object({
  blue_shift: z
    .optional(
      z.int().gte(-20).lte(20).register(z.globalRegistry, {
        description: 'Blue channel shift amount',
      }),
    )
    .default(0),
  vertex_y: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Vertex Y position',
      }),
    )
    .default(0.5),
  green_direction: z.optional(
    z.enum(['horizontal', 'vertical']).register(z.globalRegistry, {
      description: 'Green channel shift direction',
    }),
  ),
  enable_glow: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable glow effect',
      }),
    )
    .default(false),
  dodge_burn_mode: z.optional(
    z
      .enum([
        'dodge',
        'burn',
        'dodge_and_burn',
        'burn_and_dodge',
        'color_dodge',
        'color_burn',
        'linear_dodge',
        'linear_burn',
      ])
      .register(z.globalRegistry, {
        description: 'Dodge and burn mode',
      }),
  ),
  glow_intensity: z
    .optional(
      z.number().gte(0).lte(5).register(z.globalRegistry, {
        description: 'Glow intensity',
      }),
    )
    .default(1),
  blur_sigma: z
    .optional(
      z.number().gte(0.1).lte(10).register(z.globalRegistry, {
        description: 'Sigma for Gaussian blur',
      }),
    )
    .default(1),
  desaturate_method: z.optional(
    z
      .enum([
        'luminance (Rec.709)',
        'luminance (Rec.601)',
        'average',
        'lightness',
      ])
      .register(z.globalRegistry, {
        description: 'Desaturation method',
      }),
  ),
  enable_blur: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable blur effect',
      }),
    )
    .default(false),
  blur_radius: z
    .optional(
      z.int().gte(0).lte(31).register(z.globalRegistry, {
        description: 'Blur radius',
      }),
    )
    .default(3),
  grain_style: z.optional(
    z
      .enum(['modern', 'analog', 'kodak', 'fuji', 'cinematic', 'newspaper'])
      .register(z.globalRegistry, {
        description: 'Style of film grain to apply',
      }),
  ),
  cas_amount: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'CAS sharpening amount',
      }),
    )
    .default(0.8),
  gamma: z
    .optional(
      z.number().gte(0.2).lte(2.2).register(z.globalRegistry, {
        description: 'Gamma adjustment',
      }),
    )
    .default(1),
  tint_mode: z.optional(
    z
      .enum([
        'sepia',
        'red',
        'green',
        'blue',
        'cyan',
        'magenta',
        'yellow',
        'purple',
        'orange',
        'warm',
        'cool',
        'lime',
        'navy',
        'vintage',
        'rose',
        'teal',
        'maroon',
        'peach',
        'lavender',
        'olive',
      ])
      .register(z.globalRegistry, {
        description: 'Tint color mode',
      }),
  ),
  blur_type: z.optional(
    z.enum(['gaussian', 'kuwahara']).register(z.globalRegistry, {
      description: 'Type of blur to apply',
    }),
  ),
  enable_vignette: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable vignette effect',
      }),
    )
    .default(false),
  dissolve_image_url: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'URL of second image for dissolve',
      }),
    )
    .default(''),
  red_shift: z
    .optional(
      z.int().gte(-20).lte(20).register(z.globalRegistry, {
        description: 'Red channel shift amount',
      }),
    )
    .default(0),
  enable_desaturate: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable desaturation effect',
      }),
    )
    .default(false),
  grain_intensity: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Film grain intensity (when enabled)',
      }),
    )
    .default(0.4),
  dodge_burn_intensity: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Dodge and burn intensity',
      }),
    )
    .default(0.5),
  smart_sharpen_strength: z
    .optional(
      z.number().gte(0).lte(25).register(z.globalRegistry, {
        description: 'Smart sharpen strength',
      }),
    )
    .default(5),
  red_direction: z.optional(
    z.enum(['horizontal', 'vertical']).register(z.globalRegistry, {
      description: 'Red channel shift direction',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to process',
  }),
  vertex_x: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Vertex X position',
      }),
    )
    .default(0.5),
  tint_strength: z
    .optional(
      z.number().gte(0.1).lte(1).register(z.globalRegistry, {
        description: 'Tint strength',
      }),
    )
    .default(1),
  enable_dissolve: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable dissolve effect',
      }),
    )
    .default(false),
  enable_parabolize: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable parabolize effect',
      }),
    )
    .default(false),
  enable_grain: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable film grain effect',
      }),
    )
    .default(false),
  solarize_threshold: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Solarize threshold',
      }),
    )
    .default(0.5),
  enable_sharpen: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable sharpen effect',
      }),
    )
    .default(false),
  enable_dodge_burn: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable dodge and burn effect',
      }),
    )
    .default(false),
  glow_radius: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'Glow blur radius',
      }),
    )
    .default(5),
  sharpen_alpha: z
    .optional(
      z.number().gte(0.1).lte(5).register(z.globalRegistry, {
        description: 'Sharpen strength (for basic mode)',
      }),
    )
    .default(1),
  enable_color_correction: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable color correction',
      }),
    )
    .default(false),
  contrast: z
    .optional(
      z.number().gte(-100).lte(100).register(z.globalRegistry, {
        description: 'Contrast adjustment',
      }),
    )
    .default(0),
  enable_solarize: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable solarize effect',
      }),
    )
    .default(false),
  noise_radius: z
    .optional(
      z.int().gte(1).lte(25).register(z.globalRegistry, {
        description: 'Noise radius for smart sharpen',
      }),
    )
    .default(7),
  grain_scale: z
    .optional(
      z.number().gte(1).lte(100).register(z.globalRegistry, {
        description: 'Film grain scale (when enabled)',
      }),
    )
    .default(10),
  temperature: z
    .optional(
      z.number().gte(-100).lte(100).register(z.globalRegistry, {
        description: 'Color temperature adjustment',
      }),
    )
    .default(0),
  brightness: z
    .optional(
      z.number().gte(-100).lte(100).register(z.globalRegistry, {
        description: 'Brightness adjustment',
      }),
    )
    .default(0),
  blue_direction: z.optional(
    z.enum(['horizontal', 'vertical']).register(z.globalRegistry, {
      description: 'Blue channel shift direction',
    }),
  ),
  dissolve_factor: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Dissolve blend factor',
      }),
    )
    .default(0.5),
  sharpen_mode: z.optional(
    z.enum(['basic', 'smart', 'cas']).register(z.globalRegistry, {
      description: 'Type of sharpening to apply',
    }),
  ),
  vignette_strength: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description: 'Vignette strength (when enabled)',
      }),
    )
    .default(0.5),
  sharpen_radius: z
    .optional(
      z.int().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Sharpen radius (for basic mode)',
      }),
    )
    .default(1),
  parabolize_coeff: z
    .optional(
      z.number().gte(-10).lte(10).register(z.globalRegistry, {
        description: 'Parabolize coefficient',
      }),
    )
    .default(1),
  saturation: z
    .optional(
      z.number().gte(-100).lte(100).register(z.globalRegistry, {
        description: 'Saturation adjustment',
      }),
    )
    .default(0),
  enable_tint: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable color tint effect',
      }),
    )
    .default(false),
  green_shift: z
    .optional(
      z.int().gte(-20).lte(20).register(z.globalRegistry, {
        description: 'Green channel shift amount',
      }),
    )
    .default(0),
  preserve_edges: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Edge preservation factor',
      }),
    )
    .default(0.75),
  desaturate_factor: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Desaturation factor',
      }),
    )
    .default(1),
  smart_sharpen_ratio: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Smart sharpen blend ratio',
      }),
    )
    .default(0.5),
  enable_chromatic: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable chromatic aberration',
      }),
    )
    .default(false),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPostProcessingImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ProcessedOutput
 */
export const zPostProcessingOutput = z.object({
  images: z.array(zFalAiPostProcessingImage).register(z.globalRegistry, {
    description: 'The processed images',
  }),
})

/**
 * FlowEditInput
 */
export const zFloweditInput = z.object({
  src_guidance_scale: z
    .optional(
      z.int().gte(0).lte(30).register(z.globalRegistry, {
        description: 'Guidance scale for the source.',
      }),
    )
    .default(1.5),
  n_min: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Minimum step for improved style edits',
      }),
    )
    .default(0),
  n_max: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Control the strength of the edit',
      }),
    )
    .default(23),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to be used for relighting',
  }),
  source_prompt: z.string().register(z.globalRegistry, {
    description: 'Prompt of the image to be used.',
  }),
  tar_guidance_scale: z
    .optional(
      z.int().gte(0).lte(30).register(z.globalRegistry, {
        description: 'Guidance scale for target.',
      }),
    )
    .default(5.5),
  target_prompt: z.string().register(z.globalRegistry, {
    description: 'Prompt of the image to be made.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducible generation. If set none, a random seed will be used.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'Steps for which the model should run.',
      }),
    )
    .default(28),
  n_avg: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Average step count',
      }),
    )
    .default(1),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFloweditImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FlowEditOutput
 */
export const zFloweditOutput = z.object({
  image: zFalAiFloweditImage,
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFluxControlLoraCannyImageToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zFalAiFluxControlLoraCannyImageToImageLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * ImageToImageInput
 */
export const zFluxControlLoraCannyImageToImageInput = z.object({
  control_lora_strength: z
    .optional(
      z.number().gte(0).lte(2).register(z.globalRegistry, {
        description: 'The strength of the control lora.',
      }),
    )
    .default(1),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiFluxControlLoraCannyImageToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  loras: z
    .optional(
      z
        .array(zFalAiFluxControlLoraCannyImageToImageLoraWeight)
        .register(z.globalRegistry, {
          description:
            '\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ',
        }),
    )
    .default([]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(35).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to use for inpainting. or img2img',
  }),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.',
      }),
    )
    .default(0.85),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  control_lora_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        '\n            The image to use for control lora. This is used to control the style of the generated image.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiFluxControlLoraCannyImageToImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxControlLoraCannyImageToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFluxControlLoraCannyImageToImageImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFluxControlLoraDepthImageToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zFalAiFluxControlLoraDepthImageToImageLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * ImageToImageInput
 */
export const zFluxControlLoraDepthImageToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  control_lora_strength: z
    .optional(
      z.number().gte(0).lte(2).register(z.globalRegistry, {
        description: 'The strength of the control lora.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFluxControlLoraDepthImageToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  loras: z
    .optional(
      z
        .array(zFalAiFluxControlLoraDepthImageToImageLoraWeight)
        .register(z.globalRegistry, {
          description:
            '\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ',
        }),
    )
    .default([]),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(35).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to use for inpainting. or img2img',
  }),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.',
      }),
    )
    .default(0.85),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  control_lora_image_url: z.string().register(z.globalRegistry, {
    description:
      '\n            The image to use for control lora. This is used to control the style of the generated image.\n        ',
  }),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiFluxControlLoraDepthImageToImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxControlLoraDepthImageToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFluxControlLoraDepthImageToImageImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * Ben2InputImage
 */
export const zBenV2ImageInput = z.object({
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for reproducible generation.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to be used for background removal',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBenV2ImageImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * Ben2OutputImage
 */
export const zBenV2ImageOutput = z.object({
  image: zFalAiBenV2ImageImage,
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * UpscaleImageInput
 */
export const zIdeogramUpscaleInput = z.object({
  prompt: z.optional(z.union([z.string(), z.unknown()])),
  detail: z
    .optional(
      z.int().gte(1).lte(100).register(z.globalRegistry, {
        description: 'The detail of the upscaled image',
      }),
    )
    .default(50),
  resemblance: z
    .optional(
      z.int().gte(1).lte(100).register(z.globalRegistry, {
        description:
          'The resemblance of the upscaled image to the original image',
      }),
    )
    .default(50),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to expand the prompt with MagicPrompt functionality.',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The image URL to upscale',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * File
 */
export const zFalAiIdeogramUpscaleFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * UpscaleOutput
 */
export const zIdeogramUpscaleOutput = z.object({
  images: z.array(zFalAiIdeogramUpscaleFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for the random number generator',
  }),
})

/**
 * CodeformerInput
 */
export const zCodeformerInput = z.object({
  aligned: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Should faces etc should be aligned.',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to be used for relighting',
  }),
  upscale_factor: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: 'Upscaling factor',
      }),
    )
    .default(2),
  fidelity: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: 'Weight of the fidelity factor.',
      }),
    )
    .default(0.5),
  face_upscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Should faces be upscaled',
      }),
    )
    .default(true),
  only_center_face: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Should only center face be restored',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for reproducible generation.',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiCodeformerImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ConformerOutput
 */
export const zCodeformerOutput = z.object({
  image: zFalAiCodeformerImage,
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * TryOnRequest
 */
export const zKlingV15KolorsVirtualTryOnInput = z.object({
  garment_image_url: z.string().register(z.globalRegistry, {
    description: 'Url to the garment image.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the function will return the image in the response.',
      }),
    )
    .default(false),
  human_image_url: z.string().register(z.globalRegistry, {
    description: 'Url for the human image.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiKlingV15KolorsVirtualTryOnImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * TryOnOutput
 */
export const zKlingV15KolorsVirtualTryOnOutput = z.object({
  image: zFalAiKlingV15KolorsVirtualTryOnImage,
})

/**
 * ImageSize
 */
export const zFalAiFluxLoraCannyImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zFalAiFluxLoraCannyLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * CannyInput
 */
export const zFluxLoraCannyInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFluxLoraCannyImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to use for canny input',
  }),
  loras: z
    .optional(
      z.array(zFalAiFluxLoraCannyLoraWeight).register(z.globalRegistry, {
        description:
          '\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ',
      }),
    )
    .default([]),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(20).lte(40).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(30),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zFalAiFluxLoraCannyImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxLoraCannyOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFluxLoraCannyImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * FluxProFillFinetunedInput
 */
export const zFluxProV1FillFinetunedInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to fill the masked part of the image.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  finetune_strength: z.number().gte(0).lte(2).register(z.globalRegistry, {
    description:
      "\n        Controls finetune influence.\n        Increase this value if your target concept isn't showing up strongly enough.\n        The optimal setting depends on your finetune and prompt\n        ",
  }),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  finetune_id: z.string().register(z.globalRegistry, {
    description: 'References your specific model',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The image URL to generate an image from. Needs to match the dimensions of the mask.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  mask_url: z.string().register(z.globalRegistry, {
    description:
      'The mask URL to inpaint the image. Needs to match the dimensions of the input image.',
  }),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enhance the prompt for better results.',
      }),
    )
    .default(false),
})

/**
 * Image
 */
export const zFalAiFluxProV1FillFinetunedRegistryImageFastSdxlModelsImage =
  z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int(),
  })

/**
 * Output
 */
export const zFluxProV1FillFinetunedOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFluxProV1FillFinetunedRegistryImageFastSdxlModelsImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * DetectionInput
 */
export const zMoondreamNextDetectionInput = z.object({
  detection_prompt: z.string().register(z.globalRegistry, {
    description: 'Text description of what to detect',
  }),
  use_ensemble: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to use ensemble for gaze detection',
      }),
    )
    .default(false),
  task_type: z
    .enum(['bbox_detection', 'point_detection', 'gaze_detection'])
    .register(z.globalRegistry, {
      description: 'Type of detection to perform',
    }),
  show_visualization: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to show visualization for detection',
      }),
    )
    .default(true),
  combine_points: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to combine points into a single point for point detection. This has no effect for bbox detection or gaze detection.',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Image URL to be processed',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiMoondreamNextDetectionImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * DetectionOutput
 */
export const zMoondreamNextDetectionOutput = z.object({
  image: z.optional(zFalAiMoondreamNextDetectionImage),
  text_output: z.string().register(z.globalRegistry, {
    description: 'Detection results as text',
  }),
})

/**
 * ImageExpansionInput
 */
export const zBriaExpandInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Text on which you wish to base the image expansion. This parameter is optional. Bria currently supports prompts in English only, excluding special characters.',
      }),
    )
    .default(''),
  aspect_ratio: z.optional(
    z
      .enum(['1:1', '2:3', '3:2', '3:4', '4:3', '4:5', '5:4', '9:16', '16:9'])
      .register(z.globalRegistry, {
        description:
          'The desired aspect ratio of the final image. Will be used over original_image_size and original_image_location if provided.',
      }),
  ),
  original_image_location: z.optional(
    z.array(z.int()).register(z.globalRegistry, {
      description:
        'The desired location of the original image, inside the full canvas. Provide the location of the upper left corner of the original image. The location can also be outside the canvas (the original image will be cropped). Will be ignored if aspect_ratio is provided.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the input image.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  original_image_size: z.optional(
    z.array(z.int()).register(z.globalRegistry, {
      description:
        'The desired size of the original image, inside the full canvas. Ensure that the ratio of input image foreground or main subject to the canvas area is greater than 15% to achieve optimal results. Will be ignored if aspect_ratio is provided.',
    }),
  ),
  canvas_size: z.array(z.int()).register(z.globalRegistry, {
    description:
      'The desired size of the final image, after the expansion. should have an area of less than 5000x5000 pixels.',
  }),
  seed: z.optional(
    z.int().gte(0).lte(2147483647).register(z.globalRegistry, {
      description:
        'You can choose whether you want your generated expension to be random or predictable. You can recreate the same result in the future by using the seed value of a result from the response. You can exclude this parameter if you are not interested in recreating your results. This parameter is optional.',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'The negative prompt you would like to use to generate images.',
      }),
    )
    .default(''),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBriaExpandImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ImageExpansionOutput
 */
export const zBriaExpandOutput = z.object({
  image: zFalAiBriaExpandImage,
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed value used for generation.',
  }),
})

/**
 * GenFillInput
 */
export const zBriaGenfillInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt you would like to use to generate images.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'Number of Images to generate.',
      }),
    )
    .default(1),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Input Image to erase from',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().gte(0).lte(2147483647).register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  mask_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the binary mask image that represents the area that will be cleaned.',
  }),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'The negative prompt you would like to use to generate images.',
      }),
    )
    .default(''),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBriaGenfillImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * GenFillOutput
 */
export const zBriaGenfillOutput = z.object({
  images: z.array(zFalAiBriaGenfillImage).register(z.globalRegistry, {
    description: 'Generated Images',
  }),
})

/**
 * EraserInput
 */
export const zBriaEraserInput = z.object({
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  preserve_alpha: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, attempts to preserve the alpha channel of the input image.\n        ',
      }),
    )
    .default(false),
  mask_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the binary mask image that represents the area that will be cleaned.',
  }),
  mask_type: z.optional(
    z.enum(['manual', 'automatic']).register(z.globalRegistry, {
      description:
        "You can use this parameter to specify the type of the input mask from the list. 'manual' opttion should be used in cases in which the mask had been generated by a user (e.g. with a brush tool), and 'automatic' mask type should be used when mask had been generated by an algorithm like 'SAM'.",
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Input Image to erase from',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBriaEraserImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * EraserOutput
 */
export const zBriaEraserOutput = z.object({
  image: zFalAiBriaEraserImage,
})

/**
 * BGReplaceInput
 */
export const zBriaBackgroundReplaceInput = z.object({
  ref_image_url: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'The URL of the reference image to be used for generating the new background. Use "" to leave empty. Either ref_image_url or bg_prompt has to be provided but not both. If both ref_image_url and ref_image_file are provided, ref_image_url will be used. Accepted formats are jpeg, jpg, png, webp.',
      }),
    )
    .default(''),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'Number of Images to generate.',
      }),
    )
    .default(1),
  prompt: z.optional(
    z.string().min(1).register(z.globalRegistry, {
      description: 'The prompt you would like to use to generate images.',
    }),
  ),
  refine_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to refine prompt',
      }),
    )
    .default(true),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Input Image to erase from',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  fast: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to use the fast model',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().gte(0).lte(2147483647).register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'The negative prompt you would like to use to generate images.',
      }),
    )
    .default(''),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBriaBackgroundReplaceImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * BGReplaceOutput
 */
export const zBriaBackgroundReplaceOutput = z.object({
  images: z.array(zFalAiBriaBackgroundReplaceImage).register(z.globalRegistry, {
    description: 'The generated images',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed value used for generation.',
  }),
})

/**
 * ImageFillInput
 */
export const zImageFillInput = z.object({
  in_context_fill: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Uses the provided fill image in context with the base image to fill in more faithfully. Will increase price.',
      }),
    )
    .default(false),
  use_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use the prompt as well in the generation, along with the redux image.',
      }),
    )
    .default(false),
  fill_image_url: z.optional(z.union([z.array(z.string()), z.string()])),
})

/**
 * Image
 */
export const zFalAiFluxLoraFillImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxLoraFillOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFluxLoraFillImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * ProductShotInput
 */
export const zBriaProductShotInput = z.object({
  ref_image_url: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'The URL of the reference image to be used for generating the new scene or background for the product shot. Use "" to leave empty.Either ref_image_url or scene_description has to be provided but not both. If both ref_image_url and ref_image_file are provided, ref_image_url will be used. Accepted formats are jpeg, jpg, png, webp.',
      }),
    )
    .default(''),
  num_results: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description:
          'The number of lifestyle product shots you would like to generate. You will get num_results x 10 results when placement_type=automatic and according to the number of required placements x num_results if placement_type=manual_placement.',
      }),
    )
    .default(1),
  manual_placement_selection: z.optional(
    z
      .enum([
        'upper_left',
        'upper_right',
        'bottom_left',
        'bottom_right',
        'right_center',
        'left_center',
        'upper_center',
        'bottom_center',
        'center_vertical',
        'center_horizontal',
      ])
      .register(z.globalRegistry, {
        description:
          "If you've selected placement_type=manual_placement, you should use this parameter to specify which placements/positions you would like to use from the list. You can select more than one placement in one request.",
      }),
  ),
  padding_values: z.optional(
    z.array(z.int()).register(z.globalRegistry, {
      description:
        'The desired padding in pixels around the product, when using placement_type=manual_padding. The order of the values is [left, right, top, bottom]. For optimal results, the total number of pixels, including padding, should be around 1,000,000. It is recommended to first use the product cutout API, get the cutout and understand the size of the result, and then define the required padding and use the cutout as an input for this API.',
    }),
  ),
  shot_size: z
    .optional(
      z.array(z.int()).register(z.globalRegistry, {
        description:
          'The desired size of the final product shot. For optimal results, the total number of pixels should be around 1,000,000. This parameter is only relevant when placement_type=automatic or placement_type=manual_placement.',
      }),
    )
    .default([1000, 1000]),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  placement_type: z.optional(
    z
      .enum(['original', 'automatic', 'manual_placement', 'manual_padding'])
      .register(z.globalRegistry, {
        description:
          "This parameter allows you to control the positioning of the product in the image. Choosing 'original' will preserve the original position of the product in the image. Choosing 'automatic' will generate results with the 10 recommended positions for the product. Choosing 'manual_placement' will allow you to select predefined positions (using the parameter 'manual_placement_selection'). Selecting 'manual_padding' will allow you to control the position and size of the image by defining the desired padding in pixels around the product.",
      }),
  ),
  original_quality: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "This flag is only relevant when placement_type=original. If true, the output image retains the original input image's size; otherwise, the image is scaled to 1 megapixel (1MP) while preserving its aspect ratio.",
      }),
    )
    .default(false),
  fast: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to use the fast model',
      }),
    )
    .default(true),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the product shot to be placed in a lifestyle shot. If both image_url and image_file are provided, image_url will be used. Accepted formats are jpeg, jpg, png, webp. Maximum file size 12MB.',
  }),
  scene_description: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'Text description of the new scene or background for the provided product shot. Bria currently supports prompts in English only, excluding special characters.',
    }),
  ),
  optimize_description: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to optimize the scene description',
      }),
    )
    .default(true),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBriaProductShotImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ProductShotOutput
 */
export const zBriaProductShotOutput = z.object({
  images: z.array(zFalAiBriaProductShotImage).register(z.globalRegistry, {
    description: 'The generated images',
  }),
})

/**
 * BGRemoveInput
 */
export const zBriaBackgroundRemoveInput = z.object({
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Input Image to erase from',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBriaBackgroundRemoveImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * BGRemoveOutput
 */
export const zBriaBackgroundRemoveOutput = z.object({
  image: zFalAiBriaBackgroundRemoveImage,
})

/**
 * ImageSize
 */
export const zFalAiCatVtonImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * CATVTONInput
 */
export const zCatVtonInput = z.object({
  garment_image_url: z.string().register(z.globalRegistry, {
    description: 'Url to the garment image.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiCatVtonImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  human_image_url: z.string().register(z.globalRegistry, {
    description: 'Url for the human image.',
  }),
  cloth_type: z
    .enum(['upper', 'lower', 'overall', 'inner', 'outer'])
    .register(z.globalRegistry, {
      description:
        '\n        Type of the Cloth to be tried on.\n\n        Options:\n        upper: Upper body cloth\n        lower: Lower body cloth\n        overall: Full body cloth\n        inner: Inner cloth, like T-shirt inside a jacket\n        outer: Outer cloth, like a jacket over a T-shirt\n        ',
    }),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(2.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same input given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiCatVtonImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * CATVTONOutput
 */
export const zCatVtonOutput = z.object({
  image: zFalAiCatVtonImage,
})

/**
 * PoseTransferInput
 */
export const zLeffaPoseTransferInput = z.object({
  pose_image_url: z.string().register(z.globalRegistry, {
    description: 'Url for the human image.',
  }),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your input when generating the image.\n        ',
      }),
    )
    .default(2.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(50),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same input given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  person_image_url: z.string().register(z.globalRegistry, {
    description: 'Url to the garment image.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiLeffaPoseTransferImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * PoseTransferOutput
 */
export const zLeffaPoseTransferOutput = z.object({
  image: zFalAiLeffaPoseTransferImage,
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed for the inference.',
  }),
  has_nsfw_concepts: z.boolean().register(z.globalRegistry, {
    description: 'Whether the image contains NSFW concepts.',
  }),
})

/**
 * VTONInput
 */
export const zLeffaVirtualTryonInput = z.object({
  garment_image_url: z.string().register(z.globalRegistry, {
    description: 'Url to the garment image.',
  }),
  human_image_url: z.string().register(z.globalRegistry, {
    description: 'Url for the human image.',
  }),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  garment_type: z
    .enum(['upper_body', 'lower_body', 'dresses'])
    .register(z.globalRegistry, {
      description: 'The type of the garment used for virtual try-on.',
    }),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your input when generating the image.\n        ',
      }),
    )
    .default(2.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(50),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same input given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiLeffaVirtualTryonImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * VTONOutput
 */
export const zLeffaVirtualTryonOutput = z.object({
  image: zFalAiLeffaVirtualTryonImage,
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed for the inference.',
  }),
  has_nsfw_concepts: z.boolean().register(z.globalRegistry, {
    description: 'Whether the image contains NSFW concepts.',
  }),
})

/**
 * EditImageInput
 */
export const zIdeogramV2EditInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to fill the masked part of the image.',
  }),
  style: z.optional(
    z
      .enum(['auto', 'general', 'realistic', 'design', 'render_3D', 'anime'])
      .register(z.globalRegistry, {
        description: 'The style of the generated image',
      }),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to expand the prompt with MagicPrompt functionality.',
      }),
    )
    .default(true),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The image URL to generate an image from. Needs to match the dimensions of the mask.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  mask_url: z.string().register(z.globalRegistry, {
    description:
      'The mask URL to inpaint the image. Needs to match the dimensions of the input image.',
  }),
})

/**
 * File
 */
export const zFalAiIdeogramV2EditFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * Output
 */
export const zIdeogramV2EditOutput = z.object({
  images: z.array(zFalAiIdeogramV2EditFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for the random number generator',
  }),
})

/**
 * RemixImageInput
 */
export const zIdeogramV2TurboRemixInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to remix the image with',
  }),
  aspect_ratio: z.optional(
    z
      .enum([
        '10:16',
        '16:10',
        '9:16',
        '16:9',
        '4:3',
        '3:4',
        '1:1',
        '1:3',
        '3:1',
        '3:2',
        '2:3',
      ])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image',
      }),
  ),
  style: z.optional(
    z
      .enum(['auto', 'general', 'realistic', 'design', 'render_3D', 'anime'])
      .register(z.globalRegistry, {
        description: 'The style of the generated image',
      }),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to expand the prompt with MagicPrompt functionality.',
      }),
    )
    .default(true),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The image URL to remix',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description: 'Strength of the input image in the remix',
      }),
    )
    .default(0.8),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * File
 */
export const zFalAiIdeogramV2TurboRemixFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * Output
 */
export const zIdeogramV2TurboRemixOutput = z.object({
  images: z.array(zFalAiIdeogramV2TurboRemixFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for the random number generator',
  }),
})

/**
 * EditImageInput
 */
export const zIdeogramV2TurboEditInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to fill the masked part of the image.',
  }),
  style: z.optional(
    z
      .enum(['auto', 'general', 'realistic', 'design', 'render_3D', 'anime'])
      .register(z.globalRegistry, {
        description: 'The style of the generated image',
      }),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to expand the prompt with MagicPrompt functionality.',
      }),
    )
    .default(true),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The image URL to generate an image from. Needs to match the dimensions of the mask.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  mask_url: z.string().register(z.globalRegistry, {
    description:
      'The mask URL to inpaint the image. Needs to match the dimensions of the input image.',
  }),
})

/**
 * File
 */
export const zFalAiIdeogramV2TurboEditFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * Output
 */
export const zIdeogramV2TurboEditOutput = z.object({
  images: z.array(zFalAiIdeogramV2TurboEditFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for the random number generator',
  }),
})

/**
 * RemixImageInput
 */
export const zIdeogramV2RemixInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to remix the image with',
  }),
  aspect_ratio: z.optional(
    z
      .enum([
        '10:16',
        '16:10',
        '9:16',
        '16:9',
        '4:3',
        '3:4',
        '1:1',
        '1:3',
        '3:1',
        '3:2',
        '2:3',
      ])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image',
      }),
  ),
  style: z.optional(
    z
      .enum(['auto', 'general', 'realistic', 'design', 'render_3D', 'anime'])
      .register(z.globalRegistry, {
        description: 'The style of the generated image',
      }),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to expand the prompt with MagicPrompt functionality.',
      }),
    )
    .default(true),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The image URL to remix',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description: 'Strength of the input image in the remix',
      }),
    )
    .default(0.8),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * File
 */
export const zFalAiIdeogramV2RemixFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * Output
 */
export const zIdeogramV2RemixOutput = z.object({
  images: z.array(zFalAiIdeogramV2RemixFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for the random number generator',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFluxSchnellReduxImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * SchnellReduxInput
 */
export const zFluxSchnellReduxInput = z.object({
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFluxSchnellReduxImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        'The speed of the generation. The higher the speed, the faster the generation.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to generate an image from.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(12).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(4),
})

/**
 * Image
 */
export const zFalAiFluxSchnellReduxImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxSchnellReduxOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFluxSchnellReduxImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFluxProV11ReduxImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * FluxProRedux
 */
export const zFluxProV11ReduxInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The prompt to generate an image from.',
      }),
    )
    .default(''),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFluxProV11ReduxImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The image URL to generate an image from. Needs to match the dimensions of the mask.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enhance the prompt for better results.',
      }),
    )
    .default(false),
})

/**
 * Image
 */
export const zFalAiFluxProV11ReduxRegistryImageFastSdxlModelsImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxProV11ReduxOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFluxProV11ReduxRegistryImageFastSdxlModelsImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFluxDevReduxImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * BaseReduxInput
 */
export const zFluxDevReduxInput = z.object({
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFluxDevReduxImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        'The speed of the generation. The higher the speed, the faster the generation.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to generate an image from.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
})

/**
 * Image
 */
export const zFalAiFluxDevReduxImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxDevReduxOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFluxDevReduxImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFluxLoraDepthImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zFalAiFluxLoraDepthLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * DepthInput
 */
export const zFluxLoraDepthInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description:
          'The number of images to generate. This is always set to 1 for streaming output.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFluxLoraDepthImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to use for depth input',
  }),
  loras: z
    .optional(
      z.array(zFalAiFluxLoraDepthLoraWeight).register(z.globalRegistry, {
        description:
          '\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ',
      }),
    )
    .default([]),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(35).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zFalAiFluxLoraDepthImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxLoraDepthOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFluxLoraDepthImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * FluxProUltraTextToImageInputRedux
 */
export const zFluxProV11UltraReduxInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The prompt to generate an image from.',
      }),
    )
    .default(''),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  aspect_ratio: z.optional(
    z.union([
      z.enum([
        '21:9',
        '16:9',
        '4:3',
        '3:2',
        '1:1',
        '2:3',
        '3:4',
        '9:16',
        '9:21',
      ]),
      z.string(),
    ]),
  ),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enhance the prompt for better results.',
      }),
    )
    .default(false),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The image URL to generate an image from. Needs to match the dimensions of the mask.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.',
    }),
  ),
  image_prompt_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The strength of the image prompt, between 0 and 1.',
      }),
    )
    .default(0.1),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  raw: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Generate less processed, more natural-looking images.',
      }),
    )
    .default(false),
})

/**
 * Image
 */
export const zFalAiFluxProV11UltraReduxRegistryImageFastSdxlModelsImage =
  z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int(),
  })

/**
 * Output
 */
export const zFluxProV11UltraReduxOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFluxProV11UltraReduxRegistryImageFastSdxlModelsImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * FluxProFillInput
 */
export const zFluxProV1FillInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to fill the masked part of the image.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The image URL to generate an image from. Needs to match the dimensions of the mask.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  mask_url: z.string().register(z.globalRegistry, {
    description:
      'The mask URL to inpaint the image. Needs to match the dimensions of the input image.',
  }),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enhance the prompt for better results.',
      }),
    )
    .default(false),
})

/**
 * Image
 */
export const zFalAiFluxProV1FillRegistryImageFastSdxlModelsImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxProV1FillOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFluxProV1FillRegistryImageFastSdxlModelsImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiKolorsImageToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * KolorsImg2ImgInput
 */
export const zKolorsImageToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiKolorsImageToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to use for image to image',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and\n            uploaded before returning the response. This will increase the latency of\n            the function but it allows you to get the image directly in the response\n            without going through the CDN.\n        ',
      }),
    )
    .default(false),
  scheduler: z.optional(
    z
      .enum([
        'EulerDiscreteScheduler',
        'EulerAncestralDiscreteScheduler',
        'DPMSolverMultistepScheduler',
        'DPMSolverMultistepScheduler_SDE_karras',
        'UniPCMultistepScheduler',
        'DEISMultistepScheduler',
      ])
      .register(z.globalRegistry, {
        description: 'The scheduler to use for the model.',
      }),
  ),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'The strength to use for image-to-image. 1.0 is completely remakes the image while 0.0 preserves the original.',
      }),
    )
    .default(0.85),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show\n            you.\n        ',
      }),
    )
    .default(5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(150).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(50),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Seed',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small\n            details (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable safety checker.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zFalAiKolorsImageToImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zKolorsImageToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiKolorsImageToImageImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiIclightV2ImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * BaseInput
 */
export const zIclightV2Input = z.object({
  initial_latent: z.optional(
    z
      .enum(['None', 'Left', 'Right', 'Top', 'Bottom'])
      .register(z.globalRegistry, {
        description:
          '\n            Provide lighting conditions for the model\n        ',
      }),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiIclightV2ImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  background_threshold: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'Threshold for the background removal algorithm. A high threshold will produce sharper masks. Note: This parameter is currently deprecated and has no effect on the output.',
      }),
    )
    .default(0.67),
  mask_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'URL of mask to be used for ic-light conditioning image',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(5),
  lowres_denoise: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description: 'Strength for low-resolution pass.',
      }),
    )
    .default(0.98),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative Prompt for the image',
      }),
    )
    .default(''),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  hr_downscale: z.optional(z.number().gte(0.01).lte(1)).default(0.5),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to be used for relighting',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  highres_denoise: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'Strength for high-resolution pass. Only used if enable_hr_fix is True.',
      }),
    )
    .default(0.95),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  enable_hr_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Use HR fix',
      }),
    )
    .default(false),
  cfg: z
    .optional(
      z.number().gte(0.01).lte(5).register(z.globalRegistry, {
        description:
          'The real classifier-free-guidance scale for the generation.',
      }),
    )
    .default(1),
})

/**
 * Image
 */
export const zFalAiIclightV2Image = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zIclightV2Output = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiIclightV2Image).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * DiffInput
 */
export const zFluxDifferentialDiffusionInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to use as initial image.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'The strength to use for image-to-image. 1.0 is completely remakes the image while 0.0 preserves the original.',
      }),
    )
    .default(0.85),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  change_map_image_url: z.string().register(z.globalRegistry, {
    description: 'URL of change map.',
  }),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
})

/**
 * Image
 */
export const zFalAiFluxDifferentialDiffusionImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxDifferentialDiffusionOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFluxDifferentialDiffusionImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * ImageSize
 */
export const zFalAiFluxPulidImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * FluxPulidInput
 */
export const zFluxPulidInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  id_weight: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The weight of the ID loss.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFluxPulidImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  start_step: z
    .optional(
      z.int().gte(0).lte(50).register(z.globalRegistry, {
        description: 'The number of steps to start the CFG from.',
      }),
    )
    .default(0),
  reference_image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to use for inpainting.',
  }),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  max_sequence_length: z.optional(
    z.enum(['128', '256', '512']).register(z.globalRegistry, {
      description: 'The maximum sequence length for the model.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(4),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(20),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The prompt to generate an image from.',
      }),
    )
    .default(''),
  true_cfg: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The weight of the CFG loss.',
      }),
    )
    .default(1),
})

/**
 * Image
 */
export const zFalAiFluxPulidImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxPulidOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFluxPulidImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * InputV2
 */
export const zBirefnetV2Input = z.object({
  operating_resolution: z.optional(
    z.enum(['1024x1024', '2048x2048', '2304x2304']).register(z.globalRegistry, {
      description:
        "The resolution to operate on. The higher the resolution, the more accurate the output will be for high res input images. The '2304x2304' option is only available for the 'General Use (Dynamic)' model.",
    }),
  ),
  output_format: z.optional(
    z.enum(['webp', 'png', 'gif']).register(z.globalRegistry, {
      description: 'The format of the output image',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to remove background from',
  }),
  model: z.optional(
    z
      .enum([
        'General Use (Light)',
        'General Use (Light 2K)',
        'General Use (Heavy)',
        'Matting',
        'Portrait',
        'General Use (Dynamic)',
      ])
      .register(z.globalRegistry, {
        description:
          "\n            Model to use for background removal.\n            The 'General Use (Light)' model is the original model used in the BiRefNet repository.\n            The 'General Use (Light 2K)' model is the original model used in the BiRefNet repository but trained with 2K images.\n            The 'General Use (Heavy)' model is a slower but more accurate model.\n            The 'Matting' model is a model trained specifically for matting images.\n            The 'Portrait' model is a model trained specifically for portrait images.\n            The 'General Use (Dynamic)' model supports dynamic resolutions from 256x256 to 2304x2304.\n            The 'General Use (Light)' model is recommended for most use cases.\n\n            The corresponding models are as follows:\n            - 'General Use (Light)': BiRefNet\n            - 'General Use (Light 2K)': BiRefNet_lite-2K\n            - 'General Use (Heavy)': BiRefNet_lite\n            - 'Matting': BiRefNet-matting\n            - 'Portrait': BiRefNet-portrait\n            - 'General Use (Dynamic)': BiRefNet_dynamic\n        ",
      }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  output_mask: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to output the mask used to remove the background',
      }),
    )
    .default(false),
  refine_foreground: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to refine the foreground using the estimated mask',
      }),
    )
    .default(true),
})

/**
 * ImageFile
 */
export const zFalAiBirefnetV2ImageFile = z.object({
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Output
 */
export const zBirefnetV2Output = z.object({
  image: zFalAiBirefnetV2ImageFile,
  mask_image: z.optional(zFalAiBirefnetV2ImageFile),
})

/**
 * LivePortraitImageInput
 */
export const zLivePortraitImageInput = z.object({
  smile: z
    .optional(
      z.number().gte(-2).lte(2).register(z.globalRegistry, {
        description: 'Amount to smile',
      }),
    )
    .default(0),
  eyebrow: z
    .optional(
      z.number().gte(-30).lte(30).register(z.globalRegistry, {
        description: 'Amount to raise or lower eyebrows',
      }),
    )
    .default(0),
  rotate_roll: z
    .optional(
      z.number().gte(-45).lte(45).register(z.globalRegistry, {
        description: 'Amount to rotate the face in roll',
      }),
    )
    .default(0),
  wink: z
    .optional(
      z.number().gte(0).lte(25).register(z.globalRegistry, {
        description: 'Amount to wink',
      }),
    )
    .default(0),
  rotate_pitch: z
    .optional(
      z.number().gte(-45).lte(45).register(z.globalRegistry, {
        description: 'Amount to rotate the face in pitch',
      }),
    )
    .default(0),
  blink: z
    .optional(
      z.number().gte(-30).lte(30).register(z.globalRegistry, {
        description: 'Amount to blink the eyes',
      }),
    )
    .default(0),
  dsize: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Size of the output image.',
      }),
    )
    .default(512),
  vy_ratio: z
    .optional(
      z.number().register(z.globalRegistry, {
        description:
          'Vertical offset ratio for face crop. Positive values move up, negative values move down.',
      }),
    )
    .default(-0.125),
  scale: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: 'Scaling factor for the face crop.',
      }),
    )
    .default(2.3),
  pupil_x: z
    .optional(
      z.number().gte(-45).lte(45).register(z.globalRegistry, {
        description: 'Amount to move pupils horizontally',
      }),
    )
    .default(0),
  flag_pasteback: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to paste-back/stitch the animated face cropping from the face-cropping space to the original image space.',
      }),
    )
    .default(true),
  eee: z
    .optional(
      z.number().gte(-40).lte(40).register(z.globalRegistry, {
        description: "Amount to shape mouth in 'eee' position",
      }),
    )
    .default(0),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n        Whether to enable the safety checker. If enabled, the model will check if the input image contains a face before processing it.\n        The safety checker will process the input image\n        ',
      }),
    )
    .default(false),
  vx_ratio: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: 'Horizontal offset ratio for face crop.',
      }),
    )
    .default(0),
  pupil_y: z
    .optional(
      z.number().gte(-45).lte(45).register(z.globalRegistry, {
        description: 'Amount to move pupils vertically',
      }),
    )
    .default(0),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'Output format',
    }),
  ),
  rotate_yaw: z
    .optional(
      z.number().gte(-45).lte(45).register(z.globalRegistry, {
        description: 'Amount to rotate the face in yaw',
      }),
    )
    .default(0),
  flag_do_rot: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to conduct the rotation when flag_do_crop is True.',
      }),
    )
    .default(true),
  woo: z
    .optional(
      z.number().gte(-100).lte(100).register(z.globalRegistry, {
        description: "Amount to shape mouth in 'woo' position",
      }),
    )
    .default(0),
  aaa: z
    .optional(
      z.number().gte(-200).lte(200).register(z.globalRegistry, {
        description: "Amount to open mouth in 'aaa' shape",
      }),
    )
    .default(0),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to be animated',
  }),
  flag_do_crop: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to crop the source portrait to the face-cropping space.',
      }),
    )
    .default(true),
  flag_lip_zero: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to set the lip to closed state before animation. Only takes effect when flag_eye_retargeting and flag_lip_retargeting are False.',
      }),
    )
    .default(true),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiLivePortraitImageImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * LivePortraitImageOutput
 */
export const zLivePortraitImageOutput = z.object({
  image: zFalAiLivePortraitImageImage,
})

/**
 * ControlNetUnionInput
 */
export const zControlNetUnionInput = z.object({
  conditioning_scale: z
    .optional(
      z.number().gte(0).lte(2).register(z.globalRegistry, {
        description:
          '\n            The scale of the control net weight. This is used to scale the control net weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
  mask_threshold: z
    .optional(
      z.number().gte(0.01).lte(0.99).register(z.globalRegistry, {
        description: 'Threshold for mask.',
      }),
    )
    .default(0.5),
  end_percentage: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The percentage of the image to end applying the controlnet in terms of the total timesteps.\n        ',
      }),
    )
    .default(1),
  mask_image_url: z.optional(z.union([z.string(), z.null()])),
  control_image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to be used as the control image.',
  }),
  control_mode: z
    .enum(['canny', 'tile', 'depth', 'blur', 'pose', 'gray', 'low-quality'])
    .register(z.globalRegistry, {
      description:
        'Control Mode for Flux Controlnet Union. Supported values are:\n        - canny: Uses the edges for guided generation.\n        - tile: Uses the tiles for guided generation.\n        - depth: Utilizes a grayscale depth map for guided generation.\n        - blur: Adds a blur to the image.\n        - pose: Uses the pose of the image for guided generation.\n        - gray: Converts the image to grayscale.\n        - low-quality: Converts the image to a low-quality image.',
    }),
  start_percentage: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The percentage of the image to start applying the controlnet in terms of the total timesteps.\n        ',
      }),
    )
    .default(0),
})

/**
 * Image
 */
export const zFalAiFluxGeneralRfInversionImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxGeneralRfInversionOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFluxGeneralRfInversionImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * HEDInput
 */
export const zImagePreprocessorsHedInput = z.object({
  safe: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to use the safe version of the HED detector',
      }),
    )
    .default(false),
  scribble: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to use the scribble version of the HED detector',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to process',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImagePreprocessorsHedImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * HEDOutput
 */
export const zImagePreprocessorsHedOutput = z.object({
  image: zFalAiImagePreprocessorsHedImage,
})

/**
 * ScribbleInput
 */
export const zImagePreprocessorsScribbleInput = z.object({
  model: z.optional(
    z.enum(['HED', 'PiDi']).register(z.globalRegistry, {
      description: 'The model to use for the Scribble detector',
    }),
  ),
  safe: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to use the safe version of the Scribble detector',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to process',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImagePreprocessorsScribbleImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ScribbleOutput
 */
export const zImagePreprocessorsScribbleOutput = z.object({
  image: zFalAiImagePreprocessorsScribbleImage,
})

/**
 * DepthAnythingV2Input
 */
export const zImagePreprocessorsDepthAnythingV2Input = z.object({
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to process',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImagePreprocessorsDepthAnythingV2Image = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * DepthAnythingV2Output
 */
export const zImagePreprocessorsDepthAnythingV2Output = z.object({
  image: zFalAiImagePreprocessorsDepthAnythingV2Image,
})

/**
 * ZoeInput
 */
export const zImagePreprocessorsZoeInput = z.object({
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to process',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImagePreprocessorsZoeImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ZoeOutput
 */
export const zImagePreprocessorsZoeOutput = z.object({
  image: zFalAiImagePreprocessorsZoeImage,
})

/**
 * TeeDInput
 */
export const zImagePreprocessorsTeedInput = z.object({
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to process',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImagePreprocessorsTeedImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * TeeDOutput
 */
export const zImagePreprocessorsTeedOutput = z.object({
  image: zFalAiImagePreprocessorsTeedImage,
})

/**
 * MLSDInput
 */
export const zImagePreprocessorsMlsdInput = z.object({
  distance_threshold: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: 'Distance threshold for the MLSD detector',
      }),
    )
    .default(0.1),
  score_threshold: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: 'Score threshold for the MLSD detector',
      }),
    )
    .default(0.1),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to process',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImagePreprocessorsMlsdImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * MLSDOutput
 */
export const zImagePreprocessorsMlsdOutput = z.object({
  image: zFalAiImagePreprocessorsMlsdImage,
})

/**
 * LineartInput
 */
export const zImagePreprocessorsLineartInput = z.object({
  coarse: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to use the coarse model',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to process',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImagePreprocessorsLineartImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * LineartOutput
 */
export const zImagePreprocessorsLineartOutput = z.object({
  image: zFalAiImagePreprocessorsLineartImage,
})

/**
 * SamInput
 */
export const zImagePreprocessorsSamInput = z.object({
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to process',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImagePreprocessorsSamImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * SamOutput
 */
export const zImagePreprocessorsSamOutput = z.object({
  image: zFalAiImagePreprocessorsSamImage,
})

/**
 * MiDaSInput
 */
export const zImagePreprocessorsMidasInput = z.object({
  a: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: 'A parameter for the MiDaS detector',
      }),
    )
    .default(6.283185307179586),
  background_threshold: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: 'Background threshold for the MiDaS detector',
      }),
    )
    .default(0.1),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to process',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImagePreprocessorsMidasImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * MiDaSOutput
 */
export const zImagePreprocessorsMidasOutput = z.object({
  normal_map: zFalAiImagePreprocessorsMidasImage,
  depth_map: zFalAiImagePreprocessorsMidasImage,
})

/**
 * PiDiInput
 */
export const zImagePreprocessorsPidiInput = z.object({
  safe: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to use the safe version of the Pidi detector',
      }),
    )
    .default(false),
  apply_filter: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to apply the filter to the image.',
      }),
    )
    .default(false),
  scribble: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to use the scribble version of the Pidi detector',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to process',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImagePreprocessorsPidiImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * PiDiOutput
 */
export const zImagePreprocessorsPidiOutput = z.object({
  image: zFalAiImagePreprocessorsPidiImage,
})

/**
 * PointPrompt
 */
export const zFalAiSam2ImagePointPrompt = z.object({
  y: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Y Coordinate of the prompt',
      }),
    )
    .default(350),
  label: z.optional(
    z.union([z.literal(0), z.literal(1)]).register(z.globalRegistry, {
      description: 'Label of the prompt. 1 for foreground, 0 for background',
    }),
  ),
  frame_index: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'The frame index to interact with.',
      }),
    )
    .default(0),
  x: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'X Coordinate of the prompt',
      }),
    )
    .default(305),
})

/**
 * BoxPrompt
 */
export const zFalAiSam2ImageBoxPrompt = z.object({
  y_min: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Y Min Coordinate of the box',
      }),
    )
    .default(0),
  frame_index: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'The frame index to interact with.',
      }),
    )
    .default(0),
  x_max: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'X Max Coordinate of the prompt',
      }),
    )
    .default(0),
  x_min: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'X Min Coordinate of the box',
      }),
    )
    .default(0),
  y_max: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Y Max Coordinate of the prompt',
      }),
    )
    .default(0),
})

/**
 * SAM2ImageInput
 */
export const zSam2ImageInput = z.object({
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  prompts: z
    .optional(
      z.array(zFalAiSam2ImagePointPrompt).register(z.globalRegistry, {
        description: 'List of prompts to segment the image',
      }),
    )
    .default([]),
  box_prompts: z
    .optional(
      z.array(zFalAiSam2ImageBoxPrompt).register(z.globalRegistry, {
        description: 'Coordinates for boxes',
      }),
    )
    .default([]),
  apply_mask: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Apply the mask on the image.',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to be segmented',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiSam2ImageImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * SAM2ImageOutput
 */
export const zSam2ImageOutput = z.object({
  image: zFalAiSam2ImageImage,
})

/**
 * ControlNetUnionInput
 */
export const zFalAiFluxGeneralImageToImageControlNetUnionInput = z.object({
  conditioning_scale: z
    .optional(
      z.number().gte(0).lte(2).register(z.globalRegistry, {
        description:
          '\n            The scale of the control net weight. This is used to scale the control net weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
  mask_threshold: z
    .optional(
      z.number().gte(0.01).lte(0.99).register(z.globalRegistry, {
        description: 'Threshold for mask.',
      }),
    )
    .default(0.5),
  end_percentage: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The percentage of the image to end applying the controlnet in terms of the total timesteps.\n        ',
      }),
    )
    .default(1),
  mask_image_url: z.optional(z.union([z.string(), z.null()])),
  control_image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to be used as the control image.',
  }),
  control_mode: z
    .enum(['canny', 'tile', 'depth', 'blur', 'pose', 'gray', 'low-quality'])
    .register(z.globalRegistry, {
      description:
        'Control Mode for Flux Controlnet Union. Supported values are:\n        - canny: Uses the edges for guided generation.\n        - tile: Uses the tiles for guided generation.\n        - depth: Utilizes a grayscale depth map for guided generation.\n        - blur: Adds a blur to the image.\n        - pose: Uses the pose of the image for guided generation.\n        - gray: Converts the image to grayscale.\n        - low-quality: Converts the image to a low-quality image.',
    }),
  start_percentage: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The percentage of the image to start applying the controlnet in terms of the total timesteps.\n        ',
      }),
    )
    .default(0),
})

/**
 * Image
 */
export const zFalAiFluxGeneralImageToImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxGeneralImageToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFluxGeneralImageToImageImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ControlNetUnionInput
 */
export const zFalAiFluxGeneralInpaintingControlNetUnionInput = z.object({
  conditioning_scale: z
    .optional(
      z.number().gte(0).lte(2).register(z.globalRegistry, {
        description:
          '\n            The scale of the control net weight. This is used to scale the control net weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
  mask_threshold: z
    .optional(
      z.number().gte(0.01).lte(0.99).register(z.globalRegistry, {
        description: 'Threshold for mask.',
      }),
    )
    .default(0.5),
  end_percentage: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The percentage of the image to end applying the controlnet in terms of the total timesteps.\n        ',
      }),
    )
    .default(1),
  mask_image_url: z.optional(z.union([z.string(), z.null()])),
  control_image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to be used as the control image.',
  }),
  control_mode: z
    .enum(['canny', 'tile', 'depth', 'blur', 'pose', 'gray', 'low-quality'])
    .register(z.globalRegistry, {
      description:
        'Control Mode for Flux Controlnet Union. Supported values are:\n        - canny: Uses the edges for guided generation.\n        - tile: Uses the tiles for guided generation.\n        - depth: Utilizes a grayscale depth map for guided generation.\n        - blur: Adds a blur to the image.\n        - pose: Uses the pose of the image for guided generation.\n        - gray: Converts the image to grayscale.\n        - low-quality: Converts the image to a low-quality image.',
    }),
  start_percentage: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The percentage of the image to start applying the controlnet in terms of the total timesteps.\n        ',
      }),
    )
    .default(0),
})

/**
 * Image
 */
export const zFalAiFluxGeneralInpaintingImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxGeneralInpaintingOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFluxGeneralInpaintingImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ControlNetUnionInput
 */
export const zFalAiFluxGeneralDifferentialDiffusionControlNetUnionInput =
  z.object({
    conditioning_scale: z
      .optional(
        z.number().gte(0).lte(2).register(z.globalRegistry, {
          description:
            '\n            The scale of the control net weight. This is used to scale the control net weight\n            before merging it with the base model.\n        ',
        }),
      )
      .default(1),
    mask_threshold: z
      .optional(
        z.number().gte(0.01).lte(0.99).register(z.globalRegistry, {
          description: 'Threshold for mask.',
        }),
      )
      .default(0.5),
    end_percentage: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            '\n            The percentage of the image to end applying the controlnet in terms of the total timesteps.\n        ',
        }),
      )
      .default(1),
    mask_image_url: z.optional(z.union([z.string(), z.null()])),
    control_image_url: z.string().register(z.globalRegistry, {
      description: 'URL of the image to be used as the control image.',
    }),
    control_mode: z
      .enum(['canny', 'tile', 'depth', 'blur', 'pose', 'gray', 'low-quality'])
      .register(z.globalRegistry, {
        description:
          'Control Mode for Flux Controlnet Union. Supported values are:\n        - canny: Uses the edges for guided generation.\n        - tile: Uses the tiles for guided generation.\n        - depth: Utilizes a grayscale depth map for guided generation.\n        - blur: Adds a blur to the image.\n        - pose: Uses the pose of the image for guided generation.\n        - gray: Converts the image to grayscale.\n        - low-quality: Converts the image to a low-quality image.',
      }),
    start_percentage: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            '\n            The percentage of the image to start applying the controlnet in terms of the total timesteps.\n        ',
        }),
      )
      .default(0),
  })

/**
 * Image
 */
export const zFalAiFluxGeneralDifferentialDiffusionImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxGeneralDifferentialDiffusionOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFluxGeneralDifferentialDiffusionImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFluxLoraImageToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zFalAiFluxLoraImageToImageLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * ImageToImageInput
 */
export const zFluxLoraImageToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description:
          'The number of images to generate. This is always set to 1 for streaming output.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFluxLoraImageToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to use for inpainting. or img2img',
  }),
  loras: z
    .optional(
      z.array(zFalAiFluxLoraImageToImageLoraWeight).register(z.globalRegistry, {
        description:
          '\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ',
      }),
    )
    .default([]),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.',
      }),
    )
    .default(0.85),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(35).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zFalAiFluxLoraImageToImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxLoraImageToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFluxLoraImageToImageImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiSdxlControlnetUnionInpaintingImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Embedding
 */
export const zEmbedding = z.object({
  tokens: z
    .optional(
      z.array(z.string()).register(z.globalRegistry, {
        description: 'The list of tokens to use for the embedding.',
      }),
    )
    .default(['<s0>', '<s1>']),
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the embedding weights.',
  }),
})

/**
 * LoraWeight
 */
export const zFalAiSdxlControlnetUnionInpaintingLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights. Or HF model name.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
  force: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the embedding will be forced to be used.',
      }),
    )
    .default(false),
})

/**
 * InpaintingControlNetUnionInput
 */
export const zSdxlControlnetUnionInpaintingInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  depth_preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the depth image.',
      }),
    )
    .default(true),
  image_size: z.optional(
    z.union([
      zFalAiSdxlControlnetUnionInpaintingImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
      z.null(),
    ]),
  ),
  normal_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The URL of the control image.',
    }),
  ),
  embeddings: z
    .optional(
      z.array(zEmbedding).register(z.globalRegistry, {
        description: 'The list of embeddings to use.',
      }),
    )
    .default([]),
  teed_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The URL of the control image.',
    }),
  ),
  loras: z
    .optional(
      z
        .array(zFalAiSdxlControlnetUnionInpaintingLoraWeight)
        .register(z.globalRegistry, {
          description: 'The list of LoRA weights to use.',
        }),
    )
    .default([]),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(7.5),
  canny_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The URL of the control image.',
    }),
  ),
  segmentation_preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the segmentation image.',
      }),
    )
    .default(true),
  format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the image to use as a starting point for the generation.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  request_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          '\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ',
      }),
    )
    .default(''),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  mask_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the mask to use for inpainting.',
  }),
  segmentation_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The URL of the control image.',
    }),
  ),
  openpose_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The URL of the control image.',
    }),
  ),
  canny_preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the canny image.',
      }),
    )
    .default(true),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded with additional prompts.',
      }),
    )
    .default(false),
  depth_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The URL of the control image.',
    }),
  ),
  normal_preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the normal image.',
      }),
    )
    .default(true),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  teed_preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the teed image.',
      }),
    )
    .default(true),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  controlnet_conditioning_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The scale of the controlnet conditioning.',
      }),
    )
    .default(0.5),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'determines how much the generated image resembles the initial image',
      }),
    )
    .default(0.95),
  safety_checker_version: z.optional(
    z.enum(['v1', 'v2']).register(z.globalRegistry, {
      description:
        'The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.',
    }),
  ),
  openpose_preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the openpose image.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(70).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(35),
})

/**
 * Image
 */
export const zFalAiSdxlControlnetUnionInpaintingImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zSdxlControlnetUnionInpaintingOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiSdxlControlnetUnionInpaintingImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiSdxlControlnetUnionImageToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Embedding
 */
export const zFalAiSdxlControlnetUnionImageToImageEmbedding = z.object({
  tokens: z
    .optional(
      z.array(z.string()).register(z.globalRegistry, {
        description: 'The list of tokens to use for the embedding.',
      }),
    )
    .default(['<s0>', '<s1>']),
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the embedding weights.',
  }),
})

/**
 * LoraWeight
 */
export const zFalAiSdxlControlnetUnionImageToImageLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights. Or HF model name.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
  force: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the embedding will be forced to be used.',
      }),
    )
    .default(false),
})

/**
 * ImageToImageControlNetUnionInput
 */
export const zSdxlControlnetUnionImageToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  depth_preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the depth image.',
      }),
    )
    .default(true),
  image_size: z.optional(
    z.union([
      zFalAiSdxlControlnetUnionImageToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
      z.null(),
    ]),
  ),
  normal_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The URL of the control image.',
    }),
  ),
  embeddings: z
    .optional(
      z
        .array(zFalAiSdxlControlnetUnionImageToImageEmbedding)
        .register(z.globalRegistry, {
          description: 'The list of embeddings to use.',
        }),
    )
    .default([]),
  teed_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The URL of the control image.',
    }),
  ),
  loras: z
    .optional(
      z
        .array(zFalAiSdxlControlnetUnionImageToImageLoraWeight)
        .register(z.globalRegistry, {
          description: 'The list of LoRA weights to use.',
        }),
    )
    .default([]),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(7.5),
  canny_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The URL of the control image.',
    }),
  ),
  segmentation_preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the segmentation image.',
      }),
    )
    .default(true),
  format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the image to use as a starting point for the generation.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  request_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          '\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ',
      }),
    )
    .default(''),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  segmentation_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The URL of the control image.',
    }),
  ),
  openpose_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The URL of the control image.',
    }),
  ),
  canny_preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the canny image.',
      }),
    )
    .default(true),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded with additional prompts.',
      }),
    )
    .default(false),
  depth_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The URL of the control image.',
    }),
  ),
  normal_preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the normal image.',
      }),
    )
    .default(true),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  preserve_aspect_ratio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n        If set to true, the aspect ratio of the generated image will be preserved even\n        if the image size is too large. However, if the image is not a multiple of 32\n        in width or height, it will be resized to the nearest multiple of 32. By default,\n        this snapping to the nearest multiple of 32 will not preserve the aspect ratio.\n        Set crop_output to True, to crop the output to the proper aspect ratio\n        after generating.\n        ',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  crop_output: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n        If set to true, the output cropped to the proper aspect ratio after generating.\n        ',
      }),
    )
    .default(false),
  teed_preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the teed image.',
      }),
    )
    .default(true),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  controlnet_conditioning_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The scale of the controlnet conditioning.',
      }),
    )
    .default(0.5),
  strength: z
    .optional(
      z.number().gte(0.05).lte(1).register(z.globalRegistry, {
        description:
          'determines how much the generated image resembles the initial image',
      }),
    )
    .default(0.95),
  safety_checker_version: z.optional(
    z.enum(['v1', 'v2']).register(z.globalRegistry, {
      description:
        'The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.',
    }),
  ),
  openpose_preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the openpose image.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(70).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(35),
})

/**
 * Image
 */
export const zFalAiSdxlControlnetUnionImageToImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zSdxlControlnetUnionImageToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiSdxlControlnetUnionImageToImageImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * Era3DInput
 */
export const zEra3dInput = z.object({
  cfg: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(4),
  background_removal: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Background removal',
      }),
    )
    .default(true),
  steps: z
    .optional(
      z.int().gte(1).lte(200).register(z.globalRegistry, {
        description: 'Number of steps to run the model for',
      }),
    )
    .default(40),
  crop_size: z
    .optional(
      z.int().gte(256).lte(512).register(z.globalRegistry, {
        description: 'Size of the image to crop to',
      }),
    )
    .default(400),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Seed for random number generation',
      }),
    )
    .default(-1),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to remove background from',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiEra3dImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * Era3DOutput
 */
export const zEra3dOutput = z.object({
  images: z.array(zFalAiEra3dImage).register(z.globalRegistry, {
    description: 'Images with background removed',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for random number generation',
  }),
  normal_images: z.array(zFalAiEra3dImage).register(z.globalRegistry, {
    description: 'Normal images with background removed',
  }),
})

/**
 * ImageWithTextInput
 */
export const zFlorence2LargeReferringExpressionSegmentationInput = z.object({
  text_input: z.string().register(z.globalRegistry, {
    description: 'Text input for the task',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to be processed.',
  }),
})

/**
 * Polygon
 */
export const zPolygon = z.object({
  points: z.array(z.record(z.string(), z.number())).register(z.globalRegistry, {
    description: 'List of points',
  }),
  label: z.string().register(z.globalRegistry, {
    description: 'Label of the polygon',
  }),
})

/**
 * PolygonOutput
 */
export const zPolygonOutput = z.object({
  polygons: z.array(zPolygon).register(z.globalRegistry, {
    description: 'List of polygons',
  }),
})

/**
 * ImageInput
 */
export const zFlorence2LargeDenseRegionCaptionInput = z.object({
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to be processed.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlorence2LargeDenseRegionCaptionImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * BoundingBox
 */
export const zBoundingBox = z.object({
  y: z.number().register(z.globalRegistry, {
    description: 'Y-coordinate of the top-left corner',
  }),
  label: z.string().register(z.globalRegistry, {
    description: 'Label of the bounding box',
  }),
  h: z.number().register(z.globalRegistry, {
    description: 'Height of the bounding box',
  }),
  w: z.number().register(z.globalRegistry, {
    description: 'Width of the bounding box',
  }),
  x: z.number().register(z.globalRegistry, {
    description: 'X-coordinate of the top-left corner',
  }),
})

/**
 * BoundingBoxes
 */
export const zBoundingBoxes = z.object({
  bboxes: z.array(zBoundingBox).register(z.globalRegistry, {
    description: 'List of bounding boxes',
  }),
})

/**
 * BoundingBoxOutputWithLabels
 */
export const zFlorence2LargeDenseRegionCaptionOutput = z.object({
  image: z.optional(zFalAiFlorence2LargeDenseRegionCaptionImage),
  results: zBoundingBoxes,
})

/**
 * ImageInput
 */
export const zFlorence2LargeObjectDetectionInput = z.object({
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to be processed.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlorence2LargeObjectDetectionImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * BoundingBox
 */
export const zFalAiFlorence2LargeObjectDetectionBoundingBox = z.object({
  y: z.number().register(z.globalRegistry, {
    description: 'Y-coordinate of the top-left corner',
  }),
  label: z.string().register(z.globalRegistry, {
    description: 'Label of the bounding box',
  }),
  h: z.number().register(z.globalRegistry, {
    description: 'Height of the bounding box',
  }),
  w: z.number().register(z.globalRegistry, {
    description: 'Width of the bounding box',
  }),
  x: z.number().register(z.globalRegistry, {
    description: 'X-coordinate of the top-left corner',
  }),
})

/**
 * BoundingBoxes
 */
export const zFalAiFlorence2LargeObjectDetectionBoundingBoxes = z.object({
  bboxes: z
    .array(zFalAiFlorence2LargeObjectDetectionBoundingBox)
    .register(z.globalRegistry, {
      description: 'List of bounding boxes',
    }),
})

/**
 * BoundingBoxOutputWithLabels
 */
export const zFlorence2LargeObjectDetectionOutput = z.object({
  image: z.optional(zFalAiFlorence2LargeObjectDetectionImage),
  results: zFalAiFlorence2LargeObjectDetectionBoundingBoxes,
})

/**
 * ImageWithTextInput
 */
export const zFlorence2LargeOpenVocabularyDetectionInput = z.object({
  text_input: z.string().register(z.globalRegistry, {
    description: 'Text input for the task',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to be processed.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlorence2LargeOpenVocabularyDetectionImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * BoundingBox
 */
export const zFalAiFlorence2LargeOpenVocabularyDetectionBoundingBox = z.object({
  y: z.number().register(z.globalRegistry, {
    description: 'Y-coordinate of the top-left corner',
  }),
  label: z.string().register(z.globalRegistry, {
    description: 'Label of the bounding box',
  }),
  h: z.number().register(z.globalRegistry, {
    description: 'Height of the bounding box',
  }),
  w: z.number().register(z.globalRegistry, {
    description: 'Width of the bounding box',
  }),
  x: z.number().register(z.globalRegistry, {
    description: 'X-coordinate of the top-left corner',
  }),
})

/**
 * BoundingBoxes
 */
export const zFalAiFlorence2LargeOpenVocabularyDetectionBoundingBoxes =
  z.object({
    bboxes: z
      .array(zFalAiFlorence2LargeOpenVocabularyDetectionBoundingBox)
      .register(z.globalRegistry, {
        description: 'List of bounding boxes',
      }),
  })

/**
 * BoundingBoxOutputWithLabels
 */
export const zFlorence2LargeOpenVocabularyDetectionOutput = z.object({
  image: z.optional(zFalAiFlorence2LargeOpenVocabularyDetectionImage),
  results: zFalAiFlorence2LargeOpenVocabularyDetectionBoundingBoxes,
})

/**
 * ImageWithTextInput
 */
export const zFlorence2LargeCaptionToPhraseGroundingInput = z.object({
  text_input: z.string().register(z.globalRegistry, {
    description: 'Text input for the task',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to be processed.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlorence2LargeCaptionToPhraseGroundingImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * BoundingBox
 */
export const zFalAiFlorence2LargeCaptionToPhraseGroundingBoundingBox = z.object(
  {
    y: z.number().register(z.globalRegistry, {
      description: 'Y-coordinate of the top-left corner',
    }),
    label: z.string().register(z.globalRegistry, {
      description: 'Label of the bounding box',
    }),
    h: z.number().register(z.globalRegistry, {
      description: 'Height of the bounding box',
    }),
    w: z.number().register(z.globalRegistry, {
      description: 'Width of the bounding box',
    }),
    x: z.number().register(z.globalRegistry, {
      description: 'X-coordinate of the top-left corner',
    }),
  },
)

/**
 * BoundingBoxes
 */
export const zFalAiFlorence2LargeCaptionToPhraseGroundingBoundingBoxes =
  z.object({
    bboxes: z
      .array(zFalAiFlorence2LargeCaptionToPhraseGroundingBoundingBox)
      .register(z.globalRegistry, {
        description: 'List of bounding boxes',
      }),
  })

/**
 * BoundingBoxOutputWithLabels
 */
export const zFlorence2LargeCaptionToPhraseGroundingOutput = z.object({
  image: z.optional(zFalAiFlorence2LargeCaptionToPhraseGroundingImage),
  results: zFalAiFlorence2LargeCaptionToPhraseGroundingBoundingBoxes,
})

/**
 * ImageInput
 */
export const zFlorence2LargeOcrWithRegionInput = z.object({
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to be processed.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlorence2LargeOcrWithRegionImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * OCRBoundingBoxSingle
 */
export const zOcrBoundingBoxSingle = z.object({
  y: z.number().register(z.globalRegistry, {
    description: 'Y-coordinate of the top-left corner',
  }),
  label: z.string().register(z.globalRegistry, {
    description: 'Label of the bounding box',
  }),
  h: z.number().register(z.globalRegistry, {
    description: 'Height of the bounding box',
  }),
  w: z.number().register(z.globalRegistry, {
    description: 'Width of the bounding box',
  }),
  x: z.number().register(z.globalRegistry, {
    description: 'X-coordinate of the top-left corner',
  }),
})

/**
 * OCRBoundingBox
 */
export const zOcrBoundingBox = z.object({
  quad_boxes: z.array(zOcrBoundingBoxSingle).register(z.globalRegistry, {
    description: 'List of quadrilateral boxes',
  }),
})

/**
 * OCRBoundingBoxOutputWithLabels
 */
export const zFlorence2LargeOcrWithRegionOutput = z.object({
  image: z.optional(zFalAiFlorence2LargeOcrWithRegionImage),
  results: zOcrBoundingBox,
})

/**
 * ImageInput
 */
export const zFlorence2LargeRegionProposalInput = z.object({
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to be processed.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlorence2LargeRegionProposalImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * BoundingBox
 */
export const zFalAiFlorence2LargeRegionProposalBoundingBox = z.object({
  y: z.number().register(z.globalRegistry, {
    description: 'Y-coordinate of the top-left corner',
  }),
  label: z.string().register(z.globalRegistry, {
    description: 'Label of the bounding box',
  }),
  h: z.number().register(z.globalRegistry, {
    description: 'Height of the bounding box',
  }),
  w: z.number().register(z.globalRegistry, {
    description: 'Width of the bounding box',
  }),
  x: z.number().register(z.globalRegistry, {
    description: 'X-coordinate of the top-left corner',
  }),
})

/**
 * BoundingBoxes
 */
export const zFalAiFlorence2LargeRegionProposalBoundingBoxes = z.object({
  bboxes: z
    .array(zFalAiFlorence2LargeRegionProposalBoundingBox)
    .register(z.globalRegistry, {
      description: 'List of bounding boxes',
    }),
})

/**
 * BoundingBoxOutputWithLabels
 */
export const zFlorence2LargeRegionProposalOutput = z.object({
  image: z.optional(zFalAiFlorence2LargeRegionProposalImage),
  results: zFalAiFlorence2LargeRegionProposalBoundingBoxes,
})

/**
 * Region
 */
export const zRegion = z.object({
  y1: z.int().gte(0).lte(999).register(z.globalRegistry, {
    description: 'Y-coordinate of the top-left corner',
  }),
  x2: z.int().gte(0).lte(999).register(z.globalRegistry, {
    description: 'X-coordinate of the bottom-right corner',
  }),
  x1: z.int().gte(0).lte(999).register(z.globalRegistry, {
    description: 'X-coordinate of the top-left corner',
  }),
  y2: z.int().gte(0).lte(999).register(z.globalRegistry, {
    description: 'Y-coordinate of the bottom-right corner',
  }),
})

/**
 * ImageWithUserCoordinatesInput
 */
export const zFlorence2LargeRegionToSegmentationInput = z.object({
  region: zRegion,
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to be processed.',
  }),
})

/**
 * Polygon
 */
export const zFalAiFlorence2LargeRegionToSegmentationPolygon = z.object({
  points: z.array(z.record(z.string(), z.number())).register(z.globalRegistry, {
    description: 'List of points',
  }),
  label: z.string().register(z.globalRegistry, {
    description: 'Label of the polygon',
  }),
})

/**
 * PolygonOutput
 */
export const zFalAiFlorence2LargeRegionToSegmentationPolygonOutput = z.object({
  polygons: z
    .array(zFalAiFlorence2LargeRegionToSegmentationPolygon)
    .register(z.globalRegistry, {
      description: 'List of polygons',
    }),
})

/**
 * ImageSize
 */
export const zFalAiStableDiffusionV3MediumImageToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * ImageToImageInput
 */
export const zStableDiffusionV3MediumImageToImageInput = z.object({
  prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, prompt will be upsampled with more details.',
      }),
    )
    .default(false),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiStableDiffusionV3MediumImageToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
      z.null(),
    ]),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The image URL to generate an image from.',
  }),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description: 'The strength of the image-to-image transformation.',
      }),
    )
    .default(0.9),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate an image from.',
      }),
    )
    .default(''),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zFalAiStableDiffusionV3MediumImageToImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * SD3Output
 */
export const zStableDiffusionV3MediumImageToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiStableDiffusionV3MediumImageToImageImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  num_images: z.int().register(z.globalRegistry, {
    description: 'The number of images generated.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * DWPoseInput
 */
export const zDwposeInput = z.object({
  draw_mode: z.optional(
    z
      .enum([
        'full-pose',
        'body-pose',
        'face-pose',
        'hand-pose',
        'face-hand-mask',
        'face-mask',
        'hand-mask',
      ])
      .register(z.globalRegistry, {
        description:
          "Mode of drawing the pose on the image. Options are: 'full-pose', 'body-pose', 'face-pose', 'hand-pose', 'face-hand-mask', 'face-mask', 'hand-mask'.",
      }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to be processed',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiDwposeImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * DWPoseOutput
 */
export const zDwposeOutput = z.object({
  image: zFalAiDwposeImage,
})

/**
 * ImageSize
 */
export const zFalAiSd15DepthControlnetImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zFalAiSd15DepthControlnetLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights. Or HF model name.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * TextToImageControlNetInput
 */
export const zSd15DepthControlnetInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiSd15DepthControlnetImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
      z.null(),
    ]),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded with additional prompts.',
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zFalAiSd15DepthControlnetLoraWeight).register(z.globalRegistry, {
        description: 'The list of LoRA weights to use.',
      }),
    )
    .default([]),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(7.5),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  controlnet_conditioning_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The scale of the controlnet conditioning.',
      }),
    )
    .default(0.5),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  control_image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the control image.',
  }),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(70).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(35),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  enable_deep_cache: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, DeepCache will be enabled. TBD\n        ',
      }),
    )
    .default(false),
})

/**
 * Image
 */
export const zFalAiSd15DepthControlnetImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zSd15DepthControlnetOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiSd15DepthControlnetImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * CCSRInput
 */
export const zCcsrInput = z.object({
  color_fix_type: z.optional(
    z.enum(['none', 'wavelet', 'adain']).register(z.globalRegistry, {
      description: 'Type of color correction for samples.',
    }),
  ),
  tile_diffusion_size: z
    .optional(
      z.int().gte(256).lte(2048).register(z.globalRegistry, {
        description: 'Size of patch.',
      }),
    )
    .default(1024),
  tile_vae_decoder_size: z
    .optional(
      z.int().gte(64).lte(2048).register(z.globalRegistry, {
        description: 'Size of VAE patch.',
      }),
    )
    .default(226),
  tile_vae_encoder_size: z
    .optional(
      z.int().gte(128).lte(2048).register(z.globalRegistry, {
        description: 'Size of latent image',
      }),
    )
    .default(1024),
  t_min: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The starting point of uniform sampling strategy.',
      }),
    )
    .default(0.3333),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL or data URI of the image to upscale.',
  }),
  tile_diffusion_stride: z
    .optional(
      z.int().gte(128).lte(1024).register(z.globalRegistry, {
        description: 'Stride of sliding patch.',
      }),
    )
    .default(512),
  tile_vae: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If specified, a patch-based sampling strategy will be used for VAE decoding.',
      }),
    )
    .default(false),
  scale: z
    .optional(
      z.number().gte(1).lte(4).register(z.globalRegistry, {
        description:
          'The scale of the output image. The higher the scale, the bigger the output image will be.',
      }),
    )
    .default(2),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Seed for reproducibility. Different seeds will make slightly different results.',
    }),
  ),
  t_max: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The ending point of uniform sampling strategy.',
      }),
    )
    .default(0.6667),
  steps: z
    .optional(
      z.int().gte(10).lte(100).register(z.globalRegistry, {
        description:
          'The number of steps to run the model for. The higher the number the better the quality and longer it will take to generate.',
      }),
    )
    .default(50),
  tile_diffusion: z.optional(
    z.enum(['none', 'mix', 'gaussian']).register(z.globalRegistry, {
      description:
        'If specified, a patch-based sampling strategy will be used for sampling.',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiCcsrImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * CCSROutput
 */
export const zCcsrOutput = z.object({
  image: zFalAiCcsrImage,
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the generation.',
  }),
})

/**
 * OmniZeroInput
 */
export const zOmniZeroInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Prompt to guide the image generation.',
  }),
  identity_image_url: z.string().register(z.globalRegistry, {
    description: 'Identity image url.',
  }),
  identity_strength: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: 'Identity strength.',
      }),
    )
    .default(1),
  number_of_images: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Number of images.',
      }),
    )
    .default(1),
  guidance_scale: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: 'Guidance scale.',
      }),
    )
    .default(5),
  image_strength: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: 'Image strength.',
      }),
    )
    .default(0.75),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to guide the image generation.',
      }),
    )
    .default(''),
  composition_image_url: z.string().register(z.globalRegistry, {
    description: 'Composition image url.',
  }),
  depth_strength: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: 'Depth strength.',
      }),
    )
    .default(0.5),
  composition_strength: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: 'Composition strength.',
      }),
    )
    .default(1),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Input image url.',
  }),
  style_image_url: z.string().register(z.globalRegistry, {
    description: 'Style image url.',
  }),
  face_strength: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: 'Face strength.',
      }),
    )
    .default(1),
  style_strength: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: 'Style strength.',
      }),
    )
    .default(1),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Seed.',
      }),
    )
    .default(42),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiOmniZeroImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * OmniZeroOutput
 */
export const zOmniZeroOutput = z.object({
  image: zFalAiOmniZeroImage,
})

/**
 * IpAdapterFaceIdInput
 */
export const zIpAdapterFaceIdInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  face_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'An image of a face to match. If an image with a size of 640x640 is not provided, it will be scaled and cropped to that size.',
    }),
  ),
  width: z
    .optional(
      z.int().gte(512).lte(1024).register(z.globalRegistry, {
        description:
          '\n            The width of the generated image.\n        ',
      }),
    )
    .default(512),
  face_id_det_size: z
    .optional(
      z.int().gte(64).lte(640).register(z.globalRegistry, {
        description:
          '\n            The size of the face detection model. The higher the number the more accurate\n            the detection will be but it will also take longer to run. The higher the number the more\n            likely it will fail to find a face as well. Lower it if you are having trouble\n            finding a face in the image.\n        ',
      }),
    )
    .default(640),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(16).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(7.5),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(
      'blurry, low resolution, bad, ugly, low quality, pixelated, interpolated, compression artifacts, noisey, grainy',
    ),
  height: z
    .optional(
      z.int().gte(512).lte(1024).register(z.globalRegistry, {
        description:
          '\n            The height of the generated image.\n        ',
      }),
    )
    .default(512),
  num_samples: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description:
          '\n            The number of samples for face id. The more samples the better the image will\n            be but it will also take longer to generate. Default is 4.\n        ',
      }),
    )
    .default(4),
  base_sdxl_model_repo: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'The URL to the base SDXL model. Default is SG161222/RealVisXL_V3.0',
      }),
    )
    .default('SG161222/RealVisXL_V3.0'),
  base_1_5_model_repo: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'The URL to the base 1.5 model. Default is SG161222/Realistic_Vision_V4.0_noVAE',
      }),
    )
    .default('SG161222/Realistic_Vision_V4.0_noVAE'),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(200).register(z.globalRegistry, {
        description:
          '\n            The number of inference steps to use for generating the image. The more steps\n            the better the image will be but it will also take longer to generate.\n        ',
      }),
    )
    .default(50),
  model_type: z.optional(
    z
      .enum([
        '1_5-v1',
        '1_5-v1-plus',
        '1_5-v2-plus',
        'SDXL-v1',
        'SDXL-v2-plus',
        '1_5-auraface-v1',
      ])
      .register(z.globalRegistry, {
        description:
          'The model type to use. 1_5 is the default and is recommended for most use cases.',
      }),
  ),
  face_images_data_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        '\n            URL to zip archive with images of faces. The images embedding will be averaged to\n            create a more accurate face id.\n        ',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiIpAdapterFaceIdImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * IpAdapterFaceIdOutput
 */
export const zIpAdapterFaceIdOutput = z.object({
  image: zFalAiIpAdapterFaceIdImage,
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * TimestepsInput
 */
export const zTimestepsInput = z.object({
  method: z.optional(
    z.enum(['default', 'array']).register(z.globalRegistry, {
      description:
        "\n            The method to use for the timesteps. If set to 'array', the timesteps will be set based\n            on the provided timesteps schedule in the `array` field.\n            Defaults to 'default' which means the scheduler will use the `num_inference_steps` parameter.\n        ",
    }),
  ),
  array: z
    .optional(
      z.array(z.int()).register(z.globalRegistry, {
        description:
          "\n           Timesteps schedule to be used if 'custom' method is selected.\n        ",
      }),
    )
    .default([]),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiLoraInpaintImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * File
 */
export const zFalAiLoraInpaintFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * OutputParameters
 */
export const zLoraInpaintOutput = z.object({
  images: z.array(zFalAiLoraInpaintImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  debug_latents: z.optional(zFalAiLoraInpaintFile),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  debug_per_pass_latents: z.optional(zFalAiLoraInpaintFile),
})

/**
 * TimestepsInput
 */
export const zFalAiLoraImageToImageTimestepsInput = z.object({
  method: z.optional(
    z.enum(['default', 'array']).register(z.globalRegistry, {
      description:
        "\n            The method to use for the timesteps. If set to 'array', the timesteps will be set based\n            on the provided timesteps schedule in the `array` field.\n            Defaults to 'default' which means the scheduler will use the `num_inference_steps` parameter.\n        ",
    }),
  ),
  array: z
    .optional(
      z.array(z.int()).register(z.globalRegistry, {
        description:
          "\n           Timesteps schedule to be used if 'custom' method is selected.\n        ",
      }),
    )
    .default([]),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiLoraImageToImageImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * File
 */
export const zFalAiLoraImageToImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * OutputParameters
 */
export const zLoraImageToImageOutput = z.object({
  images: z.array(zFalAiLoraImageToImageImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  debug_latents: z.optional(zFalAiLoraImageToImageFile),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  debug_per_pass_latents: z.optional(zFalAiLoraImageToImageFile),
})

/**
 * ImageSize
 */
export const zFalAiFastSdxlImageToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Embedding
 */
export const zFalAiFastSdxlImageToImageEmbedding = z.object({
  tokens: z
    .optional(
      z.array(z.string()).register(z.globalRegistry, {
        description: 'The list of tokens to use for the embedding.',
      }),
    )
    .default(['<s0>', '<s1>']),
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the embedding weights.',
  }),
})

/**
 * LoraWeight
 */
export const zFalAiFastSdxlImageToImageLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights. Or HF model name.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
  force: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the embedding will be forced to be used.',
      }),
    )
    .default(false),
})

/**
 * ImageToImageInput
 */
export const zFastSdxlImageToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiFastSdxlImageToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  embeddings: z
    .optional(
      z.array(zFalAiFastSdxlImageToImageEmbedding).register(z.globalRegistry, {
        description: 'The list of embeddings to use.',
      }),
    )
    .default([]),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded with additional prompts.',
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zFalAiFastSdxlImageToImageLoraWeight).register(z.globalRegistry, {
        description: 'The list of LoRA weights to use.',
      }),
    )
    .default([]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(7.5),
  preserve_aspect_ratio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n        If set to true, the aspect ratio of the generated image will be preserved even\n        if the image size is too large. However, if the image is not a multiple of 32\n        in width or height, it will be resized to the nearest multiple of 32. By default,\n        this snapping to the nearest multiple of 32 will not preserve the aspect ratio.\n        Set crop_output to True, to crop the output to the proper aspect ratio\n        after generating.\n        ',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  crop_output: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n        If set to true, the output cropped to the proper aspect ratio after generating.\n        ',
      }),
    )
    .default(false),
  format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the image to use as a starting point for the generation.',
  }),
  strength: z
    .optional(
      z.number().gte(0.05).lte(1).register(z.globalRegistry, {
        description:
          'determines how much the generated image resembles the initial image',
      }),
    )
    .default(0.95),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  safety_checker_version: z.optional(
    z.enum(['v1', 'v2']).register(z.globalRegistry, {
      description:
        'The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.',
    }),
  ),
  request_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          '\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ',
      }),
    )
    .default(''),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(65).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(25),
})

/**
 * Image
 */
export const zFalAiFastSdxlImageToImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFastSdxlImageToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFastSdxlImageToImageImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * ImageSize
 */
export const zFalAiFastSdxlInpaintingImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Embedding
 */
export const zFalAiFastSdxlInpaintingEmbedding = z.object({
  tokens: z
    .optional(
      z.array(z.string()).register(z.globalRegistry, {
        description: 'The list of tokens to use for the embedding.',
      }),
    )
    .default(['<s0>', '<s1>']),
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the embedding weights.',
  }),
})

/**
 * LoraWeight
 */
export const zFalAiFastSdxlInpaintingLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights. Or HF model name.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
  force: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the embedding will be forced to be used.',
      }),
    )
    .default(false),
})

/**
 * InpaintingInput
 */
export const zFastSdxlInpaintingInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiFastSdxlInpaintingImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  embeddings: z
    .optional(
      z.array(zFalAiFastSdxlInpaintingEmbedding).register(z.globalRegistry, {
        description: 'The list of embeddings to use.',
      }),
    )
    .default([]),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded with additional prompts.',
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zFalAiFastSdxlInpaintingLoraWeight).register(z.globalRegistry, {
        description: 'The list of LoRA weights to use.',
      }),
    )
    .default([]),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(7.5),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the image to use as a starting point for the generation.',
  }),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'determines how much the generated image resembles the initial image',
      }),
    )
    .default(0.95),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  safety_checker_version: z.optional(
    z.enum(['v1', 'v2']).register(z.globalRegistry, {
      description:
        'The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.',
    }),
  ),
  request_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          '\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ',
      }),
    )
    .default(''),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(65).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(25),
  mask_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the mask to use for inpainting.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiFastSdxlInpaintingImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFastSdxlInpaintingOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFastSdxlInpaintingImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * ImageSize
 */
export const zFalAiFaceToStickerImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * FaceToStickerInput
 */
export const zFaceToStickerInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to false, the safety checker will be disabled.',
      }),
    )
    .default(true),
  image_size: z.optional(
    z.union([
      zFalAiFaceToStickerImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  ip_adapter_weight: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The weight of the IP adapter.',
      }),
    )
    .default(0.2),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the video.',
  }),
  upscale_steps: z
    .optional(
      z.int().gte(1).lte(20).register(z.globalRegistry, {
        description:
          'The number of steps to use for upscaling. Only used if `upscale` is `true`.',
      }),
    )
    .default(10),
  instant_id_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The strength of the instant ID.',
      }),
    )
    .default(0.7),
  upscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to upscale the image 2x.',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(4.5),
  num_inference_steps: z
    .optional(
      z.int().gte(10).lte(40).register(z.globalRegistry, {
        description:
          '\n            Increasing the amount of steps tells Stable Diffusion that it should take more steps\n            to generate your final result which can increase the amount of detail in your image.\n        ',
      }),
    )
    .default(20),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  ip_adapter_noise: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The amount of noise to add to the IP adapter.',
      }),
    )
    .default(0.5),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFaceToStickerImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FaceToStickerOutput
 */
export const zFaceToStickerOutput = z.object({
  images: z.array(zFalAiFaceToStickerImage).register(z.globalRegistry, {
    description: 'The generated images.',
  }),
  sticker_image: zFalAiFaceToStickerImage,
  sticker_image_background_removed: zFalAiFaceToStickerImage,
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used during the inference.',
  }),
  has_nsfw_concepts: z
    .record(z.string(), z.boolean())
    .register(z.globalRegistry, {
      description:
        '\n            Whether the generated images contain NSFW concepts.\n            The key is the image type and the value is a boolean.\n        ',
    }),
})

/**
 * PhotoMakerInput
 */
export const zPhotomakerInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description:
          '\n            Number of images to generate in one request. Note that the higher the batch size,\n            the longer it will take to generate the images.\n        ',
      }),
    )
    .default(1),
  style_strength: z.optional(z.int().gte(15).lte(50)).default(20),
  style: z.optional(
    z.enum([
      '(No style)',
      'Cinematic',
      'Disney Character',
      'Digital Art',
      'Photographic',
      'Fantasy art',
      'Neonpunk',
      'Enhance',
      'Comic book',
      'Lowpoly',
      'Line art',
    ]),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0.1).lte(10).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  image_archive_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the image archive containing the images you want to use.',
  }),
  initial_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'Optional initial image for img2img',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(20).lte(100).register(z.globalRegistry, {
        description:
          '\n            Increasing the amount of steps tells Stable Diffusion that it should take more steps\n            to generate your final result which can increase the amount of detail in your image.\n        ',
      }),
    )
    .default(50),
  initial_image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'How much noise to add to the latent image. O for no noise, 1 for maximum noise.',
      }),
    )
    .default(0.5),
  base_pipeline: z.optional(
    z.enum(['photomaker', 'photomaker-style']).register(z.globalRegistry, {
      description: 'The base pipeline to use for generating the image.',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPhotomakerImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * PhotoMakerOutput
 */
export const zPhotomakerOutput = z.object({
  images: z.array(zFalAiPhotomakerImage),
  seed: z.int(),
})

/**
 * CreativeUpscalerInput
 */
export const zCreativeUpscalerInput = z.object({
  shape_preservation: z
    .optional(
      z.number().gte(0).lte(3).register(z.globalRegistry, {
        description: 'How much to preserve the shape of the original image',
      }),
    )
    .default(0.25),
  prompt: z.optional(z.union([z.string(), z.null()])),
  additional_embedding_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The URL to the additional embeddings to use for the upscaling. Default is None',
    }),
  ),
  enable_safety_checks: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the resulting image will be checked whether it includes any\n            potentially unsafe content. If it does, it will be replaced with a black\n            image.\n        ',
      }),
    )
    .default(true),
  additional_lora_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The URL to the additional LORA model to use for the upscaling. Default is None',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(16).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(7.5),
  scale: z
    .optional(
      z.number().gte(1).lte(5).register(z.globalRegistry, {
        description:
          'The scale of the output image. The higher the scale, the bigger the output image will be.',
      }),
    )
    .default(2),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(
      'blurry, low resolution, bad, ugly, low quality, pixelated, interpolated, compression artifacts, noisey, grainy',
    ),
  skip_ccsr: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the image will not be processed by the CCSR model before\n            being processed by the creativity model.\n        ',
      }),
    )
    .default(false),
  additional_lora_scale: z
    .optional(
      z.number().register(z.globalRegistry, {
        description:
          'The scale of the additional LORA model to use for the upscaling. Default is 1.0',
      }),
    )
    .default(1),
  detail: z
    .optional(
      z.number().gte(0).lte(5).register(z.globalRegistry, {
        description: 'How much detail to add',
      }),
    )
    .default(1),
  base_model_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The URL to the base model to use for the upscaling',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The image to upscale.',
  }),
  creativity: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'How much the output can deviate from the original',
      }),
    )
    .default(0.5),
  override_size_limits: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            Allow for large uploads that could take a very long time.\n        ',
      }),
    )
    .default(false),
  prompt_suffix: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "The suffix to add to the prompt. This is useful to add a common ending to all prompts such as 'high quality' etc or embedding tokens.",
      }),
    )
    .default(' high quality, highly detailed, high resolution, sharp'),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(200).register(z.globalRegistry, {
        description:
          '\n            The number of inference steps to use for generating the image. The more steps\n            the better the image will be but it will also take longer to generate.\n        ',
      }),
    )
    .default(20),
  model_type: z.optional(
    z.enum(['SD_1_5', 'SDXL']).register(z.globalRegistry, {
      description:
        'The type of model to use for the upscaling. Default is SD_1_5',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiCreativeUpscalerImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * CreativeUpscalerOutput
 */
export const zCreativeUpscalerOutput = z.object({
  image: zFalAiCreativeUpscalerImage,
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * Input
 */
export const zBirefnetInput = z.object({
  operating_resolution: z.optional(
    z.enum(['1024x1024', '2048x2048']).register(z.globalRegistry, {
      description:
        'The resolution to operate on. The higher the resolution, the more accurate the output will be for high res input images.',
    }),
  ),
  output_format: z.optional(
    z.enum(['webp', 'png', 'gif']).register(z.globalRegistry, {
      description: 'The format of the output image',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to remove background from',
  }),
  model: z.optional(
    z
      .enum(['General Use (Light)', 'General Use (Heavy)', 'Portrait'])
      .register(z.globalRegistry, {
        description:
          "\n            Model to use for background removal.\n            The 'General Use (Light)' model is the original model used in the BiRefNet repository.\n            The 'General Use (Heavy)' model is a slower but more accurate model.\n            The 'Portrait' model is a model trained specifically for portrait images.\n            The 'General Use (Light)' model is recommended for most use cases.\n\n            The corresponding models are as follows:\n            - 'General Use (Light)': BiRefNet-DIS_ep580.pth\n            - 'General Use (Heavy)': BiRefNet-massive-epoch_240.pth\n            - 'Portrait': BiRefNet-portrait-TR_P3M_10k-epoch_120.pth\n        ",
      }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  output_mask: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to output the mask used to remove the background',
      }),
    )
    .default(false),
  refine_foreground: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to refine the foreground using the estimated mask',
      }),
    )
    .default(true),
})

/**
 * ImageFile
 */
export const zFalAiBirefnetImageFile = z.object({
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Output
 */
export const zBirefnetOutput = z.object({
  image: zFalAiBirefnetImageFile,
  mask_image: z.optional(zFalAiBirefnetImageFile),
})

/**
 * ImageSize
 */
export const zFalAiFastLightningSdxlImageToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Embedding
 */
export const zFalAiFastLightningSdxlImageToImageEmbedding = z.object({
  tokens: z
    .optional(
      z.array(z.string()).register(z.globalRegistry, {
        description: 'The list of tokens to use for the embedding.',
      }),
    )
    .default(['<s0>', '<s1>']),
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the embedding weights.',
  }),
})

/**
 * ImageToImageLightningInput
 */
export const zFastLightningSdxlImageToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiFastLightningSdxlImageToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  embeddings: z
    .optional(
      z
        .array(zFalAiFastLightningSdxlImageToImageEmbedding)
        .register(z.globalRegistry, {
          description: 'The list of embeddings to use.',
        }),
    )
    .default([]),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded with additional prompts.',
      }),
    )
    .default(false),
  guidance_rescale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The rescale factor for the CFG.',
      }),
    )
    .default(0),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  preserve_aspect_ratio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n        If set to true, the aspect ratio of the generated image will be preserved even\n        if the image size is too large. However, if the image is not a multiple of 32\n        in width or height, it will be resized to the nearest multiple of 32. By default,\n        this snapping to the nearest multiple of 32 will not preserve the aspect ratio.\n        Set crop_output to True, to crop the output to the proper aspect ratio\n        after generating.\n        ',
      }),
    )
    .default(false),
  crop_output: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n        If set to true, the output cropped to the proper aspect ratio after generating.\n        ',
      }),
    )
    .default(false),
  format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the image to use as a starting point for the generation.',
  }),
  strength: z
    .optional(
      z.number().gte(0.05).lte(1).register(z.globalRegistry, {
        description:
          'determines how much the generated image resembles the initial image',
      }),
    )
    .default(0.95),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  safety_checker_version: z.optional(
    z.enum(['v1', 'v2']).register(z.globalRegistry, {
      description:
        'The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.',
    }),
  ),
  request_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          '\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ',
      }),
    )
    .default(''),
  num_inference_steps: z.optional(
    z.enum(['1', '2', '4', '8']).register(z.globalRegistry, {
      description: 'The number of inference steps to perform.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiFastLightningSdxlImageToImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFastLightningSdxlImageToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFastLightningSdxlImageToImageImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiPlaygroundV25InpaintingImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Embedding
 */
export const zFalAiPlaygroundV25InpaintingEmbedding = z.object({
  tokens: z
    .optional(
      z.array(z.string()).register(z.globalRegistry, {
        description: 'The list of tokens to use for the embedding.',
      }),
    )
    .default(['<s0>', '<s1>']),
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the embedding weights.',
  }),
})

/**
 * InpaintingPlaygroundv25Input
 */
export const zPlaygroundV25InpaintingInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiPlaygroundV25InpaintingImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  embeddings: z
    .optional(
      z
        .array(zFalAiPlaygroundV25InpaintingEmbedding)
        .register(z.globalRegistry, {
          description: 'The list of embeddings to use.',
        }),
    )
    .default([]),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded with additional prompts.',
      }),
    )
    .default(false),
  guidance_rescale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The rescale factor for the CFG.',
      }),
    )
    .default(0),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the image to use as a starting point for the generation.',
  }),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'determines how much the generated image resembles the initial image',
      }),
    )
    .default(0.95),
  safety_checker_version: z.optional(
    z.enum(['v1', 'v2']).register(z.globalRegistry, {
      description:
        'The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.',
    }),
  ),
  request_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          '\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ',
      }),
    )
    .default(''),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  mask_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the mask to use for inpainting.',
  }),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(65).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(25),
})

/**
 * Image
 */
export const zFalAiPlaygroundV25InpaintingImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zPlaygroundV25InpaintingOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiPlaygroundV25InpaintingImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiPlaygroundV25ImageToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Embedding
 */
export const zFalAiPlaygroundV25ImageToImageEmbedding = z.object({
  tokens: z
    .optional(
      z.array(z.string()).register(z.globalRegistry, {
        description: 'The list of tokens to use for the embedding.',
      }),
    )
    .default(['<s0>', '<s1>']),
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the embedding weights.',
  }),
})

/**
 * ImageToImagePlaygroundv25Input
 */
export const zPlaygroundV25ImageToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiPlaygroundV25ImageToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  embeddings: z
    .optional(
      z
        .array(zFalAiPlaygroundV25ImageToImageEmbedding)
        .register(z.globalRegistry, {
          description: 'The list of embeddings to use.',
        }),
    )
    .default([]),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded with additional prompts.',
      }),
    )
    .default(false),
  guidance_rescale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The rescale factor for the CFG.',
      }),
    )
    .default(0),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3),
  preserve_aspect_ratio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n        If set to true, the aspect ratio of the generated image will be preserved even\n        if the image size is too large. However, if the image is not a multiple of 32\n        in width or height, it will be resized to the nearest multiple of 32. By default,\n        this snapping to the nearest multiple of 32 will not preserve the aspect ratio.\n        Set crop_output to True, to crop the output to the proper aspect ratio\n        after generating.\n        ',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  crop_output: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n        If set to true, the output cropped to the proper aspect ratio after generating.\n        ',
      }),
    )
    .default(false),
  format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the image to use as a starting point for the generation.',
  }),
  strength: z
    .optional(
      z.number().gte(0.05).lte(1).register(z.globalRegistry, {
        description:
          'determines how much the generated image resembles the initial image',
      }),
    )
    .default(0.95),
  safety_checker_version: z.optional(
    z.enum(['v1', 'v2']).register(z.globalRegistry, {
      description:
        'The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.',
    }),
  ),
  request_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          '\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ',
      }),
    )
    .default(''),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(65).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(25),
})

/**
 * Image
 */
export const zFalAiPlaygroundV25ImageToImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zPlaygroundV25ImageToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiPlaygroundV25ImageToImageImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFastLightningSdxlInpaintingImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Embedding
 */
export const zFalAiFastLightningSdxlInpaintingEmbedding = z.object({
  tokens: z
    .optional(
      z.array(z.string()).register(z.globalRegistry, {
        description: 'The list of tokens to use for the embedding.',
      }),
    )
    .default(['<s0>', '<s1>']),
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the embedding weights.',
  }),
})

/**
 * InpaintingLightningInput
 */
export const zFastLightningSdxlInpaintingInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiFastLightningSdxlInpaintingImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  embeddings: z
    .optional(
      z
        .array(zFalAiFastLightningSdxlInpaintingEmbedding)
        .register(z.globalRegistry, {
          description: 'The list of embeddings to use.',
        }),
    )
    .default([]),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded with additional prompts.',
      }),
    )
    .default(false),
  guidance_rescale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The rescale factor for the CFG.',
      }),
    )
    .default(0),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the image to use as a starting point for the generation.',
  }),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'determines how much the generated image resembles the initial image',
      }),
    )
    .default(0.95),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  safety_checker_version: z.optional(
    z.enum(['v1', 'v2']).register(z.globalRegistry, {
      description:
        'The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.',
    }),
  ),
  request_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          '\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ',
      }),
    )
    .default(''),
  num_inference_steps: z.optional(
    z.enum(['1', '2', '4', '8']).register(z.globalRegistry, {
      description: 'The number of inference steps to perform.',
    }),
  ),
  mask_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the mask to use for inpainting.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiFastLightningSdxlInpaintingImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFastLightningSdxlInpaintingOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFastLightningSdxlInpaintingImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFastLcmDiffusionInpaintingImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * InpaintingLCMInput
 */
export const zFastLcmDiffusionInpaintingInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiFastLcmDiffusionInpaintingImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded with additional prompts.',
      }),
    )
    .default(false),
  guidance_rescale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The rescale factor for the CFG.',
      }),
    )
    .default(0),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(1.5),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the image to use as a starting point for the generation.',
  }),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'determines how much the generated image resembles the initial image',
      }),
    )
    .default(0.95),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(true),
  safety_checker_version: z.optional(
    z.enum(['v1', 'v2']).register(z.globalRegistry, {
      description:
        'The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.',
    }),
  ),
  request_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          '\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ',
      }),
    )
    .default(''),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(32).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(6),
  mask_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the mask to use for inpainting.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  model_name: z.optional(
    z
      .enum([
        'stabilityai/stable-diffusion-xl-base-1.0',
        'runwayml/stable-diffusion-v1-5',
      ])
      .register(z.globalRegistry, {
        description: 'The name of the model to use.',
      }),
  ),
})

/**
 * Image
 */
export const zFalAiFastLcmDiffusionInpaintingImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFastLcmDiffusionInpaintingOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFastLcmDiffusionInpaintingImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFastLcmDiffusionImageToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * ImageToImageLCMInput
 */
export const zFastLcmDiffusionImageToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiFastLcmDiffusionImageToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded with additional prompts.',
      }),
    )
    .default(false),
  guidance_rescale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The rescale factor for the CFG.',
      }),
    )
    .default(0),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(1.5),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  preserve_aspect_ratio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n        If set to true, the aspect ratio of the generated image will be preserved even\n        if the image size is too large. However, if the image is not a multiple of 32\n        in width or height, it will be resized to the nearest multiple of 32. By default,\n        this snapping to the nearest multiple of 32 will not preserve the aspect ratio.\n        Set crop_output to True, to crop the output to the proper aspect ratio\n        after generating.\n        ',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  crop_output: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n        If set to true, the output cropped to the proper aspect ratio after generating.\n        ',
      }),
    )
    .default(false),
  format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the image to use as a starting point for the generation.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(true),
  model_name: z.optional(
    z
      .enum([
        'stabilityai/stable-diffusion-xl-base-1.0',
        'runwayml/stable-diffusion-v1-5',
      ])
      .register(z.globalRegistry, {
        description: 'The name of the model to use.',
      }),
  ),
  safety_checker_version: z.optional(
    z.enum(['v1', 'v2']).register(z.globalRegistry, {
      description:
        'The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.',
    }),
  ),
  request_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          '\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ',
      }),
    )
    .default(''),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(32).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(6),
  strength: z
    .optional(
      z.number().gte(0.05).lte(1).register(z.globalRegistry, {
        description:
          'determines how much the generated image resembles the initial image',
      }),
    )
    .default(0.95),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiFastLcmDiffusionImageToImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFastLcmDiffusionImageToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFastLcmDiffusionImageToImageImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * DepthMapInput
 */
export const zImageutilsDepthInput = z.object({
  bg_th: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: 'bg_th',
      }),
    )
    .default(0.1),
  a: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: 'a',
      }),
    )
    .default(6.283185307179586),
  depth_and_normal: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'depth_and_normal',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Input image url.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageutilsDepthImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * DepthMapOutput
 */
export const zImageutilsDepthOutput = z.object({
  image: zFalAiImageutilsDepthImage,
})

/**
 * RetoucherInput
 */
export const zRetoucherInput = z.object({
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Seed for reproducibility. Different seeds will make slightly different results.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to be retouched.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiRetoucherImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * RetoucherOutput
 */
export const zRetoucherOutput = z.object({
  image: zFalAiRetoucherImage,
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the generation.',
  }),
})

/**
 * MarigoldDepthMapInput
 */
export const zImageutilsMarigoldDepthInput = z.object({
  ensemble_size: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of predictions to average over. Defaults to `10`. The higher the number, the more accurate the result, but the slower the inference.',
      }),
    )
    .default(10),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of denoising steps. Defaults to `10`. The higher the number, the more accurate the result, but the slower the inference.',
      }),
    )
    .default(10),
  processing_res: z
    .optional(
      z.int().gte(0).lte(2048).register(z.globalRegistry, {
        description:
          'Maximum processing resolution. Defaults `0` which means it uses the size of the input image.',
      }),
    )
    .default(0),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Input image url.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageutilsMarigoldDepthImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * MarigoldDepthMapOutput
 */
export const zImageutilsMarigoldDepthOutput = z.object({
  image: zFalAiImageutilsMarigoldDepthImage,
})

/**
 * ImageSize
 */
export const zFalAiPulidImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * ReferenceFace
 */
export const zReferenceFace = z.object({
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the reference face image',
  }),
})

/**
 * InputModel
 */
export const zPulidInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Prompt to generate the face from',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'Number of images to generate',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiPulidImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  id_scale: z
    .optional(
      z.number().lte(5).register(z.globalRegistry, {
        description: 'ID scale',
      }),
    )
    .default(0.8),
  mode: z.optional(
    z.enum(['fidelity', 'extreme style']).register(z.globalRegistry, {
      description: 'Mode of generation',
    }),
  ),
  id_mix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'if you want to mix two ID image, please turn this on, otherwise, turn this off',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(1.5).register(z.globalRegistry, {
        description: 'Guidance scale',
      }),
    )
    .default(1.2),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(12).register(z.globalRegistry, {
        description: 'Number of steps to take',
      }),
    )
    .default(4),
  reference_images: z.array(zReferenceFace).register(z.globalRegistry, {
    description: 'List of reference faces, ideally 4 images.',
  }),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to generate the face from',
      }),
    )
    .default(
      'flaws in the eyes, flaws in the face, flaws, lowres, non-HDRi, low quality, worst quality,artifacts noise, text, watermark, glitch, deformed, mutated, ugly, disfigured, hands, low resolution, partially rendered objects,  deformed or partially rendered eyes, deformed, deformed eyeballs, cross-eyed,blurry',
    ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for reproducibility',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPulidImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * OutputModel
 */
export const zPulidOutput = z.object({
  images: z.array(zFalAiPulidImage).register(z.globalRegistry, {
    description: 'List of generated images',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'Random seed used for reproducibility',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFastSdxlControlnetCannyInpaintingImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zFalAiFastSdxlControlnetCannyInpaintingLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights. Or HF model name.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * InpaintingControlNetInput
 */
export const zFastSdxlControlnetCannyInpaintingInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiFastSdxlControlnetCannyInpaintingImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
      z.null(),
    ]),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded with additional prompts.',
      }),
    )
    .default(false),
  loras: z
    .optional(
      z
        .array(zFalAiFastSdxlControlnetCannyInpaintingLoraWeight)
        .register(z.globalRegistry, {
          description: 'The list of LoRA weights to use.',
        }),
    )
    .default([]),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(7.5),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  controlnet_conditioning_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The scale of the controlnet conditioning.',
      }),
    )
    .default(0.5),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the image to use as a starting point for the generation.',
  }),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'determines how much the generated image resembles the initial image',
      }),
    )
    .default(0.95),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  control_image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the control image.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  mask_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the mask to use for inpainting.',
  }),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(65).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(25),
})

/**
 * Image
 */
export const zFalAiFastSdxlControlnetCannyInpaintingImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFastSdxlControlnetCannyInpaintingOutput = z.object({
  images: z
    .array(zFalAiFastSdxlControlnetCannyInpaintingImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFastSdxlControlnetCannyImageToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zFalAiFastSdxlControlnetCannyImageToImageLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights. Or HF model name.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * ImageToImageControlNetInput
 */
export const zFastSdxlControlnetCannyImageToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiFastSdxlControlnetCannyImageToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
      z.null(),
    ]),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded with additional prompts.',
      }),
    )
    .default(false),
  loras: z
    .optional(
      z
        .array(zFalAiFastSdxlControlnetCannyImageToImageLoraWeight)
        .register(z.globalRegistry, {
          description: 'The list of LoRA weights to use.',
        }),
    )
    .default([]),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(7.5),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  controlnet_conditioning_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The scale of the controlnet conditioning.',
      }),
    )
    .default(0.5),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the image to use as a starting point for the generation.',
  }),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'determines how much the generated image resembles the initial image',
      }),
    )
    .default(0.95),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  control_image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the control image.',
  }),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(65).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(25),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiFastSdxlControlnetCannyImageToImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFastSdxlControlnetCannyImageToImageOutput = z.object({
  images: z
    .array(zFalAiFastSdxlControlnetCannyImageToImageImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * LCMI2IInput
 */
export const zLcmSd15I2iInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description:
          '\n            The number of images to generate. The function will return a list of images\n            with the same prompt and negative prompt but different seeds.\n        ',
      }),
    )
    .default(1),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The image to use as a base.',
  }),
  strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The strength of the image.',
      }),
    )
    .default(0.8),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  enable_safety_checks: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the resulting image will be checked whether it includes any\n            potentially unsafe content. If it does, it will be replaced with a black\n            image.\n        ',
      }),
    )
    .default(true),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(16).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(1),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  request_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          '\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ',
      }),
    )
    .default(''),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(12).register(z.globalRegistry, {
        description:
          '\n            The number of inference steps to use for generating the image. The more steps\n            the better the image will be but it will also take longer to generate.\n        ',
      }),
    )
    .default(4),
})

/**
 * Image
 */
export const zFalAiLcmSd15I2iImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * LCMOutput
 */
export const zLcmSd15I2iOutput = z.object({
  images: z.array(zFalAiLcmSd15I2iImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  request_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          '\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ',
      }),
    )
    .default(''),
  timings: z.record(z.string(), z.number()),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  num_inference_steps: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          '\n            Number of inference steps used to generate the image. It will be the same value of the one passed in the\n            input or the default one in case none was passed.\n        ',
      }),
    )
    .default(4),
  nsfw_content_detected: z.array(z.boolean()).register(z.globalRegistry, {
    description:
      '\n            A list of booleans indicating whether the generated image contains any\n            potentially unsafe content. If the safety check is disabled, this field\n            will have a false for each generated image.\n        ',
  }),
})

/**
 * InpaintInput
 */
export const zInpaintInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Input image for img2img or inpaint mode',
  }),
  model_name: z.string().register(z.globalRegistry, {
    description:
      'URL or HuggingFace ID of the base model to generate the image.',
  }),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(7.5),
  num_inference_steps: z
    .optional(
      z.int().gte(0).lte(150).register(z.globalRegistry, {
        description:
          '\n            Increasing the amount of steps tells Stable Diffusion that it should take more steps\n            to generate your final result which can increase the amount of detail in your image.\n        ',
      }),
    )
    .default(30),
  mask_url: z.string().register(z.globalRegistry, {
    description:
      'Input mask for inpaint mode. Black areas will be preserved, white areas will be inpainted.',
  }),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiInpaintImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * InpaintOutput
 */
export const zInpaintOutput = z.object({
  image: zFalAiInpaintImage,
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * UpscaleInput
 */
export const zEsrganInput = z.object({
  model: z.optional(
    z
      .enum([
        'RealESRGAN_x4plus',
        'RealESRGAN_x2plus',
        'RealESRGAN_x4plus_anime_6B',
        'RealESRGAN_x4_v3',
        'RealESRGAN_x4_wdn_v3',
        'RealESRGAN_x4_anime_v3',
      ])
      .register(z.globalRegistry, {
        description: 'Model to use for upscaling',
      }),
  ),
  face: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Upscaling a face',
      }),
    )
    .default(false),
  scale: z
    .optional(
      z.number().gte(1).lte(8).register(z.globalRegistry, {
        description: 'Rescaling factor',
      }),
    )
    .default(2),
  tile: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          'Tile size. Default is 0, that is no tile. When encountering the out-of-GPU-memory issue, please specify it, e.g., 400 or 200',
      }),
    )
    .default(0),
  output_format: z.optional(
    z.enum(['png', 'jpeg']).register(z.globalRegistry, {
      description: 'Output image format (png or jpeg)',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Url to input image',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiEsrganImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * UpscaleOutput
 */
export const zEsrganOutput = z.object({
  image: zFalAiEsrganImage,
})

/**
 * RemoveBackgroundInput
 */
export const zImageutilsRembgInput = z.object({
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  crop_to_bbox: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the resulting image be cropped to a bounding box around the subject\n        ',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Input image url.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageutilsRembgImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * RemoveBackgroundOutput
 */
export const zImageutilsRembgOutput = z.object({
  image: zFalAiImageutilsRembgImage,
})
