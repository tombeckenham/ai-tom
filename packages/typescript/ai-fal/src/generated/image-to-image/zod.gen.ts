// This file is auto-generated by @hey-api/openapi-ts

import { z } from 'zod';

export const zFile = z.object({
    url: z.url(),
    content_type: z.optional(z.string()),
    file_name: z.optional(z.string()),
    file_size: z.optional(z.int())
});

export const zQueueStatus = z.object({
    status: z.enum([
        'IN_PROGRESS',
        'COMPLETED',
        'FAILED'
    ]),
    response_url: z.optional(z.url())
});

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export const zLoRaInput = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(4)).default(1)
});

/**
 * ImageFile
 */
export const zImageFile = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * Flux2EditImageLoRAOutput
 */
export const zFlux2LoraEditOutput = z.object({
    prompt: z.string(),
    images: z.array(zImageFile),
    seed: z.int(),
    has_nsfw_concepts: z.array(z.boolean()),
    timings: z.record(z.string(), z.number())
});

/**
 * ImageSize
 */
export const zImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * Flux2EditImageInput
 */
export const zFlux2EditInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(2.5),
    seed: z.optional(z.int()),
    image_urls: z.array(z.string()),
    enable_prompt_expansion: z.optional(z.boolean()).default(false),
    num_inference_steps: z.optional(z.int().gte(4).lte(50)).default(28)
});

/**
 * ImageFile
 */
export const zFalAiFlux2EditImageFile = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * Flux2EditImageOutput
 */
export const zFlux2EditOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFlux2EditImageFile),
    seed: z.int(),
    has_nsfw_concepts: z.array(z.boolean()),
    timings: z.record(z.string(), z.number())
});

/**
 * ImageSize
 */
export const zFalAiFlux2ProEditImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * Flux2ProImageEditInput
 */
export const zFlux2ProEditInput = z.object({
    prompt: z.string(),
    image_size: z.optional(z.union([
        zFalAiFlux2ProEditImageSize,
        z.enum([
            'auto',
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5'
    ])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    seed: z.optional(z.int()),
    image_urls: z.array(z.string())
});

/**
 * ImageFile
 */
export const zFalAiFlux2ProEditImageFile = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * Flux2ProEditOutput
 */
export const zFlux2ProEditOutput = z.object({
    images: z.array(zFalAiFlux2ProEditImageFile),
    seed: z.int()
});

/**
 * BaseImageToInput
 */
export const zFluxDevImageToImageInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.95),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    guidance_scale: z.optional(z.number().gte(1).lte(20)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(10).lte(50)).default(40)
});

/**
 * Image
 */
export const zImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFluxDevImageToImageOutput = z.object({
    prompt: z.string(),
    images: z.array(zImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * Input
 */
export const zAuraSrInput = z.object({
    overlapping_tiles: z.optional(z.boolean()).default(false),
    checkpoint: z.optional(z.enum(['v1', 'v2'])),
    upscaling_factor: z.optional(z.literal(4)),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiAuraSrImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * Output
 */
export const zAuraSrOutput = z.object({
    image: zFalAiAuraSrImage,
    timings: z.record(z.string(), z.number())
});

/**
 * Input
 */
export const zClarityUpscalerInput = z.object({
    prompt: z.optional(z.string()).default('masterpiece, best quality, highres'),
    resemblance: z.optional(z.number().gte(0).lte(1)).default(0.6),
    creativity: z.optional(z.number().gte(0).lte(1)).default(0.35),
    image_url: z.string(),
    upscale_factor: z.optional(z.number().gte(1).lte(4)).default(2),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(4),
    num_inference_steps: z.optional(z.int().gte(4).lte(50)).default(18),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    negative_prompt: z.optional(z.string()).default('(worst quality, low quality, normal quality:2)'),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiClarityUpscalerImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * Output
 */
export const zClarityUpscalerOutput = z.object({
    image: zFalAiClarityUpscalerImage,
    seed: z.int(),
    timings: z.record(z.string(), z.number())
});

/**
 * FaceSwapInputImage
 *
 * Input schema for image â†” image face swap
 */
export const zAiFaceSwapFaceswapimageInput = z.object({
    source_face_url: z.string(),
    target_image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zHalfMoonAiAiFaceSwapFaceswapimageImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * FaceFusionImageOutput
 *
 * FaceFusion output payload when image content is generated
 */
export const zAiFaceSwapFaceswapimageOutput = z.object({
    image: zHalfMoonAiAiFaceSwapFaceswapimageImage,
    processing_time_ms: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * ReplaceObjectInput
 */
export const zFiboEditReplaceObjectByTextInput = z.object({
    instruction: z.string(),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaFiboEditReplaceObjectByTextImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * FiboEditExtraEPOutputModel
 */
export const zFiboEditReplaceObjectByTextOutput = z.object({
    images: z.optional(z.array(zBriaFiboEditReplaceObjectByTextImage)).default([]),
    image: zBriaFiboEditReplaceObjectByTextImage,
    structured_instruction: z.record(z.string(), z.unknown())
});

/**
 * SketchColoredImageInput
 */
export const zFiboEditSketchToColoredImageInput = z.object({
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaFiboEditSketchToColoredImageImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * FiboEditExtraEPOutputModel
 */
export const zFiboEditSketchToColoredImageOutput = z.object({
    images: z.optional(z.array(zBriaFiboEditSketchToColoredImageImage)).default([]),
    image: zBriaFiboEditSketchToColoredImageImage,
    structured_instruction: z.record(z.string(), z.unknown())
});

/**
 * RestoreInput
 */
export const zFiboEditRestoreInput = z.object({
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaFiboEditRestoreImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * FiboEditExtraEPOutputModel
 */
export const zFiboEditRestoreOutput = z.object({
    images: z.optional(z.array(zBriaFiboEditRestoreImage)).default([]),
    image: zBriaFiboEditRestoreImage,
    structured_instruction: z.record(z.string(), z.unknown())
});

/**
 * ReseasonInput
 */
export const zFiboEditReseasonInput = z.object({
    season: z.enum([
        'spring',
        'summer',
        'autumn',
        'winter'
    ]),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaFiboEditReseasonImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * FiboEditExtraEPOutputModel
 */
export const zFiboEditReseasonOutput = z.object({
    images: z.optional(z.array(zBriaFiboEditReseasonImage)).default([]),
    image: zBriaFiboEditReseasonImage,
    structured_instruction: z.record(z.string(), z.unknown())
});

/**
 * RelightInput
 */
export const zFiboEditRelightInput = z.object({
    light_type: z.enum([
        'midday',
        'blue hour light',
        'low-angle sunlight',
        'sunrise light',
        'spotlight on subject',
        'overcast light',
        'soft overcast daylight lighting',
        'cloud-filtered lighting',
        'fog-diffused lighting',
        'moonlight lighting',
        'starlight nighttime',
        'soft bokeh lighting',
        'harsh studio lighting'
    ]),
    light_direction: z.union([
        z.enum([
            'front',
            'side',
            'bottom',
            'top-down'
        ]),
        z.unknown()
    ]),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaFiboEditRelightImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * FiboEditExtraEPOutputModel
 */
export const zFiboEditRelightOutput = z.object({
    images: z.optional(z.array(zBriaFiboEditRelightImage)).default([]),
    image: zBriaFiboEditRelightImage,
    structured_instruction: z.record(z.string(), z.unknown())
});

/**
 * RestyletInput
 */
export const zFiboEditRestyleInput = z.object({
    style: z.enum([
        '3D Render',
        'Cubism',
        'Oil Painting',
        'Anime',
        'Cartoon',
        'Coloring Book',
        'Retro Ad',
        'Pop Art Halftone',
        'Vector Art',
        'Story Board',
        'Art Nouveau',
        'Cross Etching',
        'Wood Cut'
    ]),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaFiboEditRestyleImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * FiboEditExtraEPOutputModel
 */
export const zFiboEditRestyleOutput = z.object({
    images: z.optional(z.array(zBriaFiboEditRestyleImage)).default([]),
    image: zBriaFiboEditRestyleImage,
    structured_instruction: z.record(z.string(), z.unknown())
});

/**
 * RewriteTextInput
 */
export const zFiboEditRewriteTextInput = z.object({
    new_text: z.string(),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaFiboEditRewriteTextImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * FiboEditExtraEPOutputModel
 */
export const zFiboEditRewriteTextOutput = z.object({
    images: z.optional(z.array(zBriaFiboEditRewriteTextImage)).default([]),
    image: zBriaFiboEditRewriteTextImage,
    structured_instruction: z.record(z.string(), z.unknown())
});

/**
 * EraseByTextInput
 */
export const zFiboEditEraseByTextInput = z.object({
    object_name: z.string(),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaFiboEditEraseByTextImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * FiboEditExtraEPOutputModel
 */
export const zFiboEditEraseByTextOutput = z.object({
    images: z.optional(z.array(zBriaFiboEditEraseByTextImage)).default([]),
    image: zBriaFiboEditEraseByTextImage,
    structured_instruction: z.record(z.string(), z.unknown())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaFiboEditEditImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * FiboEditOutputModel
 */
export const zFiboEditEditOutput = z.object({
    images: z.optional(z.array(zBriaFiboEditEditImage)).default([]),
    image: zBriaFiboEditEditImage,
    structured_instruction: z.record(z.string(), z.unknown())
});

/**
 * Aesthetics
 */
export const zAesthetics = z.object({
    composition: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    mood_atmosphere: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    color_scheme: z.optional(z.union([
        z.string(),
        z.unknown()
    ]))
});

/**
 * PromptObject
 */
export const zPromptObject = z.object({
    relative_size: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    description: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    skin_tone_and_texture: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    appearance_details: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    number_of_objects: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    expression: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    pose: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    shape_and_color: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    relationship: z.string(),
    texture: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    gender: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    clothing: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    location: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    orientation: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    action: z.optional(z.union([
        z.string(),
        z.unknown()
    ]))
});

/**
 * PhotographicCharacteristics
 */
export const zPhotographicCharacteristics = z.object({
    focus: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    lens_focal_length: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    camera_angle: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    depth_of_field: z.optional(z.union([
        z.string(),
        z.unknown()
    ]))
});

/**
 * Lighting
 */
export const zLighting = z.object({
    shadows: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    conditions: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    direction: z.optional(z.union([
        z.string(),
        z.unknown()
    ]))
});

/**
 * StructuredInstruction
 */
export const zStructuredInstruction = z.object({
    background_setting: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    artistic_style: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    aesthetics: z.optional(z.union([
        zAesthetics,
        z.unknown()
    ])),
    text_render: z.optional(z.union([
        z.array(z.unknown()),
        z.unknown()
    ])),
    objects: z.optional(z.union([
        z.array(zPromptObject),
        z.unknown()
    ])),
    context: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    photographic_characteristics: z.optional(z.union([
        zPhotographicCharacteristics,
        z.unknown()
    ])),
    style_medium: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    lighting: z.optional(z.union([
        zLighting,
        z.unknown()
    ])),
    short_description: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    edit_instruction: z.optional(z.union([
        z.string(),
        z.unknown()
    ]))
});

/**
 * FiboEditInputModel
 */
export const zFiboEditEditInput = z.object({
    steps_num: z.optional(z.int().gte(20).lte(50)).default(50),
    instruction: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    image_url: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.union([
        z.number(),
        z.int()
    ])),
    seed: z.optional(z.int()).default(5555),
    mask_url: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    negative_prompt: z.optional(z.string()).default(''),
    structured_instruction: z.optional(z.union([
        zStructuredInstruction,
        z.unknown()
    ]))
});

/**
 * AddObjectByTextInput
 */
export const zFiboEditAddObjectByTextInput = z.object({
    instruction: z.string(),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaFiboEditAddObjectByTextImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * FiboEditExtraEPOutputModel
 */
export const zFiboEditAddObjectByTextOutput = z.object({
    images: z.optional(z.array(zBriaFiboEditAddObjectByTextImage)).default([]),
    image: zBriaFiboEditAddObjectByTextImage,
    structured_instruction: z.record(z.string(), z.unknown())
});

/**
 * BlendingInput
 */
export const zFiboEditBlendInput = z.object({
    instruction: z.string(),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaFiboEditBlendImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * FiboEditExtraEPOutputModel
 */
export const zFiboEditBlendOutput = z.object({
    images: z.optional(z.array(zBriaFiboEditBlendImage)).default([]),
    image: zBriaFiboEditBlendImage,
    structured_instruction: z.record(z.string(), z.unknown())
});

/**
 * ColorizeInput
 */
export const zFiboEditColorizeInput = z.object({
    color: z.enum([
        'contemporary color',
        'vivid color',
        'black and white colors',
        'sepia vintage'
    ]),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaFiboEditColorizeImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * FiboEditExtraEPOutputModel
 */
export const zFiboEditColorizeOutput = z.object({
    images: z.optional(z.array(zBriaFiboEditColorizeImage)).default([]),
    image: zBriaFiboEditColorizeImage,
    structured_instruction: z.record(z.string(), z.unknown())
});

/**
 * LoRAInput
 */
export const zFalAiFlux2KleinLoRaInput = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(4)).default(1)
});

/**
 * ImageFile
 */
export const zFalAiFlux2Klein9bBaseEditLoraImageFile = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * KleinT2IOutput
 */
export const zFlux2Klein9bBaseEditLoraOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFlux2Klein9bBaseEditLoraImageFile),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * LoRAInput
 */
export const zFalAiFlux2Klein4bBaseEditLoraFalAiFlux2KleinLoRaInput = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(4)).default(1)
});

/**
 * ImageFile
 */
export const zFalAiFlux2Klein4bBaseEditLoraImageFile = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * KleinT2IOutput
 */
export const zFlux2Klein4bBaseEditLoraOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFlux2Klein4bBaseEditLoraImageFile),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiFlux2Klein4bBaseEditImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * Klein4BBaseEditInput
 */
export const zFlux2Klein4bBaseEditInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiFlux2Klein4bBaseEditImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(5),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    num_inference_steps: z.optional(z.int().gte(4).lte(50)).default(28),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(''),
    seed: z.optional(z.int())
});

/**
 * ImageFile
 */
export const zFalAiFlux2Klein4bBaseEditImageFile = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * Klein4BBaseEditOutput
 */
export const zFlux2Klein4bBaseEditOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFlux2Klein4bBaseEditImageFile),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiFlux2Klein9bBaseEditImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * Klein9BEditImageInput
 */
export const zFlux2Klein9bBaseEditInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiFlux2Klein9bBaseEditImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(5),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    num_inference_steps: z.optional(z.int().gte(4).lte(50)).default(28),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(''),
    seed: z.optional(z.int())
});

/**
 * ImageFile
 */
export const zFalAiFlux2Klein9bBaseEditImageFile = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * Klein9BBaseEditOutput
 */
export const zFlux2Klein9bBaseEditOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFlux2Klein9bBaseEditImageFile),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiFlux2Klein4bEditImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * KleinDistilledEditInput
 */
export const zFlux2Klein4bEditInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiFlux2Klein4bEditImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    num_inference_steps: z.optional(z.int().gte(4).lte(8)).default(4),
    image_urls: z.array(z.string()),
    seed: z.optional(z.int())
});

/**
 * ImageFile
 */
export const zFalAiFlux2Klein4bEditImageFile = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * Klein4BDistilledEditOutput
 */
export const zFlux2Klein4bEditOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFlux2Klein4bEditImageFile),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiFlux2Klein9bEditImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * Klein9BDistilledEditInput
 */
export const zFlux2Klein9bEditInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiFlux2Klein9bEditImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    num_inference_steps: z.optional(z.int().gte(4).lte(8)).default(4),
    image_urls: z.array(z.string()),
    seed: z.optional(z.int())
});

/**
 * ImageFile
 */
export const zFalAiFlux2Klein9bEditImageFile = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * Klein9BDistilledEditOutput
 */
export const zFlux2Klein9bEditOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFlux2Klein9bEditImageFile),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiGlmImageImageToImageImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * GlmImageToImageInput
 */
export const zGlmImageImageToImageInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiGlmImageImageToImageImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9',
            'portrait_3_2',
            'landscape_3_2',
            'portrait_hd',
            'landscape_hd'
        ])
    ])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(1).lte(10)).default(1.5),
    seed: z.optional(z.int()),
    image_urls: z.array(z.string()),
    enable_prompt_expansion: z.optional(z.boolean()).default(false),
    num_inference_steps: z.optional(z.int().gte(10).lte(100)).default(30)
});

/**
 * Image
 */
export const zFalAiGlmImageImageToImageImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * GlmImageToImageOutput
 */
export const zGlmImageImageToImageOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiGlmImageImageToImageImage),
    seed: z.int(),
    has_nsfw_concepts: z.array(z.boolean()),
    timings: z.record(z.string(), z.number())
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2511MultipleAnglesImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * MultipleAnglesInput
 *
 * Input model for Multiple Angles endpoint - Camera control with precise adjustments using <sks> trigger word.
 * Prompt is built automatically from slider values.
 */
export const zQwenImageEdit2511MultipleAnglesInput = z.object({
    acceleration: z.optional(z.enum(['none', 'regular'])),
    image_size: z.optional(z.union([
        zFalAiQwenImageEdit2511MultipleAnglesImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    horizontal_angle: z.optional(z.number().gte(0).lte(360)).default(0),
    guidance_scale: z.optional(z.number().gte(1).lte(20)).default(4.5),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(''),
    zoom: z.optional(z.number().gte(0).lte(10)).default(5),
    vertical_angle: z.optional(z.number().gte(-30).lte(90)).default(0),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    lora_scale: z.optional(z.number().gte(0).lte(4)).default(1),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    additional_prompt: z.optional(z.string()),
    sync_mode: z.optional(z.boolean()).default(false),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28),
    seed: z.optional(z.int())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEdit2511MultipleAnglesImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * MultipleAnglesOutput
 *
 * Output model for Multiple Angles endpoint
 */
export const zQwenImageEdit2511MultipleAnglesOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiQwenImageEdit2511MultipleAnglesImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2511LoraImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * LoraWeight
 */
export const zLoraWeight = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(4)).default(1)
});

/**
 * EditImageLoraInput
 */
export const zQwenImageEdit2511LoraInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEdit2511LoraImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    loras: z.optional(z.array(zLoraWeight)).default([]),
    guidance_scale: z.optional(z.number().gte(1).lte(20)).default(4.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(''),
    seed: z.optional(z.int())
});

/**
 * Image
 */
export const zFalAiQwenImageEdit2511LoraImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * ImageToImageOutput
 */
export const zQwenImageEdit2511LoraOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiQwenImageEdit2511LoraImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ArchStyleInput
 */
export const zAiHomeStyleInput = z.object({
    input_image_url: z.string().max(512),
    input_image_strength: z.optional(z.number().gte(0).lte(1)).default(0.85),
    additional_elements: z.optional(z.union([
        z.string().max(200),
        z.unknown()
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    style: z.enum([
        'minimalistic-interior',
        'farmhouse-interior',
        'luxury-interior',
        'modern-interior',
        'zen-interior',
        'mid century-interior',
        'airbnb-interior',
        'cozy-interior',
        'rustic-interior',
        'christmas-interior',
        'bohemian-interior',
        'tropical-interior',
        'industrial-interior',
        'japanese-interior',
        'vintage-interior',
        'loft-interior',
        'halloween-interior',
        'soho-interior',
        'baroque-interior',
        'kids room-interior',
        'girls room-interior',
        'boys room-interior',
        'scandinavian-interior',
        'french country-interior',
        'mediterranean-interior',
        'cyberpunk-interior',
        'hot pink-interior',
        'biophilic-interior',
        'ancient egypt-interior',
        'pixel-interior',
        'art deco-interior',
        'modern-exterior',
        'minimalistic-exterior',
        'farmhouse-exterior',
        'cozy-exterior',
        'luxury-exterior',
        'colonial-exterior',
        'zen-exterior',
        'asian-exterior',
        'creepy-exterior',
        'airstone-exterior',
        'ancient greek-exterior',
        'art deco-exterior',
        'brutalist-exterior',
        'christmas lights-exterior',
        'contemporary-exterior',
        'cottage-exterior',
        'dutch colonial-exterior',
        'federal colonial-exterior',
        'fire-exterior',
        'french provincial-exterior',
        'full glass-exterior',
        'georgian colonial-exterior',
        'gothic-exterior',
        'greek revival-exterior',
        'ice-exterior',
        'italianate-exterior',
        'mediterranean-exterior',
        'midcentury-exterior',
        'middle eastern-exterior',
        'minecraft-exterior',
        'morocco-exterior',
        'neoclassical-exterior',
        'spanish-exterior',
        'tudor-exterior',
        'underwater-exterior',
        'winter-exterior',
        'yard lighting-exterior'
    ]),
    architecture_type: z.enum([
        'living room-interior',
        'bedroom-interior',
        'kitchen-interior',
        'dining room-interior',
        'bathroom-interior',
        'laundry room-interior',
        'home office-interior',
        'study room-interior',
        'dorm room-interior',
        'coffee shop-interior',
        'gaming room-interior',
        'restaurant-interior',
        'office-interior',
        'attic-interior',
        'toilet-interior',
        'other-interior',
        'house-exterior',
        'villa-exterior',
        'backyard-exterior',
        'courtyard-exterior',
        'ranch-exterior',
        'office-exterior',
        'retail-exterior',
        'tower-exterior',
        'apartment-exterior',
        'school-exterior',
        'museum-exterior',
        'commercial-exterior',
        'residential-exterior',
        'other-exterior'
    ]),
    color_palette: z.enum([
        'surprise me',
        'golden beige',
        'refined blues',
        'dusky elegance',
        'emerald charm',
        'crimson luxury',
        'golden sapphire',
        'soft pastures',
        'candy sky',
        'peach meadow',
        'muted sands',
        'ocean breeze',
        'frosted pastels',
        'spring bloom',
        'gentle horizon',
        'seaside breeze',
        'azure coast',
        'golden shore',
        'mediterranean gem',
        'ocean serenity',
        'serene blush',
        'muted horizon',
        'pastel shores',
        'dusky calm',
        'woodland retreat',
        'meadow glow',
        'forest canopy',
        'riverbank calm',
        'earthy tones',
        'earthy neutrals',
        'arctic mist',
        'aqua drift',
        'blush bloom',
        'coral haze',
        'retro rust',
        'autumn glow',
        'rustic charm',
        'vintage sage',
        'faded plum',
        'electric lime',
        'violet pulse',
        'neon sorbet',
        'aqua glow',
        'fluorescent sunset',
        'lavender bloom',
        'petal fresh',
        'meadow light',
        'sunny pastures',
        'frosted mauve',
        'snowy hearth',
        'icy blues',
        'winter twilight',
        'earthy hues',
        'stone balance',
        'neutral sands',
        'slate shades'
    ]),
    style_image_url: z.optional(z.union([
        z.string().max(512),
        z.unknown()
    ])),
    custom_prompt: z.optional(z.string().max(300)).default(''),
    enhanced_rendering: z.optional(z.union([
        z.boolean(),
        z.unknown()
    ]))
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zHalfMoonAiAiHomeStyleImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * ArchStyleOutput
 */
export const zAiHomeStyleOutput = z.object({
    image: zHalfMoonAiAiHomeStyleImage,
    status: z.string()
});

/**
 * ArchEditInput
 */
export const zAiHomeEditInput = z.object({
    input_image_url: z.string().max(512),
    editing_type: z.enum([
        'structural editing',
        'virtual staging',
        'both'
    ]),
    style: z.enum([
        'minimalistic-interior',
        'farmhouse-interior',
        'luxury-interior',
        'modern-interior',
        'zen-interior',
        'mid century-interior',
        'airbnb-interior',
        'cozy-interior',
        'rustic-interior',
        'christmas-interior',
        'bohemian-interior',
        'tropical-interior',
        'industrial-interior',
        'japanese-interior',
        'vintage-interior',
        'loft-interior',
        'halloween-interior',
        'soho-interior',
        'baroque-interior',
        'kids room-interior',
        'girls room-interior',
        'boys room-interior',
        'scandinavian-interior',
        'french country-interior',
        'mediterranean-interior',
        'cyberpunk-interior',
        'hot pink-interior',
        'biophilic-interior',
        'ancient egypt-interior',
        'pixel-interior',
        'art deco-interior',
        'modern-exterior',
        'minimalistic-exterior',
        'farmhouse-exterior',
        'cozy-exterior',
        'luxury-exterior',
        'colonial-exterior',
        'zen-exterior',
        'asian-exterior',
        'creepy-exterior',
        'airstone-exterior',
        'ancient greek-exterior',
        'art deco-exterior',
        'brutalist-exterior',
        'christmas lights-exterior',
        'contemporary-exterior',
        'cottage-exterior',
        'dutch colonial-exterior',
        'federal colonial-exterior',
        'fire-exterior',
        'french provincial-exterior',
        'full glass-exterior',
        'georgian colonial-exterior',
        'gothic-exterior',
        'greek revival-exterior',
        'ice-exterior',
        'italianate-exterior',
        'mediterranean-exterior',
        'midcentury-exterior',
        'middle eastern-exterior',
        'minecraft-exterior',
        'morocco-exterior',
        'neoclassical-exterior',
        'spanish-exterior',
        'tudor-exterior',
        'underwater-exterior',
        'winter-exterior',
        'yard lighting-exterior'
    ]),
    additional_elements: z.optional(z.union([
        z.string().max(200),
        z.unknown()
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    architecture_type: z.enum([
        'living room-interior',
        'bedroom-interior',
        'kitchen-interior',
        'dining room-interior',
        'bathroom-interior',
        'laundry room-interior',
        'home office-interior',
        'study room-interior',
        'dorm room-interior',
        'coffee shop-interior',
        'gaming room-interior',
        'restaurant-interior',
        'office-interior',
        'attic-interior',
        'toilet-interior',
        'other-interior',
        'house-exterior',
        'villa-exterior',
        'backyard-exterior',
        'courtyard-exterior',
        'ranch-exterior',
        'office-exterior',
        'retail-exterior',
        'tower-exterior',
        'apartment-exterior',
        'school-exterior',
        'museum-exterior',
        'commercial-exterior',
        'residential-exterior',
        'other-exterior'
    ]),
    color_palette: z.enum([
        'surprise me',
        'golden beige',
        'refined blues',
        'dusky elegance',
        'emerald charm',
        'crimson luxury',
        'golden sapphire',
        'soft pastures',
        'candy sky',
        'peach meadow',
        'muted sands',
        'ocean breeze',
        'frosted pastels',
        'spring bloom',
        'gentle horizon',
        'seaside breeze',
        'azure coast',
        'golden shore',
        'mediterranean gem',
        'ocean serenity',
        'serene blush',
        'muted horizon',
        'pastel shores',
        'dusky calm',
        'woodland retreat',
        'meadow glow',
        'forest canopy',
        'riverbank calm',
        'earthy tones',
        'earthy neutrals',
        'arctic mist',
        'aqua drift',
        'blush bloom',
        'coral haze',
        'retro rust',
        'autumn glow',
        'rustic charm',
        'vintage sage',
        'faded plum',
        'electric lime',
        'violet pulse',
        'neon sorbet',
        'aqua glow',
        'fluorescent sunset',
        'lavender bloom',
        'petal fresh',
        'meadow light',
        'sunny pastures',
        'frosted mauve',
        'snowy hearth',
        'icy blues',
        'winter twilight',
        'earthy hues',
        'stone balance',
        'neutral sands',
        'slate shades'
    ]),
    custom_prompt: z.optional(z.string().max(300)).default('')
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zHalfMoonAiAiHomeEditImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * ArchEditOutput
 */
export const zAiHomeEditOutput = z.object({
    image: zHalfMoonAiAiHomeEditImage,
    status: z.string()
});

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export const zFalAiQwenImageLayeredLoraLoRaInput = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(4)).default(1)
});

/**
 * ImageFile
 */
export const zFalAiQwenImageLayeredLoraImageFile = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * QwenImageLayeredOutput
 */
export const zQwenImageLayeredLoraOutput = z.object({
    prompt: z.optional(z.string()),
    images: z.array(zFalAiQwenImageLayeredLoraImageFile),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zWanV26ImageToImageImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * ImageEditInput
 *
 * Input for Wan 2.6 image editing with reference images (enable_interleave=false)
 */
export const zV26ImageToImageInput = z.object({
    prompt: z.string().min(1),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zWanV26ImageToImageImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    enable_prompt_expansion: z.optional(z.boolean()).default(true),
    seed: z.optional(z.int()),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(''),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * File
 */
export const zWanV26ImageToImageFile = z.object({
    file_size: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    url: z.string(),
    file_data: z.optional(z.string())
});

/**
 * ImageEditOutput
 *
 * Output for Wan 2.6 image editing
 */
export const zV26ImageToImageOutput = z.object({
    images: z.array(zWanV26ImageToImageFile),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2511ImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * EditImageInput
 */
export const zQwenImageEdit2511Input = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEdit2511ImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(1).lte(20)).default(4.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(''),
    seed: z.optional(z.int())
});

/**
 * Image
 */
export const zFalAiQwenImageEdit2511Image = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * ImageToImageOutput
 */
export const zQwenImageEdit2511Output = z.object({
    prompt: z.string(),
    images: z.array(zFalAiQwenImageEdit2511Image),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * TextToImageInput
 */
export const zQwenImageLayeredInput = z.object({
    prompt: z.optional(z.string()),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    num_layers: z.optional(z.int().gte(1).lte(10)).default(4),
    output_format: z.optional(z.enum(['png', 'webp'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28),
    guidance_scale: z.optional(z.number().gte(1).lte(20)).default(5),
    negative_prompt: z.optional(z.string()).default(''),
    seed: z.optional(z.int())
});

/**
 * ImageFile
 */
export const zFalAiQwenImageLayeredImageFile = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * QwenImageLayeredOutput
 */
export const zQwenImageLayeredOutput = z.object({
    prompt: z.optional(z.string()),
    images: z.array(zFalAiQwenImageLayeredImageFile),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export const zFalAiZImageTurboInpaintLoraLoRaInput = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(4)).default(1)
});

/**
 * ImageFile
 */
export const zFalAiZImageTurboInpaintLoraImageFile = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ZImageTurboInpaintOutput
 */
export const zZImageTurboInpaintLoraOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiZImageTurboInpaintLoraImageFile),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiZImageTurboInpaintImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * ZImageTurboInpaintInput
 */
export const zZImageTurboInpaintInput = z.object({
    prompt: z.string(),
    image_size: z.optional(z.union([
        zFalAiZImageTurboInpaintImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9',
            'auto'
        ])
    ])),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    mask_image_url: z.string(),
    control_end: z.optional(z.number().gte(0).lte(1)).default(0.8),
    control_start: z.optional(z.number().gte(0).lte(1)).default(0),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    strength: z.optional(z.number().gte(0).lte(1)).default(1),
    control_scale: z.optional(z.number().gte(0).lte(1)).default(0.75),
    enable_prompt_expansion: z.optional(z.boolean()).default(false),
    num_inference_steps: z.optional(z.int().gte(1).lte(8)).default(8),
    seed: z.optional(z.int())
});

/**
 * ImageFile
 */
export const zFalAiZImageTurboInpaintImageFile = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ZImageTurboInpaintOutput
 */
export const zZImageTurboInpaintOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiZImageTurboInpaintImageFile),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiFlux2FlashEditImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * Flux2FlashEditImageInput
 */
export const zFlux2FlashEditInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiFlux2FlashEditImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(2.5),
    seed: z.optional(z.int()),
    image_urls: z.array(z.string()),
    enable_prompt_expansion: z.optional(z.boolean()).default(false),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * ImageFile
 */
export const zFalAiFlux2FlashEditImageFile = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * Flux2FlashEditImageOutput
 */
export const zFlux2FlashEditOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFlux2FlashEditImageFile),
    seed: z.int(),
    has_nsfw_concepts: z.array(z.boolean()),
    timings: z.record(z.string(), z.number())
});

/**
 * EditImageRequest
 */
export const zGptImage15EditInput = z.object({
    input_fidelity: z.optional(z.enum(['low', 'high'])),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.enum([
        'auto',
        '1024x1024',
        '1536x1024',
        '1024x1536'
    ])),
    prompt: z.string().min(2),
    quality: z.optional(z.enum([
        'low',
        'medium',
        'high'
    ])),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    background: z.optional(z.enum([
        'auto',
        'transparent',
        'opaque'
    ])),
    mask_image_url: z.optional(z.string()),
    sync_mode: z.optional(z.boolean()).default(false),
    image_urls: z.array(z.string())
});

/**
 * ImageFile
 */
export const zFalAiGptImage15EditImageFile = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * EditImageResponse
 */
export const zGptImage15EditOutput = z.object({
    images: z.array(zFalAiGptImage15EditImageFile)
});

/**
 * ImageSize
 */
export const zFalAiFlux2TurboEditImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * Flux2TurboEditImageInput
 */
export const zFlux2TurboEditInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiFlux2TurboEditImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(2.5),
    seed: z.optional(z.int()),
    image_urls: z.array(z.string()),
    enable_prompt_expansion: z.optional(z.boolean()).default(false),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * ImageFile
 */
export const zFalAiFlux2TurboEditImageFile = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * Flux2TurboEditImageOutput
 */
export const zFlux2TurboEditOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFlux2TurboEditImageFile),
    seed: z.int(),
    has_nsfw_concepts: z.array(z.boolean()),
    timings: z.record(z.string(), z.number())
});

/**
 * ImageSize
 */
export const zFalAiFlux2MaxEditImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * Flux2MaxImageEditInput
 */
export const zFlux2MaxEditInput = z.object({
    prompt: z.string(),
    image_size: z.optional(z.union([
        zFalAiFlux2MaxEditImageSize,
        z.enum([
            'auto',
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5'
    ])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    seed: z.optional(z.int()),
    image_urls: z.array(z.string())
});

/**
 * ImageFile
 */
export const zFalAiFlux2MaxEditImageFile = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * Flux2MaxEditOutput
 */
export const zFlux2MaxEditOutput = z.object({
    images: z.array(zFalAiFlux2MaxEditImageFile),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zHalfMoonAiAiBabyAndAgingGeneratorMultiImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * MultiFluxIDInput
 *
 * Input schema for multi mode generation
 */
export const zAiBabyAndAgingGeneratorMultiInput = z.object({
    prompt: z.optional(z.string()).default('a newborn baby, well dressed'),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zHalfMoonAiAiBabyAndAgingGeneratorMultiImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    father_weight: z.optional(z.number().gte(0).lte(1)).default(0.5),
    mother_image_urls: z.array(z.string()).min(1),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    age_group: z.enum([
        'baby',
        'toddler',
        'preschool',
        'gradeschooler',
        'teen',
        'adult',
        'mid',
        'senior'
    ]),
    gender: z.enum(['male', 'female']),
    father_image_urls: z.array(z.string()).min(1),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zHalfMoonAiAiBabyAndAgingGeneratorMultiImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * FluxMultiIDOutput
 */
export const zAiBabyAndAgingGeneratorMultiOutput = z.object({
    prompt: z.string(),
    images: z.array(zHalfMoonAiAiBabyAndAgingGeneratorMultiImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zHalfMoonAiAiBabyAndAgingGeneratorSingleImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * SingleFluxIDInput
 *
 * Input schema for single mode generation
 */
export const zAiBabyAndAgingGeneratorSingleInput = z.object({
    prompt: z.optional(z.string()).default('a newborn baby, well dressed'),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zHalfMoonAiAiBabyAndAgingGeneratorSingleImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    id_image_urls: z.array(z.string()).min(1),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    age_group: z.enum([
        'baby',
        'toddler',
        'preschool',
        'gradeschooler',
        'teen',
        'adult',
        'mid',
        'senior'
    ]),
    gender: z.enum(['male', 'female']),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zHalfMoonAiAiBabyAndAgingGeneratorSingleImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * FluxSingleIDOutput
 */
export const zAiBabyAndAgingGeneratorSingleOutput = z.object({
    prompt: z.string(),
    images: z.array(zHalfMoonAiAiBabyAndAgingGeneratorSingleImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2509LoraGalleryShirtDesignImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * ShirtDesignInput
 *
 * Input model for Shirt Design endpoint - Put designs/graphics on people's shirts
 */
export const zQwenImageEdit2509LoraGalleryShirtDesignInput = z.object({
    prompt: z.optional(z.string()).default('Put this design on their shirt'),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEdit2509LoraGalleryShirtDesignImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    lora_scale: z.optional(z.number().gte(0).lte(4)).default(1),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(1),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(' '),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(6)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEdit2509LoraGalleryShirtDesignImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * ShirtDesignOutput
 */
export const zQwenImageEdit2509LoraGalleryShirtDesignOutput = z.object({
    images: z.array(zFalAiQwenImageEdit2509LoraGalleryShirtDesignImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2509LoraGalleryRemoveLightingImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * RemoveLightingInput
 *
 * Input model for Remove Lighting endpoint - Remove existing lighting and apply soft even lighting
 */
export const zQwenImageEdit2509LoraGalleryRemoveLightingInput = z.object({
    enable_safety_checker: z.optional(z.boolean()).default(true),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEdit2509LoraGalleryRemoveLightingImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(1),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(' '),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(6)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEdit2509LoraGalleryRemoveLightingImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * RemoveLightingOutput
 */
export const zQwenImageEdit2509LoraGalleryRemoveLightingOutput = z.object({
    images: z.array(zFalAiQwenImageEdit2509LoraGalleryRemoveLightingImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2509LoraGalleryRemoveElementImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * RemoveElementInput
 *
 * Input model for Remove Element endpoint - Remove/delete elements (objects, people, text) from the image
 */
export const zQwenImageEdit2509LoraGalleryRemoveElementInput = z.object({
    prompt: z.optional(z.string()).default('Remove the specified element from the scene'),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEdit2509LoraGalleryRemoveElementImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    lora_scale: z.optional(z.number().gte(0).lte(4)).default(1),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(1),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(' '),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(6)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEdit2509LoraGalleryRemoveElementImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * RemoveElementOutput
 */
export const zQwenImageEdit2509LoraGalleryRemoveElementOutput = z.object({
    images: z.array(zFalAiQwenImageEdit2509LoraGalleryRemoveElementImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2509LoraGalleryLightingRestorationImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * LightingRestorationInput
 *
 * Input model for Lighting Restoration endpoint - Restore natural lighting by removing harsh shadows and light spots
 */
export const zQwenImageEdit2509LoraGalleryLightingRestorationInput = z.object({
    enable_safety_checker: z.optional(z.boolean()).default(true),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEdit2509LoraGalleryLightingRestorationImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(1),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(' '),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(6)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEdit2509LoraGalleryLightingRestorationImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * LightingRestorationOutput
 */
export const zQwenImageEdit2509LoraGalleryLightingRestorationOutput = z.object({
    images: z.array(zFalAiQwenImageEdit2509LoraGalleryLightingRestorationImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2509LoraGalleryIntegrateProductImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * IntegrateProductInput
 *
 * Input model for Integrate Product endpoint - Blend and integrate products/elements into backgrounds
 */
export const zQwenImageEdit2509LoraGalleryIntegrateProductInput = z.object({
    prompt: z.optional(z.string()).default('Blend and integrate the product into the background'),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEdit2509LoraGalleryIntegrateProductImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    lora_scale: z.optional(z.number().gte(0).lte(4)).default(1),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(1),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(' '),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(6)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEdit2509LoraGalleryIntegrateProductImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * IntegrateProductOutput
 */
export const zQwenImageEdit2509LoraGalleryIntegrateProductOutput = z.object({
    images: z.array(zFalAiQwenImageEdit2509LoraGalleryIntegrateProductImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2509LoraGalleryGroupPhotoImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * GroupPhotoInput
 *
 * Input model for Group Photo endpoint - Create composite group photos with vintage/retro style
 */
export const zQwenImageEdit2509LoraGalleryGroupPhotoInput = z.object({
    prompt: z.optional(z.string()).default('Two people standing next to each other outside with a landscape background'),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEdit2509LoraGalleryGroupPhotoImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    lora_scale: z.optional(z.number().gte(0).lte(4)).default(1),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(1),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(' '),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(6)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEdit2509LoraGalleryGroupPhotoImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * GroupPhotoOutput
 */
export const zQwenImageEdit2509LoraGalleryGroupPhotoOutput = z.object({
    images: z.array(zFalAiQwenImageEdit2509LoraGalleryGroupPhotoImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * FaceToFullPortraitInput
 *
 * Input model for Face to Full Portrait endpoint - Generate full portrait from a cropped face image
 */
export const zQwenImageEdit2509LoraGalleryFaceToFullPortraitInput = z.object({
    prompt: z.optional(z.string()).default('Photography. A portrait of the person in professional attire with natural lighting'),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    lora_scale: z.optional(z.number().gte(0).lte(4)).default(1),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(1),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(' '),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(6)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * FaceToFullPortraitOutput
 */
export const zQwenImageEdit2509LoraGalleryFaceToFullPortraitOutput = z.object({
    images: z.array(zFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2509LoraGalleryAddBackgroundImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * AddBackgroundInput
 *
 * Input model for Add Background endpoint - Remove white background and add a realistic scene
 */
export const zQwenImageEdit2509LoraGalleryAddBackgroundInput = z.object({
    prompt: z.optional(z.string()).default('Remove white background and add a realistic scene behind the object'),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEdit2509LoraGalleryAddBackgroundImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    lora_scale: z.optional(z.number().gte(0).lte(4)).default(1),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(1),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(' '),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(6)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEdit2509LoraGalleryAddBackgroundImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * AddBackgroundOutput
 */
export const zQwenImageEdit2509LoraGalleryAddBackgroundOutput = z.object({
    images: z.array(zFalAiQwenImageEdit2509LoraGalleryAddBackgroundImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2509LoraGalleryNextSceneImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * NextSceneInput
 *
 * Input model for Next Scene endpoint - Create cinematic shot progressions and scene transitions
 */
export const zQwenImageEdit2509LoraGalleryNextSceneInput = z.object({
    prompt: z.optional(z.string()).default('Next Scene: The camera moves forward revealing more of the scene'),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEdit2509LoraGalleryNextSceneImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    lora_scale: z.optional(z.number().gte(0).lte(4)).default(1),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(1),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(' '),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(6)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEdit2509LoraGalleryNextSceneImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * NextSceneOutput
 */
export const zQwenImageEdit2509LoraGalleryNextSceneOutput = z.object({
    images: z.array(zFalAiQwenImageEdit2509LoraGalleryNextSceneImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2509LoraGalleryMultipleAnglesImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * MultipleAnglesInput
 *
 * Input model for Multiple Angles endpoint - Camera control with precise adjustments
 */
export const zQwenImageEdit2509LoraGalleryMultipleAnglesInput = z.object({
    image_size: z.optional(z.union([
        zFalAiQwenImageEdit2509LoraGalleryMultipleAnglesImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    wide_angle_lens: z.optional(z.boolean()).default(false),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(1),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(' '),
    vertical_angle: z.optional(z.number().gte(-1).lte(1)).default(0),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    move_forward: z.optional(z.number().gte(0).lte(10)).default(0),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    rotate_right_left: z.optional(z.number().gte(-90).lte(90)).default(0),
    lora_scale: z.optional(z.number().gte(0).lte(4)).default(1.25),
    sync_mode: z.optional(z.boolean()).default(false),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(6)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEdit2509LoraGalleryMultipleAnglesImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * MultipleAnglesOutput
 */
export const zQwenImageEdit2509LoraGalleryMultipleAnglesOutput = z.object({
    images: z.array(zFalAiQwenImageEdit2509LoraGalleryMultipleAnglesImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2509LoraImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * LoraWeight
 */
export const zFalAiQwenImageEdit2509LoraLoraWeight = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(4)).default(1)
});

/**
 * BaseQwenEditImagePlusLoRAInput
 */
export const zQwenImageEdit2509LoraInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEdit2509LoraImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    loras: z.optional(z.array(zFalAiQwenImageEdit2509LoraLoraWeight)).default([]),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(4),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(28),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(' '),
    seed: z.optional(z.int())
});

/**
 * Image
 */
export const zFalAiQwenImageEdit2509LoraImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * QwenImageOutput
 */
export const zQwenImageEdit2509LoraOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiQwenImageEdit2509LoraImage),
    seed: z.int(),
    has_nsfw_concepts: z.array(z.boolean()),
    timings: z.record(z.string(), z.number())
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEdit2509ImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * BaseQwenEditImagePlusInput
 */
export const zQwenImageEdit2509Input = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEdit2509ImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(4),
    seed: z.optional(z.int()),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(' '),
    num_inference_steps: z.optional(z.int().gte(2).lte(100)).default(50)
});

/**
 * Image
 */
export const zFalAiQwenImageEdit2509Image = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * QwenImageOutput
 */
export const zQwenImageEdit2509Output = z.object({
    prompt: z.string(),
    images: z.array(zFalAiQwenImageEdit2509Image),
    seed: z.int(),
    has_nsfw_concepts: z.array(z.boolean()),
    timings: z.record(z.string(), z.number())
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEditPlusLoraGalleryLightingRestorationImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * LightingRestorationInput
 *
 * Input model for Lighting Restoration endpoint - Restore natural lighting by removing harsh shadows and light spots
 */
export const zQwenImageEditPlusLoraGalleryLightingRestorationInput = z.object({
    enable_safety_checker: z.optional(z.boolean()).default(true),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEditPlusLoraGalleryLightingRestorationImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(1),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(' '),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(6)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEditPlusLoraGalleryLightingRestorationImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * LightingRestorationOutput
 */
export const zQwenImageEditPlusLoraGalleryLightingRestorationOutput = z.object({
    images: z.array(zFalAiQwenImageEditPlusLoraGalleryLightingRestorationImage),
    seed: z.int()
});

/**
 * SegmentSamplingSettings
 */
export const zSegmentSamplingSettings = z.object({
    top_p: z.optional(z.number().gte(0).lte(1)).default(1),
    max_tokens: z.optional(z.int().gte(1)),
    temperature: z.optional(z.number().gte(0).lte(1)).default(1)
});

/**
 * ImageFile
 */
export const zFalAiMoondream3PreviewSegmentImageFile = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * Object
 */
export const zObject = z.object({
    y_min: z.number(),
    x_max: z.number(),
    x_min: z.number(),
    y_max: z.number()
});

/**
 * UsageInfo
 */
export const zUsageInfo = z.object({
    output_tokens: z.int(),
    decode_time_ms: z.number(),
    input_tokens: z.int(),
    ttft_ms: z.number(),
    prefill_time_ms: z.number()
});

/**
 * MoondreamSegementationOutput
 */
export const zMoondream3PreviewSegmentOutput = z.object({
    finish_reason: z.string(),
    image: z.optional(zFalAiMoondream3PreviewSegmentImageFile),
    bbox: z.optional(zObject),
    path: z.optional(z.string()),
    usage_info: zUsageInfo
});

/**
 * Placeholder for missing schema Point (referenced but not defined in source OpenAPI spec)
 */
export const zPoint = z.record(z.string(), z.unknown());

/**
 * MoondreamSegementationInput
 */
export const zMoondream3PreviewSegmentInput = z.object({
    spatial_references: z.optional(z.array(z.union([zPoint, z.array(z.number())]))),
    settings: z.optional(zSegmentSamplingSettings),
    object: z.string(),
    preview: z.optional(z.boolean()).default(false),
    image_url: z.string()
});

/**
 * ImageToImageInput
 */
export const zStepxEdit2Input = z.object({
    prompt: z.string(),
    seed: z.optional(z.int()),
    enable_reflection_mode: z.optional(z.boolean()).default(true),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(6),
    num_inference_steps: z.optional(z.int().gte(1).lte(100)).default(50),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    negative_prompt: z.optional(z.string()).default(''),
    enable_thinking_mode: z.optional(z.boolean()).default(true)
});

/**
 * Image
 */
export const zFalAiStepxEdit2Image = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * ImageOutput
 */
export const zStepxEdit2Output = z.object({
    prompt: z.string(),
    has_nsfw_concepts: z.array(z.boolean()),
    best_info: z.optional(z.array(z.record(z.string(), z.unknown()))),
    images: z.array(zFalAiStepxEdit2Image),
    timings: z.record(z.string(), z.number()),
    reformat_prompt: z.optional(z.string()),
    think_info: z.optional(z.array(z.string())),
    seed: z.int()
});

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export const zFalAiZImageTurboControlnetLoraLoRaInput = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(4)).default(1)
});

/**
 * ImageFile
 */
export const zFalAiZImageTurboControlnetLoraImageFile = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ZImageTurboControlNetOutput
 */
export const zZImageTurboControlnetLoraOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiZImageTurboControlnetLoraImageFile),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiZImageTurboControlnetImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * ZImageTurboControlNetInput
 */
export const zZImageTurboControlnetInput = z.object({
    prompt: z.string(),
    image_size: z.optional(z.union([
        zFalAiZImageTurboControlnetImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9',
            'auto'
        ])
    ])),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    control_end: z.optional(z.number().gte(0).lte(1)).default(0.8),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    control_start: z.optional(z.number().gte(0).lte(1)).default(0),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    control_scale: z.optional(z.number().gte(0).lte(1)).default(0.75),
    enable_prompt_expansion: z.optional(z.boolean()).default(false),
    num_inference_steps: z.optional(z.int().gte(1).lte(8)).default(8),
    seed: z.optional(z.int()),
    preprocess: z.optional(z.enum([
        'none',
        'canny',
        'depth',
        'pose'
    ]))
});

/**
 * ImageFile
 */
export const zFalAiZImageTurboControlnetImageFile = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ZImageTurboControlNetOutput
 */
export const zZImageTurboControlnetOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiZImageTurboControlnetImageFile),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export const zFalAiZImageTurboImageToImageLoraLoRaInput = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(4)).default(1)
});

/**
 * ImageFile
 */
export const zFalAiZImageTurboImageToImageLoraImageFile = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ZImageTurboImageToImageOutput
 */
export const zZImageTurboImageToImageLoraOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiZImageTurboImageToImageLoraImageFile),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiZImageTurboImageToImageImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * ZImageTurboImageToImageInput
 */
export const zZImageTurboImageToImageInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    image_size: z.optional(z.union([
        zFalAiZImageTurboImageToImageImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9',
            'auto'
        ])
    ])),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    strength: z.optional(z.number().gte(0).lte(1)).default(0.6),
    enable_prompt_expansion: z.optional(z.boolean()).default(false),
    num_inference_steps: z.optional(z.int().gte(1).lte(8)).default(8),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    seed: z.optional(z.int())
});

/**
 * ImageFile
 */
export const zFalAiZImageTurboImageToImageImageFile = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ZImageTurboImageToImageOutput
 */
export const zZImageTurboImageToImageOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiZImageTurboImageToImageImageFile),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * EditImageInput
 */
export const zLongcatImageEditInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28),
    guidance_scale: z.optional(z.number().gte(1).lte(20)).default(4.5),
    seed: z.optional(z.int())
});

/**
 * Image
 */
export const zFalAiLongcatImageEditImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * ImageToImageOutput
 */
export const zLongcatImageEditOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiLongcatImageEditImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiBytedanceSeedreamV45EditImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * SeedDream45EditInput
 */
export const zBytedanceSeedreamV45EditInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(6)).default(1),
    image_size: z.optional(z.union([
        zFalAiBytedanceSeedreamV45EditImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9',
            'auto_2K',
            'auto_4K'
        ])
    ])),
    max_images: z.optional(z.int().gte(1).lte(6)).default(1),
    sync_mode: z.optional(z.boolean()).default(false),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    seed: z.optional(z.int()),
    image_urls: z.array(z.string())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBytedanceSeedreamV45EditImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * SeedDream45EditOutput
 */
export const zBytedanceSeedreamV45EditOutput = z.object({
    images: z.array(zFalAiBytedanceSeedreamV45EditImage)
});

/**
 * ReferenceToImageRequest
 */
export const zViduQ2ReferenceToImageInput = z.object({
    prompt: z.string().max(1500),
    aspect_ratio: z.optional(z.enum([
        '16:9',
        '9:16',
        '1:1'
    ])),
    reference_image_urls: z.array(z.string()),
    seed: z.optional(z.int())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiViduQ2ReferenceToImageImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ReferenceToImageOutput
 */
export const zViduQ2ReferenceToImageOutput = z.object({
    image: zFalAiViduQ2ReferenceToImageImage
});

/**
 * OmniImageElementInput
 */
export const zOmniImageElementInput = z.object({
    reference_image_urls: z.optional(z.array(z.string())),
    frontal_image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiKlingImageO1Image = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * OmniImageOutput
 */
export const zKlingImageO1Output = z.object({
    images: z.array(zFalAiKlingImageO1Image)
});

/**
 * ImageSize
 */
export const zFalAiFlux2LoraGalleryVirtualTryonImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * VirtualTryonInput
 *
 * Input model for Virtual Try-on endpoint - Generate virtual try-on images
 */
export const zFlux2LoraGalleryVirtualTryonInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiFlux2LoraGalleryVirtualTryonImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    lora_scale: z.optional(z.number().gte(0).lte(2)).default(1),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(2.5),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    image_urls: z.array(z.string()),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(40)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlux2LoraGalleryVirtualTryonImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * VirtualTryonOutput
 */
export const zFlux2LoraGalleryVirtualTryonOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFlux2LoraGalleryVirtualTryonImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiFlux2LoraGalleryMultipleAnglesImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * MultipleAnglesInput
 *
 * Input model for Multiple Angles endpoint - Camera control with precise adjustments using <sks> trigger word. Prompt is built automatically from slider values.
 */
export const zFlux2LoraGalleryMultipleAnglesInput = z.object({
    image_size: z.optional(z.union([
        zFalAiFlux2LoraGalleryMultipleAnglesImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    horizontal_angle: z.optional(z.number().gte(0).lte(360)).default(0),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(2.5),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    image_urls: z.array(z.string()),
    zoom: z.optional(z.number().gte(0).lte(10)).default(5),
    vertical_angle: z.optional(z.number().gte(0).lte(60)).default(0),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    lora_scale: z.optional(z.number().gte(0).lte(2)).default(1),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(40),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlux2LoraGalleryMultipleAnglesImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * MultipleAnglesOutput
 */
export const zFlux2LoraGalleryMultipleAnglesOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFlux2LoraGalleryMultipleAnglesImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiFlux2LoraGalleryFaceToFullPortraitImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * FaceToFullPortraitInput
 *
 * Input model for Face to Full Portrait endpoint - Generate full portrait from face
 */
export const zFlux2LoraGalleryFaceToFullPortraitInput = z.object({
    prompt: z.optional(z.string()).default('Face to full portrait'),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiFlux2LoraGalleryFaceToFullPortraitImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    lora_scale: z.optional(z.number().gte(0).lte(2)).default(1),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(2.5),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    image_urls: z.array(z.string()),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(40)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlux2LoraGalleryFaceToFullPortraitImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * FaceToFullPortraitOutput
 */
export const zFlux2LoraGalleryFaceToFullPortraitOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFlux2LoraGalleryFaceToFullPortraitImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiFlux2LoraGalleryApartmentStagingImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * ApartmentStagingInput
 *
 * Input model for Apartment Staging endpoint - Furnish rooms
 */
export const zFlux2LoraGalleryApartmentStagingInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiFlux2LoraGalleryApartmentStagingImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    lora_scale: z.optional(z.number().gte(0).lte(2)).default(1),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(2.5),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    image_urls: z.array(z.string()),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(40)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlux2LoraGalleryApartmentStagingImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * ApartmentStagingOutput
 */
export const zFlux2LoraGalleryApartmentStagingOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFlux2LoraGalleryApartmentStagingImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiFlux2LoraGalleryAddBackgroundImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * AddBackgroundInput
 *
 * Input model for Add Background endpoint - Add background to images
 */
export const zFlux2LoraGalleryAddBackgroundInput = z.object({
    prompt: z.optional(z.string()).default('Add Background forest'),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiFlux2LoraGalleryAddBackgroundImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    lora_scale: z.optional(z.number().gte(0).lte(2)).default(1),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(2.5),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    image_urls: z.array(z.string()),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(40)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlux2LoraGalleryAddBackgroundImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * AddBackgroundOutput
 */
export const zFlux2LoraGalleryAddBackgroundOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFlux2LoraGalleryAddBackgroundImage),
    seed: z.int()
});

/**
 * CrystalUpscaleInput
 */
export const zCrystalUpscalerInput = z.object({
    creativity: z.optional(z.number().gte(0).lte(10)).default(0),
    scale_factor: z.optional(z.number().gte(1).lte(200)).default(2),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zClarityaiCrystalUpscalerImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * CrystalUpscaleOutput
 */
export const zCrystalUpscalerOutput = z.object({
    images: z.array(zClarityaiCrystalUpscalerImage)
});

/**
 * ImageSize
 */
export const zFalAiFlux2FlexEditImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * Flux2FlexImageEditInput
 */
export const zFlux2FlexEditInput = z.object({
    prompt: z.string(),
    guidance_scale: z.optional(z.number().gte(1.5).lte(10)).default(3.5),
    image_size: z.optional(z.union([
        zFalAiFlux2FlexEditImageSize,
        z.enum([
            'auto',
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5'
    ])),
    enable_prompt_expansion: z.optional(z.boolean()).default(true),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(28),
    image_urls: z.array(z.string()),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    seed: z.optional(z.int())
});

/**
 * ImageFile
 */
export const zFalAiFlux2FlexEditImageFile = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * Flux2FlexEditOutput
 */
export const zFlux2FlexEditOutput = z.object({
    images: z.array(zFalAiFlux2FlexEditImageFile),
    seed: z.int()
});

/**
 * ChronoLoraWeight
 */
export const zChronoLoraWeight = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(4)).default(1)
});

/**
 * ChronoEditLoRAInput
 *
 * ChronoEdit input with optional custom LoRAs.
 */
export const zChronoEditLoraInput = z.object({
    prompt: z.string(),
    loras: z.optional(z.array(zChronoLoraWeight)).default([]),
    turbo_mode: z.optional(z.boolean()).default(true),
    enable_temporal_reasoning: z.optional(z.boolean()).default(false),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    guidance_scale: z.optional(z.number().gte(0).lte(10)).default(1),
    resolution: z.optional(z.enum(['480p', '720p'])),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    num_temporal_reasoning_steps: z.optional(z.int().gte(2).lte(12)).default(8),
    sync_mode: z.optional(z.boolean()).default(false),
    image_url: z.string(),
    enable_prompt_expansion: z.optional(z.boolean()).default(true),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(8),
    seed: z.optional(z.int())
});

/**
 * ImageFile
 */
export const zFalAiChronoEditLoraImageFile = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ChronoEditOutput
 *
 * Unified output model for all ChronoEdit operations
 */
export const zChronoEditLoraOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiChronoEditLoraImageFile),
    seed: z.int()
});

/**
 * ChronoLoraWeight
 */
export const zFalAiChronoEditLoraGalleryPaintbrushChronoLoraWeight = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(4)).default(1)
});

/**
 * ChronoEditPaintBrushInput
 *
 * Input for paintbrush mode
 */
export const zChronoEditLoraGalleryPaintbrushInput = z.object({
    prompt: z.string(),
    resolution: z.optional(z.enum(['480p', '720p'])),
    lora_scale: z.optional(z.number().gte(0).lte(2)).default(1),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    turbo_mode: z.optional(z.boolean()).default(true),
    loras: z.optional(z.array(zFalAiChronoEditLoraGalleryPaintbrushChronoLoraWeight)).default([]),
    guidance_scale: z.optional(z.number().gte(0).lte(10)).default(1),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(8),
    mask_url: z.optional(z.string()),
    seed: z.optional(z.int()),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * ImageFile
 */
export const zFalAiChronoEditLoraGalleryPaintbrushImageFile = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ChronoEditOutput
 *
 * Unified output model for all ChronoEdit operations
 */
export const zChronoEditLoraGalleryPaintbrushOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiChronoEditLoraGalleryPaintbrushImageFile),
    seed: z.int()
});

/**
 * ChronoLoraWeight
 */
export const zFalAiChronoEditLoraGalleryUpscalerChronoLoraWeight = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(4)).default(1)
});

/**
 * ChronoEditUpscalerInput
 *
 * Input for upscaler mode
 */
export const zChronoEditLoraGalleryUpscalerInput = z.object({
    lora_scale: z.optional(z.number().gte(0).lte(2)).default(1),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    loras: z.optional(z.array(zFalAiChronoEditLoraGalleryUpscalerChronoLoraWeight)).default([]),
    upscale_factor: z.optional(z.number().gte(1).lte(4)).default(2),
    guidance_scale: z.optional(z.number().gte(0).lte(10)).default(1),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(30),
    seed: z.optional(z.int()),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * ImageFile
 */
export const zFalAiChronoEditLoraGalleryUpscalerImageFile = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ChronoEditOutput
 *
 * Unified output model for all ChronoEdit operations
 */
export const zChronoEditLoraGalleryUpscalerOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiChronoEditLoraGalleryUpscalerImageFile),
    seed: z.int()
});

/**
 * BoxPrompt
 */
export const zBoxPrompt = z.object({
    y_min: z.optional(z.int()),
    object_id: z.optional(z.int()),
    frame_index: z.optional(z.int()),
    x_max: z.optional(z.int()),
    x_min: z.optional(z.int()),
    y_max: z.optional(z.int())
});

/**
 * PointPrompt
 */
export const zPointPrompt = z.object({
    y: z.optional(z.int()),
    x: z.optional(z.int()),
    object_id: z.optional(z.int()),
    frame_index: z.optional(z.int()),
    label: z.optional(z.union([z.literal(0), z.literal(1)]))
});

/**
 * SAM3ImageInput
 */
export const zSam3ImageRleInput = z.object({
    prompt: z.optional(z.string()).default('wheel'),
    include_boxes: z.optional(z.boolean()).default(false),
    box_prompts: z.optional(z.array(zBoxPrompt)).default([]),
    return_multiple_masks: z.optional(z.boolean()).default(false),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    point_prompts: z.optional(z.array(zPointPrompt)).default([]),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    max_masks: z.optional(z.int().gte(1).lte(32)).default(3),
    include_scores: z.optional(z.boolean()).default(false),
    apply_mask: z.optional(z.boolean()).default(true),
    text_prompt: z.optional(z.string())
});

/**
 * MaskMetadata
 */
export const zMaskMetadata = z.object({
    box: z.optional(z.array(z.number())),
    score: z.optional(z.number()),
    index: z.int()
});

/**
 * File
 */
export const zFalAiSam3ImageRleFile = z.object({
    file_size: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    url: z.string(),
    file_data: z.optional(z.string())
});

/**
 * SAM3RLEOutput
 */
export const zSam3ImageRleOutput = z.object({
    rle: z.union([
        z.string(),
        z.array(z.string())
    ]),
    metadata: z.optional(z.array(zMaskMetadata)),
    scores: z.optional(z.array(z.number())),
    boundingbox_frames_zip: z.optional(zFalAiSam3ImageRleFile),
    boxes: z.optional(z.array(z.array(z.number())))
});

/**
 * BoxPrompt
 */
export const zFalAiSam3ImageBoxPrompt = z.object({
    y_min: z.optional(z.int()),
    object_id: z.optional(z.int()),
    frame_index: z.optional(z.int()),
    x_max: z.optional(z.int()),
    x_min: z.optional(z.int()),
    y_max: z.optional(z.int())
});

/**
 * PointPrompt
 */
export const zFalAiSam3ImagePointPrompt = z.object({
    y: z.optional(z.int()),
    x: z.optional(z.int()),
    object_id: z.optional(z.int()),
    frame_index: z.optional(z.int()),
    label: z.optional(z.union([z.literal(0), z.literal(1)]))
});

/**
 * SAM3ImageInput
 */
export const zSam3ImageInput = z.object({
    prompt: z.optional(z.string()).default('wheel'),
    include_boxes: z.optional(z.boolean()).default(false),
    box_prompts: z.optional(z.array(zFalAiSam3ImageBoxPrompt)).default([]),
    return_multiple_masks: z.optional(z.boolean()).default(false),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    point_prompts: z.optional(z.array(zFalAiSam3ImagePointPrompt)).default([]),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    max_masks: z.optional(z.int().gte(1).lte(32)).default(3),
    include_scores: z.optional(z.boolean()).default(false),
    apply_mask: z.optional(z.boolean()).default(true),
    text_prompt: z.optional(z.string())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiSam3ImageImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * MaskMetadata
 */
export const zFalAiSam3ImageMaskMetadata = z.object({
    box: z.optional(z.array(z.number())),
    score: z.optional(z.number()),
    index: z.int()
});

/**
 * SAM3ImageOutput
 */
export const zSam3ImageOutput = z.object({
    image: z.optional(zFalAiSam3ImageImage),
    metadata: z.optional(z.array(zFalAiSam3ImageMaskMetadata)),
    masks: z.array(zFalAiSam3ImageImage),
    scores: z.optional(z.array(z.number())),
    boxes: z.optional(z.array(z.array(z.number())))
});

/**
 * NanoBananaImageToImageInput
 */
export const zGemini3ProImagePreviewEditInput = z.object({
    prompt: z.string().min(3).max(50000),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    enable_web_search: z.optional(z.boolean()).default(false),
    resolution: z.optional(z.enum([
        '1K',
        '2K',
        '4K'
    ])),
    aspect_ratio: z.optional(z.enum([
        'auto',
        '21:9',
        '16:9',
        '3:2',
        '4:3',
        '5:4',
        '1:1',
        '4:5',
        '3:4',
        '2:3',
        '9:16'
    ])),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    seed: z.optional(z.int()),
    image_urls: z.array(z.string()),
    limit_generations: z.optional(z.boolean()).default(false)
});

/**
 * ImageFile
 */
export const zFalAiGemini3ProImagePreviewEditImageFile = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * NanoBananaImageToImageOutput
 */
export const zGemini3ProImagePreviewEditOutput = z.object({
    images: z.array(zFalAiGemini3ProImagePreviewEditImageFile),
    description: z.string()
});

/**
 * NanoBananaImageToImageInput
 */
export const zNanoBananaProEditInput = z.object({
    prompt: z.string().min(3).max(50000),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    enable_web_search: z.optional(z.boolean()).default(false),
    aspect_ratio: z.optional(z.enum([
        'auto',
        '21:9',
        '16:9',
        '3:2',
        '4:3',
        '5:4',
        '1:1',
        '4:5',
        '3:4',
        '2:3',
        '9:16'
    ])),
    resolution: z.optional(z.enum([
        '1K',
        '2K',
        '4K'
    ])),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    seed: z.optional(z.int()),
    image_urls: z.array(z.string()),
    limit_generations: z.optional(z.boolean()).default(false)
});

/**
 * ImageFile
 */
export const zFalAiNanoBananaProEditImageFile = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * NanoBananaImageToImageOutput
 */
export const zNanoBananaProEditOutput = z.object({
    images: z.array(zFalAiNanoBananaProEditImageFile),
    description: z.string()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEditPlusLoraGalleryMultipleAnglesImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * MultipleAnglesInput
 *
 * Input model for Multiple Angles endpoint - Camera control with precise adjustments
 */
export const zQwenImageEditPlusLoraGalleryMultipleAnglesInput = z.object({
    image_size: z.optional(z.union([
        zFalAiQwenImageEditPlusLoraGalleryMultipleAnglesImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    wide_angle_lens: z.optional(z.boolean()).default(false),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(1),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(' '),
    vertical_angle: z.optional(z.number().gte(-1).lte(1)).default(0),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    move_forward: z.optional(z.number().gte(0).lte(10)).default(0),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    rotate_right_left: z.optional(z.number().gte(-90).lte(90)).default(0),
    lora_scale: z.optional(z.number().gte(0).lte(4)).default(1.25),
    sync_mode: z.optional(z.boolean()).default(false),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(6)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEditPlusLoraGalleryMultipleAnglesImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * MultipleAnglesOutput
 */
export const zQwenImageEditPlusLoraGalleryMultipleAnglesOutput = z.object({
    images: z.array(zFalAiQwenImageEditPlusLoraGalleryMultipleAnglesImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEditPlusLoraGalleryShirtDesignImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * ShirtDesignInput
 *
 * Input model for Shirt Design endpoint - Put designs/graphics on people's shirts
 */
export const zQwenImageEditPlusLoraGalleryShirtDesignInput = z.object({
    prompt: z.optional(z.string()).default('Put this design on their shirt'),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEditPlusLoraGalleryShirtDesignImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    lora_scale: z.optional(z.number().gte(0).lte(4)).default(1),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(1),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(' '),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(6)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEditPlusLoraGalleryShirtDesignImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * ShirtDesignOutput
 */
export const zQwenImageEditPlusLoraGalleryShirtDesignOutput = z.object({
    images: z.array(zFalAiQwenImageEditPlusLoraGalleryShirtDesignImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEditPlusLoraGalleryRemoveLightingImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * RemoveLightingInput
 *
 * Input model for Remove Lighting endpoint - Remove existing lighting and apply soft even lighting
 */
export const zQwenImageEditPlusLoraGalleryRemoveLightingInput = z.object({
    enable_safety_checker: z.optional(z.boolean()).default(true),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEditPlusLoraGalleryRemoveLightingImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(1),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(' '),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(6)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEditPlusLoraGalleryRemoveLightingImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * RemoveLightingOutput
 */
export const zQwenImageEditPlusLoraGalleryRemoveLightingOutput = z.object({
    images: z.array(zFalAiQwenImageEditPlusLoraGalleryRemoveLightingImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEditPlusLoraGalleryRemoveElementImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * RemoveElementInput
 *
 * Input model for Remove Element endpoint - Remove/delete elements (objects, people, text) from the image
 */
export const zQwenImageEditPlusLoraGalleryRemoveElementInput = z.object({
    prompt: z.optional(z.string()).default('Remove the specified element from the scene'),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEditPlusLoraGalleryRemoveElementImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    lora_scale: z.optional(z.number().gte(0).lte(4)).default(1),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(1),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(' '),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(6)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEditPlusLoraGalleryRemoveElementImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * RemoveElementOutput
 */
export const zQwenImageEditPlusLoraGalleryRemoveElementOutput = z.object({
    images: z.array(zFalAiQwenImageEditPlusLoraGalleryRemoveElementImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEditPlusLoraGalleryNextSceneImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * NextSceneInput
 *
 * Input model for Next Scene endpoint - Create cinematic shot progressions and scene transitions
 */
export const zQwenImageEditPlusLoraGalleryNextSceneInput = z.object({
    prompt: z.optional(z.string()).default('Next Scene: The camera moves forward revealing more of the scene'),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEditPlusLoraGalleryNextSceneImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    lora_scale: z.optional(z.number().gte(0).lte(4)).default(1),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(1),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(' '),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(6)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEditPlusLoraGalleryNextSceneImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * NextSceneOutput
 */
export const zQwenImageEditPlusLoraGalleryNextSceneOutput = z.object({
    images: z.array(zFalAiQwenImageEditPlusLoraGalleryNextSceneImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEditPlusLoraGalleryIntegrateProductImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * IntegrateProductInput
 *
 * Input model for Integrate Product endpoint - Blend and integrate products/elements into backgrounds
 */
export const zQwenImageEditPlusLoraGalleryIntegrateProductInput = z.object({
    prompt: z.optional(z.string()).default('Blend and integrate the product into the background'),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEditPlusLoraGalleryIntegrateProductImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    lora_scale: z.optional(z.number().gte(0).lte(4)).default(1),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(1),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(' '),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(6)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEditPlusLoraGalleryIntegrateProductImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * IntegrateProductOutput
 */
export const zQwenImageEditPlusLoraGalleryIntegrateProductOutput = z.object({
    images: z.array(zFalAiQwenImageEditPlusLoraGalleryIntegrateProductImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEditPlusLoraGalleryGroupPhotoImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * GroupPhotoInput
 *
 * Input model for Group Photo endpoint - Create composite group photos with vintage/retro style
 */
export const zQwenImageEditPlusLoraGalleryGroupPhotoInput = z.object({
    prompt: z.optional(z.string()).default('Two people standing next to each other outside with a landscape background'),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEditPlusLoraGalleryGroupPhotoImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    lora_scale: z.optional(z.number().gte(0).lte(4)).default(1),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(1),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(' '),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(6)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEditPlusLoraGalleryGroupPhotoImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * GroupPhotoOutput
 */
export const zQwenImageEditPlusLoraGalleryGroupPhotoOutput = z.object({
    images: z.array(zFalAiQwenImageEditPlusLoraGalleryGroupPhotoImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * FaceToFullPortraitInput
 *
 * Input model for Face to Full Portrait endpoint - Generate full portrait from a cropped face image
 */
export const zQwenImageEditPlusLoraGalleryFaceToFullPortraitInput = z.object({
    prompt: z.optional(z.string()).default('Photography. A portrait of the person in professional attire with natural lighting'),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    lora_scale: z.optional(z.number().gte(0).lte(4)).default(1),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(1),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(' '),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(6)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * FaceToFullPortraitOutput
 */
export const zQwenImageEditPlusLoraGalleryFaceToFullPortraitOutput = z.object({
    images: z.array(zFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEditPlusLoraGalleryAddBackgroundImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * AddBackgroundInput
 *
 * Input model for Add Background endpoint - Remove white background and add a realistic scene
 */
export const zQwenImageEditPlusLoraGalleryAddBackgroundInput = z.object({
    prompt: z.optional(z.string()).default('Remove white background and add a realistic scene behind the object'),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEditPlusLoraGalleryAddBackgroundImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    lora_scale: z.optional(z.number().gte(0).lte(4)).default(1),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(1),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(' '),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(6)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiQwenImageEditPlusLoraGalleryAddBackgroundImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * AddBackgroundOutput
 */
export const zQwenImageEditPlusLoraGalleryAddBackgroundOutput = z.object({
    images: z.array(zFalAiQwenImageEditPlusLoraGalleryAddBackgroundImage),
    seed: z.int()
});

/**
 * ReveRemixInput
 *
 * Input for Reve image remixing
 */
export const zReveFastRemixInput = z.object({
    prompt: z.string().min(1).max(2560),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    aspect_ratio: z.optional(z.enum([
        '16:9',
        '9:16',
        '3:2',
        '2:3',
        '4:3',
        '3:4',
        '1:1'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    image_urls: z.array(z.string()),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ]))
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiReveFastRemixImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ReveRemixOutput
 *
 * Output for Reve image remixing
 */
export const zReveFastRemixOutput = z.object({
    images: z.array(zFalAiReveFastRemixImage)
});

/**
 * ReveFastEditInput
 *
 * Input for Reve fast image editing
 */
export const zReveFastEditInput = z.object({
    prompt: z.string().min(1).max(2560),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    sync_mode: z.optional(z.boolean()).default(false),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiReveFastEditImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ReveFastEditOutput
 *
 * Output for Reve fast image editing
 */
export const zReveFastEditOutput = z.object({
    images: z.array(zFalAiReveFastEditImage)
});

/**
 * OutpaintInput
 */
export const zImageAppsV2OutpaintInput = z.object({
    prompt: z.optional(z.string().max(500)).default(''),
    expand_right: z.optional(z.int().gte(0).lte(700)).default(0),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    zoom_out_percentage: z.optional(z.number().gte(0).lte(90)).default(20),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'jpg',
        'webp'
    ])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    expand_left: z.optional(z.int().gte(0).lte(700)).default(0),
    expand_bottom: z.optional(z.int().gte(0).lte(700)).default(400),
    expand_top: z.optional(z.int().gte(0).lte(700)).default(0)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2OutpaintImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * OutpaintOutput
 */
export const zImageAppsV2OutpaintOutput = z.object({
    images: z.array(zFalAiImageAppsV2OutpaintImage)
});

/**
 * Input
 */
export const zFluxVisionUpscalerInput = z.object({
    guidance: z.optional(z.number().gte(1).lte(4)).default(1),
    creativity: z.optional(z.number().gte(0).lte(1)).default(0.3),
    image_url: z.string(),
    upscale_factor: z.optional(z.number().gte(1).lte(4)).default(2),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    steps: z.optional(z.int().gte(4).lte(50)).default(20)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFluxVisionUpscalerImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * Output
 */
export const zFluxVisionUpscalerOutput = z.object({
    image: zFalAiFluxVisionUpscalerImage,
    caption: z.string(),
    seed: z.int(),
    timings: z.record(z.string(), z.number())
});

/**
 * Emu35ImageEditInput
 */
export const zEmu35ImageEditImageInput = z.object({
    prompt: z.string(),
    resolution: z.optional(z.enum(['480p', '720p'])),
    aspect_ratio: z.optional(z.enum([
        'auto',
        '21:9',
        '16:9',
        '4:3',
        '3:2',
        '1:1',
        '2:3',
        '3:4',
        '9:16',
        '9:21'
    ])),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    seed: z.optional(z.int())
});

/**
 * ImageFile
 */
export const zFalAiEmu35ImageEditImageImageFile = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * Emu35EditOutput
 */
export const zEmu35ImageEditImageOutput = z.object({
    images: z.array(zFalAiEmu35ImageEditImageImageFile),
    seed: z.int()
});

/**
 * ChronoEditInput
 *
 * Input model for ChronoEdit standard editing operations
 */
export const zChronoEditInput = z.object({
    prompt: z.string(),
    resolution: z.optional(z.enum(['480p', '720p'])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    image_url: z.string(),
    turbo_mode: z.optional(z.boolean()).default(true),
    num_temporal_reasoning_steps: z.optional(z.int().gte(2).lte(12)).default(8),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(10)).default(1),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(8),
    enable_temporal_reasoning: z.optional(z.boolean()).default(false),
    enable_prompt_expansion: z.optional(z.boolean()).default(true),
    seed: z.optional(z.int())
});

/**
 * ImageFile
 */
export const zFalAiChronoEditImageFile = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ChronoEditOutput
 *
 * Unified output model for all ChronoEdit operations
 */
export const zChronoEditOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiChronoEditImageFile),
    seed: z.int()
});

/**
 * EditImageRequestMini
 */
export const zGptImage1MiniEditInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.enum([
        'auto',
        '1024x1024',
        '1536x1024',
        '1024x1536'
    ])),
    background: z.optional(z.enum([
        'auto',
        'transparent',
        'opaque'
    ])),
    quality: z.optional(z.enum([
        'auto',
        'low',
        'medium',
        'high'
    ])),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    image_urls: z.array(z.string())
});

/**
 * ImageFile
 */
export const zFalAiGptImage1MiniEditImageFile = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * EditImageResponseMini
 */
export const zGptImage1MiniEditOutput = z.object({
    images: z.array(zFalAiGptImage1MiniEditImageFile)
});

/**
 * ReveRemixInput
 *
 * Input for Reve image remixing
 */
export const zReveRemixInput = z.object({
    prompt: z.string().min(1).max(2560),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    aspect_ratio: z.optional(z.enum([
        '16:9',
        '9:16',
        '3:2',
        '2:3',
        '4:3',
        '3:4',
        '1:1'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    image_urls: z.array(z.string()),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ]))
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiReveRemixImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ReveRemixOutput
 *
 * Output for Reve image remixing
 */
export const zReveRemixOutput = z.object({
    images: z.array(zFalAiReveRemixImage)
});

/**
 * ReveEditInput
 *
 * Input for Reve image editing
 */
export const zReveEditInput = z.object({
    prompt: z.string().min(1).max(2560),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    sync_mode: z.optional(z.boolean()).default(false),
    output_format: z.optional(z.enum([
        'png',
        'jpeg',
        'webp'
    ])),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiReveEditImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ReveEditOutput
 *
 * Output for Reve image editing
 */
export const zReveEditOutput = z.object({
    images: z.array(zFalAiReveEditImage)
});

/**
 * Image2PixelInput
 */
export const zImage2PixelInput = z.object({
    cleanup_morph: z.optional(z.boolean()).default(false),
    auto_color_detect: z.optional(z.boolean()).default(false),
    alpha_threshold: z.optional(z.int().gte(0).lte(255)).default(128),
    snap_grid: z.optional(z.boolean()).default(true),
    fixed_palette: z.optional(z.array(z.string())),
    scale: z.optional(z.int().gte(1).lte(64)),
    cleanup_jaggy: z.optional(z.boolean()).default(false),
    trim_borders: z.optional(z.boolean()).default(false),
    background_tolerance: z.optional(z.int().gte(0).lte(255)).default(0),
    detect_method: z.optional(z.enum([
        'auto',
        'runs',
        'edge'
    ])),
    transparent_background: z.optional(z.boolean()).default(false),
    downscale_method: z.optional(z.enum([
        'dominant',
        'median',
        'mode',
        'mean',
        'content-adaptive'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    image_url: z.string(),
    background_mode: z.optional(z.enum([
        'edges',
        'corners',
        'midpoints'
    ])),
    max_colors: z.optional(z.int().gte(1).lte(256)).default(32),
    dominant_color_threshold: z.optional(z.number().gte(0).lte(1)).default(0.05)
});

/**
 * ImageFile
 */
export const zFalAiImage2PixelImageFile = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * Image2PixelOutput
 */
export const zImage2PixelOutput = z.object({
    images: z.array(zFalAiImage2PixelImageFile),
    num_colors: z.int(),
    palette: z.array(z.string()),
    pixel_scale: z.int()
});

/**
 * DreamOmni2Request
 */
export const zDreamomni2EditInput = z.object({
    prompt: z.string(),
    image_urls: z.array(z.string())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiDreamomni2EditImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * DreamOmni2Response
 */
export const zDreamomni2EditOutput = z.object({
    image: zFalAiDreamomni2EditImage
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEditPlusLoraImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * LoraWeight
 */
export const zFalAiQwenImageEditPlusLoraLoraWeight = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(4)).default(1)
});

/**
 * BaseQwenEditImagePlusLoRAInput
 */
export const zQwenImageEditPlusLoraInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEditPlusLoraImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    loras: z.optional(z.array(zFalAiQwenImageEditPlusLoraLoraWeight)).default([]),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(4),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(28),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(' '),
    seed: z.optional(z.int())
});

/**
 * Image
 */
export const zFalAiQwenImageEditPlusLoraImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * QwenImageOutput
 */
export const zQwenImageEditPlusLoraOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiQwenImageEditPlusLoraImage),
    seed: z.int(),
    has_nsfw_concepts: z.array(z.boolean()),
    timings: z.record(z.string(), z.number())
});

/**
 * LucidFluxRequest
 */
export const zLucidfluxInput = z.object({
    prompt: z.string(),
    guidance: z.optional(z.number().gte(1).lte(30)).default(4),
    target_height: z.optional(z.int().gte(512).lte(1024)).default(1024),
    image_url: z.string(),
    target_width: z.optional(z.int().gte(512).lte(1024)).default(1024),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(50),
    seed: z.optional(z.int()).default(42)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiLucidfluxImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * LucidFluxResponse
 */
export const zLucidfluxOutput = z.object({
    image: zFalAiLucidfluxImage,
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEditImageToImageImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * BaseQwenEditImg2ImgInput
 */
export const zQwenImageEditImageToImageInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEditImageToImageImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.94),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(4),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(30),
    seed: z.optional(z.int()),
    negative_prompt: z.optional(z.string()).default(' '),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * Image
 */
export const zFalAiQwenImageEditImageToImageImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * QwenImageOutput
 */
export const zQwenImageEditImageToImageOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiQwenImageEditImageToImageImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiWan25PreviewImageToImageImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * ImageToImageInput
 *
 * Input for image editing
 */
export const zWan25PreviewImageToImageInput = z.object({
    prompt: z.string().min(1),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiWan25PreviewImageToImageImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    seed: z.optional(z.int()),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string())
});

/**
 * ImageFile
 */
export const zFalAiWan25PreviewImageToImageImageFile = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ImageToImageOutput
 *
 * Output for image editing
 */
export const zWan25PreviewImageToImageOutput = z.object({
    images: z.array(zFalAiWan25PreviewImageToImageImageFile),
    seeds: z.array(z.int()),
    actual_prompt: z.optional(z.string())
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEditPlusImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * BaseQwenEditImagePlusInput
 */
export const zQwenImageEditPlusInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEditPlusImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(4),
    seed: z.optional(z.int()),
    image_urls: z.array(z.string()),
    negative_prompt: z.optional(z.string()).default(' '),
    num_inference_steps: z.optional(z.int().gte(2).lte(100)).default(50)
});

/**
 * Image
 */
export const zFalAiQwenImageEditPlusImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * QwenImageOutput
 */
export const zQwenImageEditPlusOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiQwenImageEditPlusImage),
    seed: z.int(),
    has_nsfw_concepts: z.array(z.boolean()),
    timings: z.record(z.string(), z.number())
});

/**
 * SeedVRImageInput
 */
export const zSeedvrUpscaleImageInput = z.object({
    upscale_mode: z.optional(z.enum(['target', 'factor'])),
    noise_scale: z.optional(z.number().gte(0).lte(1)).default(0.1),
    target_resolution: z.optional(z.enum([
        '720p',
        '1080p',
        '1440p',
        '2160p'
    ])),
    output_format: z.optional(z.enum([
        'png',
        'jpg',
        'webp'
    ])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    upscale_factor: z.optional(z.number().gte(1).lte(10)).default(2),
    seed: z.optional(z.int())
});

/**
 * ImageFile
 */
export const zFalAiSeedvrUpscaleImageImageFile = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * SeedVRImageOutput
 */
export const zSeedvrUpscaleImageOutput = z.object({
    image: zFalAiSeedvrUpscaleImageImageFile,
    seed: z.int()
});

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zAspectRatio = z.object({
    ratio: z.optional(z.enum([
        '1:1',
        '16:9',
        '9:16',
        '4:3',
        '3:4'
    ]))
});

/**
 * ProductHoldingInput
 */
export const zImageAppsV2ProductHoldingInput = z.object({
    aspect_ratio: z.optional(zAspectRatio),
    product_image_url: z.string(),
    person_image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2ProductHoldingImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * ProductHoldingOutput
 */
export const zImageAppsV2ProductHoldingOutput = z.object({
    images: z.array(zFalAiImageAppsV2ProductHoldingImage),
    inference_time_ms: z.int()
});

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2ProductPhotographyAspectRatio = z.object({
    ratio: z.optional(z.enum([
        '1:1',
        '16:9',
        '9:16',
        '4:3',
        '3:4'
    ]))
});

/**
 * ProductPhotographyInput
 */
export const zImageAppsV2ProductPhotographyInput = z.object({
    aspect_ratio: z.optional(zFalAiImageAppsV2ProductPhotographyAspectRatio),
    product_image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2ProductPhotographyImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * ProductPhotographyOutput
 */
export const zImageAppsV2ProductPhotographyOutput = z.object({
    images: z.array(zFalAiImageAppsV2ProductPhotographyImage),
    inference_time_ms: z.int()
});

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2VirtualTryOnAspectRatio = z.object({
    ratio: z.optional(z.enum([
        '1:1',
        '16:9',
        '9:16',
        '4:3',
        '3:4'
    ]))
});

/**
 * VirtualTryOnInput
 */
export const zImageAppsV2VirtualTryOnInput = z.object({
    preserve_pose: z.optional(z.boolean()).default(true),
    aspect_ratio: z.optional(zFalAiImageAppsV2VirtualTryOnAspectRatio),
    clothing_image_url: z.string(),
    person_image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2VirtualTryOnImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * VirtualTryOnOutput
 */
export const zImageAppsV2VirtualTryOnOutput = z.object({
    images: z.array(zFalAiImageAppsV2VirtualTryOnImage),
    inference_time_ms: z.int()
});

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2TextureTransformAspectRatio = z.object({
    ratio: z.optional(z.enum([
        '1:1',
        '16:9',
        '9:16',
        '4:3',
        '3:4'
    ]))
});

/**
 * TextureTransformInput
 */
export const zImageAppsV2TextureTransformInput = z.object({
    target_texture: z.optional(z.enum([
        'cotton',
        'denim',
        'wool',
        'felt',
        'wood',
        'leather',
        'velvet',
        'stone',
        'marble',
        'ceramic',
        'concrete',
        'brick',
        'clay',
        'foam',
        'glass',
        'metal',
        'silk',
        'fabric',
        'crystal',
        'rubber',
        'plastic',
        'lace'
    ])),
    aspect_ratio: z.optional(zFalAiImageAppsV2TextureTransformAspectRatio),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2TextureTransformImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * TextureTransformOutput
 */
export const zImageAppsV2TextureTransformOutput = z.object({
    images: z.array(zFalAiImageAppsV2TextureTransformImage),
    inference_time_ms: z.int()
});

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2RelightingAspectRatio = z.object({
    ratio: z.optional(z.enum([
        '1:1',
        '16:9',
        '9:16',
        '4:3',
        '3:4'
    ]))
});

/**
 * RelightingInput
 */
export const zImageAppsV2RelightingInput = z.object({
    aspect_ratio: z.optional(zFalAiImageAppsV2RelightingAspectRatio),
    lighting_style: z.optional(z.enum([
        'natural',
        'studio',
        'golden_hour',
        'blue_hour',
        'dramatic',
        'soft',
        'hard',
        'backlight',
        'side_light',
        'front_light',
        'rim_light',
        'sunset',
        'sunrise',
        'neon',
        'candlelight',
        'moonlight',
        'spotlight',
        'ambient'
    ])),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2RelightingImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * RelightingOutput
 */
export const zImageAppsV2RelightingOutput = z.object({
    images: z.array(zFalAiImageAppsV2RelightingImage),
    inference_time_ms: z.int()
});

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2StyleTransferAspectRatio = z.object({
    ratio: z.optional(z.enum([
        '1:1',
        '16:9',
        '9:16',
        '4:3',
        '3:4'
    ]))
});

/**
 * StyleTransferInput
 */
export const zImageAppsV2StyleTransferInput = z.object({
    target_style: z.optional(z.enum([
        'anime_character',
        'cartoon_3d',
        'hand_drawn_animation',
        'cyberpunk_future',
        'anime_game_style',
        'comic_book_animation',
        'animated_series',
        'cartoon_animation',
        'lofi_aesthetic',
        'cottagecore',
        'dark_academia',
        'y2k',
        'vaporwave',
        'liminal_space',
        'weirdcore',
        'dreamcore',
        'synthwave',
        'outrun',
        'photorealistic',
        'hyperrealistic',
        'digital_art',
        'concept_art',
        'impressionist',
        'anime',
        'pixel_art',
        'claymation'
    ])),
    aspect_ratio: z.optional(zFalAiImageAppsV2StyleTransferAspectRatio),
    style_reference_image_url: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2StyleTransferImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * StyleTransferOutput
 */
export const zImageAppsV2StyleTransferOutput = z.object({
    images: z.array(zFalAiImageAppsV2StyleTransferImage),
    inference_time_ms: z.int()
});

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2PhotoRestorationAspectRatio = z.object({
    ratio: z.optional(z.enum([
        '1:1',
        '16:9',
        '9:16',
        '4:3',
        '3:4'
    ]))
});

/**
 * PhotoRestorationInput
 */
export const zImageAppsV2PhotoRestorationInput = z.object({
    enhance_resolution: z.optional(z.boolean()).default(true),
    aspect_ratio: z.optional(zFalAiImageAppsV2PhotoRestorationAspectRatio),
    remove_scratches: z.optional(z.boolean()).default(true),
    fix_colors: z.optional(z.boolean()).default(true),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2PhotoRestorationImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * PhotoRestorationOutput
 */
export const zImageAppsV2PhotoRestorationOutput = z.object({
    images: z.array(zFalAiImageAppsV2PhotoRestorationImage),
    inference_time_ms: z.int()
});

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2PortraitEnhanceAspectRatio = z.object({
    ratio: z.optional(z.enum([
        '1:1',
        '16:9',
        '9:16',
        '4:3',
        '3:4'
    ]))
});

/**
 * PortraitInput
 */
export const zImageAppsV2PortraitEnhanceInput = z.object({
    aspect_ratio: z.optional(zFalAiImageAppsV2PortraitEnhanceAspectRatio),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2PortraitEnhanceImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * PortraitOutput
 */
export const zImageAppsV2PortraitEnhanceOutput = z.object({
    images: z.array(zFalAiImageAppsV2PortraitEnhanceImage),
    inference_time_ms: z.int()
});

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2PhotographyEffectsAspectRatio = z.object({
    ratio: z.optional(z.enum([
        '1:1',
        '16:9',
        '9:16',
        '4:3',
        '3:4'
    ]))
});

/**
 * PhotographyEffectsInput
 */
export const zImageAppsV2PhotographyEffectsInput = z.object({
    effect_type: z.optional(z.enum([
        'film',
        'vintage_film',
        'portrait_photography',
        'fashion_photography',
        'street_photography',
        'sepia_tone',
        'film_grain',
        'light_leaks',
        'vignette_effect',
        'instant_camera',
        'golden_hour',
        'dramatic_lighting',
        'soft_focus',
        'bokeh_effect',
        'high_contrast',
        'double_exposure'
    ])),
    aspect_ratio: z.optional(zFalAiImageAppsV2PhotographyEffectsAspectRatio),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2PhotographyEffectsImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * PhotographyEffectsOutput
 */
export const zImageAppsV2PhotographyEffectsOutput = z.object({
    images: z.array(zFalAiImageAppsV2PhotographyEffectsImage),
    inference_time_ms: z.int()
});

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2PerspectiveAspectRatio = z.object({
    ratio: z.optional(z.enum([
        '1:1',
        '16:9',
        '9:16',
        '4:3',
        '3:4'
    ]))
});

/**
 * PerspectiveInput
 */
export const zImageAppsV2PerspectiveInput = z.object({
    aspect_ratio: z.optional(zFalAiImageAppsV2PerspectiveAspectRatio),
    target_perspective: z.optional(z.enum([
        'front',
        'left_side',
        'right_side',
        'back',
        'top_down',
        'bottom_up',
        'birds_eye',
        'three_quarter_left',
        'three_quarter_right'
    ])),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2PerspectiveImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * PerspectiveOutput
 */
export const zImageAppsV2PerspectiveOutput = z.object({
    images: z.array(zFalAiImageAppsV2PerspectiveImage),
    inference_time_ms: z.int()
});

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2ObjectRemovalAspectRatio = z.object({
    ratio: z.optional(z.enum([
        '1:1',
        '16:9',
        '9:16',
        '4:3',
        '3:4'
    ]))
});

/**
 * ObjectRemovalInput
 */
export const zImageAppsV2ObjectRemovalInput = z.object({
    aspect_ratio: z.optional(zFalAiImageAppsV2ObjectRemovalAspectRatio),
    object_to_remove: z.string(),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2ObjectRemovalImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * ObjectRemovalOutput
 */
export const zImageAppsV2ObjectRemovalOutput = z.object({
    images: z.array(zFalAiImageAppsV2ObjectRemovalImage),
    inference_time_ms: z.int()
});

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2HeadshotPhotoAspectRatio = z.object({
    ratio: z.optional(z.enum([
        '1:1',
        '16:9',
        '9:16',
        '4:3',
        '3:4'
    ]))
});

/**
 * HeadshotInput
 */
export const zImageAppsV2HeadshotPhotoInput = z.object({
    aspect_ratio: z.optional(zFalAiImageAppsV2HeadshotPhotoAspectRatio),
    background_style: z.optional(z.enum([
        'professional',
        'corporate',
        'clean',
        'gradient'
    ])),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2HeadshotPhotoImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * HeadshotOutput
 */
export const zImageAppsV2HeadshotPhotoOutput = z.object({
    images: z.array(zFalAiImageAppsV2HeadshotPhotoImage),
    inference_time_ms: z.int()
});

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2HairChangeAspectRatio = z.object({
    ratio: z.optional(z.enum([
        '1:1',
        '16:9',
        '9:16',
        '4:3',
        '3:4'
    ]))
});

/**
 * HairChangeInput
 */
export const zImageAppsV2HairChangeInput = z.object({
    target_hairstyle: z.optional(z.enum([
        'short_hair',
        'medium_long_hair',
        'long_hair',
        'curly_hair',
        'wavy_hair',
        'high_ponytail',
        'bun',
        'bob_cut',
        'pixie_cut',
        'braids',
        'straight_hair',
        'afro',
        'dreadlocks',
        'buzz_cut',
        'mohawk',
        'bangs',
        'side_part',
        'middle_part'
    ])),
    aspect_ratio: z.optional(zFalAiImageAppsV2HairChangeAspectRatio),
    hair_color: z.optional(z.enum([
        'black',
        'dark_brown',
        'light_brown',
        'blonde',
        'platinum_blonde',
        'red',
        'auburn',
        'gray',
        'silver',
        'blue',
        'green',
        'purple',
        'pink',
        'rainbow',
        'natural',
        'highlights',
        'ombre',
        'balayage'
    ])),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2HairChangeImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * HairChangeOutput
 */
export const zImageAppsV2HairChangeOutput = z.object({
    images: z.array(zFalAiImageAppsV2HairChangeImage),
    inference_time_ms: z.int()
});

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2ExpressionChangeAspectRatio = z.object({
    ratio: z.optional(z.enum([
        '1:1',
        '16:9',
        '9:16',
        '4:3',
        '3:4'
    ]))
});

/**
 * ExpressionChangeInput
 */
export const zImageAppsV2ExpressionChangeInput = z.object({
    aspect_ratio: z.optional(zFalAiImageAppsV2ExpressionChangeAspectRatio),
    target_expression: z.optional(z.enum([
        'smile',
        'surprise',
        'glare',
        'panic',
        'shyness',
        'laugh',
        'cry',
        'angry',
        'sad',
        'happy',
        'excited',
        'shocked',
        'confused',
        'focused',
        'dreamy',
        'serious',
        'playful',
        'mysterious',
        'confident',
        'thoughtful'
    ])),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2ExpressionChangeImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * ExpressionChangeOutput
 */
export const zImageAppsV2ExpressionChangeOutput = z.object({
    images: z.array(zFalAiImageAppsV2ExpressionChangeImage),
    inference_time_ms: z.int()
});

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2CityTeleportAspectRatio = z.object({
    ratio: z.optional(z.enum([
        '1:1',
        '16:9',
        '9:16',
        '4:3',
        '3:4'
    ]))
});

/**
 * CityTeleportInput
 */
export const zImageAppsV2CityTeleportInput = z.object({
    city_image_url: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    aspect_ratio: z.optional(zFalAiImageAppsV2CityTeleportAspectRatio),
    city_name: z.string(),
    photo_shot: z.optional(z.enum([
        'extreme_close_up',
        'close_up',
        'medium_close_up',
        'medium_shot',
        'medium_long_shot',
        'long_shot',
        'extreme_long_shot',
        'full_body'
    ])),
    camera_angle: z.optional(z.enum([
        'eye_level',
        'low_angle',
        'high_angle',
        'dutch_angle',
        'birds_eye_view',
        'worms_eye_view',
        'overhead',
        'side_angle'
    ])),
    person_image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2CityTeleportImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * CityTeleportOutput
 */
export const zImageAppsV2CityTeleportOutput = z.object({
    images: z.array(zFalAiImageAppsV2CityTeleportImage),
    inference_time_ms: z.int()
});

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2AgeModifyAspectRatio = z.object({
    ratio: z.optional(z.enum([
        '1:1',
        '16:9',
        '9:16',
        '4:3',
        '3:4'
    ]))
});

/**
 * AgeModifyInput
 */
export const zImageAppsV2AgeModifyInput = z.object({
    image_url: z.string(),
    aspect_ratio: z.optional(zFalAiImageAppsV2AgeModifyAspectRatio),
    preserve_identity: z.optional(z.boolean()).default(true),
    target_age: z.optional(z.int().gte(6).lte(100)).default(30)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2AgeModifyImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * AgeModifyOutput
 */
export const zImageAppsV2AgeModifyOutput = z.object({
    images: z.array(zFalAiImageAppsV2AgeModifyImage),
    inference_time_ms: z.int()
});

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export const zFalAiImageAppsV2MakeupApplicationAspectRatio = z.object({
    ratio: z.optional(z.enum([
        '1:1',
        '16:9',
        '9:16',
        '4:3',
        '3:4'
    ]))
});

/**
 * MakeupApplicationInput
 */
export const zImageAppsV2MakeupApplicationInput = z.object({
    aspect_ratio: z.optional(zFalAiImageAppsV2MakeupApplicationAspectRatio),
    intensity: z.optional(z.enum([
        'light',
        'medium',
        'heavy',
        'dramatic'
    ])),
    makeup_style: z.optional(z.enum([
        'natural',
        'glamorous',
        'smoky_eyes',
        'bold_lips',
        'no_makeup',
        'remove_makeup',
        'dramatic',
        'bridal',
        'professional',
        'korean_style',
        'artistic'
    ])),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageAppsV2MakeupApplicationImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * MakeupApplicationOutput
 */
export const zImageAppsV2MakeupApplicationOutput = z.object({
    images: z.array(zFalAiImageAppsV2MakeupApplicationImage),
    inference_time_ms: z.int()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEditInpaintImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * BaseQwenEditInpaintImageInput
 */
export const zQwenImageEditInpaintInput = z.object({
    prompt: z.string(),
    image_size: z.optional(z.union([
        zFalAiQwenImageEditInpaintImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(4),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    negative_prompt: z.optional(z.string()).default(' '),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.93),
    seed: z.optional(z.int()),
    mask_url: z.string(),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(30)
});

/**
 * Image
 */
export const zFalAiQwenImageEditInpaintImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * QwenImageInpaintOutput
 */
export const zQwenImageEditInpaintOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiQwenImageEditInpaintImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * BaseSRPOImageToInput
 */
export const zFluxSrpoImageToImageInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.95),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    guidance_scale: z.optional(z.number().gte(1).lte(20)).default(4.5),
    num_inference_steps: z.optional(z.int().gte(10).lte(50)).default(40)
});

/**
 * Image
 */
export const zFalAiFluxSrpoImageToImageImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFluxSrpoImageToImageOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxSrpoImageToImageImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * BaseSRPOFlux1ImageToInput
 */
export const zFlux1SrpoImageToImageInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.95),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    num_inference_steps: z.optional(z.int().gte(10).lte(50)).default(40),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    guidance_scale: z.optional(z.number().gte(1).lte(20)).default(4.5)
});

/**
 * Image
 */
export const zFalAiFlux1SrpoImageToImageImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFlux1SrpoImageToImageOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFlux1SrpoImageToImageImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEditLoraImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * LoraWeight
 */
export const zFalAiQwenImageEditLoraLoraWeight = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(4)).default(1)
});

/**
 * BaseQwenEditImageLoRAInput
 */
export const zQwenImageEditLoraInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEditLoraImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    loras: z.optional(z.array(zFalAiQwenImageEditLoraLoraWeight)).default([]),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(4),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(30),
    seed: z.optional(z.int()),
    negative_prompt: z.optional(z.string()).default(' '),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * Image
 */
export const zFalAiQwenImageEditLoraImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * QwenImageOutput
 */
export const zQwenImageEditLoraOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiQwenImageEditLoraImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ReferenceToImageRequest
 */
export const zViduReferenceToImageInput = z.object({
    prompt: z.string().max(1500),
    aspect_ratio: z.optional(z.enum([
        '16:9',
        '9:16',
        '1:1'
    ])),
    reference_image_urls: z.array(z.string()),
    seed: z.optional(z.int())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiViduReferenceToImageImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ReferenceToImageOutput
 */
export const zViduReferenceToImageOutput = z.object({
    image: zFalAiViduReferenceToImageImage
});

/**
 * ImageSize
 */
export const zFalAiBytedanceSeedreamV4EditImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * SeedDream4EditInput
 */
export const zBytedanceSeedreamV4EditInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(6)).default(1),
    image_size: z.optional(z.union([
        zFalAiBytedanceSeedreamV4EditImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9',
            'auto',
            'auto_2K',
            'auto_4K'
        ])
    ])),
    enhance_prompt_mode: z.optional(z.enum(['standard', 'fast'])),
    max_images: z.optional(z.int().gte(1).lte(6)).default(1),
    sync_mode: z.optional(z.boolean()).default(false),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    seed: z.optional(z.int()),
    image_urls: z.array(z.string())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBytedanceSeedreamV4EditImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * SeedDream4EditOutput
 */
export const zBytedanceSeedreamV4EditOutput = z.object({
    images: z.array(zFalAiBytedanceSeedreamV4EditImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiWanV22A14bImageToImageImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * WanI2IRequest
 */
export const zWanV22A14bImageToImageInput = z.object({
    prompt: z.string(),
    shift: z.optional(z.number().gte(1).lte(10)).default(2),
    acceleration: z.optional(z.enum(['none', 'regular'])),
    image_size: z.optional(z.union([
        zFalAiWanV22A14bImageToImageImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    guidance_scale: z.optional(z.number().gte(1).lte(10)).default(3.5),
    enable_safety_checker: z.optional(z.boolean()).default(false),
    negative_prompt: z.optional(z.string()).default(''),
    image_format: z.optional(z.enum(['png', 'jpeg'])),
    aspect_ratio: z.optional(z.enum([
        'auto',
        '16:9',
        '9:16',
        '1:1'
    ])),
    enable_output_safety_checker: z.optional(z.boolean()).default(false),
    image_url: z.string(),
    strength: z.optional(z.number().gte(0).lte(1)).default(0.5),
    guidance_scale_2: z.optional(z.number().gte(1).lte(10)).default(4),
    enable_prompt_expansion: z.optional(z.boolean()).default(false),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    num_inference_steps: z.optional(z.int().gte(2).lte(40)).default(27)
});

/**
 * File
 */
export const zFalAiWanV22A14bImageToImageFile = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string()
});

/**
 * WanI2IResponse
 */
export const zWanV22A14bImageToImageOutput = z.object({
    prompt: z.optional(z.string()).default(''),
    image: zFalAiWanV22A14bImageToImageFile,
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiUsoImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * USOInputImage
 */
export const zUsoInput = z.object({
    prompt: z.optional(z.string()).default(''),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiUsoImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    keep_size: z.optional(z.boolean()).default(false),
    input_image_urls: z.array(z.string()),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(1).lte(10)).default(4),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28),
    seed: z.optional(z.int()),
    negative_prompt: z.optional(z.string()).default(''),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiUsoImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * USOOutputImage
 */
export const zUsoOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiUsoImage),
    timings: z.record(z.string(), z.unknown()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * NanoBananaImageToImageInput
 */
export const zGemini25FlashImageEditInput = z.object({
    prompt: z.string().min(3).max(50000),
    aspect_ratio: z.optional(z.enum([
        'auto',
        '21:9',
        '16:9',
        '3:2',
        '4:3',
        '5:4',
        '1:1',
        '4:5',
        '3:4',
        '2:3',
        '9:16'
    ])),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    image_urls: z.array(z.string()),
    limit_generations: z.optional(z.boolean()).default(false)
});

/**
 * ImageFile
 */
export const zFalAiGemini25FlashImageEditImageFile = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * NanoBananaImageToImageOutput
 */
export const zGemini25FlashImageEditOutput = z.object({
    images: z.array(zFalAiGemini25FlashImageEditImageFile),
    description: z.string()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageImageToImageImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * LoraWeight
 */
export const zFalAiQwenImageImageToImageLoraWeight = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(4)).default(1)
});

/**
 * QwenImageI2IInput
 */
export const zQwenImageImageToImageInput = z.object({
    prompt: z.string(),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    image_size: z.optional(z.union([
        zFalAiQwenImageImageToImageImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    loras: z.optional(z.array(zFalAiQwenImageImageToImageLoraWeight)).default([]),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(2.5),
    use_turbo: z.optional(z.boolean()).default(false),
    negative_prompt: z.optional(z.string()).default(' '),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    strength: z.optional(z.number().gte(0).lte(1)).default(0.6),
    num_inference_steps: z.optional(z.int().gte(2).lte(250)).default(30),
    seed: z.optional(z.int())
});

/**
 * Image
 */
export const zFalAiQwenImageImageToImageImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * QwenImageI2IOutput
 */
export const zQwenImageImageToImageOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiQwenImageImageToImageImage),
    seed: z.int(),
    has_nsfw_concepts: z.array(z.boolean()),
    timings: z.record(z.string(), z.number())
});

/**
 * InputModel
 */
export const zReimagine32Input = z.object({
    prompt: z.string(),
    depth_preprocess: z.optional(z.boolean()).default(true),
    canny_preprocess: z.optional(z.boolean()).default(true),
    depth_image_url: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    guidance_scale: z.optional(z.number().gte(1).lte(10)).default(5),
    canny_image_url: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    negative_prompt: z.optional(z.string()).default('Logo,Watermark,Ugly,Morbid,Extra fingers,Poorly drawn hands,Mutation,Blurry,Extra limbs,Gross proportions,Missing arms,Mutated hands,Long neck,Duplicate,Mutilated,Mutilated hands,Poorly drawn face,Deformed,Bad anatomy,Cloned face,Malformed limbs,Missing legs,Too many fingers'),
    depth_scale: z.optional(z.number().gte(0).lte(1)).default(0.5),
    aspect_ratio: z.optional(z.enum([
        '1:1',
        '2:3',
        '3:2',
        '3:4',
        '4:3',
        '4:5',
        '5:4',
        '9:16',
        '16:9'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    prompt_enhancer: z.optional(z.boolean()).default(true),
    truncate_prompt: z.optional(z.boolean()).default(true),
    seed: z.optional(z.int()).default(5555),
    canny_scale: z.optional(z.number().gte(0).lte(1)).default(0.5),
    num_inference_steps: z.optional(z.int().gte(20).lte(50)).default(30)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaReimagine32Image = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * OutputModel
 */
export const zReimagine32Output = z.object({
    image: zBriaReimagine32Image
});

/**
 * NanoBananaImageToImageInput
 */
export const zNanoBananaEditInput = z.object({
    prompt: z.string().min(3).max(50000),
    aspect_ratio: z.optional(z.enum([
        'auto',
        '21:9',
        '16:9',
        '3:2',
        '4:3',
        '5:4',
        '1:1',
        '4:5',
        '3:4',
        '2:3',
        '9:16'
    ])),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    image_urls: z.array(z.string()),
    limit_generations: z.optional(z.boolean()).default(false)
});

/**
 * ImageFile
 */
export const zFalAiNanoBananaEditImageFile = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * NanoBananaImageToImageOutput
 */
export const zNanoBananaEditOutput = z.object({
    images: z.array(zFalAiNanoBananaEditImageFile),
    description: z.string()
});

/**
 * NextStepEditRequest
 */
export const zNextstep1Input = z.object({
    prompt: z.string(),
    negative_prompt: z.string(),
    image_url: z.string()
});

/**
 * NextStepResponse
 */
export const zNextstep1Output = z.object({
    image: z.object({
        file_size: z.optional(z.union([
            z.int(),
            z.unknown()
        ])),
        height: z.optional(z.union([
            z.int(),
            z.unknown()
        ])),
        file_name: z.optional(z.union([
            z.string(),
            z.unknown()
        ])),
        content_type: z.optional(z.union([
            z.string(),
            z.unknown()
        ])),
        url: z.string(),
        width: z.optional(z.union([
            z.int(),
            z.unknown()
        ]))
    }),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiQwenImageEditImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * BaseQwenEditImageInput
 */
export const zQwenImageEditInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiQwenImageEditImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(4),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(30),
    seed: z.optional(z.int()),
    negative_prompt: z.optional(z.string()).default(' '),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * Image
 */
export const zFalAiQwenImageEditImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * QwenImageOutput
 */
export const zQwenImageEditOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiQwenImageEditImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * File
 */
export const zFalAiIdeogramCharacterEditFile = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string()
});

/**
 * CharacterEditOutputV3
 */
export const zIdeogramCharacterEditOutput = z.object({
    images: z.array(zFalAiIdeogramCharacterEditFile),
    seed: z.int()
});

/**
 * RGBColor
 */
export const zRgbColor = z.object({
    r: z.optional(z.int().gte(0).lte(255)).default(0),
    b: z.optional(z.int().gte(0).lte(255)).default(0),
    g: z.optional(z.int().gte(0).lte(255)).default(0)
});

/**
 * ColorPaletteMember
 */
export const zColorPaletteMember = z.object({
    color_weight: z.optional(z.union([
        z.number().gte(0.05).lte(1),
        z.unknown()
    ])),
    rgb: zRgbColor
});

/**
 * ColorPalette
 */
export const zColorPalette = z.object({
    members: z.optional(z.union([
        z.array(zColorPaletteMember),
        z.unknown()
    ])),
    name: z.optional(z.union([
        z.enum([
            'EMBER',
            'FRESH',
            'JUNGLE',
            'MAGIC',
            'MELON',
            'MOSAIC',
            'PASTEL',
            'ULTRAMARINE'
        ]),
        z.unknown()
    ]))
});

/**
 * CharacterEditInputV3
 */
export const zIdeogramCharacterEditInput = z.object({
    prompt: z.string(),
    style: z.optional(z.enum([
        'AUTO',
        'REALISTIC',
        'FICTION'
    ])),
    expand_prompt: z.optional(z.boolean()).default(true),
    rendering_speed: z.optional(z.enum([
        'TURBO',
        'BALANCED',
        'QUALITY'
    ])),
    reference_mask_urls: z.optional(z.array(z.string())),
    reference_image_urls: z.array(z.string()),
    image_urls: z.optional(z.union([
        z.array(z.string()),
        z.unknown()
    ])),
    num_images: z.optional(z.int().gte(1).lte(8)).default(1),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    color_palette: z.optional(z.union([
        zColorPalette,
        z.unknown()
    ])),
    style_codes: z.optional(z.union([
        z.array(z.string()),
        z.unknown()
    ])),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    mask_url: z.string()
});

/**
 * ImageSize
 */
export const zFalAiIdeogramCharacterImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * File
 */
export const zFalAiIdeogramCharacterFile = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string()
});

/**
 * CharacterOutputV3
 */
export const zIdeogramCharacterOutput = z.object({
    images: z.array(zFalAiIdeogramCharacterFile),
    seed: z.int()
});

/**
 * RGBColor
 */
export const zFalAiIdeogramCharacterRgbColor = z.object({
    r: z.optional(z.int().gte(0).lte(255)).default(0),
    b: z.optional(z.int().gte(0).lte(255)).default(0),
    g: z.optional(z.int().gte(0).lte(255)).default(0)
});

/**
 * ColorPaletteMember
 */
export const zFalAiIdeogramCharacterColorPaletteMember = z.object({
    color_weight: z.optional(z.union([
        z.number().gte(0.05).lte(1),
        z.unknown()
    ])),
    rgb: zFalAiIdeogramCharacterRgbColor
});

/**
 * ColorPalette
 */
export const zFalAiIdeogramCharacterColorPalette = z.object({
    members: z.optional(z.union([
        z.array(zFalAiIdeogramCharacterColorPaletteMember),
        z.unknown()
    ])),
    name: z.optional(z.union([
        z.enum([
            'EMBER',
            'FRESH',
            'JUNGLE',
            'MAGIC',
            'MELON',
            'MOSAIC',
            'PASTEL',
            'ULTRAMARINE'
        ]),
        z.unknown()
    ]))
});

/**
 * BaseCharacterInputV3
 */
export const zIdeogramCharacterInput = z.object({
    prompt: z.string(),
    image_size: z.optional(z.union([
        zFalAiIdeogramCharacterImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    style: z.optional(z.enum([
        'AUTO',
        'REALISTIC',
        'FICTION'
    ])),
    expand_prompt: z.optional(z.boolean()).default(true),
    rendering_speed: z.optional(z.enum([
        'TURBO',
        'BALANCED',
        'QUALITY'
    ])),
    reference_mask_urls: z.optional(z.array(z.string())),
    reference_image_urls: z.array(z.string()),
    image_urls: z.optional(z.union([
        z.array(z.string()),
        z.unknown()
    ])),
    negative_prompt: z.optional(z.string()).default(''),
    num_images: z.optional(z.int().gte(1).lte(8)).default(1),
    sync_mode: z.optional(z.boolean()).default(false),
    color_palette: z.optional(z.union([
        zFalAiIdeogramCharacterColorPalette,
        z.unknown()
    ])),
    style_codes: z.optional(z.union([
        z.array(z.string()),
        z.unknown()
    ])),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * ImageSize
 */
export const zFalAiIdeogramCharacterRemixImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * File
 */
export const zFalAiIdeogramCharacterRemixFile = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string()
});

/**
 * CharacterRemixOutputV3
 */
export const zIdeogramCharacterRemixOutput = z.object({
    images: z.array(zFalAiIdeogramCharacterRemixFile),
    seed: z.int()
});

/**
 * RGBColor
 */
export const zFalAiIdeogramCharacterRemixRgbColor = z.object({
    r: z.optional(z.int().gte(0).lte(255)).default(0),
    b: z.optional(z.int().gte(0).lte(255)).default(0),
    g: z.optional(z.int().gte(0).lte(255)).default(0)
});

/**
 * ColorPaletteMember
 */
export const zFalAiIdeogramCharacterRemixColorPaletteMember = z.object({
    color_weight: z.optional(z.union([
        z.number().gte(0.05).lte(1),
        z.unknown()
    ])),
    rgb: zFalAiIdeogramCharacterRemixRgbColor
});

/**
 * ColorPalette
 */
export const zFalAiIdeogramCharacterRemixColorPalette = z.object({
    members: z.optional(z.union([
        z.array(zFalAiIdeogramCharacterRemixColorPaletteMember),
        z.unknown()
    ])),
    name: z.optional(z.union([
        z.enum([
            'EMBER',
            'FRESH',
            'JUNGLE',
            'MAGIC',
            'MELON',
            'MOSAIC',
            'PASTEL',
            'ULTRAMARINE'
        ]),
        z.unknown()
    ]))
});

/**
 * CharacterRemixInputV3
 */
export const zIdeogramCharacterRemixInput = z.object({
    prompt: z.string(),
    image_size: z.optional(z.union([
        zFalAiIdeogramCharacterRemixImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    style: z.optional(z.enum([
        'AUTO',
        'REALISTIC',
        'FICTION'
    ])),
    expand_prompt: z.optional(z.boolean()).default(true),
    rendering_speed: z.optional(z.enum([
        'TURBO',
        'BALANCED',
        'QUALITY'
    ])),
    reference_mask_urls: z.optional(z.array(z.string())),
    reference_image_urls: z.array(z.string()),
    image_urls: z.optional(z.union([
        z.array(z.string()),
        z.unknown()
    ])),
    negative_prompt: z.optional(z.string()).default(''),
    num_images: z.optional(z.int().gte(1).lte(8)).default(1),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    color_palette: z.optional(z.union([
        zFalAiIdeogramCharacterRemixColorPalette,
        z.unknown()
    ])),
    style_codes: z.optional(z.union([
        z.array(z.string()),
        z.unknown()
    ])),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.8),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * ImageSize
 */
export const zFalAiFluxKreaLoraInpaintingImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * LoraWeight
 */
export const zFalAiFluxKreaLoraInpaintingLoraWeight = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(4)).default(1)
});

/**
 * InpaintInput
 */
export const zFluxKreaLoraInpaintingInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiFluxKreaLoraInpaintingImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    loras: z.optional(z.array(zFalAiFluxKreaLoraInpaintingLoraWeight)).default([]),
    sync_mode: z.optional(z.boolean()).default(false),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.85),
    guidance_scale: z.optional(z.number().gte(0).lte(35)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28),
    mask_url: z.string(),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    seed: z.optional(z.int())
});

/**
 * Image
 */
export const zFalAiFluxKreaLoraInpaintingImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFluxKreaLoraInpaintingOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxKreaLoraInpaintingImage),
    seed: z.int(),
    has_nsfw_concepts: z.array(z.boolean()),
    timings: z.record(z.string(), z.number())
});

/**
 * ImageSize
 */
export const zFalAiFluxKreaLoraImageToImageImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * LoraWeight
 */
export const zFalAiFluxKreaLoraImageToImageLoraWeight = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(4)).default(1)
});

/**
 * ImageToImageInput
 */
export const zFluxKreaLoraImageToImageInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiFluxKreaLoraImageToImageImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    loras: z.optional(z.array(zFalAiFluxKreaLoraImageToImageLoraWeight)).default([]),
    sync_mode: z.optional(z.boolean()).default(false),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.85),
    guidance_scale: z.optional(z.number().gte(0).lte(35)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    seed: z.optional(z.int())
});

/**
 * Image
 */
export const zFalAiFluxKreaLoraImageToImageImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFluxKreaLoraImageToImageOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxKreaLoraImageToImageImage),
    seed: z.int(),
    has_nsfw_concepts: z.array(z.boolean()),
    timings: z.record(z.string(), z.number())
});

/**
 * BaseKreaImageToInput
 */
export const zFluxKreaImageToImageInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.95),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    guidance_scale: z.optional(z.number().gte(1).lte(20)).default(4.5),
    num_inference_steps: z.optional(z.int().gte(10).lte(50)).default(40)
});

/**
 * Image
 */
export const zFalAiFluxKreaImageToImageImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFluxKreaImageToImageOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxKreaImageToImageImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiFluxKreaReduxImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * BaseKreaReduxInput
 */
export const zFluxKreaReduxInput = z.object({
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiFluxKreaReduxImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    guidance_scale: z.optional(z.number().gte(1).lte(20)).default(4.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28)
});

/**
 * Image
 */
export const zFalAiFluxKreaReduxImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * KreaReduxOutput
 */
export const zFluxKreaReduxOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxKreaReduxImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * BaseKreaFlux1ImageToInput
 */
export const zFlux1KreaImageToImageInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.95),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    num_inference_steps: z.optional(z.int().gte(10).lte(50)).default(40),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    guidance_scale: z.optional(z.number().gte(1).lte(20)).default(4.5)
});

/**
 * Image
 */
export const zFalAiFlux1KreaImageToImageImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * KreaOutput
 */
export const zFlux1KreaImageToImageOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFlux1KreaImageToImageImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiFlux1KreaReduxImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * BaseKreaFlux1ReduxInput
 */
export const zFlux1KreaReduxInput = z.object({
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiFlux1KreaReduxImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    guidance_scale: z.optional(z.number().gte(1).lte(20)).default(4.5)
});

/**
 * Image
 */
export const zFalAiFlux1KreaReduxImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * KreaReduxOutput
 */
export const zFlux1KreaReduxOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFlux1KreaReduxImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * LoraWeight
 */
export const zFalAiFluxKontextLoraInpaintLoraWeight = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(4)).default(1)
});

/**
 * BaseKontextInpaintInput
 */
export const zFluxKontextLoraInpaintInput = z.object({
    prompt: z.string(),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    reference_image_url: z.string(),
    loras: z.optional(z.array(zFalAiFluxKontextLoraInpaintLoraWeight)).default([]),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(2.5),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.88),
    num_inference_steps: z.optional(z.int().gte(10).lte(50)).default(30),
    mask_url: z.string(),
    seed: z.optional(z.int())
});

/**
 * Image
 */
export const zFalAiFluxKontextLoraInpaintImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * KontextInpaintOutput
 */
export const zFluxKontextLoraInpaintOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxKontextLoraInpaintImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageToPanoramaRequest
 */
export const zHunyuanWorldInput = z.object({
    prompt: z.string(),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiHunyuanWorldImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ImageToPanoramaResponse
 */
export const zHunyuanWorldOutput = z.object({
    image: zFalAiHunyuanWorldImage
});

/**
 * RetouchInput
 *
 * Input model for retouch endpoint.
 */
export const zImageEditingRetouchInput = z.object({
    lora_scale: z.optional(z.number().gte(0).lte(4)).default(1),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    seed: z.optional(z.int()),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(30),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingRetouchImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * RetouchOutput
 */
export const zImageEditingRetouchOutput = z.object({
    images: z.array(zFalAiImageEditingRetouchImage),
    seed: z.int()
});

/**
 * BaseInput
 */
export const zHidreamE11Input = z.object({
    prompt: z.optional(z.string()),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_guidance_scale: z.optional(z.number().gte(0).lte(20)).default(2),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(50),
    target_image_description: z.optional(z.string()),
    negative_prompt: z.optional(z.string()).default('low resolution, blur'),
    seed: z.optional(z.int())
});

/**
 * Image
 */
export const zFalAiHidreamE11Image = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zHidreamE11Output = z.object({
    prompt: z.string(),
    images: z.array(zFalAiHidreamE11Image),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * RIFEImageInput
 */
export const zRifeInput = z.object({
    output_format: z.optional(z.enum(['png', 'jpeg'])),
    fps: z.optional(z.int().gte(1).lte(60)).default(8),
    sync_mode: z.optional(z.boolean()).default(false),
    include_end: z.optional(z.boolean()).default(false),
    include_start: z.optional(z.boolean()).default(false),
    num_frames: z.optional(z.int().gte(1).lte(64)).default(1),
    end_image_url: z.string(),
    output_type: z.optional(z.enum(['images', 'video'])),
    start_image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiRifeImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * File
 */
export const zFalAiRifeFile = z.object({
    file_size: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    url: z.string(),
    file_data: z.optional(z.string())
});

/**
 * RIFEImageOutput
 */
export const zRifeOutput = z.object({
    images: z.optional(z.array(zFalAiRifeImage)).default([]),
    video: z.optional(zFalAiRifeFile)
});

/**
 * FILMImageInput
 */
export const zFilmInput = z.object({
    video_write_mode: z.optional(z.enum([
        'fast',
        'balanced',
        'small'
    ])),
    num_frames: z.optional(z.int().gte(1).lte(64)).default(1),
    include_start: z.optional(z.boolean()).default(false),
    video_quality: z.optional(z.enum([
        'low',
        'medium',
        'high',
        'maximum'
    ])),
    include_end: z.optional(z.boolean()).default(false),
    sync_mode: z.optional(z.boolean()).default(false),
    fps: z.optional(z.int().gte(1).lte(60)).default(8),
    start_image_url: z.string(),
    end_image_url: z.string(),
    image_format: z.optional(z.enum(['png', 'jpeg'])),
    output_type: z.optional(z.enum(['images', 'video']))
});

/**
 * ImageFile
 */
export const zFalAiFilmImageFile = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * VideoFile
 */
export const zVideoFile = z.object({
    file_size: z.optional(z.int()),
    duration: z.optional(z.number()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    fps: z.optional(z.number()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    num_frames: z.optional(z.int()),
    file_data: z.optional(z.string())
});

/**
 * FILMImageOutput
 */
export const zFilmOutput = z.object({
    images: z.optional(z.array(zFalAiFilmImageFile)).default([]),
    video: z.optional(zVideoFile)
});

/**
 * ImageSize
 */
export const zFalAiCalligrapherImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * Input
 */
export const zCalligrapherInput = z.object({
    use_context: z.optional(z.boolean()).default(true),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiCalligrapherImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    auto_mask_generation: z.optional(z.boolean()).default(false),
    reference_image_url: z.optional(z.string()),
    source_image_url: z.string(),
    prompt: z.string(),
    mask_image_url: z.optional(z.string()),
    source_text: z.optional(z.string()).default(''),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(50),
    seed: z.optional(z.int()),
    cfg_scale: z.optional(z.number().gte(0).lte(5)).default(1)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiCalligrapherImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * Output
 */
export const zCalligrapherOutput = z.object({
    images: z.array(zFalAiCalligrapherImage)
});

/**
 * ReimagineInput
 */
export const zBriaReimagineInput = z.object({
    prompt: z.string(),
    num_results: z.optional(z.int().gte(1).lte(4)).default(1),
    structure_ref_influence: z.optional(z.number()).default(0.75),
    sync_mode: z.optional(z.boolean()).default(false),
    fast: z.optional(z.boolean()).default(true),
    seed: z.optional(z.int().gte(0).lte(2147483647)),
    num_inference_steps: z.optional(z.int().gte(20).lte(50)).default(30),
    structure_image_url: z.optional(z.string()).default('')
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBriaReimagineImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ReimagineOutput
 */
export const zBriaReimagineOutput = z.object({
    images: z.array(zFalAiBriaReimagineImage),
    seed: z.int()
});

/**
 * RealismInput
 *
 * Input model for realism enhancement endpoint.
 */
export const zImageEditingRealismInput = z.object({
    lora_scale: z.optional(z.number().gte(0).lte(2)).default(0.6),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    seed: z.optional(z.int()),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(30),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingRealismImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * RealismOutput
 */
export const zImageEditingRealismOutput = z.object({
    images: z.array(zFalAiImageEditingRealismImage),
    seed: z.int()
});

/**
 * VignetteInput
 */
export const zPostProcessingVignetteInput = z.object({
    vignette_strength: z.optional(z.number().gte(0).lte(10)).default(0.5),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPostProcessingVignetteImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * VignetteOutput
 */
export const zPostProcessingVignetteOutput = z.object({
    images: z.array(zFalAiPostProcessingVignetteImage)
});

/**
 * SolarizeInput
 */
export const zPostProcessingSolarizeInput = z.object({
    solarize_threshold: z.optional(z.number().gte(0).lte(1)).default(0.5),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPostProcessingSolarizeImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * SolarizeOutput
 */
export const zPostProcessingSolarizeOutput = z.object({
    images: z.array(zFalAiPostProcessingSolarizeImage)
});

/**
 * SharpenInput
 */
export const zPostProcessingSharpenInput = z.object({
    sharpen_mode: z.optional(z.enum([
        'basic',
        'smart',
        'cas'
    ])),
    sharpen_alpha: z.optional(z.number().gte(0.1).lte(5)).default(1),
    noise_radius: z.optional(z.int().gte(1).lte(25)).default(7),
    sharpen_radius: z.optional(z.int().gte(1).lte(15)).default(1),
    image_url: z.string(),
    smart_sharpen_strength: z.optional(z.number().gte(0).lte(25)).default(5),
    cas_amount: z.optional(z.number().gte(0).lte(1)).default(0.8),
    preserve_edges: z.optional(z.number().gte(0).lte(1)).default(0.75),
    smart_sharpen_ratio: z.optional(z.number().gte(0).lte(1)).default(0.5)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPostProcessingSharpenImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * SharpenOutput
 */
export const zPostProcessingSharpenOutput = z.object({
    images: z.array(zFalAiPostProcessingSharpenImage)
});

/**
 * ParabolizeInput
 */
export const zPostProcessingParabolizeInput = z.object({
    parabolize_coeff: z.optional(z.number().gte(-10).lte(10)).default(1),
    vertex_y: z.optional(z.number().gte(0).lte(1)).default(0.5),
    vertex_x: z.optional(z.number().gte(0).lte(1)).default(0.5),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPostProcessingParabolizeImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ParabolizeOutput
 */
export const zPostProcessingParabolizeOutput = z.object({
    images: z.array(zFalAiPostProcessingParabolizeImage)
});

/**
 * GrainInput
 */
export const zPostProcessingGrainInput = z.object({
    grain_style: z.optional(z.enum([
        'modern',
        'analog',
        'kodak',
        'fuji',
        'cinematic',
        'newspaper'
    ])),
    grain_intensity: z.optional(z.number().gte(0).lte(1)).default(0.4),
    grain_scale: z.optional(z.number().gte(1).lte(100)).default(10),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPostProcessingGrainImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * GrainOutput
 */
export const zPostProcessingGrainOutput = z.object({
    images: z.array(zFalAiPostProcessingGrainImage)
});

/**
 * DodgeBurnInput
 */
export const zPostProcessingDodgeBurnInput = z.object({
    dodge_burn_mode: z.optional(z.enum([
        'dodge',
        'burn',
        'dodge_and_burn',
        'burn_and_dodge',
        'color_dodge',
        'color_burn',
        'linear_dodge',
        'linear_burn'
    ])),
    dodge_burn_intensity: z.optional(z.number().gte(0).lte(1)).default(0.5),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPostProcessingDodgeBurnImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * DodgeBurnOutput
 */
export const zPostProcessingDodgeBurnOutput = z.object({
    images: z.array(zFalAiPostProcessingDodgeBurnImage)
});

/**
 * DissolveInput
 */
export const zPostProcessingDissolveInput = z.object({
    dissolve_factor: z.optional(z.number().gte(0).lte(1)).default(0.5),
    dissolve_image_url: z.string(),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPostProcessingDissolveImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * DissolveOutput
 */
export const zPostProcessingDissolveOutput = z.object({
    images: z.array(zFalAiPostProcessingDissolveImage)
});

/**
 * DesaturateInput
 */
export const zPostProcessingDesaturateInput = z.object({
    desaturate_method: z.optional(z.enum([
        'luminance (Rec.709)',
        'luminance (Rec.601)',
        'average',
        'lightness'
    ])),
    desaturate_factor: z.optional(z.number().gte(0).lte(1)).default(1),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPostProcessingDesaturateImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * DesaturateOutput
 */
export const zPostProcessingDesaturateOutput = z.object({
    images: z.array(zFalAiPostProcessingDesaturateImage)
});

/**
 * ColorTintInput
 */
export const zPostProcessingColorTintInput = z.object({
    tint_strength: z.optional(z.number().gte(0.1).lte(1)).default(1),
    tint_mode: z.optional(z.enum([
        'sepia',
        'red',
        'green',
        'blue',
        'cyan',
        'magenta',
        'yellow',
        'purple',
        'orange',
        'warm',
        'cool',
        'lime',
        'navy',
        'vintage',
        'rose',
        'teal',
        'maroon',
        'peach',
        'lavender',
        'olive'
    ])),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPostProcessingColorTintImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ColorTintOutput
 */
export const zPostProcessingColorTintOutput = z.object({
    images: z.array(zFalAiPostProcessingColorTintImage)
});

/**
 * ColorCorrectionInput
 */
export const zPostProcessingColorCorrectionInput = z.object({
    gamma: z.optional(z.number().gte(0.2).lte(2.2)).default(1),
    saturation: z.optional(z.number().gte(-100).lte(100)).default(0),
    temperature: z.optional(z.number().gte(-100).lte(100)).default(0),
    brightness: z.optional(z.number().gte(-100).lte(100)).default(0),
    contrast: z.optional(z.number().gte(-100).lte(100)).default(0),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPostProcessingColorCorrectionImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ColorCorrectionOutput
 */
export const zPostProcessingColorCorrectionOutput = z.object({
    images: z.array(zFalAiPostProcessingColorCorrectionImage)
});

/**
 * ChromaticAberrationInput
 */
export const zPostProcessingChromaticAberrationInput = z.object({
    blue_shift: z.optional(z.int().gte(-20).lte(20)).default(0),
    red_shift: z.optional(z.int().gte(-20).lte(20)).default(0),
    green_direction: z.optional(z.enum(['horizontal', 'vertical'])),
    blue_direction: z.optional(z.enum(['horizontal', 'vertical'])),
    red_direction: z.optional(z.enum(['horizontal', 'vertical'])),
    image_url: z.string(),
    green_shift: z.optional(z.int().gte(-20).lte(20)).default(0)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPostProcessingChromaticAberrationImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ChromaticAberrationOutput
 */
export const zPostProcessingChromaticAberrationOutput = z.object({
    images: z.array(zFalAiPostProcessingChromaticAberrationImage)
});

/**
 * BlurInput
 */
export const zPostProcessingBlurInput = z.object({
    blur_sigma: z.optional(z.number().gte(0.1).lte(10)).default(1),
    blur_radius: z.optional(z.int().gte(0).lte(31)).default(3),
    blur_type: z.optional(z.enum(['gaussian', 'kuwahara'])),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPostProcessingBlurImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * BlurOutput
 */
export const zPostProcessingBlurOutput = z.object({
    images: z.array(zFalAiPostProcessingBlurImage)
});

/**
 * YouTubeThumbnailsInput
 *
 * Input model for YouTube thumbnails endpoint.
 */
export const zImageEditingYoutubeThumbnailsInput = z.object({
    prompt: z.optional(z.string()).default('Generate youtube thumbnails'),
    lora_scale: z.optional(z.number().gte(0).lte(4)).default(0.5),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    seed: z.optional(z.int()),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(30),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingYoutubeThumbnailsImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * YouTubeThumbnailsOutput
 */
export const zImageEditingYoutubeThumbnailsOutput = z.object({
    images: z.array(zFalAiImageEditingYoutubeThumbnailsImage),
    seed: z.int()
});

/**
 * ImageUpscaleRequest
 */
export const zTopazUpscaleImageInput = z.object({
    face_enhancement_creativity: z.optional(z.number().gte(0).lte(1)).default(0),
    face_enhancement_strength: z.optional(z.number().gte(0).lte(1)).default(0.8),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    face_enhancement: z.optional(z.boolean()).default(true),
    subject_detection: z.optional(z.enum([
        'All',
        'Foreground',
        'Background'
    ])),
    model: z.optional(z.enum([
        'Low Resolution V2',
        'Standard V2',
        'CGI',
        'High Fidelity V2',
        'Text Refine',
        'Recovery',
        'Redefine',
        'Recovery V2'
    ])),
    image_url: z.string(),
    upscale_factor: z.optional(z.number().gte(1).lte(4)).default(2),
    crop_to_fill: z.optional(z.boolean()).default(false)
});

/**
 * File
 */
export const zFalAiTopazUpscaleImageFile = z.object({
    file_size: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    url: z.string(),
    file_data: z.optional(z.string())
});

/**
 * ImageUpscaleOutput
 */
export const zTopazUpscaleImageOutput = z.object({
    image: zFalAiTopazUpscaleImageFile
});

/**
 * BroccoliHaircutInput
 *
 * Input model for broccoli haircut endpoint.
 */
export const zImageEditingBroccoliHaircutInput = z.object({
    lora_scale: z.optional(z.number().gte(0).lte(4)).default(1),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    seed: z.optional(z.int()),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(30),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingBroccoliHaircutImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * BroccoliHaircutOutput
 */
export const zImageEditingBroccoliHaircutOutput = z.object({
    images: z.array(zFalAiImageEditingBroccoliHaircutImage),
    seed: z.int()
});

/**
 * WojakStyleInput
 *
 * Input model for wojak style endpoint.
 */
export const zImageEditingWojakStyleInput = z.object({
    lora_scale: z.optional(z.number().gte(0).lte(4)).default(1),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    seed: z.optional(z.int()),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(30),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingWojakStyleImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * WojakStyleOutput
 */
export const zImageEditingWojakStyleOutput = z.object({
    images: z.array(zFalAiImageEditingWojakStyleImage),
    seed: z.int()
});

/**
 * PlushieStyleInput
 *
 * Input model for plushie style endpoint.
 */
export const zImageEditingPlushieStyleInput = z.object({
    lora_scale: z.optional(z.number().gte(0).lte(4)).default(1),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    seed: z.optional(z.int()),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(30),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingPlushieStyleImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * PlushieStyleOutput
 */
export const zImageEditingPlushieStyleOutput = z.object({
    images: z.array(zFalAiImageEditingPlushieStyleImage),
    seed: z.int()
});

/**
 * LoraWeight
 */
export const zFalAiFluxKontextLoraLoraWeight = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(4)).default(1)
});

/**
 * BaseKontextEditInput
 */
export const zFluxKontextLoraInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    resolution_mode: z.optional(z.enum([
        'auto',
        'match_input',
        '1:1',
        '16:9',
        '21:9',
        '3:2',
        '2:3',
        '4:5',
        '5:4',
        '3:4',
        '4:3',
        '9:16',
        '9:21'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    loras: z.optional(z.array(zFalAiFluxKontextLoraLoraWeight)).default([]),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(2.5),
    num_inference_steps: z.optional(z.int().gte(10).lte(50)).default(30),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    seed: z.optional(z.int())
});

/**
 * Image
 */
export const zFalAiFluxKontextLoraImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * KontextEditOutput
 */
export const zFluxKontextLoraOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxKontextLoraImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * V16Input
 */
export const zFashnTryonV16Input = z.object({
    model_image: z.string(),
    moderation_level: z.optional(z.enum([
        'none',
        'permissive',
        'conservative'
    ])),
    garment_photo_type: z.optional(z.enum([
        'auto',
        'model',
        'flat-lay'
    ])),
    garment_image: z.string(),
    category: z.optional(z.enum([
        'tops',
        'bottoms',
        'one-pieces',
        'auto'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    segmentation_free: z.optional(z.boolean()).default(true),
    num_samples: z.optional(z.int().gte(1).lte(4)).default(1),
    mode: z.optional(z.enum([
        'performance',
        'balanced',
        'quality'
    ])),
    seed: z.optional(z.int()),
    output_format: z.optional(z.enum(['png', 'jpeg']))
});

/**
 * File
 */
export const zFalAiFashnTryonV16File = z.object({
    file_size: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    url: z.string(),
    file_data: z.optional(z.string())
});

/**
 * V16Output
 */
export const zFashnTryonV16Output = z.object({
    images: z.array(zFalAiFashnTryonV16File)
});

/**
 * Input
 */
export const zChainOfZoomInput = z.object({
    sync_mode: z.optional(z.boolean()).default(false),
    center_y: z.optional(z.number().gte(0).lte(1)).default(0.5),
    scale: z.optional(z.number().gte(1).lte(8)).default(5),
    center_x: z.optional(z.number().gte(0).lte(1)).default(0.5),
    user_prompt: z.optional(z.string()).default(''),
    image_url: z.string()
});

/**
 * Image
 */
export const zFalAiChainOfZoomImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zChainOfZoomOutput = z.object({
    images: z.array(zFalAiChainOfZoomImage),
    zoom_center: z.array(z.number()),
    scale: z.number()
});

/**
 * Input
 */
export const zPasdInput = z.object({
    conditioning_scale: z.optional(z.number().gte(0.1).lte(1)).default(0.8),
    prompt: z.optional(z.string()).default(''),
    image_url: z.string(),
    steps: z.optional(z.int().gte(10).lte(50)).default(25),
    scale: z.optional(z.int().gte(1).lte(4)).default(2),
    guidance_scale: z.optional(z.number().gte(1).lte(20)).default(7),
    negative_prompt: z.optional(z.string()).default('blurry, dirty, messy, frames, deformed, dotted, noise, raster lines, unclear, lowres, over-smoothed, painting, ai generated')
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPasdImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * Output
 */
export const zPasdOutput = z.object({
    images: z.array(zFalAiPasdImage),
    timings: z.optional(z.record(z.string(), z.number()))
});

/**
 * BBoxPromptBase
 */
export const zBBoxPromptBase = z.object({
    y_min: z.optional(z.number().gte(0).lte(1)).default(0),
    x_max: z.optional(z.number().gte(0).lte(1)).default(0),
    x_min: z.optional(z.number().gte(0).lte(1)).default(0),
    y_max: z.optional(z.number().gte(0).lte(1)).default(0)
});

/**
 * BboxInput
 */
export const zObjectRemovalBboxInput = z.object({
    model: z.optional(z.enum([
        'low_quality',
        'medium_quality',
        'high_quality',
        'best_quality'
    ])),
    mask_expansion: z.optional(z.int().gte(0).lte(50)).default(15),
    box_prompts: z.optional(z.array(zBBoxPromptBase)).default([]),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiObjectRemovalBboxImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * Output
 */
export const zObjectRemovalBboxOutput = z.object({
    images: z.array(zFalAiObjectRemovalBboxImage)
});

/**
 * MaskInput
 */
export const zObjectRemovalMaskInput = z.object({
    model: z.optional(z.enum([
        'low_quality',
        'medium_quality',
        'high_quality',
        'best_quality'
    ])),
    mask_expansion: z.optional(z.int().gte(0).lte(50)).default(15),
    mask_url: z.string(),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiObjectRemovalMaskImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * Output
 */
export const zObjectRemovalMaskOutput = z.object({
    images: z.array(zFalAiObjectRemovalMaskImage)
});

/**
 * PromptInput
 */
export const zObjectRemovalInput = z.object({
    prompt: z.string(),
    mask_expansion: z.optional(z.int().gte(0).lte(50)).default(15),
    model: z.optional(z.enum([
        'low_quality',
        'medium_quality',
        'high_quality',
        'best_quality'
    ])),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiObjectRemovalImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * Output
 */
export const zObjectRemovalOutput = z.object({
    images: z.array(zFalAiObjectRemovalImage)
});

/**
 * VectorizeInput
 */
export const zRecraftVectorizeInput = z.object({
    image_url: z.string()
});

/**
 * File
 */
export const zFalAiRecraftVectorizeFile = z.object({
    file_size: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    url: z.string(),
    file_data: z.optional(z.string())
});

/**
 * VectorizeOutput
 */
export const zRecraftVectorizeOutput = z.object({
    image: zFalAiRecraftVectorizeFile
});

/**
 * FrameInput
 */
export const zFfmpegApiExtractFrameInput = z.object({
    video_url: z.string(),
    frame_type: z.optional(z.enum([
        'first',
        'middle',
        'last'
    ]))
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFfmpegApiExtractFrameImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * FrameOutput
 */
export const zFfmpegApiExtractFrameOutput = z.object({
    images: z.array(zFalAiFfmpegApiExtractFrameImage)
});

/**
 * ModifyImageRequest
 */
export const zLumaPhotonFlashModifyInput = z.object({
    prompt: z.optional(z.string().min(3).max(5000)),
    aspect_ratio: z.enum([
        '1:1',
        '16:9',
        '9:16',
        '4:3',
        '3:4',
        '21:9',
        '9:21'
    ]),
    strength: z.number().gte(0).lte(1),
    image_url: z.string()
});

/**
 * File
 */
export const zFalAiLumaPhotonFlashModifyFile = z.object({
    file_size: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    url: z.string(),
    file_data: z.optional(z.string())
});

/**
 * T2IOutput
 */
export const zLumaPhotonFlashModifyOutput = z.object({
    images: z.array(zFalAiLumaPhotonFlashModifyFile)
});

/**
 * ModifyImageRequest
 */
export const zLumaPhotonModifyInput = z.object({
    prompt: z.optional(z.string().min(3).max(5000)),
    aspect_ratio: z.enum([
        '1:1',
        '16:9',
        '9:16',
        '4:3',
        '3:4',
        '21:9',
        '9:21'
    ]),
    strength: z.number().gte(0).lte(1),
    image_url: z.string()
});

/**
 * File
 */
export const zFalAiLumaPhotonModifyFile = z.object({
    file_size: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    url: z.string(),
    file_data: z.optional(z.string())
});

/**
 * T2IOutput
 */
export const zLumaPhotonModifyOutput = z.object({
    images: z.array(zFalAiLumaPhotonModifyFile)
});

/**
 * ReframeInput
 */
export const zImageEditingReframeInput = z.object({
    aspect_ratio: z.optional(z.enum([
        '21:9',
        '16:9',
        '4:3',
        '3:2',
        '1:1',
        '2:3',
        '3:4',
        '9:16',
        '9:21'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5',
        '6'
    ])),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(30),
    seed: z.optional(z.int())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingReframeImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ReframeOutput
 */
export const zImageEditingReframeOutput = z.object({
    images: z.array(zFalAiImageEditingReframeImage),
    seed: z.int()
});

/**
 * BabyVersionInput
 *
 * Input model for baby version endpoint.
 */
export const zImageEditingBabyVersionInput = z.object({
    aspect_ratio: z.optional(z.enum([
        '21:9',
        '16:9',
        '4:3',
        '3:2',
        '1:1',
        '2:3',
        '3:4',
        '9:16',
        '9:21'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5',
        '6'
    ])),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(30),
    seed: z.optional(z.int())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingBabyVersionImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * BabyVersionOutput
 */
export const zImageEditingBabyVersionOutput = z.object({
    images: z.array(zFalAiImageEditingBabyVersionImage),
    seed: z.int()
});

/**
 * ReframeImageRequest
 */
export const zLumaPhotonFlashReframeInput = z.object({
    prompt: z.optional(z.string().min(3).max(5000)),
    aspect_ratio: z.enum([
        '1:1',
        '16:9',
        '9:16',
        '4:3',
        '3:4',
        '21:9',
        '9:21'
    ]),
    y_start: z.optional(z.int()),
    x_end: z.optional(z.int()),
    y_end: z.optional(z.int()),
    grid_position_y: z.optional(z.int()),
    image_url: z.string(),
    grid_position_x: z.optional(z.int()),
    x_start: z.optional(z.int())
});

/**
 * File
 */
export const zFalAiLumaPhotonFlashReframeFile = z.object({
    file_size: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    url: z.string(),
    file_data: z.optional(z.string())
});

/**
 * T2IOutput
 */
export const zLumaPhotonFlashReframeOutput = z.object({
    images: z.array(zFalAiLumaPhotonFlashReframeFile)
});

/**
 * ReframeImageRequest
 */
export const zLumaPhotonReframeInput = z.object({
    prompt: z.optional(z.string().min(3).max(5000)),
    aspect_ratio: z.enum([
        '1:1',
        '16:9',
        '9:16',
        '4:3',
        '3:4',
        '21:9',
        '9:21'
    ]),
    y_start: z.optional(z.int()),
    x_end: z.optional(z.int()),
    y_end: z.optional(z.int()),
    grid_position_y: z.optional(z.int()),
    image_url: z.string(),
    grid_position_x: z.optional(z.int()),
    x_start: z.optional(z.int())
});

/**
 * File
 */
export const zFalAiLumaPhotonReframeFile = z.object({
    file_size: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    url: z.string(),
    file_data: z.optional(z.string())
});

/**
 * T2IOutput
 */
export const zLumaPhotonReframeOutput = z.object({
    images: z.array(zFalAiLumaPhotonReframeFile)
});

/**
 * ImageSize
 */
export const zFalAiFlux1SchnellReduxImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * SchnellFlux1ReduxInput
 */
export const zFlux1SchnellReduxInput = z.object({
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiFlux1SchnellReduxImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    num_inference_steps: z.optional(z.int().gte(1).lte(12)).default(4),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * Image
 */
export const zFalAiFlux1SchnellReduxImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFlux1SchnellReduxOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFlux1SchnellReduxImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiFlux1DevReduxImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * BaseFlux1ReduxInput
 */
export const zFlux1DevReduxInput = z.object({
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiFlux1DevReduxImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    guidance_scale: z.optional(z.number().gte(1).lte(20)).default(3.5)
});

/**
 * Image
 */
export const zFalAiFlux1DevReduxImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFlux1DevReduxOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFlux1DevReduxImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * BaseFlux1ImageToInput
 */
export const zFlux1DevImageToImageInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.95),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    num_inference_steps: z.optional(z.int().gte(10).lte(50)).default(40),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    guidance_scale: z.optional(z.number().gte(1).lte(20)).default(3.5)
});

/**
 * Image
 */
export const zFalAiFlux1DevImageToImageImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFlux1DevImageToImageOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFlux1DevImageToImageImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * TextRemovalInput
 *
 * Input model for text removal endpoint.
 */
export const zImageEditingTextRemovalInput = z.object({
    aspect_ratio: z.optional(z.enum([
        '21:9',
        '16:9',
        '4:3',
        '3:2',
        '1:1',
        '2:3',
        '3:4',
        '9:16',
        '9:21'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5',
        '6'
    ])),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(30),
    seed: z.optional(z.int())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingTextRemovalImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * TextRemovalOutput
 */
export const zImageEditingTextRemovalOutput = z.object({
    images: z.array(zFalAiImageEditingTextRemovalImage),
    seed: z.int()
});

/**
 * PhotoRestorationInput
 *
 * Input model for photo restoration endpoint.
 */
export const zImageEditingPhotoRestorationInput = z.object({
    aspect_ratio: z.optional(z.enum([
        '21:9',
        '16:9',
        '4:3',
        '3:2',
        '1:1',
        '2:3',
        '3:4',
        '9:16',
        '9:21'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5',
        '6'
    ])),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(30),
    seed: z.optional(z.int())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingPhotoRestorationImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * PhotoRestorationOutput
 */
export const zImageEditingPhotoRestorationOutput = z.object({
    images: z.array(zFalAiImageEditingPhotoRestorationImage),
    seed: z.int()
});

/**
 * WeatherEffectInput
 */
export const zImageEditingWeatherEffectInput = z.object({
    prompt: z.optional(z.string()).default('heavy snowfall'),
    aspect_ratio: z.optional(z.enum([
        '21:9',
        '16:9',
        '4:3',
        '3:2',
        '1:1',
        '2:3',
        '3:4',
        '9:16',
        '9:21'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5',
        '6'
    ])),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(30),
    seed: z.optional(z.int())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingWeatherEffectImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * WeatherEffectOutput
 */
export const zImageEditingWeatherEffectOutput = z.object({
    images: z.array(zFalAiImageEditingWeatherEffectImage),
    seed: z.int()
});

/**
 * TimeOfDayInput
 */
export const zImageEditingTimeOfDayInput = z.object({
    prompt: z.optional(z.string()).default('golden hour'),
    aspect_ratio: z.optional(z.enum([
        '21:9',
        '16:9',
        '4:3',
        '3:2',
        '1:1',
        '2:3',
        '3:4',
        '9:16',
        '9:21'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5',
        '6'
    ])),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(30),
    seed: z.optional(z.int())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingTimeOfDayImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * TimeOfDayOutput
 */
export const zImageEditingTimeOfDayOutput = z.object({
    images: z.array(zFalAiImageEditingTimeOfDayImage),
    seed: z.int()
});

/**
 * StyleTransferInput
 */
export const zImageEditingStyleTransferInput = z.object({
    prompt: z.optional(z.string()).default('Van Gogh\'s Starry Night'),
    aspect_ratio: z.optional(z.enum([
        '21:9',
        '16:9',
        '4:3',
        '3:2',
        '1:1',
        '2:3',
        '3:4',
        '9:16',
        '9:21'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5',
        '6'
    ])),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(30),
    seed: z.optional(z.int())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingStyleTransferImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * StyleTransferOutput
 */
export const zImageEditingStyleTransferOutput = z.object({
    images: z.array(zFalAiImageEditingStyleTransferImage),
    seed: z.int()
});

/**
 * SceneCompositionInput
 */
export const zImageEditingSceneCompositionInput = z.object({
    prompt: z.optional(z.string()).default('enchanted forest'),
    aspect_ratio: z.optional(z.enum([
        '21:9',
        '16:9',
        '4:3',
        '3:2',
        '1:1',
        '2:3',
        '3:4',
        '9:16',
        '9:21'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5',
        '6'
    ])),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(30),
    seed: z.optional(z.int())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingSceneCompositionImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * SceneCompositionOutput
 */
export const zImageEditingSceneCompositionOutput = z.object({
    images: z.array(zFalAiImageEditingSceneCompositionImage),
    seed: z.int()
});

/**
 * BaseInput
 */
export const zImageEditingProfessionalPhotoInput = z.object({
    aspect_ratio: z.optional(z.enum([
        '21:9',
        '16:9',
        '4:3',
        '3:2',
        '1:1',
        '2:3',
        '3:4',
        '9:16',
        '9:21'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5',
        '6'
    ])),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(30),
    seed: z.optional(z.int())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingProfessionalPhotoImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ProfessionalPhotoOutput
 */
export const zImageEditingProfessionalPhotoOutput = z.object({
    images: z.array(zFalAiImageEditingProfessionalPhotoImage),
    seed: z.int()
});

/**
 * ObjectRemovalInput
 */
export const zImageEditingObjectRemovalInput = z.object({
    prompt: z.optional(z.string()).default('background people'),
    aspect_ratio: z.optional(z.enum([
        '21:9',
        '16:9',
        '4:3',
        '3:2',
        '1:1',
        '2:3',
        '3:4',
        '9:16',
        '9:21'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5',
        '6'
    ])),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(30),
    seed: z.optional(z.int())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingObjectRemovalImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ObjectRemovalOutput
 */
export const zImageEditingObjectRemovalOutput = z.object({
    images: z.array(zFalAiImageEditingObjectRemovalImage),
    seed: z.int()
});

/**
 * HairChangeInput
 */
export const zImageEditingHairChangeInput = z.object({
    prompt: z.optional(z.string()).default('bald'),
    aspect_ratio: z.optional(z.enum([
        '21:9',
        '16:9',
        '4:3',
        '3:2',
        '1:1',
        '2:3',
        '3:4',
        '9:16',
        '9:21'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5',
        '6'
    ])),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(30),
    seed: z.optional(z.int())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingHairChangeImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * HairChangeOutput
 */
export const zImageEditingHairChangeOutput = z.object({
    images: z.array(zFalAiImageEditingHairChangeImage),
    seed: z.int()
});

/**
 * BaseInput
 */
export const zImageEditingFaceEnhancementInput = z.object({
    aspect_ratio: z.optional(z.enum([
        '21:9',
        '16:9',
        '4:3',
        '3:2',
        '1:1',
        '2:3',
        '3:4',
        '9:16',
        '9:21'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5',
        '6'
    ])),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(30),
    seed: z.optional(z.int())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingFaceEnhancementImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * FaceEnhancementOutput
 */
export const zImageEditingFaceEnhancementOutput = z.object({
    images: z.array(zFalAiImageEditingFaceEnhancementImage),
    seed: z.int()
});

/**
 * ExpressionChangeInput
 */
export const zImageEditingExpressionChangeInput = z.object({
    prompt: z.optional(z.string()).default('sad'),
    aspect_ratio: z.optional(z.enum([
        '21:9',
        '16:9',
        '4:3',
        '3:2',
        '1:1',
        '2:3',
        '3:4',
        '9:16',
        '9:21'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5',
        '6'
    ])),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(30),
    seed: z.optional(z.int())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingExpressionChangeImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ExpressionChangeOutput
 */
export const zImageEditingExpressionChangeOutput = z.object({
    images: z.array(zFalAiImageEditingExpressionChangeImage),
    seed: z.int()
});

/**
 * BaseInput
 */
export const zImageEditingColorCorrectionInput = z.object({
    aspect_ratio: z.optional(z.enum([
        '21:9',
        '16:9',
        '4:3',
        '3:2',
        '1:1',
        '2:3',
        '3:4',
        '9:16',
        '9:21'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5',
        '6'
    ])),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(30),
    seed: z.optional(z.int())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingColorCorrectionImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ColorCorrectionOutput
 */
export const zImageEditingColorCorrectionOutput = z.object({
    images: z.array(zFalAiImageEditingColorCorrectionImage),
    seed: z.int()
});

/**
 * BaseInput
 */
export const zImageEditingCartoonifyInput = z.object({
    aspect_ratio: z.optional(z.enum([
        '21:9',
        '16:9',
        '4:3',
        '3:2',
        '1:1',
        '2:3',
        '3:4',
        '9:16',
        '9:21'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5',
        '6'
    ])),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(30),
    seed: z.optional(z.int())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingCartoonifyImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * CartoonifyOutput
 */
export const zImageEditingCartoonifyOutput = z.object({
    images: z.array(zFalAiImageEditingCartoonifyImage),
    seed: z.int()
});

/**
 * BackgroundChangeInput
 */
export const zImageEditingBackgroundChangeInput = z.object({
    prompt: z.optional(z.string()).default('beach sunset with palm trees'),
    aspect_ratio: z.optional(z.enum([
        '21:9',
        '16:9',
        '4:3',
        '3:2',
        '1:1',
        '2:3',
        '3:4',
        '9:16',
        '9:21'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5',
        '6'
    ])),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(30),
    seed: z.optional(z.int())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingBackgroundChangeImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * BackgroundChangeOutput
 */
export const zImageEditingBackgroundChangeOutput = z.object({
    images: z.array(zFalAiImageEditingBackgroundChangeImage),
    seed: z.int()
});

/**
 * AgeProgressionInput
 */
export const zImageEditingAgeProgressionInput = z.object({
    prompt: z.optional(z.string()).default('20 years older'),
    aspect_ratio: z.optional(z.enum([
        '21:9',
        '16:9',
        '4:3',
        '3:2',
        '1:1',
        '2:3',
        '3:4',
        '9:16',
        '9:21'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5',
        '6'
    ])),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(30),
    seed: z.optional(z.int())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageEditingAgeProgressionImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * AgeProgressionOutput
 */
export const zImageEditingAgeProgressionOutput = z.object({
    images: z.array(zFalAiImageEditingAgeProgressionImage),
    seed: z.int()
});

/**
 * FluxKontextMultiInput
 */
export const zFluxProKontextMaxMultiInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    aspect_ratio: z.optional(z.enum([
        '21:9',
        '16:9',
        '4:3',
        '3:2',
        '1:1',
        '2:3',
        '3:4',
        '9:16',
        '9:21'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5',
        '6'
    ])),
    guidance_scale: z.optional(z.number().gte(1).lte(20)).default(3.5),
    seed: z.optional(z.int()),
    image_urls: z.array(z.string()),
    enhance_prompt: z.optional(z.boolean()).default(false)
});

/**
 * Image
 */
export const zRegistryImageFastSdxlModelsImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFluxProKontextMaxMultiOutput = z.object({
    prompt: z.string(),
    images: z.array(zRegistryImageFastSdxlModelsImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * FluxKontextMultiInput
 */
export const zFluxProKontextMultiInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    aspect_ratio: z.optional(z.enum([
        '21:9',
        '16:9',
        '4:3',
        '3:2',
        '1:1',
        '2:3',
        '3:4',
        '9:16',
        '9:21'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5',
        '6'
    ])),
    guidance_scale: z.optional(z.number().gte(1).lte(20)).default(3.5),
    seed: z.optional(z.int()),
    image_urls: z.array(z.string()),
    enhance_prompt: z.optional(z.boolean()).default(false)
});

/**
 * Image
 */
export const zFalAiFluxProKontextMultiRegistryImageFastSdxlModelsImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFluxProKontextMultiOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxProKontextMultiRegistryImageFastSdxlModelsImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * FluxKontextInput
 */
export const zFluxProKontextMaxInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    aspect_ratio: z.optional(z.enum([
        '21:9',
        '16:9',
        '4:3',
        '3:2',
        '1:1',
        '2:3',
        '3:4',
        '9:16',
        '9:21'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5',
        '6'
    ])),
    guidance_scale: z.optional(z.number().gte(1).lte(20)).default(3.5),
    seed: z.optional(z.int()),
    enhance_prompt: z.optional(z.boolean()).default(false)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalToolkitImageImageImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * FluxKontextOutput
 */
export const zFluxProKontextMaxOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalToolkitImageImageImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * BaseKontextEditInput
 */
export const zFluxKontextDevInput = z.object({
    prompt: z.string(),
    resolution_mode: z.optional(z.enum([
        'auto',
        'match_input',
        '1:1',
        '16:9',
        '21:9',
        '3:2',
        '2:3',
        '4:5',
        '5:4',
        '3:4',
        '4:3',
        '9:16',
        '9:21'
    ])),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(1).lte(20)).default(2.5),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    num_inference_steps: z.optional(z.int().gte(10).lte(50)).default(28)
});

/**
 * Image
 */
export const zFalAiFluxKontextDevImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * KontextEditOutput
 */
export const zFluxKontextDevOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxKontextDevImage),
    seed: z.int(),
    has_nsfw_concepts: z.array(z.boolean()),
    timings: z.record(z.string(), z.number())
});

/**
 * FluxKontextInput
 */
export const zFluxProKontextInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    aspect_ratio: z.optional(z.enum([
        '21:9',
        '16:9',
        '4:3',
        '3:2',
        '1:1',
        '2:3',
        '3:4',
        '9:16',
        '9:21'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5',
        '6'
    ])),
    guidance_scale: z.optional(z.number().gte(1).lte(20)).default(3.5),
    seed: z.optional(z.int()),
    enhance_prompt: z.optional(z.boolean()).default(false)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFluxProKontextFalToolkitImageImageImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * FluxKontextOutput
 */
export const zFluxProKontextOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxProKontextFalToolkitImageImageImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageEditInput
 */
export const zBagelEditInput = z.object({
    prompt: z.string(),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    seed: z.optional(z.int()),
    use_thought: z.optional(z.boolean()).default(false),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBagelEditImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ImageEditOutput
 */
export const zBagelEditOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiBagelEditImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageInput
 */
export const zRembgEnhanceInput = z.object({
    image_url: z.string()
});

/**
 * File
 */
export const zSmoretalkAiRembgEnhanceFile = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string()
});

/**
 * ImageOutput
 */
export const zRembgEnhanceOutput = z.object({
    image: zSmoretalkAiRembgEnhanceFile
});

/**
 * UpscaleInput
 */
export const zRecraftUpscaleCreativeInput = z.object({
    sync_mode: z.optional(z.boolean()).default(false),
    enable_safety_checker: z.optional(z.boolean()).default(false),
    image_url: z.string()
});

/**
 * File
 */
export const zFalAiRecraftUpscaleCreativeFile = z.object({
    file_size: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    url: z.string(),
    file_data: z.optional(z.string())
});

/**
 * UpscaleOutput
 */
export const zRecraftUpscaleCreativeOutput = z.object({
    image: zFalAiRecraftUpscaleCreativeFile
});

/**
 * UpscaleInput
 */
export const zRecraftUpscaleCrispInput = z.object({
    sync_mode: z.optional(z.boolean()).default(false),
    enable_safety_checker: z.optional(z.boolean()).default(false),
    image_url: z.string()
});

/**
 * File
 */
export const zFalAiRecraftUpscaleCrispFile = z.object({
    file_size: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    url: z.string(),
    file_data: z.optional(z.string())
});

/**
 * UpscaleOutput
 */
export const zRecraftUpscaleCrispOutput = z.object({
    image: zFalAiRecraftUpscaleCrispFile
});

/**
 * RGBColor
 */
export const zFalAiRecraftV3ImageToImageRgbColor = z.object({
    r: z.optional(z.int().gte(0).lte(255)).default(0),
    b: z.optional(z.int().gte(0).lte(255)).default(0),
    g: z.optional(z.int().gte(0).lte(255)).default(0)
});

/**
 * ImageToImageInput
 */
export const zRecraftV3ImageToImageInput = z.object({
    prompt: z.string().max(1000),
    style: z.optional(z.enum([
        'any',
        'realistic_image',
        'digital_illustration',
        'vector_illustration',
        'realistic_image/b_and_w',
        'realistic_image/hard_flash',
        'realistic_image/hdr',
        'realistic_image/natural_light',
        'realistic_image/studio_portrait',
        'realistic_image/enterprise',
        'realistic_image/motion_blur',
        'realistic_image/evening_light',
        'realistic_image/faded_nostalgia',
        'realistic_image/forest_life',
        'realistic_image/mystic_naturalism',
        'realistic_image/natural_tones',
        'realistic_image/organic_calm',
        'realistic_image/real_life_glow',
        'realistic_image/retro_realism',
        'realistic_image/retro_snapshot',
        'realistic_image/urban_drama',
        'realistic_image/village_realism',
        'realistic_image/warm_folk',
        'digital_illustration/pixel_art',
        'digital_illustration/hand_drawn',
        'digital_illustration/grain',
        'digital_illustration/infantile_sketch',
        'digital_illustration/2d_art_poster',
        'digital_illustration/handmade_3d',
        'digital_illustration/hand_drawn_outline',
        'digital_illustration/engraving_color',
        'digital_illustration/2d_art_poster_2',
        'digital_illustration/antiquarian',
        'digital_illustration/bold_fantasy',
        'digital_illustration/child_book',
        'digital_illustration/child_books',
        'digital_illustration/cover',
        'digital_illustration/crosshatch',
        'digital_illustration/digital_engraving',
        'digital_illustration/expressionism',
        'digital_illustration/freehand_details',
        'digital_illustration/grain_20',
        'digital_illustration/graphic_intensity',
        'digital_illustration/hard_comics',
        'digital_illustration/long_shadow',
        'digital_illustration/modern_folk',
        'digital_illustration/multicolor',
        'digital_illustration/neon_calm',
        'digital_illustration/noir',
        'digital_illustration/nostalgic_pastel',
        'digital_illustration/outline_details',
        'digital_illustration/pastel_gradient',
        'digital_illustration/pastel_sketch',
        'digital_illustration/pop_art',
        'digital_illustration/pop_renaissance',
        'digital_illustration/street_art',
        'digital_illustration/tablet_sketch',
        'digital_illustration/urban_glow',
        'digital_illustration/urban_sketching',
        'digital_illustration/vanilla_dreams',
        'digital_illustration/young_adult_book',
        'digital_illustration/young_adult_book_2',
        'vector_illustration/bold_stroke',
        'vector_illustration/chemistry',
        'vector_illustration/colored_stencil',
        'vector_illustration/contour_pop_art',
        'vector_illustration/cosmics',
        'vector_illustration/cutout',
        'vector_illustration/depressive',
        'vector_illustration/editorial',
        'vector_illustration/emotional_flat',
        'vector_illustration/infographical',
        'vector_illustration/marker_outline',
        'vector_illustration/mosaic',
        'vector_illustration/naivector',
        'vector_illustration/roundish_flat',
        'vector_illustration/segmented_colors',
        'vector_illustration/sharp_contrast',
        'vector_illustration/thin',
        'vector_illustration/vector_photo',
        'vector_illustration/vivid_shapes',
        'vector_illustration/engraving',
        'vector_illustration/line_art',
        'vector_illustration/line_circuit',
        'vector_illustration/linocut'
    ])),
    style_id: z.optional(z.string()),
    image_url: z.string(),
    strength: z.optional(z.number().gte(0).lte(1)).default(0.5),
    sync_mode: z.optional(z.boolean()).default(false),
    colors: z.optional(z.array(zFalAiRecraftV3ImageToImageRgbColor)).default([]),
    negative_prompt: z.optional(z.string().max(1000))
});

/**
 * File
 */
export const zFalAiRecraftV3ImageToImageFile = z.object({
    file_size: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    url: z.string(),
    file_data: z.optional(z.string())
});

/**
 * ImageToImageOutput
 */
export const zRecraftV3ImageToImageOutput = z.object({
    images: z.array(zFalAiRecraftV3ImageToImageFile)
});

/**
 * MiniMaxTextToImageWithReferenceRequest
 */
export const zMinimaxImage01SubjectReferenceInput = z.object({
    prompt_optimizer: z.optional(z.boolean()).default(false),
    aspect_ratio: z.optional(z.enum([
        '1:1',
        '16:9',
        '4:3',
        '3:2',
        '2:3',
        '3:4',
        '9:16',
        '21:9'
    ])),
    num_images: z.optional(z.int().gte(1).lte(9)).default(1),
    prompt: z.string().min(1).max(1500),
    image_url: z.string()
});

/**
 * File
 */
export const zFalAiMinimaxImage01SubjectReferenceFile = z.object({
    file_size: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    url: z.string(),
    file_data: z.optional(z.string())
});

/**
 * MiniMaxTextToImageWithReferenceOutput
 */
export const zMinimaxImage01SubjectReferenceOutput = z.object({
    images: z.array(zFalAiMinimaxImage01SubjectReferenceFile)
});

/**
 * ImageSize
 */
export const zFalAiHidreamI1FullImageToImageImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * LoraWeight
 */
export const zFalAiHidreamI1FullImageToImageLoraWeight = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(4)).default(1),
    weight_name: z.optional(z.string())
});

/**
 * ImageToImageInput
 */
export const zHidreamI1FullImageToImageInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiHidreamI1FullImageToImageImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    loras: z.optional(z.array(zFalAiHidreamI1FullImageToImageLoraWeight)).default([]),
    strength: z.optional(z.number().gte(0).lte(1)).default(0.75),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(50),
    seed: z.optional(z.int()),
    negative_prompt: z.optional(z.string()).default(''),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * Image
 */
export const zFalAiHidreamI1FullImageToImageImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Img2ImgOutput
 */
export const zHidreamI1FullImageToImageOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiHidreamI1FullImageToImageImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiIdeogramV3ReframeImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * File
 */
export const zFalAiIdeogramV3ReframeFile = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string()
});

/**
 * ReframeOutputV3
 */
export const zIdeogramV3ReframeOutput = z.object({
    images: z.array(zFalAiIdeogramV3ReframeFile),
    seed: z.int()
});

/**
 * RGBColor
 */
export const zFalAiIdeogramV3ReframeRgbColor = z.object({
    r: z.optional(z.int().gte(0).lte(255)).default(0),
    b: z.optional(z.int().gte(0).lte(255)).default(0),
    g: z.optional(z.int().gte(0).lte(255)).default(0)
});

/**
 * ColorPaletteMember
 */
export const zFalAiIdeogramV3ReframeColorPaletteMember = z.object({
    color_weight: z.optional(z.union([
        z.number().gte(0.05).lte(1),
        z.unknown()
    ])),
    rgb: zFalAiIdeogramV3ReframeRgbColor
});

/**
 * ColorPalette
 */
export const zFalAiIdeogramV3ReframeColorPalette = z.object({
    members: z.optional(z.union([
        z.array(zFalAiIdeogramV3ReframeColorPaletteMember),
        z.unknown()
    ])),
    name: z.optional(z.union([
        z.enum([
            'EMBER',
            'FRESH',
            'JUNGLE',
            'MAGIC',
            'MELON',
            'MOSAIC',
            'PASTEL',
            'ULTRAMARINE'
        ]),
        z.unknown()
    ]))
});

/**
 * ReframeImageInputV3
 */
export const zIdeogramV3ReframeInput = z.object({
    num_images: z.optional(z.int().gte(1).lte(8)).default(1),
    image_size: z.union([
        zFalAiIdeogramV3ReframeImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ]),
    style: z.optional(z.union([
        z.enum([
            'AUTO',
            'GENERAL',
            'REALISTIC',
            'DESIGN'
        ]),
        z.unknown()
    ])),
    style_preset: z.optional(z.union([
        z.enum([
            '80S_ILLUSTRATION',
            '90S_NOSTALGIA',
            'ABSTRACT_ORGANIC',
            'ANALOG_NOSTALGIA',
            'ART_BRUT',
            'ART_DECO',
            'ART_POSTER',
            'AURA',
            'AVANT_GARDE',
            'BAUHAUS',
            'BLUEPRINT',
            'BLURRY_MOTION',
            'BRIGHT_ART',
            'C4D_CARTOON',
            'CHILDRENS_BOOK',
            'COLLAGE',
            'COLORING_BOOK_I',
            'COLORING_BOOK_II',
            'CUBISM',
            'DARK_AURA',
            'DOODLE',
            'DOUBLE_EXPOSURE',
            'DRAMATIC_CINEMA',
            'EDITORIAL',
            'EMOTIONAL_MINIMAL',
            'ETHEREAL_PARTY',
            'EXPIRED_FILM',
            'FLAT_ART',
            'FLAT_VECTOR',
            'FOREST_REVERIE',
            'GEO_MINIMALIST',
            'GLASS_PRISM',
            'GOLDEN_HOUR',
            'GRAFFITI_I',
            'GRAFFITI_II',
            'HALFTONE_PRINT',
            'HIGH_CONTRAST',
            'HIPPIE_ERA',
            'ICONIC',
            'JAPANDI_FUSION',
            'JAZZY',
            'LONG_EXPOSURE',
            'MAGAZINE_EDITORIAL',
            'MINIMAL_ILLUSTRATION',
            'MIXED_MEDIA',
            'MONOCHROME',
            'NIGHTLIFE',
            'OIL_PAINTING',
            'OLD_CARTOONS',
            'PAINT_GESTURE',
            'POP_ART',
            'RETRO_ETCHING',
            'RIVIERA_POP',
            'SPOTLIGHT_80S',
            'STYLIZED_RED',
            'SURREAL_COLLAGE',
            'TRAVEL_POSTER',
            'VINTAGE_GEO',
            'VINTAGE_POSTER',
            'WATERCOLOR',
            'WEIRD',
            'WOODBLOCK_PRINT'
        ]),
        z.unknown()
    ])),
    rendering_speed: z.optional(z.enum([
        'TURBO',
        'BALANCED',
        'QUALITY'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    color_palette: z.optional(z.union([
        zFalAiIdeogramV3ReframeColorPalette,
        z.unknown()
    ])),
    style_codes: z.optional(z.union([
        z.array(z.string()),
        z.unknown()
    ])),
    image_url: z.string(),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    image_urls: z.optional(z.union([
        z.array(z.string()),
        z.unknown()
    ]))
});

/**
 * File
 */
export const zFalAiIdeogramV3ReplaceBackgroundFile = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string()
});

/**
 * ReplaceBackgroundOutputV3
 */
export const zIdeogramV3ReplaceBackgroundOutput = z.object({
    images: z.array(zFalAiIdeogramV3ReplaceBackgroundFile),
    seed: z.int()
});

/**
 * RGBColor
 */
export const zFalAiIdeogramV3ReplaceBackgroundRgbColor = z.object({
    r: z.optional(z.int().gte(0).lte(255)).default(0),
    b: z.optional(z.int().gte(0).lte(255)).default(0),
    g: z.optional(z.int().gte(0).lte(255)).default(0)
});

/**
 * ColorPaletteMember
 */
export const zFalAiIdeogramV3ReplaceBackgroundColorPaletteMember = z.object({
    color_weight: z.optional(z.union([
        z.number().gte(0.05).lte(1),
        z.unknown()
    ])),
    rgb: zFalAiIdeogramV3ReplaceBackgroundRgbColor
});

/**
 * ColorPalette
 */
export const zFalAiIdeogramV3ReplaceBackgroundColorPalette = z.object({
    members: z.optional(z.union([
        z.array(zFalAiIdeogramV3ReplaceBackgroundColorPaletteMember),
        z.unknown()
    ])),
    name: z.optional(z.union([
        z.enum([
            'EMBER',
            'FRESH',
            'JUNGLE',
            'MAGIC',
            'MELON',
            'MOSAIC',
            'PASTEL',
            'ULTRAMARINE'
        ]),
        z.unknown()
    ]))
});

/**
 * ReplaceBackgroundInputV3
 */
export const zIdeogramV3ReplaceBackgroundInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(8)).default(1),
    style: z.optional(z.union([
        z.enum([
            'AUTO',
            'GENERAL',
            'REALISTIC',
            'DESIGN'
        ]),
        z.unknown()
    ])),
    style_preset: z.optional(z.union([
        z.enum([
            '80S_ILLUSTRATION',
            '90S_NOSTALGIA',
            'ABSTRACT_ORGANIC',
            'ANALOG_NOSTALGIA',
            'ART_BRUT',
            'ART_DECO',
            'ART_POSTER',
            'AURA',
            'AVANT_GARDE',
            'BAUHAUS',
            'BLUEPRINT',
            'BLURRY_MOTION',
            'BRIGHT_ART',
            'C4D_CARTOON',
            'CHILDRENS_BOOK',
            'COLLAGE',
            'COLORING_BOOK_I',
            'COLORING_BOOK_II',
            'CUBISM',
            'DARK_AURA',
            'DOODLE',
            'DOUBLE_EXPOSURE',
            'DRAMATIC_CINEMA',
            'EDITORIAL',
            'EMOTIONAL_MINIMAL',
            'ETHEREAL_PARTY',
            'EXPIRED_FILM',
            'FLAT_ART',
            'FLAT_VECTOR',
            'FOREST_REVERIE',
            'GEO_MINIMALIST',
            'GLASS_PRISM',
            'GOLDEN_HOUR',
            'GRAFFITI_I',
            'GRAFFITI_II',
            'HALFTONE_PRINT',
            'HIGH_CONTRAST',
            'HIPPIE_ERA',
            'ICONIC',
            'JAPANDI_FUSION',
            'JAZZY',
            'LONG_EXPOSURE',
            'MAGAZINE_EDITORIAL',
            'MINIMAL_ILLUSTRATION',
            'MIXED_MEDIA',
            'MONOCHROME',
            'NIGHTLIFE',
            'OIL_PAINTING',
            'OLD_CARTOONS',
            'PAINT_GESTURE',
            'POP_ART',
            'RETRO_ETCHING',
            'RIVIERA_POP',
            'SPOTLIGHT_80S',
            'STYLIZED_RED',
            'SURREAL_COLLAGE',
            'TRAVEL_POSTER',
            'VINTAGE_GEO',
            'VINTAGE_POSTER',
            'WATERCOLOR',
            'WEIRD',
            'WOODBLOCK_PRINT'
        ]),
        z.unknown()
    ])),
    expand_prompt: z.optional(z.boolean()).default(true),
    rendering_speed: z.optional(z.enum([
        'TURBO',
        'BALANCED',
        'QUALITY'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    color_palette: z.optional(z.union([
        zFalAiIdeogramV3ReplaceBackgroundColorPalette,
        z.unknown()
    ])),
    style_codes: z.optional(z.union([
        z.array(z.string()),
        z.unknown()
    ])),
    image_url: z.string(),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    image_urls: z.optional(z.union([
        z.array(z.string()),
        z.unknown()
    ]))
});

/**
 * ImageSize
 */
export const zFalAiIdeogramV3RemixImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * File
 */
export const zFalAiIdeogramV3RemixFile = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string()
});

/**
 * RemixOutputV3
 */
export const zIdeogramV3RemixOutput = z.object({
    images: z.array(zFalAiIdeogramV3RemixFile),
    seed: z.int()
});

/**
 * RGBColor
 */
export const zFalAiIdeogramV3RemixRgbColor = z.object({
    r: z.optional(z.int().gte(0).lte(255)).default(0),
    b: z.optional(z.int().gte(0).lte(255)).default(0),
    g: z.optional(z.int().gte(0).lte(255)).default(0)
});

/**
 * ColorPaletteMember
 */
export const zFalAiIdeogramV3RemixColorPaletteMember = z.object({
    color_weight: z.optional(z.union([
        z.number().gte(0.05).lte(1),
        z.unknown()
    ])),
    rgb: zFalAiIdeogramV3RemixRgbColor
});

/**
 * ColorPalette
 */
export const zFalAiIdeogramV3RemixColorPalette = z.object({
    members: z.optional(z.union([
        z.array(zFalAiIdeogramV3RemixColorPaletteMember),
        z.unknown()
    ])),
    name: z.optional(z.union([
        z.enum([
            'EMBER',
            'FRESH',
            'JUNGLE',
            'MAGIC',
            'MELON',
            'MOSAIC',
            'PASTEL',
            'ULTRAMARINE'
        ]),
        z.unknown()
    ]))
});

/**
 * RemixImageInputV3
 */
export const zIdeogramV3RemixInput = z.object({
    prompt: z.string(),
    image_size: z.optional(z.union([
        zFalAiIdeogramV3RemixImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.unknown()
    ])),
    style: z.optional(z.union([
        z.enum([
            'AUTO',
            'GENERAL',
            'REALISTIC',
            'DESIGN'
        ]),
        z.unknown()
    ])),
    expand_prompt: z.optional(z.boolean()).default(true),
    rendering_speed: z.optional(z.enum([
        'TURBO',
        'BALANCED',
        'QUALITY'
    ])),
    image_urls: z.optional(z.union([
        z.array(z.string()),
        z.unknown()
    ])),
    negative_prompt: z.optional(z.string()).default(''),
    num_images: z.optional(z.int().gte(1).lte(8)).default(1),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    color_palette: z.optional(z.union([
        zFalAiIdeogramV3RemixColorPalette,
        z.unknown()
    ])),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.8),
    style_codes: z.optional(z.union([
        z.array(z.string()),
        z.unknown()
    ])),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * File
 */
export const zFalAiIdeogramV3EditFile = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string()
});

/**
 * EditOutputV3
 */
export const zIdeogramV3EditOutput = z.object({
    images: z.array(zFalAiIdeogramV3EditFile),
    seed: z.int()
});

/**
 * RGBColor
 */
export const zFalAiIdeogramV3EditRgbColor = z.object({
    r: z.optional(z.int().gte(0).lte(255)).default(0),
    b: z.optional(z.int().gte(0).lte(255)).default(0),
    g: z.optional(z.int().gte(0).lte(255)).default(0)
});

/**
 * ColorPaletteMember
 */
export const zFalAiIdeogramV3EditColorPaletteMember = z.object({
    color_weight: z.optional(z.union([
        z.number().gte(0.05).lte(1),
        z.unknown()
    ])),
    rgb: zFalAiIdeogramV3EditRgbColor
});

/**
 * ColorPalette
 */
export const zFalAiIdeogramV3EditColorPalette = z.object({
    members: z.optional(z.union([
        z.array(zFalAiIdeogramV3EditColorPaletteMember),
        z.unknown()
    ])),
    name: z.optional(z.union([
        z.enum([
            'EMBER',
            'FRESH',
            'JUNGLE',
            'MAGIC',
            'MELON',
            'MOSAIC',
            'PASTEL',
            'ULTRAMARINE'
        ]),
        z.unknown()
    ]))
});

/**
 * EditImageInputV3
 */
export const zIdeogramV3EditInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(8)).default(1),
    style_preset: z.optional(z.union([
        z.enum([
            '80S_ILLUSTRATION',
            '90S_NOSTALGIA',
            'ABSTRACT_ORGANIC',
            'ANALOG_NOSTALGIA',
            'ART_BRUT',
            'ART_DECO',
            'ART_POSTER',
            'AURA',
            'AVANT_GARDE',
            'BAUHAUS',
            'BLUEPRINT',
            'BLURRY_MOTION',
            'BRIGHT_ART',
            'C4D_CARTOON',
            'CHILDRENS_BOOK',
            'COLLAGE',
            'COLORING_BOOK_I',
            'COLORING_BOOK_II',
            'CUBISM',
            'DARK_AURA',
            'DOODLE',
            'DOUBLE_EXPOSURE',
            'DRAMATIC_CINEMA',
            'EDITORIAL',
            'EMOTIONAL_MINIMAL',
            'ETHEREAL_PARTY',
            'EXPIRED_FILM',
            'FLAT_ART',
            'FLAT_VECTOR',
            'FOREST_REVERIE',
            'GEO_MINIMALIST',
            'GLASS_PRISM',
            'GOLDEN_HOUR',
            'GRAFFITI_I',
            'GRAFFITI_II',
            'HALFTONE_PRINT',
            'HIGH_CONTRAST',
            'HIPPIE_ERA',
            'ICONIC',
            'JAPANDI_FUSION',
            'JAZZY',
            'LONG_EXPOSURE',
            'MAGAZINE_EDITORIAL',
            'MINIMAL_ILLUSTRATION',
            'MIXED_MEDIA',
            'MONOCHROME',
            'NIGHTLIFE',
            'OIL_PAINTING',
            'OLD_CARTOONS',
            'PAINT_GESTURE',
            'POP_ART',
            'RETRO_ETCHING',
            'RIVIERA_POP',
            'SPOTLIGHT_80S',
            'STYLIZED_RED',
            'SURREAL_COLLAGE',
            'TRAVEL_POSTER',
            'VINTAGE_GEO',
            'VINTAGE_POSTER',
            'WATERCOLOR',
            'WEIRD',
            'WOODBLOCK_PRINT'
        ]),
        z.unknown()
    ])),
    expand_prompt: z.optional(z.boolean()).default(true),
    rendering_speed: z.optional(z.enum([
        'TURBO',
        'BALANCED',
        'QUALITY'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    color_palette: z.optional(z.union([
        zFalAiIdeogramV3EditColorPalette,
        z.unknown()
    ])),
    style_codes: z.optional(z.union([
        z.array(z.string()),
        z.unknown()
    ])),
    image_url: z.string(),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    image_urls: z.optional(z.union([
        z.array(z.string()),
        z.unknown()
    ])),
    mask_url: z.string()
});

/**
 * TextToImageInput
 */
export const zStep1xEditInput = z.object({
    prompt: z.string(),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    seed: z.optional(z.int()),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(4),
    negative_prompt: z.optional(z.string()).default(''),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(30)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiStep1xEditImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ImageOutput
 */
export const zStep1xEditOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiStep1xEditImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * Image2SVGInput
 */
export const zImage2SvgInput = z.object({
    splice_threshold: z.optional(z.int().gte(0).lte(90)).default(45),
    hierarchical: z.optional(z.enum(['stacked', 'cutout'])),
    color_precision: z.optional(z.int().gte(1).lte(10)).default(6),
    colormode: z.optional(z.enum(['color', 'binary'])),
    max_iterations: z.optional(z.int().gte(1).lte(20)).default(10),
    length_threshold: z.optional(z.number().gte(0).lte(10)).default(4),
    image_url: z.string(),
    mode: z.optional(z.enum(['spline', 'polygon'])),
    corner_threshold: z.optional(z.int().gte(0).lte(180)).default(60),
    path_precision: z.optional(z.int().gte(1).lte(10)).default(3),
    filter_speckle: z.optional(z.int().gte(0).lte(20)).default(4),
    layer_difference: z.optional(z.int().gte(1).lte(32)).default(16)
});

/**
 * File
 */
export const zFalAiImage2SvgFile = z.object({
    file_size: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    url: z.string(),
    file_data: z.optional(z.string())
});

/**
 * Image2SVGOutput
 */
export const zImage2SvgOutput = z.object({
    images: z.array(zFalAiImage2SvgFile)
});

/**
 * ImageSize
 */
export const zFalAiUnoImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * UNOInput
 */
export const zUnoInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiUnoImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    input_image_urls: z.array(z.string()),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(1).lte(20)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28),
    seed: z.optional(z.int()),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiUnoImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * UNOOutput
 */
export const zUnoOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiUnoImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * EditImageRequest
 */
export const zGptImage1EditImageInput = z.object({
    prompt: z.string().min(2),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.enum([
        'auto',
        '1024x1024',
        '1536x1024',
        '1024x1536'
    ])),
    background: z.optional(z.enum([
        'auto',
        'transparent',
        'opaque'
    ])),
    quality: z.optional(z.enum([
        'auto',
        'low',
        'medium',
        'high'
    ])),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    input_fidelity: z.optional(z.enum(['low', 'high'])),
    sync_mode: z.optional(z.boolean()).default(false),
    image_urls: z.array(z.string())
});

/**
 * ImageFile
 */
export const zFalAiGptImage1EditImageImageFile = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * EditImageResponse
 */
export const zGptImage1EditImageOutput = z.object({
    images: z.array(zFalAiGptImage1EditImageImageFile)
});

/**
 * ImageSize
 */
export const zRundiffusionFalJuggernautFluxLoraInpaintingImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * LoraWeight
 */
export const zRundiffusionFalJuggernautFluxLoraInpaintingLoraWeight = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(4)).default(1)
});

/**
 * InpaintInput
 */
export const zJuggernautFluxLoraInpaintingInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zRundiffusionFalJuggernautFluxLoraInpaintingImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    loras: z.optional(z.array(zRundiffusionFalJuggernautFluxLoraInpaintingLoraWeight)).default([]),
    sync_mode: z.optional(z.boolean()).default(false),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.85),
    guidance_scale: z.optional(z.number().gte(0).lte(35)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28),
    mask_url: z.string(),
    seed: z.optional(z.int()),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * Image
 */
export const zRundiffusionFalJuggernautFluxLoraInpaintingImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zJuggernautFluxLoraInpaintingOutput = z.object({
    prompt: z.string(),
    images: z.array(zRundiffusionFalJuggernautFluxLoraInpaintingImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * Input
 */
export const zFashnTryonV15Input = z.object({
    model_image: z.string(),
    moderation_level: z.optional(z.enum([
        'none',
        'permissive',
        'conservative'
    ])),
    garment_photo_type: z.optional(z.enum([
        'auto',
        'model',
        'flat-lay'
    ])),
    garment_image: z.string(),
    category: z.optional(z.enum([
        'tops',
        'bottoms',
        'one-pieces',
        'auto'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    segmentation_free: z.optional(z.boolean()).default(true),
    num_samples: z.optional(z.int().gte(1).lte(4)).default(1),
    mode: z.optional(z.enum([
        'performance',
        'balanced',
        'quality'
    ])),
    seed: z.optional(z.int()),
    output_format: z.optional(z.enum(['png', 'jpeg']))
});

/**
 * File
 */
export const zFalAiFashnTryonV15File = z.object({
    file_size: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    url: z.string(),
    file_data: z.optional(z.string())
});

/**
 * Output
 */
export const zFashnTryonV15Output = z.object({
    images: z.array(zFalAiFashnTryonV15File)
});

/**
 * PlushifyInput
 */
export const zPlushifyInput = z.object({
    prompt: z.optional(z.string()).default(''),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    use_cfg_zero: z.optional(z.boolean()).default(false),
    image_url: z.string(),
    scale: z.optional(z.number().gte(0.1).lte(2)).default(1),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    seed: z.optional(z.int())
});

/**
 * Image
 */
export const zFalAiPlushifyImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zPlushifyOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiPlushifyImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiInstantCharacterImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * TextToImageInput
 */
export const zInstantCharacterInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiInstantCharacterImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    scale: z.optional(z.number().gte(0).lte(2)).default(1),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28),
    seed: z.optional(z.int()),
    negative_prompt: z.optional(z.string()).default(''),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiInstantCharacterImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ImageOutput
 */
export const zInstantCharacterOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiInstantCharacterImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * CartoonifyInput
 */
export const zCartoonifyInput = z.object({
    use_cfg_zero: z.optional(z.boolean()).default(false),
    image_url: z.string(),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28),
    scale: z.optional(z.number().gte(0.1).lte(2)).default(1),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    seed: z.optional(z.int())
});

/**
 * Image
 */
export const zFalAiCartoonifyImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zCartoonifyOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiCartoonifyImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * MaskEraseRequest
 */
export const zFinegrainEraserMaskInput = z.object({
    mode: z.optional(z.enum([
        'express',
        'standard',
        'premium'
    ])),
    seed: z.optional(z.int().gte(0).lte(999)),
    mask_url: z.string(),
    image_url: z.string()
});

/**
 * File
 */
export const zFalAiFinegrainEraserMaskFile = z.object({
    file_size: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    url: z.string(),
    file_data: z.optional(z.string())
});

/**
 * EraseOutput
 */
export const zFinegrainEraserMaskOutput = z.object({
    image: zFalAiFinegrainEraserMaskFile,
    used_seed: z.int()
});

/**
 * BoxPromptBase
 */
export const zBoxPromptBase = z.object({
    y_min: z.optional(z.int()).default(0),
    x_max: z.optional(z.int()).default(0),
    x_min: z.optional(z.int()).default(0),
    y_max: z.optional(z.int()).default(0)
});

/**
 * BBoxEraseRequest
 */
export const zFinegrainEraserBboxInput = z.object({
    mode: z.optional(z.enum([
        'express',
        'standard',
        'premium'
    ])),
    seed: z.optional(z.int().gte(0).lte(999)),
    box_prompts: z.array(zBoxPromptBase),
    image_url: z.string()
});

/**
 * File
 */
export const zFalAiFinegrainEraserBboxFile = z.object({
    file_size: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    url: z.string(),
    file_data: z.optional(z.string())
});

/**
 * EraseOutput
 */
export const zFinegrainEraserBboxOutput = z.object({
    image: zFalAiFinegrainEraserBboxFile,
    used_seed: z.int()
});

/**
 * PromptEraseRequest
 */
export const zFinegrainEraserInput = z.object({
    prompt: z.string(),
    mode: z.optional(z.enum([
        'express',
        'standard',
        'premium'
    ])),
    seed: z.optional(z.int().gte(0).lte(999)),
    image_url: z.string()
});

/**
 * File
 */
export const zFalAiFinegrainEraserFile = z.object({
    file_size: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    url: z.string(),
    file_data: z.optional(z.string())
});

/**
 * EraseOutput
 */
export const zFinegrainEraserOutput = z.object({
    image: zFalAiFinegrainEraserFile,
    used_seed: z.int()
});

/**
 * StarVectorInput
 */
export const zStarVectorInput = z.object({
    seed: z.optional(z.int()),
    image_url: z.string()
});

/**
 * File
 */
export const zFalAiStarVectorFile = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string()
});

/**
 * StarVectorOutput
 */
export const zStarVectorOutput = z.object({
    image: zFalAiStarVectorFile,
    seed: z.int()
});

/**
 * Input
 */
export const zGhiblifyInput = z.object({
    enable_safety_checker: z.optional(z.boolean()).default(true),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiGhiblifyImage = z.object({
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * Output
 */
export const zGhiblifyOutput = z.object({
    image: zFalAiGhiblifyImage
});

/**
 * TheraInput
 */
export const zTheraInput = z.object({
    upscale_factor: z.optional(z.number().gte(1).lte(6)).default(2),
    seed: z.optional(z.int()),
    backbone: z.enum(['edsr', 'rdn']),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiTheraImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * TheraOutput
 */
export const zTheraOutput = z.object({
    image: zFalAiTheraImage,
    seed: z.int()
});

/**
 * MixDehazeNetInput
 */
export const zMixDehazeNetInput = z.object({
    model: z.optional(z.enum(['indoor', 'outdoor'])),
    seed: z.optional(z.int()),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiMixDehazeNetImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * MixDehazeNetOutput
 */
export const zMixDehazeNetOutput = z.object({
    image: zFalAiMixDehazeNetImage
});

/**
 * GeminiImageRequest
 */
export const zGeminiFlashEditInput = z.object({
    prompt: z.string().min(3).max(5000),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiGeminiFlashEditImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * GeminiImageOutput
 */
export const zGeminiFlashEditOutput = z.object({
    description: z.string(),
    image: zFalAiGeminiFlashEditImage
});

/**
 * GeminiMultiImageRequest
 */
export const zGeminiFlashEditMultiInput = z.object({
    prompt: z.string().min(3).max(5000),
    input_image_urls: z.array(z.string()).min(1).max(10)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiGeminiFlashEditMultiImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * GeminiImageOutput
 */
export const zGeminiFlashEditMultiOutput = z.object({
    description: z.string(),
    image: zFalAiGeminiFlashEditMultiImage
});

/**
 * WatermarkInput
 */
export const zInvisibleWatermarkInput = z.object({
    decode: z.optional(z.boolean()).default(false),
    watermark: z.optional(z.string()).default('watermark'),
    length: z.optional(z.int()).default(0),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiInvisibleWatermarkImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * WatermarkOutput
 */
export const zInvisibleWatermarkOutput = z.object({
    image: z.optional(zFalAiInvisibleWatermarkImage),
    extracted_watermark: z.optional(z.string()),
    length: z.optional(z.int()).default(0)
});

/**
 * DevImageToImageInput
 */
export const zJuggernautFluxProImageToImageInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.95),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(1).lte(20)).default(3.5),
    seed: z.optional(z.int()),
    num_inference_steps: z.optional(z.int().gte(10).lte(50)).default(40),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * Image
 */
export const zRundiffusionFalJuggernautFluxProImageToImageImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zJuggernautFluxProImageToImageOutput = z.object({
    prompt: z.string(),
    images: z.array(zRundiffusionFalJuggernautFluxProImageToImageImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * DevImageToImageInput
 */
export const zJuggernautFluxBaseImageToImageInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.95),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(1).lte(20)).default(3.5),
    seed: z.optional(z.int()),
    num_inference_steps: z.optional(z.int().gte(10).lte(50)).default(40),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * Image
 */
export const zRundiffusionFalJuggernautFluxBaseImageToImageImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zJuggernautFluxBaseImageToImageOutput = z.object({
    prompt: z.string(),
    images: z.array(zRundiffusionFalJuggernautFluxBaseImageToImageImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * DocResInputDewarp
 */
export const zDocresDewarpInput = z.object({
    seed: z.optional(z.int()),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiDocresDewarpImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * DocResOutput
 */
export const zDocresDewarpOutput = z.object({
    image: zFalAiDocresDewarpImage
});

/**
 * DocResInput
 */
export const zDocresInput = z.object({
    task: z.enum([
        'deshadowing',
        'appearance',
        'deblurring',
        'binarization'
    ]),
    seed: z.optional(z.int()),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiDocresImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * DocResOutput
 */
export const zDocresOutput = z.object({
    image: zFalAiDocresImage
});

/**
 * SwinSrInput
 */
export const zSwin2SrInput = z.object({
    task: z.optional(z.enum([
        'classical_sr',
        'compressed_sr',
        'real_sr'
    ])),
    seed: z.optional(z.int()),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiSwin2SrImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * SwinSrOutput
 */
export const zSwin2SrOutput = z.object({
    image: zFalAiSwin2SrImage
});

/**
 * RemixImageInput
 */
export const zIdeogramV2aRemixInput = z.object({
    prompt: z.string(),
    aspect_ratio: z.optional(z.enum([
        '10:16',
        '16:10',
        '9:16',
        '16:9',
        '4:3',
        '3:4',
        '1:1',
        '1:3',
        '3:1',
        '3:2',
        '2:3'
    ])),
    style: z.optional(z.enum([
        'auto',
        'general',
        'realistic',
        'design',
        'render_3D',
        'anime'
    ])),
    expand_prompt: z.optional(z.boolean()).default(true),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.8),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * File
 */
export const zFalAiIdeogramV2aRemixFile = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string()
});

/**
 * Output
 */
export const zIdeogramV2aRemixOutput = z.object({
    images: z.array(zFalAiIdeogramV2aRemixFile),
    seed: z.int()
});

/**
 * RemixImageInput
 */
export const zIdeogramV2aTurboRemixInput = z.object({
    prompt: z.string(),
    aspect_ratio: z.optional(z.enum([
        '10:16',
        '16:10',
        '9:16',
        '16:9',
        '4:3',
        '3:4',
        '1:1',
        '1:3',
        '3:1',
        '3:2',
        '2:3'
    ])),
    style: z.optional(z.enum([
        'auto',
        'general',
        'realistic',
        'design',
        'render_3D',
        'anime'
    ])),
    expand_prompt: z.optional(z.boolean()).default(true),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.8),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * File
 */
export const zFalAiIdeogramV2aTurboRemixFile = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string()
});

/**
 * Output
 */
export const zIdeogramV2aTurboRemixOutput = z.object({
    images: z.array(zFalAiIdeogramV2aTurboRemixFile),
    seed: z.int()
});

/**
 * ImageInput
 */
export const zEvfSamInput = z.object({
    prompt: z.string(),
    use_grounding_dino: z.optional(z.boolean()).default(false),
    semantic_type: z.optional(z.boolean()).default(false),
    fill_holes: z.optional(z.boolean()).default(false),
    expand_mask: z.optional(z.int().gte(0).lte(20)).default(0),
    mask_only: z.optional(z.boolean()).default(true),
    revert_mask: z.optional(z.boolean()).default(false),
    blur_mask: z.optional(z.int().gte(0).lte(50)).default(0),
    negative_prompt: z.optional(z.string()),
    image_url: z.string()
});

/**
 * File
 */
export const zFalAiEvfSamFile = z.object({
    file_size: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    url: z.string(),
    file_data: z.optional(z.string())
});

/**
 * ImageOutput
 */
export const zEvfSamOutput = z.object({
    image: zFalAiEvfSamFile
});

/**
 * DDColorInput
 */
export const zDdcolorInput = z.object({
    seed: z.optional(z.int()),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiDdcolorImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * DDColorOutput
 */
export const zDdcolorOutput = z.object({
    image: zFalAiDdcolorImage
});

/**
 * SAM2AutomaticSegmentationInput
 */
export const zSam2AutoSegmentInput = z.object({
    points_per_side: z.optional(z.int()).default(32),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    min_mask_region_area: z.optional(z.int()).default(100),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    pred_iou_thresh: z.optional(z.number()).default(0.88),
    stability_score_thresh: z.optional(z.number()).default(0.95)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiSam2AutoSegmentImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * SAM2AutomaticSegmentationOutput
 */
export const zSam2AutoSegmentOutput = z.object({
    combined_mask: zFalAiSam2AutoSegmentImage,
    individual_masks: z.array(zFalAiSam2AutoSegmentImage)
});

/**
 * Input
 */
export const zDrctSuperResolutionInput = z.object({
    upscale_factor: z.optional(z.literal(4)),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiDrctSuperResolutionImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * Output
 */
export const zDrctSuperResolutionOutput = z.object({
    image: zFalAiDrctSuperResolutionImage
});

/**
 * NafnetInputDenoise
 */
export const zNafnetDenoiseInput = z.object({
    seed: z.optional(z.int()),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiNafnetDenoiseImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * NafnetOutputDenoise
 */
export const zNafnetDenoiseOutput = z.object({
    image: zFalAiNafnetDenoiseImage
});

/**
 * NafnetInput
 */
export const zNafnetDeblurInput = z.object({
    seed: z.optional(z.int()),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiNafnetDeblurImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * NafnetOutput
 */
export const zNafnetDeblurOutput = z.object({
    image: zFalAiNafnetDeblurImage
});

/**
 * ImageProcessingInput
 */
export const zPostProcessingInput = z.object({
    blue_shift: z.optional(z.int().gte(-20).lte(20)).default(0),
    vertex_y: z.optional(z.number().gte(0).lte(1)).default(0.5),
    green_direction: z.optional(z.enum(['horizontal', 'vertical'])),
    enable_glow: z.optional(z.boolean()).default(false),
    dodge_burn_mode: z.optional(z.enum([
        'dodge',
        'burn',
        'dodge_and_burn',
        'burn_and_dodge',
        'color_dodge',
        'color_burn',
        'linear_dodge',
        'linear_burn'
    ])),
    glow_intensity: z.optional(z.number().gte(0).lte(5)).default(1),
    blur_sigma: z.optional(z.number().gte(0.1).lte(10)).default(1),
    desaturate_method: z.optional(z.enum([
        'luminance (Rec.709)',
        'luminance (Rec.601)',
        'average',
        'lightness'
    ])),
    enable_blur: z.optional(z.boolean()).default(false),
    blur_radius: z.optional(z.int().gte(0).lte(31)).default(3),
    grain_style: z.optional(z.enum([
        'modern',
        'analog',
        'kodak',
        'fuji',
        'cinematic',
        'newspaper'
    ])),
    cas_amount: z.optional(z.number().gte(0).lte(1)).default(0.8),
    gamma: z.optional(z.number().gte(0.2).lte(2.2)).default(1),
    tint_mode: z.optional(z.enum([
        'sepia',
        'red',
        'green',
        'blue',
        'cyan',
        'magenta',
        'yellow',
        'purple',
        'orange',
        'warm',
        'cool',
        'lime',
        'navy',
        'vintage',
        'rose',
        'teal',
        'maroon',
        'peach',
        'lavender',
        'olive'
    ])),
    blur_type: z.optional(z.enum(['gaussian', 'kuwahara'])),
    enable_vignette: z.optional(z.boolean()).default(false),
    dissolve_image_url: z.optional(z.string()).default(''),
    red_shift: z.optional(z.int().gte(-20).lte(20)).default(0),
    enable_desaturate: z.optional(z.boolean()).default(false),
    grain_intensity: z.optional(z.number().gte(0).lte(1)).default(0.4),
    dodge_burn_intensity: z.optional(z.number().gte(0).lte(1)).default(0.5),
    smart_sharpen_strength: z.optional(z.number().gte(0).lte(25)).default(5),
    red_direction: z.optional(z.enum(['horizontal', 'vertical'])),
    image_url: z.string(),
    vertex_x: z.optional(z.number().gte(0).lte(1)).default(0.5),
    tint_strength: z.optional(z.number().gte(0.1).lte(1)).default(1),
    enable_dissolve: z.optional(z.boolean()).default(false),
    enable_parabolize: z.optional(z.boolean()).default(false),
    enable_grain: z.optional(z.boolean()).default(false),
    solarize_threshold: z.optional(z.number().gte(0).lte(1)).default(0.5),
    enable_sharpen: z.optional(z.boolean()).default(false),
    enable_dodge_burn: z.optional(z.boolean()).default(false),
    glow_radius: z.optional(z.int().gte(1).lte(50)).default(5),
    sharpen_alpha: z.optional(z.number().gte(0.1).lte(5)).default(1),
    enable_color_correction: z.optional(z.boolean()).default(false),
    contrast: z.optional(z.number().gte(-100).lte(100)).default(0),
    enable_solarize: z.optional(z.boolean()).default(false),
    noise_radius: z.optional(z.int().gte(1).lte(25)).default(7),
    grain_scale: z.optional(z.number().gte(1).lte(100)).default(10),
    temperature: z.optional(z.number().gte(-100).lte(100)).default(0),
    brightness: z.optional(z.number().gte(-100).lte(100)).default(0),
    blue_direction: z.optional(z.enum(['horizontal', 'vertical'])),
    dissolve_factor: z.optional(z.number().gte(0).lte(1)).default(0.5),
    sharpen_mode: z.optional(z.enum([
        'basic',
        'smart',
        'cas'
    ])),
    vignette_strength: z.optional(z.number().gte(0).lte(10)).default(0.5),
    sharpen_radius: z.optional(z.int().gte(1).lte(15)).default(1),
    parabolize_coeff: z.optional(z.number().gte(-10).lte(10)).default(1),
    saturation: z.optional(z.number().gte(-100).lte(100)).default(0),
    enable_tint: z.optional(z.boolean()).default(false),
    green_shift: z.optional(z.int().gte(-20).lte(20)).default(0),
    preserve_edges: z.optional(z.number().gte(0).lte(1)).default(0.75),
    desaturate_factor: z.optional(z.number().gte(0).lte(1)).default(1),
    smart_sharpen_ratio: z.optional(z.number().gte(0).lte(1)).default(0.5),
    enable_chromatic: z.optional(z.boolean()).default(false)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPostProcessingImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ProcessedOutput
 */
export const zPostProcessingOutput = z.object({
    images: z.array(zFalAiPostProcessingImage)
});

/**
 * FlowEditInput
 */
export const zFloweditInput = z.object({
    src_guidance_scale: z.optional(z.int().gte(0).lte(30)).default(1.5),
    n_min: z.optional(z.int()).default(0),
    n_max: z.optional(z.int()).default(23),
    image_url: z.string(),
    source_prompt: z.string(),
    tar_guidance_scale: z.optional(z.int().gte(0).lte(30)).default(5.5),
    target_prompt: z.string(),
    seed: z.optional(z.int()),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28),
    n_avg: z.optional(z.int()).default(1)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFloweditImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * FlowEditOutput
 */
export const zFloweditOutput = z.object({
    image: zFalAiFloweditImage,
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiFluxControlLoraCannyImageToImageImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * LoraWeight
 */
export const zFalAiFluxControlLoraCannyImageToImageLoraWeight = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(4)).default(1)
});

/**
 * ImageToImageInput
 */
export const zFluxControlLoraCannyImageToImageInput = z.object({
    control_lora_strength: z.optional(z.number().gte(0).lte(2)).default(1),
    prompt: z.string(),
    image_size: z.optional(z.union([
        zFalAiFluxControlLoraCannyImageToImageImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    loras: z.optional(z.array(zFalAiFluxControlLoraCannyImageToImageLoraWeight)).default([]),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    guidance_scale: z.optional(z.number().gte(0).lte(35)).default(3.5),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.85),
    sync_mode: z.optional(z.boolean()).default(false),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28),
    seed: z.optional(z.int()),
    control_lora_image_url: z.optional(z.string())
});

/**
 * Image
 */
export const zFalAiFluxControlLoraCannyImageToImageImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFluxControlLoraCannyImageToImageOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxControlLoraCannyImageToImageImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiFluxControlLoraDepthImageToImageImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * LoraWeight
 */
export const zFalAiFluxControlLoraDepthImageToImageLoraWeight = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(4)).default(1)
});

/**
 * ImageToImageInput
 */
export const zFluxControlLoraDepthImageToImageInput = z.object({
    prompt: z.string(),
    control_lora_strength: z.optional(z.number().gte(0).lte(2)).default(1),
    image_size: z.optional(z.union([
        zFalAiFluxControlLoraDepthImageToImageImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    loras: z.optional(z.array(zFalAiFluxControlLoraDepthImageToImageLoraWeight)).default([]),
    guidance_scale: z.optional(z.number().gte(0).lte(35)).default(3.5),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.85),
    sync_mode: z.optional(z.boolean()).default(false),
    control_lora_image_url: z.string(),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28),
    seed: z.optional(z.int())
});

/**
 * Image
 */
export const zFalAiFluxControlLoraDepthImageToImageImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFluxControlLoraDepthImageToImageOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxControlLoraDepthImageToImageImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * Ben2InputImage
 */
export const zBenV2ImageInput = z.object({
    seed: z.optional(z.int()),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBenV2ImageImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * Ben2OutputImage
 */
export const zBenV2ImageOutput = z.object({
    image: zFalAiBenV2ImageImage,
    seed: z.int()
});

/**
 * UpscaleImageInput
 */
export const zIdeogramUpscaleInput = z.object({
    prompt: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    detail: z.optional(z.int().gte(1).lte(100)).default(50),
    resemblance: z.optional(z.int().gte(1).lte(100)).default(50),
    expand_prompt: z.optional(z.boolean()).default(false),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * File
 */
export const zFalAiIdeogramUpscaleFile = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string()
});

/**
 * UpscaleOutput
 */
export const zIdeogramUpscaleOutput = z.object({
    images: z.array(zFalAiIdeogramUpscaleFile),
    seed: z.int()
});

/**
 * CodeformerInput
 */
export const zCodeformerInput = z.object({
    aligned: z.optional(z.boolean()).default(false),
    image_url: z.string(),
    upscale_factor: z.optional(z.number()).default(2),
    fidelity: z.optional(z.number()).default(0.5),
    face_upscale: z.optional(z.boolean()).default(true),
    only_center_face: z.optional(z.boolean()).default(false),
    seed: z.optional(z.int())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiCodeformerImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ConformerOutput
 */
export const zCodeformerOutput = z.object({
    image: zFalAiCodeformerImage,
    seed: z.int()
});

/**
 * TryOnRequest
 */
export const zKlingV15KolorsVirtualTryOnInput = z.object({
    garment_image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    human_image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiKlingV15KolorsVirtualTryOnImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * TryOnOutput
 */
export const zKlingV15KolorsVirtualTryOnOutput = z.object({
    image: zFalAiKlingV15KolorsVirtualTryOnImage
});

/**
 * ImageSize
 */
export const zFalAiFluxLoraCannyImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * LoraWeight
 */
export const zFalAiFluxLoraCannyLoraWeight = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(4)).default(1)
});

/**
 * CannyInput
 */
export const zFluxLoraCannyInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiFluxLoraCannyImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    loras: z.optional(z.array(zFalAiFluxLoraCannyLoraWeight)).default([]),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(20).lte(40)).default(30),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28),
    seed: z.optional(z.int()),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * Image
 */
export const zFalAiFluxLoraCannyImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFluxLoraCannyOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxLoraCannyImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * FluxProFillFinetunedInput
 */
export const zFluxProV1FillFinetunedInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    finetune_strength: z.number().gte(0).lte(2),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    finetune_id: z.string(),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5',
        '6'
    ])),
    seed: z.optional(z.int()),
    mask_url: z.string(),
    enhance_prompt: z.optional(z.boolean()).default(false)
});

/**
 * Image
 */
export const zFalAiFluxProV1FillFinetunedRegistryImageFastSdxlModelsImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFluxProV1FillFinetunedOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxProV1FillFinetunedRegistryImageFastSdxlModelsImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * DetectionInput
 */
export const zMoondreamNextDetectionInput = z.object({
    detection_prompt: z.string(),
    use_ensemble: z.optional(z.boolean()).default(false),
    task_type: z.enum([
        'bbox_detection',
        'point_detection',
        'gaze_detection'
    ]),
    show_visualization: z.optional(z.boolean()).default(true),
    combine_points: z.optional(z.boolean()).default(false),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiMoondreamNextDetectionImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * DetectionOutput
 */
export const zMoondreamNextDetectionOutput = z.object({
    image: z.optional(zFalAiMoondreamNextDetectionImage),
    text_output: z.string()
});

/**
 * ImageExpansionInput
 */
export const zBriaExpandInput = z.object({
    prompt: z.optional(z.string()).default(''),
    aspect_ratio: z.optional(z.enum([
        '1:1',
        '2:3',
        '3:2',
        '3:4',
        '4:3',
        '4:5',
        '5:4',
        '9:16',
        '16:9'
    ])),
    original_image_location: z.optional(z.array(z.int())),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    original_image_size: z.optional(z.array(z.int())),
    canvas_size: z.array(z.int()),
    seed: z.optional(z.int().gte(0).lte(2147483647)),
    negative_prompt: z.optional(z.string()).default('')
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBriaExpandImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ImageExpansionOutput
 */
export const zBriaExpandOutput = z.object({
    image: zFalAiBriaExpandImage,
    seed: z.int()
});

/**
 * GenFillInput
 */
export const zBriaGenfillInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    seed: z.optional(z.int().gte(0).lte(2147483647)),
    mask_url: z.string(),
    negative_prompt: z.optional(z.string()).default('')
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBriaGenfillImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * GenFillOutput
 */
export const zBriaGenfillOutput = z.object({
    images: z.array(zFalAiBriaGenfillImage)
});

/**
 * EraserInput
 */
export const zBriaEraserInput = z.object({
    sync_mode: z.optional(z.boolean()).default(false),
    preserve_alpha: z.optional(z.boolean()).default(false),
    mask_url: z.string(),
    mask_type: z.optional(z.enum(['manual', 'automatic'])),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBriaEraserImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * EraserOutput
 */
export const zBriaEraserOutput = z.object({
    image: zFalAiBriaEraserImage
});

/**
 * BGReplaceInput
 */
export const zBriaBackgroundReplaceInput = z.object({
    ref_image_url: z.optional(z.string()).default(''),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    prompt: z.optional(z.string().min(1)),
    refine_prompt: z.optional(z.boolean()).default(true),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    fast: z.optional(z.boolean()).default(true),
    seed: z.optional(z.int().gte(0).lte(2147483647)),
    negative_prompt: z.optional(z.string()).default('')
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBriaBackgroundReplaceImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * BGReplaceOutput
 */
export const zBriaBackgroundReplaceOutput = z.object({
    images: z.array(zFalAiBriaBackgroundReplaceImage),
    seed: z.int()
});

/**
 * ImageFillInput
 */
export const zImageFillInput = z.object({
    in_context_fill: z.optional(z.boolean()).default(false),
    use_prompt: z.optional(z.boolean()).default(false),
    fill_image_url: z.optional(z.union([
        z.array(z.string()),
        z.string()
    ]))
});

/**
 * Image
 */
export const zFalAiFluxLoraFillImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFluxLoraFillOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxLoraFillImage),
    seed: z.int(),
    has_nsfw_concepts: z.array(z.boolean()),
    timings: z.record(z.string(), z.number())
});

/**
 * ProductShotInput
 */
export const zBriaProductShotInput = z.object({
    ref_image_url: z.optional(z.string()).default(''),
    num_results: z.optional(z.int().gte(1).lte(4)).default(1),
    manual_placement_selection: z.optional(z.enum([
        'upper_left',
        'upper_right',
        'bottom_left',
        'bottom_right',
        'right_center',
        'left_center',
        'upper_center',
        'bottom_center',
        'center_vertical',
        'center_horizontal'
    ])),
    padding_values: z.optional(z.array(z.int())),
    shot_size: z.optional(z.array(z.int())).default([1000, 1000]),
    sync_mode: z.optional(z.boolean()).default(false),
    placement_type: z.optional(z.enum([
        'original',
        'automatic',
        'manual_placement',
        'manual_padding'
    ])),
    original_quality: z.optional(z.boolean()).default(false),
    fast: z.optional(z.boolean()).default(true),
    image_url: z.string(),
    scene_description: z.optional(z.string()),
    optimize_description: z.optional(z.boolean()).default(true)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBriaProductShotImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * ProductShotOutput
 */
export const zBriaProductShotOutput = z.object({
    images: z.array(zFalAiBriaProductShotImage)
});

/**
 * BGRemoveInput
 */
export const zBriaBackgroundRemoveInput = z.object({
    sync_mode: z.optional(z.boolean()).default(false),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBriaBackgroundRemoveImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * BGRemoveOutput
 */
export const zBriaBackgroundRemoveOutput = z.object({
    image: zFalAiBriaBackgroundRemoveImage
});

/**
 * ImageSize
 */
export const zFalAiCatVtonImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * CATVTONInput
 */
export const zCatVtonInput = z.object({
    garment_image_url: z.string(),
    image_size: z.optional(z.union([
        zFalAiCatVtonImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    human_image_url: z.string(),
    cloth_type: z.enum([
        'upper',
        'lower',
        'overall',
        'inner',
        'outer'
    ]),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(2.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(30),
    seed: z.optional(z.int())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiCatVtonImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * CATVTONOutput
 */
export const zCatVtonOutput = z.object({
    image: zFalAiCatVtonImage
});

/**
 * PoseTransferInput
 */
export const zLeffaPoseTransferInput = z.object({
    pose_image_url: z.string(),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(2.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(50),
    seed: z.optional(z.int()),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    person_image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiLeffaPoseTransferImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * PoseTransferOutput
 */
export const zLeffaPoseTransferOutput = z.object({
    image: zFalAiLeffaPoseTransferImage,
    seed: z.int(),
    has_nsfw_concepts: z.boolean()
});

/**
 * VTONInput
 */
export const zLeffaVirtualTryonInput = z.object({
    garment_image_url: z.string(),
    human_image_url: z.string(),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    sync_mode: z.optional(z.boolean()).default(false),
    garment_type: z.enum([
        'upper_body',
        'lower_body',
        'dresses'
    ]),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(2.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(50),
    seed: z.optional(z.int()),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiLeffaVirtualTryonImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * VTONOutput
 */
export const zLeffaVirtualTryonOutput = z.object({
    image: zFalAiLeffaVirtualTryonImage,
    seed: z.int(),
    has_nsfw_concepts: z.boolean()
});

/**
 * EditImageInput
 */
export const zIdeogramV2EditInput = z.object({
    prompt: z.string(),
    style: z.optional(z.enum([
        'auto',
        'general',
        'realistic',
        'design',
        'render_3D',
        'anime'
    ])),
    expand_prompt: z.optional(z.boolean()).default(true),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    mask_url: z.string()
});

/**
 * File
 */
export const zFalAiIdeogramV2EditFile = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string()
});

/**
 * Output
 */
export const zIdeogramV2EditOutput = z.object({
    images: z.array(zFalAiIdeogramV2EditFile),
    seed: z.int()
});

/**
 * RemixImageInput
 */
export const zIdeogramV2TurboRemixInput = z.object({
    prompt: z.string(),
    aspect_ratio: z.optional(z.enum([
        '10:16',
        '16:10',
        '9:16',
        '16:9',
        '4:3',
        '3:4',
        '1:1',
        '1:3',
        '3:1',
        '3:2',
        '2:3'
    ])),
    style: z.optional(z.enum([
        'auto',
        'general',
        'realistic',
        'design',
        'render_3D',
        'anime'
    ])),
    expand_prompt: z.optional(z.boolean()).default(true),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.8),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * File
 */
export const zFalAiIdeogramV2TurboRemixFile = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string()
});

/**
 * Output
 */
export const zIdeogramV2TurboRemixOutput = z.object({
    images: z.array(zFalAiIdeogramV2TurboRemixFile),
    seed: z.int()
});

/**
 * EditImageInput
 */
export const zIdeogramV2TurboEditInput = z.object({
    prompt: z.string(),
    style: z.optional(z.enum([
        'auto',
        'general',
        'realistic',
        'design',
        'render_3D',
        'anime'
    ])),
    expand_prompt: z.optional(z.boolean()).default(true),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    mask_url: z.string()
});

/**
 * File
 */
export const zFalAiIdeogramV2TurboEditFile = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string()
});

/**
 * Output
 */
export const zIdeogramV2TurboEditOutput = z.object({
    images: z.array(zFalAiIdeogramV2TurboEditFile),
    seed: z.int()
});

/**
 * RemixImageInput
 */
export const zIdeogramV2RemixInput = z.object({
    prompt: z.string(),
    aspect_ratio: z.optional(z.enum([
        '10:16',
        '16:10',
        '9:16',
        '16:9',
        '4:3',
        '3:4',
        '1:1',
        '1:3',
        '3:1',
        '3:2',
        '2:3'
    ])),
    style: z.optional(z.enum([
        'auto',
        'general',
        'realistic',
        'design',
        'render_3D',
        'anime'
    ])),
    expand_prompt: z.optional(z.boolean()).default(true),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.8),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * File
 */
export const zFalAiIdeogramV2RemixFile = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string()
});

/**
 * Output
 */
export const zIdeogramV2RemixOutput = z.object({
    images: z.array(zFalAiIdeogramV2RemixFile),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiFluxSchnellReduxImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * SchnellReduxInput
 */
export const zFluxSchnellReduxInput = z.object({
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiFluxSchnellReduxImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    num_inference_steps: z.optional(z.int().gte(1).lte(12)).default(4)
});

/**
 * Image
 */
export const zFalAiFluxSchnellReduxImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFluxSchnellReduxOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxSchnellReduxImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiFluxProV11ReduxImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * FluxProRedux
 */
export const zFluxProV11ReduxInput = z.object({
    prompt: z.optional(z.string()).default(''),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiFluxProV11ReduxImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5',
        '6'
    ])),
    guidance_scale: z.optional(z.number().gte(1).lte(20)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28),
    seed: z.optional(z.int()),
    enhance_prompt: z.optional(z.boolean()).default(false)
});

/**
 * Image
 */
export const zFalAiFluxProV11ReduxRegistryImageFastSdxlModelsImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFluxProV11ReduxOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxProV11ReduxRegistryImageFastSdxlModelsImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiFluxDevReduxImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * BaseReduxInput
 */
export const zFluxDevReduxInput = z.object({
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiFluxDevReduxImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    acceleration: z.optional(z.enum([
        'none',
        'regular',
        'high'
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    seed: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    guidance_scale: z.optional(z.number().gte(1).lte(20)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28)
});

/**
 * Image
 */
export const zFalAiFluxDevReduxImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFluxDevReduxOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxDevReduxImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiFluxLoraDepthImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * LoraWeight
 */
export const zFalAiFluxLoraDepthLoraWeight = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(4)).default(1)
});

/**
 * DepthInput
 */
export const zFluxLoraDepthInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiFluxLoraDepthImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    loras: z.optional(z.array(zFalAiFluxLoraDepthLoraWeight)).default([]),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(35)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28),
    seed: z.optional(z.int()),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * Image
 */
export const zFalAiFluxLoraDepthImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFluxLoraDepthOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxLoraDepthImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * FluxProUltraTextToImageInputRedux
 */
export const zFluxProV11UltraReduxInput = z.object({
    prompt: z.optional(z.string()).default(''),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    aspect_ratio: z.optional(z.union([
        z.enum([
            '21:9',
            '16:9',
            '4:3',
            '3:2',
            '1:1',
            '2:3',
            '3:4',
            '9:16',
            '9:21'
        ]),
        z.string()
    ])),
    enhance_prompt: z.optional(z.boolean()).default(false),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5',
        '6'
    ])),
    image_prompt_strength: z.optional(z.number().gte(0).lte(1)).default(0.1),
    seed: z.optional(z.int()),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    raw: z.optional(z.boolean()).default(false)
});

/**
 * Image
 */
export const zFalAiFluxProV11UltraReduxRegistryImageFastSdxlModelsImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFluxProV11UltraReduxOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxProV11UltraReduxRegistryImageFastSdxlModelsImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * FluxProFillInput
 */
export const zFluxProV1FillInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_tolerance: z.optional(z.enum([
        '1',
        '2',
        '3',
        '4',
        '5',
        '6'
    ])),
    seed: z.optional(z.int()),
    mask_url: z.string(),
    enhance_prompt: z.optional(z.boolean()).default(false)
});

/**
 * Image
 */
export const zFalAiFluxProV1FillRegistryImageFastSdxlModelsImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFluxProV1FillOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxProV1FillRegistryImageFastSdxlModelsImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiKolorsImageToImageImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * KolorsImg2ImgInput
 */
export const zKolorsImageToImageInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(8)).default(1),
    image_size: z.optional(z.union([
        zFalAiKolorsImageToImageImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    scheduler: z.optional(z.enum([
        'EulerDiscreteScheduler',
        'EulerAncestralDiscreteScheduler',
        'DPMSolverMultistepScheduler',
        'DPMSolverMultistepScheduler_SDE_karras',
        'UniPCMultistepScheduler',
        'DEISMultistepScheduler'
    ])),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.85),
    guidance_scale: z.optional(z.number().gte(1).lte(10)).default(5),
    num_inference_steps: z.optional(z.int().gte(1).lte(150)).default(50),
    seed: z.optional(z.int()),
    negative_prompt: z.optional(z.string()).default(''),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * Image
 */
export const zFalAiKolorsImageToImageImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zKolorsImageToImageOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiKolorsImageToImageImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiIclightV2ImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * BaseInput
 */
export const zIclightV2Input = z.object({
    initial_latent: z.optional(z.enum([
        'None',
        'Left',
        'Right',
        'Top',
        'Bottom'
    ])),
    prompt: z.string(),
    image_size: z.optional(z.union([
        zFalAiIclightV2ImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    background_threshold: z.optional(z.number().gte(0.01).lte(1)).default(0.67),
    mask_image_url: z.optional(z.string()),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(5),
    lowres_denoise: z.optional(z.number().gte(0.01).lte(1)).default(0.98),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    negative_prompt: z.optional(z.string()).default(''),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    hr_downscale: z.optional(z.number().gte(0.01).lte(1)).default(0.5),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    highres_denoise: z.optional(z.number().gte(0.01).lte(1)).default(0.95),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28),
    seed: z.optional(z.int()),
    enable_hr_fix: z.optional(z.boolean()).default(false),
    cfg: z.optional(z.number().gte(0.01).lte(5)).default(1)
});

/**
 * Image
 */
export const zFalAiIclightV2Image = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zIclightV2Output = z.object({
    prompt: z.string(),
    images: z.array(zFalAiIclightV2Image),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * DiffInput
 */
export const zFluxDifferentialDiffusionInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.85),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3.5),
    seed: z.optional(z.int()),
    change_map_image_url: z.string(),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28)
});

/**
 * Image
 */
export const zFalAiFluxDifferentialDiffusionImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFluxDifferentialDiffusionOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxDifferentialDiffusionImage),
    seed: z.int(),
    has_nsfw_concepts: z.array(z.boolean()),
    timings: z.record(z.string(), z.number())
});

/**
 * ImageSize
 */
export const zFalAiFluxPulidImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * FluxPulidInput
 */
export const zFluxPulidInput = z.object({
    prompt: z.string(),
    id_weight: z.optional(z.number().gte(0).lte(1)).default(1),
    image_size: z.optional(z.union([
        zFalAiFluxPulidImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    start_step: z.optional(z.int().gte(0).lte(50)).default(0),
    reference_image_url: z.string(),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    max_sequence_length: z.optional(z.enum([
        '128',
        '256',
        '512'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(4),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(20),
    seed: z.optional(z.int()),
    negative_prompt: z.optional(z.string()).default(''),
    true_cfg: z.optional(z.number().gte(1).lte(10)).default(1)
});

/**
 * Image
 */
export const zFalAiFluxPulidImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFluxPulidOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxPulidImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * InputV2
 */
export const zBirefnetV2Input = z.object({
    operating_resolution: z.optional(z.enum([
        '1024x1024',
        '2048x2048',
        '2304x2304'
    ])),
    output_format: z.optional(z.enum([
        'webp',
        'png',
        'gif'
    ])),
    image_url: z.string(),
    model: z.optional(z.enum([
        'General Use (Light)',
        'General Use (Light 2K)',
        'General Use (Heavy)',
        'Matting',
        'Portrait',
        'General Use (Dynamic)'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    output_mask: z.optional(z.boolean()).default(false),
    refine_foreground: z.optional(z.boolean()).default(true)
});

/**
 * ImageFile
 */
export const zFalAiBirefnetV2ImageFile = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * Output
 */
export const zBirefnetV2Output = z.object({
    image: zFalAiBirefnetV2ImageFile,
    mask_image: z.optional(zFalAiBirefnetV2ImageFile)
});

/**
 * LivePortraitImageInput
 */
export const zLivePortraitImageInput = z.object({
    smile: z.optional(z.number().gte(-2).lte(2)).default(0),
    eyebrow: z.optional(z.number().gte(-30).lte(30)).default(0),
    rotate_roll: z.optional(z.number().gte(-45).lte(45)).default(0),
    wink: z.optional(z.number().gte(0).lte(25)).default(0),
    rotate_pitch: z.optional(z.number().gte(-45).lte(45)).default(0),
    blink: z.optional(z.number().gte(-30).lte(30)).default(0),
    dsize: z.optional(z.int()).default(512),
    vy_ratio: z.optional(z.number()).default(-0.125),
    scale: z.optional(z.number()).default(2.3),
    pupil_x: z.optional(z.number().gte(-45).lte(45)).default(0),
    flag_pasteback: z.optional(z.boolean()).default(true),
    eee: z.optional(z.number().gte(-40).lte(40)).default(0),
    enable_safety_checker: z.optional(z.boolean()).default(false),
    vx_ratio: z.optional(z.number()).default(0),
    pupil_y: z.optional(z.number().gte(-45).lte(45)).default(0),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    rotate_yaw: z.optional(z.number().gte(-45).lte(45)).default(0),
    flag_do_rot: z.optional(z.boolean()).default(true),
    woo: z.optional(z.number().gte(-100).lte(100)).default(0),
    aaa: z.optional(z.number().gte(-200).lte(200)).default(0),
    image_url: z.string(),
    flag_do_crop: z.optional(z.boolean()).default(true),
    flag_lip_zero: z.optional(z.boolean()).default(true)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiLivePortraitImageImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * LivePortraitImageOutput
 */
export const zLivePortraitImageOutput = z.object({
    image: zFalAiLivePortraitImageImage
});

/**
 * ControlNetUnionInput
 */
export const zControlNetUnionInput = z.object({
    conditioning_scale: z.optional(z.number().gte(0).lte(2)).default(1),
    mask_threshold: z.optional(z.number().gte(0.01).lte(0.99)).default(0.5),
    end_percentage: z.optional(z.number().gte(0).lte(1)).default(1),
    mask_image_url: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    control_image_url: z.string(),
    control_mode: z.enum([
        'canny',
        'tile',
        'depth',
        'blur',
        'pose',
        'gray',
        'low-quality'
    ]),
    start_percentage: z.optional(z.number().gte(0).lte(1)).default(0)
});

/**
 * Image
 */
export const zFalAiFluxGeneralRfInversionImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFluxGeneralRfInversionOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxGeneralRfInversionImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * HEDInput
 */
export const zImagePreprocessorsHedInput = z.object({
    safe: z.optional(z.boolean()).default(false),
    scribble: z.optional(z.boolean()).default(false),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImagePreprocessorsHedImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * HEDOutput
 */
export const zImagePreprocessorsHedOutput = z.object({
    image: zFalAiImagePreprocessorsHedImage
});

/**
 * ScribbleInput
 */
export const zImagePreprocessorsScribbleInput = z.object({
    model: z.optional(z.enum(['HED', 'PiDi'])),
    safe: z.optional(z.boolean()).default(false),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImagePreprocessorsScribbleImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * ScribbleOutput
 */
export const zImagePreprocessorsScribbleOutput = z.object({
    image: zFalAiImagePreprocessorsScribbleImage
});

/**
 * DepthAnythingV2Input
 */
export const zImagePreprocessorsDepthAnythingV2Input = z.object({
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImagePreprocessorsDepthAnythingV2Image = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * DepthAnythingV2Output
 */
export const zImagePreprocessorsDepthAnythingV2Output = z.object({
    image: zFalAiImagePreprocessorsDepthAnythingV2Image
});

/**
 * ZoeInput
 */
export const zImagePreprocessorsZoeInput = z.object({
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImagePreprocessorsZoeImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * ZoeOutput
 */
export const zImagePreprocessorsZoeOutput = z.object({
    image: zFalAiImagePreprocessorsZoeImage
});

/**
 * TeeDInput
 */
export const zImagePreprocessorsTeedInput = z.object({
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImagePreprocessorsTeedImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * TeeDOutput
 */
export const zImagePreprocessorsTeedOutput = z.object({
    image: zFalAiImagePreprocessorsTeedImage
});

/**
 * MLSDInput
 */
export const zImagePreprocessorsMlsdInput = z.object({
    distance_threshold: z.optional(z.number()).default(0.1),
    score_threshold: z.optional(z.number()).default(0.1),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImagePreprocessorsMlsdImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * MLSDOutput
 */
export const zImagePreprocessorsMlsdOutput = z.object({
    image: zFalAiImagePreprocessorsMlsdImage
});

/**
 * LineartInput
 */
export const zImagePreprocessorsLineartInput = z.object({
    coarse: z.optional(z.boolean()).default(false),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImagePreprocessorsLineartImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * LineartOutput
 */
export const zImagePreprocessorsLineartOutput = z.object({
    image: zFalAiImagePreprocessorsLineartImage
});

/**
 * SamInput
 */
export const zImagePreprocessorsSamInput = z.object({
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImagePreprocessorsSamImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * SamOutput
 */
export const zImagePreprocessorsSamOutput = z.object({
    image: zFalAiImagePreprocessorsSamImage
});

/**
 * MiDaSInput
 */
export const zImagePreprocessorsMidasInput = z.object({
    a: z.optional(z.number()).default(6.283185307179586),
    background_threshold: z.optional(z.number()).default(0.1),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImagePreprocessorsMidasImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * MiDaSOutput
 */
export const zImagePreprocessorsMidasOutput = z.object({
    normal_map: zFalAiImagePreprocessorsMidasImage,
    depth_map: zFalAiImagePreprocessorsMidasImage
});

/**
 * PiDiInput
 */
export const zImagePreprocessorsPidiInput = z.object({
    safe: z.optional(z.boolean()).default(false),
    apply_filter: z.optional(z.boolean()).default(false),
    scribble: z.optional(z.boolean()).default(false),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImagePreprocessorsPidiImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * PiDiOutput
 */
export const zImagePreprocessorsPidiOutput = z.object({
    image: zFalAiImagePreprocessorsPidiImage
});

/**
 * PointPrompt
 */
export const zFalAiSam2ImagePointPrompt = z.object({
    y: z.optional(z.int()).default(350),
    label: z.optional(z.union([z.literal(0), z.literal(1)])),
    frame_index: z.optional(z.int()).default(0),
    x: z.optional(z.int()).default(305)
});

/**
 * BoxPrompt
 */
export const zFalAiSam2ImageBoxPrompt = z.object({
    y_min: z.optional(z.int()).default(0),
    frame_index: z.optional(z.int()).default(0),
    x_max: z.optional(z.int()).default(0),
    x_min: z.optional(z.int()).default(0),
    y_max: z.optional(z.int()).default(0)
});

/**
 * SAM2ImageInput
 */
export const zSam2ImageInput = z.object({
    sync_mode: z.optional(z.boolean()).default(false),
    output_format: z.optional(z.enum([
        'jpeg',
        'png',
        'webp'
    ])),
    prompts: z.optional(z.array(zFalAiSam2ImagePointPrompt)).default([]),
    box_prompts: z.optional(z.array(zFalAiSam2ImageBoxPrompt)).default([]),
    apply_mask: z.optional(z.boolean()).default(false),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiSam2ImageImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * SAM2ImageOutput
 */
export const zSam2ImageOutput = z.object({
    image: zFalAiSam2ImageImage
});

/**
 * ControlNetUnionInput
 */
export const zFalAiFluxGeneralImageToImageControlNetUnionInput = z.object({
    conditioning_scale: z.optional(z.number().gte(0).lte(2)).default(1),
    mask_threshold: z.optional(z.number().gte(0.01).lte(0.99)).default(0.5),
    end_percentage: z.optional(z.number().gte(0).lte(1)).default(1),
    mask_image_url: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    control_image_url: z.string(),
    control_mode: z.enum([
        'canny',
        'tile',
        'depth',
        'blur',
        'pose',
        'gray',
        'low-quality'
    ]),
    start_percentage: z.optional(z.number().gte(0).lte(1)).default(0)
});

/**
 * Image
 */
export const zFalAiFluxGeneralImageToImageImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFluxGeneralImageToImageOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxGeneralImageToImageImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ControlNetUnionInput
 */
export const zFalAiFluxGeneralInpaintingControlNetUnionInput = z.object({
    conditioning_scale: z.optional(z.number().gte(0).lte(2)).default(1),
    mask_threshold: z.optional(z.number().gte(0.01).lte(0.99)).default(0.5),
    end_percentage: z.optional(z.number().gte(0).lte(1)).default(1),
    mask_image_url: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    control_image_url: z.string(),
    control_mode: z.enum([
        'canny',
        'tile',
        'depth',
        'blur',
        'pose',
        'gray',
        'low-quality'
    ]),
    start_percentage: z.optional(z.number().gte(0).lte(1)).default(0)
});

/**
 * Image
 */
export const zFalAiFluxGeneralInpaintingImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFluxGeneralInpaintingOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxGeneralInpaintingImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ControlNetUnionInput
 */
export const zFalAiFluxGeneralDifferentialDiffusionControlNetUnionInput = z.object({
    conditioning_scale: z.optional(z.number().gte(0).lte(2)).default(1),
    mask_threshold: z.optional(z.number().gte(0.01).lte(0.99)).default(0.5),
    end_percentage: z.optional(z.number().gte(0).lte(1)).default(1),
    mask_image_url: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    control_image_url: z.string(),
    control_mode: z.enum([
        'canny',
        'tile',
        'depth',
        'blur',
        'pose',
        'gray',
        'low-quality'
    ]),
    start_percentage: z.optional(z.number().gte(0).lte(1)).default(0)
});

/**
 * Image
 */
export const zFalAiFluxGeneralDifferentialDiffusionImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFluxGeneralDifferentialDiffusionOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxGeneralDifferentialDiffusionImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiFluxLoraImageToImageImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * LoraWeight
 */
export const zFalAiFluxLoraImageToImageLoraWeight = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(4)).default(1)
});

/**
 * ImageToImageInput
 */
export const zFluxLoraImageToImageInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiFluxLoraImageToImageImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    output_format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    loras: z.optional(z.array(zFalAiFluxLoraImageToImageLoraWeight)).default([]),
    sync_mode: z.optional(z.boolean()).default(false),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.85),
    guidance_scale: z.optional(z.number().gte(0).lte(35)).default(3.5),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28),
    seed: z.optional(z.int()),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * Image
 */
export const zFalAiFluxLoraImageToImageImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFluxLoraImageToImageOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFluxLoraImageToImageImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiSdxlControlnetUnionInpaintingImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * Embedding
 */
export const zEmbedding = z.object({
    tokens: z.optional(z.array(z.string())).default(['<s0>', '<s1>']),
    path: z.string()
});

/**
 * LoraWeight
 */
export const zFalAiSdxlControlnetUnionInpaintingLoraWeight = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(1)).default(1),
    force: z.optional(z.boolean()).default(false)
});

/**
 * InpaintingControlNetUnionInput
 */
export const zSdxlControlnetUnionInpaintingInput = z.object({
    prompt: z.string(),
    depth_preprocess: z.optional(z.boolean()).default(true),
    image_size: z.optional(z.union([
        zFalAiSdxlControlnetUnionInpaintingImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.null()
    ])),
    normal_image_url: z.optional(z.string()),
    embeddings: z.optional(z.array(zEmbedding)).default([]),
    teed_image_url: z.optional(z.string()),
    loras: z.optional(z.array(zFalAiSdxlControlnetUnionInpaintingLoraWeight)).default([]),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(7.5),
    canny_image_url: z.optional(z.string()),
    segmentation_preprocess: z.optional(z.boolean()).default(true),
    format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    request_id: z.optional(z.string()).default(''),
    seed: z.optional(z.int()),
    mask_url: z.string(),
    segmentation_image_url: z.optional(z.string()),
    openpose_image_url: z.optional(z.string()),
    canny_preprocess: z.optional(z.boolean()).default(true),
    expand_prompt: z.optional(z.boolean()).default(false),
    depth_image_url: z.optional(z.string()),
    normal_preprocess: z.optional(z.boolean()).default(true),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    negative_prompt: z.optional(z.string()).default(''),
    teed_preprocess: z.optional(z.boolean()).default(true),
    num_images: z.optional(z.int().gte(1).lte(8)).default(1),
    controlnet_conditioning_scale: z.optional(z.number().gte(0).lte(1)).default(0.5),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.95),
    safety_checker_version: z.optional(z.enum(['v1', 'v2'])),
    openpose_preprocess: z.optional(z.boolean()).default(true),
    num_inference_steps: z.optional(z.int().gte(1).lte(70)).default(35)
});

/**
 * Image
 */
export const zFalAiSdxlControlnetUnionInpaintingImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zSdxlControlnetUnionInpaintingOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiSdxlControlnetUnionInpaintingImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiSdxlControlnetUnionImageToImageImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * Embedding
 */
export const zFalAiSdxlControlnetUnionImageToImageEmbedding = z.object({
    tokens: z.optional(z.array(z.string())).default(['<s0>', '<s1>']),
    path: z.string()
});

/**
 * LoraWeight
 */
export const zFalAiSdxlControlnetUnionImageToImageLoraWeight = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(1)).default(1),
    force: z.optional(z.boolean()).default(false)
});

/**
 * ImageToImageControlNetUnionInput
 */
export const zSdxlControlnetUnionImageToImageInput = z.object({
    prompt: z.string(),
    depth_preprocess: z.optional(z.boolean()).default(true),
    image_size: z.optional(z.union([
        zFalAiSdxlControlnetUnionImageToImageImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.null()
    ])),
    normal_image_url: z.optional(z.string()),
    embeddings: z.optional(z.array(zFalAiSdxlControlnetUnionImageToImageEmbedding)).default([]),
    teed_image_url: z.optional(z.string()),
    loras: z.optional(z.array(zFalAiSdxlControlnetUnionImageToImageLoraWeight)).default([]),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(7.5),
    canny_image_url: z.optional(z.string()),
    segmentation_preprocess: z.optional(z.boolean()).default(true),
    format: z.optional(z.enum(['jpeg', 'png'])),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(false),
    request_id: z.optional(z.string()).default(''),
    seed: z.optional(z.int()),
    segmentation_image_url: z.optional(z.string()),
    openpose_image_url: z.optional(z.string()),
    canny_preprocess: z.optional(z.boolean()).default(true),
    expand_prompt: z.optional(z.boolean()).default(false),
    depth_image_url: z.optional(z.string()),
    normal_preprocess: z.optional(z.boolean()).default(true),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    preserve_aspect_ratio: z.optional(z.boolean()).default(false),
    negative_prompt: z.optional(z.string()).default(''),
    crop_output: z.optional(z.boolean()).default(false),
    teed_preprocess: z.optional(z.boolean()).default(true),
    num_images: z.optional(z.int().gte(1).lte(8)).default(1),
    controlnet_conditioning_scale: z.optional(z.number().gte(0).lte(1)).default(0.5),
    strength: z.optional(z.number().gte(0.05).lte(1)).default(0.95),
    safety_checker_version: z.optional(z.enum(['v1', 'v2'])),
    openpose_preprocess: z.optional(z.boolean()).default(true),
    num_inference_steps: z.optional(z.int().gte(1).lte(70)).default(35)
});

/**
 * Image
 */
export const zFalAiSdxlControlnetUnionImageToImageImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zSdxlControlnetUnionImageToImageOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiSdxlControlnetUnionImageToImageImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * Era3DInput
 */
export const zEra3dInput = z.object({
    cfg: z.optional(z.number().gte(0).lte(20)).default(4),
    background_removal: z.optional(z.boolean()).default(true),
    steps: z.optional(z.int().gte(1).lte(200)).default(40),
    crop_size: z.optional(z.int().gte(256).lte(512)).default(400),
    seed: z.optional(z.int()).default(-1),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiEra3dImage = z.object({
    file_size: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    height: z.optional(z.union([
        z.int(),
        z.unknown()
    ])),
    file_name: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    content_type: z.optional(z.union([
        z.string(),
        z.unknown()
    ])),
    url: z.string(),
    width: z.optional(z.union([
        z.int(),
        z.unknown()
    ]))
});

/**
 * Era3DOutput
 */
export const zEra3dOutput = z.object({
    images: z.array(zFalAiEra3dImage),
    seed: z.int(),
    normal_images: z.array(zFalAiEra3dImage)
});

/**
 * ImageWithTextInput
 */
export const zFlorence2LargeReferringExpressionSegmentationInput = z.object({
    text_input: z.string(),
    image_url: z.string()
});

/**
 * Polygon
 */
export const zPolygon = z.object({
    points: z.array(z.record(z.string(), z.number())),
    label: z.string()
});

/**
 * PolygonOutput
 */
export const zPolygonOutput = z.object({
    polygons: z.array(zPolygon)
});

/**
 * ImageInput
 */
export const zFlorence2LargeDenseRegionCaptionInput = z.object({
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlorence2LargeDenseRegionCaptionImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * BoundingBox
 */
export const zBoundingBox = z.object({
    y: z.number(),
    label: z.string(),
    h: z.number(),
    w: z.number(),
    x: z.number()
});

/**
 * BoundingBoxes
 */
export const zBoundingBoxes = z.object({
    bboxes: z.array(zBoundingBox)
});

/**
 * BoundingBoxOutputWithLabels
 */
export const zFlorence2LargeDenseRegionCaptionOutput = z.object({
    image: z.optional(zFalAiFlorence2LargeDenseRegionCaptionImage),
    results: zBoundingBoxes
});

/**
 * ImageInput
 */
export const zFlorence2LargeObjectDetectionInput = z.object({
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlorence2LargeObjectDetectionImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * BoundingBox
 */
export const zFalAiFlorence2LargeObjectDetectionBoundingBox = z.object({
    y: z.number(),
    label: z.string(),
    h: z.number(),
    w: z.number(),
    x: z.number()
});

/**
 * BoundingBoxes
 */
export const zFalAiFlorence2LargeObjectDetectionBoundingBoxes = z.object({
    bboxes: z.array(zFalAiFlorence2LargeObjectDetectionBoundingBox)
});

/**
 * BoundingBoxOutputWithLabels
 */
export const zFlorence2LargeObjectDetectionOutput = z.object({
    image: z.optional(zFalAiFlorence2LargeObjectDetectionImage),
    results: zFalAiFlorence2LargeObjectDetectionBoundingBoxes
});

/**
 * ImageWithTextInput
 */
export const zFlorence2LargeOpenVocabularyDetectionInput = z.object({
    text_input: z.string(),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlorence2LargeOpenVocabularyDetectionImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * BoundingBox
 */
export const zFalAiFlorence2LargeOpenVocabularyDetectionBoundingBox = z.object({
    y: z.number(),
    label: z.string(),
    h: z.number(),
    w: z.number(),
    x: z.number()
});

/**
 * BoundingBoxes
 */
export const zFalAiFlorence2LargeOpenVocabularyDetectionBoundingBoxes = z.object({
    bboxes: z.array(zFalAiFlorence2LargeOpenVocabularyDetectionBoundingBox)
});

/**
 * BoundingBoxOutputWithLabels
 */
export const zFlorence2LargeOpenVocabularyDetectionOutput = z.object({
    image: z.optional(zFalAiFlorence2LargeOpenVocabularyDetectionImage),
    results: zFalAiFlorence2LargeOpenVocabularyDetectionBoundingBoxes
});

/**
 * ImageWithTextInput
 */
export const zFlorence2LargeCaptionToPhraseGroundingInput = z.object({
    text_input: z.string(),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlorence2LargeCaptionToPhraseGroundingImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * BoundingBox
 */
export const zFalAiFlorence2LargeCaptionToPhraseGroundingBoundingBox = z.object({
    y: z.number(),
    label: z.string(),
    h: z.number(),
    w: z.number(),
    x: z.number()
});

/**
 * BoundingBoxes
 */
export const zFalAiFlorence2LargeCaptionToPhraseGroundingBoundingBoxes = z.object({
    bboxes: z.array(zFalAiFlorence2LargeCaptionToPhraseGroundingBoundingBox)
});

/**
 * BoundingBoxOutputWithLabels
 */
export const zFlorence2LargeCaptionToPhraseGroundingOutput = z.object({
    image: z.optional(zFalAiFlorence2LargeCaptionToPhraseGroundingImage),
    results: zFalAiFlorence2LargeCaptionToPhraseGroundingBoundingBoxes
});

/**
 * ImageInput
 */
export const zFlorence2LargeOcrWithRegionInput = z.object({
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlorence2LargeOcrWithRegionImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * OCRBoundingBoxSingle
 */
export const zOcrBoundingBoxSingle = z.object({
    y: z.number(),
    label: z.string(),
    h: z.number(),
    w: z.number(),
    x: z.number()
});

/**
 * OCRBoundingBox
 */
export const zOcrBoundingBox = z.object({
    quad_boxes: z.array(zOcrBoundingBoxSingle)
});

/**
 * OCRBoundingBoxOutputWithLabels
 */
export const zFlorence2LargeOcrWithRegionOutput = z.object({
    image: z.optional(zFalAiFlorence2LargeOcrWithRegionImage),
    results: zOcrBoundingBox
});

/**
 * ImageInput
 */
export const zFlorence2LargeRegionProposalInput = z.object({
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlorence2LargeRegionProposalImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * BoundingBox
 */
export const zFalAiFlorence2LargeRegionProposalBoundingBox = z.object({
    y: z.number(),
    label: z.string(),
    h: z.number(),
    w: z.number(),
    x: z.number()
});

/**
 * BoundingBoxes
 */
export const zFalAiFlorence2LargeRegionProposalBoundingBoxes = z.object({
    bboxes: z.array(zFalAiFlorence2LargeRegionProposalBoundingBox)
});

/**
 * BoundingBoxOutputWithLabels
 */
export const zFlorence2LargeRegionProposalOutput = z.object({
    image: z.optional(zFalAiFlorence2LargeRegionProposalImage),
    results: zFalAiFlorence2LargeRegionProposalBoundingBoxes
});

/**
 * Region
 */
export const zRegion = z.object({
    y1: z.int().gte(0).lte(999),
    x2: z.int().gte(0).lte(999),
    x1: z.int().gte(0).lte(999),
    y2: z.int().gte(0).lte(999)
});

/**
 * ImageWithUserCoordinatesInput
 */
export const zFlorence2LargeRegionToSegmentationInput = z.object({
    region: zRegion,
    image_url: z.string()
});

/**
 * Polygon
 */
export const zFalAiFlorence2LargeRegionToSegmentationPolygon = z.object({
    points: z.array(z.record(z.string(), z.number())),
    label: z.string()
});

/**
 * PolygonOutput
 */
export const zFalAiFlorence2LargeRegionToSegmentationPolygonOutput = z.object({
    polygons: z.array(zFalAiFlorence2LargeRegionToSegmentationPolygon)
});

/**
 * ImageSize
 */
export const zFalAiStableDiffusionV3MediumImageToImageImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * ImageToImageInput
 */
export const zStableDiffusionV3MediumImageToImageInput = z.object({
    prompt_expansion: z.optional(z.boolean()).default(false),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    image_size: z.optional(z.union([
        zFalAiStableDiffusionV3MediumImageToImageImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.null()
    ])),
    prompt: z.string(),
    image_url: z.string(),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.9),
    sync_mode: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(5),
    seed: z.optional(z.int()),
    num_inference_steps: z.optional(z.int().gte(1).lte(50)).default(28),
    negative_prompt: z.optional(z.string()).default(''),
    enable_safety_checker: z.optional(z.boolean()).default(true)
});

/**
 * Image
 */
export const zFalAiStableDiffusionV3MediumImageToImageImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * SD3Output
 */
export const zStableDiffusionV3MediumImageToImageOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiStableDiffusionV3MediumImageToImageImage),
    num_images: z.int(),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * DWPoseInput
 */
export const zDwposeInput = z.object({
    draw_mode: z.optional(z.enum([
        'full-pose',
        'body-pose',
        'face-pose',
        'hand-pose',
        'face-hand-mask',
        'face-mask',
        'hand-mask'
    ])),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiDwposeImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * DWPoseOutput
 */
export const zDwposeOutput = z.object({
    image: zFalAiDwposeImage
});

/**
 * ImageSize
 */
export const zFalAiSd15DepthControlnetImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * LoraWeight
 */
export const zFalAiSd15DepthControlnetLoraWeight = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(1)).default(1)
});

/**
 * TextToImageControlNetInput
 */
export const zSd15DepthControlnetInput = z.object({
    prompt: z.string(),
    image_size: z.optional(z.union([
        zFalAiSd15DepthControlnetImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.null()
    ])),
    expand_prompt: z.optional(z.boolean()).default(false),
    loras: z.optional(z.array(zFalAiSd15DepthControlnetLoraWeight)).default([]),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(7.5),
    enable_safety_checker: z.optional(z.boolean()).default(false),
    negative_prompt: z.optional(z.string()).default(''),
    num_images: z.optional(z.int().gte(1).lte(8)).default(1),
    controlnet_conditioning_scale: z.optional(z.number().gte(0).lte(1)).default(0.5),
    sync_mode: z.optional(z.boolean()).default(false),
    control_image_url: z.string(),
    num_inference_steps: z.optional(z.int().gte(1).lte(70)).default(35),
    seed: z.optional(z.int()),
    enable_deep_cache: z.optional(z.boolean()).default(false)
});

/**
 * Image
 */
export const zFalAiSd15DepthControlnetImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zSd15DepthControlnetOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiSd15DepthControlnetImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * CCSRInput
 */
export const zCcsrInput = z.object({
    color_fix_type: z.optional(z.enum([
        'none',
        'wavelet',
        'adain'
    ])),
    tile_diffusion_size: z.optional(z.int().gte(256).lte(2048)).default(1024),
    tile_vae_decoder_size: z.optional(z.int().gte(64).lte(2048)).default(226),
    tile_vae_encoder_size: z.optional(z.int().gte(128).lte(2048)).default(1024),
    t_min: z.optional(z.number().gte(0).lte(1)).default(0.3333),
    image_url: z.string(),
    tile_diffusion_stride: z.optional(z.int().gte(128).lte(1024)).default(512),
    tile_vae: z.optional(z.boolean()).default(false),
    scale: z.optional(z.number().gte(1).lte(4)).default(2),
    seed: z.optional(z.int()),
    t_max: z.optional(z.number().gte(0).lte(1)).default(0.6667),
    steps: z.optional(z.int().gte(10).lte(100)).default(50),
    tile_diffusion: z.optional(z.enum([
        'none',
        'mix',
        'gaussian'
    ]))
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiCcsrImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * CCSROutput
 */
export const zCcsrOutput = z.object({
    image: zFalAiCcsrImage,
    seed: z.int()
});

/**
 * OmniZeroInput
 */
export const zOmniZeroInput = z.object({
    prompt: z.string(),
    identity_image_url: z.string(),
    identity_strength: z.optional(z.number()).default(1),
    number_of_images: z.optional(z.int()).default(1),
    guidance_scale: z.optional(z.number()).default(5),
    image_strength: z.optional(z.number()).default(0.75),
    negative_prompt: z.optional(z.string()).default(''),
    composition_image_url: z.string(),
    depth_strength: z.optional(z.number()).default(0.5),
    composition_strength: z.optional(z.number()).default(1),
    image_url: z.string(),
    style_image_url: z.string(),
    face_strength: z.optional(z.number()).default(1),
    style_strength: z.optional(z.number()).default(1),
    seed: z.optional(z.int()).default(42)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiOmniZeroImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * OmniZeroOutput
 */
export const zOmniZeroOutput = z.object({
    image: zFalAiOmniZeroImage
});

/**
 * IpAdapterFaceIdInput
 */
export const zIpAdapterFaceIdInput = z.object({
    prompt: z.string(),
    face_image_url: z.optional(z.string()),
    width: z.optional(z.int().gte(512).lte(1024)).default(512),
    face_id_det_size: z.optional(z.int().gte(64).lte(640)).default(640),
    guidance_scale: z.optional(z.number().gte(0).lte(16)).default(7.5),
    negative_prompt: z.optional(z.string()).default('blurry, low resolution, bad, ugly, low quality, pixelated, interpolated, compression artifacts, noisey, grainy'),
    height: z.optional(z.int().gte(512).lte(1024)).default(512),
    num_samples: z.optional(z.int().gte(1).lte(4)).default(4),
    base_sdxl_model_repo: z.optional(z.string()).default('SG161222/RealVisXL_V3.0'),
    base_1_5_model_repo: z.optional(z.string()).default('SG161222/Realistic_Vision_V4.0_noVAE'),
    num_inference_steps: z.optional(z.int().gte(1).lte(200)).default(50),
    model_type: z.optional(z.enum([
        '1_5-v1',
        '1_5-v1-plus',
        '1_5-v2-plus',
        'SDXL-v1',
        'SDXL-v2-plus',
        '1_5-auraface-v1'
    ])),
    face_images_data_url: z.optional(z.string()),
    seed: z.optional(z.int())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiIpAdapterFaceIdImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * IpAdapterFaceIdOutput
 */
export const zIpAdapterFaceIdOutput = z.object({
    image: zFalAiIpAdapterFaceIdImage,
    seed: z.int()
});

/**
 * TimestepsInput
 */
export const zTimestepsInput = z.object({
    method: z.optional(z.enum(['default', 'array'])),
    array: z.optional(z.array(z.int())).default([])
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiLoraInpaintImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * File
 */
export const zFalAiLoraInpaintFile = z.object({
    file_size: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    url: z.string(),
    file_data: z.optional(z.string())
});

/**
 * OutputParameters
 */
export const zLoraInpaintOutput = z.object({
    images: z.array(zFalAiLoraInpaintImage),
    debug_latents: z.optional(zFalAiLoraInpaintFile),
    seed: z.int(),
    has_nsfw_concepts: z.array(z.boolean()),
    debug_per_pass_latents: z.optional(zFalAiLoraInpaintFile)
});

/**
 * TimestepsInput
 */
export const zFalAiLoraImageToImageTimestepsInput = z.object({
    method: z.optional(z.enum(['default', 'array'])),
    array: z.optional(z.array(z.int())).default([])
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiLoraImageToImageImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * File
 */
export const zFalAiLoraImageToImageFile = z.object({
    file_size: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    url: z.string(),
    file_data: z.optional(z.string())
});

/**
 * OutputParameters
 */
export const zLoraImageToImageOutput = z.object({
    images: z.array(zFalAiLoraImageToImageImage),
    debug_latents: z.optional(zFalAiLoraImageToImageFile),
    seed: z.int(),
    has_nsfw_concepts: z.array(z.boolean()),
    debug_per_pass_latents: z.optional(zFalAiLoraImageToImageFile)
});

/**
 * ImageSize
 */
export const zFalAiFastSdxlImageToImageImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * Embedding
 */
export const zFalAiFastSdxlImageToImageEmbedding = z.object({
    tokens: z.optional(z.array(z.string())).default(['<s0>', '<s1>']),
    path: z.string()
});

/**
 * LoraWeight
 */
export const zFalAiFastSdxlImageToImageLoraWeight = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(1)).default(1),
    force: z.optional(z.boolean()).default(false)
});

/**
 * ImageToImageInput
 */
export const zFastSdxlImageToImageInput = z.object({
    prompt: z.string(),
    image_size: z.optional(z.union([
        zFalAiFastSdxlImageToImageImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    embeddings: z.optional(z.array(zFalAiFastSdxlImageToImageEmbedding)).default([]),
    expand_prompt: z.optional(z.boolean()).default(false),
    loras: z.optional(z.array(zFalAiFastSdxlImageToImageLoraWeight)).default([]),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(7.5),
    preserve_aspect_ratio: z.optional(z.boolean()).default(false),
    negative_prompt: z.optional(z.string()).default(''),
    crop_output: z.optional(z.boolean()).default(false),
    format: z.optional(z.enum(['jpeg', 'png'])),
    num_images: z.optional(z.int().gte(1).lte(8)).default(1),
    image_url: z.string(),
    strength: z.optional(z.number().gte(0.05).lte(1)).default(0.95),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_checker_version: z.optional(z.enum(['v1', 'v2'])),
    request_id: z.optional(z.string()).default(''),
    seed: z.optional(z.int()),
    num_inference_steps: z.optional(z.int().gte(1).lte(65)).default(25)
});

/**
 * Image
 */
export const zFalAiFastSdxlImageToImageImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFastSdxlImageToImageOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFastSdxlImageToImageImage),
    seed: z.int(),
    has_nsfw_concepts: z.array(z.boolean()),
    timings: z.record(z.string(), z.number())
});

/**
 * ImageSize
 */
export const zFalAiFastSdxlInpaintingImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * Embedding
 */
export const zFalAiFastSdxlInpaintingEmbedding = z.object({
    tokens: z.optional(z.array(z.string())).default(['<s0>', '<s1>']),
    path: z.string()
});

/**
 * LoraWeight
 */
export const zFalAiFastSdxlInpaintingLoraWeight = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(1)).default(1),
    force: z.optional(z.boolean()).default(false)
});

/**
 * InpaintingInput
 */
export const zFastSdxlInpaintingInput = z.object({
    prompt: z.string(),
    image_size: z.optional(z.union([
        zFalAiFastSdxlInpaintingImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    embeddings: z.optional(z.array(zFalAiFastSdxlInpaintingEmbedding)).default([]),
    expand_prompt: z.optional(z.boolean()).default(false),
    loras: z.optional(z.array(zFalAiFastSdxlInpaintingLoraWeight)).default([]),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(7.5),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    negative_prompt: z.optional(z.string()).default(''),
    format: z.optional(z.enum(['jpeg', 'png'])),
    num_images: z.optional(z.int().gte(1).lte(8)).default(1),
    image_url: z.string(),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.95),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_checker_version: z.optional(z.enum(['v1', 'v2'])),
    request_id: z.optional(z.string()).default(''),
    num_inference_steps: z.optional(z.int().gte(1).lte(65)).default(25),
    mask_url: z.string(),
    seed: z.optional(z.int())
});

/**
 * Image
 */
export const zFalAiFastSdxlInpaintingImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFastSdxlInpaintingOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFastSdxlInpaintingImage),
    seed: z.int(),
    has_nsfw_concepts: z.array(z.boolean()),
    timings: z.record(z.string(), z.number())
});

/**
 * ImageSize
 */
export const zFalAiFaceToStickerImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * FaceToStickerInput
 */
export const zFaceToStickerInput = z.object({
    prompt: z.string(),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    image_size: z.optional(z.union([
        zFalAiFaceToStickerImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    ip_adapter_weight: z.optional(z.number().gte(0).lte(1)).default(0.2),
    image_url: z.string(),
    upscale_steps: z.optional(z.int().gte(1).lte(20)).default(10),
    instant_id_strength: z.optional(z.number().gte(0).lte(1)).default(0.7),
    upscale: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(0).lte(10)).default(4.5),
    num_inference_steps: z.optional(z.int().gte(10).lte(40)).default(20),
    seed: z.optional(z.int()),
    negative_prompt: z.optional(z.string()).default(''),
    ip_adapter_noise: z.optional(z.number().gte(0).lte(1)).default(0.5)
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFaceToStickerImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * FaceToStickerOutput
 */
export const zFaceToStickerOutput = z.object({
    images: z.array(zFalAiFaceToStickerImage),
    sticker_image: zFalAiFaceToStickerImage,
    sticker_image_background_removed: zFalAiFaceToStickerImage,
    seed: z.int(),
    has_nsfw_concepts: z.record(z.string(), z.boolean())
});

/**
 * PhotoMakerInput
 */
export const zPhotomakerInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(4)).default(1),
    style_strength: z.optional(z.int().gte(15).lte(50)).default(20),
    style: z.optional(z.enum([
        '(No style)',
        'Cinematic',
        'Disney Character',
        'Digital Art',
        'Photographic',
        'Fantasy art',
        'Neonpunk',
        'Enhance',
        'Comic book',
        'Lowpoly',
        'Line art'
    ])),
    guidance_scale: z.optional(z.number().gte(0.1).lte(10)).default(5),
    seed: z.optional(z.int()),
    image_archive_url: z.string(),
    initial_image_url: z.optional(z.string()),
    num_inference_steps: z.optional(z.int().gte(20).lte(100)).default(50),
    initial_image_strength: z.optional(z.number().gte(0).lte(1)).default(0.5),
    base_pipeline: z.optional(z.enum(['photomaker', 'photomaker-style'])),
    negative_prompt: z.optional(z.string()).default('')
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPhotomakerImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    url: z.string(),
    width: z.optional(z.int())
});

/**
 * PhotoMakerOutput
 */
export const zPhotomakerOutput = z.object({
    images: z.array(zFalAiPhotomakerImage),
    seed: z.int()
});

/**
 * CreativeUpscalerInput
 */
export const zCreativeUpscalerInput = z.object({
    shape_preservation: z.optional(z.number().gte(0).lte(3)).default(0.25),
    prompt: z.optional(z.union([
        z.string(),
        z.null()
    ])),
    additional_embedding_url: z.optional(z.string()),
    enable_safety_checks: z.optional(z.boolean()).default(true),
    additional_lora_url: z.optional(z.string()),
    guidance_scale: z.optional(z.number().gte(0).lte(16)).default(7.5),
    scale: z.optional(z.number().gte(1).lte(5)).default(2),
    negative_prompt: z.optional(z.string()).default('blurry, low resolution, bad, ugly, low quality, pixelated, interpolated, compression artifacts, noisey, grainy'),
    skip_ccsr: z.optional(z.boolean()).default(false),
    additional_lora_scale: z.optional(z.number()).default(1),
    detail: z.optional(z.number().gte(0).lte(5)).default(1),
    base_model_url: z.optional(z.string()),
    image_url: z.string(),
    creativity: z.optional(z.number().gte(0).lte(1)).default(0.5),
    override_size_limits: z.optional(z.boolean()).default(false),
    prompt_suffix: z.optional(z.string()).default(' high quality, highly detailed, high resolution, sharp'),
    num_inference_steps: z.optional(z.int().gte(1).lte(200)).default(20),
    model_type: z.optional(z.enum(['SD_1_5', 'SDXL'])),
    seed: z.optional(z.int())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiCreativeUpscalerImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * CreativeUpscalerOutput
 */
export const zCreativeUpscalerOutput = z.object({
    image: zFalAiCreativeUpscalerImage,
    seed: z.int()
});

/**
 * Input
 */
export const zBirefnetInput = z.object({
    operating_resolution: z.optional(z.enum(['1024x1024', '2048x2048'])),
    output_format: z.optional(z.enum([
        'webp',
        'png',
        'gif'
    ])),
    image_url: z.string(),
    model: z.optional(z.enum([
        'General Use (Light)',
        'General Use (Heavy)',
        'Portrait'
    ])),
    sync_mode: z.optional(z.boolean()).default(false),
    output_mask: z.optional(z.boolean()).default(false),
    refine_foreground: z.optional(z.boolean()).default(true)
});

/**
 * ImageFile
 */
export const zFalAiBirefnetImageFile = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * Output
 */
export const zBirefnetOutput = z.object({
    image: zFalAiBirefnetImageFile,
    mask_image: z.optional(zFalAiBirefnetImageFile)
});

/**
 * ImageSize
 */
export const zFalAiFastLightningSdxlImageToImageImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * Embedding
 */
export const zFalAiFastLightningSdxlImageToImageEmbedding = z.object({
    tokens: z.optional(z.array(z.string())).default(['<s0>', '<s1>']),
    path: z.string()
});

/**
 * ImageToImageLightningInput
 */
export const zFastLightningSdxlImageToImageInput = z.object({
    prompt: z.string(),
    image_size: z.optional(z.union([
        zFalAiFastLightningSdxlImageToImageImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    embeddings: z.optional(z.array(zFalAiFastLightningSdxlImageToImageEmbedding)).default([]),
    expand_prompt: z.optional(z.boolean()).default(false),
    guidance_rescale: z.optional(z.number().gte(0).lte(1)).default(0),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    preserve_aspect_ratio: z.optional(z.boolean()).default(false),
    crop_output: z.optional(z.boolean()).default(false),
    format: z.optional(z.enum(['jpeg', 'png'])),
    num_images: z.optional(z.int().gte(1).lte(8)).default(1),
    image_url: z.string(),
    strength: z.optional(z.number().gte(0.05).lte(1)).default(0.95),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_checker_version: z.optional(z.enum(['v1', 'v2'])),
    request_id: z.optional(z.string()).default(''),
    num_inference_steps: z.optional(z.enum([
        '1',
        '2',
        '4',
        '8'
    ])),
    seed: z.optional(z.int())
});

/**
 * Image
 */
export const zFalAiFastLightningSdxlImageToImageImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFastLightningSdxlImageToImageOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFastLightningSdxlImageToImageImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiPlaygroundV25InpaintingImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * Embedding
 */
export const zFalAiPlaygroundV25InpaintingEmbedding = z.object({
    tokens: z.optional(z.array(z.string())).default(['<s0>', '<s1>']),
    path: z.string()
});

/**
 * InpaintingPlaygroundv25Input
 */
export const zPlaygroundV25InpaintingInput = z.object({
    prompt: z.string(),
    image_size: z.optional(z.union([
        zFalAiPlaygroundV25InpaintingImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    embeddings: z.optional(z.array(zFalAiPlaygroundV25InpaintingEmbedding)).default([]),
    expand_prompt: z.optional(z.boolean()).default(false),
    guidance_rescale: z.optional(z.number().gte(0).lte(1)).default(0),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    negative_prompt: z.optional(z.string()).default(''),
    format: z.optional(z.enum(['jpeg', 'png'])),
    num_images: z.optional(z.int().gte(1).lte(8)).default(1),
    image_url: z.string(),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.95),
    safety_checker_version: z.optional(z.enum(['v1', 'v2'])),
    request_id: z.optional(z.string()).default(''),
    seed: z.optional(z.int()),
    mask_url: z.string(),
    num_inference_steps: z.optional(z.int().gte(1).lte(65)).default(25)
});

/**
 * Image
 */
export const zFalAiPlaygroundV25InpaintingImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zPlaygroundV25InpaintingOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiPlaygroundV25InpaintingImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiPlaygroundV25ImageToImageImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * Embedding
 */
export const zFalAiPlaygroundV25ImageToImageEmbedding = z.object({
    tokens: z.optional(z.array(z.string())).default(['<s0>', '<s1>']),
    path: z.string()
});

/**
 * ImageToImagePlaygroundv25Input
 */
export const zPlaygroundV25ImageToImageInput = z.object({
    prompt: z.string(),
    image_size: z.optional(z.union([
        zFalAiPlaygroundV25ImageToImageImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    embeddings: z.optional(z.array(zFalAiPlaygroundV25ImageToImageEmbedding)).default([]),
    expand_prompt: z.optional(z.boolean()).default(false),
    guidance_rescale: z.optional(z.number().gte(0).lte(1)).default(0),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(3),
    preserve_aspect_ratio: z.optional(z.boolean()).default(false),
    negative_prompt: z.optional(z.string()).default(''),
    crop_output: z.optional(z.boolean()).default(false),
    format: z.optional(z.enum(['jpeg', 'png'])),
    num_images: z.optional(z.int().gte(1).lte(8)).default(1),
    image_url: z.string(),
    strength: z.optional(z.number().gte(0.05).lte(1)).default(0.95),
    safety_checker_version: z.optional(z.enum(['v1', 'v2'])),
    request_id: z.optional(z.string()).default(''),
    seed: z.optional(z.int()),
    num_inference_steps: z.optional(z.int().gte(1).lte(65)).default(25)
});

/**
 * Image
 */
export const zFalAiPlaygroundV25ImageToImageImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zPlaygroundV25ImageToImageOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiPlaygroundV25ImageToImageImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiFastLightningSdxlInpaintingImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * Embedding
 */
export const zFalAiFastLightningSdxlInpaintingEmbedding = z.object({
    tokens: z.optional(z.array(z.string())).default(['<s0>', '<s1>']),
    path: z.string()
});

/**
 * InpaintingLightningInput
 */
export const zFastLightningSdxlInpaintingInput = z.object({
    prompt: z.string(),
    image_size: z.optional(z.union([
        zFalAiFastLightningSdxlInpaintingImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    embeddings: z.optional(z.array(zFalAiFastLightningSdxlInpaintingEmbedding)).default([]),
    expand_prompt: z.optional(z.boolean()).default(false),
    guidance_rescale: z.optional(z.number().gte(0).lte(1)).default(0),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    format: z.optional(z.enum(['jpeg', 'png'])),
    num_images: z.optional(z.int().gte(1).lte(8)).default(1),
    image_url: z.string(),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.95),
    sync_mode: z.optional(z.boolean()).default(false),
    safety_checker_version: z.optional(z.enum(['v1', 'v2'])),
    request_id: z.optional(z.string()).default(''),
    num_inference_steps: z.optional(z.enum([
        '1',
        '2',
        '4',
        '8'
    ])),
    mask_url: z.string(),
    seed: z.optional(z.int())
});

/**
 * Image
 */
export const zFalAiFastLightningSdxlInpaintingImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFastLightningSdxlInpaintingOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFastLightningSdxlInpaintingImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiFastLcmDiffusionInpaintingImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * InpaintingLCMInput
 */
export const zFastLcmDiffusionInpaintingInput = z.object({
    prompt: z.string(),
    image_size: z.optional(z.union([
        zFalAiFastLcmDiffusionInpaintingImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    expand_prompt: z.optional(z.boolean()).default(false),
    guidance_rescale: z.optional(z.number().gte(0).lte(1)).default(0),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(1.5),
    negative_prompt: z.optional(z.string()).default(''),
    format: z.optional(z.enum(['jpeg', 'png'])),
    num_images: z.optional(z.int().gte(1).lte(8)).default(1),
    image_url: z.string(),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.95),
    sync_mode: z.optional(z.boolean()).default(true),
    safety_checker_version: z.optional(z.enum(['v1', 'v2'])),
    request_id: z.optional(z.string()).default(''),
    num_inference_steps: z.optional(z.int().gte(1).lte(32)).default(6),
    mask_url: z.string(),
    seed: z.optional(z.int()),
    model_name: z.optional(z.enum(['stabilityai/stable-diffusion-xl-base-1.0', 'runwayml/stable-diffusion-v1-5']))
});

/**
 * Image
 */
export const zFalAiFastLcmDiffusionInpaintingImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFastLcmDiffusionInpaintingOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFastLcmDiffusionInpaintingImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiFastLcmDiffusionImageToImageImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * ImageToImageLCMInput
 */
export const zFastLcmDiffusionImageToImageInput = z.object({
    prompt: z.string(),
    image_size: z.optional(z.union([
        zFalAiFastLcmDiffusionImageToImageImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    expand_prompt: z.optional(z.boolean()).default(false),
    guidance_rescale: z.optional(z.number().gte(0).lte(1)).default(0),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(1.5),
    enable_safety_checker: z.optional(z.boolean()).default(true),
    preserve_aspect_ratio: z.optional(z.boolean()).default(false),
    negative_prompt: z.optional(z.string()).default(''),
    crop_output: z.optional(z.boolean()).default(false),
    format: z.optional(z.enum(['jpeg', 'png'])),
    num_images: z.optional(z.int().gte(1).lte(8)).default(1),
    image_url: z.string(),
    sync_mode: z.optional(z.boolean()).default(true),
    model_name: z.optional(z.enum(['stabilityai/stable-diffusion-xl-base-1.0', 'runwayml/stable-diffusion-v1-5'])),
    safety_checker_version: z.optional(z.enum(['v1', 'v2'])),
    request_id: z.optional(z.string()).default(''),
    num_inference_steps: z.optional(z.int().gte(1).lte(32)).default(6),
    strength: z.optional(z.number().gte(0.05).lte(1)).default(0.95),
    seed: z.optional(z.int())
});

/**
 * Image
 */
export const zFalAiFastLcmDiffusionImageToImageImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFastLcmDiffusionImageToImageOutput = z.object({
    prompt: z.string(),
    images: z.array(zFalAiFastLcmDiffusionImageToImageImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * DepthMapInput
 */
export const zImageutilsDepthInput = z.object({
    bg_th: z.optional(z.number()).default(0.1),
    a: z.optional(z.number()).default(6.283185307179586),
    depth_and_normal: z.optional(z.boolean()).default(false),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageutilsDepthImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * DepthMapOutput
 */
export const zImageutilsDepthOutput = z.object({
    image: zFalAiImageutilsDepthImage
});

/**
 * RetoucherInput
 */
export const zRetoucherInput = z.object({
    seed: z.optional(z.int()),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiRetoucherImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * RetoucherOutput
 */
export const zRetoucherOutput = z.object({
    image: zFalAiRetoucherImage,
    seed: z.int()
});

/**
 * MarigoldDepthMapInput
 */
export const zImageutilsMarigoldDepthInput = z.object({
    ensemble_size: z.optional(z.int().gte(2).lte(50)).default(10),
    num_inference_steps: z.optional(z.int().gte(2).lte(50)).default(10),
    processing_res: z.optional(z.int().gte(0).lte(2048)).default(0),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageutilsMarigoldDepthImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * MarigoldDepthMapOutput
 */
export const zImageutilsMarigoldDepthOutput = z.object({
    image: zFalAiImageutilsMarigoldDepthImage
});

/**
 * ImageSize
 */
export const zFalAiPulidImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * ReferenceFace
 */
export const zReferenceFace = z.object({
    image_url: z.string()
});

/**
 * InputModel
 */
export const zPulidInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(8)).default(1),
    image_size: z.optional(z.union([
        zFalAiPulidImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ])
    ])),
    id_scale: z.optional(z.number().lte(5)).default(0.8),
    mode: z.optional(z.enum(['fidelity', 'extreme style'])),
    id_mix: z.optional(z.boolean()).default(false),
    guidance_scale: z.optional(z.number().gte(1).lte(1.5)).default(1.2),
    num_inference_steps: z.optional(z.int().gte(1).lte(12)).default(4),
    reference_images: z.array(zReferenceFace),
    negative_prompt: z.optional(z.string()).default('flaws in the eyes, flaws in the face, flaws, lowres, non-HDRi, low quality, worst quality,artifacts noise, text, watermark, glitch, deformed, mutated, ugly, disfigured, hands, low resolution, partially rendered objects,  deformed or partially rendered eyes, deformed, deformed eyeballs, cross-eyed,blurry'),
    seed: z.optional(z.int())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPulidImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * OutputModel
 */
export const zPulidOutput = z.object({
    images: z.array(zFalAiPulidImage),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiFastSdxlControlnetCannyInpaintingImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * LoraWeight
 */
export const zFalAiFastSdxlControlnetCannyInpaintingLoraWeight = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(1)).default(1)
});

/**
 * InpaintingControlNetInput
 */
export const zFastSdxlControlnetCannyInpaintingInput = z.object({
    prompt: z.string(),
    image_size: z.optional(z.union([
        zFalAiFastSdxlControlnetCannyInpaintingImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.null()
    ])),
    expand_prompt: z.optional(z.boolean()).default(false),
    loras: z.optional(z.array(zFalAiFastSdxlControlnetCannyInpaintingLoraWeight)).default([]),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(7.5),
    enable_safety_checker: z.optional(z.boolean()).default(false),
    negative_prompt: z.optional(z.string()).default(''),
    num_images: z.optional(z.int().gte(1).lte(8)).default(1),
    controlnet_conditioning_scale: z.optional(z.number().gte(0).lte(1)).default(0.5),
    image_url: z.string(),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.95),
    sync_mode: z.optional(z.boolean()).default(false),
    control_image_url: z.string(),
    seed: z.optional(z.int()),
    mask_url: z.string(),
    num_inference_steps: z.optional(z.int().gte(1).lte(65)).default(25)
});

/**
 * Image
 */
export const zFalAiFastSdxlControlnetCannyInpaintingImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFastSdxlControlnetCannyInpaintingOutput = z.object({
    images: z.array(zFalAiFastSdxlControlnetCannyInpaintingImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * ImageSize
 */
export const zFalAiFastSdxlControlnetCannyImageToImageImageSize = z.object({
    height: z.optional(z.int().lte(14142)).default(512),
    width: z.optional(z.int().lte(14142)).default(512)
});

/**
 * LoraWeight
 */
export const zFalAiFastSdxlControlnetCannyImageToImageLoraWeight = z.object({
    path: z.string(),
    scale: z.optional(z.number().gte(0).lte(1)).default(1)
});

/**
 * ImageToImageControlNetInput
 */
export const zFastSdxlControlnetCannyImageToImageInput = z.object({
    prompt: z.string(),
    image_size: z.optional(z.union([
        zFalAiFastSdxlControlnetCannyImageToImageImageSize,
        z.enum([
            'square_hd',
            'square',
            'portrait_4_3',
            'portrait_16_9',
            'landscape_4_3',
            'landscape_16_9'
        ]),
        z.null()
    ])),
    expand_prompt: z.optional(z.boolean()).default(false),
    loras: z.optional(z.array(zFalAiFastSdxlControlnetCannyImageToImageLoraWeight)).default([]),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(7.5),
    enable_safety_checker: z.optional(z.boolean()).default(false),
    negative_prompt: z.optional(z.string()).default(''),
    num_images: z.optional(z.int().gte(1).lte(8)).default(1),
    controlnet_conditioning_scale: z.optional(z.number().gte(0).lte(1)).default(0.5),
    image_url: z.string(),
    strength: z.optional(z.number().gte(0.01).lte(1)).default(0.95),
    sync_mode: z.optional(z.boolean()).default(false),
    control_image_url: z.string(),
    num_inference_steps: z.optional(z.int().gte(1).lte(65)).default(25),
    seed: z.optional(z.int())
});

/**
 * Image
 */
export const zFalAiFastSdxlControlnetCannyImageToImageImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * Output
 */
export const zFastSdxlControlnetCannyImageToImageOutput = z.object({
    images: z.array(zFalAiFastSdxlControlnetCannyImageToImageImage),
    timings: z.record(z.string(), z.number()),
    has_nsfw_concepts: z.array(z.boolean()),
    seed: z.int()
});

/**
 * LCMI2IInput
 */
export const zLcmSd15I2iInput = z.object({
    prompt: z.string(),
    num_images: z.optional(z.int().gte(1).lte(8)).default(1),
    image_url: z.string(),
    strength: z.optional(z.number().gte(0).lte(1)).default(0.8),
    sync_mode: z.optional(z.boolean()).default(false),
    enable_safety_checks: z.optional(z.boolean()).default(true),
    guidance_scale: z.optional(z.number().gte(0).lte(16)).default(1),
    seed: z.optional(z.int()),
    request_id: z.optional(z.string()).default(''),
    negative_prompt: z.optional(z.string()).default(''),
    num_inference_steps: z.optional(z.int().gte(1).lte(12)).default(4)
});

/**
 * Image
 */
export const zFalAiLcmSd15I2iImage = z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int()
});

/**
 * LCMOutput
 */
export const zLcmSd15I2iOutput = z.object({
    images: z.array(zFalAiLcmSd15I2iImage),
    request_id: z.optional(z.string()).default(''),
    timings: z.record(z.string(), z.number()),
    seed: z.int(),
    num_inference_steps: z.optional(z.int()).default(4),
    nsfw_content_detected: z.array(z.boolean())
});

/**
 * InpaintInput
 */
export const zInpaintInput = z.object({
    prompt: z.string(),
    image_url: z.string(),
    model_name: z.string(),
    guidance_scale: z.optional(z.number().gte(0).lte(20)).default(7.5),
    num_inference_steps: z.optional(z.int().gte(0).lte(150)).default(30),
    mask_url: z.string(),
    negative_prompt: z.optional(z.string()).default(''),
    seed: z.optional(z.int())
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiInpaintImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * InpaintOutput
 */
export const zInpaintOutput = z.object({
    image: zFalAiInpaintImage,
    seed: z.int()
});

/**
 * UpscaleInput
 */
export const zEsrganInput = z.object({
    model: z.optional(z.enum([
        'RealESRGAN_x4plus',
        'RealESRGAN_x2plus',
        'RealESRGAN_x4plus_anime_6B',
        'RealESRGAN_x4_v3',
        'RealESRGAN_x4_wdn_v3',
        'RealESRGAN_x4_anime_v3'
    ])),
    face: z.optional(z.boolean()).default(false),
    scale: z.optional(z.number().gte(1).lte(8)).default(2),
    tile: z.optional(z.int()).default(0),
    output_format: z.optional(z.enum(['png', 'jpeg'])),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiEsrganImage = z.object({
    file_size: z.optional(z.int()),
    height: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * UpscaleOutput
 */
export const zEsrganOutput = z.object({
    image: zFalAiEsrganImage
});

/**
 * RemoveBackgroundInput
 */
export const zImageutilsRembgInput = z.object({
    sync_mode: z.optional(z.boolean()).default(false),
    crop_to_bbox: z.optional(z.boolean()).default(false),
    image_url: z.string()
});

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiImageutilsRembgImage = z.object({
    height: z.optional(z.int()),
    file_size: z.optional(z.int()),
    url: z.string(),
    width: z.optional(z.int()),
    file_name: z.optional(z.string()),
    content_type: z.optional(z.string()),
    file_data: z.optional(z.string())
});

/**
 * RemoveBackgroundOutput
 */
export const zImageutilsRembgOutput = z.object({
    image: zFalAiImageutilsRembgImage
});
