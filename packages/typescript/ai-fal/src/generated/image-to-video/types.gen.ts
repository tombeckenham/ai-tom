// This file is auto-generated by @hey-api/openapi-ts

export type ClientOptions = {
  baseUrl: `${string}://${string}` | (string & {})
}

export type File = {
  url: string
  content_type?: string
  file_name?: string
  file_size?: number
}

export type QueueStatus = {
  status: 'IN_PROGRESS' | 'COMPLETED' | 'FAILED'
  response_url?: string
}

/**
 * BaseInput
 */
export type WanEffectsInput = {
  /**
   * Effect Type
   *
   * The type of effect to apply to the video.
   */
  effect_type?:
    | 'squish'
    | 'muscle'
    | 'inflate'
    | 'crush'
    | 'rotate'
    | 'gun-shooting'
    | 'deflate'
    | 'cakeify'
    | 'hulk'
    | 'baby'
    | 'bride'
    | 'classy'
    | 'puppy'
    | 'snow-white'
    | 'disney-princess'
    | 'mona-lisa'
    | 'painting'
    | 'pirate-captain'
    | 'princess'
    | 'jungle'
    | 'samurai'
    | 'vip'
    | 'warrior'
    | 'zen'
    | 'assassin'
    | 'timelapse'
    | 'tsunami'
    | 'fire'
    | 'zoom-call'
    | 'doom-fps'
    | 'fus-ro-dah'
    | 'hug-jesus'
    | 'robot-face-reveal'
    | 'super-saiyan'
    | 'jumpscare'
    | 'laughing'
    | 'cartoon-jaw-drop'
    | 'crying'
    | 'kissing'
    | 'angry-face'
    | 'selfie-younger-self'
    | 'animeify'
    | 'blast'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the output video.
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Subject
   *
   * The subject to insert into the predefined prompt template for the selected effect.
   */
  subject: string
  /**
   * Lora Scale
   *
   * The scale of the LoRA weight. Used to adjust effect intensity.
   */
  lora_scale?: number
  /**
   * Image URL
   *
   * URL of the input image.
   */
  image_url: string
  /**
   * Turbo Mode
   *
   * Whether to use turbo mode. If True, the video will be generated faster but with lower quality.
   */
  turbo_mode?: boolean
  /**
   * Frames Per Second
   *
   * Frames per second of the generated video.
   */
  frames_per_second?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Num Frames
   *
   * Number of frames to generate.
   */
  num_frames?: number
}

/**
 * WanEffectsOutput
 */
export type WanEffectsOutput = {
  /**
   * Seed
   */
  seed: number
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiWanEffectsFile
}

/**
 * File
 */
export type FalAiWanEffectsFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * WanProI2VRequest
 */
export type WanProImageToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video
   */
  prompt: string
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number | unknown
  /**
   * Image Url
   *
   * The URL of the image to generate the video from
   */
  image_url: string
}

/**
 * WanProI2VResponse
 */
export type WanProImageToVideoOutput = {
  video: FalAiWanProImageToVideoFile
}

/**
 * File
 */
export type FalAiWanProImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * ImageToVideoInput
 */
export type Veo2ImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt describing how the image should be animated
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5s' | '6s' | '7s' | '8s'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: 'auto' | 'auto_prefer_portrait' | '16:9' | '9:16'
  /**
   * Image Url
   *
   * URL of the input image to animate. Should be 720p or higher resolution.
   */
  image_url: string
}

/**
 * ImageToVideoOutput
 */
export type Veo2ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiVeo2ImageToVideoFile
}

/**
 * File
 */
export type FalAiVeo2ImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ProImageToVideoRequest
 */
export type KlingVideoV16ProImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video frame
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Image Url
   */
  image_url: string
  /**
   * Tail Image Url
   *
   * URL of the image to be used for the end of the video
   */
  tail_image_url?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * I2VOutput
 */
export type KlingVideoV16ProImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV16ProImageToVideoFile
}

/**
 * File
 */
export type FalAiKlingVideoV16ProImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoRequest
 */
export type MinimaxVideo01ImageToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Prompt
   */
  prompt: string
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * VideoOutput
 */
export type MinimaxVideo01ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiMinimaxVideo01ImageToVideoFile
}

/**
 * File
 */
export type FalAiMinimaxVideo01ImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ProImageToVideoHailuo23Input
 */
export type MinimaxHailuo23ProImageToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Prompt
   *
   * Text prompt for video generation
   */
  prompt: string
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * ProImageToVideoHailuo23Output
 */
export type MinimaxHailuo23ProImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiMinimaxHailuo23ProImageToVideoFile
}

/**
 * File
 */
export type FalAiMinimaxHailuo23ProImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoInput
 *
 * Input for image-to-video generation
 */
export type Wan25PreviewImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt describing the desired video motion. Max 800 characters.
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution. Valid values: 480p, 720p, 1080p
   */
  resolution?: '480p' | '720p' | '1080p'
  /**
   * Duration
   *
   * Duration of the generated video in seconds. Choose between 5 or 10 seconds.
   */
  duration?: '5' | '10'
  /**
   * Image URL
   *
   * URL of the image to use as the first frame. Must be publicly accessible or base64 data URI.
   *
   * Max file size: 25.0MB, Min width: 360px, Min height: 360px, Max width: 2000px, Max height: 2000px, Timeout: 20.0s
   */
  image_url: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Audio Url
   *
   *
   * URL of the audio to use as the background music. Must be publicly accessible.
   * Limit handling: If the audio duration exceeds the duration value (5 or 10 seconds),
   * the audio is truncated to the first 5 or 10 seconds, and the rest is discarded. If
   * the audio is shorter than the video, the remaining part of the video will be silent.
   * For example, if the audio is 3 seconds long and the video duration is 5 seconds, the
   * first 3 seconds of the output video will have sound, and the last 2 seconds will be silent.
   * - Format: WAV, MP3.
   * - Duration: 3 to 30 s.
   * - File size: Up to 15 MB.
   *
   */
  audio_url?: string
  /**
   * Negative Prompt
   *
   * Negative prompt to describe content to avoid. Max 500 characters.
   */
  negative_prompt?: string
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt rewriting using LLM.
   */
  enable_prompt_expansion?: boolean
}

/**
 * VideoOutput
 *
 * Base output for video generation
 */
export type Wan25PreviewImageToVideoOutput = {
  /**
   * Actual Prompt
   *
   * The actual prompt used if prompt rewriting was enabled
   */
  actual_prompt?: string
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * The generated video file
   */
  video: VideoFile
}

/**
 * VideoFile
 */
export type VideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number
  /**
   * Height
   *
   * The height of the video
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number
  /**
   * Width
   *
   * The width of the video
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoV25ProRequest
 */
export type KlingVideoV25TurboProImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Tail Image Url
   *
   * URL of the image to be used for the end of the video
   */
  tail_image_url?: string
  /**
   * Image Url
   *
   * URL of the image to be used for the video
   */
  image_url: string
}

/**
 * ImageToVideoV25ProOutput
 */
export type KlingVideoV25TurboProImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV25TurboProImageToVideoFile
}

/**
 * File
 */
export type FalAiKlingVideoV25TurboProImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * StandardImageToVideoHailuo02Input
 */
export type MinimaxHailuo02StandardImageToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Duration
   *
   * The duration of the video in seconds. 10 seconds videos are not supported for 1080p resolution.
   */
  duration?: '6' | '10'
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '512P' | '768P'
  /**
   * Prompt
   */
  prompt: string
  /**
   * End Image Url
   *
   * Optional URL of the image to use as the last frame of the video
   */
  end_image_url?: string
  /**
   * Image Url
   */
  image_url: string
}

/**
 * ImageToVideoHailuo02Output
 */
export type MinimaxHailuo02StandardImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiMinimaxHailuo02StandardImageToVideoFile
}

/**
 * File
 */
export type FalAiMinimaxHailuo02StandardImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * SeedanceProImageToVideoInput
 */
export type BytedanceSeedanceV1ProImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt used to generate the video
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality
   */
  resolution?: '480p' | '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '21:9' | '16:9' | '4:3' | '1:1' | '3:4' | '9:16' | 'auto'
  /**
   * Duration
   *
   * Duration of the video in seconds
   */
  duration?: '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9' | '10' | '11' | '12'
  /**
   * Image Url
   *
   * The URL of the image used to generate video
   */
  image_url: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Camera Fixed
   *
   * Whether to fix the camera position
   */
  camera_fixed?: boolean
  /**
   * End Image Url
   *
   * The URL of the image the video ends with. Defaults to None.
   */
  end_image_url?: string
  /**
   * Seed
   *
   * Random seed to control video generation. Use -1 for random.
   */
  seed?: number
}

/**
 * SeedanceProI2VVideoOutput
 */
export type BytedanceSeedanceV1ProImageToVideoOutput = {
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * Generated video file
   */
  video: FalAiBytedanceSeedanceV1ProImageToVideoFile
}

/**
 * File
 */
export type FalAiBytedanceSeedanceV1ProImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoV21MasterRequest
 */
export type KlingVideoV21MasterImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Image Url
   *
   * URL of the image to be used for the video
   */
  image_url: string
}

/**
 * ImageToVideoV21MasterOutput
 */
export type KlingVideoV21MasterImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV21MasterImageToVideoFile
}

/**
 * File
 */
export type FalAiKlingVideoV21MasterImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoV21StandardRequest
 */
export type KlingVideoV21StandardImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Image Url
   *
   * URL of the image to be used for the video
   */
  image_url: string
}

/**
 * ImageToVideoV21StandardOutput
 */
export type KlingVideoV21StandardImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV21StandardImageToVideoFile
}

/**
 * File
 */
export type FalAiKlingVideoV21StandardImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoV2MasterRequest
 */
export type KlingVideoV2MasterImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Image Url
   *
   * URL of the image to be used for the video
   */
  image_url: string
}

/**
 * ImageToVideoV2MasterOutput
 */
export type KlingVideoV2MasterImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV2MasterImageToVideoFile
}

/**
 * File
 */
export type FalAiKlingVideoV2MasterImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * WanI2VRequest
 */
export type WanI2vInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Shift
   *
   * Shift parameter for video generation.
   */
  shift?: number
  /**
   * Acceleration
   *
   * Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Frames Per Second
   *
   * Frames per second of the generated video. Must be between 5 to 24.
   */
  frames_per_second?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Frames
   *
   * Number of frames to generate. Must be between 81 to 100 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.
   */
  num_frames?: number
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16' | '1:1'
  /**
   * Resolution
   *
   * Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.
   */
  resolution?: '480p' | '720p'
  /**
   * Image Url
   *
   * URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Guide Scale
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guide_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
}

/**
 * WanI2VResponse
 */
export type WanI2vOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiWanI2vFile
}

/**
 * File
 */
export type FalAiWanI2vFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Q2ProReferenceToVideoRequest
 */
export type ViduQ2ReferenceToVideoProInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 2000 characters
   */
  prompt: string
  /**
   * Resolution
   *
   * Output video resolution
   */
  resolution?: '540p' | '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the output video (e.g., auto, 16:9, 9:16, 1:1, or any W:H)
   */
  aspect_ratio?: string
  /**
   * Duration
   *
   * Duration of the video in seconds (0 for automatic duration)
   */
  duration?: number
  /**
   * Reference Video Urls
   *
   * URLs of the reference videos for video editing or motion reference. Supports up to 2 videos.
   */
  reference_video_urls?: Array<string>
  /**
   * Bgm
   *
   * Whether to add background music to the generated video
   */
  bgm?: boolean
  /**
   * Reference Image Urls
   *
   * URLs of the reference images for subject appearance. If videos are provided, up to 4 images are allowed; otherwise up to 7 images.
   */
  reference_image_urls?: Array<string>
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Movement Amplitude
   *
   * The movement amplitude of objects in the frame
   */
  movement_amplitude?: 'auto' | 'small' | 'medium' | 'large'
}

/**
 * Q2ProReferenceToVideoOutput
 */
export type ViduQ2ReferenceToVideoProOutput = {
  /**
   * Video
   *
   * The generated video with video/image references using the Q2 Pro model
   */
  video: FalAiViduQ2ReferenceToVideoProFile
}

/**
 * File
 */
export type FalAiViduQ2ReferenceToVideoProFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoInput
 *
 * Input for Wan 2.6 image-to-video generation
 */
export type V26ImageToVideoFlashInput = {
  /**
   * Prompt
   *
   * The text prompt describing the desired video motion. Max 800 characters.
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution. Valid values: 720p, 1080p
   */
  resolution?: '720p' | '1080p'
  /**
   * Duration
   *
   * Duration of the generated video in seconds. Choose between 5, 10 or 15 seconds.
   */
  duration?: '5' | '10' | '15'
  /**
   * Audio Url
   *
   *
   * URL of the audio to use as the background music. Must be publicly accessible.
   * Limit handling: If the audio duration exceeds the duration value (5, 10, or 15 seconds),
   * the audio is truncated to the first N seconds, and the rest is discarded. If
   * the audio is shorter than the video, the remaining part of the video will be silent.
   * For example, if the audio is 3 seconds long and the video duration is 5 seconds, the
   * first 3 seconds of the output video will have sound, and the last 2 seconds will be silent.
   * - Format: WAV, MP3.
   * - Duration: 3 to 30 s.
   * - File size: Up to 15 MB.
   *
   */
  audio_url?: string
  /**
   * Image URL
   *
   * URL of the image to use as the first frame. Must be publicly accessible or base64 data URI. Image dimensions must be between 240 and 7680.
   */
  image_url: string
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt rewriting using LLM.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Multi Shots
   *
   * When true, enables intelligent multi-shot segmentation. Only active when enable_prompt_expansion is True. Set to false for single-shot generation.
   */
  multi_shots?: boolean
  /**
   * Negative Prompt
   *
   * Negative prompt to describe content to avoid. Max 500 characters.
   */
  negative_prompt?: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
}

/**
 * ImageToVideoOutput
 *
 * Output for image-to-video generation
 */
export type V26ImageToVideoFlashOutput = {
  /**
   * Actual Prompt
   *
   * The actual prompt used if prompt rewriting was enabled
   */
  actual_prompt?: string
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * The generated video file
   */
  video: WanV26ImageToVideoFlashVideoFile
}

/**
 * VideoFile
 */
export type WanV26ImageToVideoFlashVideoFile = {
  /**
   * Height
   *
   * The height of the video
   */
  height?: number
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number
  /**
   * Width
   *
   * The width of the video
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export type LoRaInput = {
  /**
   * Path
   *
   * URL, HuggingFace repo ID (owner/repo) to lora weights.
   */
  path: string
  /**
   * Scale
   *
   * Scale factor for LoRA application (0.0 to 4.0).
   */
  scale?: number
  /**
   * Weight Name
   *
   * Name of the LoRA weight. Only used if `path` is a HuggingFace repository, and is only required when the repository contains multiple LoRA weights.
   */
  weight_name?: string | unknown
}

/**
 * LTX2ImageToVideoOutput
 */
export type Ltx219bDistilledImageToVideoLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for the generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for the random number generator.
   */
  seed: number
  video: FalAiLtx219bDistilledImageToVideoLoraVideoFile
}

/**
 * VideoFile
 */
export type FalAiLtx219bDistilledImageToVideoLoraVideoFile = {
  /**
   * Height
   *
   * The height of the video
   */
  height?: number | unknown
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number | unknown
  /**
   * Width
   *
   * The width of the video
   */
  width?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
}

/**
 * LTX2DistilledImageToVideoInput
 */
export type Ltx219bDistilledImageToVideoInput = {
  /**
   * Use Multi-Scale
   *
   * Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.
   */
  use_multiscale?: boolean
  /**
   * Prompt
   *
   * The prompt used for the generation.
   */
  prompt: string
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: 'none' | 'regular' | 'high' | 'full'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * FPS
   *
   * The frames per second of the generated video.
   */
  fps?: number
  /**
   * Camera LoRA
   *
   * The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.
   */
  camera_lora?:
    | 'dolly_in'
    | 'dolly_out'
    | 'dolly_left'
    | 'dolly_right'
    | 'jib_up'
    | 'jib_down'
    | 'static'
    | 'none'
  /**
   * Video Size
   *
   * The size of the generated video.
   */
  video_size?:
    | ImageSize
    | 'auto'
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Image Strength
   *
   * The strength of the image to use for the video generation.
   */
  image_strength?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to generate the video from.
   */
  negative_prompt?: string
  /**
   * Camera LoRA Scale
   *
   * The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.
   */
  camera_lora_scale?: number
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * Image URL
   *
   * The URL of the image to generate the video from.
   */
  image_url: string
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number | unknown
}

/**
 * ImageSize
 */
export type ImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * LTX2ImageToVideoOutput
 */
export type Ltx219bDistilledImageToVideoOutput = {
  /**
   * Prompt
   *
   * The prompt used for the generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for the random number generator.
   */
  seed: number
  video: FalAiLtx219bDistilledImageToVideoVideoFile
}

/**
 * VideoFile
 */
export type FalAiLtx219bDistilledImageToVideoVideoFile = {
  /**
   * Height
   *
   * The height of the video
   */
  height?: number | unknown
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number | unknown
  /**
   * Width
   *
   * The width of the video
   */
  width?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
}

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export type FalAiLtx219bImageToVideoLoraLoRaInput = {
  /**
   * Path
   *
   * URL, HuggingFace repo ID (owner/repo) to lora weights.
   */
  path: string
  /**
   * Scale
   *
   * Scale factor for LoRA application (0.0 to 4.0).
   */
  scale?: number
  /**
   * Weight Name
   *
   * Name of the LoRA weight. Only used if `path` is a HuggingFace repository, and is only required when the repository contains multiple LoRA weights.
   */
  weight_name?: string | unknown
}

/**
 * LTX2ImageToVideoOutput
 */
export type Ltx219bImageToVideoLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for the generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for the random number generator.
   */
  seed: number
  video: FalAiLtx219bImageToVideoLoraVideoFile
}

/**
 * VideoFile
 */
export type FalAiLtx219bImageToVideoLoraVideoFile = {
  /**
   * Height
   *
   * The height of the video
   */
  height?: number | unknown
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number | unknown
  /**
   * Width
   *
   * The width of the video
   */
  width?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
}

/**
 * LTX2ImageToVideoInput
 */
export type Ltx219bImageToVideoInput = {
  /**
   * Use Multi-Scale
   *
   * Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.
   */
  use_multiscale?: boolean
  /**
   * Prompt
   *
   * The prompt used for the generation.
   */
  prompt: string
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: 'none' | 'regular' | 'high' | 'full'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * FPS
   *
   * The frames per second of the generated video.
   */
  fps?: number
  /**
   * Camera LoRA
   *
   * The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.
   */
  camera_lora?:
    | 'dolly_in'
    | 'dolly_out'
    | 'dolly_left'
    | 'dolly_right'
    | 'jib_up'
    | 'jib_down'
    | 'static'
    | 'none'
  /**
   * Video Size
   *
   * The size of the generated video.
   */
  video_size?:
    | FalAiLtx219bImageToVideoImageSize
    | 'auto'
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Guidance Scale
   *
   * The guidance scale to use.
   */
  guidance_scale?: number
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Image Strength
   *
   * The strength of the image to use for the video generation.
   */
  image_strength?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to generate the video from.
   */
  negative_prompt?: string
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * Camera LoRA Scale
   *
   * The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.
   */
  camera_lora_scale?: number
  /**
   * Image URL
   *
   * The URL of the image to generate the video from.
   */
  image_url: string
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number | unknown
}

/**
 * ImageSize
 */
export type FalAiLtx219bImageToVideoImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * LTX2ImageToVideoOutput
 */
export type Ltx219bImageToVideoOutput = {
  /**
   * Prompt
   *
   * The prompt used for the generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for the random number generator.
   */
  seed: number
  video: FalAiLtx219bImageToVideoVideoFile
}

/**
 * VideoFile
 */
export type FalAiLtx219bImageToVideoVideoFile = {
  /**
   * Height
   *
   * The height of the video
   */
  height?: number | unknown
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number | unknown
  /**
   * Width
   *
   * The width of the video
   */
  width?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
}

/**
 * WANMoveInput
 */
export type WanMoveInput = {
  /**
   * Prompt
   *
   * Text prompt to guide the video generation.
   */
  prompt: string
  /**
   * Trajectories
   *
   * A list of trajectories. Each trajectory list means the movement of one object.
   */
  trajectories: Array<Array<TrajectoryPoint>>
  /**
   * Image Url
   *
   * URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Guidance Scale
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to guide the video generation.
   */
  negative_prompt?: string
}

/**
 * WanMoveOutput
 */
export type WanMoveOutput = {
  /**
   * Seed
   *
   * Random seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * Generated Video File
   */
  video: FalAiWanMoveVideoFile
}

/**
 * VideoFile
 */
export type FalAiWanMoveVideoFile = {
  /**
   * Height
   *
   * The height of the video
   */
  height?: number
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the video
   */
  width?: number
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Placeholder for missing schema TrajectoryPoint (referenced but not defined in source OpenAPI spec)
 */
export type TrajectoryPoint = {
  [key: string]: unknown
}

/**
 * KandinskyI2VRequest
 */
export type Kandinsky5ProImageToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution: 512p or 1024p.
   */
  resolution?: '512P' | '1024P'
  /**
   * Acceleration
   *
   * Acceleration level for faster generation.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Duration
   *
   * Video duration.
   */
  duration?: '5s'
  /**
   * Num Inference Steps
   */
  num_inference_steps?: number
  /**
   * Image Url
   *
   * The URL of the image to use as a reference for the video generation.
   */
  image_url: string
}

/**
 * KandinskyI2VResponse
 */
export type Kandinsky5ProImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video file.
   */
  video?: FalAiKandinsky5ProImageToVideoFile
}

/**
 * File
 */
export type FalAiKandinsky5ProImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * SeedanceProv15ImageToVideoInput
 */
export type BytedanceSeedanceV15ProImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt used to generate the video
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality
   */
  resolution?: '480p' | '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '21:9' | '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video
   */
  generate_audio?: boolean
  /**
   * Duration
   *
   * Duration of the video in seconds
   */
  duration?: '4' | '5' | '6' | '7' | '8' | '9' | '10' | '11' | '12'
  /**
   * Image Url
   *
   * The URL of the image used to generate video
   */
  image_url: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Camera Fixed
   *
   * Whether to fix the camera position
   */
  camera_fixed?: boolean
  /**
   * End Image Url
   *
   * The URL of the image the video ends with. Defaults to None.
   */
  end_image_url?: string
  /**
   * Seed
   *
   * Random seed to control video generation. Use -1 for random.
   */
  seed?: number
}

/**
 * SeedanceProv15I2VVideoOutput
 */
export type BytedanceSeedanceV15ProImageToVideoOutput = {
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * Generated video file
   */
  video: FalAiBytedanceSeedanceV15ProImageToVideoFile
}

/**
 * File
 */
export type FalAiBytedanceSeedanceV15ProImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * LiveAvatarRequest
 */
export type LiveAvatarInput = {
  /**
   * Frames per Clip
   *
   * Number of frames per clip. Must be a multiple of 4. Higher values = smoother but slower generation.
   */
  frames_per_clip?: number
  /**
   * Prompt
   *
   * A text prompt describing the scene and character. Helps guide the video generation style and context.
   */
  prompt: string
  /**
   * Acceleration
   *
   * Acceleration level for faster video decoding
   */
  acceleration?: 'none' | 'light' | 'regular' | 'high'
  /**
   * Reference Image URL
   *
   * The URL of the reference image for avatar generation. The character in this image will be animated.
   */
  image_url: string
  /**
   * Number of Clips
   *
   * Number of video clips to generate. Each clip is approximately 3 seconds. Set higher for longer videos.
   */
  num_clips?: number
  /**
   * Audio URL
   *
   * The URL of the driving audio file (WAV or MP3). The avatar will be animated to match this audio.
   */
  audio_url: string
  /**
   * Seed
   *
   * Random seed for reproducible generation.
   */
  seed?: number
  /**
   * Guidance Scale
   *
   * Classifier-free guidance scale. Higher values follow the prompt more closely.
   */
  guidance_scale?: number
  /**
   * Enable Safety Checker
   *
   * Enable safety checker for content moderation.
   */
  enable_safety_checker?: boolean
}

/**
 * LiveAvatarResponse
 */
export type LiveAvatarOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated avatar video file with synchronized audio.
   */
  video: FalAiLiveAvatarVideoFile
}

/**
 * VideoFile
 */
export type FalAiLiveAvatarVideoFile = {
  /**
   * Height
   *
   * The height of the video
   */
  height?: number
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number
  /**
   * Width
   *
   * The width of the video
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * HunyuanVideo15I2VRequest
 */
export type HunyuanVideoV15ImageToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the video.
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the video.
   */
  resolution?: '480p'
  /**
   * Image Url
   *
   * URL of the reference image for image-to-video generation.
   */
  image_url: string
  /**
   * Enable Prompt Expansion
   *
   * Enable prompt expansion to enhance the input prompt.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility.
   */
  seed?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps.
   */
  num_inference_steps?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to guide what not to generate.
   */
  negative_prompt?: string
  /**
   * Num Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
}

/**
 * HunyuanVideo15Response
 */
export type HunyuanVideoV15ImageToVideoOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiHunyuanVideoV15ImageToVideoFile
}

/**
 * File
 */
export type FalAiHunyuanVideoV15ImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoInput
 *
 * Input for Wan 2.6 image-to-video generation
 */
export type V26ImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt describing the desired video motion. Max 800 characters.
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution. Valid values: 720p, 1080p
   */
  resolution?: '720p' | '1080p'
  /**
   * Duration
   *
   * Duration of the generated video in seconds. Choose between 5, 10 or 15 seconds.
   */
  duration?: '5' | '10' | '15'
  /**
   * Audio Url
   *
   *
   * URL of the audio to use as the background music. Must be publicly accessible.
   * Limit handling: If the audio duration exceeds the duration value (5, 10, or 15 seconds),
   * the audio is truncated to the first N seconds, and the rest is discarded. If
   * the audio is shorter than the video, the remaining part of the video will be silent.
   * For example, if the audio is 3 seconds long and the video duration is 5 seconds, the
   * first 3 seconds of the output video will have sound, and the last 2 seconds will be silent.
   * - Format: WAV, MP3.
   * - Duration: 3 to 30 s.
   * - File size: Up to 15 MB.
   *
   */
  audio_url?: string
  /**
   * Image URL
   *
   * URL of the image to use as the first frame. Must be publicly accessible or base64 data URI. Image dimensions must be between 240 and 7680.
   */
  image_url: string
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt rewriting using LLM.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Multi Shots
   *
   * When true, enables intelligent multi-shot segmentation. Only active when enable_prompt_expansion is True. Set to false for single-shot generation.
   */
  multi_shots?: boolean
  /**
   * Negative Prompt
   *
   * Negative prompt to describe content to avoid. Max 500 characters.
   */
  negative_prompt?: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
}

/**
 * ImageToVideoOutput
 *
 * Output for image-to-video generation
 */
export type V26ImageToVideoOutput = {
  /**
   * Actual Prompt
   *
   * The actual prompt used if prompt rewriting was enabled
   */
  actual_prompt?: string
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * The generated video file
   */
  video: WanV26ImageToVideoVideoFile
}

/**
 * VideoFile
 */
export type WanV26ImageToVideoVideoFile = {
  /**
   * Height
   *
   * The height of the video
   */
  height?: number
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number
  /**
   * Width
   *
   * The width of the video
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * OmniVideoElementInput
 */
export type OmniVideoElementInput = {
  /**
   * Reference Image Urls
   *
   * Additional reference images from different angles. 1-3 images supported. At least one image is required.
   */
  reference_image_urls?: Array<string>
  /**
   * Frontal Image Url
   *
   * The frontal image of the element (main view).
   *
   * Max file size: 10.0MB, Min width: 300px, Min height: 300px, Min aspect ratio: 0.40, Max aspect ratio: 2.50, Timeout: 20.0s
   */
  frontal_image_url: string
}

/**
 * OmniVideoReferenceToVideoOutput
 */
export type KlingVideoO1StandardReferenceToVideoOutput = {
  /**
   * Video
   *
   * The generated video.
   */
  video: FalAiKlingVideoO1StandardReferenceToVideoFile
}

/**
 * File
 */
export type FalAiKlingVideoO1StandardReferenceToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * OmniVideoImageToVideoInput
 */
export type KlingVideoO1StandardImageToVideoInput = {
  /**
   * Prompt
   *
   * Use @Image1 to reference the start frame, @Image2 to reference the end frame.
   */
  prompt: string
  /**
   * Duration
   *
   * Video duration in seconds.
   */
  duration?: '3' | '4' | '5' | '6' | '7' | '8' | '9' | '10'
  /**
   * Start Image Url
   *
   * Image to use as the first frame of the video.
   *
   * Max file size: 10.0MB, Min width: 300px, Min height: 300px, Min aspect ratio: 0.40, Max aspect ratio: 2.50, Timeout: 20.0s
   */
  start_image_url: string
  /**
   * End Image Url
   *
   * Image to use as the last frame of the video.
   *
   * Max file size: 10.0MB, Min width: 300px, Min height: 300px, Min aspect ratio: 0.40, Max aspect ratio: 2.50, Timeout: 20.0s
   */
  end_image_url?: string
}

/**
 * OmniVideoImageToVideoOutput
 *
 * Output for Kling Omni Video generation.
 */
export type KlingVideoO1StandardImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video.
   */
  video: FalAiKlingVideoO1StandardImageToVideoFile
}

/**
 * File
 */
export type FalAiKlingVideoO1StandardImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * AuroraInputModel
 */
export type CreatifyAuroraInput = {
  /**
   * Prompt
   *
   * A text prompt to guide the video generation process.
   */
  prompt?: string
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '480p' | '720p'
  /**
   * Guidance Scale
   *
   * Guidance scale to be used for text prompt adherence.
   */
  guidance_scale?: number
  /**
   * Audio Guidance Scale
   *
   * Guidance scale to be used for audio adherence.
   */
  audio_guidance_scale?: number
  /**
   * Audio Url
   *
   * The URL of the audio file to be used for video generation.
   */
  audio_url: string
  /**
   * Image Url
   *
   * The URL of the image file to be used for video generation.
   */
  image_url: string
}

/**
 * AuroraOutputModel
 */
export type CreatifyAuroraOutput = {
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiCreatifyAuroraVideoFile
}

/**
 * VideoFile
 */
export type FalAiCreatifyAuroraVideoFile = {
  /**
   * Height
   *
   * The height of the video
   */
  height?: number
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the video
   */
  width?: number
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * AIAvatarInput
 */
export type KlingVideoAiAvatarV2ProInput = {
  /**
   * Prompt
   *
   * The prompt to use for the video generation.
   */
  prompt?: string
  /**
   * Audio Url
   *
   * The URL of the audio file.
   */
  audio_url: string
  /**
   * Image Url
   *
   * The URL of the image to use as your avatar
   */
  image_url: string
}

/**
 * AIAvatarOutput
 */
export type KlingVideoAiAvatarV2ProOutput = {
  /**
   * Duration
   *
   * Duration of the output video in seconds.
   */
  duration: number
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoAiAvatarV2ProFile
}

/**
 * File
 */
export type FalAiKlingVideoAiAvatarV2ProFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * AIAvatarInput
 */
export type KlingVideoAiAvatarV2StandardInput = {
  /**
   * Prompt
   *
   * The prompt to use for the video generation.
   */
  prompt?: string
  /**
   * Audio Url
   *
   * The URL of the audio file.
   */
  audio_url: string
  /**
   * Image Url
   *
   * The URL of the image to use as your avatar
   */
  image_url: string
}

/**
 * AIAvatarOutput
 */
export type KlingVideoAiAvatarV2StandardOutput = {
  /**
   * Duration
   *
   * Duration of the output video in seconds.
   */
  duration: number
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoAiAvatarV2StandardFile
}

/**
 * File
 */
export type FalAiKlingVideoAiAvatarV2StandardFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoV26ProRequest
 */
export type KlingVideoV26ProImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Voice Ids
   *
   * List of voice IDs to use for voice control. Reference voices in the prompt using <<<voice_1>>>, <<<voice_2>>>. Maximum 2 voices allowed. When provided and referenced in prompt, enables voice control billing.
   */
  voice_ids?: Array<string>
  /**
   * Generate Audio
   *
   * Whether to generate native audio for the video. Supports Chinese and English voice output. Other languages are automatically translated to English. For English speech, use lowercase letters; for acronyms or proper nouns, use uppercase.
   */
  generate_audio?: boolean
  /**
   * Start Image Url
   *
   * URL of the image to be used for the video
   */
  start_image_url: string
  /**
   * End Image Url
   *
   * URL of the image to be used for the end of the video
   */
  end_image_url?: string
  /**
   * Negative Prompt
   */
  negative_prompt?: string
}

/**
 * ImageToVideoV26ProOutput
 */
export type KlingVideoV26ProImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV26ProImageToVideoFile
}

/**
 * File
 */
export type FalAiKlingVideoV26ProImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * EffectInputV5_5
 */
export type PixverseV55EffectsInput = {
  /**
   * Effect
   *
   * The effect to apply to the video
   */
  effect:
    | 'Kiss Me AI'
    | 'Kiss'
    | 'Muscle Surge'
    | 'Warmth of Jesus'
    | 'Anything, Robot'
    | 'The Tiger Touch'
    | 'Hug'
    | 'Holy Wings'
    | 'Microwave'
    | 'Zombie Mode'
    | 'Squid Game'
    | 'Baby Face'
    | 'Black Myth: Wukong'
    | 'Long Hair Magic'
    | 'Leggy Run'
    | 'Fin-tastic Mermaid'
    | 'Punch Face'
    | 'Creepy Devil Smile'
    | 'Thunder God'
    | 'Eye Zoom Challenge'
    | "Who's Arrested?"
    | 'Baby Arrived'
    | 'Werewolf Rage'
    | 'Bald Swipe'
    | 'BOOM DROP'
    | 'Huge Cutie'
    | 'Liquid Metal'
    | 'Sharksnap!'
    | 'Dust Me Away'
    | '3D Figurine Factor'
    | 'Bikini Up'
    | 'My Girlfriends'
    | 'My Boyfriends'
    | 'Subject 3 Fever'
    | 'Earth Zoom'
    | 'Pole Dance'
    | 'Vroom Dance'
    | 'GhostFace Terror'
    | 'Dragon Evoker'
    | 'Skeletal Bae'
    | 'Summoning succubus'
    | 'Halloween Voodoo Doll'
    | '3D Naked-Eye AD'
    | 'Package Explosion'
    | 'Dishes Served'
    | 'Ocean ad'
    | 'Supermarket AD'
    | 'Tree doll'
    | 'Come Feel My Abs'
    | 'The Bicep Flex'
    | 'London Elite Vibe'
    | 'Flora Nymph Gown'
    | 'Christmas Costume'
    | "It's Snowy"
    | 'Reindeer Cruiser'
    | 'Snow Globe Maker'
    | 'Pet Christmas Outfit'
    | 'Adopt a Polar Pal'
    | 'Cat Christmas Box'
    | 'Starlight Gift Box'
    | 'Xmas Poster'
    | 'Pet Christmas Tree'
    | 'City Santa Hat'
    | 'Stocking Sweetie'
    | 'Christmas Night'
    | 'Xmas Front Page Karma'
    | "Grinch's Xmas Hijack"
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '8' | '10'
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Thinking Type
   *
   * Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision
   */
  thinking_type?: 'enabled' | 'disabled' | 'auto'
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
  /**
   * Image Url
   *
   * Optional URL of the image to use as the first frame. If not provided, generates from text
   */
  image_url: string
}

/**
 * EffectOutput
 */
export type PixverseV55EffectsOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPixverseV55EffectsFile
}

/**
 * File
 */
export type FalAiPixverseV55EffectsFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TransitionRequestV5_5
 */
export type PixverseV55TransitionInput = {
  /**
   * Prompt
   *
   * The prompt for the transition
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Duration
   *
   * The duration of the generated video in seconds. Longer durations cost more. 1080p videos are limited to 5 or 8 seconds
   */
  duration?: '5' | '8' | '10'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Thinking Type
   *
   * Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision
   */
  thinking_type?: 'enabled' | 'disabled' | 'auto'
  /**
   * First Image Url
   *
   * URL of the image to use as the first frame
   */
  first_image_url: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Generate Audio Switch
   *
   * Enable audio generation (BGM, SFX, dialogue)
   */
  generate_audio_switch?: boolean
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * End Image Url
   *
   * URL of the image to use as the last frame
   */
  end_image_url?: string
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * TransitionOutputV5_5
 */
export type PixverseV55TransitionOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPixverseV55TransitionFile
}

/**
 * File
 */
export type FalAiPixverseV55TransitionFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoRequestV5_5
 */
export type PixverseV55ImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds. Longer durations cost more. 1080p videos are limited to 5 or 8 seconds
   */
  duration?: '5' | '8' | '10'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Generate Multi Clip Switch
   *
   * Enable multi-clip generation with dynamic camera changes
   */
  generate_multi_clip_switch?: boolean
  /**
   * Thinking Type
   *
   * Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision
   */
  thinking_type?: 'enabled' | 'disabled' | 'auto'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
  /**
   * Generate Audio Switch
   *
   * Enable audio generation (BGM, SFX, dialogue)
   */
  generate_audio_switch?: boolean
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * I2VOutputV5_5
 */
export type PixverseV55ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPixverseV55ImageToVideoFile
}

/**
 * File
 */
export type FalAiPixverseV55ImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * OmniVideoImageToVideoInput
 */
export type KlingVideoO1ImageToVideoInput = {
  /**
   * Prompt
   *
   * Use @Image1 to reference the start frame, @Image2 to reference the end frame.
   */
  prompt: string
  /**
   * Duration
   *
   * Video duration in seconds.
   */
  duration?: '3' | '4' | '5' | '6' | '7' | '8' | '9' | '10'
  /**
   * Start Image Url
   *
   * Image to use as the first frame of the video.
   *
   * Max file size: 10.0MB, Min width: 300px, Min height: 300px, Min aspect ratio: 0.40, Max aspect ratio: 2.50, Timeout: 20.0s
   */
  start_image_url: string
  /**
   * End Image Url
   *
   * Image to use as the last frame of the video.
   *
   * Max file size: 10.0MB, Min width: 300px, Min height: 300px, Min aspect ratio: 0.40, Max aspect ratio: 2.50, Timeout: 20.0s
   */
  end_image_url?: string
}

/**
 * OmniVideoImageToVideoOutput
 *
 * Output for Kling Omni Video generation.
 */
export type KlingVideoO1ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video.
   */
  video: FalAiKlingVideoO1ImageToVideoFile
}

/**
 * File
 */
export type FalAiKlingVideoO1ImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * OmniVideoElementInput
 */
export type FalAiKlingVideoO1ReferenceToVideoOmniVideoElementInput = {
  /**
   * Reference Image Urls
   *
   * Additional reference images from different angles. 1-3 images supported. At least one image is required.
   */
  reference_image_urls?: Array<string>
  /**
   * Frontal Image Url
   *
   * The frontal image of the element (main view).
   *
   * Max file size: 10.0MB, Min width: 300px, Min height: 300px, Min aspect ratio: 0.40, Max aspect ratio: 2.50, Timeout: 20.0s
   */
  frontal_image_url: string
}

/**
 * OmniVideoReferenceToVideoOutput
 */
export type KlingVideoO1ReferenceToVideoOutput = {
  /**
   * Video
   *
   * The generated video.
   */
  video: FalAiKlingVideoO1ReferenceToVideoFile
}

/**
 * File
 */
export type FalAiKlingVideoO1ReferenceToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * LTXVImageToVideoFastRequest
 */
export type Ltx2ImageToVideoFastInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9'
  /**
   * Duration
   *
   * The duration of the generated video in seconds. The fast model supports 6-20 seconds. Note: Durations longer than 10 seconds (12, 14, 16, 18, 20) are only supported with 25 FPS and 1080p resolution.
   */
  duration?: 6 | 8 | 10 | 12 | 14 | 16 | 18 | 20
  /**
   * Generate Audio
   *
   * Whether to generate audio for the generated video
   */
  generate_audio?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '1080p' | '1440p' | '2160p'
  /**
   * Image URL
   *
   * URL of the image to generate the video from. Must be publicly accessible or base64 data URI. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.
   */
  image_url: string
  /**
   * Frames per Second
   *
   * The frames per second of the generated video
   */
  fps?: 25 | 50
}

/**
 * LTXVImageToVideoResponse
 */
export type Ltx2ImageToVideoFastOutput = {
  /**
   * Video
   *
   * The generated video file
   */
  video: FalAiLtx2ImageToVideoFastVideoFile
}

/**
 * VideoFile
 */
export type FalAiLtx2ImageToVideoFastVideoFile = {
  /**
   * Height
   *
   * The height of the video
   */
  height?: number
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number
  /**
   * Width
   *
   * The width of the video
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * LTXVImageToVideoRequest
 */
export type Ltx2ImageToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: 6 | 8 | 10
  /**
   * Generate Audio
   *
   * Whether to generate audio for the generated video
   */
  generate_audio?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '1080p' | '1440p' | '2160p'
  /**
   * Image URL
   *
   * URL of the image to generate the video from. Must be publicly accessible or base64 data URI. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.
   */
  image_url: string
  /**
   * Frames per Second
   *
   * The frames per second of the generated video
   */
  fps?: 25 | 50
}

/**
 * LTXVImageToVideoResponse
 */
export type Ltx2ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video file
   */
  video: FalAiLtx2ImageToVideoVideoFile
}

/**
 * VideoFile
 */
export type FalAiLtx2ImageToVideoVideoFile = {
  /**
   * Height
   *
   * The height of the video
   */
  height?: number
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number
  /**
   * Width
   *
   * The width of the video
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * LynxInput
 */
export type LynxInput = {
  /**
   * Prompt
   *
   * Text prompt to guide video generation
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p, 580p, or 720p)
   */
  resolution?: '480p' | '580p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video (16:9, 9:16, or 1:1)
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Guidance Scale 2
   *
   * Image guidance scale. Controls how closely the generated video follows the reference image. Higher values increase adherence to the reference image but may decrease quality.
   */
  guidance_scale_2?: number
  /**
   * Strength
   *
   * Reference image scale. Controls the influence of the reference image on the generated video.
   */
  strength?: number
  /**
   * Frames Per Second
   *
   * Frames per second of the generated video. Must be between 5 to 30.
   */
  frames_per_second?: number
  /**
   * Image Url
   *
   * The URL of the subject image to be used for video generation
   */
  image_url: string
  /**
   * Guidance Scale
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Num Frames
   *
   * Number of frames in the generated video. Must be between 9 to 100.
   */
  num_frames?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to guide what should not appear in the generated video
   */
  negative_prompt?: string
  /**
   * Ip Scale
   *
   * Identity preservation scale. Controls how closely the generated video preserves the subject's identity from the reference image.
   */
  ip_scale?: number
}

/**
 * LynxOutput
 */
export type LynxOutput = {
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * The generated video file
   */
  video: BytedanceLynxVideoFile
}

/**
 * VideoFile
 */
export type BytedanceLynxVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number
  /**
   * Height
   *
   * The height of the video
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number
  /**
   * Width
   *
   * The width of the video
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * SwapRequest
 */
export type PixverseSwapInput = {
  /**
   * Original Sound Switch
   *
   * Whether to keep the original audio
   */
  original_sound_switch?: boolean
  /**
   * Video Url
   *
   * URL of the external video to swap
   */
  video_url: string
  /**
   * Resolution
   *
   * The output resolution (1080p not supported)
   */
  resolution?: '360p' | '540p' | '720p'
  /**
   * Mode
   *
   * The swap mode to use
   */
  mode?: 'person' | 'object' | 'background'
  /**
   * Image Url
   *
   * URL of the target image for swapping
   */
  image_url: string
  /**
   * Keyframe Id
   *
   * The keyframe ID (from 1 to the last frame position)
   */
  keyframe_id?: number
}

/**
 * SwapOutput
 */
export type PixverseSwapOutput = {
  /**
   * Video
   *
   * The generated swapped video
   */
  video: FalAiPixverseSwapFile
}

/**
 * File
 */
export type FalAiPixverseSwapFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Pika22KeyframesToVideoRequest
 */
export type PikaV22PikaframesInput = {
  /**
   * Prompt
   *
   * Default prompt for all transitions. Individual transition prompts override this.
   */
  prompt?: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '720p' | '1080p'
  /**
   * Transitions
   *
   * Configuration for each transition. Length must be len(image_urls) - 1. Total duration of all transitions must not exceed 25 seconds. If not provided, uses default 5-second transitions with the global prompt.
   */
  transitions?: Array<KeyframeTransition>
  /**
   * Seed
   *
   * The seed for the random number generator
   */
  seed?: number
  /**
   * Image Urls
   *
   * URLs of keyframe images (2-5 images) to create transitions between
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the model
   */
  negative_prompt?: string
}

/**
 * KeyframeTransition
 *
 * Configuration for a transition between two keyframes
 */
export type KeyframeTransition = {
  /**
   * Prompt
   *
   * Specific prompt for this transition. Overrides the global prompt if provided.
   */
  prompt?: string
  /**
   * Duration
   *
   * Duration of this transition in seconds
   */
  duration?: number
}

/**
 * Pika22KeyframesToVideoOutput
 *
 * Output model for Pika 2.2 keyframes-to-video generation
 */
export type PikaV22PikaframesOutput = {
  /**
   * Video
   *
   * The generated video with transitions between keyframes
   */
  video: FalAiPikaV22PikaframesFile
}

/**
 * File
 */
export type FalAiPikaV22PikaframesFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * LongCat720PCFGImageToVideoRequest
 */
export type LongcatVideoImageToVideo720pInput = {
  /**
   * Prompt
   *
   * The prompt to guide the video generation.
   */
  prompt?: string
  /**
   * Acceleration
   *
   * The acceleration level to use for the video generation.
   */
  acceleration?: 'none' | 'regular'
  /**
   * FPS
   *
   * The frame rate of the generated video.
   */
  fps?: number
  /**
   * Number of Refinement Inference Steps
   *
   * The number of inference steps to use for refinement.
   */
  num_refine_inference_steps?: number
  /**
   * Guidance Scale
   *
   * The guidance scale to use for the video generation.
   */
  guidance_scale?: number
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * The negative prompt to use for the video generation.
   */
  negative_prompt?: string
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * Image URL
   *
   * The URL of the image to generate a video from.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use for the video generation.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
}

/**
 * LongCatImageToVideoResponse
 */
export type LongcatVideoImageToVideo720pOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiLongcatVideoImageToVideo720pFile
}

/**
 * File
 */
export type FalAiLongcatVideoImageToVideo720pFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * LongCatCFGImageToVideoRequest
 */
export type LongcatVideoImageToVideo480pInput = {
  /**
   * Prompt
   *
   * The prompt to guide the video generation.
   */
  prompt?: string
  /**
   * Acceleration
   *
   * The acceleration level to use for the video generation.
   */
  acceleration?: 'none' | 'regular'
  /**
   * FPS
   *
   * The frame rate of the generated video.
   */
  fps?: number
  /**
   * Guidance Scale
   *
   * The guidance scale to use for the video generation.
   */
  guidance_scale?: number
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * The negative prompt to use for the video generation.
   */
  negative_prompt?: string
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * Image URL
   *
   * The URL of the image to generate a video from.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use for the video generation.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
}

/**
 * LongCatImageToVideoResponse
 */
export type LongcatVideoImageToVideo480pOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiLongcatVideoImageToVideo480pFile
}

/**
 * File
 */
export type FalAiLongcatVideoImageToVideo480pFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * LongCat720PImageToVideoRequest
 */
export type LongcatVideoDistilledImageToVideo720pInput = {
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Prompt
   *
   * The prompt to guide the video generation.
   */
  prompt?: string
  /**
   * FPS
   *
   * The frame rate of the generated video.
   */
  fps?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Number of Refinement Inference Steps
   *
   * The number of inference steps to use for refinement.
   */
  num_refine_inference_steps?: number
  /**
   * Image URL
   *
   * The URL of the image to generate a video from.
   */
  image_url: string
  /**
   * Enable Safety Checker
   *
   * Whether to enable safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
}

/**
 * LongCatImageToVideoResponse
 */
export type LongcatVideoDistilledImageToVideo720pOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiLongcatVideoDistilledImageToVideo720pFile
}

/**
 * File
 */
export type FalAiLongcatVideoDistilledImageToVideo720pFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * LongCatImageToVideoRequest
 */
export type LongcatVideoDistilledImageToVideo480pInput = {
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * Prompt
   *
   * The prompt to guide the video generation.
   */
  prompt?: string
  /**
   * FPS
   *
   * The frame rate of the generated video.
   */
  fps?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Image URL
   *
   * The URL of the image to generate a video from.
   */
  image_url: string
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Safety Checker
   *
   * Whether to enable safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
}

/**
 * LongCatImageToVideoResponse
 */
export type LongcatVideoDistilledImageToVideo480pOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiLongcatVideoDistilledImageToVideo480pFile
}

/**
 * File
 */
export type FalAiLongcatVideoDistilledImageToVideo480pFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * StandardFastImageToVideoHailuo23Input
 */
export type MinimaxHailuo23FastStandardImageToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Duration
   *
   * The duration of the video in seconds.
   */
  duration?: '6' | '10'
  /**
   * Prompt
   *
   * Text prompt for video generation
   */
  prompt: string
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * StandardFastImageToVideoHailuo23Output
 */
export type MinimaxHailuo23FastStandardImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiMinimaxHailuo23FastStandardImageToVideoFile
}

/**
 * File
 */
export type FalAiMinimaxHailuo23FastStandardImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * StandardImageToVideoHailuo23Input
 */
export type MinimaxHailuo23StandardImageToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Duration
   *
   * The duration of the video in seconds.
   */
  duration?: '6' | '10'
  /**
   * Prompt
   *
   * Text prompt for video generation
   */
  prompt: string
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * StandardImageToVideoHailuo23Output
 */
export type MinimaxHailuo23StandardImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiMinimaxHailuo23StandardImageToVideoFile
}

/**
 * File
 */
export type FalAiMinimaxHailuo23StandardImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ProFastImageToVideoHailuo23Input
 */
export type MinimaxHailuo23FastProImageToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Prompt
   *
   * Text prompt for video generation
   */
  prompt: string
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * ProFastImageToVideoHailuo23Output
 */
export type MinimaxHailuo23FastProImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiMinimaxHailuo23FastProImageToVideoFile
}

/**
 * File
 */
export type FalAiMinimaxHailuo23FastProImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * SeedanceProFastImageToVideoInput
 */
export type BytedanceSeedanceV1ProFastImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt used to generate the video
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality
   */
  resolution?: '480p' | '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '21:9' | '16:9' | '4:3' | '1:1' | '3:4' | '9:16' | 'auto'
  /**
   * Duration
   *
   * Duration of the video in seconds
   */
  duration?: '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9' | '10' | '11' | '12'
  /**
   * Image Url
   *
   * The URL of the image used to generate video
   */
  image_url: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Camera Fixed
   *
   * Whether to fix the camera position
   */
  camera_fixed?: boolean
  /**
   * Seed
   *
   * Random seed to control video generation. Use -1 for random.
   */
  seed?: number
}

/**
 * SeedanceFastI2VVideoOutput
 */
export type BytedanceSeedanceV1ProFastImageToVideoOutput = {
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * Generated video file
   */
  video: FalAiBytedanceSeedanceV1ProFastImageToVideoFile
}

/**
 * File
 */
export type FalAiBytedanceSeedanceV1ProFastImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Q2ImageToVideoRequest
 */
export type ViduQ2ImageToVideoTurboInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 3000 characters
   */
  prompt: string
  /**
   * Resolution
   *
   * Output video resolution
   */
  resolution?: '720p' | '1080p'
  /**
   * Duration
   *
   * Duration of the video in seconds
   */
  duration?: 2 | 3 | 4 | 5 | 6 | 7 | 8
  /**
   * Image Url
   *
   * URL of the image to use as the starting frame
   */
  image_url: string
  /**
   * Bgm
   *
   * Whether to add background music to the video (only for 4-second videos)
   */
  bgm?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Movement Amplitude
   *
   * The movement amplitude of objects in the frame
   */
  movement_amplitude?: 'auto' | 'small' | 'medium' | 'large'
  /**
   * End Image Url
   *
   * URL of the image to use as the ending frame. When provided, generates a transition video between start and end frames.
   */
  end_image_url?: string
}

/**
 * Q2ImageToVideoOutput
 */
export type ViduQ2ImageToVideoTurboOutput = {
  /**
   * Video
   *
   * The generated video from image using the Q2 model
   */
  video: FalAiViduQ2ImageToVideoTurboFile
}

/**
 * File
 */
export type FalAiViduQ2ImageToVideoTurboFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Q2ImageToVideoRequest
 */
export type ViduQ2ImageToVideoProInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 3000 characters
   */
  prompt: string
  /**
   * Resolution
   *
   * Output video resolution
   */
  resolution?: '720p' | '1080p'
  /**
   * Duration
   *
   * Duration of the video in seconds
   */
  duration?: 2 | 3 | 4 | 5 | 6 | 7 | 8
  /**
   * Image Url
   *
   * URL of the image to use as the starting frame
   */
  image_url: string
  /**
   * Bgm
   *
   * Whether to add background music to the video (only for 4-second videos)
   */
  bgm?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Movement Amplitude
   *
   * The movement amplitude of objects in the frame
   */
  movement_amplitude?: 'auto' | 'small' | 'medium' | 'large'
  /**
   * End Image Url
   *
   * URL of the image to use as the ending frame. When provided, generates a transition video between start and end frames.
   */
  end_image_url?: string
}

/**
 * Q2ImageToVideoOutput
 */
export type ViduQ2ImageToVideoProOutput = {
  /**
   * Video
   *
   * The generated video from image using the Q2 model
   */
  video: FalAiViduQ2ImageToVideoProFile
}

/**
 * File
 */
export type FalAiViduQ2ImageToVideoProFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Q2ReferenceToVideoRequest
 */
export type ViduQ2ReferenceToVideoInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 3000 characters
   */
  prompt: string
  /**
   * Resolution
   *
   * Output video resolution
   */
  resolution?: '360p' | '520p' | '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the output video
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Duration
   *
   * Duration of the video in seconds
   */
  duration?: 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8
  /**
   * Bgm
   *
   * Whether to add background music to the video (only for 4-second videos)
   */
  bgm?: boolean
  /**
   * Reference Image Urls
   *
   * URLs of the reference images to use for consistent subject appearance (up to 7 images)
   */
  reference_image_urls: Array<string>
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Movement Amplitude
   *
   * The movement amplitude of objects in the frame
   */
  movement_amplitude?: 'auto' | 'small' | 'medium' | 'large'
}

/**
 * Q2ReferenceToVideoOutput
 */
export type ViduQ2ReferenceToVideoOutput = {
  /**
   * Video
   *
   * The generated video with consistent subjects from reference images using the Q2 model
   */
  video: FalAiViduQ2ReferenceToVideoFile
}

/**
 * File
 */
export type FalAiViduQ2ReferenceToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoV25StandardRequest
 */
export type KlingVideoV25TurboStandardImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Image Url
   *
   * URL of the image to be used for the video
   */
  image_url: string
}

/**
 * ImageToVideoV25StandardOutput
 */
export type KlingVideoV25TurboStandardImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV25TurboStandardImageToVideoFile
}

/**
 * File
 */
export type FalAiKlingVideoV25TurboStandardImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Veo31FirstLastFrameToVideoInput
 */
export type Veo31FastFirstLastFrameToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video.
   */
  duration?: '4s' | '6s' | '8s'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * Auto Fix
   *
   * Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.
   */
  auto_fix?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '720p' | '1080p' | '4k'
  /**
   * First Frame URL
   *
   * URL of the first frame of the video
   */
  first_frame_url: string
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Last Frame URL
   *
   * URL of the last frame of the video
   */
  last_frame_url: string
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the video generation.
   */
  negative_prompt?: string
}

/**
 * Veo31FirstLastFrameToVideoOutput
 */
export type Veo31FastFirstLastFrameToVideoOutput = {
  /**
   * Video
   *
   * The generated video.
   */
  video: FalAiVeo31FastFirstLastFrameToVideoFile
}

/**
 * File
 */
export type FalAiVeo31FastFirstLastFrameToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Veo31FirstLastFrameToVideoInput
 */
export type Veo31FirstLastFrameToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video.
   */
  duration?: '4s' | '6s' | '8s'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * Auto Fix
   *
   * Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.
   */
  auto_fix?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '720p' | '1080p' | '4k'
  /**
   * First Frame URL
   *
   * URL of the first frame of the video
   */
  first_frame_url: string
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Last Frame URL
   *
   * URL of the last frame of the video
   */
  last_frame_url: string
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the video generation.
   */
  negative_prompt?: string
}

/**
 * Veo31FirstLastFrameToVideoOutput
 */
export type Veo31FirstLastFrameToVideoOutput = {
  /**
   * Video
   *
   * The generated video.
   */
  video: FalAiVeo31FirstLastFrameToVideoFile
}

/**
 * File
 */
export type FalAiVeo31FirstLastFrameToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Veo31ReferenceToVideoInput
 */
export type Veo31ReferenceToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video.
   */
  duration?: '8s'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video.
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '720p' | '1080p' | '4k'
  /**
   * Auto Fix
   *
   * Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.
   */
  auto_fix?: boolean
  /**
   * Image Urls
   *
   * URLs of the reference images to use for consistent subject appearance
   */
  image_urls: Array<string>
}

/**
 * Veo31ReferenceToVideoOutput
 */
export type Veo31ReferenceToVideoOutput = {
  /**
   * Video
   *
   * The generated video.
   */
  video: FalAiVeo31ReferenceToVideoFile
}

/**
 * File
 */
export type FalAiVeo31ReferenceToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Veo31ImageToVideoInput
 */
export type Veo31FastImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video.
   */
  duration?: '4s' | '6s' | '8s'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video. Only 16:9 and 9:16 are supported.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * Auto Fix
   *
   * Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.
   */
  auto_fix?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '720p' | '1080p' | '4k'
  /**
   * Image URL
   *
   * URL of the input image to animate. Should be 720p or higher resolution in 16:9 or 9:16 aspect ratio. If the image is not in 16:9 or 9:16 aspect ratio, it will be cropped to fit.
   */
  image_url: string
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the video generation.
   */
  negative_prompt?: string
}

/**
 * Veo31ImageToVideoOutput
 */
export type Veo31FastImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video.
   */
  video: FalAiVeo31FastImageToVideoFile
}

/**
 * File
 */
export type FalAiVeo31FastImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Veo31ImageToVideoInput
 */
export type Veo31ImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video.
   */
  duration?: '4s' | '6s' | '8s'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video. Only 16:9 and 9:16 are supported.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * Auto Fix
   *
   * Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.
   */
  auto_fix?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '720p' | '1080p' | '4k'
  /**
   * Image URL
   *
   * URL of the input image to animate. Should be 720p or higher resolution in 16:9 or 9:16 aspect ratio. If the image is not in 16:9 or 9:16 aspect ratio, it will be cropped to fit.
   */
  image_url: string
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the video generation.
   */
  negative_prompt?: string
}

/**
 * Veo31ImageToVideoOutput
 */
export type Veo31ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video.
   */
  video: FalAiVeo31ImageToVideoFile
}

/**
 * File
 */
export type FalAiVeo31ImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ProImageToVideoInput
 */
export type Sora2ImageToVideoProInput = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * Duration of the generated video in seconds
   */
  duration?: 4 | 8 | 12
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: 'auto' | '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: 'auto' | '9:16' | '16:9'
  /**
   * Delete Video
   *
   * Whether to delete the video after generation for privacy reasons. If True, the video cannot be used for remixing and will be permanently deleted.
   */
  delete_video?: boolean
  /**
   * Image URL
   *
   * The URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * ProImageToVideoOutput
 */
export type Sora2ImageToVideoProOutput = {
  /**
   * Spritesheet
   *
   * Spritesheet image for the video
   */
  spritesheet?: ImageFile
  /**
   * Thumbnail
   *
   * Thumbnail image for the video
   */
  thumbnail?: ImageFile
  /**
   * Video ID
   *
   * The ID of the generated video
   */
  video_id: string
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiSora2ImageToVideoProVideoFile
}

/**
 * ImageFile
 */
export type ImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * VideoFile
 */
export type FalAiSora2ImageToVideoProVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number
  /**
   * Height
   *
   * The height of the video
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number
  /**
   * Width
   *
   * The width of the video
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoInput
 */
export type Sora2ImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * Duration of the generated video in seconds
   */
  duration?: 4 | 8 | 12
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: 'auto' | '720p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: 'auto' | '9:16' | '16:9'
  /**
   * Image URL
   *
   * The URL of the image to use as the first frame
   */
  image_url: string
  /**
   * Model
   *
   * The model to use for the generation. When the default model is selected, the latest snapshot of the model will be used - otherwise, select a specific snapshot of the model.
   */
  model?: 'sora-2' | 'sora-2-2025-12-08' | 'sora-2-2025-10-06'
  /**
   * Delete Video
   *
   * Whether to delete the video after generation for privacy reasons. If True, the video cannot be used for remixing and will be permanently deleted.
   */
  delete_video?: boolean
}

/**
 * ImageToVideoOutput
 */
export type Sora2ImageToVideoOutput = {
  /**
   * Spritesheet
   *
   * Spritesheet image for the video
   */
  spritesheet?: FalAiSora2ImageToVideoImageFile
  /**
   * Thumbnail
   *
   * Thumbnail image for the video
   */
  thumbnail?: FalAiSora2ImageToVideoImageFile
  /**
   * Video ID
   *
   * The ID of the generated video
   */
  video_id: string
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiSora2ImageToVideoVideoFile
}

/**
 * ImageFile
 */
export type FalAiSora2ImageToVideoImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * VideoFile
 */
export type FalAiSora2ImageToVideoVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number
  /**
   * Height
   *
   * The height of the video
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number
  /**
   * Width
   *
   * The width of the video
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * OviI2VRequest
 */
export type OviImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number | unknown
  /**
   * Num Inference Steps
   *
   * The number of inference steps.
   */
  num_inference_steps?: number
  /**
   * Audio Negative Prompt
   *
   * Negative prompt for audio generation.
   */
  audio_negative_prompt?: string
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Image Url
   *
   * The image URL to guide video generation.
   */
  image_url: string
}

/**
 * OviI2VResponse
 */
export type OviImageToVideoOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * The generated video file.
   */
  video?: FalAiOviImageToVideoFile | unknown
}

/**
 * File
 */
export type FalAiOviImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * FabricOneLipsyncInput
 */
export type Fabric10FastInput = {
  /**
   * Resolution
   *
   * Resolution
   */
  resolution: '720p' | '480p'
  /**
   * Audio Url
   */
  audio_url: string
  /**
   * Image Url
   */
  image_url: string
}

/**
 * FabricOneOutput
 */
export type Fabric10FastOutput = {
  video: VeedFabric10FastFile
}

/**
 * File
 */
export type VeedFabric10FastFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * OmniHumanv15Input
 */
export type BytedanceOmnihumanV15Input = {
  /**
   * Turbo Mode
   *
   * Generate a video at a faster rate with a slight quality trade-off.
   */
  turbo_mode?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video. Defaults to 1080p. 720p generation is faster and higher in quality. 1080p generation is limited to 30s audio and 720p generation is limited to 60s audio.
   */
  resolution?: '720p' | '1080p'
  /**
   * Prompt
   *
   * The text prompt used to guide the video generation.
   */
  prompt?: string
  /**
   * Audio Url
   *
   * The URL of the audio file to generate the video. Audio must be under 30s long for 1080p generation and under 60s long for 720p generation.
   */
  audio_url: string
  /**
   * Image Url
   *
   * The URL of the image used to generate the video
   */
  image_url: string
}

/**
 * OmniHumanv15Output
 */
export type BytedanceOmnihumanV15Output = {
  /**
   * Duration
   *
   * Duration of audio input/video output as used for billing.
   */
  duration: number
  /**
   * Video
   *
   * Generated video file
   */
  video: FalAiBytedanceOmnihumanV15File
}

/**
 * File
 */
export type FalAiBytedanceOmnihumanV15File = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * FabricOneLipsyncInput
 */
export type Fabric10Input = {
  /**
   * Resolution
   *
   * Resolution
   */
  resolution: '720p' | '480p'
  /**
   * Audio Url
   */
  audio_url: string
  /**
   * Image Url
   */
  image_url: string
}

/**
 * FabricOneOutput
 */
export type Fabric10Output = {
  video: VeedFabric10File
}

/**
 * File
 */
export type VeedFabric10File = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * AIAvatarInput
 */
export type KlingVideoV1StandardAiAvatarInput = {
  /**
   * Prompt
   *
   * The prompt to use for the video generation.
   */
  prompt?: string
  /**
   * Audio Url
   *
   * The URL of the audio file.
   */
  audio_url: string
  /**
   * Image Url
   *
   * The URL of the image to use as your avatar
   */
  image_url: string
}

/**
 * AIAvatarOutput
 */
export type KlingVideoV1StandardAiAvatarOutput = {
  /**
   * Duration
   *
   * Duration of the output video in seconds.
   */
  duration: number
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV1StandardAiAvatarFile
}

/**
 * File
 */
export type FalAiKlingVideoV1StandardAiAvatarFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * AIAvatarInput
 */
export type KlingVideoV1ProAiAvatarInput = {
  /**
   * Prompt
   *
   * The prompt to use for the video generation.
   */
  prompt?: string
  /**
   * Audio Url
   *
   * The URL of the audio file.
   */
  audio_url: string
  /**
   * Image Url
   *
   * The URL of the image to use as your avatar
   */
  image_url: string
}

/**
 * AIAvatarOutput
 */
export type KlingVideoV1ProAiAvatarOutput = {
  /**
   * Duration
   *
   * Duration of the output video in seconds.
   */
  duration: number
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV1ProAiAvatarFile
}

/**
 * File
 */
export type FalAiKlingVideoV1ProAiAvatarFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Lucy14BImageToVideoInput
 */
export type Lucy14bImageToVideoInput = {
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated
   * and uploaded before returning the response. This will increase the
   * latency of the function but it allows you to get the image directly
   * in the response without going through the CDN.
   *
   */
  sync_mode?: boolean
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video.
   */
  aspect_ratio?: '9:16' | '16:9'
  /**
   * Prompt
   *
   * Text description of the desired video content
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the generated video
   */
  resolution?: '720p'
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * Lucy14BOutput
 */
export type Lucy14bImageToVideoOutput = {
  /**
   * Video
   *
   * The generated MP4 video with H.264 encoding
   */
  video: DecartLucy14bImageToVideoFile
}

/**
 * File
 */
export type DecartLucy14bImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * SeedanceReferenceToVideoInput
 */
export type BytedanceSeedanceV1LiteReferenceToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt used to generate the video
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution - 480p for faster generation, 720p for higher quality
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '21:9' | '16:9' | '4:3' | '1:1' | '3:4' | '9:16' | 'auto'
  /**
   * Duration
   *
   * Duration of the video in seconds
   */
  duration?: '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9' | '10' | '11' | '12'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Camera Fixed
   *
   * Whether to fix the camera position
   */
  camera_fixed?: boolean
  /**
   * Reference Image Urls
   *
   * Reference images to generate the video with.
   */
  reference_image_urls: Array<string>
  /**
   * Seed
   *
   * Random seed to control video generation. Use -1 for random.
   */
  seed?: number
}

/**
 * SeedanceReferenceToVideoOutput
 */
export type BytedanceSeedanceV1LiteReferenceToVideoOutput = {
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * Generated video file
   */
  video: FalAiBytedanceSeedanceV1LiteReferenceToVideoFile
}

/**
 * File
 */
export type FalAiBytedanceSeedanceV1LiteReferenceToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * WanATIRequest
 */
export type WanAtiInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p, 580p, 720p).
   */
  resolution?: '480p' | '580p' | '720p'
  /**
   * Image URL
   *
   * URL of the input image.
   */
  image_url: string
  /**
   * Track
   *
   * Motion tracks to guide video generation. Each track is a sequence of points defining a motion trajectory. Multiple tracks can control different elements or objects in the video. Expected format: array of tracks, where each track is an array of points with 'x' and 'y' coordinates (up to 121 points per track). Points will be automatically padded to 121 if fewer are provided. Coordinates should be within the image dimensions.
   */
  track: Array<Array<TrackPoint>>
  /**
   * Guidance Scale (1st Stage)
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guidance_scale?: number
  /**
   * Number of Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
}

/**
 * WanATIResponse
 */
export type WanAtiOutput = {
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiWanAtiFile
}

/**
 * File
 */
export type FalAiWanAtiFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Placeholder for missing schema TrackPoint (referenced but not defined in source OpenAPI spec)
 */
export type TrackPoint = {
  [key: string]: unknown
}

/**
 * ProcessRequest
 */
export type DecartLucy5bImageToVideoInput = {
  /**
   * Prompt
   *
   * Text description of the desired video content
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video.
   */
  aspect_ratio?: '9:16' | '16:9'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Resolution
   *
   * Resolution of the generated video
   */
  resolution?: '720p'
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * ProcessOutput
 */
export type DecartLucy5bImageToVideoOutput = {
  /**
   * Video
   *
   * The generated MP4 video with H.264 encoding
   */
  video: FalAiDecartLucy5bImageToVideoFile
}

/**
 * File
 */
export type FalAiDecartLucy5bImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TransitionRequest
 */
export type PixverseV5TransitionInput = {
  /**
   * Prompt
   *
   * The prompt for the transition
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '8'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * First Image Url
   *
   * URL of the image to use as the first frame
   */
  first_image_url: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * End Image Url
   *
   * URL of the image to use as the last frame
   */
  end_image_url?: string
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * TransitionOutputV5
 */
export type PixverseV5TransitionOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPixverseV5TransitionFile
}

/**
 * File
 */
export type FalAiPixverseV5TransitionFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * EffectInput
 */
export type PixverseV5EffectsInput = {
  /**
   * Effect
   *
   * The effect to apply to the video
   */
  effect:
    | 'Kiss Me AI'
    | 'Kiss'
    | 'Muscle Surge'
    | 'Warmth of Jesus'
    | 'Anything, Robot'
    | 'The Tiger Touch'
    | 'Hug'
    | 'Holy Wings'
    | 'Microwave'
    | 'Zombie Mode'
    | 'Squid Game'
    | 'Baby Face'
    | 'Black Myth: Wukong'
    | 'Long Hair Magic'
    | 'Leggy Run'
    | 'Fin-tastic Mermaid'
    | 'Punch Face'
    | 'Creepy Devil Smile'
    | 'Thunder God'
    | 'Eye Zoom Challenge'
    | "Who's Arrested?"
    | 'Baby Arrived'
    | 'Werewolf Rage'
    | 'Bald Swipe'
    | 'BOOM DROP'
    | 'Huge Cutie'
    | 'Liquid Metal'
    | 'Sharksnap!'
    | 'Dust Me Away'
    | '3D Figurine Factor'
    | 'Bikini Up'
    | 'My Girlfriends'
    | 'My Boyfriends'
    | 'Subject 3 Fever'
    | 'Earth Zoom'
    | 'Pole Dance'
    | 'Vroom Dance'
    | 'GhostFace Terror'
    | 'Dragon Evoker'
    | 'Skeletal Bae'
    | 'Summoning succubus'
    | 'Halloween Voodoo Doll'
    | '3D Naked-Eye AD'
    | 'Package Explosion'
    | 'Dishes Served'
    | 'Ocean ad'
    | 'Supermarket AD'
    | 'Tree doll'
    | 'Come Feel My Abs'
    | 'The Bicep Flex'
    | 'London Elite Vibe'
    | 'Flora Nymph Gown'
    | 'Christmas Costume'
    | "It's Snowy"
    | 'Reindeer Cruiser'
    | 'Snow Globe Maker'
    | 'Pet Christmas Outfit'
    | 'Adopt a Polar Pal'
    | 'Cat Christmas Box'
    | 'Starlight Gift Box'
    | 'Xmas Poster'
    | 'Pet Christmas Tree'
    | 'City Santa Hat'
    | 'Stocking Sweetie'
    | 'Christmas Night'
    | 'Xmas Front Page Karma'
    | "Grinch's Xmas Hijack"
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '8'
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
  /**
   * Image Url
   *
   * Optional URL of the image to use as the first frame. If not provided, generates from text
   */
  image_url: string
}

/**
 * EffectOutput
 */
export type PixverseV5EffectsOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPixverseV5EffectsFile
}

/**
 * File
 */
export type FalAiPixverseV5EffectsFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoRequestV5
 */
export type PixverseV5ImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds
   */
  duration?: '5' | '8'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * I2VOutputV5
 */
export type PixverseV5ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPixverseV5ImageToVideoFile
}

/**
 * File
 */
export type FalAiPixverseV5ImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * MareyInputI2V
 */
export type MareyI2vInput = {
  /**
   * Prompt
   *
   * The prompt to generate a video from
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video.
   */
  duration?: '5s' | '10s'
  /**
   * Image Url
   *
   * The URL of the image to use as the first frame of the video.
   */
  image_url: string
  /**
   * Dimensions
   *
   * The dimensions of the generated video in width x height format.
   */
  dimensions?:
    | '1920x1080'
    | '1080x1920'
    | '1152x1152'
    | '1536x1152'
    | '1152x1536'
  /**
   * Guidance Scale
   *
   * Controls how strongly the generation is guided by the prompt (0-20). Higher values follow the prompt more closely.
   */
  guidance_scale?: number | unknown
  /**
   * Seed
   *
   * Seed for random number generation. Use -1 for random seed each run.
   */
  seed?: number | unknown
  /**
   * Negative Prompt
   *
   * Negative prompt used to guide the model away from undesirable features.
   */
  negative_prompt?: string | unknown
}

/**
 * MareyOutput
 */
export type MareyI2vOutput = {
  video: MoonvalleyMareyI2vFile
}

/**
 * File
 */
export type MoonvalleyMareyI2vFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * StylizeInput
 */
export type BytedanceVideoStylizeInput = {
  /**
   * Style
   *
   * The style for your character in the video. Please use a short description.
   */
  style: string
  /**
   * Image Url
   *
   * URL of the image to make the stylized video from.
   */
  image_url: string
}

export type BytedanceVideoStylizeOutput = unknown

/**
 * WanLoRAI2VRequest
 */
export type WanV22A14bImageToVideoLoraInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Shift
   *
   * Shift value for the video. Must be between 1.0 and 10.0.
   */
  shift?: number
  /**
   * Acceleration
   *
   * Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Number of Interpolated Frames
   *
   * Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.
   */
  num_interpolated_frames?: number
  /**
   * Reverse Video
   *
   * If true, the video will be reversed.
   */
  reverse_video?: boolean
  /**
   * Loras
   *
   * LoRA weights to be used in the inference.
   */
  loras?: Array<LoRaWeight>
  /**
   * Frames per Second
   *
   * Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.
   */
  frames_per_second?: number | unknown
  /**
   * Enable Safety Checker
   *
   * If set to true, input data will be checked for safety before processing.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Frames
   *
   * Number of frames to generate. Must be between 17 to 161 (inclusive).
   */
  num_frames?: number
  /**
   * End Image URL
   *
   * URL of the end image.
   */
  end_image_url?: string | unknown
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Guidance Scale (1st Stage)
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guidance_scale?: number
  /**
   * Video Write Mode
   *
   * The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Resolution
   *
   * Resolution of the generated video (480p, 580p, or 720p).
   */
  resolution?: '480p' | '580p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16' | '1:1'
  /**
   * Enable Output Safety Checker
   *
   * If set to true, output video will be checked for safety after generation.
   */
  enable_output_safety_checker?: boolean
  /**
   * Image URL
   *
   * URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Video Quality
   *
   * The quality of the output video. Higher quality means better visual quality but larger file size.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Guidance Scale (2nd Stage)
   *
   * Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.
   */
  guidance_scale_2?: number
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number | unknown
  /**
   * Interpolator Model
   *
   * The model to use for frame interpolation. If None, no interpolation is applied.
   */
  interpolator_model?: 'none' | 'film' | 'rife'
  /**
   * Adjust FPS for Interpolation
   *
   * If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.
   */
  adjust_fps_for_interpolation?: boolean
  /**
   * Number of Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
}

/**
 * LoRAWeight
 */
export type LoRaWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
  /**
   * Transformer
   *
   * Specifies the transformer to load the lora weight into. 'high' loads into the high-noise transformer, 'low' loads it into the low-noise transformer, while 'both' loads the LoRA into both transformers.
   */
  transformer?: 'high' | 'low' | 'both'
  /**
   * Weight Name
   *
   * Name of the LoRA weight. Used only if `path` is a Hugging Face repository, and required only if you have more than 1 safetensors file in the repo.
   */
  weight_name?: string | unknown
}

/**
 * WanI2VResponse
 */
export type WanV22A14bImageToVideoLoraOutput = {
  /**
   * Prompt
   *
   * The text prompt used for video generation.
   */
  prompt?: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  video: FalAiWanV22A14bImageToVideoLoraFile
}

/**
 * File
 */
export type FalAiWanV22A14bImageToVideoLoraFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * FastImageToVideoHailuo02Input
 */
export type MinimaxHailuo02FastImageToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Duration
   *
   * The duration of the video in seconds. 10 seconds videos are not supported for 1080p resolution.
   */
  duration?: '6' | '10'
  /**
   * Prompt
   */
  prompt: string
  /**
   * Image Url
   */
  image_url: string
}

/**
 * ImageToVideoHailuo02FastOutput
 */
export type MinimaxHailuo02FastImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiMinimaxHailuo02FastImageToVideoFile
}

/**
 * File
 */
export type FalAiMinimaxHailuo02FastImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Veo3ImageToVideoInput
 */
export type Veo3ImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt describing how the image should be animated
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * Auto Fix
   *
   * Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.
   */
  auto_fix?: boolean
  /**
   * Duration
   *
   * The duration of the generated video.
   */
  duration?: '4s' | '6s' | '8s'
  /**
   * Image URL
   *
   * URL of the input image to animate. Should be 720p or higher resolution in 16:9 or 9:16 aspect ratio. If the image is not in 16:9 or 9:16 aspect ratio, it will be cropped to fit.
   */
  image_url: string
}

/**
 * Veo3ImageToVideoOutput
 */
export type Veo3ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video.
   */
  video: FalAiVeo3ImageToVideoFile
}

/**
 * File
 */
export type FalAiVeo3ImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * WanTurboI2VRequest
 */
export type WanV22A14bImageToVideoTurboInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p, 580p, or 720p).
   */
  resolution?: '480p' | '580p' | '720p'
  /**
   * Acceleration
   *
   * Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16' | '1:1'
  /**
   * Video Write Mode
   *
   * The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Enable Output Safety Checker
   *
   * If set to true, output video will be checked for safety after generation.
   */
  enable_output_safety_checker?: boolean
  /**
   * Image URL
   *
   * URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Video Quality
   *
   * The quality of the output video. Higher quality means better visual quality but larger file size.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Safety Checker
   *
   * If set to true, input data will be checked for safety before processing.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number | unknown
  /**
   * End Image URL
   *
   * URL of the end image.
   */
  end_image_url?: string | unknown
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean
}

/**
 * WanTurboI2VResponse
 */
export type WanV22A14bImageToVideoTurboOutput = {
  /**
   * Prompt
   *
   * The text prompt used for video generation.
   */
  prompt?: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  video: FalAiWanV22A14bImageToVideoTurboFile
}

/**
 * File
 */
export type FalAiWanV22A14bImageToVideoTurboFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * WanSmallI2VRequest
 */
export type WanV225bImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Shift
   *
   * Shift value for the video. Must be between 1.0 and 10.0.
   */
  shift?: number
  /**
   * Number of Interpolated Frames
   *
   * Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.
   */
  num_interpolated_frames?: number
  /**
   * Frames per Second
   *
   * Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.
   */
  frames_per_second?: number | unknown
  /**
   * Guidance Scale
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guidance_scale?: number
  /**
   * Number of Frames
   *
   * Number of frames to generate. Must be between 17 to 161 (inclusive).
   */
  num_frames?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, input data will be checked for safety before processing.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Video Write Mode
   *
   * The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Resolution
   *
   * Resolution of the generated video (580p or 720p).
   */
  resolution?: '580p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16' | '1:1'
  /**
   * Enable Output Safety Checker
   *
   * If set to true, output video will be checked for safety after generation.
   */
  enable_output_safety_checker?: boolean
  /**
   * Image URL
   *
   * URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Video Quality
   *
   * The quality of the output video. Higher quality means better visual quality but larger file size.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number | unknown
  /**
   * Interpolator Model
   *
   * The model to use for frame interpolation. If None, no interpolation is applied.
   */
  interpolator_model?: 'none' | 'film' | 'rife'
  /**
   * Number of Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Adjust FPS for Interpolation
   *
   * If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.
   */
  adjust_fps_for_interpolation?: boolean
}

/**
 * WanSmallI2VResponse
 */
export type WanV225bImageToVideoOutput = {
  /**
   * Prompt
   *
   * The text prompt used for video generation.
   */
  prompt?: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  video: FalAiWanV225bImageToVideoFile
}

/**
 * File
 */
export type FalAiWanV225bImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * WanI2VRequest
 */
export type WanV22A14bImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Shift
   *
   * Shift value for the video. Must be between 1.0 and 10.0.
   */
  shift?: number
  /**
   * Acceleration
   *
   * Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Number of Interpolated Frames
   *
   * Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.
   */
  num_interpolated_frames?: number
  /**
   * Frames per Second
   *
   * Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.
   */
  frames_per_second?: number | unknown
  /**
   * Enable Safety Checker
   *
   * If set to true, input data will be checked for safety before processing.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Frames
   *
   * Number of frames to generate. Must be between 17 to 161 (inclusive).
   */
  num_frames?: number
  /**
   * End Image URL
   *
   * URL of the end image.
   */
  end_image_url?: string | unknown
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Guidance Scale (1st Stage)
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guidance_scale?: number
  /**
   * Video Write Mode
   *
   * The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Resolution
   *
   * Resolution of the generated video (480p, 580p, or 720p).
   */
  resolution?: '480p' | '580p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16' | '1:1'
  /**
   * Enable Output Safety Checker
   *
   * If set to true, output video will be checked for safety after generation.
   */
  enable_output_safety_checker?: boolean
  /**
   * Image URL
   *
   * URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Video Quality
   *
   * The quality of the output video. Higher quality means better visual quality but larger file size.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Guidance Scale (2nd Stage)
   *
   * Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.
   */
  guidance_scale_2?: number
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number | unknown
  /**
   * Interpolator Model
   *
   * The model to use for frame interpolation. If None, no interpolation is applied.
   */
  interpolator_model?: 'none' | 'film' | 'rife'
  /**
   * Adjust FPS for Interpolation
   *
   * If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.
   */
  adjust_fps_for_interpolation?: boolean
  /**
   * Number of Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
}

/**
 * WanI2VResponse
 */
export type WanV22A14bImageToVideoOutput = {
  /**
   * Prompt
   *
   * The text prompt used for video generation.
   */
  prompt?: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  video: FalAiWanV22A14bImageToVideoFile
}

/**
 * File
 */
export type FalAiWanV22A14bImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * OmniHumanInput
 */
export type BytedanceOmnihumanInput = {
  /**
   * Audio Url
   *
   * The URL of the audio file to generate the video. Audio must be under 30s long.
   */
  audio_url: string
  /**
   * Image Url
   *
   * The URL of the image used to generate the video
   */
  image_url: string
}

/**
 * OmniHumanOutput
 */
export type BytedanceOmnihumanOutput = {
  /**
   * Duration
   *
   * Duration of audio input/video output as used for billing.
   */
  duration: number
  /**
   * Video
   *
   * Generated video file
   */
  video: FalAiBytedanceOmnihumanFile
}

/**
 * File
 */
export type FalAiBytedanceOmnihumanFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * DistilledImageToVideoInput
 *
 * Distilled model input
 */
export type Ltxv13B098DistilledImageToVideoInput = {
  /**
   * Second Pass Skip Initial Steps
   *
   * The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.
   */
  second_pass_skip_initial_steps?: number
  /**
   * Number of Inference Steps
   *
   * Number of inference steps during the first pass.
   */
  first_pass_num_inference_steps?: number
  /**
   * Frame Rate
   *
   * The frame rate of the video.
   */
  frame_rate?: number
  /**
   * Reverse Video
   *
   * Whether to reverse the video.
   */
  reverse_video?: boolean
  /**
   * Prompt
   *
   * Text prompt to guide generation
   */
  prompt: string
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt using a language model.
   */
  expand_prompt?: boolean
  /**
   * Temporal AdaIN Factor
   *
   * The factor for adaptive instance normalization (AdaIN) applied to generated video chunks after the first. This can help deal with a gradual increase in saturation/contrast in the generated video by normalizing the color distribution across the video. A high value will ensure the color distribution is more consistent across the video, while a low value will allow for more variation in color distribution.
   */
  temporal_adain_factor?: number
  /**
   * Loras
   *
   * LoRA weights to use for generation
   */
  loras?: Array<FalAiLtxv13B098DistilledImageToVideoLoRaWeight>
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Frames
   *
   * The number of frames in the video.
   */
  num_frames?: number
  /**
   * Second Pass Number of Inference Steps
   *
   * Number of inference steps during the second pass.
   */
  second_pass_num_inference_steps?: number
  /**
   * Negative Prompt
   *
   * Negative prompt for generation
   */
  negative_prompt?: string
  /**
   * Enable Detail Pass
   *
   * Whether to use a detail pass. If True, the model will perform a second pass to refine the video and enhance details. This incurs a 2.0x cost multiplier on the base price.
   */
  enable_detail_pass?: boolean
  /**
   * Resolution
   *
   * Resolution of the generated video.
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the video.
   */
  aspect_ratio?: '9:16' | '1:1' | '16:9' | 'auto'
  /**
   * Tone Map Compression Ratio
   *
   * The compression ratio for tone mapping. This is used to compress the dynamic range of the video to improve visual quality. A value of 0.0 means no compression, while a value of 1.0 means maximum compression.
   */
  tone_map_compression_ratio?: number
  /**
   * Image URL
   *
   * Image URL for Image-to-Video task
   */
  image_url: string
  /**
   * Constant Rate Factor
   *
   * The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.
   */
  constant_rate_factor?: number
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number
}

/**
 * LoRAWeight
 */
export type FalAiLtxv13B098DistilledImageToVideoLoRaWeight = {
  /**
   * Path
   *
   * URL or path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   * Scale of the LoRA weight. This is a multiplier applied to the LoRA weight when loading it.
   */
  scale?: number
  /**
   * Weight Name
   *
   * Name of the LoRA weight. Only used if `path` is a HuggingFace repository, and is only required when the repository contains multiple LoRA weights.
   */
  weight_name?: string
}

/**
 * ImageToVideoOutput
 */
export type Ltxv13B098DistilledImageToVideoOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiLtxv13B098DistilledImageToVideoFile
}

/**
 * File
 */
export type FalAiLtxv13B098DistilledImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Veo3ImageToVideoInput
 */
export type Veo3FastImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt describing how the image should be animated
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * Auto Fix
   *
   * Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.
   */
  auto_fix?: boolean
  /**
   * Duration
   *
   * The duration of the generated video.
   */
  duration?: '4s' | '6s' | '8s'
  /**
   * Image URL
   *
   * URL of the input image to animate. Should be 720p or higher resolution in 16:9 or 9:16 aspect ratio. If the image is not in 16:9 or 9:16 aspect ratio, it will be cropped to fit.
   */
  image_url: string
}

/**
 * Veo3ImageToVideoOutput
 */
export type Veo3FastImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video.
   */
  video: FalAiVeo3FastImageToVideoFile
}

/**
 * File
 */
export type FalAiVeo3FastImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Q1ReferenceToVideoRequest
 */
export type ViduQ1ReferenceToVideoInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 1500 characters
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the output video
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Bgm
   *
   * Whether to add background music to the generated video
   */
  bgm?: boolean
  /**
   * Reference Image Urls
   *
   * URLs of the reference images to use for consistent subject appearance. Q1 model supports up to 7 reference images.
   */
  reference_image_urls: Array<string>
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number
  /**
   * Movement Amplitude
   *
   * The movement amplitude of objects in the frame
   */
  movement_amplitude?: 'auto' | 'small' | 'medium' | 'large'
}

/**
 * Q1ReferenceToVideoOutput
 */
export type ViduQ1ReferenceToVideoOutput = {
  /**
   * Video
   *
   * The generated video with consistent subjects from reference images using the Q1 model
   */
  video: FalAiViduQ1ReferenceToVideoFile
}

/**
 * File
 */
export type FalAiViduQ1ReferenceToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * AvatarSingleTextRequest
 */
export type AiAvatarSingleTextInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the video to generate. Must be either 480p or 720p.
   */
  resolution?: '480p' | '720p'
  /**
   * Acceleration
   *
   * The acceleration level to use for generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Text Input
   *
   * The text input to guide video generation.
   */
  text_input: string
  /**
   * Image URL
   *
   * URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Voice
   *
   * The voice to use for speech generation
   */
  voice:
    | 'Aria'
    | 'Roger'
    | 'Sarah'
    | 'Laura'
    | 'Charlie'
    | 'George'
    | 'Callum'
    | 'River'
    | 'Liam'
    | 'Charlotte'
    | 'Alice'
    | 'Matilda'
    | 'Will'
    | 'Jessica'
    | 'Eric'
    | 'Chris'
    | 'Brian'
    | 'Daniel'
    | 'Lily'
    | 'Bill'
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Number of Frames
   *
   * Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.
   */
  num_frames?: number
}

/**
 * AvatarSingleTextResponse
 */
export type AiAvatarSingleTextOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiAiAvatarSingleTextFile
}

/**
 * File
 */
export type FalAiAiAvatarSingleTextFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * AvatarSingleAudioRequest
 */
export type AiAvatarInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the video to generate. Must be either 480p or 720p.
   */
  resolution?: '480p' | '720p'
  /**
   * Acceleration
   *
   * The acceleration level to use for generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Image URL
   *
   * URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Audio URL
   *
   * The URL of the audio file.
   */
  audio_url: string
  /**
   * Number of Frames
   *
   * Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.
   */
  num_frames?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
}

/**
 * AvatarSingleAudioResponse
 */
export type AiAvatarOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiAiAvatarFile
}

/**
 * File
 */
export type FalAiAiAvatarFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * AvatarMultiTextRequest
 */
export type AiAvatarMultiTextInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Second Text Input
   *
   * The text input to guide video generation.
   */
  second_text_input: string
  /**
   * Acceleration
   *
   * The acceleration level to use for generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Resolution
   *
   * Resolution of the video to generate. Must be either 480p or 720p.
   */
  resolution?: '480p' | '720p'
  /**
   * First Text Input
   *
   * The text input to guide video generation.
   */
  first_text_input: string
  /**
   * Image URL
   *
   * URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Voice2
   *
   * The second person's voice to use for speech generation
   */
  voice2?:
    | 'Aria'
    | 'Roger'
    | 'Sarah'
    | 'Laura'
    | 'Charlie'
    | 'George'
    | 'Callum'
    | 'River'
    | 'Liam'
    | 'Charlotte'
    | 'Alice'
    | 'Matilda'
    | 'Will'
    | 'Jessica'
    | 'Eric'
    | 'Chris'
    | 'Brian'
    | 'Daniel'
    | 'Lily'
    | 'Bill'
  /**
   * Voice1
   *
   * The first person's voice to use for speech generation
   */
  voice1?:
    | 'Aria'
    | 'Roger'
    | 'Sarah'
    | 'Laura'
    | 'Charlie'
    | 'George'
    | 'Callum'
    | 'River'
    | 'Liam'
    | 'Charlotte'
    | 'Alice'
    | 'Matilda'
    | 'Will'
    | 'Jessica'
    | 'Eric'
    | 'Chris'
    | 'Brian'
    | 'Daniel'
    | 'Lily'
    | 'Bill'
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Number of Frames
   *
   * Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.
   */
  num_frames?: number
}

/**
 * AvatarMultiTextResponse
 */
export type AiAvatarMultiTextOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiAiAvatarMultiTextFile
}

/**
 * File
 */
export type FalAiAiAvatarMultiTextFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * AvatarMultiAudioPersonRequest
 */
export type AiAvatarMultiInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the video to generate. Must be either 480p or 720p.
   */
  resolution?: '480p' | '720p'
  /**
   * Acceleration
   *
   * The acceleration level to use for generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * First Audio URL
   *
   * The URL of the Person 1 audio file.
   */
  first_audio_url: string
  /**
   * Image URL
   *
   * URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Second Audio URL
   *
   * The URL of the Person 2 audio file.
   */
  second_audio_url?: string
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Use Only First Audio
   *
   * Whether to use only the first audio file.
   */
  use_only_first_audio?: boolean
  /**
   * Number of Frames
   *
   * Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.
   */
  num_frames?: number
}

/**
 * AvatarMultiAudioResponse
 */
export type AiAvatarMultiOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiAiAvatarMultiFile
}

/**
 * File
 */
export type FalAiAiAvatarMultiFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ProImageToVideoHailuo02Input
 */
export type MinimaxHailuo02ProImageToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Prompt
   */
  prompt: string
  /**
   * End Image Url
   *
   * Optional URL of the image to use as the last frame of the video
   */
  end_image_url?: string
  /**
   * Image Url
   */
  image_url: string
}

/**
 * ImageToVideoHailuo02Output
 */
export type MinimaxHailuo02ProImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiMinimaxHailuo02ProImageToVideoFile
}

/**
 * File
 */
export type FalAiMinimaxHailuo02ProImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * SeedanceImageToVideoInput
 */
export type BytedanceSeedanceV1LiteImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt used to generate the video
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution - 480p for faster generation, 720p for higher quality
   */
  resolution?: '480p' | '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '21:9' | '16:9' | '4:3' | '1:1' | '3:4' | '9:16' | 'auto'
  /**
   * Duration
   *
   * Duration of the video in seconds
   */
  duration?: '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9' | '10' | '11' | '12'
  /**
   * Image Url
   *
   * The URL of the image used to generate video
   */
  image_url: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Camera Fixed
   *
   * Whether to fix the camera position
   */
  camera_fixed?: boolean
  /**
   * End Image Url
   *
   * The URL of the image the video ends with. Defaults to None.
   */
  end_image_url?: string
  /**
   * Seed
   *
   * Random seed to control video generation. Use -1 for random.
   */
  seed?: number
}

/**
 * SeedanceVideoOutput
 */
export type BytedanceSeedanceV1LiteImageToVideoOutput = {
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * Generated video file
   */
  video: FalAiBytedanceSeedanceV1LiteImageToVideoFile
}

/**
 * File
 */
export type FalAiBytedanceSeedanceV1LiteImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Input
 */
export type HunyuanAvatarInput = {
  /**
   * Text
   *
   * Text prompt describing the scene.
   */
  text?: string
  /**
   * Image Url
   *
   * The URL of the reference image.
   */
  image_url: string
  /**
   * Turbo Mode
   *
   * If true, the video will be generated faster with no noticeable degradation in the visual quality.
   */
  turbo_mode?: boolean
  /**
   * Audio Url
   *
   * The URL of the audio file.
   */
  audio_url: string
  /**
   * Seed
   *
   * Random seed for generation.
   */
  seed?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Num Frames
   *
   * Number of video frames to generate at 25 FPS. If greater than the input audio length, it will capped to the length of the input audio.
   */
  num_frames?: number
}

/**
 * Output
 */
export type HunyuanAvatarOutput = {
  /**
   * Video
   *
   * The generated video with the avatar animation.
   */
  video: FalAiHunyuanAvatarFile
}

/**
 * File
 */
export type FalAiHunyuanAvatarFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoV21ProRequest
 */
export type KlingVideoV21ProImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Tail Image Url
   *
   * URL of the image to be used for the end of the video
   */
  tail_image_url?: string
  /**
   * Image Url
   *
   * URL of the image to be used for the video
   */
  image_url: string
}

/**
 * ImageToVideoV21ProOutput
 */
export type KlingVideoV21ProImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV21ProImageToVideoFile
}

/**
 * File
 */
export type FalAiKlingVideoV21ProImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Input
 */
export type HunyuanPortraitInput = {
  /**
   * Video Url
   *
   * The URL of the driving video.
   */
  video_url: string
  /**
   * Seed
   *
   * Random seed for generation. If None, a random seed will be used.
   */
  seed?: number
  /**
   * Use Arcface
   *
   * Whether to use ArcFace for face recognition.
   */
  use_arcface?: boolean
  /**
   * Image Url
   *
   * The URL of the source image.
   */
  image_url: string
}

/**
 * Output
 */
export type HunyuanPortraitOutput = {
  /**
   * Video
   *
   * The generated video with the portrait animation.
   */
  video: FalAiHunyuanPortraitFile
}

/**
 * File
 */
export type FalAiHunyuanPortraitFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * MultiImageToVideoRequest
 */
export type KlingVideoV16StandardElementsInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video frame
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Input Image Urls
   *
   * List of image URLs to use for video generation. Supports up to 4 images.
   */
  input_image_urls: Array<string>
  /**
   * Negative Prompt
   */
  negative_prompt?: string
}

/**
 * ElementsOutput
 */
export type KlingVideoV16StandardElementsOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV16StandardElementsFile
}

/**
 * File
 */
export type FalAiKlingVideoV16StandardElementsFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * MultiImageToVideoRequest
 */
export type KlingVideoV16ProElementsInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video frame
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Input Image Urls
   *
   * List of image URLs to use for video generation. Supports up to 4 images.
   */
  input_image_urls: Array<string>
  /**
   * Negative Prompt
   */
  negative_prompt?: string
}

/**
 * ElementsOutput
 */
export type KlingVideoV16ProElementsOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV16ProElementsFile
}

/**
 * File
 */
export type FalAiKlingVideoV16ProElementsFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * DistilledImageToVideoInput
 *
 * Distilled model input
 */
export type LtxVideo13bDistilledImageToVideoInput = {
  /**
   * Second Pass Skip Initial Steps
   *
   * The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.
   */
  second_pass_skip_initial_steps?: number
  /**
   * First Pass Num Inference Steps
   *
   * Number of inference steps during the first pass.
   */
  first_pass_num_inference_steps?: number
  /**
   * Frame Rate
   *
   * The frame rate of the video.
   */
  frame_rate?: number
  /**
   * Reverse Video
   *
   * Whether to reverse the video.
   */
  reverse_video?: boolean
  /**
   * Prompt
   *
   * Text prompt to guide generation
   */
  prompt: string
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt using a language model.
   */
  expand_prompt?: boolean
  /**
   * Loras
   *
   * LoRA weights to use for generation
   */
  loras?: Array<FalAiLtxVideo13bDistilledImageToVideoLoRaWeight>
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Num Frames
   *
   * The number of frames in the video.
   */
  num_frames?: number
  /**
   * Second Pass Num Inference Steps
   *
   * Number of inference steps during the second pass.
   */
  second_pass_num_inference_steps?: number
  /**
   * Negative Prompt
   *
   * Negative prompt for generation
   */
  negative_prompt?: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p or 720p).
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the video.
   */
  aspect_ratio?: '9:16' | '1:1' | '16:9' | 'auto'
  /**
   * Image Url
   *
   * Image URL for Image-to-Video task
   */
  image_url: string
  /**
   * Constant Rate Factor
   *
   * The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.
   */
  constant_rate_factor?: number
  /**
   * First Pass Skip Final Steps
   *
   * Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.
   */
  first_pass_skip_final_steps?: number
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number
}

/**
 * LoRAWeight
 */
export type FalAiLtxVideo13bDistilledImageToVideoLoRaWeight = {
  /**
   * Path
   *
   * URL or path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   * Scale of the LoRA weight. This is a multiplier applied to the LoRA weight when loading it.
   */
  scale?: number
  /**
   * Weight Name
   *
   * Name of the LoRA weight. Only used if `path` is a HuggingFace repository, and is only required when the repository contains multiple LoRA weights.
   */
  weight_name?: string
}

/**
 * ImageToVideoOutput
 */
export type LtxVideo13bDistilledImageToVideoOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiLtxVideo13bDistilledImageToVideoFile
}

/**
 * File
 */
export type FalAiLtxVideo13bDistilledImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoInput
 */
export type LtxVideo13bDevImageToVideoInput = {
  /**
   * Second Pass Skip Initial Steps
   *
   * The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.
   */
  second_pass_skip_initial_steps?: number
  /**
   * First Pass Num Inference Steps
   *
   * Number of inference steps during the first pass.
   */
  first_pass_num_inference_steps?: number
  /**
   * Frame Rate
   *
   * The frame rate of the video.
   */
  frame_rate?: number
  /**
   * Prompt
   *
   * Text prompt to guide generation
   */
  prompt: string
  /**
   * Reverse Video
   *
   * Whether to reverse the video.
   */
  reverse_video?: boolean
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt using a language model.
   */
  expand_prompt?: boolean
  /**
   * Loras
   *
   * LoRA weights to use for generation
   */
  loras?: Array<FalAiLtxVideo13bDevImageToVideoLoRaWeight>
  /**
   * Second Pass Num Inference Steps
   *
   * Number of inference steps during the second pass.
   */
  second_pass_num_inference_steps?: number
  /**
   * Num Frames
   *
   * The number of frames in the video.
   */
  num_frames?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * Negative prompt for generation
   */
  negative_prompt?: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p or 720p).
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the video.
   */
  aspect_ratio?: '9:16' | '1:1' | '16:9' | 'auto'
  /**
   * Image Url
   *
   * Image URL for Image-to-Video task
   */
  image_url: string
  /**
   * Constant Rate Factor
   *
   * The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.
   */
  constant_rate_factor?: number
  /**
   * First Pass Skip Final Steps
   *
   * Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.
   */
  first_pass_skip_final_steps?: number
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number
}

/**
 * LoRAWeight
 */
export type FalAiLtxVideo13bDevImageToVideoLoRaWeight = {
  /**
   * Path
   *
   * URL or path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   * Scale of the LoRA weight. This is a multiplier applied to the LoRA weight when loading it.
   */
  scale?: number
  /**
   * Weight Name
   *
   * Name of the LoRA weight. Only used if `path` is a HuggingFace repository, and is only required when the repository contains multiple LoRA weights.
   */
  weight_name?: string
}

/**
 * ImageToVideoOutput
 */
export type LtxVideo13bDevImageToVideoOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiLtxVideo13bDevImageToVideoFile
}

/**
 * File
 */
export type FalAiLtxVideo13bDevImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoInput
 *
 * Request model for image-to-video generation.
 */
export type LtxVideoLoraImageToVideoInput = {
  /**
   * Number Of Steps
   *
   * The number of inference steps to use.
   */
  number_of_steps?: number
  /**
   * Resolution
   *
   * The resolution of the video.
   */
  resolution?: '480p' | '720p'
  /**
   * Reverse Video
   *
   * Whether to reverse the video.
   */
  reverse_video?: boolean
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the video.
   */
  aspect_ratio?: '16:9' | '1:1' | '9:16' | 'auto'
  /**
   * Frame Rate
   *
   * The frame rate of the video.
   */
  frame_rate?: number
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt using the LLM.
   */
  expand_prompt?: boolean
  /**
   * Number Of Frames
   *
   * The number of frames in the video.
   */
  number_of_frames?: number
  /**
   * Image Url
   *
   * The URL of the image to use as input.
   */
  image_url: string
  /**
   * Loras
   *
   * The LoRA weights to use for generation.
   */
  loras?: Array<FalAiLtxVideoLoraImageToVideoLoRaWeight>
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * The seed to use for generation.
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to use.
   */
  negative_prompt?: string
}

/**
 * LoRAWeight
 *
 * LoRA weight to use for generation.
 */
export type FalAiLtxVideoLoraImageToVideoLoRaWeight = {
  /**
   * Path
   *
   * URL or path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   * Scale of the LoRA weight. This is a multiplier applied to the LoRA weight when loading it.
   */
  scale?: number
  /**
   * Weight Name
   *
   * Name of the LoRA weight. Only used if `path` is a HuggingFace repository, and is only required when the repository contains multiple LoRA weights.
   */
  weight_name?: string
}

/**
 * ImageToVideoOutput
 */
export type LtxVideoLoraImageToVideoOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video.
   */
  video: FalAiLtxVideoLoraImageToVideoFile
}

/**
 * File
 */
export type FalAiLtxVideoLoraImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TransitionRequest
 */
export type PixverseV45TransitionInput = {
  /**
   * Prompt
   *
   * The prompt for the transition
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '8'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * First Image Url
   *
   * URL of the image to use as the first frame
   */
  first_image_url: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * End Image Url
   *
   * URL of the image to use as the last frame
   */
  end_image_url?: string
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * TransitionOutput
 */
export type PixverseV45TransitionOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPixverseV45TransitionFile
}

/**
 * File
 */
export type FalAiPixverseV45TransitionFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * FastImageToVideoRequestV4
 */
export type PixverseV45ImageToVideoFastInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Camera Movement
   *
   * The type of camera movement to apply to the video
   */
  camera_movement?:
    | 'horizontal_left'
    | 'horizontal_right'
    | 'vertical_up'
    | 'vertical_down'
    | 'zoom_in'
    | 'zoom_out'
    | 'crane_up'
    | 'quickly_zoom_in'
    | 'quickly_zoom_out'
    | 'smooth_zoom_in'
    | 'camera_rotation'
    | 'robo_arm'
    | 'super_dolly_out'
    | 'whip_pan'
    | 'hitchcock'
    | 'left_follow'
    | 'right_follow'
    | 'pan_left'
    | 'pan_right'
    | 'fix_bg'
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * I2VOutputV4
 */
export type PixverseV45ImageToVideoFastOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPixverseV45ImageToVideoFastFile
}

/**
 * File
 */
export type FalAiPixverseV45ImageToVideoFastFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoRequestV4
 */
export type PixverseV45ImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds
   */
  duration?: '5' | '8'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Camera Movement
   *
   * The type of camera movement to apply to the video
   */
  camera_movement?:
    | 'horizontal_left'
    | 'horizontal_right'
    | 'vertical_up'
    | 'vertical_down'
    | 'zoom_in'
    | 'zoom_out'
    | 'crane_up'
    | 'quickly_zoom_in'
    | 'quickly_zoom_out'
    | 'smooth_zoom_in'
    | 'camera_rotation'
    | 'robo_arm'
    | 'super_dolly_out'
    | 'whip_pan'
    | 'hitchcock'
    | 'left_follow'
    | 'right_follow'
    | 'pan_left'
    | 'pan_right'
    | 'fix_bg'
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * I2VOutputV4
 */
export type PixverseV45ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPixverseV45ImageToVideoFile
}

/**
 * File
 */
export type FalAiPixverseV45ImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * EffectInput
 */
export type PixverseV45EffectsInput = {
  /**
   * Effect
   *
   * The effect to apply to the video
   */
  effect:
    | 'Kiss Me AI'
    | 'Kiss'
    | 'Muscle Surge'
    | 'Warmth of Jesus'
    | 'Anything, Robot'
    | 'The Tiger Touch'
    | 'Hug'
    | 'Holy Wings'
    | 'Microwave'
    | 'Zombie Mode'
    | 'Squid Game'
    | 'Baby Face'
    | 'Black Myth: Wukong'
    | 'Long Hair Magic'
    | 'Leggy Run'
    | 'Fin-tastic Mermaid'
    | 'Punch Face'
    | 'Creepy Devil Smile'
    | 'Thunder God'
    | 'Eye Zoom Challenge'
    | "Who's Arrested?"
    | 'Baby Arrived'
    | 'Werewolf Rage'
    | 'Bald Swipe'
    | 'BOOM DROP'
    | 'Huge Cutie'
    | 'Liquid Metal'
    | 'Sharksnap!'
    | 'Dust Me Away'
    | '3D Figurine Factor'
    | 'Bikini Up'
    | 'My Girlfriends'
    | 'My Boyfriends'
    | 'Subject 3 Fever'
    | 'Earth Zoom'
    | 'Pole Dance'
    | 'Vroom Dance'
    | 'GhostFace Terror'
    | 'Dragon Evoker'
    | 'Skeletal Bae'
    | 'Summoning succubus'
    | 'Halloween Voodoo Doll'
    | '3D Naked-Eye AD'
    | 'Package Explosion'
    | 'Dishes Served'
    | 'Ocean ad'
    | 'Supermarket AD'
    | 'Tree doll'
    | 'Come Feel My Abs'
    | 'The Bicep Flex'
    | 'London Elite Vibe'
    | 'Flora Nymph Gown'
    | 'Christmas Costume'
    | "It's Snowy"
    | 'Reindeer Cruiser'
    | 'Snow Globe Maker'
    | 'Pet Christmas Outfit'
    | 'Adopt a Polar Pal'
    | 'Cat Christmas Box'
    | 'Starlight Gift Box'
    | 'Xmas Poster'
    | 'Pet Christmas Tree'
    | 'City Santa Hat'
    | 'Stocking Sweetie'
    | 'Christmas Night'
    | 'Xmas Front Page Karma'
    | "Grinch's Xmas Hijack"
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '8'
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
  /**
   * Image Url
   *
   * Optional URL of the image to use as the first frame. If not provided, generates from text
   */
  image_url: string
}

/**
 * EffectOutput
 */
export type PixverseV45EffectsOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPixverseV45EffectsFile
}

/**
 * File
 */
export type FalAiPixverseV45EffectsFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * HunyuanCustomRequest
 */
export type HunyuanCustomInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation (max 500 characters).
   */
  prompt: string
  /**
   * Aspect Ratio (W:H)
   *
   * The aspect ratio of the video to generate.
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.
   */
  resolution?: '512p' | '720p'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Image Url
   *
   * URL of the image input.
   */
  image_url: string
  /**
   * Frames per second
   *
   * The frames per second of the generated video.
   */
  fps?: number
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * The seed to use for generating the video.
   */
  seed?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to run. Lower gets faster results, higher gets better results.
   */
  num_inference_steps?: number
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * CFG Scale
   *
   * Classifier-Free Guidance scale for the generation.
   */
  cfg_scale?: number
}

/**
 * HunyuanCustomResponse
 */
export type HunyuanCustomOutput = {
  /**
   * Seed
   *
   * The seed used for generating the video.
   */
  seed: number
  /**
   * Video
   */
  video: FalAiHunyuanCustomFile
}

/**
 * File
 */
export type FalAiHunyuanCustomFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * FramePackF1Request
 */
export type FramepackF1Input = {
  /**
   * Prompt
   *
   * Text prompt for video generation (max 500 characters).
   */
  prompt: string
  /**
   * Aspect Ratio (W:H)
   *
   * The aspect ratio of the video to generate.
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.
   */
  resolution?: '720p' | '480p'
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Image Url
   *
   * URL of the image input.
   */
  image_url: string
  /**
   * Guidance Scale
   *
   * Guidance scale for the generation.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * The seed to use for generating the video.
   */
  seed?: number | unknown
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * CFG Scale
   *
   * Classifier-Free Guidance scale for the generation.
   */
  cfg_scale?: number
}

/**
 * FramePackF1Response
 */
export type FramepackF1Output = {
  /**
   * Seed
   *
   * The seed used for generating the video.
   */
  seed: number
  video: FalAiFramepackF1File
}

/**
 * File
 */
export type FalAiFramepackF1File = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * Q1StartEndToVideoRequest
 */
export type ViduQ1StartEndToVideoInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 1500 characters
   */
  prompt: string
  /**
   * Start Image Url
   *
   * URL of the image to use as the first frame
   */
  start_image_url: string
  /**
   * Movement Amplitude
   *
   * The movement amplitude of objects in the frame
   */
  movement_amplitude?: 'auto' | 'small' | 'medium' | 'large'
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number
  /**
   * End Image Url
   *
   * URL of the image to use as the last frame
   */
  end_image_url: string
}

/**
 * Q1StartEndToVideoOutput
 */
export type ViduQ1StartEndToVideoOutput = {
  /**
   * Video
   *
   * The generated transition video between start and end frames using the Q1 model
   */
  video: FalAiViduQ1StartEndToVideoFile
}

/**
 * File
 */
export type FalAiViduQ1StartEndToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Q1ImageToVideoRequest
 */
export type ViduQ1ImageToVideoInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 1500 characters
   */
  prompt: string
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number
  /**
   * Movement Amplitude
   *
   * The movement amplitude of objects in the frame
   */
  movement_amplitude?: 'auto' | 'small' | 'medium' | 'large'
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * Q1ImageToVideoOutput
 */
export type ViduQ1ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video using the Q1 model from a single image
   */
  video: FalAiViduQ1ImageToVideoFile
}

/**
 * File
 */
export type FalAiViduQ1ImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * MagiImageToVideoRequest
 */
export type MagiImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16' | '1:1'
  /**
   * Image Url
   *
   * URL of the input image to represent the first frame of the video. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: 4 | 8 | 16 | 32 | 64
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Num Frames
   *
   * Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.
   */
  num_frames?: number
}

/**
 * MagiImageToVideoResponse
 */
export type MagiImageToVideoOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiMagiImageToVideoFile
}

/**
 * File
 */
export type FalAiMagiImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * EffectInput
 */
export type PixverseV4EffectsInput = {
  /**
   * Effect
   *
   * The effect to apply to the video
   */
  effect:
    | 'Kiss Me AI'
    | 'Kiss'
    | 'Muscle Surge'
    | 'Warmth of Jesus'
    | 'Anything, Robot'
    | 'The Tiger Touch'
    | 'Hug'
    | 'Holy Wings'
    | 'Microwave'
    | 'Zombie Mode'
    | 'Squid Game'
    | 'Baby Face'
    | 'Black Myth: Wukong'
    | 'Long Hair Magic'
    | 'Leggy Run'
    | 'Fin-tastic Mermaid'
    | 'Punch Face'
    | 'Creepy Devil Smile'
    | 'Thunder God'
    | 'Eye Zoom Challenge'
    | "Who's Arrested?"
    | 'Baby Arrived'
    | 'Werewolf Rage'
    | 'Bald Swipe'
    | 'BOOM DROP'
    | 'Huge Cutie'
    | 'Liquid Metal'
    | 'Sharksnap!'
    | 'Dust Me Away'
    | '3D Figurine Factor'
    | 'Bikini Up'
    | 'My Girlfriends'
    | 'My Boyfriends'
    | 'Subject 3 Fever'
    | 'Earth Zoom'
    | 'Pole Dance'
    | 'Vroom Dance'
    | 'GhostFace Terror'
    | 'Dragon Evoker'
    | 'Skeletal Bae'
    | 'Summoning succubus'
    | 'Halloween Voodoo Doll'
    | '3D Naked-Eye AD'
    | 'Package Explosion'
    | 'Dishes Served'
    | 'Ocean ad'
    | 'Supermarket AD'
    | 'Tree doll'
    | 'Come Feel My Abs'
    | 'The Bicep Flex'
    | 'London Elite Vibe'
    | 'Flora Nymph Gown'
    | 'Christmas Costume'
    | "It's Snowy"
    | 'Reindeer Cruiser'
    | 'Snow Globe Maker'
    | 'Pet Christmas Outfit'
    | 'Adopt a Polar Pal'
    | 'Cat Christmas Box'
    | 'Starlight Gift Box'
    | 'Xmas Poster'
    | 'Pet Christmas Tree'
    | 'City Santa Hat'
    | 'Stocking Sweetie'
    | 'Christmas Night'
    | 'Xmas Front Page Karma'
    | "Grinch's Xmas Hijack"
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '8'
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
  /**
   * Image Url
   *
   * Optional URL of the image to use as the first frame. If not provided, generates from text
   */
  image_url: string
}

/**
 * EffectOutput
 */
export type PixverseV4EffectsOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPixverseV4EffectsFile
}

/**
 * File
 */
export type FalAiPixverseV4EffectsFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * MagiImageToVideoRequest
 */
export type MagiDistilledImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16' | '1:1'
  /**
   * Image Url
   *
   * URL of the input image to represent the first frame of the video. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: 4 | 8 | 16 | 32
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Num Frames
   *
   * Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.
   */
  num_frames?: number
}

/**
 * MagiImageToVideoResponse
 */
export type MagiDistilledImageToVideoOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiMagiDistilledImageToVideoFile
}

/**
 * File
 */
export type FalAiMagiDistilledImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * FramePackF2LFRequest
 */
export type FramepackFlf2vInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation (max 500 characters).
   */
  prompt: string
  /**
   * Aspect Ratio (W:H)
   *
   * The aspect ratio of the video to generate.
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.
   */
  resolution?: '720p' | '480p'
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Image Url
   *
   * URL of the image input.
   */
  image_url: string
  /**
   * Strength of last frame
   *
   * Determines the influence of the final frame on the generated video. Higher values result in the output being more heavily influenced by the last frame.
   */
  strength?: number
  /**
   * Guidance Scale
   *
   * Guidance scale for the generation.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * The seed to use for generating the video.
   */
  seed?: number | unknown
  /**
   * End Image Url
   *
   * URL of the end image input.
   */
  end_image_url: string
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * CFG Scale
   *
   * Classifier-Free Guidance scale for the generation.
   */
  cfg_scale?: number
}

/**
 * FramePackFLF2VResponse
 */
export type FramepackFlf2vOutput = {
  /**
   * Seed
   *
   * The seed used for generating the video.
   */
  seed: number
  video: FalAiFramepackFlf2vFile
}

/**
 * File
 */
export type FalAiFramepackFlf2vFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * WanFLF2VRequest
 */
export type WanFlf2vInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Shift
   *
   * Shift parameter for video generation.
   */
  shift?: number
  /**
   * Acceleration
   *
   * Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Frames Per Second
   *
   * Frames per second of the generated video. Must be between 5 to 24.
   */
  frames_per_second?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Start Image Url
   *
   * URL of the starting image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  start_image_url: string
  /**
   * End Image Url
   *
   * URL of the ending image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  end_image_url: string
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Num Frames
   *
   * Number of frames to generate. Must be between 81 to 100 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.
   */
  num_frames?: number
  /**
   * Resolution
   *
   * Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16' | '1:1'
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Guide Scale
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guide_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
}

/**
 * WanFLF2VResponse
 */
export type WanFlf2vOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiWanFlf2vFile
}

/**
 * File
 */
export type FalAiWanFlf2vFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * FramePackRequest
 */
export type FramepackInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation (max 500 characters).
   */
  prompt: string
  /**
   * Aspect Ratio (W:H)
   *
   * The aspect ratio of the video to generate.
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.
   */
  resolution?: '720p' | '480p'
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Image Url
   *
   * URL of the image input.
   */
  image_url: string
  /**
   * Guidance Scale
   *
   * Guidance scale for the generation.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * The seed to use for generating the video.
   */
  seed?: number | unknown
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * CFG Scale
   *
   * Classifier-Free Guidance scale for the generation.
   */
  cfg_scale?: number
}

/**
 * FramePackResponse
 */
export type FramepackOutput = {
  /**
   * Seed
   *
   * The seed used for generating the video.
   */
  seed: number
  video: FalAiFramepackFile
}

/**
 * File
 */
export type FalAiFramepackFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * FastImageToVideoRequestV4
 */
export type PixverseV4ImageToVideoFastInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Camera Movement
   *
   * The type of camera movement to apply to the video
   */
  camera_movement?:
    | 'horizontal_left'
    | 'horizontal_right'
    | 'vertical_up'
    | 'vertical_down'
    | 'zoom_in'
    | 'zoom_out'
    | 'crane_up'
    | 'quickly_zoom_in'
    | 'quickly_zoom_out'
    | 'smooth_zoom_in'
    | 'camera_rotation'
    | 'robo_arm'
    | 'super_dolly_out'
    | 'whip_pan'
    | 'hitchcock'
    | 'left_follow'
    | 'right_follow'
    | 'pan_left'
    | 'pan_right'
    | 'fix_bg'
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * I2VOutputV4
 */
export type PixverseV4ImageToVideoFastOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPixverseV4ImageToVideoFastFile
}

/**
 * File
 */
export type FalAiPixverseV4ImageToVideoFastFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoRequestV4
 */
export type PixverseV4ImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds
   */
  duration?: '5' | '8'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Camera Movement
   *
   * The type of camera movement to apply to the video
   */
  camera_movement?:
    | 'horizontal_left'
    | 'horizontal_right'
    | 'vertical_up'
    | 'vertical_down'
    | 'zoom_in'
    | 'zoom_out'
    | 'crane_up'
    | 'quickly_zoom_in'
    | 'quickly_zoom_out'
    | 'smooth_zoom_in'
    | 'camera_rotation'
    | 'robo_arm'
    | 'super_dolly_out'
    | 'whip_pan'
    | 'hitchcock'
    | 'left_follow'
    | 'right_follow'
    | 'pan_left'
    | 'pan_right'
    | 'fix_bg'
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * I2VOutputV4
 */
export type PixverseV4ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPixverseV4ImageToVideoFile
}

/**
 * File
 */
export type FalAiPixverseV4ImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * EffectInput
 */
export type PixverseV35EffectsInput = {
  /**
   * Effect
   *
   * The effect to apply to the video
   */
  effect:
    | 'Kiss Me AI'
    | 'Kiss'
    | 'Muscle Surge'
    | 'Warmth of Jesus'
    | 'Anything, Robot'
    | 'The Tiger Touch'
    | 'Hug'
    | 'Holy Wings'
    | 'Microwave'
    | 'Zombie Mode'
    | 'Squid Game'
    | 'Baby Face'
    | 'Black Myth: Wukong'
    | 'Long Hair Magic'
    | 'Leggy Run'
    | 'Fin-tastic Mermaid'
    | 'Punch Face'
    | 'Creepy Devil Smile'
    | 'Thunder God'
    | 'Eye Zoom Challenge'
    | "Who's Arrested?"
    | 'Baby Arrived'
    | 'Werewolf Rage'
    | 'Bald Swipe'
    | 'BOOM DROP'
    | 'Huge Cutie'
    | 'Liquid Metal'
    | 'Sharksnap!'
    | 'Dust Me Away'
    | '3D Figurine Factor'
    | 'Bikini Up'
    | 'My Girlfriends'
    | 'My Boyfriends'
    | 'Subject 3 Fever'
    | 'Earth Zoom'
    | 'Pole Dance'
    | 'Vroom Dance'
    | 'GhostFace Terror'
    | 'Dragon Evoker'
    | 'Skeletal Bae'
    | 'Summoning succubus'
    | 'Halloween Voodoo Doll'
    | '3D Naked-Eye AD'
    | 'Package Explosion'
    | 'Dishes Served'
    | 'Ocean ad'
    | 'Supermarket AD'
    | 'Tree doll'
    | 'Come Feel My Abs'
    | 'The Bicep Flex'
    | 'London Elite Vibe'
    | 'Flora Nymph Gown'
    | 'Christmas Costume'
    | "It's Snowy"
    | 'Reindeer Cruiser'
    | 'Snow Globe Maker'
    | 'Pet Christmas Outfit'
    | 'Adopt a Polar Pal'
    | 'Cat Christmas Box'
    | 'Starlight Gift Box'
    | 'Xmas Poster'
    | 'Pet Christmas Tree'
    | 'City Santa Hat'
    | 'Stocking Sweetie'
    | 'Christmas Night'
    | 'Xmas Front Page Karma'
    | "Grinch's Xmas Hijack"
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '8'
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
  /**
   * Image Url
   *
   * Optional URL of the image to use as the first frame. If not provided, generates from text
   */
  image_url: string
}

/**
 * EffectOutput
 */
export type PixverseV35EffectsOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPixverseV35EffectsFile
}

/**
 * File
 */
export type FalAiPixverseV35EffectsFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TransitionRequest
 */
export type PixverseV35TransitionInput = {
  /**
   * Prompt
   *
   * The prompt for the transition
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '8'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * First Image Url
   *
   * URL of the image to use as the first frame
   */
  first_image_url: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * End Image Url
   *
   * URL of the image to use as the last frame
   */
  end_image_url?: string
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * TransitionOutput
 */
export type PixverseV35TransitionOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPixverseV35TransitionFile
}

/**
 * File
 */
export type FalAiPixverseV35TransitionFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Ray2ImageToVideoRequest
 */
export type LumaDreamMachineRay2FlashImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '9:16' | '4:3' | '3:4' | '21:9' | '9:21'
  /**
   * Resolution
   *
   * The resolution of the generated video (720p costs 2x more, 1080p costs 4x more)
   */
  resolution?: '540p' | '720p' | '1080p'
  /**
   * Loop
   *
   * Whether the video should loop (end of video is blended with the beginning)
   */
  loop?: boolean
  /**
   * Duration
   *
   * The duration of the generated video
   */
  duration?: '5s' | '9s'
  /**
   * Image Url
   *
   * Initial image to start the video from. Can be used together with end_image_url.
   */
  image_url?: string
  /**
   * End Image Url
   *
   * Final image to end the video with. Can be used together with image_url.
   */
  end_image_url?: string
}

/**
 * Ray2I2VOutput
 */
export type LumaDreamMachineRay2FlashImageToVideoOutput = {
  /**
   * Video
   *
   * URL of the generated video
   */
  video: FalAiLumaDreamMachineRay2FlashImageToVideoFile
}

/**
 * File
 */
export type FalAiLumaDreamMachineRay2FlashImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * PikaffectsRequest
 *
 * Request model for Pikaffects endpoint
 */
export type PikaV15PikaffectsInput = {
  /**
   * Pikaffect
   *
   * The Pikaffect to apply
   */
  pikaffect:
    | 'Cake-ify'
    | 'Crumble'
    | 'Crush'
    | 'Decapitate'
    | 'Deflate'
    | 'Dissolve'
    | 'Explode'
    | 'Eye-pop'
    | 'Inflate'
    | 'Levitate'
    | 'Melt'
    | 'Peel'
    | 'Poke'
    | 'Squish'
    | 'Ta-da'
    | 'Tear'
  /**
   * Prompt
   *
   * Text prompt to guide the effect
   */
  prompt?: string
  /**
   * Seed
   *
   * The seed for the random number generator
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to guide the model
   */
  negative_prompt?: string
  /**
   * Image Url
   *
   * URL of the input image
   */
  image_url: string
}

/**
 * PikaffectsOutput
 *
 * Output from Pikaffects generation
 */
export type PikaV15PikaffectsOutput = {
  /**
   * Video
   *
   * The generated video with applied effect
   */
  video: FalAiPikaV15PikaffectsFile
}

/**
 * File
 */
export type FalAiPikaV15PikaffectsFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoTurboInput
 *
 * Base request for image-to-video generation
 */
export type PikaV2TurboImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '720p' | '1080p'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: number
  /**
   * Seed
   *
   * The seed for the random number generator
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the model
   */
  negative_prompt?: string
  /**
   * Image Url
   */
  image_url: string
}

/**
 * TurboImageToVideoOutput
 *
 * Output model for all video generation endpoints
 */
export type PikaV2TurboImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPikaV2TurboImageToVideoFile
}

/**
 * File
 */
export type FalAiPikaV2TurboImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Pika22PikascenesRequest
 *
 * Request model for Pika 2.2 Pikascenes (collection-to-video) generation
 */
export type PikaV22PikascenesInput = {
  /**
   * Prompt
   *
   * Text prompt describing the desired video
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1' | '4:5' | '5:4' | '3:2' | '2:3'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: 5 | 10
  /**
   * Ingredients Mode
   *
   * Mode for integrating multiple images. Precise mode is more accurate, creative mode is more creative.
   */
  ingredients_mode?: 'precise' | 'creative'
  /**
   * Seed
   *
   * The seed for the random number generator
   */
  seed?: number
  /**
   * Image Urls
   *
   * URLs of images to combine into a video
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the model
   */
  negative_prompt?: string
}

/**
 * Pika22PikascenesOutput
 *
 * Output model for Pika 2.2 Pikascenes generation
 */
export type PikaV22PikascenesOutput = {
  /**
   * Video
   *
   * The generated video combining multiple images
   */
  video: FalAiPikaV22PikascenesFile
}

/**
 * File
 */
export type FalAiPikaV22PikascenesFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Pika22ImageToVideoRequest
 *
 * Request model for Pika 2.2 image-to-video generation
 */
export type PikaV22ImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '720p' | '1080p'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: 5 | 10
  /**
   * Seed
   *
   * The seed for the random number generator
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the model
   */
  negative_prompt?: string
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * Pika22ImageToVideoOutput
 *
 * Output model for Pika 2.2 image-to-video generation
 */
export type PikaV22ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPikaV22ImageToVideoFile
}

/**
 * File
 */
export type FalAiPikaV22ImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideov21Input
 *
 * Base request for image-to-video generation
 */
export type PikaV21ImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '720p' | '1080p'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: number
  /**
   * Seed
   *
   * The seed for the random number generator
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the model
   */
  negative_prompt?: string
  /**
   * Image Url
   */
  image_url: string
}

/**
 * ImageToVideoV21Output
 *
 * Output from image-to-video generation
 */
export type PikaV21ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPikaV21ImageToVideoFile
}

/**
 * File
 */
export type FalAiPikaV21ImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoRequest
 */
export type ViduImageToVideoInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 1500 characters
   */
  prompt: string
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number
  /**
   * Movement Amplitude
   *
   * The movement amplitude of objects in the frame
   */
  movement_amplitude?: 'auto' | 'small' | 'medium' | 'large'
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * VideoOutput
 */
export type ViduImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiViduImageToVideoFile
}

/**
 * File
 */
export type FalAiViduImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * StartEndToVideoRequest
 */
export type ViduStartEndToVideoInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 1500 characters
   */
  prompt: string
  /**
   * Start Image Url
   *
   * URL of the image to use as the first frame
   */
  start_image_url: string
  /**
   * Movement Amplitude
   *
   * The movement amplitude of objects in the frame
   */
  movement_amplitude?: 'auto' | 'small' | 'medium' | 'large'
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number
  /**
   * End Image Url
   *
   * URL of the image to use as the last frame
   */
  end_image_url: string
}

/**
 * StartEndToVideoOutput
 */
export type ViduStartEndToVideoOutput = {
  /**
   * Video
   *
   * The generated transition video between start and end frames
   */
  video: FalAiViduStartEndToVideoFile
}

/**
 * File
 */
export type FalAiViduStartEndToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ReferenceToVideoRequest
 */
export type ViduReferenceToVideoInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 1500 characters
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the output video
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Reference Image Urls
   *
   * URLs of the reference images to use for consistent subject appearance
   */
  reference_image_urls: Array<string>
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number
  /**
   * Movement Amplitude
   *
   * The movement amplitude of objects in the frame
   */
  movement_amplitude?: 'auto' | 'small' | 'medium' | 'large'
}

/**
 * ReferenceToVideoOutput
 */
export type ViduReferenceToVideoOutput = {
  /**
   * Video
   *
   * The generated video with consistent subjects from reference images
   */
  video: FalAiViduReferenceToVideoFile
}

/**
 * File
 */
export type FalAiViduReferenceToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TemplateToVideoRequest
 */
export type ViduTemplateToVideoInput = {
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the output video
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Template
   *
   * AI video template to use. Pricing varies by template: Standard templates (hug, kiss, love_pose, etc.) cost 4 credits ($0.20), Premium templates (lunar_newyear, dynasty_dress, dreamy_wedding, etc.) cost 6 credits ($0.30), and Advanced templates (live_photo) cost 10 credits ($0.50).
   */
  template?:
    | 'dreamy_wedding'
    | 'romantic_lift'
    | 'sweet_proposal'
    | 'couple_arrival'
    | 'cupid_arrow'
    | 'pet_lovers'
    | 'lunar_newyear'
    | 'hug'
    | 'kiss'
    | 'dynasty_dress'
    | 'wish_sender'
    | 'love_pose'
    | 'hair_swap'
    | 'youth_rewind'
    | 'morphlab'
    | 'live_photo'
    | 'emotionlab'
    | 'live_memory'
    | 'interaction'
    | 'christmas'
    | 'pet_finger'
    | 'eat_mushrooms'
    | 'beast_chase_library'
    | 'beast_chase_supermarket'
    | 'petal_scattered'
    | 'emoji_figure'
    | 'hair_color_change'
    | 'multiple_people_kissing'
    | 'beast_chase_amazon'
    | 'beast_chase_mountain'
    | 'balloonman_explodes_pro'
    | 'get_thinner'
    | 'jump2pool'
    | 'bodyshake'
    | 'jiggle_up'
    | 'shake_it_dance'
    | 'subject_3'
    | 'pubg_winner_hit'
    | 'shake_it_down'
    | 'blueprint_supreme'
    | 'hip_twist'
    | 'motor_dance'
    | 'rat_dance'
    | 'kwok_dance'
    | 'leg_sweep_dance'
    | 'heeseung_march'
    | 'shake_to_max'
    | 'dame_un_grrr'
    | 'i_know'
    | 'lit_bounce'
    | 'wave_dance'
    | 'chill_dance'
    | 'hip_flicking'
    | 'sakura_season'
    | 'zongzi_wrap'
    | 'zongzi_drop'
    | 'dragonboat_shot'
    | 'rain_kiss'
    | 'child_memory'
    | 'couple_drop'
    | 'couple_walk'
    | 'flower_receive'
    | 'love_drop'
    | 'cheek_kiss'
    | 'carry_me'
    | 'blow_kiss'
    | 'love_fall'
    | 'french_kiss_8s'
    | 'workday_feels'
    | 'love_story'
    | 'bloom_magic'
    | 'ghibli'
    | 'minecraft'
    | 'box_me'
    | 'claw_me'
    | 'clayshot'
    | 'manga_meme'
    | 'quad_meme'
    | 'pixel_me'
    | 'clayshot_duo'
    | 'irasutoya'
    | 'american_comic'
    | 'simpsons_comic'
    | 'yayoi_kusama_style'
    | 'pop_art'
    | 'jojo_style'
    | 'slice_therapy'
    | 'balloon_flyaway'
    | 'flying'
    | 'paperman'
    | 'pinch'
    | 'bloom_doorobear'
    | 'gender_swap'
    | 'nap_me'
    | 'sexy_me'
    | 'spin360'
    | 'smooth_shift'
    | 'paper_fall'
    | 'jump_to_cloud'
    | 'pilot'
    | 'sweet_dreams'
    | 'soul_depart'
    | 'punch_hit'
    | 'watermelon_hit'
    | 'split_stance_pet'
    | 'make_face'
    | 'break_glass'
    | 'split_stance_human'
    | 'covered_liquid_metal'
    | 'fluffy_plunge'
    | 'pet_belly_dance'
    | 'water_float'
    | 'relax_cut'
    | 'head_to_balloon'
    | 'cloning'
    | 'across_the_universe_jungle'
    | 'clothes_spinning_remnant'
    | 'across_the_universe_jurassic'
    | 'across_the_universe_moon'
    | 'fisheye_pet'
    | 'hitchcock_zoom'
    | 'cute_bangs'
    | 'earth_zoom_out'
    | 'fisheye_human'
    | 'drive_yacht'
    | 'virtual_singer'
    | 'earth_zoom_in'
    | 'aliens_coming'
    | 'drive_ferrari'
    | 'bjd_style'
    | 'virtual_fitting'
    | 'orbit'
    | 'zoom_in'
    | 'ai_outfit'
    | 'spin180'
    | 'orbit_dolly'
    | 'orbit_dolly_fast'
    | 'auto_spin'
    | 'walk_forward'
    | 'outfit_show'
    | 'zoom_in_fast'
    | 'zoom_out_image'
    | 'zoom_out_startend'
    | 'muscling'
    | 'captain_america'
    | 'hulk'
    | 'cap_walk'
    | 'hulk_dive'
    | 'exotic_princess'
    | 'beast_companion'
    | 'cartoon_doll'
    | 'golden_epoch'
    | 'oscar_gala'
    | 'fashion_stride'
    | 'star_carpet'
    | 'flame_carpet'
    | 'frost_carpet'
    | 'mecha_x'
    | 'style_me'
    | 'tap_me'
    | 'saber_warrior'
    | 'pet2human'
    | 'graduation'
    | 'fishermen'
    | 'happy_birthday'
    | 'fairy_me'
    | 'ladudu_me'
    | 'ladudu_me_random'
    | 'squid_game'
    | 'superman'
    | 'grow_wings'
    | 'clevage'
    | 'fly_with_doraemon'
    | 'creatice_product_down'
    | 'pole_dance'
    | 'hug_from_behind'
    | 'creatice_product_up_cybercity'
    | 'creatice_product_up_bluecircuit'
    | 'creatice_product_up'
    | 'run_fast'
    | 'background_explosion'
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number
  /**
   * Input Image Urls
   *
   * URLs of the images to use with the template. Number of images required varies by template: 'dynasty_dress' and 'shop_frame' accept 1-2 images, 'wish_sender' requires exactly 3 images, all other templates accept only 1 image.
   */
  input_image_urls: Array<string>
}

/**
 * TemplateToVideoOutput
 */
export type ViduTemplateToVideoOutput = {
  /**
   * Video
   *
   * The generated video using a predefined template
   */
  video: FalAiViduTemplateToVideoFile
}

/**
 * File
 */
export type FalAiViduTemplateToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * WanLoRAI2VRequest
 */
export type WanI2vLoraInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Shift
   *
   * Shift parameter for video generation.
   */
  shift?: number
  /**
   * Reverse Video
   *
   * If true, the video will be reversed.
   */
  reverse_video?: boolean
  /**
   * Loras
   *
   * LoRA weights to be used in the inference.
   */
  loras?: Array<LoraWeight>
  /**
   * Frames Per Second
   *
   * Frames per second of the generated video. Must be between 5 to 24.
   */
  frames_per_second?: number
  /**
   * Turbo Mode
   *
   * If true, the video will be generated faster with no noticeable degradation in the visual quality.
   */
  turbo_mode?: boolean
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Frames
   *
   * Number of frames to generate. Must be between 81 to 100 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.
   */
  num_frames?: number
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the output video.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16' | '1:1'
  /**
   * Resolution
   *
   * Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.
   */
  resolution?: '480p' | '720p'
  /**
   * Image Url
   *
   * URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Guide Scale
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guide_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
}

/**
 * LoraWeight
 */
export type LoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
  /**
   * Weight Name
   *
   * Name of the LoRA weight. Used only if `path` is a Hugging Face repository, and required only if you have more than 1 safetensors file in the repo.
   */
  weight_name?: string
}

/**
 * WanI2VResponse
 */
export type WanI2vLoraOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiWanI2vLoraFile
}

/**
 * File
 */
export type FalAiWanI2vLoraFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * HunyuanVideoRequest
 */
export type HunyuanVideoImageToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Aspect Ratio (W:H)
   *
   * The aspect ratio of the video to generate.
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the video to generate.
   */
  resolution?: '720p'
  /**
   * Image Url
   *
   * URL of the image input.
   */
  image_url: string
  /**
   * Seed
   *
   * The seed to use for generating the video.
   */
  seed?: number
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: '129'
  /**
   * I2V Stability
   *
   * Turning on I2V Stability reduces hallucination but also reduces motion.
   */
  i2v_stability?: boolean
}

/**
 * HunyuanI2VResponse
 */
export type HunyuanVideoImageToVideoOutput = {
  /**
   * Seed
   *
   * The seed used for generating the video.
   */
  seed: number
  video: FalAiHunyuanVideoImageToVideoFile
}

/**
 * File
 */
export type FalAiHunyuanVideoImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoDirectorRequest
 */
export type MinimaxVideo01DirectorImageToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Prompt
   *
   * Text prompt for video generation. Camera movement instructions can be added using square brackets (e.g. [Pan left] or [Zoom in]). You can use up to 3 combined movements per prompt. Supported movements: Truck left/right, Pan left/right, Push in/Pull out, Pedestal up/down, Tilt up/down, Zoom in/out, Shake, Tracking shot, Static shot. For example: [Truck left, Pan right, Zoom in]. For a more detailed guide, refer https://sixth-switch-2ac.notion.site/T2V-01-Director-Model-Tutorial-with-camera-movement-1886c20a98eb80f395b8e05291ad8645
   */
  prompt: string
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * I2VDirectorOutput
 */
export type MinimaxVideo01DirectorImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiMinimaxVideo01DirectorImageToVideoFile
}

/**
 * File
 */
export type FalAiMinimaxVideo01DirectorImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * SkyreelsI2VRequest
 */
export type SkyreelsI2vInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the output video
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Image Url
   *
   * URL of the image input.
   */
  image_url: string
  /**
   * Guidance Scale
   *
   * Guidance scale for generation (between 1.0 and 20.0)
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for generation. If not provided, a random seed will be used.
   */
  seed?: number
  /**
   * Num Inference Steps
   *
   * Number of denoising steps (between 1 and 50). Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to guide generation away from certain attributes.
   */
  negative_prompt?: string
}

/**
 * SkyreelsI2VResponse
 */
export type SkyreelsI2vOutput = {
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
  /**
   * Video
   */
  video: FalAiSkyreelsI2vFile
}

/**
 * File
 */
export type FalAiSkyreelsI2vFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Ray2ImageToVideoRequest
 */
export type LumaDreamMachineRay2ImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '9:16' | '4:3' | '3:4' | '21:9' | '9:21'
  /**
   * Resolution
   *
   * The resolution of the generated video (720p costs 2x more, 1080p costs 4x more)
   */
  resolution?: '540p' | '720p' | '1080p'
  /**
   * Loop
   *
   * Whether the video should loop (end of video is blended with the beginning)
   */
  loop?: boolean
  /**
   * Duration
   *
   * The duration of the generated video
   */
  duration?: '5s' | '9s'
  /**
   * Image Url
   *
   * Initial image to start the video from. Can be used together with end_image_url.
   */
  image_url?: string
  /**
   * End Image Url
   *
   * Final image to end the video with. Can be used together with image_url.
   */
  end_image_url?: string
}

/**
 * Ray2I2VOutput
 */
export type LumaDreamMachineRay2ImageToVideoOutput = {
  /**
   * Video
   *
   * URL of the generated video
   */
  video: FalAiLumaDreamMachineRay2ImageToVideoFile
}

/**
 * File
 */
export type FalAiLumaDreamMachineRay2ImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Input
 */
export type HunyuanVideoImg2VidLoraInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed to use for generating the video.
   */
  seed?: number
  /**
   * Image URL
   *
   * The URL to the image to generate the video from. The image must be 960x544 or it will get cropped and resized to that size.
   */
  image_url: string
}

/**
 * Output
 */
export type HunyuanVideoImg2VidLoraOutput = {
  /**
   * Seed
   *
   * The seed used for generating the video.
   */
  seed: number
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiHunyuanVideoImg2VidLoraFile
}

/**
 * File
 */
export type FalAiHunyuanVideoImg2VidLoraFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * FastImageToVideoRequest
 */
export type PixverseV35ImageToVideoFastInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * I2VOutput
 */
export type PixverseV35ImageToVideoFastOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPixverseV35ImageToVideoFastFile
}

/**
 * File
 */
export type FalAiPixverseV35ImageToVideoFastFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoRequest
 */
export type PixverseV35ImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds
   */
  duration?: '5' | '8'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * I2VOutput
 */
export type PixverseV35ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPixverseV35ImageToVideoFile
}

/**
 * File
 */
export type FalAiPixverseV35ImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * SubjectReferenceRequest
 */
export type MinimaxVideo01SubjectReferenceInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Prompt
   */
  prompt: string
  /**
   * Subject Reference Image Url
   *
   * URL of the subject reference image to use for consistent subject appearance
   */
  subject_reference_image_url: string
}

/**
 * SubjectReferenceOutput
 */
export type MinimaxVideo01SubjectReferenceOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiMinimaxVideo01SubjectReferenceFile
}

/**
 * File
 */
export type FalAiMinimaxVideo01SubjectReferenceFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoRequest
 */
export type KlingVideoV16StandardImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Image Url
   */
  image_url: string
}

/**
 * I2VOutput
 */
export type KlingVideoV16StandardImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV16StandardImageToVideoFile
}

/**
 * File
 */
export type FalAiKlingVideoV16StandardImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * SadTalkerRefVideoInput
 */
export type SadtalkerReferenceInput = {
  /**
   * Pose Style
   *
   * The style of the pose
   */
  pose_style?: number
  /**
   * Source Image Url
   *
   * URL of the source image
   */
  source_image_url: string
  /**
   * Reference Pose Video Url
   *
   * URL of the reference video
   */
  reference_pose_video_url: string
  /**
   * Driven Audio Url
   *
   * URL of the driven audio
   */
  driven_audio_url: string
  /**
   * Face Enhancer
   *
   * The type of face enhancer to use
   */
  face_enhancer?: 'gfpgan'
  /**
   * Expression Scale
   *
   * The scale of the expression
   */
  expression_scale?: number
  /**
   * Face Model Resolution
   *
   * The resolution of the face model
   */
  face_model_resolution?: '256' | '512'
  /**
   * Still Mode
   *
   * Whether to use still mode. Fewer head motion, works with preprocess `full`.
   */
  still_mode?: boolean
  /**
   * Preprocess
   *
   * The type of preprocessing to use
   */
  preprocess?: 'crop' | 'extcrop' | 'resize' | 'full' | 'extfull'
}

/**
 * SadTalkerOutput
 */
export type SadtalkerReferenceOutput = {
  /**
   * Video
   *
   * URL of the generated video
   */
  video: FalAiSadtalkerReferenceFile
}

/**
 * File
 */
export type FalAiSadtalkerReferenceFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoRequest
 */
export type MinimaxVideo01LiveImageToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Prompt
   */
  prompt: string
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * I2VLiveOutput
 */
export type MinimaxVideo01LiveImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiMinimaxVideo01LiveImageToVideoFile
}

/**
 * File
 */
export type FalAiMinimaxVideo01LiveImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoInput
 */
export type LtxVideoImageToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Guidance Scale
   *
   * The guidance scale to use.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * The seed to use for random number generation.
   */
  seed?: number
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to take.
   */
  num_inference_steps?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to generate the video from.
   */
  negative_prompt?: string
  /**
   * Image URL
   *
   * The URL of the image to generate the video from.
   */
  image_url: string
}

/**
 * Output
 */
export type LtxVideoImageToVideoOutput = {
  /**
   * Seed
   *
   * The seed used for random number generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video.
   */
  video: FalAiLtxVideoImageToVideoFile
}

/**
 * File
 */
export type FalAiLtxVideoImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoInput
 */
export type Cogvideox5bImageToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Use Rife
   *
   * Use RIFE for video interpolation
   */
  use_rife?: boolean
  /**
   * Image URL
   *
   * The URL to the image to generate the video from.
   */
  image_url: string
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. We currently support one lora.
   *
   */
  loras?: Array<FalAiCogvideox5bImageToVideoLoraWeight>
  /**
   * Video Size
   *
   * The size of the generated video.
   */
  video_size?:
    | FalAiCogvideox5bImageToVideoImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related video to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Export Fps
   *
   * The target FPS of the video
   */
  export_fps?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to generate video from
   */
  negative_prompt?: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
}

/**
 * LoraWeight
 */
export type FalAiCogvideox5bImageToVideoLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
}

/**
 * ImageSize
 */
export type FalAiCogvideox5bImageToVideoImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Output
 */
export type Cogvideox5bImageToVideoOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the video.
   */
  prompt: string
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Seed
   *
   *
   * Seed of the generated video. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
  /**
   * Video
   *
   * The URL to the generated video
   */
  video: FalAiCogvideox5bImageToVideoFile
}

/**
 * File
 */
export type FalAiCogvideox5bImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * KlingV15ProImageToVideoRequest
 */
export type KlingVideoV15ProImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video frame
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Image Url
   */
  image_url: string
  /**
   * Static Mask Url
   *
   * URL of the image for Static Brush Application Area (Mask image created by users using the motion brush)
   */
  static_mask_url?: string
  /**
   * Dynamic Masks
   *
   * List of dynamic masks
   */
  dynamic_masks?: Array<DynamicMask>
  /**
   * Tail Image Url
   *
   * URL of the image to be used for the end of the video
   */
  tail_image_url?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * DynamicMask
 */
export type DynamicMask = {
  /**
   * Trajectories
   *
   * List of trajectories
   */
  trajectories?: Array<Trajectory>
  /**
   * Mask Url
   *
   * URL of the image for Dynamic Brush Application Area (Mask image created by users using the motion brush)
   */
  mask_url: string
}

/**
 * Trajectory
 */
export type Trajectory = {
  /**
   * Y
   *
   * Y coordinate of the motion trajectory
   */
  y: number
  /**
   * X
   *
   * X coordinate of the motion trajectory
   */
  x: number
}

/**
 * I2VOutput
 */
export type KlingVideoV15ProImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV15ProImageToVideoFile
}

/**
 * File
 */
export type FalAiKlingVideoV15ProImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * V1ImageToVideoRequest
 */
export type KlingVideoV1StandardImageToVideoInput = {
  /**
   * Prompt
   *
   * The prompt for the video
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Image Url
   *
   * URL of the image to be used for the video
   */
  image_url: string
  /**
   * Static Mask Url
   *
   * URL of the image for Static Brush Application Area (Mask image created by users using the motion brush)
   */
  static_mask_url?: string
  /**
   * Dynamic Masks
   *
   * List of dynamic masks
   */
  dynamic_masks?: Array<FalAiKlingVideoV1StandardImageToVideoDynamicMask>
  /**
   * Tail Image Url
   *
   * URL of the image to be used for the end of the video
   */
  tail_image_url?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * DynamicMask
 */
export type FalAiKlingVideoV1StandardImageToVideoDynamicMask = {
  /**
   * Trajectories
   *
   * List of trajectories
   */
  trajectories?: Array<FalAiKlingVideoV1StandardImageToVideoTrajectory>
  /**
   * Mask Url
   *
   * URL of the image for Dynamic Brush Application Area (Mask image created by users using the motion brush)
   */
  mask_url: string
}

/**
 * Trajectory
 */
export type FalAiKlingVideoV1StandardImageToVideoTrajectory = {
  /**
   * Y
   *
   * Y coordinate of the motion trajectory
   */
  y: number
  /**
   * X
   *
   * X coordinate of the motion trajectory
   */
  x: number
}

/**
 * KlingV1I2VOutput
 */
export type KlingVideoV1StandardImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV1StandardImageToVideoFile
}

/**
 * File
 */
export type FalAiKlingVideoV1StandardImageToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageInput
 */
export type StableVideoInput = {
  /**
   * Motion Bucket Id
   *
   *
   * The motion bucket id determines the motion of the generated video. The
   * higher the number, the more motion there will be.
   *
   */
  motion_bucket_id?: number
  /**
   * Fps
   *
   * The frames per second of the generated video.
   */
  fps?: number
  /**
   * Cond Aug
   *
   *
   * The conditoning augmentation determines the amount of noise that will be
   * added to the conditioning frame. The higher the number, the more noise
   * there will be, and the less the video will look like the initial image.
   * Increase it for more motion.
   *
   */
  cond_aug?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string
}

/**
 * VideoOutput
 */
export type StableVideoOutput = {
  /**
   * Seed
   *
   * Seed for random number generator
   */
  seed: number
  /**
   * Video
   *
   * Generated video
   */
  video: FalAiStableVideoFile
}

/**
 * File
 */
export type FalAiStableVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * AMTFrameInterpolationInput
 */
export type AmtInterpolationFrameInterpolationInput = {
  /**
   * Frames
   *
   * Frames to interpolate
   */
  frames: Array<Frame>
  /**
   * Recursive Interpolation Passes
   *
   * Number of recursive interpolation passes
   */
  recursive_interpolation_passes?: number
  /**
   * Output FPS
   *
   * Output frames per second
   */
  output_fps?: number
}

/**
 * Frame
 */
export type Frame = {
  /**
   * URL
   *
   * URL of the frame
   */
  url: string
}

/**
 * AMTInterpolationOutput
 */
export type AmtInterpolationFrameInterpolationOutput = {
  /**
   * Video
   *
   * Generated video
   */
  video: FalAiAmtInterpolationFrameInterpolationFile
}

/**
 * File
 */
export type FalAiAmtInterpolationFrameInterpolationFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * LivePortraitInput
 */
export type LivePortraitInput = {
  /**
   * Smile
   *
   * Amount to smile
   */
  smile?: number
  /**
   * Video Url
   *
   * URL of the video to drive the lip syncing.
   */
  video_url: string
  /**
   * Eyebrow
   *
   * Amount to raise or lower eyebrows
   */
  eyebrow?: number
  /**
   * Flag Stitching
   *
   * Whether to enable stitching. Recommended to set to True.
   */
  flag_stitching?: boolean
  /**
   * Wink
   *
   * Amount to wink
   */
  wink?: number
  /**
   * Rotate Pitch
   *
   * Amount to rotate the face in pitch
   */
  rotate_pitch?: number
  /**
   * Blink
   *
   * Amount to blink the eyes
   */
  blink?: number
  /**
   * Scale
   *
   * Scaling factor for the face crop.
   */
  scale?: number
  /**
   * Eee
   *
   * Amount to shape mouth in 'eee' position
   */
  eee?: number
  /**
   * Flag Pasteback
   *
   * Whether to paste-back/stitch the animated face cropping from the face-cropping space to the original image space.
   */
  flag_pasteback?: boolean
  /**
   * Pupil Y
   *
   * Amount to move pupils vertically
   */
  pupil_y?: number
  /**
   * Rotate Yaw
   *
   * Amount to rotate the face in yaw
   */
  rotate_yaw?: number
  /**
   * Flag Do Rot
   *
   * Whether to conduct the rotation when flag_do_crop is True.
   */
  flag_do_rot?: boolean
  /**
   * Woo
   *
   * Amount to shape mouth in 'woo' position
   */
  woo?: number
  /**
   * Aaa
   *
   * Amount to open mouth in 'aaa' shape
   */
  aaa?: number
  /**
   * Image Url
   *
   * URL of the image to be animated
   */
  image_url: string
  /**
   * Flag Relative
   *
   * Whether to use relative motion.
   */
  flag_relative?: boolean
  /**
   * Flag Eye Retargeting
   *
   * Whether to enable eye retargeting.
   */
  flag_eye_retargeting?: boolean
  /**
   * Flag Lip Zero
   *
   * Whether to set the lip to closed state before animation. Only takes effect when flag_eye_retargeting and flag_lip_retargeting are False.
   */
  flag_lip_zero?: boolean
  /**
   * Batch Size
   *
   * Batch size for the model. The larger the batch size, the faster the model will run, but the more memory it will consume.
   */
  batch_size?: number
  /**
   * Rotate Roll
   *
   * Amount to rotate the face in roll
   */
  rotate_roll?: number
  /**
   * Pupil X
   *
   * Amount to move pupils horizontally
   */
  pupil_x?: number
  /**
   * Vy Ratio
   *
   * Vertical offset ratio for face crop. Positive values move up, negative values move down.
   */
  vy_ratio?: number
  /**
   * Dsize
   *
   * Size of the output image.
   */
  dsize?: number
  /**
   * Enable Safety Checker
   *
   *
   * Whether to enable the safety checker. If enabled, the model will check if the input image contains a face before processing it.
   * The safety checker will process the input image
   *
   */
  enable_safety_checker?: boolean
  /**
   * Vx Ratio
   *
   * Horizontal offset ratio for face crop.
   */
  vx_ratio?: number
  /**
   * Flag Lip Retargeting
   *
   * Whether to enable lip retargeting.
   */
  flag_lip_retargeting?: boolean
  /**
   * Flag Do Crop
   *
   * Whether to crop the source portrait to the face-cropping space.
   */
  flag_do_crop?: boolean
}

/**
 * LivePortraitOutput
 */
export type LivePortraitOutput = {
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiLivePortraitFile
}

/**
 * File
 */
export type FalAiLivePortraitFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * MuseTalkInput
 */
export type MusetalkInput = {
  /**
   * Source Video Url
   *
   * URL of the source video
   */
  source_video_url: string
  /**
   * Audio Url
   *
   * URL of the audio
   */
  audio_url: string
}

/**
 * MuseTalkOutput
 */
export type MusetalkOutput = {
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiMusetalkFile
}

/**
 * File
 */
export type FalAiMusetalkFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * SadTalkerInput
 */
export type SadtalkerInput = {
  /**
   * Pose Style
   *
   * The style of the pose
   */
  pose_style?: number
  /**
   * Source Image Url
   *
   * URL of the source image
   */
  source_image_url: string
  /**
   * Driven Audio Url
   *
   * URL of the driven audio
   */
  driven_audio_url: string
  /**
   * Face Enhancer
   *
   * The type of face enhancer to use
   */
  face_enhancer?: 'gfpgan'
  /**
   * Expression Scale
   *
   * The scale of the expression
   */
  expression_scale?: number
  /**
   * Face Model Resolution
   *
   * The resolution of the face model
   */
  face_model_resolution?: '256' | '512'
  /**
   * Still Mode
   *
   * Whether to use still mode. Fewer head motion, works with preprocess `full`.
   */
  still_mode?: boolean
  /**
   * Preprocess
   *
   * The type of preprocessing to use
   */
  preprocess?: 'crop' | 'extcrop' | 'resize' | 'full' | 'extfull'
}

/**
 * SadTalkerOutput
 */
export type SadtalkerOutput = {
  /**
   * Video
   *
   * URL of the generated video
   */
  video: FalAiSadtalkerFile
}

/**
 * File
 */
export type FalAiSadtalkerFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * FastSVDImageInput
 */
export type FastSvdLcmInput = {
  /**
   * Motion Bucket Id
   *
   *
   * The motion bucket id determines the motion of the generated video. The
   * higher the number, the more motion there will be.
   *
   */
  motion_bucket_id?: number
  /**
   * Fps
   *
   *
   * The FPS of the generated video. The higher the number, the faster the video will
   * play. Total video length is 25 frames.
   *
   */
  fps?: number
  /**
   * Steps
   *
   *
   * The number of steps to run the model for. The higher the number the better
   * the quality and longer it will take to generate.
   *
   */
  steps?: number
  /**
   * Cond Aug
   *
   *
   * The conditoning augmentation determines the amount of noise that will be
   * added to the conditioning frame. The higher the number, the more noise
   * there will be, and the less the video will look like the initial image.
   * Increase it for more motion.
   *
   */
  cond_aug?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string
}

/**
 * FastSVDOutput
 */
export type FastSvdLcmOutput = {
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   *
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiFastSvdLcmFile
}

/**
 * File
 */
export type FalAiFastSvdLcmFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}
