// This file is auto-generated by @hey-api/openapi-ts

import { z } from 'zod'

/**
 * File
 */
export const zSchemaFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * FastSVDOutput
 */
export const zSchemaFastSvdLcmOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n\n        ',
  }),
  video: zSchemaFile,
})

/**
 * FastSVDImageInput
 */
export const zSchemaFastSvdLcmInput = z.object({
  motion_bucket_id: z
    .optional(
      z.int().gte(1).lte(255).register(z.globalRegistry, {
        description:
          '\n            The motion bucket id determines the motion of the generated video. The\n            higher the number, the more motion there will be.\n        ',
      }),
    )
    .default(127),
  fps: z
    .optional(
      z.int().gte(1).lte(25).register(z.globalRegistry, {
        description:
          '\n            The FPS of the generated video. The higher the number, the faster the video will\n            play. Total video length is 25 frames.\n        ',
      }),
    )
    .default(10),
  steps: z
    .optional(
      z.int().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n            The number of steps to run the model for. The higher the number the better\n            the quality and longer it will take to generate.\n        ',
      }),
    )
    .default(4),
  cond_aug: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description:
          '\n            The conditoning augmentation determines the amount of noise that will be\n            added to the conditioning frame. The higher the number, the more noise\n            there will be, and the less the video will look like the initial image.\n            Increase it for more motion.\n        ',
      }),
    )
    .default(0.02),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the image to use as a starting point for the generation.',
  }),
})

/**
 * SadTalkerOutput
 */
export const zSchemaSadtalkerOutput = z.object({
  video: zSchemaFile,
})

/**
 * SadTalkerInput
 */
export const zSchemaSadtalkerInput = z.object({
  pose_style: z
    .optional(
      z.int().gte(0).lte(45).register(z.globalRegistry, {
        description: 'The style of the pose',
      }),
    )
    .default(0),
  source_image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the source image',
  }),
  driven_audio_url: z.string().register(z.globalRegistry, {
    description: 'URL of the driven audio',
  }),
  face_enhancer: z.optional(
    z.enum(['gfpgan']).register(z.globalRegistry, {
      description: 'The type of face enhancer to use',
    }),
  ),
  expression_scale: z
    .optional(
      z.number().gte(0).lte(3).register(z.globalRegistry, {
        description: 'The scale of the expression',
      }),
    )
    .default(1),
  face_model_resolution: z.optional(
    z.enum(['256', '512']).register(z.globalRegistry, {
      description: 'The resolution of the face model',
    }),
  ),
  still_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use still mode. Fewer head motion, works with preprocess `full`.',
      }),
    )
    .default(false),
  preprocess: z.optional(
    z
      .enum(['crop', 'extcrop', 'resize', 'full', 'extfull'])
      .register(z.globalRegistry, {
        description: 'The type of preprocessing to use',
      }),
  ),
})

/**
 * MuseTalkOutput
 */
export const zSchemaMusetalkOutput = z.object({
  video: zSchemaFile,
})

/**
 * MuseTalkInput
 */
export const zSchemaMusetalkInput = z.object({
  source_video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the source video',
  }),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'URL of the audio',
  }),
})

/**
 * LivePortraitOutput
 */
export const zSchemaLivePortraitOutput = z.object({
  video: zSchemaFile,
})

/**
 * LivePortraitInput
 */
export const zSchemaLivePortraitInput = z.object({
  smile: z
    .optional(
      z.number().gte(-2).lte(2).register(z.globalRegistry, {
        description: 'Amount to smile',
      }),
    )
    .default(0),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the video to drive the lip syncing.',
  }),
  eyebrow: z
    .optional(
      z.number().gte(-30).lte(30).register(z.globalRegistry, {
        description: 'Amount to raise or lower eyebrows',
      }),
    )
    .default(0),
  flag_stitching: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable stitching. Recommended to set to True.',
      }),
    )
    .default(true),
  wink: z
    .optional(
      z.number().gte(0).lte(25).register(z.globalRegistry, {
        description: 'Amount to wink',
      }),
    )
    .default(0),
  rotate_pitch: z
    .optional(
      z.number().gte(-45).lte(45).register(z.globalRegistry, {
        description: 'Amount to rotate the face in pitch',
      }),
    )
    .default(0),
  blink: z
    .optional(
      z.number().gte(-30).lte(30).register(z.globalRegistry, {
        description: 'Amount to blink the eyes',
      }),
    )
    .default(0),
  scale: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: 'Scaling factor for the face crop.',
      }),
    )
    .default(2.3),
  eee: z
    .optional(
      z.number().gte(-40).lte(40).register(z.globalRegistry, {
        description: "Amount to shape mouth in 'eee' position",
      }),
    )
    .default(0),
  flag_pasteback: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to paste-back/stitch the animated face cropping from the face-cropping space to the original image space.',
      }),
    )
    .default(true),
  pupil_y: z
    .optional(
      z.number().gte(-45).lte(45).register(z.globalRegistry, {
        description: 'Amount to move pupils vertically',
      }),
    )
    .default(0),
  rotate_yaw: z
    .optional(
      z.number().gte(-45).lte(45).register(z.globalRegistry, {
        description: 'Amount to rotate the face in yaw',
      }),
    )
    .default(0),
  flag_do_rot: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to conduct the rotation when flag_do_crop is True.',
      }),
    )
    .default(true),
  woo: z
    .optional(
      z.number().gte(-100).lte(100).register(z.globalRegistry, {
        description: "Amount to shape mouth in 'woo' position",
      }),
    )
    .default(0),
  aaa: z
    .optional(
      z.number().gte(-200).lte(200).register(z.globalRegistry, {
        description: "Amount to open mouth in 'aaa' shape",
      }),
    )
    .default(0),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to be animated',
  }),
  flag_relative: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to use relative motion.',
      }),
    )
    .default(true),
  flag_eye_retargeting: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable eye retargeting.',
      }),
    )
    .default(false),
  flag_lip_zero: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to set the lip to closed state before animation. Only takes effect when flag_eye_retargeting and flag_lip_retargeting are False.',
      }),
    )
    .default(true),
  batch_size: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          'Batch size for the model. The larger the batch size, the faster the model will run, but the more memory it will consume.',
      }),
    )
    .default(32),
  rotate_roll: z
    .optional(
      z.number().gte(-45).lte(45).register(z.globalRegistry, {
        description: 'Amount to rotate the face in roll',
      }),
    )
    .default(0),
  pupil_x: z
    .optional(
      z.number().gte(-45).lte(45).register(z.globalRegistry, {
        description: 'Amount to move pupils horizontally',
      }),
    )
    .default(0),
  vy_ratio: z
    .optional(
      z.number().register(z.globalRegistry, {
        description:
          'Vertical offset ratio for face crop. Positive values move up, negative values move down.',
      }),
    )
    .default(-0.125),
  dsize: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Size of the output image.',
      }),
    )
    .default(512),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n        Whether to enable the safety checker. If enabled, the model will check if the input image contains a face before processing it.\n        The safety checker will process the input image\n        ',
      }),
    )
    .default(false),
  vx_ratio: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: 'Horizontal offset ratio for face crop.',
      }),
    )
    .default(0),
  flag_lip_retargeting: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable lip retargeting.',
      }),
    )
    .default(false),
  flag_do_crop: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to crop the source portrait to the face-cropping space.',
      }),
    )
    .default(true),
})

/**
 * Frame
 */
export const zSchemaFrame = z.object({
  url: z.string().register(z.globalRegistry, {
    description: 'URL of the frame',
  }),
})

/**
 * AMTInterpolationOutput
 */
export const zSchemaAmtInterpolationFrameInterpolationOutput = z.object({
  video: zSchemaFile,
})

/**
 * AMTFrameInterpolationInput
 */
export const zSchemaAmtInterpolationFrameInterpolationInput = z.object({
  frames: z.array(zSchemaFrame).register(z.globalRegistry, {
    description: 'Frames to interpolate',
  }),
  recursive_interpolation_passes: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Number of recursive interpolation passes',
      }),
    )
    .default(4),
  output_fps: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Output frames per second',
      }),
    )
    .default(24),
})

/**
 * VideoOutput
 */
export const zSchemaStableVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed for random number generator',
  }),
  video: zSchemaFile,
})

/**
 * ImageInput
 */
export const zSchemaStableVideoInput = z.object({
  motion_bucket_id: z
    .optional(
      z.int().gte(1).lte(255).register(z.globalRegistry, {
        description:
          '\n            The motion bucket id determines the motion of the generated video. The\n            higher the number, the more motion there will be.\n        ',
      }),
    )
    .default(127),
  fps: z
    .optional(
      z.int().gte(10).lte(100).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  cond_aug: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description:
          '\n            The conditoning augmentation determines the amount of noise that will be\n            added to the conditioning frame. The higher the number, the more noise\n            there will be, and the less the video will look like the initial image.\n            Increase it for more motion.\n        ',
      }),
    )
    .default(0.02),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  image_url: z.string().min(1).register(z.globalRegistry, {
    description:
      'The URL of the image to use as a starting point for the generation.',
  }),
})

/**
 * KlingV1I2VOutput
 */
export const zSchemaKlingVideoV1StandardImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Trajectory
 */
export const zSchemaTrajectory = z.object({
  y: z.int().register(z.globalRegistry, {
    description: 'Y coordinate of the motion trajectory',
  }),
  x: z.int().register(z.globalRegistry, {
    description: 'X coordinate of the motion trajectory',
  }),
})

/**
 * DynamicMask
 */
export const zSchemaDynamicMask = z.object({
  trajectories: z.optional(
    z.array(zSchemaTrajectory).register(z.globalRegistry, {
      description: 'List of trajectories',
    }),
  ),
  mask_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the image for Dynamic Brush Application Area (Mask image created by users using the motion brush)',
  }),
})

/**
 * V1ImageToVideoRequest
 */
export const zSchemaKlingVideoV1StandardImageToVideoInput = z.object({
  prompt: z.string().max(2500).register(z.globalRegistry, {
    description: 'The prompt for the video',
  }),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to be used for the video',
  }),
  static_mask_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'URL of the image for Static Brush Application Area (Mask image created by users using the motion brush)',
    }),
  ),
  dynamic_masks: z.optional(
    z.array(zSchemaDynamicMask).register(z.globalRegistry, {
      description: 'List of dynamic masks',
    }),
  ),
  tail_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'URL of the image to be used for the end of the video',
    }),
  ),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * I2VOutput
 */
export const zSchemaKlingVideoV15ProImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * KlingV15ProImageToVideoRequest
 */
export const zSchemaKlingVideoV15ProImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video frame',
    }),
  ),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  image_url: z.string(),
  static_mask_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'URL of the image for Static Brush Application Area (Mask image created by users using the motion brush)',
    }),
  ),
  dynamic_masks: z.optional(
    z.array(zSchemaDynamicMask).register(z.globalRegistry, {
      description: 'List of dynamic masks',
    }),
  ),
  tail_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'URL of the image to be used for the end of the video',
    }),
  ),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * Output
 */
export const zSchemaCogvideox5bImageToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the video.',
  }),
  timings: z.record(z.string(), z.number()),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated video. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  video: zSchemaFile,
})

/**
 * ImageSize
 */
export const zSchemaImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zSchemaLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * ImageToVideoInput
 */
export const zSchemaCogvideox5bImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  use_rife: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Use RIFE for video interpolation',
      }),
    )
    .default(true),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL to the image to generate the video from.',
  }),
  loras: z
    .optional(
      z.array(zSchemaLoraWeight).register(z.globalRegistry, {
        description:
          '\n            The LoRAs to use for the image generation. We currently support one lora.\n        ',
      }),
    )
    .default([]),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related video to show you.\n        ',
      }),
    )
    .default(7),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(50),
  export_fps: z
    .optional(
      z.int().gte(4).lte(32).register(z.globalRegistry, {
        description: 'The target FPS of the video',
      }),
    )
    .default(16),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate video from',
      }),
    )
    .default(''),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
})

/**
 * Output
 */
export const zSchemaLtxVideoImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for random number generation.',
  }),
  video: zSchemaFile,
})

/**
 * ImageToVideoInput
 */
export const zSchemaLtxVideoImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  guidance_scale: z
    .optional(
      z.number().lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use.',
      }),
    )
    .default(3),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for random number generation.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to take.',
      }),
    )
    .default(30),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'low quality, worst quality, deformed, distorted, disfigured, motion smear, motion artifacts, fused fingers, bad anatomy, weird hand, ugly',
    ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to generate the video from.',
  }),
})

/**
 * I2VLiveOutput
 */
export const zSchemaMinimaxVideo01LiveImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoRequest
 */
export const zSchemaMinimaxVideo01LiveImageToVideoInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  prompt: z.string().max(2000),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
})

/**
 * SadTalkerOutput
 */
export const zSchemaSadtalkerReferenceOutput = z.object({
  video: zSchemaFile,
})

/**
 * SadTalkerRefVideoInput
 */
export const zSchemaSadtalkerReferenceInput = z.object({
  pose_style: z
    .optional(
      z.int().gte(0).lte(45).register(z.globalRegistry, {
        description: 'The style of the pose',
      }),
    )
    .default(0),
  source_image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the source image',
  }),
  reference_pose_video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the reference video',
  }),
  driven_audio_url: z.string().register(z.globalRegistry, {
    description: 'URL of the driven audio',
  }),
  face_enhancer: z.optional(
    z.enum(['gfpgan']).register(z.globalRegistry, {
      description: 'The type of face enhancer to use',
    }),
  ),
  expression_scale: z
    .optional(
      z.number().gte(0).lte(3).register(z.globalRegistry, {
        description: 'The scale of the expression',
      }),
    )
    .default(1),
  face_model_resolution: z.optional(
    z.enum(['256', '512']).register(z.globalRegistry, {
      description: 'The resolution of the face model',
    }),
  ),
  still_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use still mode. Fewer head motion, works with preprocess `full`.',
      }),
    )
    .default(false),
  preprocess: z.optional(
    z
      .enum(['crop', 'extcrop', 'resize', 'full', 'extfull'])
      .register(z.globalRegistry, {
        description: 'The type of preprocessing to use',
      }),
  ),
})

/**
 * I2VOutput
 */
export const zSchemaKlingVideoV16StandardImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoRequest
 */
export const zSchemaKlingVideoV16StandardImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  image_url: z.string(),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * SubjectReferenceOutput
 */
export const zSchemaMinimaxVideo01SubjectReferenceOutput = z.object({
  video: zSchemaFile,
})

/**
 * SubjectReferenceRequest
 */
export const zSchemaMinimaxVideo01SubjectReferenceInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  prompt: z.string().max(2000),
  subject_reference_image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the subject reference image to use for consistent subject appearance',
  }),
})

/**
 * I2VOutput
 */
export const zSchemaPixverseV35ImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoRequest
 */
export const zSchemaPixverseV35ImageToVideoInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description:
        'The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * I2VOutput
 */
export const zSchemaPixverseV35ImageToVideoFastOutput = z.object({
  video: zSchemaFile,
})

/**
 * FastImageToVideoRequest
 */
export const zSchemaPixverseV35ImageToVideoFastInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
})

/**
 * Output
 */
export const zSchemaHunyuanVideoImg2VidLoraOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generating the video.',
  }),
  video: zSchemaFile,
})

/**
 * Input
 */
export const zSchemaHunyuanVideoImg2VidLoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for generating the video.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL to the image to generate the video from. The image must be 960x544 or it will get cropped and resized to that size.',
  }),
})

/**
 * Ray2I2VOutput
 */
export const zSchemaLumaDreamMachineRay2ImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Ray2ImageToVideoRequest
 */
export const zSchemaLumaDreamMachineRay2ImageToVideoInput = z.object({
  prompt: z.string().min(3).max(5000),
  aspect_ratio: z.optional(
    z
      .enum(['16:9', '9:16', '4:3', '3:4', '21:9', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video',
      }),
  ),
  resolution: z.optional(
    z.enum(['540p', '720p', '1080p']).register(z.globalRegistry, {
      description:
        'The resolution of the generated video (720p costs 2x more, 1080p costs 4x more)',
    }),
  ),
  loop: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether the video should loop (end of video is blended with the beginning)',
      }),
    )
    .default(false),
  duration: z.optional(
    z.enum(['5s', '9s']).register(z.globalRegistry, {
      description: 'The duration of the generated video',
    }),
  ),
  image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'Initial image to start the video from. Can be used together with end_image_url.',
    }),
  ),
  end_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'Final image to end the video with. Can be used together with image_url.',
    }),
  ),
})

/**
 * SkyreelsI2VResponse
 */
export const zSchemaSkyreelsI2vOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
  video: zSchemaFile,
})

/**
 * SkyreelsI2VRequest
 */
export const zSchemaSkyreelsI2vInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the output video',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image input.',
  }),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description: 'Guidance scale for generation (between 1.0 and 20.0)',
      }),
    )
    .default(6),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for generation. If not provided, a random seed will be used.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description:
          'Number of denoising steps (between 1 and 50). Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  negative_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'Negative prompt to guide generation away from certain attributes.',
    }),
  ),
})

/**
 * I2VDirectorOutput
 */
export const zSchemaMinimaxVideo01DirectorImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoDirectorRequest
 */
export const zSchemaMinimaxVideo01DirectorImageToVideoInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  prompt: z.string().max(2000).register(z.globalRegistry, {
    description:
      'Text prompt for video generation. Camera movement instructions can be added using square brackets (e.g. [Pan left] or [Zoom in]). You can use up to 3 combined movements per prompt. Supported movements: Truck left/right, Pan left/right, Push in/Pull out, Pedestal up/down, Tilt up/down, Zoom in/out, Shake, Tracking shot, Static shot. For example: [Truck left, Pan right, Zoom in]. For a more detailed guide, refer https://sixth-switch-2ac.notion.site/T2V-01-Director-Model-Tutorial-with-camera-movement-1886c20a98eb80f395b8e05291ad8645',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
})

/**
 * HunyuanI2VResponse
 */
export const zSchemaHunyuanVideoImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generating the video.',
  }),
  video: zSchemaFile,
})

/**
 * HunyuanVideoRequest
 */
export const zSchemaHunyuanVideoImageToVideoInput = z.object({
  prompt: z.string().max(1000).register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the video to generate.',
    }),
  ),
  resolution: z.optional(
    z.enum(['720p']).register(z.globalRegistry, {
      description: 'The resolution of the video to generate.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image input.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for generating the video.',
    }),
  ),
  num_frames: z.optional(
    z.enum(['129']).register(z.globalRegistry, {
      description: 'The number of frames to generate.',
    }),
  ),
  i2v_stability: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Turning on I2V Stability reduces hallucination but also reduces motion.',
      }),
    )
    .default(false),
})

/**
 * WanI2VResponse
 */
export const zSchemaWanI2vLoraOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanLoRAI2VRequest
 */
export const zSchemaWanI2vLoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  reverse_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If true, the video will be reversed.',
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zSchemaLoraWeight).register(z.globalRegistry, {
        description: 'LoRA weights to be used in the inference.',
      }),
    )
    .default([]),
  frames_per_second: z
    .optional(
      z.int().gte(5).lte(24).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 5 to 24.',
      }),
    )
    .default(16),
  turbo_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the video will be generated faster with no noticeable degradation in the visual quality.',
      }),
    )
    .default(true),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(81).lte(100).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 100 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.',
      }),
    )
    .default(81),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'Aspect ratio of the output video.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.',
  }),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  guide_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(5),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
})

/**
 * TemplateToVideoOutput
 */
export const zSchemaViduTemplateToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * TemplateToVideoRequest
 */
export const zSchemaViduTemplateToVideoInput = z.object({
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the output video',
    }),
  ),
  template: z.optional(
    z
      .enum([
        'dreamy_wedding',
        'romantic_lift',
        'sweet_proposal',
        'couple_arrival',
        'cupid_arrow',
        'pet_lovers',
        'lunar_newyear',
        'hug',
        'kiss',
        'dynasty_dress',
        'wish_sender',
        'love_pose',
        'hair_swap',
        'youth_rewind',
        'morphlab',
        'live_photo',
        'emotionlab',
        'live_memory',
        'interaction',
        'christmas',
        'pet_finger',
        'eat_mushrooms',
        'beast_chase_library',
        'beast_chase_supermarket',
        'petal_scattered',
        'emoji_figure',
        'hair_color_change',
        'multiple_people_kissing',
        'beast_chase_amazon',
        'beast_chase_mountain',
        'balloonman_explodes_pro',
        'get_thinner',
        'jump2pool',
        'bodyshake',
        'jiggle_up',
        'shake_it_dance',
        'subject_3',
        'pubg_winner_hit',
        'shake_it_down',
        'blueprint_supreme',
        'hip_twist',
        'motor_dance',
        'rat_dance',
        'kwok_dance',
        'leg_sweep_dance',
        'heeseung_march',
        'shake_to_max',
        'dame_un_grrr',
        'i_know',
        'lit_bounce',
        'wave_dance',
        'chill_dance',
        'hip_flicking',
        'sakura_season',
        'zongzi_wrap',
        'zongzi_drop',
        'dragonboat_shot',
        'rain_kiss',
        'child_memory',
        'couple_drop',
        'couple_walk',
        'flower_receive',
        'love_drop',
        'cheek_kiss',
        'carry_me',
        'blow_kiss',
        'love_fall',
        'french_kiss_8s',
        'workday_feels',
        'love_story',
        'bloom_magic',
        'ghibli',
        'minecraft',
        'box_me',
        'claw_me',
        'clayshot',
        'manga_meme',
        'quad_meme',
        'pixel_me',
        'clayshot_duo',
        'irasutoya',
        'american_comic',
        'simpsons_comic',
        'yayoi_kusama_style',
        'pop_art',
        'jojo_style',
        'slice_therapy',
        'balloon_flyaway',
        'flying',
        'paperman',
        'pinch',
        'bloom_doorobear',
        'gender_swap',
        'nap_me',
        'sexy_me',
        'spin360',
        'smooth_shift',
        'paper_fall',
        'jump_to_cloud',
        'pilot',
        'sweet_dreams',
        'soul_depart',
        'punch_hit',
        'watermelon_hit',
        'split_stance_pet',
        'make_face',
        'break_glass',
        'split_stance_human',
        'covered_liquid_metal',
        'fluffy_plunge',
        'pet_belly_dance',
        'water_float',
        'relax_cut',
        'head_to_balloon',
        'cloning',
        'across_the_universe_jungle',
        'clothes_spinning_remnant',
        'across_the_universe_jurassic',
        'across_the_universe_moon',
        'fisheye_pet',
        'hitchcock_zoom',
        'cute_bangs',
        'earth_zoom_out',
        'fisheye_human',
        'drive_yacht',
        'virtual_singer',
        'earth_zoom_in',
        'aliens_coming',
        'drive_ferrari',
        'bjd_style',
        'virtual_fitting',
        'orbit',
        'zoom_in',
        'ai_outfit',
        'spin180',
        'orbit_dolly',
        'orbit_dolly_fast',
        'auto_spin',
        'walk_forward',
        'outfit_show',
        'zoom_in_fast',
        'zoom_out_image',
        'zoom_out_startend',
        'muscling',
        'captain_america',
        'hulk',
        'cap_walk',
        'hulk_dive',
        'exotic_princess',
        'beast_companion',
        'cartoon_doll',
        'golden_epoch',
        'oscar_gala',
        'fashion_stride',
        'star_carpet',
        'flame_carpet',
        'frost_carpet',
        'mecha_x',
        'style_me',
        'tap_me',
        'saber_warrior',
        'pet2human',
        'graduation',
        'fishermen',
        'happy_birthday',
        'fairy_me',
        'ladudu_me',
        'ladudu_me_random',
        'squid_game',
        'superman',
        'grow_wings',
        'clevage',
        'fly_with_doraemon',
        'creatice_product_down',
        'pole_dance',
        'hug_from_behind',
        'creatice_product_up_cybercity',
        'creatice_product_up_bluecircuit',
        'creatice_product_up',
        'run_fast',
        'background_explosion',
      ])
      .register(z.globalRegistry, {
        description:
          'AI video template to use. Pricing varies by template: Standard templates (hug, kiss, love_pose, etc.) cost 4 credits ($0.20), Premium templates (lunar_newyear, dynasty_dress, dreamy_wedding, etc.) cost 6 credits ($0.30), and Advanced templates (live_photo) cost 10 credits ($0.50).',
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
  input_image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      "URLs of the images to use with the template. Number of images required varies by template: 'dynasty_dress' and 'shop_frame' accept 1-2 images, 'wish_sender' requires exactly 3 images, all other templates accept only 1 image.",
  }),
})

/**
 * ReferenceToVideoOutput
 */
export const zSchemaViduReferenceToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ReferenceToVideoRequest
 */
export const zSchemaViduReferenceToVideoInput = z.object({
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text prompt for video generation, max 1500 characters',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the output video',
    }),
  ),
  reference_image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'URLs of the reference images to use for consistent subject appearance',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(['auto', 'small', 'medium', 'large']).register(z.globalRegistry, {
      description: 'The movement amplitude of objects in the frame',
    }),
  ),
})

/**
 * StartEndToVideoOutput
 */
export const zSchemaViduStartEndToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * StartEndToVideoRequest
 */
export const zSchemaViduStartEndToVideoInput = z.object({
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text prompt for video generation, max 1500 characters',
  }),
  start_image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
  movement_amplitude: z.optional(
    z.enum(['auto', 'small', 'medium', 'large']).register(z.globalRegistry, {
      description: 'The movement amplitude of objects in the frame',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
  end_image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the last frame',
  }),
})

/**
 * VideoOutput
 */
export const zSchemaViduImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoRequest
 */
export const zSchemaViduImageToVideoInput = z.object({
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text prompt for video generation, max 1500 characters',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(['auto', 'small', 'medium', 'large']).register(z.globalRegistry, {
      description: 'The movement amplitude of objects in the frame',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
})

/**
 * ImageToVideoV21Output
 *
 * Output from image-to-video generation
 */
export const zSchemaPikaV21ImageToVideoOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output from image-to-video generation',
  })

/**
 * ImageToVideov21Input
 *
 * Base request for image-to-video generation
 */
export const zSchemaPikaV21ImageToVideoInput = z
  .object({
    prompt: z.string(),
    resolution: z.optional(
      z.enum(['720p', '1080p']).register(z.globalRegistry, {
        description: 'The resolution of the generated video',
      }),
    ),
    duration: z
      .optional(
        z.int().register(z.globalRegistry, {
          description: 'The duration of the generated video in seconds',
        }),
      )
      .default(5),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the random number generator',
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'A negative prompt to guide the model',
        }),
      )
      .default(''),
    image_url: z.string(),
  })
  .register(z.globalRegistry, {
    description: 'Base request for image-to-video generation',
  })

/**
 * Pika22ImageToVideoOutput
 *
 * Output model for Pika 2.2 image-to-video generation
 */
export const zSchemaPikaV22ImageToVideoOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output model for Pika 2.2 image-to-video generation',
  })

/**
 * Pika22ImageToVideoRequest
 *
 * Request model for Pika 2.2 image-to-video generation
 */
export const zSchemaPikaV22ImageToVideoInput = z
  .object({
    prompt: z.string(),
    resolution: z.optional(
      z.enum(['720p', '1080p']).register(z.globalRegistry, {
        description: 'The resolution of the generated video',
      }),
    ),
    duration: z.optional(
      z.union([z.literal(5), z.literal(10)]).register(z.globalRegistry, {
        description: 'The duration of the generated video in seconds',
      }),
    ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the random number generator',
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'A negative prompt to guide the model',
        }),
      )
      .default(''),
    image_url: z.string().register(z.globalRegistry, {
      description: 'URL of the image to use as the first frame',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Request model for Pika 2.2 image-to-video generation',
  })

/**
 * Pika22PikascenesOutput
 *
 * Output model for Pika 2.2 Pikascenes generation
 */
export const zSchemaPikaV22PikascenesOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output model for Pika 2.2 Pikascenes generation',
  })

/**
 * Pika22PikascenesRequest
 *
 * Request model for Pika 2.2 Pikascenes (collection-to-video) generation
 */
export const zSchemaPikaV22PikascenesInput = z
  .object({
    prompt: z.string().register(z.globalRegistry, {
      description: 'Text prompt describing the desired video',
    }),
    resolution: z.optional(
      z.enum(['720p', '1080p']).register(z.globalRegistry, {
        description: 'The resolution of the generated video',
      }),
    ),
    aspect_ratio: z.optional(
      z
        .enum(['16:9', '9:16', '1:1', '4:5', '5:4', '3:2', '2:3'])
        .register(z.globalRegistry, {
          description: 'The aspect ratio of the generated video',
        }),
    ),
    duration: z.optional(
      z.union([z.literal(5), z.literal(10)]).register(z.globalRegistry, {
        description: 'The duration of the generated video in seconds',
      }),
    ),
    ingredients_mode: z.optional(
      z.enum(['precise', 'creative']).register(z.globalRegistry, {
        description:
          'Mode for integrating multiple images. Precise mode is more accurate, creative mode is more creative.',
      }),
    ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the random number generator',
      }),
    ),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description: 'URLs of images to combine into a video',
    }),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'A negative prompt to guide the model',
        }),
      )
      .default('ugly, bad, terrible'),
  })
  .register(z.globalRegistry, {
    description:
      'Request model for Pika 2.2 Pikascenes (collection-to-video) generation',
  })

/**
 * TurboImageToVideoOutput
 *
 * Output model for all video generation endpoints
 */
export const zSchemaPikaV2TurboImageToVideoOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output model for all video generation endpoints',
  })

/**
 * ImageToVideoTurboInput
 *
 * Base request for image-to-video generation
 */
export const zSchemaPikaV2TurboImageToVideoInput = z
  .object({
    prompt: z.string(),
    resolution: z.optional(
      z.enum(['720p', '1080p']).register(z.globalRegistry, {
        description: 'The resolution of the generated video',
      }),
    ),
    duration: z
      .optional(
        z.int().register(z.globalRegistry, {
          description: 'The duration of the generated video in seconds',
        }),
      )
      .default(5),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the random number generator',
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'A negative prompt to guide the model',
        }),
      )
      .default(''),
    image_url: z.string(),
  })
  .register(z.globalRegistry, {
    description: 'Base request for image-to-video generation',
  })

/**
 * PikaffectsOutput
 *
 * Output from Pikaffects generation
 */
export const zSchemaPikaV15PikaffectsOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output from Pikaffects generation',
  })

/**
 * PikaffectsRequest
 *
 * Request model for Pikaffects endpoint
 */
export const zSchemaPikaV15PikaffectsInput = z
  .object({
    pikaffect: z
      .enum([
        'Cake-ify',
        'Crumble',
        'Crush',
        'Decapitate',
        'Deflate',
        'Dissolve',
        'Explode',
        'Eye-pop',
        'Inflate',
        'Levitate',
        'Melt',
        'Peel',
        'Poke',
        'Squish',
        'Ta-da',
        'Tear',
      ])
      .register(z.globalRegistry, {
        description: 'The Pikaffect to apply',
      }),
    prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'Text prompt to guide the effect',
      }),
    ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the random number generator',
      }),
    ),
    negative_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to guide the model',
      }),
    ),
    image_url: z.string().register(z.globalRegistry, {
      description: 'URL of the input image',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Request model for Pikaffects endpoint',
  })

/**
 * Ray2I2VOutput
 */
export const zSchemaLumaDreamMachineRay2FlashImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Ray2ImageToVideoRequest
 */
export const zSchemaLumaDreamMachineRay2FlashImageToVideoInput = z.object({
  prompt: z.string().min(3).max(5000),
  aspect_ratio: z.optional(
    z
      .enum(['16:9', '9:16', '4:3', '3:4', '21:9', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video',
      }),
  ),
  resolution: z.optional(
    z.enum(['540p', '720p', '1080p']).register(z.globalRegistry, {
      description:
        'The resolution of the generated video (720p costs 2x more, 1080p costs 4x more)',
    }),
  ),
  loop: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether the video should loop (end of video is blended with the beginning)',
      }),
    )
    .default(false),
  duration: z.optional(
    z.enum(['5s', '9s']).register(z.globalRegistry, {
      description: 'The duration of the generated video',
    }),
  ),
  image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'Initial image to start the video from. Can be used together with end_image_url.',
    }),
  ),
  end_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'Final image to end the video with. Can be used together with image_url.',
    }),
  ),
})

/**
 * TransitionOutput
 */
export const zSchemaPixverseV35TransitionOutput = z.object({
  video: zSchemaFile,
})

/**
 * TransitionRequest
 */
export const zSchemaPixverseV35TransitionInput = z.object({
  first_image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '4:3', '1:1', '3:4', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt for the transition',
  }),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  end_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'URL of the image to use as the last frame',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * EffectOutput
 */
export const zSchemaPixverseV35EffectsOutput = z.object({
  video: zSchemaFile,
})

/**
 * EffectInput
 */
export const zSchemaPixverseV35EffectsInput = z.object({
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  effect: z
    .enum([
      'Kiss Me AI',
      'Kiss',
      'Muscle Surge',
      'Warmth of Jesus',
      'Anything, Robot',
      'The Tiger Touch',
      'Hug',
      'Holy Wings',
      'Microwave',
      'Zombie Mode',
      'Squid Game',
      'Baby Face',
      'Black Myth: Wukong',
      'Long Hair Magic',
      'Leggy Run',
      'Fin-tastic Mermaid',
      'Punch Face',
      'Creepy Devil Smile',
      'Thunder God',
      'Eye Zoom Challenge',
      "Who's Arrested?",
      'Baby Arrived',
      'Werewolf Rage',
      'Bald Swipe',
      'BOOM DROP',
      'Huge Cutie',
      'Liquid Metal',
      'Sharksnap!',
      'Dust Me Away',
      '3D Figurine Factor',
      'Bikini Up',
      'My Girlfriends',
      'My Boyfriends',
      'Subject 3 Fever',
      'Earth Zoom',
      'Pole Dance',
      'Vroom Dance',
      'GhostFace Terror',
      'Dragon Evoker',
      'Skeletal Bae',
      'Summoning succubus',
      'Halloween Voodoo Doll',
      '3D Naked-Eye AD',
      'Package Explosion',
      'Dishes Served',
      'Ocean ad',
      'Supermarket AD',
      'Tree doll',
      'Come Feel My Abs',
      'The Bicep Flex',
      'London Elite Vibe',
      'Flora Nymph Gown',
      'Christmas Costume',
      "It's Snowy",
      'Reindeer Cruiser',
      'Snow Globe Maker',
      'Pet Christmas Outfit',
      'Adopt a Polar Pal',
      'Cat Christmas Box',
      'Starlight Gift Box',
      'Xmas Poster',
      'Pet Christmas Tree',
      'City Santa Hat',
      'Stocking Sweetie',
      'Christmas Night',
      'Xmas Front Page Karma',
      "Grinch's Xmas Hijack",
      'Giant Product',
      'Truck Fashion Shoot',
      'Beach AD',
      'Shoal Surround',
      'Mechanical Assembly',
      'Lighting AD',
      'Billboard AD',
      'Product close-up',
      'Parachute Delivery',
      'Dreamlike Cloud',
      'Macaron Machine',
      'Poster AD',
      'Truck AD',
      'Graffiti AD',
      '3D Figurine Factory',
      'The Exclusive First Class',
      'Art Zoom Challenge',
      'I Quit',
      'Hitchcock Dolly Zoom',
      'Smell the Lens',
      'I believe I can fly',
      'Strikout Dance',
      'Pixel World',
      'Mint in Box',
      'Hands up, Hand',
      'Flora Nymph Go',
      'Somber Embrace',
      'Beam me up',
      'Suit Swagger',
    ])
    .register(z.globalRegistry, {
      description: 'The effect to apply to the video',
    }),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'Optional URL of the image to use as the first frame. If not provided, generates from text',
  }),
})

/**
 * I2VOutputV4
 */
export const zSchemaPixverseV4ImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoRequestV4
 */
export const zSchemaPixverseV4ImageToVideoInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description:
        'The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  camera_movement: z.optional(
    z
      .enum([
        'horizontal_left',
        'horizontal_right',
        'vertical_up',
        'vertical_down',
        'zoom_in',
        'zoom_out',
        'crane_up',
        'quickly_zoom_in',
        'quickly_zoom_out',
        'smooth_zoom_in',
        'camera_rotation',
        'robo_arm',
        'super_dolly_out',
        'whip_pan',
        'hitchcock',
        'left_follow',
        'right_follow',
        'pan_left',
        'pan_right',
        'fix_bg',
      ])
      .register(z.globalRegistry, {
        description: 'The type of camera movement to apply to the video',
      }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * I2VOutputV4
 */
export const zSchemaPixverseV4ImageToVideoFastOutput = z.object({
  video: zSchemaFile,
})

/**
 * FastImageToVideoRequestV4
 */
export const zSchemaPixverseV4ImageToVideoFastInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  camera_movement: z.optional(
    z
      .enum([
        'horizontal_left',
        'horizontal_right',
        'vertical_up',
        'vertical_down',
        'zoom_in',
        'zoom_out',
        'crane_up',
        'quickly_zoom_in',
        'quickly_zoom_out',
        'smooth_zoom_in',
        'camera_rotation',
        'robo_arm',
        'super_dolly_out',
        'whip_pan',
        'hitchcock',
        'left_follow',
        'right_follow',
        'pan_left',
        'pan_right',
        'fix_bg',
      ])
      .register(z.globalRegistry, {
        description: 'The type of camera movement to apply to the video',
      }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * FramePackResponse
 */
export const zSchemaFramepackOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generating the video.',
  }),
  video: zSchemaFile,
})

/**
 * FramePackRequest
 */
export const zSchemaFramepackInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt for video generation (max 500 characters).',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the video to generate.',
    }),
  ),
  resolution: z.optional(
    z.enum(['720p', '480p']).register(z.globalRegistry, {
      description:
        'The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(30).lte(900).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(180),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image input.',
  }),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(32).register(z.globalRegistry, {
        description: 'Guidance scale for the generation.',
      }),
    )
    .default(10),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(''),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(7).register(z.globalRegistry, {
        description: 'Classifier-Free Guidance scale for the generation.',
      }),
    )
    .default(1),
})

/**
 * WanFLF2VResponse
 */
export const zSchemaWanFlf2vOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanFLF2VRequest
 */
export const zSchemaWanFlf2vInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  frames_per_second: z
    .optional(
      z.int().gte(5).lte(24).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 5 to 24.',
      }),
    )
    .default(16),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  start_image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the starting image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.',
  }),
  end_image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the ending image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.',
  }),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  num_frames: z
    .optional(
      z.int().gte(81).lte(100).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 100 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.',
      }),
    )
    .default(81),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  guide_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(5),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
})

/**
 * FramePackFLF2VResponse
 */
export const zSchemaFramepackFlf2vOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generating the video.',
  }),
  video: zSchemaFile,
})

/**
 * FramePackF2LFRequest
 */
export const zSchemaFramepackFlf2vInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt for video generation (max 500 characters).',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the video to generate.',
    }),
  ),
  resolution: z.optional(
    z.enum(['720p', '480p']).register(z.globalRegistry, {
      description:
        'The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(30).lte(1800).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(240),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image input.',
  }),
  strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Determines the influence of the final frame on the generated video. Higher values result in the output being more heavily influenced by the last frame.',
      }),
    )
    .default(0.8),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(32).register(z.globalRegistry, {
        description: 'Guidance scale for the generation.',
      }),
    )
    .default(10),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  end_image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the end image input.',
  }),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(''),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(7).register(z.globalRegistry, {
        description: 'Classifier-Free Guidance scale for the generation.',
      }),
    )
    .default(1),
})

/**
 * MagiImageToVideoResponse
 */
export const zSchemaMagiDistilledImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * MagiImageToVideoRequest
 */
export const zSchemaMagiDistilledImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the input image to represent the first frame of the video. If the input image does not match the chosen aspect ratio, it is resized and center cropped.',
  }),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z.optional(
    z
      .union([z.literal(4), z.literal(8), z.literal(16), z.literal(32)])
      .register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(96).lte(192).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.',
      }),
    )
    .default(96),
})

/**
 * EffectOutput
 */
export const zSchemaPixverseV4EffectsOutput = z.object({
  video: zSchemaFile,
})

/**
 * EffectInput
 */
export const zSchemaPixverseV4EffectsInput = z.object({
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  effect: z
    .enum([
      'Kiss Me AI',
      'Kiss',
      'Muscle Surge',
      'Warmth of Jesus',
      'Anything, Robot',
      'The Tiger Touch',
      'Hug',
      'Holy Wings',
      'Microwave',
      'Zombie Mode',
      'Squid Game',
      'Baby Face',
      'Black Myth: Wukong',
      'Long Hair Magic',
      'Leggy Run',
      'Fin-tastic Mermaid',
      'Punch Face',
      'Creepy Devil Smile',
      'Thunder God',
      'Eye Zoom Challenge',
      "Who's Arrested?",
      'Baby Arrived',
      'Werewolf Rage',
      'Bald Swipe',
      'BOOM DROP',
      'Huge Cutie',
      'Liquid Metal',
      'Sharksnap!',
      'Dust Me Away',
      '3D Figurine Factor',
      'Bikini Up',
      'My Girlfriends',
      'My Boyfriends',
      'Subject 3 Fever',
      'Earth Zoom',
      'Pole Dance',
      'Vroom Dance',
      'GhostFace Terror',
      'Dragon Evoker',
      'Skeletal Bae',
      'Summoning succubus',
      'Halloween Voodoo Doll',
      '3D Naked-Eye AD',
      'Package Explosion',
      'Dishes Served',
      'Ocean ad',
      'Supermarket AD',
      'Tree doll',
      'Come Feel My Abs',
      'The Bicep Flex',
      'London Elite Vibe',
      'Flora Nymph Gown',
      'Christmas Costume',
      "It's Snowy",
      'Reindeer Cruiser',
      'Snow Globe Maker',
      'Pet Christmas Outfit',
      'Adopt a Polar Pal',
      'Cat Christmas Box',
      'Starlight Gift Box',
      'Xmas Poster',
      'Pet Christmas Tree',
      'City Santa Hat',
      'Stocking Sweetie',
      'Christmas Night',
      'Xmas Front Page Karma',
      "Grinch's Xmas Hijack",
      'Giant Product',
      'Truck Fashion Shoot',
      'Beach AD',
      'Shoal Surround',
      'Mechanical Assembly',
      'Lighting AD',
      'Billboard AD',
      'Product close-up',
      'Parachute Delivery',
      'Dreamlike Cloud',
      'Macaron Machine',
      'Poster AD',
      'Truck AD',
      'Graffiti AD',
      '3D Figurine Factory',
      'The Exclusive First Class',
      'Art Zoom Challenge',
      'I Quit',
      'Hitchcock Dolly Zoom',
      'Smell the Lens',
      'I believe I can fly',
      'Strikout Dance',
      'Pixel World',
      'Mint in Box',
      'Hands up, Hand',
      'Flora Nymph Go',
      'Somber Embrace',
      'Beam me up',
      'Suit Swagger',
    ])
    .register(z.globalRegistry, {
      description: 'The effect to apply to the video',
    }),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'Optional URL of the image to use as the first frame. If not provided, generates from text',
  }),
})

/**
 * MagiImageToVideoResponse
 */
export const zSchemaMagiImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * MagiImageToVideoRequest
 */
export const zSchemaMagiImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the input image to represent the first frame of the video. If the input image does not match the chosen aspect ratio, it is resized and center cropped.',
  }),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z.optional(
    z
      .union([
        z.literal(4),
        z.literal(8),
        z.literal(16),
        z.literal(32),
        z.literal(64),
      ])
      .register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(96).lte(192).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.',
      }),
    )
    .default(96),
})

/**
 * Q1ImageToVideoOutput
 */
export const zSchemaViduQ1ImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Q1ImageToVideoRequest
 */
export const zSchemaViduQ1ImageToVideoInput = z.object({
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text prompt for video generation, max 1500 characters',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Seed for the random number generator',
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(['auto', 'small', 'medium', 'large']).register(z.globalRegistry, {
      description: 'The movement amplitude of objects in the frame',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
})

/**
 * Q1StartEndToVideoOutput
 */
export const zSchemaViduQ1StartEndToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Q1StartEndToVideoRequest
 */
export const zSchemaViduQ1StartEndToVideoInput = z.object({
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text prompt for video generation, max 1500 characters',
  }),
  start_image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
  movement_amplitude: z.optional(
    z.enum(['auto', 'small', 'medium', 'large']).register(z.globalRegistry, {
      description: 'The movement amplitude of objects in the frame',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Seed for the random number generator',
    }),
  ),
  end_image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the last frame',
  }),
})

/**
 * FramePackF1Response
 */
export const zSchemaFramepackF1Output = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generating the video.',
  }),
  video: zSchemaFile,
})

/**
 * FramePackF1Request
 */
export const zSchemaFramepackF1Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt for video generation (max 500 characters).',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the video to generate.',
    }),
  ),
  resolution: z.optional(
    z.enum(['720p', '480p']).register(z.globalRegistry, {
      description:
        'The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(30).lte(900).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(180),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image input.',
  }),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(32).register(z.globalRegistry, {
        description: 'Guidance scale for the generation.',
      }),
    )
    .default(10),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(''),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(7).register(z.globalRegistry, {
        description: 'Classifier-Free Guidance scale for the generation.',
      }),
    )
    .default(1),
})

/**
 * HunyuanCustomResponse
 */
export const zSchemaHunyuanCustomOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generating the video.',
  }),
  video: zSchemaFile,
})

/**
 * HunyuanCustomRequest
 */
export const zSchemaHunyuanCustomInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt for video generation (max 500 characters).',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the video to generate.',
    }),
  ),
  resolution: z.optional(
    z.enum(['512p', '720p']).register(z.globalRegistry, {
      description:
        'The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(81).lte(129).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(129),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image input.',
  }),
  fps: z
    .optional(
      z.int().gte(16).lte(30).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for generating the video.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(10).lte(30).register(z.globalRegistry, {
        description:
          'The number of inference steps to run. Lower gets faster results, higher gets better results.',
      }),
    )
    .default(30),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion, blurring, text, subtitles, static, picture, black border.',
    ),
  cfg_scale: z
    .optional(
      z.number().gte(1.5).lte(13).register(z.globalRegistry, {
        description: 'Classifier-Free Guidance scale for the generation.',
      }),
    )
    .default(7.5),
})

/**
 * EffectOutput
 */
export const zSchemaPixverseV45EffectsOutput = z.object({
  video: zSchemaFile,
})

/**
 * EffectInput
 */
export const zSchemaPixverseV45EffectsInput = z.object({
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  effect: z
    .enum([
      'Kiss Me AI',
      'Kiss',
      'Muscle Surge',
      'Warmth of Jesus',
      'Anything, Robot',
      'The Tiger Touch',
      'Hug',
      'Holy Wings',
      'Microwave',
      'Zombie Mode',
      'Squid Game',
      'Baby Face',
      'Black Myth: Wukong',
      'Long Hair Magic',
      'Leggy Run',
      'Fin-tastic Mermaid',
      'Punch Face',
      'Creepy Devil Smile',
      'Thunder God',
      'Eye Zoom Challenge',
      "Who's Arrested?",
      'Baby Arrived',
      'Werewolf Rage',
      'Bald Swipe',
      'BOOM DROP',
      'Huge Cutie',
      'Liquid Metal',
      'Sharksnap!',
      'Dust Me Away',
      '3D Figurine Factor',
      'Bikini Up',
      'My Girlfriends',
      'My Boyfriends',
      'Subject 3 Fever',
      'Earth Zoom',
      'Pole Dance',
      'Vroom Dance',
      'GhostFace Terror',
      'Dragon Evoker',
      'Skeletal Bae',
      'Summoning succubus',
      'Halloween Voodoo Doll',
      '3D Naked-Eye AD',
      'Package Explosion',
      'Dishes Served',
      'Ocean ad',
      'Supermarket AD',
      'Tree doll',
      'Come Feel My Abs',
      'The Bicep Flex',
      'London Elite Vibe',
      'Flora Nymph Gown',
      'Christmas Costume',
      "It's Snowy",
      'Reindeer Cruiser',
      'Snow Globe Maker',
      'Pet Christmas Outfit',
      'Adopt a Polar Pal',
      'Cat Christmas Box',
      'Starlight Gift Box',
      'Xmas Poster',
      'Pet Christmas Tree',
      'City Santa Hat',
      'Stocking Sweetie',
      'Christmas Night',
      'Xmas Front Page Karma',
      "Grinch's Xmas Hijack",
      'Giant Product',
      'Truck Fashion Shoot',
      'Beach AD',
      'Shoal Surround',
      'Mechanical Assembly',
      'Lighting AD',
      'Billboard AD',
      'Product close-up',
      'Parachute Delivery',
      'Dreamlike Cloud',
      'Macaron Machine',
      'Poster AD',
      'Truck AD',
      'Graffiti AD',
      '3D Figurine Factory',
      'The Exclusive First Class',
      'Art Zoom Challenge',
      'I Quit',
      'Hitchcock Dolly Zoom',
      'Smell the Lens',
      'I believe I can fly',
      'Strikout Dance',
      'Pixel World',
      'Mint in Box',
      'Hands up, Hand',
      'Flora Nymph Go',
      'Somber Embrace',
      'Beam me up',
      'Suit Swagger',
    ])
    .register(z.globalRegistry, {
      description: 'The effect to apply to the video',
    }),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'Optional URL of the image to use as the first frame. If not provided, generates from text',
  }),
})

/**
 * I2VOutputV4
 */
export const zSchemaPixverseV45ImageToVideoFastOutput = z.object({
  video: zSchemaFile,
})

/**
 * FastImageToVideoRequestV4
 */
export const zSchemaPixverseV45ImageToVideoFastInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  camera_movement: z.optional(
    z
      .enum([
        'horizontal_left',
        'horizontal_right',
        'vertical_up',
        'vertical_down',
        'zoom_in',
        'zoom_out',
        'crane_up',
        'quickly_zoom_in',
        'quickly_zoom_out',
        'smooth_zoom_in',
        'camera_rotation',
        'robo_arm',
        'super_dolly_out',
        'whip_pan',
        'hitchcock',
        'left_follow',
        'right_follow',
        'pan_left',
        'pan_right',
        'fix_bg',
      ])
      .register(z.globalRegistry, {
        description: 'The type of camera movement to apply to the video',
      }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * TransitionOutput
 */
export const zSchemaPixverseV45TransitionOutput = z.object({
  video: zSchemaFile,
})

/**
 * TransitionRequest
 */
export const zSchemaPixverseV45TransitionInput = z.object({
  first_image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '4:3', '1:1', '3:4', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt for the transition',
  }),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  end_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'URL of the image to use as the last frame',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * ImageToVideoOutput
 */
export const zSchemaLtxVideoLoraImageToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * LoRAWeight
 *
 * LoRA weight to use for generation.
 */
export const zSchemaLoRaWeight = z
  .object({
    path: z.string().register(z.globalRegistry, {
      description: 'URL or path to the LoRA weights.',
    }),
    scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'Scale of the LoRA weight. This is a multiplier applied to the LoRA weight when loading it.',
        }),
      )
      .default(1),
    weight_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'Name of the LoRA weight. Only used if `path` is a HuggingFace repository, and is only required when the repository contains multiple LoRA weights.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'LoRA weight to use for generation.',
  })

/**
 * ImageToVideoInput
 *
 * Request model for image-to-video generation.
 */
export const zSchemaLtxVideoLoraImageToVideoInput = z
  .object({
    number_of_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to use.',
        }),
      )
      .default(30),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description: 'The resolution of the video.',
      }),
    ),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to reverse the video.',
        }),
      )
      .default(false),
    aspect_ratio: z.optional(
      z.enum(['16:9', '1:1', '9:16', 'auto']).register(z.globalRegistry, {
        description: 'The aspect ratio of the video.',
      }),
    ),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: 'The frame rate of the video.',
        }),
      )
      .default(25),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to expand the prompt using the LLM.',
        }),
      )
      .default(false),
    number_of_frames: z
      .optional(
        z.int().gte(9).lte(161).register(z.globalRegistry, {
          description: 'The number of frames in the video.',
        }),
      )
      .default(89),
    image_url: z.string().register(z.globalRegistry, {
      description: 'The URL of the image to use as input.',
    }),
    loras: z
      .optional(
        z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
          description: 'The LoRA weights to use for generation.',
        }),
      )
      .default([]),
    prompt: z.string().register(z.globalRegistry, {
      description: 'The prompt to generate the video from.',
    }),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable the safety checker.',
        }),
      )
      .default(true),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed to use for generation.',
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt to use.',
        }),
      )
      .default(
        'blurry, low quality, low resolution, inconsistent motion, jittery, distorted',
      ),
  })
  .register(z.globalRegistry, {
    description: 'Request model for image-to-video generation.',
  })

/**
 * ImageToVideoOutput
 */
export const zSchemaLtxVideo13bDevImageToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * ImageToVideoInput
 */
export const zSchemaLtxVideo13bDevImageToVideoInput = z.object({
  second_pass_skip_initial_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description:
          'The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.',
      }),
    )
    .default(17),
  first_pass_num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps during the first pass.',
      }),
    )
    .default(30),
  frame_rate: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frame rate of the video.',
      }),
    )
    .default(30),
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt to guide generation',
  }),
  reverse_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to reverse the video.',
      }),
    )
    .default(false),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to expand the prompt using a language model.',
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
        description: 'LoRA weights to use for generation',
      }),
    )
    .default([]),
  second_pass_num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps during the second pass.',
      }),
    )
    .default(30),
  num_frames: z
    .optional(
      z.int().gte(9).lte(161).register(z.globalRegistry, {
        description: 'The number of frames in the video.',
      }),
    )
    .default(121),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for generation',
      }),
    )
    .default('worst quality, inconsistent motion, blurry, jittery, distorted'),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['9:16', '1:1', '16:9', 'auto']).register(z.globalRegistry, {
      description: 'The aspect ratio of the video.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Image URL for Image-to-Video task',
  }),
  constant_rate_factor: z
    .optional(
      z.int().gte(20).lte(60).register(z.globalRegistry, {
        description:
          "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
      }),
    )
    .default(35),
  first_pass_skip_final_steps: z
    .optional(
      z.int().gte(0).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.',
      }),
    )
    .default(3),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
})

/**
 * ImageToVideoOutput
 */
export const zSchemaLtxVideo13bDistilledImageToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * DistilledImageToVideoInput
 *
 * Distilled model input
 */
export const zSchemaLtxVideo13bDistilledImageToVideoInput = z
  .object({
    second_pass_skip_initial_steps: z
      .optional(
        z.int().gte(1).lte(20).register(z.globalRegistry, {
          description:
            'The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.',
        }),
      )
      .default(5),
    first_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(20).register(z.globalRegistry, {
          description: 'Number of inference steps during the first pass.',
        }),
      )
      .default(8),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: 'The frame rate of the video.',
        }),
      )
      .default(30),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to reverse the video.',
        }),
      )
      .default(false),
    prompt: z.string().register(z.globalRegistry, {
      description: 'Text prompt to guide generation',
    }),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to expand the prompt using a language model.',
        }),
      )
      .default(false),
    loras: z
      .optional(
        z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
          description: 'LoRA weights to use for generation',
        }),
      )
      .default([]),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable the safety checker.',
        }),
      )
      .default(true),
    num_frames: z
      .optional(
        z.int().gte(9).lte(161).register(z.globalRegistry, {
          description: 'The number of frames in the video.',
        }),
      )
      .default(121),
    second_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(20).register(z.globalRegistry, {
          description: 'Number of inference steps during the second pass.',
        }),
      )
      .default(8),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'Negative prompt for generation',
        }),
      )
      .default(
        'worst quality, inconsistent motion, blurry, jittery, distorted',
      ),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description: 'Resolution of the generated video (480p or 720p).',
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(['9:16', '1:1', '16:9', 'auto']).register(z.globalRegistry, {
        description: 'The aspect ratio of the video.',
      }),
    ),
    image_url: z.string().register(z.globalRegistry, {
      description: 'Image URL for Image-to-Video task',
    }),
    constant_rate_factor: z
      .optional(
        z.int().gte(20).lte(60).register(z.globalRegistry, {
          description:
            "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        }),
      )
      .default(35),
    first_pass_skip_final_steps: z
      .optional(
        z.int().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.',
        }),
      )
      .default(1),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'Random seed for generation',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Distilled model input',
  })

/**
 * ElementsOutput
 */
export const zSchemaKlingVideoV16ProElementsOutput = z.object({
  video: zSchemaFile,
})

/**
 * MultiImageToVideoRequest
 */
export const zSchemaKlingVideoV16ProElementsInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video frame',
    }),
  ),
  input_image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'List of image URLs to use for video generation. Supports up to 4 images.',
  }),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
})

/**
 * ElementsOutput
 */
export const zSchemaKlingVideoV16StandardElementsOutput = z.object({
  video: zSchemaFile,
})

/**
 * MultiImageToVideoRequest
 */
export const zSchemaKlingVideoV16StandardElementsInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video frame',
    }),
  ),
  input_image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'List of image URLs to use for video generation. Supports up to 4 images.',
  }),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
})

/**
 * Output
 */
export const zSchemaHunyuanPortraitOutput = z.object({
  video: zSchemaFile,
})

/**
 * Input
 */
export const zSchemaHunyuanPortraitInput = z.object({
  video_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the driving video.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for generation. If None, a random seed will be used.',
    }),
  ),
  use_arcface: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to use ArcFace for face recognition.',
      }),
    )
    .default(true),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the source image.',
  }),
})

/**
 * ImageToVideoV21ProOutput
 */
export const zSchemaKlingVideoV21ProImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoV21ProRequest
 */
export const zSchemaKlingVideoV21ProImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to be used for the video',
  }),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  tail_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'URL of the image to be used for the end of the video',
    }),
  ),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * Output
 */
export const zSchemaHunyuanAvatarOutput = z.object({
  video: zSchemaFile,
})

/**
 * Input
 */
export const zSchemaHunyuanAvatarInput = z.object({
  text: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Text prompt describing the scene.',
      }),
    )
    .default('A cat is singing.'),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the reference image.',
  }),
  turbo_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the video will be generated faster with no noticeable degradation in the visual quality.',
      }),
    )
    .default(true),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the audio file.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(30).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  num_frames: z
    .optional(
      z.int().gte(129).lte(401).register(z.globalRegistry, {
        description:
          'Number of video frames to generate at 25 FPS. If greater than the input audio length, it will capped to the length of the input audio.',
      }),
    )
    .default(129),
})

/**
 * SeedanceVideoOutput
 */
export const zSchemaBytedanceSeedanceV1LiteImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generation',
  }),
  video: zSchemaFile,
})

/**
 * SeedanceImageToVideoInput
 */
export const zSchemaBytedanceSeedanceV1LiteImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt used to generate the video',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p', '1080p']).register(z.globalRegistry, {
      description:
        'Video resolution - 480p for faster generation, 720p for higher quality',
    }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '1:1', '3:4', '9:16', 'auto'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video',
      }),
  ),
  duration: z.optional(
    z
      .enum(['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'])
      .register(z.globalRegistry, {
        description: 'Duration of the video in seconds',
      }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image used to generate video',
  }),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  camera_fixed: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to fix the camera position',
      }),
    )
    .default(false),
  end_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The URL of the image the video ends with. Defaults to None.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed to control video generation. Use -1 for random.',
    }),
  ),
})

/**
 * ImageToVideoHailuo02Output
 */
export const zSchemaMinimaxHailuo02ProImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ProImageToVideoHailuo02Input
 */
export const zSchemaMinimaxHailuo02ProImageToVideoInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  prompt: z.string().max(2000),
  end_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'Optional URL of the image to use as the last frame of the video',
    }),
  ),
  image_url: z.string(),
})

/**
 * AvatarMultiAudioResponse
 */
export const zSchemaAiAvatarMultiOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * AvatarMultiAudioPersonRequest
 */
export const zSchemaAiAvatarMultiInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the video to generate. Must be either 480p or 720p.',
    }),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use for generation.',
    }),
  ),
  first_audio_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the Person 1 audio file.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.',
  }),
  second_audio_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The URL of the Person 2 audio file.',
    }),
  ),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    )
    .default(81),
  use_only_first_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to use only the first audio file.',
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(41).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.',
      }),
    )
    .default(181),
})

/**
 * AvatarMultiTextResponse
 */
export const zSchemaAiAvatarMultiTextOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * AvatarMultiTextRequest
 */
export const zSchemaAiAvatarMultiTextInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  second_text_input: z.string().register(z.globalRegistry, {
    description: 'The text input to guide video generation.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use for generation.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the video to generate. Must be either 480p or 720p.',
    }),
  ),
  first_text_input: z.string().register(z.globalRegistry, {
    description: 'The text input to guide video generation.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.',
  }),
  voice2: z.optional(
    z
      .enum([
        'Aria',
        'Roger',
        'Sarah',
        'Laura',
        'Charlie',
        'George',
        'Callum',
        'River',
        'Liam',
        'Charlotte',
        'Alice',
        'Matilda',
        'Will',
        'Jessica',
        'Eric',
        'Chris',
        'Brian',
        'Daniel',
        'Lily',
        'Bill',
      ])
      .register(z.globalRegistry, {
        description: "The second person's voice to use for speech generation",
      }),
  ),
  voice1: z.optional(
    z
      .enum([
        'Aria',
        'Roger',
        'Sarah',
        'Laura',
        'Charlie',
        'George',
        'Callum',
        'River',
        'Liam',
        'Charlotte',
        'Alice',
        'Matilda',
        'Will',
        'Jessica',
        'Eric',
        'Chris',
        'Brian',
        'Daniel',
        'Lily',
        'Bill',
      ])
      .register(z.globalRegistry, {
        description: "The first person's voice to use for speech generation",
      }),
  ),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    )
    .default(81),
  num_frames: z
    .optional(
      z.int().gte(41).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.',
      }),
    )
    .default(191),
})

/**
 * AvatarSingleAudioResponse
 */
export const zSchemaAiAvatarOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * AvatarSingleAudioRequest
 */
export const zSchemaAiAvatarInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the video to generate. Must be either 480p or 720p.',
    }),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use for generation.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.',
  }),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the audio file.',
  }),
  num_frames: z
    .optional(
      z.int().gte(41).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.',
      }),
    )
    .default(145),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    )
    .default(42),
})

/**
 * AvatarSingleTextResponse
 */
export const zSchemaAiAvatarSingleTextOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * AvatarSingleTextRequest
 */
export const zSchemaAiAvatarSingleTextInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the video to generate. Must be either 480p or 720p.',
    }),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use for generation.',
    }),
  ),
  text_input: z.string().register(z.globalRegistry, {
    description: 'The text input to guide video generation.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.',
  }),
  voice: z
    .enum([
      'Aria',
      'Roger',
      'Sarah',
      'Laura',
      'Charlie',
      'George',
      'Callum',
      'River',
      'Liam',
      'Charlotte',
      'Alice',
      'Matilda',
      'Will',
      'Jessica',
      'Eric',
      'Chris',
      'Brian',
      'Daniel',
      'Lily',
      'Bill',
    ])
    .register(z.globalRegistry, {
      description: 'The voice to use for speech generation',
    }),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    )
    .default(42),
  num_frames: z
    .optional(
      z.int().gte(41).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.',
      }),
    )
    .default(136),
})

/**
 * Q1ReferenceToVideoOutput
 */
export const zSchemaViduQ1ReferenceToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Q1ReferenceToVideoRequest
 */
export const zSchemaViduQ1ReferenceToVideoInput = z.object({
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text prompt for video generation, max 1500 characters',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the output video',
    }),
  ),
  bgm: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to add background music to the generated video',
      }),
    )
    .default(false),
  reference_image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'URLs of the reference images to use for consistent subject appearance. Q1 model supports up to 7 reference images.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(['auto', 'small', 'medium', 'large']).register(z.globalRegistry, {
      description: 'The movement amplitude of objects in the frame',
    }),
  ),
})

/**
 * Veo3ImageToVideoOutput
 */
export const zSchemaVeo3FastImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Veo3ImageToVideoInput
 */
export const zSchemaVeo3FastImageToVideoInput = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: 'The text prompt describing how the image should be animated',
  }),
  resolution: z.optional(
    z.enum(['720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.',
      }),
    )
    .default(false),
  duration: z.optional(
    z.enum(['4s', '6s', '8s']).register(z.globalRegistry, {
      description: 'The duration of the generated video.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the input image to animate. Should be 720p or higher resolution in 16:9 or 9:16 aspect ratio. If the image is not in 16:9 or 9:16 aspect ratio, it will be cropped to fit.',
  }),
})

/**
 * ImageToVideoOutput
 */
export const zSchemaLtxv13B098DistilledImageToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * DistilledImageToVideoInput
 *
 * Distilled model input
 */
export const zSchemaLtxv13B098DistilledImageToVideoInput = z
  .object({
    second_pass_skip_initial_steps: z
      .optional(
        z.int().gte(1).lte(11).register(z.globalRegistry, {
          description:
            'The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.',
        }),
      )
      .default(5),
    first_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(12).register(z.globalRegistry, {
          description: 'Number of inference steps during the first pass.',
        }),
      )
      .default(8),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: 'The frame rate of the video.',
        }),
      )
      .default(24),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to reverse the video.',
        }),
      )
      .default(false),
    prompt: z.string().register(z.globalRegistry, {
      description: 'Text prompt to guide generation',
    }),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to expand the prompt using a language model.',
        }),
      )
      .default(false),
    temporal_adain_factor: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            'The factor for adaptive instance normalization (AdaIN) applied to generated video chunks after the first. This can help deal with a gradual increase in saturation/contrast in the generated video by normalizing the color distribution across the video. A high value will ensure the color distribution is more consistent across the video, while a low value will allow for more variation in color distribution.',
        }),
      )
      .default(0.5),
    loras: z
      .optional(
        z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
          description: 'LoRA weights to use for generation',
        }),
      )
      .default([]),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable the safety checker.',
        }),
      )
      .default(true),
    num_frames: z
      .optional(
        z.int().gte(9).lte(1441).register(z.globalRegistry, {
          description: 'The number of frames in the video.',
        }),
      )
      .default(121),
    second_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(12).register(z.globalRegistry, {
          description: 'Number of inference steps during the second pass.',
        }),
      )
      .default(8),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'Negative prompt for generation',
        }),
      )
      .default(
        'worst quality, inconsistent motion, blurry, jittery, distorted',
      ),
    enable_detail_pass: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to use a detail pass. If True, the model will perform a second pass to refine the video and enhance details. This incurs a 2.0x cost multiplier on the base price.',
        }),
      )
      .default(false),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(['9:16', '1:1', '16:9', 'auto']).register(z.globalRegistry, {
        description: 'The aspect ratio of the video.',
      }),
    ),
    tone_map_compression_ratio: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            'The compression ratio for tone mapping. This is used to compress the dynamic range of the video to improve visual quality. A value of 0.0 means no compression, while a value of 1.0 means maximum compression.',
        }),
      )
      .default(0),
    image_url: z.string().register(z.globalRegistry, {
      description: 'Image URL for Image-to-Video task',
    }),
    constant_rate_factor: z
      .optional(
        z.int().gte(0).lte(51).register(z.globalRegistry, {
          description:
            "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        }),
      )
      .default(29),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'Random seed for generation',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Distilled model input',
  })

/**
 * OmniHumanOutput
 */
export const zSchemaBytedanceOmnihumanOutput = z.object({
  duration: z.number().register(z.globalRegistry, {
    description: 'Duration of audio input/video output as used for billing.',
  }),
  video: zSchemaFile,
})

/**
 * OmniHumanInput
 */
export const zSchemaBytedanceOmnihumanInput = z.object({
  audio_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the audio file to generate the video. Audio must be under 30s long.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image used to generate the video',
  }),
})

/**
 * WanI2VResponse
 */
export const zSchemaWanV22A14bImageToVideoOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The text prompt used for video generation.',
      }),
    )
    .default(''),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanI2VRequest
 */
export const zSchemaWanV22A14bImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift value for the video. Must be between 1.0 and 10.0.',
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(4).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.',
      }),
    )
    .default(1),
  frames_per_second: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.',
      }),
    )
    .default(16),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(3.5),
  num_frames: z
    .optional(
      z.int().gte(17).lte(161).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 17 to 161 (inclusive).',
      }),
    )
    .default(81),
  end_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'URL of the end image.',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(''),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, input data will be checked for safety before processing.',
      }),
    )
    .default(false),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description:
        'The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p, 580p, or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, output video will be checked for safety after generation.',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.',
  }),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description:
        'The quality of the output video. Higher quality means better visual quality but larger file size.',
    }),
  ),
  guidance_scale_2: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.',
      }),
    )
    .default(3.5),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  interpolator_model: z.optional(
    z.enum(['none', 'film', 'rife']).register(z.globalRegistry, {
      description:
        'The model to use for frame interpolation. If None, no interpolation is applied.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(27),
  adjust_fps_for_interpolation: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.',
      }),
    )
    .default(true),
})

/**
 * WanSmallI2VResponse
 */
export const zSchemaWanV225bImageToVideoOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The text prompt used for video generation.',
      }),
    )
    .default(''),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanSmallI2VRequest
 */
export const zSchemaWanV225bImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift value for the video. Must be between 1.0 and 10.0.',
      }),
    )
    .default(5),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(4).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.',
      }),
    )
    .default(0),
  frames_per_second: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.',
      }),
    )
    .default(24),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(3.5),
  num_frames: z
    .optional(
      z.int().gte(17).lte(161).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 17 to 161 (inclusive).',
      }),
    )
    .default(81),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, input data will be checked for safety before processing.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(''),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description:
        'The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.',
    }),
  ),
  resolution: z.optional(
    z.enum(['580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (580p or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, output video will be checked for safety after generation.',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.',
  }),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description:
        'The quality of the output video. Higher quality means better visual quality but larger file size.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(40),
  interpolator_model: z.optional(
    z.enum(['none', 'film', 'rife']).register(z.globalRegistry, {
      description:
        'The model to use for frame interpolation. If None, no interpolation is applied.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  adjust_fps_for_interpolation: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.',
      }),
    )
    .default(true),
})

/**
 * WanTurboI2VResponse
 */
export const zSchemaWanV22A14bImageToVideoTurboOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The text prompt used for video generation.',
      }),
    )
    .default(''),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanTurboI2VRequest
 */
export const zSchemaWanV22A14bImageToVideoTurboInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p, 580p, or 720p).',
    }),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description:
        'The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.',
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, output video will be checked for safety after generation.',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.',
  }),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description:
        'The quality of the output video. Higher quality means better visual quality but larger file size.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, input data will be checked for safety before processing.',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  end_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'URL of the end image.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.',
      }),
    )
    .default(false),
})

/**
 * Veo3ImageToVideoOutput
 */
export const zSchemaVeo3ImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Veo3ImageToVideoInput
 */
export const zSchemaVeo3ImageToVideoInput = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: 'The text prompt describing how the image should be animated',
  }),
  resolution: z.optional(
    z.enum(['720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.',
      }),
    )
    .default(false),
  duration: z.optional(
    z.enum(['4s', '6s', '8s']).register(z.globalRegistry, {
      description: 'The duration of the generated video.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the input image to animate. Should be 720p or higher resolution in 16:9 or 9:16 aspect ratio. If the image is not in 16:9 or 9:16 aspect ratio, it will be cropped to fit.',
  }),
})

/**
 * ImageToVideoHailuo02FastOutput
 */
export const zSchemaMinimaxHailuo02FastImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * FastImageToVideoHailuo02Input
 */
export const zSchemaMinimaxHailuo02FastImageToVideoInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  duration: z.optional(
    z.enum(['6', '10']).register(z.globalRegistry, {
      description:
        'The duration of the video in seconds. 10 seconds videos are not supported for 1080p resolution.',
    }),
  ),
  prompt: z.string().max(2000),
  image_url: z.string(),
})

/**
 * WanI2VResponse
 */
export const zSchemaWanV22A14bImageToVideoLoraOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The text prompt used for video generation.',
      }),
    )
    .default(''),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanLoRAI2VRequest
 */
export const zSchemaWanV22A14bImageToVideoLoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift value for the video. Must be between 1.0 and 10.0.',
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(4).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.',
      }),
    )
    .default(1),
  reverse_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If true, the video will be reversed.',
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
        description: 'LoRA weights to be used in the inference.',
      }),
    )
    .default([]),
  frames_per_second: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.',
      }),
    )
    .default(16),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, input data will be checked for safety before processing.',
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(17).lte(161).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 17 to 161 (inclusive).',
      }),
    )
    .default(81),
  end_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'URL of the end image.',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(''),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(3.5),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description:
        'The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p, 580p, or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, output video will be checked for safety after generation.',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.',
  }),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description:
        'The quality of the output video. Higher quality means better visual quality but larger file size.',
    }),
  ),
  guidance_scale_2: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.',
      }),
    )
    .default(4),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(27),
  interpolator_model: z.optional(
    z.enum(['none', 'film', 'rife']).register(z.globalRegistry, {
      description:
        'The model to use for frame interpolation. If None, no interpolation is applied.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  adjust_fps_for_interpolation: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.',
      }),
    )
    .default(true),
})

export const zSchemaBytedanceVideoStylizeOutput = z.unknown()

/**
 * StylizeInput
 */
export const zSchemaBytedanceVideoStylizeInput = z.object({
  style: z.string().max(100).register(z.globalRegistry, {
    description:
      'The style for your character in the video. Please use a short description.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to make the stylized video from.',
  }),
})

/**
 * MareyOutput
 */
export const zSchemaMareyI2vOutput = z.object({
  video: zSchemaFile,
})

/**
 * MareyInputI2V
 */
export const zSchemaMareyI2vInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate a video from',
  }),
  duration: z.optional(
    z.enum(['5s', '10s']).register(z.globalRegistry, {
      description: 'The duration of the generated video.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to use as the first frame of the video.',
  }),
  dimensions: z.optional(
    z
      .enum(['1920x1080', '1080x1920', '1152x1152', '1536x1152', '1152x1536'])
      .register(z.globalRegistry, {
        description:
          'The dimensions of the generated video in width x height format.',
      }),
  ),
  guidance_scale: z.optional(z.union([z.number(), z.unknown()])),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  negative_prompt: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * I2VOutputV5
 */
export const zSchemaPixverseV5ImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoRequestV5
 */
export const zSchemaPixverseV5ImageToVideoInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description:
        'The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * EffectOutput
 */
export const zSchemaPixverseV5EffectsOutput = z.object({
  video: zSchemaFile,
})

/**
 * EffectInput
 */
export const zSchemaPixverseV5EffectsInput = z.object({
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  effect: z
    .enum([
      'Kiss Me AI',
      'Kiss',
      'Muscle Surge',
      'Warmth of Jesus',
      'Anything, Robot',
      'The Tiger Touch',
      'Hug',
      'Holy Wings',
      'Microwave',
      'Zombie Mode',
      'Squid Game',
      'Baby Face',
      'Black Myth: Wukong',
      'Long Hair Magic',
      'Leggy Run',
      'Fin-tastic Mermaid',
      'Punch Face',
      'Creepy Devil Smile',
      'Thunder God',
      'Eye Zoom Challenge',
      "Who's Arrested?",
      'Baby Arrived',
      'Werewolf Rage',
      'Bald Swipe',
      'BOOM DROP',
      'Huge Cutie',
      'Liquid Metal',
      'Sharksnap!',
      'Dust Me Away',
      '3D Figurine Factor',
      'Bikini Up',
      'My Girlfriends',
      'My Boyfriends',
      'Subject 3 Fever',
      'Earth Zoom',
      'Pole Dance',
      'Vroom Dance',
      'GhostFace Terror',
      'Dragon Evoker',
      'Skeletal Bae',
      'Summoning succubus',
      'Halloween Voodoo Doll',
      '3D Naked-Eye AD',
      'Package Explosion',
      'Dishes Served',
      'Ocean ad',
      'Supermarket AD',
      'Tree doll',
      'Come Feel My Abs',
      'The Bicep Flex',
      'London Elite Vibe',
      'Flora Nymph Gown',
      'Christmas Costume',
      "It's Snowy",
      'Reindeer Cruiser',
      'Snow Globe Maker',
      'Pet Christmas Outfit',
      'Adopt a Polar Pal',
      'Cat Christmas Box',
      'Starlight Gift Box',
      'Xmas Poster',
      'Pet Christmas Tree',
      'City Santa Hat',
      'Stocking Sweetie',
      'Christmas Night',
      'Xmas Front Page Karma',
      "Grinch's Xmas Hijack",
      'Giant Product',
      'Truck Fashion Shoot',
      'Beach AD',
      'Shoal Surround',
      'Mechanical Assembly',
      'Lighting AD',
      'Billboard AD',
      'Product close-up',
      'Parachute Delivery',
      'Dreamlike Cloud',
      'Macaron Machine',
      'Poster AD',
      'Truck AD',
      'Graffiti AD',
      '3D Figurine Factory',
      'The Exclusive First Class',
      'Art Zoom Challenge',
      'I Quit',
      'Hitchcock Dolly Zoom',
      'Smell the Lens',
      'I believe I can fly',
      'Strikout Dance',
      'Pixel World',
      'Mint in Box',
      'Hands up, Hand',
      'Flora Nymph Go',
      'Somber Embrace',
      'Beam me up',
      'Suit Swagger',
    ])
    .register(z.globalRegistry, {
      description: 'The effect to apply to the video',
    }),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'Optional URL of the image to use as the first frame. If not provided, generates from text',
  }),
})

/**
 * TransitionOutputV5
 */
export const zSchemaPixverseV5TransitionOutput = z.object({
  video: zSchemaFile,
})

/**
 * TransitionRequest
 */
export const zSchemaPixverseV5TransitionInput = z.object({
  first_image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '4:3', '1:1', '3:4', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt for the transition',
  }),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  end_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'URL of the image to use as the last frame',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * ProcessOutput
 */
export const zSchemaDecartLucy5bImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ProcessRequest
 */
export const zSchemaDecartLucy5bImageToVideoInput = z.object({
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text description of the desired video content',
  }),
  aspect_ratio: z.optional(
    z.enum(['9:16', '16:9']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(true),
  resolution: z.optional(
    z.enum(['720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
})

/**
 * A coordinate point with x and y values for motion tracking
 */
export const zSchemaTrackPoint = z
  .object({
    x: z.number().register(z.globalRegistry, {
      description: 'X coordinate',
    }),
    y: z.number().register(z.globalRegistry, {
      description: 'Y coordinate',
    }),
  })
  .register(z.globalRegistry, {
    description: 'A coordinate point with x and y values for motion tracking',
  })

/**
 * WanATIResponse
 */
export const zSchemaWanAtiOutput = z.object({
  video: zSchemaFile,
})

/**
 * WanATIRequest
 */
export const zSchemaWanAtiInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p, 580p, 720p).',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input image.',
  }),
  track: z.array(z.array(zSchemaTrackPoint)).register(z.globalRegistry, {
    description:
      "Motion tracks to guide video generation. Each track is a sequence of points defining a motion trajectory. Multiple tracks can control different elements or objects in the video. Expected format: array of tracks, where each track is an array of points with 'x' and 'y' coordinates (up to 121 points per track). Points will be automatically padded to 121 if fewer are provided. Coordinates should be within the image dimensions.",
  }),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(5),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(40),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
})

/**
 * SeedanceReferenceToVideoOutput
 */
export const zSchemaBytedanceSeedanceV1LiteReferenceToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generation',
  }),
  video: zSchemaFile,
})

/**
 * SeedanceReferenceToVideoInput
 */
export const zSchemaBytedanceSeedanceV1LiteReferenceToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt used to generate the video',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Video resolution - 480p for faster generation, 720p for higher quality',
    }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '1:1', '3:4', '9:16', 'auto'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video',
      }),
  ),
  duration: z.optional(
    z
      .enum(['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'])
      .register(z.globalRegistry, {
        description: 'Duration of the video in seconds',
      }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  camera_fixed: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to fix the camera position',
      }),
    )
    .default(false),
  reference_image_urls: z.array(z.string()).register(z.globalRegistry, {
    description: 'Reference images to generate the video with.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed to control video generation. Use -1 for random.',
    }),
  ),
})

/**
 * Lucy14BOutput
 */
export const zSchemaLucy14bImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Lucy14BImageToVideoInput
 */
export const zSchemaLucy14bImageToVideoInput = z.object({
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated\n            and uploaded before returning the response. This will increase the\n            latency of the function but it allows you to get the image directly\n            in the response without going through the CDN.\n        ',
      }),
    )
    .default(true),
  aspect_ratio: z.optional(
    z.enum(['9:16', '16:9']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text description of the desired video content',
  }),
  resolution: z.optional(
    z.enum(['720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
})

/**
 * AIAvatarOutput
 */
export const zSchemaKlingVideoV1ProAiAvatarOutput = z.object({
  duration: z.number().register(z.globalRegistry, {
    description: 'Duration of the output video in seconds.',
  }),
  video: zSchemaFile,
})

/**
 * AIAvatarInput
 */
export const zSchemaKlingVideoV1ProAiAvatarInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The prompt to use for the video generation.',
      }),
    )
    .default('.'),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the audio file.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to use as your avatar',
  }),
})

/**
 * AIAvatarOutput
 */
export const zSchemaKlingVideoV1StandardAiAvatarOutput = z.object({
  duration: z.number().register(z.globalRegistry, {
    description: 'Duration of the output video in seconds.',
  }),
  video: zSchemaFile,
})

/**
 * AIAvatarInput
 */
export const zSchemaKlingVideoV1StandardAiAvatarInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The prompt to use for the video generation.',
      }),
    )
    .default('.'),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the audio file.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to use as your avatar',
  }),
})

/**
 * FabricOneOutput
 */
export const zSchemaFabric10Output = z.object({
  video: zSchemaFile,
})

/**
 * FabricOneLipsyncInput
 */
export const zSchemaFabric10Input = z.object({
  resolution: z.enum(['720p', '480p']).register(z.globalRegistry, {
    description: 'Resolution',
  }),
  audio_url: z.url().min(1).max(2083),
  image_url: z.url().min(1).max(2083),
})

/**
 * OmniHumanv15Output
 */
export const zSchemaBytedanceOmnihumanV15Output = z.object({
  duration: z.number().register(z.globalRegistry, {
    description: 'Duration of audio input/video output as used for billing.',
  }),
  video: zSchemaFile,
})

/**
 * OmniHumanv15Input
 */
export const zSchemaBytedanceOmnihumanV15Input = z.object({
  turbo_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Generate a video at a faster rate with a slight quality trade-off.',
      }),
    )
    .default(false),
  resolution: z.optional(
    z.enum(['720p', '1080p']).register(z.globalRegistry, {
      description:
        'The resolution of the generated video. Defaults to 1080p. 720p generation is faster and higher in quality. 1080p generation is limited to 30s audio and 720p generation is limited to 60s audio.',
    }),
  ),
  prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The text prompt used to guide the video generation.',
    }),
  ),
  audio_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the audio file to generate the video. Audio must be under 30s long for 1080p generation and under 60s long for 720p generation.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image used to generate the video',
  }),
})

/**
 * FabricOneOutput
 */
export const zSchemaFabric10FastOutput = z.object({
  video: zSchemaFile,
})

/**
 * FabricOneLipsyncInput
 */
export const zSchemaFabric10FastInput = z.object({
  resolution: z.enum(['720p', '480p']).register(z.globalRegistry, {
    description: 'Resolution',
  }),
  audio_url: z.url().min(1).max(2083),
  image_url: z.url().min(1).max(2083),
})

/**
 * OviI2VResponse
 */
export const zSchemaOviImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: z.optional(z.union([zSchemaFile, z.unknown()])),
})

/**
 * OviI2VRequest
 */
export const zSchemaOviImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps.',
      }),
    )
    .default(30),
  audio_negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for audio generation.',
      }),
    )
    .default('robotic, muffled, echo, distorted'),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default('jitter, bad hands, blur, distortion'),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The image URL to guide video generation.',
  }),
})

/**
 * VideoFile
 */
export const zSchemaVideoFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  duration: z.optional(
    z.number().register(z.globalRegistry, {
      description: 'The duration of the video',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the video',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  fps: z.optional(
    z.number().register(z.globalRegistry, {
      description: 'The FPS of the video',
    }),
  ),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the video',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  num_frames: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The number of frames in the video',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ImageFile
 */
export const zSchemaImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ImageToVideoOutput
 */
export const zSchemaSora2ImageToVideoOutput = z.object({
  spritesheet: z.optional(zSchemaImageFile),
  thumbnail: z.optional(zSchemaImageFile),
  video_id: z.string().register(z.globalRegistry, {
    description: 'The ID of the generated video',
  }),
  video: zSchemaVideoFile,
})

/**
 * ImageToVideoInput
 */
export const zSchemaSora2ImageToVideoInput = z.object({
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: 'The text prompt describing the video you want to generate',
  }),
  duration: z.optional(
    z
      .union([z.literal(4), z.literal(8), z.literal(12)])
      .register(z.globalRegistry, {
        description: 'Duration of the generated video in seconds',
      }),
  ),
  resolution: z.optional(
    z.enum(['auto', '720p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '9:16', '16:9']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to use as the first frame',
  }),
  model: z.optional(
    z
      .enum(['sora-2', 'sora-2-2025-12-08', 'sora-2-2025-10-06'])
      .register(z.globalRegistry, {
        description:
          'The model to use for the generation. When the default model is selected, the latest snapshot of the model will be used - otherwise, select a specific snapshot of the model.',
      }),
  ),
  delete_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to delete the video after generation for privacy reasons. If True, the video cannot be used for remixing and will be permanently deleted.',
      }),
    )
    .default(true),
})

/**
 * ProImageToVideoOutput
 */
export const zSchemaSora2ImageToVideoProOutput = z.object({
  spritesheet: z.optional(zSchemaImageFile),
  thumbnail: z.optional(zSchemaImageFile),
  video_id: z.string().register(z.globalRegistry, {
    description: 'The ID of the generated video',
  }),
  video: zSchemaVideoFile,
})

/**
 * ProImageToVideoInput
 */
export const zSchemaSora2ImageToVideoProInput = z.object({
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: 'The text prompt describing the video you want to generate',
  }),
  duration: z.optional(
    z
      .union([z.literal(4), z.literal(8), z.literal(12)])
      .register(z.globalRegistry, {
        description: 'Duration of the generated video in seconds',
      }),
  ),
  resolution: z.optional(
    z.enum(['auto', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '9:16', '16:9']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  delete_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to delete the video after generation for privacy reasons. If True, the video cannot be used for remixing and will be permanently deleted.',
      }),
    )
    .default(true),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to use as the first frame',
  }),
})

/**
 * Veo31ImageToVideoOutput
 */
export const zSchemaVeo31ImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Veo31ImageToVideoInput
 */
export const zSchemaVeo31ImageToVideoInput = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: 'The text prompt describing the video you want to generate',
  }),
  duration: z.optional(
    z.enum(['4s', '6s', '8s']).register(z.globalRegistry, {
      description: 'The duration of the generated video.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16']).register(z.globalRegistry, {
      description:
        'The aspect ratio of the generated video. Only 16:9 and 9:16 are supported.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.',
      }),
    )
    .default(false),
  resolution: z.optional(
    z.enum(['720p', '1080p', '4k']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the input image to animate. Should be 720p or higher resolution in 16:9 or 9:16 aspect ratio. If the image is not in 16:9 or 9:16 aspect ratio, it will be cropped to fit.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
  negative_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'A negative prompt to guide the video generation.',
    }),
  ),
})

/**
 * Veo31ImageToVideoOutput
 */
export const zSchemaVeo31FastImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Veo31ImageToVideoInput
 */
export const zSchemaVeo31FastImageToVideoInput = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: 'The text prompt describing the video you want to generate',
  }),
  duration: z.optional(
    z.enum(['4s', '6s', '8s']).register(z.globalRegistry, {
      description: 'The duration of the generated video.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16']).register(z.globalRegistry, {
      description:
        'The aspect ratio of the generated video. Only 16:9 and 9:16 are supported.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.',
      }),
    )
    .default(false),
  resolution: z.optional(
    z.enum(['720p', '1080p', '4k']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the input image to animate. Should be 720p or higher resolution in 16:9 or 9:16 aspect ratio. If the image is not in 16:9 or 9:16 aspect ratio, it will be cropped to fit.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
  negative_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'A negative prompt to guide the video generation.',
    }),
  ),
})

/**
 * Veo31ReferenceToVideoOutput
 */
export const zSchemaVeo31ReferenceToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Veo31ReferenceToVideoInput
 */
export const zSchemaVeo31ReferenceToVideoInput = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: 'The text prompt describing the video you want to generate',
  }),
  duration: z.optional(
    z.enum(['8s']).register(z.globalRegistry, {
      description: 'The duration of the generated video.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  resolution: z.optional(
    z.enum(['720p', '1080p', '4k']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.',
      }),
    )
    .default(false),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'URLs of the reference images to use for consistent subject appearance',
  }),
})

/**
 * Veo31FirstLastFrameToVideoOutput
 */
export const zSchemaVeo31FirstLastFrameToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Veo31FirstLastFrameToVideoInput
 */
export const zSchemaVeo31FirstLastFrameToVideoInput = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: 'The text prompt describing the video you want to generate',
  }),
  duration: z.optional(
    z.enum(['4s', '6s', '8s']).register(z.globalRegistry, {
      description: 'The duration of the generated video.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.',
      }),
    )
    .default(false),
  resolution: z.optional(
    z.enum(['720p', '1080p', '4k']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  first_frame_url: z.string().register(z.globalRegistry, {
    description: 'URL of the first frame of the video',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
  last_frame_url: z.string().register(z.globalRegistry, {
    description: 'URL of the last frame of the video',
  }),
  negative_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'A negative prompt to guide the video generation.',
    }),
  ),
})

/**
 * Veo31FirstLastFrameToVideoOutput
 */
export const zSchemaVeo31FastFirstLastFrameToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Veo31FirstLastFrameToVideoInput
 */
export const zSchemaVeo31FastFirstLastFrameToVideoInput = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: 'The text prompt describing the video you want to generate',
  }),
  duration: z.optional(
    z.enum(['4s', '6s', '8s']).register(z.globalRegistry, {
      description: 'The duration of the generated video.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.',
      }),
    )
    .default(false),
  resolution: z.optional(
    z.enum(['720p', '1080p', '4k']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  first_frame_url: z.string().register(z.globalRegistry, {
    description: 'URL of the first frame of the video',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
  last_frame_url: z.string().register(z.globalRegistry, {
    description: 'URL of the last frame of the video',
  }),
  negative_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'A negative prompt to guide the video generation.',
    }),
  ),
})

/**
 * ImageToVideoV25StandardOutput
 */
export const zSchemaKlingVideoV25TurboStandardImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoV25StandardRequest
 */
export const zSchemaKlingVideoV25TurboStandardImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to be used for the video',
  }),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * Q2ImageToVideoOutput
 */
export const zSchemaViduQ2ImageToVideoProOutput = z.object({
  video: zSchemaFile,
})

/**
 * Q2ImageToVideoRequest
 */
export const zSchemaViduQ2ImageToVideoProInput = z.object({
  prompt: z.string().max(3000).register(z.globalRegistry, {
    description: 'Text prompt for video generation, max 3000 characters',
  }),
  resolution: z.optional(
    z.enum(['720p', '1080p']).register(z.globalRegistry, {
      description: 'Output video resolution',
    }),
  ),
  duration: z.optional(
    z
      .union([
        z.literal(2),
        z.literal(3),
        z.literal(4),
        z.literal(5),
        z.literal(6),
        z.literal(7),
        z.literal(8),
      ])
      .register(z.globalRegistry, {
        description: 'Duration of the video in seconds',
      }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the starting frame',
  }),
  bgm: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to add background music to the video (only for 4-second videos)',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(['auto', 'small', 'medium', 'large']).register(z.globalRegistry, {
      description: 'The movement amplitude of objects in the frame',
    }),
  ),
  end_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'URL of the image to use as the ending frame. When provided, generates a transition video between start and end frames.',
    }),
  ),
})

/**
 * Q2ImageToVideoOutput
 */
export const zSchemaViduQ2ImageToVideoTurboOutput = z.object({
  video: zSchemaFile,
})

/**
 * Q2ImageToVideoRequest
 */
export const zSchemaViduQ2ImageToVideoTurboInput = z.object({
  prompt: z.string().max(3000).register(z.globalRegistry, {
    description: 'Text prompt for video generation, max 3000 characters',
  }),
  resolution: z.optional(
    z.enum(['720p', '1080p']).register(z.globalRegistry, {
      description: 'Output video resolution',
    }),
  ),
  duration: z.optional(
    z
      .union([
        z.literal(2),
        z.literal(3),
        z.literal(4),
        z.literal(5),
        z.literal(6),
        z.literal(7),
        z.literal(8),
      ])
      .register(z.globalRegistry, {
        description: 'Duration of the video in seconds',
      }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the starting frame',
  }),
  bgm: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to add background music to the video (only for 4-second videos)',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(['auto', 'small', 'medium', 'large']).register(z.globalRegistry, {
      description: 'The movement amplitude of objects in the frame',
    }),
  ),
  end_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'URL of the image to use as the ending frame. When provided, generates a transition video between start and end frames.',
    }),
  ),
})

/**
 * SeedanceFastI2VVideoOutput
 */
export const zSchemaBytedanceSeedanceV1ProFastImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generation',
  }),
  video: zSchemaFile,
})

/**
 * SeedanceProFastImageToVideoInput
 */
export const zSchemaBytedanceSeedanceV1ProFastImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt used to generate the video',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p', '1080p']).register(z.globalRegistry, {
      description:
        'Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality',
    }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '1:1', '3:4', '9:16', 'auto'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video',
      }),
  ),
  duration: z.optional(
    z
      .enum(['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'])
      .register(z.globalRegistry, {
        description: 'Duration of the video in seconds',
      }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image used to generate video',
  }),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  camera_fixed: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to fix the camera position',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed to control video generation. Use -1 for random.',
    }),
  ),
})

/**
 * ProFastImageToVideoHailuo23Output
 */
export const zSchemaMinimaxHailuo23FastProImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ProFastImageToVideoHailuo23Input
 */
export const zSchemaMinimaxHailuo23FastProImageToVideoInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  prompt: z.string().min(1).max(2000).register(z.globalRegistry, {
    description: 'Text prompt for video generation',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
})

/**
 * StandardImageToVideoHailuo23Output
 */
export const zSchemaMinimaxHailuo23StandardImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * StandardImageToVideoHailuo23Input
 */
export const zSchemaMinimaxHailuo23StandardImageToVideoInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  duration: z.optional(
    z.enum(['6', '10']).register(z.globalRegistry, {
      description: 'The duration of the video in seconds.',
    }),
  ),
  prompt: z.string().min(1).max(2000).register(z.globalRegistry, {
    description: 'Text prompt for video generation',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
})

/**
 * StandardFastImageToVideoHailuo23Output
 */
export const zSchemaMinimaxHailuo23FastStandardImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * StandardFastImageToVideoHailuo23Input
 */
export const zSchemaMinimaxHailuo23FastStandardImageToVideoInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  duration: z.optional(
    z.enum(['6', '10']).register(z.globalRegistry, {
      description: 'The duration of the video in seconds.',
    }),
  ),
  prompt: z.string().min(1).max(2000).register(z.globalRegistry, {
    description: 'Text prompt for video generation',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
})

/**
 * LongCatImageToVideoResponse
 */
export const zSchemaLongcatVideoDistilledImageToVideo480pOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * LongCatImageToVideoRequest
 */
export const zSchemaLongcatVideoDistilledImageToVideo480pInput = z.object({
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The prompt to guide the video generation.',
      }),
    )
    .default(
      "First-person view from the cockpit of a Formula 1 car. The driver's gloved hands firmly grip the intricate, carbon-fiber steering wheel adorned with numerous colorful buttons and a vibrant digital display showing race data. Beyond the windshield, a sun-drenched racetrack stretches ahead, lined with cheering spectators in the grandstands. Several rival cars are visible in the distance, creating a dynamic sense of competition. The sky above is a clear, brilliant blue, reflecting the exhilarating atmosphere of a high-speed race. high resolution 4k",
    ),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frame rate of the generated video.',
      }),
    )
    .default(15),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to generate a video from.',
  }),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable safety checker.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(16).register(z.globalRegistry, {
        description: 'The number of inference steps to use.',
      }),
    )
    .default(12),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(961).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(162),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
})

/**
 * LongCatImageToVideoResponse
 */
export const zSchemaLongcatVideoDistilledImageToVideo720pOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * LongCat720PImageToVideoRequest
 */
export const zSchemaLongcatVideoDistilledImageToVideo720pInput = z.object({
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The prompt to guide the video generation.',
      }),
    )
    .default(
      "First-person view from the cockpit of a Formula 1 car. The driver's gloved hands firmly grip the intricate, carbon-fiber steering wheel adorned with numerous colorful buttons and a vibrant digital display showing race data. Beyond the windshield, a sun-drenched racetrack stretches ahead, lined with cheering spectators in the grandstands. Several rival cars are visible in the distance, creating a dynamic sense of competition. The sky above is a clear, brilliant blue, reflecting the exhilarating atmosphere of a high-speed race. high resolution 4k",
    ),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frame rate of the generated video.',
      }),
    )
    .default(30),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  num_refine_inference_steps: z
    .optional(
      z.int().gte(2).lte(16).register(z.globalRegistry, {
        description: 'The number of inference steps to use for refinement.',
      }),
    )
    .default(12),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to generate a video from.',
  }),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable safety checker.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(16).register(z.globalRegistry, {
        description: 'The number of inference steps to use.',
      }),
    )
    .default(12),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(961).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(162),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
})

/**
 * LongCatImageToVideoResponse
 */
export const zSchemaLongcatVideoImageToVideo480pOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * LongCatCFGImageToVideoRequest
 */
export const zSchemaLongcatVideoImageToVideo480pInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The prompt to guide the video generation.',
      }),
    )
    .default(
      "First-person view from the cockpit of a Formula 1 car. The driver's gloved hands firmly grip the intricate, carbon-fiber steering wheel adorned with numerous colorful buttons and a vibrant digital display showing race data. Beyond the windshield, a sun-drenched racetrack stretches ahead, lined with cheering spectators in the grandstands. Several rival cars are visible in the distance, creating a dynamic sense of competition. The sky above is a clear, brilliant blue, reflecting the exhilarating atmosphere of a high-speed race. high resolution 4k",
    ),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description: 'The acceleration level to use for the video generation.',
    }),
  ),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frame rate of the generated video.',
      }),
    )
    .default(15),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use for the video generation.',
      }),
    )
    .default(4),
  num_frames: z
    .optional(
      z.int().gte(17).lte(961).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(162),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable safety checker.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to use for the video generation.',
      }),
    )
    .default(
      'Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to generate a video from.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description:
          'The number of inference steps to use for the video generation.',
      }),
    )
    .default(40),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
})

/**
 * LongCatImageToVideoResponse
 */
export const zSchemaLongcatVideoImageToVideo720pOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * LongCat720PCFGImageToVideoRequest
 */
export const zSchemaLongcatVideoImageToVideo720pInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The prompt to guide the video generation.',
      }),
    )
    .default(
      "First-person view from the cockpit of a Formula 1 car. The driver's gloved hands firmly grip the intricate, carbon-fiber steering wheel adorned with numerous colorful buttons and a vibrant digital display showing race data. Beyond the windshield, a sun-drenched racetrack stretches ahead, lined with cheering spectators in the grandstands. Several rival cars are visible in the distance, creating a dynamic sense of competition. The sky above is a clear, brilliant blue, reflecting the exhilarating atmosphere of a high-speed race. high resolution 4k",
    ),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description: 'The acceleration level to use for the video generation.',
    }),
  ),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frame rate of the generated video.',
      }),
    )
    .default(30),
  num_refine_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to use for refinement.',
      }),
    )
    .default(40),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use for the video generation.',
      }),
    )
    .default(4),
  num_frames: z
    .optional(
      z.int().gte(17).lte(961).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(162),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable safety checker.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to use for the video generation.',
      }),
    )
    .default(
      'Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to generate a video from.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description:
          'The number of inference steps to use for the video generation.',
      }),
    )
    .default(40),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
})

/**
 * KeyframeTransition
 *
 * Configuration for a transition between two keyframes
 */
export const zSchemaKeyframeTransition = z
  .object({
    prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'Specific prompt for this transition. Overrides the global prompt if provided.',
      }),
    ),
    duration: z
      .optional(
        z.int().gte(1).lte(25).register(z.globalRegistry, {
          description: 'Duration of this transition in seconds',
        }),
      )
      .default(5),
  })
  .register(z.globalRegistry, {
    description: 'Configuration for a transition between two keyframes',
  })

/**
 * Pika22KeyframesToVideoOutput
 *
 * Output model for Pika 2.2 keyframes-to-video generation
 */
export const zSchemaPikaV22PikaframesOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output model for Pika 2.2 keyframes-to-video generation',
  })

/**
 * Pika22KeyframesToVideoRequest
 */
export const zSchemaPikaV22PikaframesInput = z.object({
  prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'Default prompt for all transitions. Individual transition prompts override this.',
    }),
  ),
  resolution: z.optional(
    z.enum(['720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  transitions: z.optional(
    z.array(zSchemaKeyframeTransition).register(z.globalRegistry, {
      description:
        'Configuration for each transition. Length must be len(image_urls) - 1. Total duration of all transitions must not exceed 25 seconds. If not provided, uses default 5-second transitions with the global prompt.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator',
    }),
  ),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'URLs of keyframe images (2-5 images) to create transitions between',
  }),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'A negative prompt to guide the model',
      }),
    )
    .default(''),
})

/**
 * SwapOutput
 */
export const zSchemaPixverseSwapOutput = z.object({
  video: zSchemaFile,
})

/**
 * SwapRequest
 */
export const zSchemaPixverseSwapInput = z.object({
  original_sound_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to keep the original audio',
      }),
    )
    .default(true),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the external video to swap',
  }),
  keyframe_id: z
    .optional(
      z.int().gte(1).register(z.globalRegistry, {
        description: 'The keyframe ID (from 1 to the last frame position)',
      }),
    )
    .default(1),
  mode: z.optional(
    z.enum(['person', 'object', 'background']).register(z.globalRegistry, {
      description: 'The swap mode to use',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p']).register(z.globalRegistry, {
      description: 'The output resolution (1080p not supported)',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the target image for swapping',
  }),
})

/**
 * LynxOutput
 */
export const zSchemaLynxOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
  video: zSchemaVideoFile,
})

/**
 * LynxInput
 */
export const zSchemaLynxInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt to guide video generation',
  }),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p, 580p, or 720p)',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video (16:9, 9:16, or 1:1)',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(75).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(50),
  guidance_scale_2: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description:
          'Image guidance scale. Controls how closely the generated video follows the reference image. Higher values increase adherence to the reference image but may decrease quality.',
      }),
    )
    .default(2),
  strength: z
    .optional(
      z.number().gte(0).lte(2).register(z.globalRegistry, {
        description:
          'Reference image scale. Controls the influence of the reference image on the generated video.',
      }),
    )
    .default(1),
  frames_per_second: z
    .optional(
      z.int().gte(5).lte(30).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 5 to 30.',
      }),
    )
    .default(16),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the subject image to be used for video generation',
  }),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(9).lte(81).register(z.globalRegistry, {
        description:
          'Number of frames in the generated video. Must be between 9 to 100.',
      }),
    )
    .default(81),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Negative prompt to guide what should not appear in the generated video',
      }),
    )
    .default(
      'Bright tones, overexposed, blurred background, static, subtitles, style, works, paintings, images, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards',
    ),
  ip_scale: z
    .optional(
      z.number().gte(0).lte(2).register(z.globalRegistry, {
        description:
          "Identity preservation scale. Controls how closely the generated video preserves the subject's identity from the reference image.",
      }),
    )
    .default(1),
})

/**
 * LTXVImageToVideoResponse
 */
export const zSchemaLtx2ImageToVideoOutput = z.object({
  video: zSchemaVideoFile,
})

/**
 * LTXVImageToVideoRequest
 */
export const zSchemaLtx2ImageToVideoInput = z.object({
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: 'The prompt to generate the video from',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  duration: z.optional(
    z
      .union([z.literal(6), z.literal(8), z.literal(10)])
      .register(z.globalRegistry, {
        description: 'The duration of the generated video in seconds',
      }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the generated video',
      }),
    )
    .default(true),
  resolution: z.optional(
    z.enum(['1080p', '1440p', '2160p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the image to generate the video from. Must be publicly accessible or base64 data URI. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.',
  }),
  fps: z.optional(
    z.union([z.literal(25), z.literal(50)]).register(z.globalRegistry, {
      description: 'The frames per second of the generated video',
    }),
  ),
})

/**
 * LTXVImageToVideoResponse
 */
export const zSchemaLtx2ImageToVideoFastOutput = z.object({
  video: zSchemaVideoFile,
})

/**
 * LTXVImageToVideoFastRequest
 */
export const zSchemaLtx2ImageToVideoFastInput = z.object({
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: 'The prompt to generate the video from',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  duration: z.optional(
    z
      .union([
        z.literal(6),
        z.literal(8),
        z.literal(10),
        z.literal(12),
        z.literal(14),
        z.literal(16),
        z.literal(18),
        z.literal(20),
      ])
      .register(z.globalRegistry, {
        description:
          'The duration of the generated video in seconds. The fast model supports 6-20 seconds. Note: Durations longer than 10 seconds (12, 14, 16, 18, 20) are only supported with 25 FPS and 1080p resolution.',
      }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the generated video',
      }),
    )
    .default(true),
  resolution: z.optional(
    z.enum(['1080p', '1440p', '2160p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the image to generate the video from. Must be publicly accessible or base64 data URI. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.',
  }),
  fps: z.optional(
    z.union([z.literal(25), z.literal(50)]).register(z.globalRegistry, {
      description: 'The frames per second of the generated video',
    }),
  ),
})

/**
 * OmniVideoReferenceToVideoOutput
 */
export const zSchemaKlingVideoO1ReferenceToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * OmniVideoElementInput
 */
export const zSchemaOmniVideoElementInput = z.object({
  reference_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'Additional reference images from different angles. 1-4 images supported. At least one image is required.',
    }),
  ),
  frontal_image_url: z.string().register(z.globalRegistry, {
    description:
      'The frontal image of the element (main view).\n\nMax file size: 10.0MB, Min width: 300px, Min height: 300px, Min aspect ratio: 0.40, Max aspect ratio: 2.50, Timeout: 20.0s',
  }),
})

/**
 * OmniVideoReferenceToVideoInput
 *
 * Input for start-frame video generation with optional reference images and elements.
 */
export const zSchemaKlingVideoO1ReferenceToVideoInput = z
  .object({
    prompt: z.string().max(2500).register(z.globalRegistry, {
      description:
        'Take @Element1, @Element2 to reference elements and @Image1, @Image2 to reference images in order.',
    }),
    duration: z.optional(
      z
        .enum(['3', '4', '5', '6', '7', '8', '9', '10'])
        .register(z.globalRegistry, {
          description: 'Video duration in seconds.',
        }),
    ),
    aspect_ratio: z.optional(
      z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video frame.',
      }),
    ),
    elements: z.optional(
      z.array(zSchemaOmniVideoElementInput).register(z.globalRegistry, {
        description:
          'Elements (characters/objects) to include in the video. Reference in prompt as @Element1, @Element2, etc. Maximum 7 total (elements + reference images + start image).',
      }),
    ),
    image_urls: z.optional(
      z.array(z.string()).register(z.globalRegistry, {
        description:
          'Additional reference images for style/appearance. Reference in prompt as @Image1, @Image2, etc. Maximum 7 total (elements + reference images + start image).',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description:
      'Input for start-frame video generation with optional reference images and elements.',
  })

/**
 * OmniVideoImageToVideoOutput
 *
 * Output for Kling Omni Video generation.
 */
export const zSchemaKlingVideoO1ImageToVideoOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output for Kling Omni Video generation.',
  })

/**
 * OmniVideoImageToVideoInput
 */
export const zSchemaKlingVideoO1ImageToVideoInput = z.object({
  prompt: z.string().max(2500).register(z.globalRegistry, {
    description:
      'Use @Image1 to reference the start frame, @Image2 to reference the end frame.',
  }),
  duration: z.optional(
    z
      .enum(['3', '4', '5', '6', '7', '8', '9', '10'])
      .register(z.globalRegistry, {
        description: 'Video duration in seconds.',
      }),
  ),
  start_image_url: z.string().register(z.globalRegistry, {
    description:
      'Image to use as the first frame of the video.\n\nMax file size: 10.0MB, Min width: 300px, Min height: 300px, Min aspect ratio: 0.40, Max aspect ratio: 2.50, Timeout: 20.0s',
  }),
  end_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'Image to use as the last frame of the video.\n\nMax file size: 10.0MB, Min width: 300px, Min height: 300px, Min aspect ratio: 0.40, Max aspect ratio: 2.50, Timeout: 20.0s',
    }),
  ),
})

/**
 * I2VOutputV5_5
 */
export const zSchemaPixverseV55ImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoRequestV5_5
 */
export const zSchemaPixverseV55ImageToVideoInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  duration: z.optional(
    z.enum(['5', '8', '10']).register(z.globalRegistry, {
      description:
        'The duration of the generated video in seconds. Longer durations cost more. 1080p videos are limited to 5 or 8 seconds',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  thinking_type: z.optional(
    z.enum(['enabled', 'disabled', 'auto']).register(z.globalRegistry, {
      description:
        "Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision",
    }),
  ),
  generate_multi_clip_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable multi-clip generation with dynamic camera changes',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
  generate_audio_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable audio generation (BGM, SFX, dialogue)',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * TransitionOutputV5_5
 */
export const zSchemaPixverseV55TransitionOutput = z.object({
  video: zSchemaFile,
})

/**
 * TransitionRequestV5_5
 */
export const zSchemaPixverseV55TransitionInput = z.object({
  first_image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '4:3', '1:1', '3:4', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  thinking_type: z.optional(
    z.enum(['enabled', 'disabled', 'auto']).register(z.globalRegistry, {
      description:
        "Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision",
    }),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt for the transition',
  }),
  duration: z.optional(
    z.enum(['5', '8', '10']).register(z.globalRegistry, {
      description:
        'The duration of the generated video in seconds. Longer durations cost more. 1080p videos are limited to 5 or 8 seconds',
    }),
  ),
  generate_audio_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable audio generation (BGM, SFX, dialogue)',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  end_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'URL of the image to use as the last frame',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * EffectOutput
 */
export const zSchemaPixverseV55EffectsOutput = z.object({
  video: zSchemaFile,
})

/**
 * EffectInputV5_5
 */
export const zSchemaPixverseV55EffectsInput = z.object({
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
  duration: z.optional(
    z.enum(['5', '8', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  thinking_type: z.optional(
    z.enum(['enabled', 'disabled', 'auto']).register(z.globalRegistry, {
      description:
        "Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision",
    }),
  ),
  effect: z
    .enum([
      'Kiss Me AI',
      'Kiss',
      'Muscle Surge',
      'Warmth of Jesus',
      'Anything, Robot',
      'The Tiger Touch',
      'Hug',
      'Holy Wings',
      'Microwave',
      'Zombie Mode',
      'Squid Game',
      'Baby Face',
      'Black Myth: Wukong',
      'Long Hair Magic',
      'Leggy Run',
      'Fin-tastic Mermaid',
      'Punch Face',
      'Creepy Devil Smile',
      'Thunder God',
      'Eye Zoom Challenge',
      "Who's Arrested?",
      'Baby Arrived',
      'Werewolf Rage',
      'Bald Swipe',
      'BOOM DROP',
      'Huge Cutie',
      'Liquid Metal',
      'Sharksnap!',
      'Dust Me Away',
      '3D Figurine Factor',
      'Bikini Up',
      'My Girlfriends',
      'My Boyfriends',
      'Subject 3 Fever',
      'Earth Zoom',
      'Pole Dance',
      'Vroom Dance',
      'GhostFace Terror',
      'Dragon Evoker',
      'Skeletal Bae',
      'Summoning succubus',
      'Halloween Voodoo Doll',
      '3D Naked-Eye AD',
      'Package Explosion',
      'Dishes Served',
      'Ocean ad',
      'Supermarket AD',
      'Tree doll',
      'Come Feel My Abs',
      'The Bicep Flex',
      'London Elite Vibe',
      'Flora Nymph Gown',
      'Christmas Costume',
      "It's Snowy",
      'Reindeer Cruiser',
      'Snow Globe Maker',
      'Pet Christmas Outfit',
      'Adopt a Polar Pal',
      'Cat Christmas Box',
      'Starlight Gift Box',
      'Xmas Poster',
      'Pet Christmas Tree',
      'City Santa Hat',
      'Stocking Sweetie',
      'Christmas Night',
      'Xmas Front Page Karma',
      "Grinch's Xmas Hijack",
      'Giant Product',
      'Truck Fashion Shoot',
      'Beach AD',
      'Shoal Surround',
      'Mechanical Assembly',
      'Lighting AD',
      'Billboard AD',
      'Product close-up',
      'Parachute Delivery',
      'Dreamlike Cloud',
      'Macaron Machine',
      'Poster AD',
      'Truck AD',
      'Graffiti AD',
      '3D Figurine Factory',
      'The Exclusive First Class',
      'Art Zoom Challenge',
      'I Quit',
      'Hitchcock Dolly Zoom',
      'Smell the Lens',
      'I believe I can fly',
      'Strikout Dance',
      'Pixel World',
      'Mint in Box',
      'Hands up, Hand',
      'Flora Nymph Go',
      'Somber Embrace',
      'Beam me up',
      'Suit Swagger',
    ])
    .register(z.globalRegistry, {
      description: 'The effect to apply to the video',
    }),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'Optional URL of the image to use as the first frame. If not provided, generates from text',
  }),
})

/**
 * ImageToVideoV26ProOutput
 */
export const zSchemaKlingVideoV26ProImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoV26ProRequest
 */
export const zSchemaKlingVideoV26ProImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  voice_ids: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'List of voice IDs to use for voice control. Reference voices in the prompt using <<<voice_1>>>, <<<voice_2>>>. Maximum 2 voices allowed. When provided and referenced in prompt, enables voice control billing.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to generate native audio for the video. Supports Chinese and English voice output. Other languages are automatically translated to English. For English speech, use lowercase letters; for acronyms or proper nouns, use uppercase.',
      }),
    )
    .default(true),
  start_image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to be used for the video',
  }),
  end_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'URL of the image to be used for the end of the video',
    }),
  ),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
})

/**
 * AIAvatarOutput
 */
export const zSchemaKlingVideoAiAvatarV2StandardOutput = z.object({
  duration: z.number().register(z.globalRegistry, {
    description: 'Duration of the output video in seconds.',
  }),
  video: zSchemaFile,
})

/**
 * AIAvatarInput
 */
export const zSchemaKlingVideoAiAvatarV2StandardInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The prompt to use for the video generation.',
      }),
    )
    .default('.'),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the audio file.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to use as your avatar',
  }),
})

/**
 * AIAvatarOutput
 */
export const zSchemaKlingVideoAiAvatarV2ProOutput = z.object({
  duration: z.number().register(z.globalRegistry, {
    description: 'Duration of the output video in seconds.',
  }),
  video: zSchemaFile,
})

/**
 * AIAvatarInput
 */
export const zSchemaKlingVideoAiAvatarV2ProInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The prompt to use for the video generation.',
      }),
    )
    .default('.'),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the audio file.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to use as your avatar',
  }),
})

/**
 * AuroraOutputModel
 */
export const zSchemaCreatifyAuroraOutput = z.object({
  video: zSchemaVideoFile,
})

/**
 * AuroraInputModel
 */
export const zSchemaCreatifyAuroraInput = z.object({
  prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'A text prompt to guide the video generation process.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(5).register(z.globalRegistry, {
        description: 'Guidance scale to be used for text prompt adherence.',
      }),
    )
    .default(1),
  audio_guidance_scale: z
    .optional(
      z.number().gte(0).lte(5).register(z.globalRegistry, {
        description: 'Guidance scale to be used for audio adherence.',
      }),
    )
    .default(2),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the audio file to be used for video generation.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image file to be used for video generation.',
  }),
})

/**
 * OmniVideoImageToVideoOutput
 *
 * Output for Kling Omni Video generation.
 */
export const zSchemaKlingVideoO1StandardImageToVideoOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output for Kling Omni Video generation.',
  })

/**
 * OmniVideoImageToVideoInput
 */
export const zSchemaKlingVideoO1StandardImageToVideoInput = z.object({
  prompt: z.string().max(2500).register(z.globalRegistry, {
    description:
      'Use @Image1 to reference the start frame, @Image2 to reference the end frame.',
  }),
  duration: z.optional(
    z
      .enum(['3', '4', '5', '6', '7', '8', '9', '10'])
      .register(z.globalRegistry, {
        description: 'Video duration in seconds.',
      }),
  ),
  start_image_url: z.string().register(z.globalRegistry, {
    description:
      'Image to use as the first frame of the video.\n\nMax file size: 10.0MB, Min width: 300px, Min height: 300px, Min aspect ratio: 0.40, Max aspect ratio: 2.50, Timeout: 20.0s',
  }),
  end_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'Image to use as the last frame of the video.\n\nMax file size: 10.0MB, Min width: 300px, Min height: 300px, Min aspect ratio: 0.40, Max aspect ratio: 2.50, Timeout: 20.0s',
    }),
  ),
})

/**
 * OmniVideoReferenceToVideoOutput
 */
export const zSchemaKlingVideoO1StandardReferenceToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * OmniVideoReferenceToVideoInput
 *
 * Input for start-frame video generation with optional reference images and elements.
 */
export const zSchemaKlingVideoO1StandardReferenceToVideoInput = z
  .object({
    prompt: z.string().max(2500).register(z.globalRegistry, {
      description:
        'Take @Element1, @Element2 to reference elements and @Image1, @Image2 to reference images in order.',
    }),
    duration: z.optional(
      z
        .enum(['3', '4', '5', '6', '7', '8', '9', '10'])
        .register(z.globalRegistry, {
          description: 'Video duration in seconds.',
        }),
    ),
    aspect_ratio: z.optional(
      z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video frame.',
      }),
    ),
    elements: z.optional(
      z.array(zSchemaOmniVideoElementInput).register(z.globalRegistry, {
        description:
          'Elements (characters/objects) to include in the video. Reference in prompt as @Element1, @Element2, etc. Maximum 7 total (elements + reference images + start image).',
      }),
    ),
    image_urls: z.optional(
      z.array(z.string()).register(z.globalRegistry, {
        description:
          'Additional reference images for style/appearance. Reference in prompt as @Image1, @Image2, etc. Maximum 7 total (elements + reference images + start image).',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description:
      'Input for start-frame video generation with optional reference images and elements.',
  })

/**
 * ImageToVideoOutput
 *
 * Output for image-to-video generation
 */
export const zSchemaV26ImageToVideoOutput = z
  .object({
    actual_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The actual prompt used if prompt rewriting was enabled',
      }),
    ),
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed used for generation',
    }),
    video: zSchemaVideoFile,
  })
  .register(z.globalRegistry, {
    description: 'Output for image-to-video generation',
  })

/**
 * ImageToVideoInput
 *
 * Input for Wan 2.6 image-to-video generation
 */
export const zSchemaV26ImageToVideoInput = z
  .object({
    prompt: z.string().min(1).register(z.globalRegistry, {
      description:
        'The text prompt describing the desired video motion. Max 800 characters.',
    }),
    resolution: z.optional(
      z.enum(['720p', '1080p']).register(z.globalRegistry, {
        description: 'Video resolution. Valid values: 720p, 1080p',
      }),
    ),
    duration: z.optional(
      z.enum(['5', '10', '15']).register(z.globalRegistry, {
        description:
          'Duration of the generated video in seconds. Choose between 5, 10 or 15 seconds.',
      }),
    ),
    audio_url: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          '\nURL of the audio to use as the background music. Must be publicly accessible.\nLimit handling: If the audio duration exceeds the duration value (5, 10, or 15 seconds),\nthe audio is truncated to the first N seconds, and the rest is discarded. If\nthe audio is shorter than the video, the remaining part of the video will be silent.\nFor example, if the audio is 3 seconds long and the video duration is 5 seconds, the\nfirst 3 seconds of the output video will have sound, and the last 2 seconds will be silent.\n- Format: WAV, MP3.\n- Duration: 3 to 30 s.\n- File size: Up to 15 MB.\n',
      }),
    ),
    image_url: z.string().register(z.globalRegistry, {
      description:
        'URL of the image to use as the first frame. Must be publicly accessible or base64 data URI. Image dimensions must be between 240 and 7680.',
    }),
    enable_prompt_expansion: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable prompt rewriting using LLM.',
        }),
      )
      .default(true),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    ),
    multi_shots: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'When true, enables intelligent multi-shot segmentation. Only active when enable_prompt_expansion is True. Set to false for single-shot generation.',
        }),
      )
      .default(false),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            'Negative prompt to describe content to avoid. Max 500 characters.',
        }),
      )
      .default(''),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'If set to true, the safety checker will be enabled.',
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description: 'Input for Wan 2.6 image-to-video generation',
  })

/**
 * HunyuanVideo15Response
 */
export const zSchemaHunyuanVideoV15ImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * HunyuanVideo15I2VRequest
 */
export const zSchemaHunyuanVideoV15ImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the video.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p']).register(z.globalRegistry, {
      description: 'The resolution of the video.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the reference image for image-to-video generation.',
  }),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable prompt expansion to enhance the input prompt.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for reproducibility.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps.',
      }),
    )
    .default(28),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to guide what not to generate.',
      }),
    )
    .default(''),
  num_frames: z
    .optional(
      z.int().gte(1).lte(121).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
})

/**
 * LiveAvatarResponse
 */
export const zSchemaLiveAvatarOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LiveAvatarRequest
 */
export const zSchemaLiveAvatarInput = z.object({
  frames_per_clip: z
    .optional(
      z.int().gte(16).lte(80).register(z.globalRegistry, {
        description:
          'Number of frames per clip. Must be a multiple of 4. Higher values = smoother but slower generation.',
      }),
    )
    .default(48),
  prompt: z.string().register(z.globalRegistry, {
    description:
      'A text prompt describing the scene and character. Helps guide the video generation style and context.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'light', 'regular', 'high']).register(z.globalRegistry, {
      description: 'Acceleration level for faster video decoding ',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the reference image for avatar generation. The character in this image will be animated.',
  }),
  num_clips: z
    .optional(
      z.int().gte(1).lte(100).register(z.globalRegistry, {
        description:
          'Number of video clips to generate. Each clip is approximately 3 seconds. Set higher for longer videos.',
      }),
    )
    .default(10),
  audio_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the driving audio file (WAV or MP3). The avatar will be animated to match this audio.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for reproducible generation.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values follow the prompt more closely.',
      }),
    )
    .default(0),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable safety checker for content moderation.',
      }),
    )
    .default(true),
})

/**
 * SeedanceProv15I2VVideoOutput
 */
export const zSchemaBytedanceSeedanceV15ProImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generation',
  }),
  video: zSchemaFile,
})

/**
 * SeedanceProv15ImageToVideoInput
 */
export const zSchemaBytedanceSeedanceV15ProImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt used to generate the video',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p', '1080p']).register(z.globalRegistry, {
      description:
        'Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality',
    }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '1:1', '3:4', '9:16'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video',
      }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video',
      }),
    )
    .default(true),
  duration: z.optional(
    z
      .enum(['4', '5', '6', '7', '8', '9', '10', '11', '12'])
      .register(z.globalRegistry, {
        description: 'Duration of the video in seconds',
      }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image used to generate video',
  }),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  camera_fixed: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to fix the camera position',
      }),
    )
    .default(false),
  end_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The URL of the image the video ends with. Defaults to None.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed to control video generation. Use -1 for random.',
    }),
  ),
})

/**
 * KandinskyI2VResponse
 */
export const zSchemaKandinsky5ProImageToVideoOutput = z.object({
  video: z.optional(zSchemaFile),
})

/**
 * KandinskyI2VRequest
 */
export const zSchemaKandinsky5ProImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  resolution: z.optional(
    z.enum(['512P', '1024P']).register(z.globalRegistry, {
      description: 'Video resolution: 512p or 1024p.',
    }),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description: 'Acceleration level for faster generation.',
    }),
  ),
  duration: z.optional(
    z.enum(['5s']).register(z.globalRegistry, {
      description: 'Video duration.',
    }),
  ),
  num_inference_steps: z.optional(z.int().gte(1).lte(40)).default(28),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the image to use as a reference for the video generation.',
  }),
})

/**
 * Schema referenced but not defined by fal.ai (missing from source OpenAPI spec)
 */
export const zSchemaTrajectoryPoint = z
  .record(z.string(), z.unknown())
  .register(z.globalRegistry, {
    description:
      'Schema referenced but not defined by fal.ai (missing from source OpenAPI spec)',
  })

/**
 * WanMoveOutput
 */
export const zSchemaWanMoveOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'Random seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * WANMoveInput
 */
export const zSchemaWanMoveInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt to guide the video generation.',
  }),
  trajectories: z
    .array(z.array(zSchemaTrajectoryPoint))
    .register(z.globalRegistry, {
      description:
        'A list of trajectories. Each trajectory list means the movement of one object.',
    }),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.',
  }),
  guidance_scale: z
    .optional(
      z.number().gte(1).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(40),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to guide the video generation.',
      }),
    )
    .default(
      'JPEG',
    ),
})

/**
 * LTX2ImageToVideoOutput
 */
export const zSchemaLtx219bImageToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2ImageToVideoInput
 */
export const zSchemaLtx219bImageToVideoInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the image to use for the video generation.',
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use.',
      }),
    )
    .default(3),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to generate the video from.',
  }),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to use.',
      }),
    )
    .default(40),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * LTX2ImageToVideoOutput
 */
export const zSchemaLtx219bImageToVideoLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export const zSchemaLoRaInput = z
  .object({
    path: z.string().register(z.globalRegistry, {
      description: 'URL, HuggingFace repo ID (owner/repo) to lora weights.',
    }),
    scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description: 'Scale factor for LoRA application (0.0 to 4.0).',
        }),
      )
      .default(1),
    weight_name: z.optional(z.union([z.string(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'LoRA weight configuration.',
  })

/**
 * LTX2LoRAImageToVideoInput
 */
export const zSchemaLtx219bImageToVideoLoraInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  loras: z.array(zSchemaLoRaInput).register(z.globalRegistry, {
    description: 'The LoRAs to use for the generation.',
  }),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the image to use for the video generation.',
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use.',
      }),
    )
    .default(3),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to generate the video from.',
  }),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to use.',
      }),
    )
    .default(40),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * LTX2ImageToVideoOutput
 */
export const zSchemaLtx219bDistilledImageToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2DistilledImageToVideoInput
 */
export const zSchemaLtx219bDistilledImageToVideoInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the image to use for the video generation.',
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to generate the video from.',
  }),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * LTX2ImageToVideoOutput
 */
export const zSchemaLtx219bDistilledImageToVideoLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2LoRADistilledImageToVideoInput
 */
export const zSchemaLtx219bDistilledImageToVideoLoraInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  loras: z.array(zSchemaLoRaInput).register(z.globalRegistry, {
    description: 'The LoRAs to use for the generation.',
  }),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the image to use for the video generation.',
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to generate the video from.',
  }),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * ImageToVideoOutput
 *
 * Output for image-to-video generation
 */
export const zSchemaV26ImageToVideoFlashOutput = z
  .object({
    actual_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The actual prompt used if prompt rewriting was enabled',
      }),
    ),
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed used for generation',
    }),
    video: zSchemaVideoFile,
  })
  .register(z.globalRegistry, {
    description: 'Output for image-to-video generation',
  })

/**
 * ImageToVideoInput
 *
 * Input for Wan 2.6 image-to-video generation
 */
export const zSchemaV26ImageToVideoFlashInput = z
  .object({
    prompt: z.string().min(1).register(z.globalRegistry, {
      description:
        'The text prompt describing the desired video motion. Max 800 characters.',
    }),
    resolution: z.optional(
      z.enum(['720p', '1080p']).register(z.globalRegistry, {
        description: 'Video resolution. Valid values: 720p, 1080p',
      }),
    ),
    duration: z.optional(
      z.enum(['5', '10', '15']).register(z.globalRegistry, {
        description:
          'Duration of the generated video in seconds. Choose between 5, 10 or 15 seconds.',
      }),
    ),
    audio_url: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          '\nURL of the audio to use as the background music. Must be publicly accessible.\nLimit handling: If the audio duration exceeds the duration value (5, 10, or 15 seconds),\nthe audio is truncated to the first N seconds, and the rest is discarded. If\nthe audio is shorter than the video, the remaining part of the video will be silent.\nFor example, if the audio is 3 seconds long and the video duration is 5 seconds, the\nfirst 3 seconds of the output video will have sound, and the last 2 seconds will be silent.\n- Format: WAV, MP3.\n- Duration: 3 to 30 s.\n- File size: Up to 15 MB.\n',
      }),
    ),
    image_url: z.string().register(z.globalRegistry, {
      description:
        'URL of the image to use as the first frame. Must be publicly accessible or base64 data URI. Image dimensions must be between 240 and 7680.',
    }),
    enable_prompt_expansion: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable prompt rewriting using LLM.',
        }),
      )
      .default(true),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    ),
    multi_shots: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'When true, enables intelligent multi-shot segmentation. Only active when enable_prompt_expansion is True. Set to false for single-shot generation.',
        }),
      )
      .default(false),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            'Negative prompt to describe content to avoid. Max 500 characters.',
        }),
      )
      .default(''),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'If set to true, the safety checker will be enabled.',
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description: 'Input for Wan 2.6 image-to-video generation',
  })

/**
 * Q2ProReferenceToVideoOutput
 */
export const zSchemaViduQ2ReferenceToVideoProOutput = z.object({
  video: zSchemaFile,
})

/**
 * Q2ProReferenceToVideoRequest
 */
export const zSchemaViduQ2ReferenceToVideoProInput = z.object({
  prompt: z.string().max(2000).register(z.globalRegistry, {
    description: 'Text prompt for video generation, max 2000 characters',
  }),
  resolution: z.optional(
    z.enum(['540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'Output video resolution',
    }),
  ),
  aspect_ratio: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Aspect ratio of the output video (e.g., auto, 16:9, 9:16, 1:1, or any W:H)',
      }),
    )
    .default('16:9'),
  duration: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description:
          'Duration of the video in seconds (0 for automatic duration)',
      }),
    )
    .default(4),
  reference_video_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'URLs of the reference videos for video editing or motion reference. Supports up to 2 videos.',
    }),
  ),
  bgm: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to add background music to the generated video',
      }),
    )
    .default(false),
  reference_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'URLs of the reference images for subject appearance. If videos are provided, up to 4 images are allowed; otherwise up to 7 images.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(['auto', 'small', 'medium', 'large']).register(z.globalRegistry, {
      description: 'The movement amplitude of objects in the frame',
    }),
  ),
})

/**
 * I2VOutputV5_5
 */
export const zSchemaPixverseV56ImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoRequestV5_6
 */
export const zSchemaPixverseV56ImageToVideoInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  duration: z.optional(
    z.enum(['5', '8', '10']).register(z.globalRegistry, {
      description:
        'The duration of the generated video in seconds. 1080p videos are limited to 5 or 8 seconds',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  thinking_type: z.optional(
    z.enum(['enabled', 'disabled', 'auto']).register(z.globalRegistry, {
      description:
        "Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision",
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
  generate_audio_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable audio generation (BGM, SFX, dialogue)',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * TransitionOutputV5_5
 */
export const zSchemaPixverseV56TransitionOutput = z.object({
  video: zSchemaFile,
})

/**
 * TransitionRequestV5_6
 */
export const zSchemaPixverseV56TransitionInput = z.object({
  first_image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '4:3', '1:1', '3:4', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  thinking_type: z.optional(
    z.enum(['enabled', 'disabled', 'auto']).register(z.globalRegistry, {
      description:
        "Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision",
    }),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt for the transition',
  }),
  duration: z.optional(
    z.enum(['5', '8', '10']).register(z.globalRegistry, {
      description:
        'The duration of the generated video in seconds. 1080p videos are limited to 5 or 8 seconds',
    }),
  ),
  generate_audio_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable audio generation (BGM, SFX, dialogue)',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  end_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'URL of the image to use as the last frame',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * WanI2VResponse
 */
export const zSchemaWanI2vOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanI2VRequest
 */
export const zSchemaWanI2vInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  frames_per_second: z
    .optional(
      z.int().gte(5).lte(24).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 5 to 24.',
      }),
    )
    .default(16),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(81).lte(100).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 100 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.',
      }),
    )
    .default(81),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.',
  }),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  guide_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
})

/**
 * ImageToVideoV2MasterOutput
 */
export const zSchemaKlingVideoV2MasterImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoV2MasterRequest
 */
export const zSchemaKlingVideoV2MasterImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to be used for the video',
  }),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * I2VOutputV4
 */
export const zSchemaPixverseV45ImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoRequestV4
 */
export const zSchemaPixverseV45ImageToVideoInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description:
        'The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  camera_movement: z.optional(
    z
      .enum([
        'horizontal_left',
        'horizontal_right',
        'vertical_up',
        'vertical_down',
        'zoom_in',
        'zoom_out',
        'crane_up',
        'quickly_zoom_in',
        'quickly_zoom_out',
        'smooth_zoom_in',
        'camera_rotation',
        'robo_arm',
        'super_dolly_out',
        'whip_pan',
        'hitchcock',
        'left_follow',
        'right_follow',
        'pan_left',
        'pan_right',
        'fix_bg',
      ])
      .register(z.globalRegistry, {
        description: 'The type of camera movement to apply to the video',
      }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * ImageToVideoV21StandardOutput
 */
export const zSchemaKlingVideoV21StandardImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoV21StandardRequest
 */
export const zSchemaKlingVideoV21StandardImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to be used for the video',
  }),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * ImageToVideoV21MasterOutput
 */
export const zSchemaKlingVideoV21MasterImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoV21MasterRequest
 */
export const zSchemaKlingVideoV21MasterImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to be used for the video',
  }),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * SeedanceProI2VVideoOutput
 */
export const zSchemaBytedanceSeedanceV1ProImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generation',
  }),
  video: zSchemaFile,
})

/**
 * SeedanceProImageToVideoInput
 */
export const zSchemaBytedanceSeedanceV1ProImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt used to generate the video',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p', '1080p']).register(z.globalRegistry, {
      description:
        'Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality',
    }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '1:1', '3:4', '9:16', 'auto'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video',
      }),
  ),
  duration: z.optional(
    z
      .enum(['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'])
      .register(z.globalRegistry, {
        description: 'Duration of the video in seconds',
      }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image used to generate video',
  }),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  camera_fixed: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to fix the camera position',
      }),
    )
    .default(false),
  end_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The URL of the image the video ends with. Defaults to None.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed to control video generation. Use -1 for random.',
    }),
  ),
})

/**
 * ImageToVideoHailuo02Output
 */
export const zSchemaMinimaxHailuo02StandardImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * StandardImageToVideoHailuo02Input
 */
export const zSchemaMinimaxHailuo02StandardImageToVideoInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  duration: z.optional(
    z.enum(['6', '10']).register(z.globalRegistry, {
      description:
        'The duration of the video in seconds. 10 seconds videos are not supported for 1080p resolution.',
    }),
  ),
  resolution: z.optional(
    z.enum(['512P', '768P']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  prompt: z.string().max(2000),
  end_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'Optional URL of the image to use as the last frame of the video',
    }),
  ),
  image_url: z.string(),
})

/**
 * ImageToVideoV25ProOutput
 */
export const zSchemaKlingVideoV25TurboProImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoV25ProRequest
 */
export const zSchemaKlingVideoV25TurboProImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to be used for the video',
  }),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  tail_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'URL of the image to be used for the end of the video',
    }),
  ),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * VideoOutput
 *
 * Base output for video generation
 */
export const zSchemaWan25PreviewImageToVideoOutput = z
  .object({
    actual_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The actual prompt used if prompt rewriting was enabled',
      }),
    ),
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed used for generation',
    }),
    video: zSchemaVideoFile,
  })
  .register(z.globalRegistry, {
    description: 'Base output for video generation',
  })

/**
 * ImageToVideoInput
 *
 * Input for image-to-video generation
 */
export const zSchemaWan25PreviewImageToVideoInput = z
  .object({
    prompt: z.string().min(1).register(z.globalRegistry, {
      description:
        'The text prompt describing the desired video motion. Max 800 characters.',
    }),
    resolution: z.optional(
      z.enum(['480p', '720p', '1080p']).register(z.globalRegistry, {
        description: 'Video resolution. Valid values: 480p, 720p, 1080p',
      }),
    ),
    duration: z.optional(
      z.enum(['5', '10']).register(z.globalRegistry, {
        description:
          'Duration of the generated video in seconds. Choose between 5 or 10 seconds.',
      }),
    ),
    image_url: z.string().register(z.globalRegistry, {
      description:
        'URL of the image to use as the first frame. Must be publicly accessible or base64 data URI.\n\nMax file size: 25.0MB, Min width: 360px, Min height: 360px, Max width: 2000px, Max height: 2000px, Timeout: 20.0s',
    }),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'If set to true, the safety checker will be enabled.',
        }),
      )
      .default(true),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    ),
    audio_url: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          '\nURL of the audio to use as the background music. Must be publicly accessible.\nLimit handling: If the audio duration exceeds the duration value (5 or 10 seconds),\nthe audio is truncated to the first 5 or 10 seconds, and the rest is discarded. If\nthe audio is shorter than the video, the remaining part of the video will be silent.\nFor example, if the audio is 3 seconds long and the video duration is 5 seconds, the\nfirst 3 seconds of the output video will have sound, and the last 2 seconds will be silent.\n- Format: WAV, MP3.\n- Duration: 3 to 30 s.\n- File size: Up to 15 MB.\n',
      }),
    ),
    negative_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'Negative prompt to describe content to avoid. Max 500 characters.',
      }),
    ),
    enable_prompt_expansion: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable prompt rewriting using LLM.',
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description: 'Input for image-to-video generation',
  })

/**
 * ProImageToVideoHailuo23Output
 */
export const zSchemaMinimaxHailuo23ProImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ProImageToVideoHailuo23Input
 */
export const zSchemaMinimaxHailuo23ProImageToVideoInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  prompt: z.string().min(1).max(2000).register(z.globalRegistry, {
    description: 'Text prompt for video generation',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
})

/**
 * VideoOutput
 */
export const zSchemaMinimaxVideo01ImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoRequest
 */
export const zSchemaMinimaxVideo01ImageToVideoInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  prompt: z.string().max(2000),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to use as the first frame',
  }),
})

/**
 * I2VOutput
 */
export const zSchemaKlingVideoV16ProImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ProImageToVideoRequest
 */
export const zSchemaKlingVideoV16ProImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video frame',
    }),
  ),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  image_url: z.string(),
  tail_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'URL of the image to be used for the end of the video',
    }),
  ),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * ImageToVideoOutput
 */
export const zSchemaVeo2ImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoInput
 */
export const zSchemaVeo2ImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt describing how the image should be animated',
  }),
  duration: z.optional(
    z.enum(['5s', '6s', '7s', '8s']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(['auto', 'auto_prefer_portrait', '16:9', '9:16'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video',
      }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the input image to animate. Should be 720p or higher resolution.',
  }),
})

/**
 * WanProI2VResponse
 */
export const zSchemaWanProImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * WanProI2VRequest
 */
export const zSchemaWanProImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video',
  }),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker',
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the image to generate the video from',
  }),
})

/**
 * WanEffectsOutput
 */
export const zSchemaWanEffectsOutput = z.object({
  seed: z.int(),
  video: zSchemaFile,
})

/**
 * BaseInput
 */
export const zSchemaWanEffectsInput = z.object({
  effect_type: z.optional(
    z
      .enum([
        'squish',
        'muscle',
        'inflate',
        'crush',
        'rotate',
        'gun-shooting',
        'deflate',
        'cakeify',
        'hulk',
        'baby',
        'bride',
        'classy',
        'puppy',
        'snow-white',
        'disney-princess',
        'mona-lisa',
        'painting',
        'pirate-captain',
        'princess',
        'jungle',
        'samurai',
        'vip',
        'warrior',
        'zen',
        'assassin',
        'timelapse',
        'tsunami',
        'fire',
        'zoom-call',
        'doom-fps',
        'fus-ro-dah',
        'hug-jesus',
        'robot-face-reveal',
        'super-saiyan',
        'jumpscare',
        'laughing',
        'cartoon-jaw-drop',
        'crying',
        'kissing',
        'angry-face',
        'selfie-younger-self',
        'animeify',
        'blast',
      ])
      .register(z.globalRegistry, {
        description: 'The type of effect to apply to the video.',
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'Aspect ratio of the output video.',
    }),
  ),
  subject: z.string().register(z.globalRegistry, {
    description:
      'The subject to insert into the predefined prompt template for the selected effect.',
  }),
  lora_scale: z
    .optional(
      z.number().gte(0.1).lte(2).register(z.globalRegistry, {
        description:
          'The scale of the LoRA weight. Used to adjust effect intensity.',
      }),
    )
    .default(1),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input image.',
  }),
  turbo_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use turbo mode. If True, the video will be generated faster but with lower quality.',
      }),
    )
    .default(false),
  frames_per_second: z
    .optional(
      z.int().gte(5).lte(24).register(z.globalRegistry, {
        description: 'Frames per second of the generated video.',
      }),
    )
    .default(16),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(81).lte(100).register(z.globalRegistry, {
        description: 'Number of frames to generate.',
      }),
    )
    .default(81),
})

export const zSchemaQueueStatus = z.object({
  status: z.enum(['IN_QUEUE', 'IN_PROGRESS', 'COMPLETED']),
  request_id: z.string().register(z.globalRegistry, {
    description: 'The request id.',
  }),
  response_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The response url.',
    }),
  ),
  status_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The status url.',
    }),
  ),
  cancel_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The cancel url.',
    }),
  ),
  logs: z.optional(
    z.record(z.string(), z.unknown()).register(z.globalRegistry, {
      description: 'The logs.',
    }),
  ),
  metrics: z.optional(
    z.record(z.string(), z.unknown()).register(z.globalRegistry, {
      description: 'The metrics.',
    }),
  ),
  queue_position: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The queue position.',
    }),
  ),
})

export const zGetFalAiWanEffectsRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanEffectsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanEffectsRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanEffectsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanEffectsData = z.object({
  body: zSchemaWanEffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanEffectsResponse = zSchemaQueueStatus

export const zGetFalAiWanEffectsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanEffectsRequestsByRequestIdResponse =
  zSchemaWanEffectsOutput

export const zGetFalAiWanProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanProImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanProImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanProImageToVideoData = z.object({
  body: zSchemaWanProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanProImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiWanProImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanProImageToVideoRequestsByRequestIdResponse =
  zSchemaWanProImageToVideoOutput

export const zGetFalAiVeo2ImageToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiVeo2ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVeo2ImageToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo2ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiVeo2ImageToVideoData = z.object({
  body: zSchemaVeo2ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVeo2ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiVeo2ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiVeo2ImageToVideoRequestsByRequestIdResponse =
  zSchemaVeo2ImageToVideoOutput

export const zGetFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV16ProImageToVideoData = z.object({
  body: zSchemaKlingVideoV16ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV16ProImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV16ProImageToVideoOutput

export const zGetFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxVideo01ImageToVideoData = z.object({
  body: zSchemaMinimaxVideo01ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxVideo01ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdResponse =
  zSchemaMinimaxVideo01ImageToVideoOutput

export const zGetFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxHailuo23ProImageToVideoData = z.object({
  body: zSchemaMinimaxHailuo23ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo23ProImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdResponse =
  zSchemaMinimaxHailuo23ProImageToVideoOutput

export const zGetFalAiWan25PreviewImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWan25PreviewImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWan25PreviewImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWan25PreviewImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWan25PreviewImageToVideoData = z.object({
  body: zSchemaWan25PreviewImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWan25PreviewImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiWan25PreviewImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiWan25PreviewImageToVideoRequestsByRequestIdResponse =
  zSchemaWan25PreviewImageToVideoOutput

export const zGetFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV25TurboProImageToVideoData = z.object({
  body: zSchemaKlingVideoV25TurboProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV25TurboProImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV25TurboProImageToVideoOutput

export const zGetFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxHailuo02StandardImageToVideoData = z.object({
  body: zSchemaMinimaxHailuo02StandardImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo02StandardImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdResponse =
  zSchemaMinimaxHailuo02StandardImageToVideoOutput

export const zGetFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiBytedanceSeedanceV1ProImageToVideoData = z.object({
  body: zSchemaBytedanceSeedanceV1ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiBytedanceSeedanceV1ProImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdResponse =
  zSchemaBytedanceSeedanceV1ProImageToVideoOutput

export const zGetFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV21MasterImageToVideoData = z.object({
  body: zSchemaKlingVideoV21MasterImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV21MasterImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV21MasterImageToVideoOutput

export const zGetFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV21StandardImageToVideoData = z.object({
  body: zSchemaKlingVideoV21StandardImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV21StandardImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV21StandardImageToVideoOutput

export const zGetFalAiPixverseV45ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV45ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV45ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV45ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPixverseV45ImageToVideoData = z.object({
  body: zSchemaPixverseV45ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV45ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV45ImageToVideoRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV45ImageToVideoRequestsByRequestIdResponse =
  zSchemaPixverseV45ImageToVideoOutput

export const zGetFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV2MasterImageToVideoData = z.object({
  body: zSchemaKlingVideoV2MasterImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV2MasterImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV2MasterImageToVideoOutput

export const zGetFalAiWanI2vRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanI2vRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanI2vRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanI2vRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanI2vData = z.object({
  body: zSchemaWanI2vInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanI2vResponse = zSchemaQueueStatus

export const zGetFalAiWanI2vRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanI2vRequestsByRequestIdResponse = zSchemaWanI2vOutput

export const zGetFalAiPixverseV56TransitionRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV56TransitionRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV56TransitionRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV56TransitionRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseV56TransitionData = z.object({
  body: zSchemaPixverseV56TransitionInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV56TransitionResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV56TransitionRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV56TransitionRequestsByRequestIdResponse =
  zSchemaPixverseV56TransitionOutput

export const zGetFalAiPixverseV56ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV56ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV56ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV56ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPixverseV56ImageToVideoData = z.object({
  body: zSchemaPixverseV56ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV56ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV56ImageToVideoRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV56ImageToVideoRequestsByRequestIdResponse =
  zSchemaPixverseV56ImageToVideoOutput

export const zGetFalAiViduQ2ReferenceToVideoProRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiViduQ2ReferenceToVideoProRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiViduQ2ReferenceToVideoProRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ2ReferenceToVideoProRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiViduQ2ReferenceToVideoProData = z.object({
  body: zSchemaViduQ2ReferenceToVideoProInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiViduQ2ReferenceToVideoProResponse = zSchemaQueueStatus

export const zGetFalAiViduQ2ReferenceToVideoProRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiViduQ2ReferenceToVideoProRequestsByRequestIdResponse =
  zSchemaViduQ2ReferenceToVideoProOutput

export const zGetWanV26ImageToVideoFlashRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetWanV26ImageToVideoFlashRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutWanV26ImageToVideoFlashRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutWanV26ImageToVideoFlashRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostWanV26ImageToVideoFlashData = z.object({
  body: zSchemaV26ImageToVideoFlashInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostWanV26ImageToVideoFlashResponse = zSchemaQueueStatus

export const zGetWanV26ImageToVideoFlashRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetWanV26ImageToVideoFlashRequestsByRequestIdResponse =
  zSchemaV26ImageToVideoFlashOutput

export const zGetFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtx219bDistilledImageToVideoLoraData = z.object({
  body: zSchemaLtx219bDistilledImageToVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bDistilledImageToVideoLoraResponse =
  zSchemaQueueStatus

export const zGetFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdResponse =
  zSchemaLtx219bDistilledImageToVideoLoraOutput

export const zGetFalAiLtx219bDistilledImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bDistilledImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bDistilledImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bDistilledImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtx219bDistilledImageToVideoData = z.object({
  body: zSchemaLtx219bDistilledImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bDistilledImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtx219bDistilledImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bDistilledImageToVideoRequestsByRequestIdResponse =
  zSchemaLtx219bDistilledImageToVideoOutput

export const zGetFalAiLtx219bImageToVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bImageToVideoLoraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bImageToVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bImageToVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtx219bImageToVideoLoraData = z.object({
  body: zSchemaLtx219bImageToVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bImageToVideoLoraResponse = zSchemaQueueStatus

export const zGetFalAiLtx219bImageToVideoLoraRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bImageToVideoLoraRequestsByRequestIdResponse =
  zSchemaLtx219bImageToVideoLoraOutput

export const zGetFalAiLtx219bImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtx219bImageToVideoData = z.object({
  body: zSchemaLtx219bImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtx219bImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bImageToVideoRequestsByRequestIdResponse =
  zSchemaLtx219bImageToVideoOutput

export const zGetFalAiWanMoveRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanMoveRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanMoveRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanMoveRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanMoveData = z.object({
  body: zSchemaWanMoveInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanMoveResponse = zSchemaQueueStatus

export const zGetFalAiWanMoveRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanMoveRequestsByRequestIdResponse = zSchemaWanMoveOutput

export const zGetFalAiKandinsky5ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKandinsky5ProImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKandinsky5ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKandinsky5ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKandinsky5ProImageToVideoData = z.object({
  body: zSchemaKandinsky5ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKandinsky5ProImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiKandinsky5ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKandinsky5ProImageToVideoRequestsByRequestIdResponse =
  zSchemaKandinsky5ProImageToVideoOutput

export const zGetFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiBytedanceSeedanceV15ProImageToVideoData = z.object({
  body: zSchemaBytedanceSeedanceV15ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiBytedanceSeedanceV15ProImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdResponse =
  zSchemaBytedanceSeedanceV15ProImageToVideoOutput

export const zGetFalAiLiveAvatarRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiLiveAvatarRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLiveAvatarRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiLiveAvatarRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLiveAvatarData = z.object({
  body: zSchemaLiveAvatarInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLiveAvatarResponse = zSchemaQueueStatus

export const zGetFalAiLiveAvatarRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLiveAvatarRequestsByRequestIdResponse =
  zSchemaLiveAvatarOutput

export const zGetFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiHunyuanVideoV15ImageToVideoData = z.object({
  body: zSchemaHunyuanVideoV15ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiHunyuanVideoV15ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdResponse =
  zSchemaHunyuanVideoV15ImageToVideoOutput

export const zGetWanV26ImageToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetWanV26ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutWanV26ImageToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutWanV26ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostWanV26ImageToVideoData = z.object({
  body: zSchemaV26ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostWanV26ImageToVideoResponse = zSchemaQueueStatus

export const zGetWanV26ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetWanV26ImageToVideoRequestsByRequestIdResponse =
  zSchemaV26ImageToVideoOutput

export const zGetFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoO1StandardReferenceToVideoData = z.object({
  body: zSchemaKlingVideoO1StandardReferenceToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoO1StandardReferenceToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoO1StandardReferenceToVideoOutput

export const zGetFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoO1StandardImageToVideoData = z.object({
  body: zSchemaKlingVideoO1StandardImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoO1StandardImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoO1StandardImageToVideoOutput

export const zGetFalAiCreatifyAuroraRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiCreatifyAuroraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiCreatifyAuroraRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiCreatifyAuroraRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiCreatifyAuroraData = z.object({
  body: zSchemaCreatifyAuroraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiCreatifyAuroraResponse = zSchemaQueueStatus

export const zGetFalAiCreatifyAuroraRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiCreatifyAuroraRequestsByRequestIdResponse =
  zSchemaCreatifyAuroraOutput

export const zGetFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoAiAvatarV2ProData = z.object({
  body: zSchemaKlingVideoAiAvatarV2ProInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoAiAvatarV2ProResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdResponse =
  zSchemaKlingVideoAiAvatarV2ProOutput

export const zGetFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoAiAvatarV2StandardData = z.object({
  body: zSchemaKlingVideoAiAvatarV2StandardInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoAiAvatarV2StandardResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdResponse =
  zSchemaKlingVideoAiAvatarV2StandardOutput

export const zGetFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV26ProImageToVideoData = z.object({
  body: zSchemaKlingVideoV26ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV26ProImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV26ProImageToVideoOutput

export const zGetFalAiPixverseV55EffectsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV55EffectsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV55EffectsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV55EffectsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseV55EffectsData = z.object({
  body: zSchemaPixverseV55EffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV55EffectsResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV55EffectsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV55EffectsRequestsByRequestIdResponse =
  zSchemaPixverseV55EffectsOutput

export const zGetFalAiPixverseV55TransitionRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV55TransitionRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV55TransitionRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV55TransitionRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseV55TransitionData = z.object({
  body: zSchemaPixverseV55TransitionInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV55TransitionResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV55TransitionRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV55TransitionRequestsByRequestIdResponse =
  zSchemaPixverseV55TransitionOutput

export const zGetFalAiPixverseV55ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV55ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV55ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV55ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPixverseV55ImageToVideoData = z.object({
  body: zSchemaPixverseV55ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV55ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV55ImageToVideoRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV55ImageToVideoRequestsByRequestIdResponse =
  zSchemaPixverseV55ImageToVideoOutput

export const zGetFalAiKlingVideoO1ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoO1ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoO1ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoO1ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoO1ImageToVideoData = z.object({
  body: zSchemaKlingVideoO1ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoO1ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoO1ImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoO1ImageToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoO1ImageToVideoOutput

export const zGetFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoO1ReferenceToVideoData = z.object({
  body: zSchemaKlingVideoO1ReferenceToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoO1ReferenceToVideoResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoO1ReferenceToVideoOutput

export const zGetFalAiLtx2ImageToVideoFastRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx2ImageToVideoFastRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx2ImageToVideoFastRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx2ImageToVideoFastRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtx2ImageToVideoFastData = z.object({
  body: zSchemaLtx2ImageToVideoFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx2ImageToVideoFastResponse = zSchemaQueueStatus

export const zGetFalAiLtx2ImageToVideoFastRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtx2ImageToVideoFastRequestsByRequestIdResponse =
  zSchemaLtx2ImageToVideoFastOutput

export const zGetFalAiLtx2ImageToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiLtx2ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx2ImageToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx2ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtx2ImageToVideoData = z.object({
  body: zSchemaLtx2ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx2ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtx2ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtx2ImageToVideoRequestsByRequestIdResponse =
  zSchemaLtx2ImageToVideoOutput

export const zGetBytedanceLynxRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetBytedanceLynxRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutBytedanceLynxRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutBytedanceLynxRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostBytedanceLynxData = z.object({
  body: zSchemaLynxInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostBytedanceLynxResponse = zSchemaQueueStatus

export const zGetBytedanceLynxRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetBytedanceLynxRequestsByRequestIdResponse = zSchemaLynxOutput

export const zGetFalAiPixverseSwapRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiPixverseSwapRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseSwapRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseSwapRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseSwapData = z.object({
  body: zSchemaPixverseSwapInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseSwapResponse = zSchemaQueueStatus

export const zGetFalAiPixverseSwapRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseSwapRequestsByRequestIdResponse =
  zSchemaPixverseSwapOutput

export const zGetFalAiPikaV22PikaframesRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiPikaV22PikaframesRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPikaV22PikaframesRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV22PikaframesRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPikaV22PikaframesData = z.object({
  body: zSchemaPikaV22PikaframesInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPikaV22PikaframesResponse = zSchemaQueueStatus

export const zGetFalAiPikaV22PikaframesRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPikaV22PikaframesRequestsByRequestIdResponse =
  zSchemaPikaV22PikaframesOutput

export const zGetFalAiLongcatVideoImageToVideo720pRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLongcatVideoImageToVideo720pRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLongcatVideoImageToVideo720pRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLongcatVideoImageToVideo720pRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLongcatVideoImageToVideo720pData = z.object({
  body: zSchemaLongcatVideoImageToVideo720pInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLongcatVideoImageToVideo720pResponse = zSchemaQueueStatus

export const zGetFalAiLongcatVideoImageToVideo720pRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLongcatVideoImageToVideo720pRequestsByRequestIdResponse =
  zSchemaLongcatVideoImageToVideo720pOutput

export const zGetFalAiLongcatVideoImageToVideo480pRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLongcatVideoImageToVideo480pRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLongcatVideoImageToVideo480pRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLongcatVideoImageToVideo480pRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLongcatVideoImageToVideo480pData = z.object({
  body: zSchemaLongcatVideoImageToVideo480pInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLongcatVideoImageToVideo480pResponse = zSchemaQueueStatus

export const zGetFalAiLongcatVideoImageToVideo480pRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLongcatVideoImageToVideo480pRequestsByRequestIdResponse =
  zSchemaLongcatVideoImageToVideo480pOutput

export const zGetFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLongcatVideoDistilledImageToVideo720pData = z.object({
  body: zSchemaLongcatVideoDistilledImageToVideo720pInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLongcatVideoDistilledImageToVideo720pResponse =
  zSchemaQueueStatus

export const zGetFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdResponse =
  zSchemaLongcatVideoDistilledImageToVideo720pOutput

export const zGetFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLongcatVideoDistilledImageToVideo480pData = z.object({
  body: zSchemaLongcatVideoDistilledImageToVideo480pInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLongcatVideoDistilledImageToVideo480pResponse =
  zSchemaQueueStatus

export const zGetFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdResponse =
  zSchemaLongcatVideoDistilledImageToVideo480pOutput

export const zGetFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxHailuo23FastStandardImageToVideoData = z.object({
  body: zSchemaMinimaxHailuo23FastStandardImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo23FastStandardImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdResponse =
  zSchemaMinimaxHailuo23FastStandardImageToVideoOutput

export const zGetFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxHailuo23StandardImageToVideoData = z.object({
  body: zSchemaMinimaxHailuo23StandardImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo23StandardImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdResponse =
  zSchemaMinimaxHailuo23StandardImageToVideoOutput

export const zGetFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxHailuo23FastProImageToVideoData = z.object({
  body: zSchemaMinimaxHailuo23FastProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo23FastProImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdResponse =
  zSchemaMinimaxHailuo23FastProImageToVideoOutput

export const zGetFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiBytedanceSeedanceV1ProFastImageToVideoData = z.object({
  body: zSchemaBytedanceSeedanceV1ProFastImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiBytedanceSeedanceV1ProFastImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdResponse =
  zSchemaBytedanceSeedanceV1ProFastImageToVideoOutput

export const zGetFalAiViduQ2ImageToVideoTurboRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiViduQ2ImageToVideoTurboRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiViduQ2ImageToVideoTurboRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ2ImageToVideoTurboRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiViduQ2ImageToVideoTurboData = z.object({
  body: zSchemaViduQ2ImageToVideoTurboInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiViduQ2ImageToVideoTurboResponse = zSchemaQueueStatus

export const zGetFalAiViduQ2ImageToVideoTurboRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiViduQ2ImageToVideoTurboRequestsByRequestIdResponse =
  zSchemaViduQ2ImageToVideoTurboOutput

export const zGetFalAiViduQ2ImageToVideoProRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiViduQ2ImageToVideoProRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiViduQ2ImageToVideoProRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ2ImageToVideoProRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiViduQ2ImageToVideoProData = z.object({
  body: zSchemaViduQ2ImageToVideoProInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiViduQ2ImageToVideoProResponse = zSchemaQueueStatus

export const zGetFalAiViduQ2ImageToVideoProRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiViduQ2ImageToVideoProRequestsByRequestIdResponse =
  zSchemaViduQ2ImageToVideoProOutput

export const zGetFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV25TurboStandardImageToVideoData = z.object({
  body: zSchemaKlingVideoV25TurboStandardImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV25TurboStandardImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV25TurboStandardImageToVideoOutput

export const zGetFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiVeo31FastFirstLastFrameToVideoData = z.object({
  body: zSchemaVeo31FastFirstLastFrameToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVeo31FastFirstLastFrameToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdResponse =
  zSchemaVeo31FastFirstLastFrameToVideoOutput

export const zGetFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiVeo31FirstLastFrameToVideoData = z.object({
  body: zSchemaVeo31FirstLastFrameToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVeo31FirstLastFrameToVideoResponse = zSchemaQueueStatus

export const zGetFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdResponse =
  zSchemaVeo31FirstLastFrameToVideoOutput

export const zGetFalAiVeo31ReferenceToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiVeo31ReferenceToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVeo31ReferenceToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo31ReferenceToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiVeo31ReferenceToVideoData = z.object({
  body: zSchemaVeo31ReferenceToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVeo31ReferenceToVideoResponse = zSchemaQueueStatus

export const zGetFalAiVeo31ReferenceToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiVeo31ReferenceToVideoRequestsByRequestIdResponse =
  zSchemaVeo31ReferenceToVideoOutput

export const zGetFalAiVeo31FastImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiVeo31FastImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVeo31FastImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo31FastImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiVeo31FastImageToVideoData = z.object({
  body: zSchemaVeo31FastImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVeo31FastImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiVeo31FastImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiVeo31FastImageToVideoRequestsByRequestIdResponse =
  zSchemaVeo31FastImageToVideoOutput

export const zGetFalAiVeo31ImageToVideoRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiVeo31ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVeo31ImageToVideoRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo31ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiVeo31ImageToVideoData = z.object({
  body: zSchemaVeo31ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVeo31ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiVeo31ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiVeo31ImageToVideoRequestsByRequestIdResponse =
  zSchemaVeo31ImageToVideoOutput

export const zGetFalAiSora2ImageToVideoProRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiSora2ImageToVideoProRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSora2ImageToVideoProRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiSora2ImageToVideoProRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSora2ImageToVideoProData = z.object({
  body: zSchemaSora2ImageToVideoProInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSora2ImageToVideoProResponse = zSchemaQueueStatus

export const zGetFalAiSora2ImageToVideoProRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSora2ImageToVideoProRequestsByRequestIdResponse =
  zSchemaSora2ImageToVideoProOutput

export const zGetFalAiSora2ImageToVideoRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiSora2ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSora2ImageToVideoRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiSora2ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSora2ImageToVideoData = z.object({
  body: zSchemaSora2ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSora2ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiSora2ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSora2ImageToVideoRequestsByRequestIdResponse =
  zSchemaSora2ImageToVideoOutput

export const zGetFalAiOviImageToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiOviImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiOviImageToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiOviImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiOviImageToVideoData = z.object({
  body: zSchemaOviImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiOviImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiOviImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiOviImageToVideoRequestsByRequestIdResponse =
  zSchemaOviImageToVideoOutput

export const zGetVeedFabric10FastRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetVeedFabric10FastRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutVeedFabric10FastRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutVeedFabric10FastRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostVeedFabric10FastData = z.object({
  body: zSchemaFabric10FastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostVeedFabric10FastResponse = zSchemaQueueStatus

export const zGetVeedFabric10FastRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetVeedFabric10FastRequestsByRequestIdResponse =
  zSchemaFabric10FastOutput

export const zGetFalAiBytedanceOmnihumanV15RequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiBytedanceOmnihumanV15RequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiBytedanceOmnihumanV15RequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceOmnihumanV15RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiBytedanceOmnihumanV15Data = z.object({
  body: zSchemaBytedanceOmnihumanV15Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiBytedanceOmnihumanV15Response = zSchemaQueueStatus

export const zGetFalAiBytedanceOmnihumanV15RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceOmnihumanV15RequestsByRequestIdResponse =
  zSchemaBytedanceOmnihumanV15Output

export const zGetVeedFabric10RequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetVeedFabric10RequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutVeedFabric10RequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutVeedFabric10RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostVeedFabric10Data = z.object({
  body: zSchemaFabric10Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostVeedFabric10Response = zSchemaQueueStatus

export const zGetVeedFabric10RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetVeedFabric10RequestsByRequestIdResponse = zSchemaFabric10Output

export const zGetFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV1StandardAiAvatarData = z.object({
  body: zSchemaKlingVideoV1StandardAiAvatarInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV1StandardAiAvatarResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdResponse =
  zSchemaKlingVideoV1StandardAiAvatarOutput

export const zGetFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV1ProAiAvatarData = z.object({
  body: zSchemaKlingVideoV1ProAiAvatarInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV1ProAiAvatarResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdResponse =
  zSchemaKlingVideoV1ProAiAvatarOutput

export const zGetDecartLucy14bImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetDecartLucy14bImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutDecartLucy14bImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutDecartLucy14bImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostDecartLucy14bImageToVideoData = z.object({
  body: zSchemaLucy14bImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostDecartLucy14bImageToVideoResponse = zSchemaQueueStatus

export const zGetDecartLucy14bImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetDecartLucy14bImageToVideoRequestsByRequestIdResponse =
  zSchemaLucy14bImageToVideoOutput

export const zGetFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiBytedanceSeedanceV1LiteReferenceToVideoData = z.object({
  body: zSchemaBytedanceSeedanceV1LiteReferenceToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiBytedanceSeedanceV1LiteReferenceToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdResponse =
  zSchemaBytedanceSeedanceV1LiteReferenceToVideoOutput

export const zGetFalAiWanAtiRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanAtiRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanAtiRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanAtiRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanAtiData = z.object({
  body: zSchemaWanAtiInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanAtiResponse = zSchemaQueueStatus

export const zGetFalAiWanAtiRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanAtiRequestsByRequestIdResponse = zSchemaWanAtiOutput

export const zGetFalAiDecartLucy5bImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiDecartLucy5bImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiDecartLucy5bImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiDecartLucy5bImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiDecartLucy5bImageToVideoData = z.object({
  body: zSchemaDecartLucy5bImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiDecartLucy5bImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiDecartLucy5bImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiDecartLucy5bImageToVideoRequestsByRequestIdResponse =
  zSchemaDecartLucy5bImageToVideoOutput

export const zGetFalAiPixverseV5TransitionRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV5TransitionRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV5TransitionRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV5TransitionRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseV5TransitionData = z.object({
  body: zSchemaPixverseV5TransitionInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV5TransitionResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV5TransitionRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV5TransitionRequestsByRequestIdResponse =
  zSchemaPixverseV5TransitionOutput

export const zGetFalAiPixverseV5EffectsRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiPixverseV5EffectsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV5EffectsRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV5EffectsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseV5EffectsData = z.object({
  body: zSchemaPixverseV5EffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV5EffectsResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV5EffectsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV5EffectsRequestsByRequestIdResponse =
  zSchemaPixverseV5EffectsOutput

export const zGetFalAiPixverseV5ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV5ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV5ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV5ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPixverseV5ImageToVideoData = z.object({
  body: zSchemaPixverseV5ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV5ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV5ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV5ImageToVideoRequestsByRequestIdResponse =
  zSchemaPixverseV5ImageToVideoOutput

export const zGetMoonvalleyMareyI2vRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetMoonvalleyMareyI2vRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutMoonvalleyMareyI2vRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutMoonvalleyMareyI2vRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostMoonvalleyMareyI2vData = z.object({
  body: zSchemaMareyI2vInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostMoonvalleyMareyI2vResponse = zSchemaQueueStatus

export const zGetMoonvalleyMareyI2vRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetMoonvalleyMareyI2vRequestsByRequestIdResponse =
  zSchemaMareyI2vOutput

export const zGetFalAiBytedanceVideoStylizeRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiBytedanceVideoStylizeRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiBytedanceVideoStylizeRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceVideoStylizeRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiBytedanceVideoStylizeData = z.object({
  body: zSchemaBytedanceVideoStylizeInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiBytedanceVideoStylizeResponse = zSchemaQueueStatus

export const zGetFalAiBytedanceVideoStylizeRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceVideoStylizeRequestsByRequestIdResponse =
  zSchemaBytedanceVideoStylizeOutput

export const zGetFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWanV22A14bImageToVideoLoraData = z.object({
  body: zSchemaWanV22A14bImageToVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanV22A14bImageToVideoLoraResponse = zSchemaQueueStatus

export const zGetFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdResponse =
  zSchemaWanV22A14bImageToVideoLoraOutput

export const zGetFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxHailuo02FastImageToVideoData = z.object({
  body: zSchemaMinimaxHailuo02FastImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo02FastImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdResponse =
  zSchemaMinimaxHailuo02FastImageToVideoOutput

export const zGetFalAiVeo3ImageToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiVeo3ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVeo3ImageToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo3ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiVeo3ImageToVideoData = z.object({
  body: zSchemaVeo3ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVeo3ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiVeo3ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiVeo3ImageToVideoRequestsByRequestIdResponse =
  zSchemaVeo3ImageToVideoOutput

export const zGetFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWanV22A14bImageToVideoTurboData = z.object({
  body: zSchemaWanV22A14bImageToVideoTurboInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanV22A14bImageToVideoTurboResponse = zSchemaQueueStatus

export const zGetFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdResponse =
  zSchemaWanV22A14bImageToVideoTurboOutput

export const zGetFalAiWanV225bImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanV225bImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanV225bImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV225bImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanV225bImageToVideoData = z.object({
  body: zSchemaWanV225bImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanV225bImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiWanV225bImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanV225bImageToVideoRequestsByRequestIdResponse =
  zSchemaWanV225bImageToVideoOutput

export const zGetFalAiWanV22A14bImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanV22A14bImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanV22A14bImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV22A14bImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWanV22A14bImageToVideoData = z.object({
  body: zSchemaWanV22A14bImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanV22A14bImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiWanV22A14bImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanV22A14bImageToVideoRequestsByRequestIdResponse =
  zSchemaWanV22A14bImageToVideoOutput

export const zGetFalAiBytedanceOmnihumanRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiBytedanceOmnihumanRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiBytedanceOmnihumanRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceOmnihumanRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiBytedanceOmnihumanData = z.object({
  body: zSchemaBytedanceOmnihumanInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiBytedanceOmnihumanResponse = zSchemaQueueStatus

export const zGetFalAiBytedanceOmnihumanRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceOmnihumanRequestsByRequestIdResponse =
  zSchemaBytedanceOmnihumanOutput

export const zGetFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtxv13B098DistilledImageToVideoData = z.object({
  body: zSchemaLtxv13B098DistilledImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxv13B098DistilledImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdResponse =
  zSchemaLtxv13B098DistilledImageToVideoOutput

export const zGetFalAiVeo3FastImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiVeo3FastImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVeo3FastImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo3FastImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiVeo3FastImageToVideoData = z.object({
  body: zSchemaVeo3FastImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVeo3FastImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiVeo3FastImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiVeo3FastImageToVideoRequestsByRequestIdResponse =
  zSchemaVeo3FastImageToVideoOutput

export const zGetFalAiViduQ1ReferenceToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiViduQ1ReferenceToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiViduQ1ReferenceToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ1ReferenceToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiViduQ1ReferenceToVideoData = z.object({
  body: zSchemaViduQ1ReferenceToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiViduQ1ReferenceToVideoResponse = zSchemaQueueStatus

export const zGetFalAiViduQ1ReferenceToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiViduQ1ReferenceToVideoRequestsByRequestIdResponse =
  zSchemaViduQ1ReferenceToVideoOutput

export const zGetFalAiAiAvatarSingleTextRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiAiAvatarSingleTextRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiAiAvatarSingleTextRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiAiAvatarSingleTextRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiAiAvatarSingleTextData = z.object({
  body: zSchemaAiAvatarSingleTextInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiAiAvatarSingleTextResponse = zSchemaQueueStatus

export const zGetFalAiAiAvatarSingleTextRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiAiAvatarSingleTextRequestsByRequestIdResponse =
  zSchemaAiAvatarSingleTextOutput

export const zGetFalAiAiAvatarRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiAiAvatarRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiAiAvatarRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiAiAvatarRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiAiAvatarData = z.object({
  body: zSchemaAiAvatarInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiAiAvatarResponse = zSchemaQueueStatus

export const zGetFalAiAiAvatarRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiAiAvatarRequestsByRequestIdResponse =
  zSchemaAiAvatarOutput

export const zGetFalAiAiAvatarMultiTextRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiAiAvatarMultiTextRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiAiAvatarMultiTextRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiAiAvatarMultiTextRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiAiAvatarMultiTextData = z.object({
  body: zSchemaAiAvatarMultiTextInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiAiAvatarMultiTextResponse = zSchemaQueueStatus

export const zGetFalAiAiAvatarMultiTextRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiAiAvatarMultiTextRequestsByRequestIdResponse =
  zSchemaAiAvatarMultiTextOutput

export const zGetFalAiAiAvatarMultiRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiAiAvatarMultiRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiAiAvatarMultiRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiAiAvatarMultiRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiAiAvatarMultiData = z.object({
  body: zSchemaAiAvatarMultiInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiAiAvatarMultiResponse = zSchemaQueueStatus

export const zGetFalAiAiAvatarMultiRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiAiAvatarMultiRequestsByRequestIdResponse =
  zSchemaAiAvatarMultiOutput

export const zGetFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxHailuo02ProImageToVideoData = z.object({
  body: zSchemaMinimaxHailuo02ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo02ProImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdResponse =
  zSchemaMinimaxHailuo02ProImageToVideoOutput

export const zGetFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiBytedanceSeedanceV1LiteImageToVideoData = z.object({
  body: zSchemaBytedanceSeedanceV1LiteImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiBytedanceSeedanceV1LiteImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdResponse =
  zSchemaBytedanceSeedanceV1LiteImageToVideoOutput

export const zGetFalAiHunyuanAvatarRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiHunyuanAvatarRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiHunyuanAvatarRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanAvatarRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiHunyuanAvatarData = z.object({
  body: zSchemaHunyuanAvatarInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiHunyuanAvatarResponse = zSchemaQueueStatus

export const zGetFalAiHunyuanAvatarRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanAvatarRequestsByRequestIdResponse =
  zSchemaHunyuanAvatarOutput

export const zGetFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV21ProImageToVideoData = z.object({
  body: zSchemaKlingVideoV21ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV21ProImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV21ProImageToVideoOutput

export const zGetFalAiHunyuanPortraitRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiHunyuanPortraitRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiHunyuanPortraitRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanPortraitRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiHunyuanPortraitData = z.object({
  body: zSchemaHunyuanPortraitInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiHunyuanPortraitResponse = zSchemaQueueStatus

export const zGetFalAiHunyuanPortraitRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanPortraitRequestsByRequestIdResponse =
  zSchemaHunyuanPortraitOutput

export const zGetFalAiKlingVideoV16StandardElementsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV16StandardElementsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV16StandardElementsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV16StandardElementsRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV16StandardElementsData = z.object({
  body: zSchemaKlingVideoV16StandardElementsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV16StandardElementsResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoV16StandardElementsRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV16StandardElementsRequestsByRequestIdResponse =
  zSchemaKlingVideoV16StandardElementsOutput

export const zGetFalAiKlingVideoV16ProElementsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV16ProElementsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV16ProElementsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV16ProElementsRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV16ProElementsData = z.object({
  body: zSchemaKlingVideoV16ProElementsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV16ProElementsResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoV16ProElementsRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV16ProElementsRequestsByRequestIdResponse =
  zSchemaKlingVideoV16ProElementsOutput

export const zGetFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtxVideo13bDistilledImageToVideoData = z.object({
  body: zSchemaLtxVideo13bDistilledImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxVideo13bDistilledImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdResponse =
  zSchemaLtxVideo13bDistilledImageToVideoOutput

export const zGetFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtxVideo13bDevImageToVideoData = z.object({
  body: zSchemaLtxVideo13bDevImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxVideo13bDevImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdResponse =
  zSchemaLtxVideo13bDevImageToVideoOutput

export const zGetFalAiLtxVideoLoraImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxVideoLoraImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxVideoLoraImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideoLoraImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtxVideoLoraImageToVideoData = z.object({
  body: zSchemaLtxVideoLoraImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxVideoLoraImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtxVideoLoraImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideoLoraImageToVideoRequestsByRequestIdResponse =
  zSchemaLtxVideoLoraImageToVideoOutput

export const zGetFalAiPixverseV45TransitionRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV45TransitionRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV45TransitionRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV45TransitionRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseV45TransitionData = z.object({
  body: zSchemaPixverseV45TransitionInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV45TransitionResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV45TransitionRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV45TransitionRequestsByRequestIdResponse =
  zSchemaPixverseV45TransitionOutput

export const zGetFalAiPixverseV45ImageToVideoFastRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV45ImageToVideoFastRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV45ImageToVideoFastRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV45ImageToVideoFastRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPixverseV45ImageToVideoFastData = z.object({
  body: zSchemaPixverseV45ImageToVideoFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV45ImageToVideoFastResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV45ImageToVideoFastRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV45ImageToVideoFastRequestsByRequestIdResponse =
  zSchemaPixverseV45ImageToVideoFastOutput

export const zGetFalAiPixverseV45EffectsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV45EffectsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV45EffectsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV45EffectsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseV45EffectsData = z.object({
  body: zSchemaPixverseV45EffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV45EffectsResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV45EffectsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV45EffectsRequestsByRequestIdResponse =
  zSchemaPixverseV45EffectsOutput

export const zGetFalAiHunyuanCustomRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiHunyuanCustomRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiHunyuanCustomRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanCustomRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiHunyuanCustomData = z.object({
  body: zSchemaHunyuanCustomInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiHunyuanCustomResponse = zSchemaQueueStatus

export const zGetFalAiHunyuanCustomRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanCustomRequestsByRequestIdResponse =
  zSchemaHunyuanCustomOutput

export const zGetFalAiFramepackF1RequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiFramepackF1RequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiFramepackF1RequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiFramepackF1RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiFramepackF1Data = z.object({
  body: zSchemaFramepackF1Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiFramepackF1Response = zSchemaQueueStatus

export const zGetFalAiFramepackF1RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiFramepackF1RequestsByRequestIdResponse =
  zSchemaFramepackF1Output

export const zGetFalAiViduQ1StartEndToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiViduQ1StartEndToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiViduQ1StartEndToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ1StartEndToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiViduQ1StartEndToVideoData = z.object({
  body: zSchemaViduQ1StartEndToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiViduQ1StartEndToVideoResponse = zSchemaQueueStatus

export const zGetFalAiViduQ1StartEndToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiViduQ1StartEndToVideoRequestsByRequestIdResponse =
  zSchemaViduQ1StartEndToVideoOutput

export const zGetFalAiViduQ1ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiViduQ1ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiViduQ1ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ1ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiViduQ1ImageToVideoData = z.object({
  body: zSchemaViduQ1ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiViduQ1ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiViduQ1ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiViduQ1ImageToVideoRequestsByRequestIdResponse =
  zSchemaViduQ1ImageToVideoOutput

export const zGetFalAiMagiImageToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiMagiImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMagiImageToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiMagiImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiMagiImageToVideoData = z.object({
  body: zSchemaMagiImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMagiImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiMagiImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiMagiImageToVideoRequestsByRequestIdResponse =
  zSchemaMagiImageToVideoOutput

export const zGetFalAiPixverseV4EffectsRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiPixverseV4EffectsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV4EffectsRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV4EffectsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseV4EffectsData = z.object({
  body: zSchemaPixverseV4EffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV4EffectsResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV4EffectsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV4EffectsRequestsByRequestIdResponse =
  zSchemaPixverseV4EffectsOutput

export const zGetFalAiMagiDistilledImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMagiDistilledImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMagiDistilledImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMagiDistilledImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMagiDistilledImageToVideoData = z.object({
  body: zSchemaMagiDistilledImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMagiDistilledImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiMagiDistilledImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMagiDistilledImageToVideoRequestsByRequestIdResponse =
  zSchemaMagiDistilledImageToVideoOutput

export const zGetFalAiFramepackFlf2vRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiFramepackFlf2vRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiFramepackFlf2vRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiFramepackFlf2vRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiFramepackFlf2vData = z.object({
  body: zSchemaFramepackFlf2vInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiFramepackFlf2vResponse = zSchemaQueueStatus

export const zGetFalAiFramepackFlf2vRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiFramepackFlf2vRequestsByRequestIdResponse =
  zSchemaFramepackFlf2vOutput

export const zGetFalAiWanFlf2vRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanFlf2vRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanFlf2vRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanFlf2vRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanFlf2vData = z.object({
  body: zSchemaWanFlf2vInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanFlf2vResponse = zSchemaQueueStatus

export const zGetFalAiWanFlf2vRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanFlf2vRequestsByRequestIdResponse =
  zSchemaWanFlf2vOutput

export const zGetFalAiFramepackRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiFramepackRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiFramepackRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiFramepackRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiFramepackData = z.object({
  body: zSchemaFramepackInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiFramepackResponse = zSchemaQueueStatus

export const zGetFalAiFramepackRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiFramepackRequestsByRequestIdResponse =
  zSchemaFramepackOutput

export const zGetFalAiPixverseV4ImageToVideoFastRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV4ImageToVideoFastRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV4ImageToVideoFastRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV4ImageToVideoFastRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPixverseV4ImageToVideoFastData = z.object({
  body: zSchemaPixverseV4ImageToVideoFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV4ImageToVideoFastResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV4ImageToVideoFastRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV4ImageToVideoFastRequestsByRequestIdResponse =
  zSchemaPixverseV4ImageToVideoFastOutput

export const zGetFalAiPixverseV4ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV4ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV4ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV4ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPixverseV4ImageToVideoData = z.object({
  body: zSchemaPixverseV4ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV4ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV4ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV4ImageToVideoRequestsByRequestIdResponse =
  zSchemaPixverseV4ImageToVideoOutput

export const zGetFalAiPixverseV35EffectsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV35EffectsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV35EffectsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV35EffectsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseV35EffectsData = z.object({
  body: zSchemaPixverseV35EffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV35EffectsResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV35EffectsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV35EffectsRequestsByRequestIdResponse =
  zSchemaPixverseV35EffectsOutput

export const zGetFalAiPixverseV35TransitionRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV35TransitionRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV35TransitionRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV35TransitionRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseV35TransitionData = z.object({
  body: zSchemaPixverseV35TransitionInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV35TransitionResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV35TransitionRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV35TransitionRequestsByRequestIdResponse =
  zSchemaPixverseV35TransitionOutput

export const zGetFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLumaDreamMachineRay2FlashImageToVideoData = z.object({
  body: zSchemaLumaDreamMachineRay2FlashImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLumaDreamMachineRay2FlashImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdResponse =
  zSchemaLumaDreamMachineRay2FlashImageToVideoOutput

export const zGetFalAiPikaV15PikaffectsRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiPikaV15PikaffectsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPikaV15PikaffectsRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV15PikaffectsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPikaV15PikaffectsData = z.object({
  body: zSchemaPikaV15PikaffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPikaV15PikaffectsResponse = zSchemaQueueStatus

export const zGetFalAiPikaV15PikaffectsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPikaV15PikaffectsRequestsByRequestIdResponse =
  zSchemaPikaV15PikaffectsOutput

export const zGetFalAiPikaV2TurboImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPikaV2TurboImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPikaV2TurboImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV2TurboImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPikaV2TurboImageToVideoData = z.object({
  body: zSchemaPikaV2TurboImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPikaV2TurboImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPikaV2TurboImageToVideoRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiPikaV2TurboImageToVideoRequestsByRequestIdResponse =
  zSchemaPikaV2TurboImageToVideoOutput

export const zGetFalAiPikaV22PikascenesRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiPikaV22PikascenesRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPikaV22PikascenesRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV22PikascenesRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPikaV22PikascenesData = z.object({
  body: zSchemaPikaV22PikascenesInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPikaV22PikascenesResponse = zSchemaQueueStatus

export const zGetFalAiPikaV22PikascenesRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPikaV22PikascenesRequestsByRequestIdResponse =
  zSchemaPikaV22PikascenesOutput

export const zGetFalAiPikaV22ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPikaV22ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPikaV22ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV22ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPikaV22ImageToVideoData = z.object({
  body: zSchemaPikaV22ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPikaV22ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPikaV22ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPikaV22ImageToVideoRequestsByRequestIdResponse =
  zSchemaPikaV22ImageToVideoOutput

export const zGetFalAiPikaV21ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPikaV21ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPikaV21ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV21ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPikaV21ImageToVideoData = z.object({
  body: zSchemaPikaV21ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPikaV21ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPikaV21ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPikaV21ImageToVideoRequestsByRequestIdResponse =
  zSchemaPikaV21ImageToVideoOutput

export const zGetFalAiViduImageToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiViduImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiViduImageToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiViduImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiViduImageToVideoData = z.object({
  body: zSchemaViduImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiViduImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiViduImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiViduImageToVideoRequestsByRequestIdResponse =
  zSchemaViduImageToVideoOutput

export const zGetFalAiViduStartEndToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiViduStartEndToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiViduStartEndToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiViduStartEndToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiViduStartEndToVideoData = z.object({
  body: zSchemaViduStartEndToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiViduStartEndToVideoResponse = zSchemaQueueStatus

export const zGetFalAiViduStartEndToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiViduStartEndToVideoRequestsByRequestIdResponse =
  zSchemaViduStartEndToVideoOutput

export const zGetFalAiViduReferenceToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiViduReferenceToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiViduReferenceToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiViduReferenceToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiViduReferenceToVideoData = z.object({
  body: zSchemaViduReferenceToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiViduReferenceToVideoResponse = zSchemaQueueStatus

export const zGetFalAiViduReferenceToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiViduReferenceToVideoRequestsByRequestIdResponse =
  zSchemaViduReferenceToVideoOutput

export const zGetFalAiViduTemplateToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiViduTemplateToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiViduTemplateToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiViduTemplateToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiViduTemplateToVideoData = z.object({
  body: zSchemaViduTemplateToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiViduTemplateToVideoResponse = zSchemaQueueStatus

export const zGetFalAiViduTemplateToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiViduTemplateToVideoRequestsByRequestIdResponse =
  zSchemaViduTemplateToVideoOutput

export const zGetFalAiWanI2vLoraRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanI2vLoraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanI2vLoraRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanI2vLoraRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanI2vLoraData = z.object({
  body: zSchemaWanI2vLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanI2vLoraResponse = zSchemaQueueStatus

export const zGetFalAiWanI2vLoraRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanI2vLoraRequestsByRequestIdResponse =
  zSchemaWanI2vLoraOutput

export const zGetFalAiHunyuanVideoImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiHunyuanVideoImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiHunyuanVideoImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanVideoImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiHunyuanVideoImageToVideoData = z.object({
  body: zSchemaHunyuanVideoImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiHunyuanVideoImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiHunyuanVideoImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanVideoImageToVideoRequestsByRequestIdResponse =
  zSchemaHunyuanVideoImageToVideoOutput

export const zGetFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxVideo01DirectorImageToVideoData = z.object({
  body: zSchemaMinimaxVideo01DirectorImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxVideo01DirectorImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdResponse =
  zSchemaMinimaxVideo01DirectorImageToVideoOutput

export const zGetFalAiSkyreelsI2vRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiSkyreelsI2vRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSkyreelsI2vRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiSkyreelsI2vRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSkyreelsI2vData = z.object({
  body: zSchemaSkyreelsI2vInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSkyreelsI2vResponse = zSchemaQueueStatus

export const zGetFalAiSkyreelsI2vRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSkyreelsI2vRequestsByRequestIdResponse =
  zSchemaSkyreelsI2vOutput

export const zGetFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLumaDreamMachineRay2ImageToVideoData = z.object({
  body: zSchemaLumaDreamMachineRay2ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLumaDreamMachineRay2ImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdResponse =
  zSchemaLumaDreamMachineRay2ImageToVideoOutput

export const zGetFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiHunyuanVideoImg2VidLoraData = z.object({
  body: zSchemaHunyuanVideoImg2VidLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiHunyuanVideoImg2VidLoraResponse = zSchemaQueueStatus

export const zGetFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdResponse =
  zSchemaHunyuanVideoImg2VidLoraOutput

export const zGetFalAiPixverseV35ImageToVideoFastRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV35ImageToVideoFastRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV35ImageToVideoFastRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV35ImageToVideoFastRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPixverseV35ImageToVideoFastData = z.object({
  body: zSchemaPixverseV35ImageToVideoFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV35ImageToVideoFastResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV35ImageToVideoFastRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV35ImageToVideoFastRequestsByRequestIdResponse =
  zSchemaPixverseV35ImageToVideoFastOutput

export const zGetFalAiPixverseV35ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV35ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV35ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV35ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPixverseV35ImageToVideoData = z.object({
  body: zSchemaPixverseV35ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV35ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV35ImageToVideoRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV35ImageToVideoRequestsByRequestIdResponse =
  zSchemaPixverseV35ImageToVideoOutput

export const zGetFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxVideo01SubjectReferenceData = z.object({
  body: zSchemaMinimaxVideo01SubjectReferenceInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxVideo01SubjectReferenceResponse =
  zSchemaQueueStatus

export const zGetFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdResponse =
  zSchemaMinimaxVideo01SubjectReferenceOutput

export const zGetFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV16StandardImageToVideoData = z.object({
  body: zSchemaKlingVideoV16StandardImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV16StandardImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV16StandardImageToVideoOutput

export const zGetFalAiSadtalkerReferenceRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiSadtalkerReferenceRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSadtalkerReferenceRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiSadtalkerReferenceRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSadtalkerReferenceData = z.object({
  body: zSchemaSadtalkerReferenceInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSadtalkerReferenceResponse = zSchemaQueueStatus

export const zGetFalAiSadtalkerReferenceRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSadtalkerReferenceRequestsByRequestIdResponse =
  zSchemaSadtalkerReferenceOutput

export const zGetFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxVideo01LiveImageToVideoData = z.object({
  body: zSchemaMinimaxVideo01LiveImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxVideo01LiveImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdResponse =
  zSchemaMinimaxVideo01LiveImageToVideoOutput

export const zGetFalAiLtxVideoImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxVideoImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxVideoImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideoImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtxVideoImageToVideoData = z.object({
  body: zSchemaLtxVideoImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxVideoImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtxVideoImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideoImageToVideoRequestsByRequestIdResponse =
  zSchemaLtxVideoImageToVideoOutput

export const zGetFalAiCogvideox5bImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiCogvideox5bImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiCogvideox5bImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiCogvideox5bImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiCogvideox5bImageToVideoData = z.object({
  body: zSchemaCogvideox5bImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiCogvideox5bImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiCogvideox5bImageToVideoRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiCogvideox5bImageToVideoRequestsByRequestIdResponse =
  zSchemaCogvideox5bImageToVideoOutput

export const zGetFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV15ProImageToVideoData = z.object({
  body: zSchemaKlingVideoV15ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV15ProImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV15ProImageToVideoOutput

export const zGetFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV1StandardImageToVideoData = z.object({
  body: zSchemaKlingVideoV1StandardImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV1StandardImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV1StandardImageToVideoOutput

export const zGetFalAiStableVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiStableVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiStableVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiStableVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiStableVideoData = z.object({
  body: zSchemaStableVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiStableVideoResponse = zSchemaQueueStatus

export const zGetFalAiStableVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiStableVideoRequestsByRequestIdResponse =
  zSchemaStableVideoOutput

export const zGetFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiAmtInterpolationFrameInterpolationData = z.object({
  body: zSchemaAmtInterpolationFrameInterpolationInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiAmtInterpolationFrameInterpolationResponse =
  zSchemaQueueStatus

export const zGetFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdResponse =
  zSchemaAmtInterpolationFrameInterpolationOutput

export const zGetFalAiLivePortraitRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiLivePortraitRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLivePortraitRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiLivePortraitRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLivePortraitData = z.object({
  body: zSchemaLivePortraitInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLivePortraitResponse = zSchemaQueueStatus

export const zGetFalAiLivePortraitRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLivePortraitRequestsByRequestIdResponse =
  zSchemaLivePortraitOutput

export const zGetFalAiMusetalkRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiMusetalkRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMusetalkRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiMusetalkRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiMusetalkData = z.object({
  body: zSchemaMusetalkInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMusetalkResponse = zSchemaQueueStatus

export const zGetFalAiMusetalkRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiMusetalkRequestsByRequestIdResponse =
  zSchemaMusetalkOutput

export const zGetFalAiSadtalkerRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiSadtalkerRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSadtalkerRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiSadtalkerRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSadtalkerData = z.object({
  body: zSchemaSadtalkerInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSadtalkerResponse = zSchemaQueueStatus

export const zGetFalAiSadtalkerRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSadtalkerRequestsByRequestIdResponse =
  zSchemaSadtalkerOutput

export const zGetFalAiFastSvdLcmRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiFastSvdLcmRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiFastSvdLcmRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiFastSvdLcmRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiFastSvdLcmData = z.object({
  body: zSchemaFastSvdLcmInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiFastSvdLcmResponse = zSchemaQueueStatus

export const zGetFalAiFastSvdLcmRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiFastSvdLcmRequestsByRequestIdResponse =
  zSchemaFastSvdLcmOutput
