// This file is auto-generated by @hey-api/openapi-ts

export type ClientOptions = {
  baseUrl: 'https://queue.fal.run' | (string & {})
}

/**
 * Audio
 */
export type SchemaAudio = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * AudioOutput
 */
export type SchemaSfxV1VideoToAudioOutput = {
  /**
   * Audio
   *
   * The generated sound effects audio
   */
  audio: Array<SchemaAudio>
}

/**
 * Input
 */
export type SchemaSfxV1VideoToAudioInput = {
  /**
   * Num Samples
   *
   * The number of samples to generate from the model
   */
  num_samples?: number | unknown
  /**
   * Video Url
   *
   * A video url that can accessed from the API to process and add sound effects
   */
  video_url: string | Blob | File
  /**
   * Duration
   *
   * The duration of the generated audio in seconds
   */
  duration?: number | unknown
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used
   */
  seed?: number | unknown
  /**
   * Text Prompt
   *
   * Additional description to guide the model
   */
  text_prompt?: string | unknown
}

/**
 * VideoToAudioOutput
 */
export type SchemaKlingVideoVideoToAudioOutput = {
  /**
   * Audio
   *
   * The extracted/generated audio from the video in MP3 format
   */
  audio: SchemaFile
  /**
   * Video
   *
   * The original video with dubbed audio applied
   */
  video: SchemaFile
}

/**
 * File
 */
export type SchemaFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: string
}

/**
 * VideoToAudioInput
 */
export type SchemaKlingVideoVideoToAudioInput = {
  /**
   * Video Url
   *
   * The video URL to extract audio from. Only .mp4/.mov formats are supported. File size does not exceed 100MB. Video duration between 3.0s and 20.0s.
   */
  video_url: string | Blob | File
  /**
   * Asmr Mode
   *
   * Enable ASMR mode. This mode enhances detailed sound effects and is suitable for highly immersive content scenarios.
   */
  asmr_mode?: boolean
  /**
   * Background Music Prompt
   *
   * Background music prompt. Cannot exceed 200 characters.
   */
  background_music_prompt?: string
  /**
   * Sound Effect Prompt
   *
   * Sound effect prompt. Cannot exceed 200 characters.
   */
  sound_effect_prompt?: string
}

/**
 * Audio
 */
export type SchemaAudioOutput = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * AudioOutput
 */
export type SchemaSfxV15VideoToAudioOutput = {
  /**
   * Audio
   *
   * The generated sound effects audio
   */
  audio: Array<SchemaAudioOutput>
}

/**
 * Input
 */
export type SchemaSfxV15VideoToAudioInput = {
  /**
   * Num Samples
   *
   * The number of samples to generate from the model
   */
  num_samples?: number | unknown
  /**
   * Duration
   *
   * The duration of the generated audio in seconds
   */
  duration?: number | unknown
  /**
   * Start Offset
   *
   * The start offset in seconds to start the audio generation from
   */
  start_offset?: number | unknown
  /**
   * Video Url
   *
   * A video url that can accessed from the API to process and add sound effects
   */
  video_url: string | Blob | File
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used
   */
  seed?: number | unknown
  /**
   * Text Prompt
   *
   * Additional description to guide the model
   */
  text_prompt?: string | unknown
}

/**
 * SAMAudioVisualSeparateOutput
 *
 * Output for visual-prompted audio separation.
 */
export type SchemaSamAudioVisualSeparateOutput = {
  /**
   * Target
   *
   * The isolated target sound.
   */
  target: SchemaFile
  /**
   * Duration
   *
   * Duration of the output audio in seconds.
   */
  duration: number
  /**
   * Sample Rate
   *
   * Sample rate of the output audio in Hz.
   */
  sample_rate?: number
  /**
   * Residual
   *
   * Everything else in the audio.
   */
  residual: SchemaFile
}

/**
 * SAMAudioVisualInput
 *
 * Input for visual-prompted audio separation.
 */
export type SchemaSamAudioVisualSeparateInput = {
  /**
   * Prompt
   *
   * Text prompt to assist with separation. Use natural language to describe the target sound.
   */
  prompt?: string
  /**
   * Video Url
   *
   * URL of the video file to process (MP4, MOV, etc.)
   */
  video_url: string | Blob | File
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: 'fast' | 'balanced' | 'quality'
  /**
   * Mask Video Url
   *
   * URL of the mask video (binary mask indicating target object). Black=target, White=background.
   */
  mask_video_url?: string | Blob | File
  /**
   * Output Format
   *
   * Output audio format.
   */
  output_format?: 'wav' | 'mp3'
  /**
   * Reranking Candidates
   *
   * Number of candidates to generate and rank. Higher improves quality but increases latency and cost.
   */
  reranking_candidates?: number
}

/**
 * Output
 */
export type SchemaStableAudioOutput = {
  audio_file: SchemaFile
}

/**
 * Input
 */
export type SchemaStableAudioInput = {
  /**
   * Prompt
   *
   * The prompt to generate audio from
   */
  prompt: string
  /**
   * Steps
   *
   * The number of steps to denoise the audio for
   */
  steps?: number
  /**
   * Seconds Total
   *
   * The duration of the audio clip to generate
   */
  seconds_total?: number
  /**
   * Seconds Start
   *
   * The start point of the audio clip to generate
   */
  seconds_start?: number
}

/**
 * TTSOutput
 */
export type SchemaF5TtsOutput = {
  audio_url: SchemaAudioFile
}

/**
 * AudioFile
 */
export type SchemaAudioFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   */
  file_name?: string
  /**
   * Content Type
   */
  content_type?: string
  /**
   * Url
   */
  url: string
}

/**
 * TTSInput
 */
export type SchemaF5TtsInput = {
  /**
   * Reference Text for the Reference Audio
   *
   * The reference text to be used for TTS. If not provided, an ASR (Automatic Speech Recognition) model will be used to generate the reference text.
   */
  ref_text?: string
  /**
   * Remove Silence
   *
   * Whether to remove the silence from the audio file.
   */
  remove_silence?: boolean
  /**
   * Text to be converted to speech
   *
   * The text to be converted to speech.
   */
  gen_text: string
  /**
   * Model Type
   *
   * The name of the model to be used for TTS.
   */
  model_type: 'F5-TTS' | 'E2-TTS'
  /**
   * Reference Audio URL
   *
   * The URL of the reference audio file.
   */
  ref_audio_url: string | Blob | File
}

/**
 * MusicOutput
 */
export type SchemaMinimaxMusicOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: SchemaFile
}

/**
 * TextToMusicRequest
 */
export type SchemaMinimaxMusicInput = {
  /**
   * Prompt
   *
   * Lyrics with optional formatting. You can use a newline to separate each line of lyrics. You can use two newlines to add a pause between lines. You can use double hash marks (##) at the beginning and end of the lyrics to add accompaniment. Maximum 600 characters.
   */
  prompt: string
  /**
   * Reference Audio Url
   *
   * Reference song, should contain music and vocals. Must be a .wav or .mp3 file longer than 15 seconds.
   */
  reference_audio_url: string | Blob | File
}

/**
 * AudioOutput
 */
export type SchemaMmaudioV2TextToAudioOutput = {
  /**
   * Audio
   *
   * The generated audio.
   */
  audio: SchemaFile
}

/**
 * AudioInput
 */
export type SchemaMmaudioV2TextToAudioInput = {
  /**
   * Prompt
   *
   * The prompt to generate the audio for.
   */
  prompt: string
  /**
   * Num Steps
   *
   * The number of steps to generate the audio for.
   */
  num_steps?: number
  /**
   * Duration
   *
   * The duration of the audio to generate.
   */
  duration?: number
  /**
   * Cfg Strength
   *
   * The strength of Classifier Free Guidance.
   */
  cfg_strength?: number
  /**
   * Seed
   *
   * The seed for the random number generator
   */
  seed?: number
  /**
   * Mask Away Clip
   *
   * Whether to mask away the clip.
   */
  mask_away_clip?: boolean
  /**
   * Negative Prompt
   *
   * The negative prompt to generate the audio for.
   */
  negative_prompt?: string
}

/**
 * Output
 */
export type SchemaYueOutput = {
  /**
   * Audio
   *
   * Generated music file.
   */
  audio: SchemaFile
}

/**
 * TextToMusicInput
 */
export type SchemaYueInput = {
  /**
   * Lyrics
   *
   * The prompt to generate an image from. Must have two sections. Sections start with either [chorus] or a [verse].
   */
  lyrics: string
  /**
   * Genres
   *
   * The genres (separated by a space ' ') to guide the music generation.
   */
  genres: string
}

/**
 * ItalianOutput
 */
export type SchemaKokoroItalianOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: SchemaFile
}

/**
 * ItalianRequest
 */
export type SchemaKokoroItalianInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice: 'if_sara' | 'im_nicola'
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number
}

/**
 * ZonosOutput
 */
export type SchemaZonosOutput = {
  /**
   * Audio
   *
   * The generated audio
   */
  audio: SchemaFile
}

/**
 * ZonosInput
 */
export type SchemaZonosInput = {
  /**
   * Prompt
   *
   * The content generated using cloned voice.
   */
  prompt: string
  /**
   * Reference Audio Url
   *
   * The reference audio.
   */
  reference_audio_url: string | Blob | File
}

/**
 * AmEngOutput
 */
export type SchemaKokoroAmericanEnglishOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: SchemaFile
}

/**
 * AmEnglishRequest
 */
export type SchemaKokoroAmericanEnglishInput = {
  /**
   * Prompt
   */
  prompt?: string
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice?:
    | 'af_heart'
    | 'af_alloy'
    | 'af_aoede'
    | 'af_bella'
    | 'af_jessica'
    | 'af_kore'
    | 'af_nicole'
    | 'af_nova'
    | 'af_river'
    | 'af_sarah'
    | 'af_sky'
    | 'am_adam'
    | 'am_echo'
    | 'am_eric'
    | 'am_fenrir'
    | 'am_liam'
    | 'am_michael'
    | 'am_onyx'
    | 'am_puck'
    | 'am_santa'
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number
}

/**
 * JapaneseOutput
 */
export type SchemaKokoroJapaneseOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: SchemaFile
}

/**
 * JapaneseRequest
 */
export type SchemaKokoroJapaneseInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice: 'jf_alpha' | 'jf_gongitsune' | 'jf_nezumi' | 'jf_tebukuro' | 'jm_kumo'
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number
}

/**
 * FrenchOutput
 */
export type SchemaKokoroFrenchOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: SchemaFile
}

/**
 * FrenchRequest
 */
export type SchemaKokoroFrenchInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice: 'ff_siwis'
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number
}

/**
 * BrEngOutput
 */
export type SchemaKokoroBritishEnglishOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: SchemaFile
}

/**
 * BrEnglishRequest
 */
export type SchemaKokoroBritishEnglishInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice:
    | 'bf_alice'
    | 'bf_emma'
    | 'bf_isabella'
    | 'bf_lily'
    | 'bm_daniel'
    | 'bm_fable'
    | 'bm_george'
    | 'bm_lewis'
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number
}

/**
 * BrPortugeseOutput
 */
export type SchemaKokoroBrazilianPortugueseOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: SchemaFile
}

/**
 * BrPortugueseRequest
 */
export type SchemaKokoroBrazilianPortugueseInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice: 'pf_dora' | 'pm_alex' | 'pm_santa'
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number
}

/**
 * SpanishOutput
 */
export type SchemaKokoroSpanishOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: SchemaFile
}

/**
 * SpanishRequest
 */
export type SchemaKokoroSpanishInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice: 'ef_dora' | 'em_alex' | 'em_santa'
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number
}

/**
 * MandarinOutput
 */
export type SchemaKokoroMandarinChineseOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: SchemaFile
}

/**
 * MandarinRequest
 */
export type SchemaKokoroMandarinChineseInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice:
    | 'zf_xiaobei'
    | 'zf_xiaoni'
    | 'zf_xiaoxiao'
    | 'zf_xiaoyi'
    | 'zm_yunjian'
    | 'zm_yunxi'
    | 'zm_yunxia'
    | 'zm_yunyang'
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number
}

/**
 * HindiOutput
 */
export type SchemaKokoroHindiOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: SchemaFile
}

/**
 * HindiRequest
 */
export type SchemaKokoroHindiInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice: 'hf_alpha' | 'hf_beta' | 'hm_omega' | 'hm_psi'
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number
}

/**
 * TTSOutput
 */
export type SchemaElevenlabsTtsMultilingualV2Output = {
  audio: SchemaFile
  /**
   * Timestamps
   *
   * Timestamps for each word in the generated speech. Only returned if `timestamps` is set to True in the request.
   */
  timestamps?: Array<unknown> | unknown
}

/**
 * TextToSpeechRequest
 */
export type SchemaElevenlabsTtsMultilingualV2Input = {
  /**
   * Stability
   *
   * Voice stability (0-1)
   */
  stability?: number
  /**
   * Next Text
   *
   * The text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.
   */
  next_text?: string | unknown
  /**
   * Speed
   *
   * Speech speed (0.7-1.2). Values below 1.0 slow down the speech, above 1.0 speed it up. Extreme values may affect quality.
   */
  speed?: number
  /**
   * Style
   *
   * Style exaggeration (0-1)
   */
  style?: number
  /**
   * Text
   *
   * The text to convert to speech
   */
  text: string
  /**
   * Timestamps
   *
   * Whether to return timestamps for each word in the generated speech
   */
  timestamps?: boolean
  /**
   * Similarity Boost
   *
   * Similarity boost (0-1)
   */
  similarity_boost?: number
  /**
   * Voice
   *
   * The voice to use for speech generation
   */
  voice?: string
  /**
   * Language Code
   *
   * Language code (ISO 639-1) used to enforce a language for the model. An error will be returned if language code is not supported by the model.
   */
  language_code?: string | unknown
  /**
   * Previous Text
   *
   * The text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.
   */
  previous_text?: string | unknown
}

/**
 * Output
 */
export type SchemaDiffrhythmOutput = {
  /**
   * Audio
   *
   * Generated music file.
   */
  audio: SchemaFile
}

/**
 * TextToMusicInput
 */
export type SchemaDiffrhythmInput = {
  /**
   * Lyrics
   *
   * The prompt to generate the song from. Must have two sections. Sections start with either [chorus] or a [verse].
   */
  lyrics: string
  /**
   * CFG Strength
   *
   * The CFG strength to use for the music generation.
   */
  cfg_strength?: number
  /**
   * Reference Audio URL
   *
   * The URL of the reference audio to use for the music generation.
   */
  reference_audio_url?: string | Blob | File
  /**
   * Music Duration
   *
   * The duration of the music to generate.
   */
  music_duration?: '95s' | '285s'
  /**
   * Scheduler
   *
   * The scheduler to use for the music generation.
   */
  scheduler?: 'euler' | 'midpoint' | 'rk4' | 'implicit_adams'
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use for the music generation.
   */
  num_inference_steps?: number
  /**
   * Style Prompt
   *
   * The style prompt to use for the music generation.
   */
  style_prompt?: string
}

/**
 * Speaker
 */
export type SchemaSpeaker = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Audio Url
   */
  audio_url: string
  /**
   * Speaker Id
   */
  speaker_id: number
}

/**
 * Turn
 */
export type SchemaTurn = {
  /**
   * Text
   */
  text: string
  /**
   * Speaker Id
   */
  speaker_id: number
}

/**
 * Output
 */
export type SchemaCsm1bOutput = {
  /**
   * Audio
   *
   * The generated audio.
   */
  audio: SchemaFile | string
}

/**
 * Input
 */
export type SchemaCsm1bInput = {
  /**
   * Scene
   *
   * The text to generate an audio from.
   */
  scene: Array<SchemaTurn>
  /**
   * Context
   *
   * The context to generate an audio from.
   */
  context?: Array<SchemaSpeaker>
}

/**
 * AudioOutput
 *
 * Example Pydantic model showing how to include a File in the output.
 */
export type SchemaMusicGeneratorOutput = {
  audio_file: SchemaFile
}

/**
 * Input
 */
export type SchemaMusicGeneratorInput = {
  /**
   * Prompt
   *
   * The prompt to generate music from.
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated music in seconds.
   */
  duration: number
}

/**
 * AudioOutput
 *
 * Example Pydantic model showing how to include a File in the output.
 */
export type SchemaSoundEffectsGeneratorOutput = {
  audio_file: SchemaFile
}

/**
 * Input
 */
export type SchemaSoundEffectsGeneratorInput = {
  /**
   * Prompt
   *
   * The prompt to generate SFX.
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated SFX in seconds.
   */
  duration: number
}

/**
 * ACEStepResponse
 */
export type SchemaAceStepOutput = {
  /**
   * Tags
   *
   * The genre tags used in the generation process.
   */
  tags: string
  /**
   * Lyrics
   *
   * The lyrics used in the generation process.
   */
  lyrics: string
  /**
   * Seed
   *
   * The random seed used for the generation process.
   */
  seed: number
  /**
   * Audio
   *
   * The generated audio file.
   */
  audio: SchemaFile
}

/**
 * ACEStepTextToAudioRequest
 */
export type SchemaAceStepInput = {
  /**
   * Number Of Steps
   *
   * Number of steps to generate the audio.
   */
  number_of_steps?: number
  /**
   * Duration
   *
   * The duration of the generated audio in seconds.
   */
  duration?: number
  /**
   * Tags
   *
   * Comma-separated list of genre tags to control the style of the generated audio.
   */
  tags: string
  /**
   * Minimum Guidance Scale
   *
   * Minimum guidance scale for the generation after the decay.
   */
  minimum_guidance_scale?: number
  /**
   * Lyrics
   *
   * Lyrics to be sung in the audio. If not provided or if [inst] or [instrumental] is the content of this field, no lyrics will be sung. Use control structures like [verse], [chorus] and [bridge] to control the structure of the song.
   */
  lyrics?: string
  /**
   * Tag Guidance Scale
   *
   * Tag guidance scale for the generation.
   */
  tag_guidance_scale?: number
  /**
   * Scheduler
   *
   * Scheduler to use for the generation process.
   */
  scheduler?: 'euler' | 'heun'
  /**
   * Guidance Scale
   *
   * Guidance scale for the generation.
   */
  guidance_scale?: number
  /**
   * Guidance Type
   *
   * Type of CFG to use for the generation process.
   */
  guidance_type?: 'cfg' | 'apg' | 'cfg_star'
  /**
   * Lyric Guidance Scale
   *
   * Lyric guidance scale for the generation.
   */
  lyric_guidance_scale?: number
  /**
   * Guidance Interval
   *
   * Guidance interval for the generation. 0.5 means only apply guidance in the middle steps (0.25 * infer_steps to 0.75 * infer_steps)
   */
  guidance_interval?: number
  /**
   * Guidance Interval Decay
   *
   * Guidance interval decay for the generation. Guidance scale will decay from guidance_scale to min_guidance_scale in the interval. 0.0 means no decay.
   */
  guidance_interval_decay?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. If not provided, a random seed will be used.
   */
  seed?: number
  /**
   * Granularity Scale
   *
   * Granularity scale for the generation process. Higher values can reduce artifacts.
   */
  granularity_scale?: number
}

/**
 * ACEStepResponse
 */
export type SchemaAceStepPromptToAudioOutput = {
  /**
   * Tags
   *
   * The genre tags used in the generation process.
   */
  tags: string
  /**
   * Lyrics
   *
   * The lyrics used in the generation process.
   */
  lyrics: string
  /**
   * Seed
   *
   * The random seed used for the generation process.
   */
  seed: number
  /**
   * Audio
   *
   * The generated audio file.
   */
  audio: SchemaFile
}

/**
 * ACEStepPromptToAudioRequest
 */
export type SchemaAceStepPromptToAudioInput = {
  /**
   * Number Of Steps
   *
   * Number of steps to generate the audio.
   */
  number_of_steps?: number
  /**
   * Duration
   *
   * The duration of the generated audio in seconds.
   */
  duration?: number
  /**
   * Prompt
   *
   * Prompt to control the style of the generated audio. This will be used to generate tags and lyrics.
   */
  prompt: string
  /**
   * Minimum Guidance Scale
   *
   * Minimum guidance scale for the generation after the decay.
   */
  minimum_guidance_scale?: number
  /**
   * Tag Guidance Scale
   *
   * Tag guidance scale for the generation.
   */
  tag_guidance_scale?: number
  /**
   * Scheduler
   *
   * Scheduler to use for the generation process.
   */
  scheduler?: 'euler' | 'heun'
  /**
   * Guidance Scale
   *
   * Guidance scale for the generation.
   */
  guidance_scale?: number
  /**
   * Guidance Type
   *
   * Type of CFG to use for the generation process.
   */
  guidance_type?: 'cfg' | 'apg' | 'cfg_star'
  /**
   * Instrumental
   *
   * Whether to generate an instrumental version of the audio.
   */
  instrumental?: boolean
  /**
   * Lyric Guidance Scale
   *
   * Lyric guidance scale for the generation.
   */
  lyric_guidance_scale?: number
  /**
   * Guidance Interval
   *
   * Guidance interval for the generation. 0.5 means only apply guidance in the middle steps (0.25 * infer_steps to 0.75 * infer_steps)
   */
  guidance_interval?: number
  /**
   * Guidance Interval Decay
   *
   * Guidance interval decay for the generation. Guidance scale will decay from guidance_scale to min_guidance_scale in the interval. 0.0 means no decay.
   */
  guidance_interval_decay?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. If not provided, a random seed will be used.
   */
  seed?: number
  /**
   * Granularity Scale
   *
   * Granularity scale for the generation process. Higher values can reduce artifacts.
   */
  granularity_scale?: number
}

/**
 * TextToMusicOutput
 */
export type SchemaLyria2Output = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: SchemaFile
}

/**
 * TextToMusicInput
 */
export type SchemaLyria2Input = {
  /**
   * Prompt
   *
   * The text prompt describing the music you want to generate
   */
  prompt: string
  /**
   * Seed
   *
   * A seed for deterministic generation. If provided, the model will attempt to produce the same audio given the same prompt and other parameters.
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A description of what to exclude from the generated audio
   */
  negative_prompt?: string
}

/**
 * TTSOutput
 */
export type SchemaElevenlabsTtsElevenV3Output = {
  audio: SchemaFile
  /**
   * Timestamps
   *
   * Timestamps for each word in the generated speech. Only returned if `timestamps` is set to True in the request.
   */
  timestamps?: Array<unknown> | unknown
}

/**
 * TextToSpeechRequestV3
 *
 * Request model for eleven_v3 which doesn't support previous_text/next_text
 */
export type SchemaElevenlabsTtsElevenV3Input = {
  /**
   * Stability
   *
   * Voice stability (0-1)
   */
  stability?: number
  /**
   * Speed
   *
   * Speech speed (0.7-1.2). Values below 1.0 slow down the speech, above 1.0 speed it up. Extreme values may affect quality.
   */
  speed?: number
  /**
   * Text
   *
   * The text to convert to speech
   */
  text: string
  /**
   * Style
   *
   * Style exaggeration (0-1)
   */
  style?: number
  /**
   * Timestamps
   *
   * Whether to return timestamps for each word in the generated speech
   */
  timestamps?: boolean
  /**
   * Similarity Boost
   *
   * Similarity boost (0-1)
   */
  similarity_boost?: number
  /**
   * Voice
   *
   * The voice to use for speech generation
   */
  voice?: string
  /**
   * Language Code
   *
   * Language code (ISO 639-1) used to enforce a language for the model.
   */
  language_code?: string | unknown
}

/**
 * GenerateOutput
 */
export type SchemaV2TextToMusicOutput = {
  /**
   * Tags
   *
   * The style tags used for generation.
   */
  tags?: Array<string> | unknown
  /**
   * Seed
   *
   * The seed used for generation. This can be used to generate an identical song by passing the same parameters with this seed in a future request.
   */
  seed: number
  /**
   * Lyrics
   *
   * The lyrics used for generation.
   */
  lyrics?: string | unknown
  /**
   * Audio
   *
   * The generated audio files.
   */
  audio: Array<SchemaFile>
}

/**
 * GenerateInput
 */
export type SchemaV2TextToMusicInput = {
  /**
   * Prompt
   *
   * A description of the track you want to generate. This prompt will be used to automatically generate the tags and lyrics unless you manually set them. For example, if you set prompt and tags, then the prompt will be used to generate only the lyrics.
   */
  prompt?: string | unknown
  /**
   * Lyrics Prompt
   *
   * The lyrics sung in the generated song. An empty string will generate an instrumental track.
   */
  lyrics_prompt?: string | unknown
  /**
   * Tags
   *
   * Tags/styles of the music to generate. You can view a list of all available tags at https://sonauto.ai/tag-explorer.
   */
  tags?: Array<string> | unknown
  /**
   * Prompt Strength
   *
   * Controls how strongly your prompt influences the output. Greater values adhere more to the prompt but sound less natural. (This is CFG.)
   */
  prompt_strength?: number
  /**
   * Output Bit Rate
   *
   * The bit rate to use for mp3 and m4a formats. Not available for other formats.
   */
  output_bit_rate?: 128 | 192 | 256 | 320 | unknown
  /**
   * Num Songs
   *
   * Generating 2 songs costs 1.5x the price of generating 1 song. Also, note that using the same seed may not result in identical songs if the number of songs generated is changed.
   */
  num_songs?: number
  /**
   * Output Format
   */
  output_format?: 'flac' | 'mp3' | 'wav' | 'ogg' | 'm4a'
  /**
   * Bpm
   *
   * The beats per minute of the song. This can be set to an integer or the literal string "auto" to pick a suitable bpm based on the tags. Set bpm to null to not condition the model on bpm information.
   */
  bpm?: number | string | unknown
  /**
   * Balance Strength
   *
   * Greater means more natural vocals. Lower means sharper instrumentals. We recommend 0.7.
   */
  balance_strength?: number
  /**
   * Seed
   *
   * The seed to use for generation. Will pick a random seed if not provided. Repeating a request with identical parameters (must use lyrics and tags, not prompt) and the same seed will generate the same song.
   */
  seed?: number | unknown
}

/**
 * InpaintSection
 */
export type SchemaInpaintSection = {
  /**
   * End
   *
   * End time in seconds of the section to inpaint.
   */
  end: number
  /**
   * Start
   *
   * Start time in seconds of the section to inpaint.
   */
  start: number
}

/**
 * InpaintOutput
 */
export type SchemaV2InpaintOutput = {
  /**
   * Seed
   *
   * The seed used for generation. This can be used to generate an identical song by passing the same parameters with this seed in a future request.
   */
  seed: number
  /**
   * Audio
   *
   * The generated audio files.
   */
  audio: Array<SchemaFile>
}

/**
 * InpaintInput
 */
export type SchemaV2InpaintInput = {
  /**
   * Lyrics Prompt
   *
   * The lyrics sung in the generated song. An empty string will generate an instrumental track.
   */
  lyrics_prompt: string
  /**
   * Tags
   *
   * Tags/styles of the music to generate. You can view a list of all available tags at https://sonauto.ai/tag-explorer.
   */
  tags?: Array<string>
  /**
   * Prompt Strength
   *
   * Controls how strongly your prompt influences the output. Greater values adhere more to the prompt but sound less natural. (This is CFG.)
   */
  prompt_strength?: number
  /**
   * Output Bit Rate
   *
   * The bit rate to use for mp3 and m4a formats. Not available for other formats.
   */
  output_bit_rate?: 128 | 192 | 256 | 320 | unknown
  /**
   * Num Songs
   *
   * Generating 2 songs costs 1.5x the price of generating 1 song. Also, note that using the same seed may not result in identical songs if the number of songs generated is changed.
   */
  num_songs?: number
  /**
   * Output Format
   */
  output_format?: 'flac' | 'mp3' | 'wav' | 'ogg' | 'm4a'
  /**
   * Selection Crop
   *
   * Crop to the selected region
   */
  selection_crop?: boolean
  /**
   * Sections
   *
   * List of sections to inpaint. Currently, only one section is supported so the list length must be 1.
   */
  sections: Array<SchemaInpaintSection>
  /**
   * Balance Strength
   *
   * Greater means more natural vocals. Lower means sharper instrumentals. We recommend 0.7.
   */
  balance_strength?: number
  /**
   * Audio Url
   *
   * The URL of the audio file to alter. Must be a valid publicly accessible URL.
   */
  audio_url: string | Blob | File
  /**
   * Seed
   *
   * The seed to use for generation. Will pick a random seed if not provided. Repeating a request with identical parameters (must use lyrics and tags, not prompt) and the same seed will generate the same song.
   */
  seed?: number | unknown
}

/**
 * SoundEffectOutput
 *
 * Output format for generated sound effects
 */
export type SchemaElevenlabsSoundEffectsV2Output = {
  audio: SchemaFile
}

/**
 * SoundEffectRequestV2
 */
export type SchemaElevenlabsSoundEffectsV2Input = {
  /**
   * Text
   *
   * The text describing the sound effect to generate
   */
  text: string
  /**
   * Loop
   *
   * Whether to create a sound effect that loops smoothly.
   */
  loop?: boolean
  /**
   * Prompt Influence
   *
   * How closely to follow the prompt (0-1). Higher values mean less variation.
   */
  prompt_influence?: number
  /**
   * Output Format
   *
   * Output format of the generated audio. Formatted as codec_sample_rate_bitrate.
   */
  output_format?:
    | 'mp3_22050_32'
    | 'mp3_44100_32'
    | 'mp3_44100_64'
    | 'mp3_44100_96'
    | 'mp3_44100_128'
    | 'mp3_44100_192'
    | 'pcm_8000'
    | 'pcm_16000'
    | 'pcm_22050'
    | 'pcm_24000'
    | 'pcm_44100'
    | 'pcm_48000'
    | 'ulaw_8000'
    | 'alaw_8000'
    | 'opus_48000_32'
    | 'opus_48000_64'
    | 'opus_48000_96'
    | 'opus_48000_128'
    | 'opus_48000_192'
  /**
   * Duration Seconds
   *
   * Duration in seconds (0.5-22). If None, optimal duration will be determined from prompt.
   */
  duration_seconds?: number | unknown
}

/**
 * PronunciationDictionaryLocator
 */
export type SchemaPronunciationDictionaryLocator = {
  /**
   * Version Id
   *
   * The ID of the version of the pronunciation dictionary. If not provided, the latest version will be used.
   */
  version_id?: string | unknown
  /**
   * Pronunciation Dictionary Id
   *
   * The ID of the pronunciation dictionary.
   */
  pronunciation_dictionary_id: string | unknown
}

/**
 * DialogueBlock
 */
export type SchemaDialogueBlock = {
  /**
   * Text
   *
   * The dialogue text
   */
  text: string
  /**
   * Voice
   *
   * The name or the ID of the voice to be used for the generation.
   */
  voice: string
}

/**
 * TextToDialogueOutput
 */
export type SchemaElevenlabsTextToDialogueElevenV3Output = {
  /**
   * Seed
   *
   * Random seed for reproducibility.
   */
  seed: number
  audio: SchemaFile
}

/**
 * TextToDialogueRequest
 */
export type SchemaElevenlabsTextToDialogueElevenV3Input = {
  /**
   * Stability
   *
   * Determines how stable the voice is and the randomness between each generation. Lower values introduce broader emotional range for the voice. Higher values can result in a monotonous voice with limited emotion. Must be one of 0.0, 0.5, 1.0, else it will be rounded to the nearest value.
   */
  stability?: number | unknown
  /**
   * Inputs
   *
   * A list of dialogue inputs, each containing text and a voice ID which will be converted into speech.
   */
  inputs: Array<SchemaDialogueBlock>
  /**
   * Language Code
   *
   * Language code (ISO 639-1) used to enforce a language for the model. An error will be returned if language code is not supported by the model.
   */
  language_code?: string | unknown
  /**
   * Seed
   *
   * Random seed for reproducibility.
   */
  seed?: number | unknown
  /**
   * Use Speaker Boost
   *
   * This setting boosts the similarity to the original speaker. Using this setting requires a slightly higher computational load, which in turn increases latency.
   */
  use_speaker_boost?: boolean | unknown
  /**
   * Pronunciation Dictionary Locators
   *
   * A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request
   */
  pronunciation_dictionary_locators?: Array<SchemaPronunciationDictionaryLocator>
}

/**
 * TextToAudioOutput
 */
export type SchemaStableAudio25TextToAudioOutput = {
  /**
   * Seed
   *
   * The random seed used for generation
   */
  seed: number
  /**
   * Audio
   *
   * The generated audio clip
   */
  audio: SchemaFile
}

/**
 * TextToAudioInput
 */
export type SchemaStableAudio25TextToAudioInput = {
  /**
   * Prompt
   *
   * The prompt to generate audio from
   */
  prompt: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Seconds Total
   *
   * The duration of the audio clip to generate
   */
  seconds_total?: number
  /**
   * Num Inference Steps
   *
   * The number of steps to denoise the audio for
   */
  num_inference_steps?: number
  /**
   * Guidance Scale
   *
   * How strictly the diffusion process adheres to the prompt text (higher values make your audio closer to your prompt).
   */
  guidance_scale?: number
  /**
   * Seed
   */
  seed?: number
}

/**
 * MusicV15Output
 */
export type SchemaMinimaxMusicV15Output = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: SchemaFile
}

/**
 * TextToMusic15Request
 */
export type SchemaMinimaxMusicV15Input = {
  /**
   * Prompt
   *
   * Lyrics, supports [intro][verse][chorus][bridge][outro] sections. 10-600 characters.
   */
  prompt: string
  /**
   * Lyrics Prompt
   *
   * Control music generation. 10-3000 characters.
   */
  lyrics_prompt: string
  /**
   * Audio Setting
   *
   * Audio configuration settings
   */
  audio_setting?: SchemaAudioSetting
}

/**
 * AudioSetting
 */
export type SchemaAudioSetting = {
  /**
   * Format
   *
   * Audio format
   */
  format?: 'mp3' | 'pcm' | 'flac'
  /**
   * Sample Rate
   *
   * Sample rate of generated audio
   */
  sample_rate?: 8000 | 16000 | 22050 | 24000 | 32000 | 44100
  /**
   * Bitrate
   *
   * Bitrate of generated audio
   */
  bitrate?: 32000 | 64000 | 128000 | 256000
}

/**
 * MusicGenerationOutput
 *
 * Output schema for music generation.
 */
export type SchemaMusicGenerationOutput = {
  /**
   * Prompt
   *
   * The processed prompt used for generation
   */
  prompt: string
  /**
   * Metadata
   *
   * Generation metadata including duration, sample rate, and parameters
   */
  metadata: {
    [key: string]: unknown
  }
  audio: SchemaFile
}

/**
 * MusicGenerationInput
 *
 * Input schema for music generation with form controls for the playground.
 */
export type SchemaMusicGenerationInput = {
  /**
   * Prompt
   *
   * Describe the music you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * Length of the generated music in seconds
   */
  duration?: number
  /**
   * Refinement
   *
   * Refinement level - higher values may improve quality but take longer
   */
  refinement?: number
  /**
   * Seed
   *
   * Random seed for reproducible results - leave empty for random generation
   */
  seed?: number | unknown
  /**
   * Negative Prompt
   *
   * Describe what you want to avoid in the music (instruments, styles, moods). Leave blank for none.
   */
  negative_prompt?: string
  /**
   * Creativity
   *
   * Creativity level - higher values allow more creative interpretation of the prompt
   */
  creativity?: number
}

/**
 * SoundEffectGenerationOutput
 *
 * Output schema for sound effect generation.
 */
export type SchemaSoundEffectGenerationOutput = {
  /**
   * Prompt
   *
   * The processed prompt used for generation
   */
  prompt: string
  /**
   * Metadata
   *
   * Generation metadata including duration, sample rate, and parameters
   */
  metadata: {
    [key: string]: unknown
  }
  audio: SchemaFile
}

/**
 * SoundEffectGenerationInput
 *
 * Input schema for sound effect generation with form controls for the playground.
 */
export type SchemaSoundEffectGenerationInput = {
  /**
   * Prompt
   *
   * Describe the sound effect you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * Length of the generated sound effect in seconds
   */
  duration?: number
  /**
   * Refinement
   *
   * Refinement level - Higher values may improve quality but take longer
   */
  refinement?: number
  /**
   * Seed
   *
   * Random seed for reproducible results - leave empty for random generation
   */
  seed?: number | unknown
  /**
   * Negative Prompt
   *
   * Describe the types of sounds you don't want to generate in the output, avoid double-negatives, compare with positive prompts
   */
  negative_prompt?: string
  /**
   * Creativity
   *
   * Creativity level - higher values allow more creative interpretation of the prompt
   */
  creativity?: number
}

/**
 * MusicV15Output
 */
export type SchemaMinimaxMusicV2Output = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: SchemaFile
}

/**
 * TextToMusic20Request
 */
export type SchemaMinimaxMusicV2Input = {
  /**
   * Prompt
   *
   * A description of the music, specifying style, mood, and scenario. 10-300 characters.
   */
  prompt: string
  /**
   * Lyrics Prompt
   *
   * Lyrics of the song. Use n to separate lines. You may add structure tags like [Intro], [Verse], [Chorus], [Bridge], [Outro] to enhance the arrangement. 10-3000 characters.
   */
  lyrics_prompt: string
  /**
   * Audio Setting
   *
   * Audio configuration settings
   */
  audio_setting?: SchemaAudioSetting
}

/**
 * MusicSection
 */
export type SchemaMusicSection = {
  /**
   * Positive Local Styles
   *
   * The styles that should be present in this section.
   */
  positive_local_styles: Array<string>
  /**
   * Lines
   *
   * The lyrics of the section. Each line must be at most 200 characters long.
   */
  lines: Array<string>
  /**
   * Negative Local Styles
   *
   * The styles that should not be present in this section.
   */
  negative_local_styles: Array<string>
  /**
   * Duration Ms
   *
   * The duration of the section in milliseconds. Must be between 3000ms and 120000ms.
   */
  duration_ms: number
  /**
   * Section Name
   *
   * The name of the section. Must be between 1 and 100 characters.
   */
  section_name: string
}

/**
 * MusicCompositionPlan
 */
export type SchemaMusicCompositionPlan = {
  /**
   * Negative Global Styles
   *
   * The styles that should not be present in the entire song.
   */
  negative_global_styles: Array<string>
  /**
   * Sections
   *
   * The sections of the song.
   */
  sections: Array<SchemaMusicSection>
  /**
   * Positive Global Styles
   *
   * The styles that should be present in the entire song.
   */
  positive_global_styles: Array<string>
}

/**
 * MusicOutput
 */
export type SchemaElevenlabsMusicOutput = {
  audio: SchemaFile
}

/**
 * MusicRequest
 *
 * Request format for Elevenlabs Music API
 */
export type SchemaElevenlabsMusicInput = {
  /**
   * Prompt
   *
   * The text prompt describing the music to generate
   */
  prompt?: string | unknown
  /**
   * The composition plan for the music
   */
  composition_plan?: SchemaMusicCompositionPlan | unknown
  /**
   * Music Length Ms
   *
   * The length of the song to generate in milliseconds. Used only in conjunction with prompt. Must be between 3000ms and 600000ms. Optional - if not provided, the model will choose a length based on the prompt.
   */
  music_length_ms?: number | unknown
  /**
   * Output Format
   *
   * Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the Î¼-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.
   */
  output_format?:
    | 'mp3_22050_32'
    | 'mp3_44100_32'
    | 'mp3_44100_64'
    | 'mp3_44100_96'
    | 'mp3_44100_128'
    | 'mp3_44100_192'
    | 'pcm_8000'
    | 'pcm_16000'
    | 'pcm_22050'
    | 'pcm_24000'
    | 'pcm_44100'
    | 'pcm_48000'
    | 'ulaw_8000'
    | 'alaw_8000'
    | 'opus_48000_32'
    | 'opus_48000_64'
    | 'opus_48000_96'
    | 'opus_48000_128'
    | 'opus_48000_192'
  /**
   * Respect Sections Durations
   *
   * Controls how strictly section durations in the composition_plan are enforced. It will only have an effect if it is used with composition_plan. When set to true, the model will precisely respect each section's duration_ms from the plan. When set to false, the model may adjust individual section durations which will generally lead to better generation quality and improved latency, while always preserving the total song duration from the plan.
   */
  respect_sections_durations?: boolean
  /**
   * Force Instrumental
   *
   * If true, guarantees that the generated song will be instrumental. If false, the song may or may not be instrumental depending on the prompt. Can only be used with prompt.
   */
  force_instrumental?: boolean
}

/**
 * TTSOutput
 */
export type SchemaElevenlabsAudioIsolationOutput = {
  audio: SchemaFile
  /**
   * Timestamps
   *
   * Timestamps for each word in the generated speech. Only returned if `timestamps` is set to True in the request.
   */
  timestamps?: Array<unknown> | unknown
}

/**
 * AudioIsolationRequest
 */
export type SchemaElevenlabsAudioIsolationInput = {
  /**
   * Video Url
   *
   * Video file to use for audio isolation. Either `audio_url` or `video_url` must be provided.
   */
  video_url?: string | unknown
  /**
   * Audio Url
   *
   * URL of the audio file to isolate voice from
   */
  audio_url?: string | unknown
}

/**
 * DiaCloneOutput
 */
export type SchemaDiaTtsVoiceCloneOutput = {
  /**
   * The generated speech audio
   */
  audio: SchemaFile
}

/**
 * CloneRequest
 */
export type SchemaDiaTtsVoiceCloneInput = {
  /**
   * Text
   *
   * The text to be converted to speech.
   */
  text: string
  /**
   * Reference Text for the Reference Audio
   *
   * The reference text to be used for TTS.
   */
  ref_text: string
  /**
   * Reference Audio URL
   *
   * The URL of the reference audio file.
   */
  ref_audio_url: string | Blob | File
}

/**
 * ACEStepAudioToAudioResponse
 */
export type SchemaAceStepAudioToAudioOutput = {
  /**
   * Tags
   *
   * The genre tags used in the generation process.
   */
  tags: string
  /**
   * Lyrics
   *
   * The lyrics used in the generation process.
   */
  lyrics: string
  /**
   * Seed
   *
   * The random seed used for the generation process.
   */
  seed: number
  /**
   * Audio
   *
   * The generated audio file.
   */
  audio: SchemaFile
}

/**
 * ACEStepAudioToAudioRequest
 */
export type SchemaAceStepAudioToAudioInput = {
  /**
   * Number Of Steps
   *
   * Number of steps to generate the audio.
   */
  number_of_steps?: number
  /**
   * Tags
   *
   * Comma-separated list of genre tags to control the style of the generated audio.
   */
  tags: string
  /**
   * Minimum Guidance Scale
   *
   * Minimum guidance scale for the generation after the decay.
   */
  minimum_guidance_scale?: number
  /**
   * Lyrics
   *
   * Lyrics to be sung in the audio. If not provided or if [inst] or [instrumental] is the content of this field, no lyrics will be sung. Use control structures like [verse], [chorus] and [bridge] to control the structure of the song.
   */
  lyrics?: string
  /**
   * Tag Guidance Scale
   *
   * Tag guidance scale for the generation.
   */
  tag_guidance_scale?: number
  /**
   * Original Lyrics
   *
   * Original lyrics of the audio file.
   */
  original_lyrics?: string
  /**
   * Scheduler
   *
   * Scheduler to use for the generation process.
   */
  scheduler?: 'euler' | 'heun'
  /**
   * Guidance Scale
   *
   * Guidance scale for the generation.
   */
  guidance_scale?: number
  /**
   * Guidance Type
   *
   * Type of CFG to use for the generation process.
   */
  guidance_type?: 'cfg' | 'apg' | 'cfg_star'
  /**
   * Lyric Guidance Scale
   *
   * Lyric guidance scale for the generation.
   */
  lyric_guidance_scale?: number
  /**
   * Guidance Interval
   *
   * Guidance interval for the generation. 0.5 means only apply guidance in the middle steps (0.25 * infer_steps to 0.75 * infer_steps)
   */
  guidance_interval?: number
  /**
   * Edit Mode
   *
   * Whether to edit the lyrics only or remix the audio.
   */
  edit_mode?: 'lyrics' | 'remix'
  /**
   * Guidance Interval Decay
   *
   * Guidance interval decay for the generation. Guidance scale will decay from guidance_scale to min_guidance_scale in the interval. 0.0 means no decay.
   */
  guidance_interval_decay?: number
  /**
   * Audio Url
   *
   * URL of the audio file to be outpainted.
   */
  audio_url: string | Blob | File
  /**
   * Seed
   *
   * Random seed for reproducibility. If not provided, a random seed will be used.
   */
  seed?: number
  /**
   * Granularity Scale
   *
   * Granularity scale for the generation process. Higher values can reduce artifacts.
   */
  granularity_scale?: number
  /**
   * Original Tags
   *
   * Original tags of the audio file.
   */
  original_tags: string
  /**
   * Original Seed
   *
   * Original seed of the audio file.
   */
  original_seed?: number
}

/**
 * ACEStepAudioInpaintResponse
 */
export type SchemaAceStepAudioInpaintOutput = {
  /**
   * Tags
   *
   * The genre tags used in the generation process.
   */
  tags: string
  /**
   * Lyrics
   *
   * The lyrics used in the generation process.
   */
  lyrics: string
  /**
   * Seed
   *
   * The random seed used for the generation process.
   */
  seed: number
  /**
   * Audio
   *
   * The generated audio file.
   */
  audio: SchemaFile
}

/**
 * ACEStepAudioInpaintRequest
 */
export type SchemaAceStepAudioInpaintInput = {
  /**
   * Number Of Steps
   *
   * Number of steps to generate the audio.
   */
  number_of_steps?: number
  /**
   * Start Time
   *
   * start time in seconds for the inpainting process.
   */
  start_time?: number
  /**
   * Tags
   *
   * Comma-separated list of genre tags to control the style of the generated audio.
   */
  tags: string
  /**
   * Minimum Guidance Scale
   *
   * Minimum guidance scale for the generation after the decay.
   */
  minimum_guidance_scale?: number
  /**
   * Lyrics
   *
   * Lyrics to be sung in the audio. If not provided or if [inst] or [instrumental] is the content of this field, no lyrics will be sung. Use control structures like [verse], [chorus] and [bridge] to control the structure of the song.
   */
  lyrics?: string
  /**
   * End Time Relative To
   *
   * Whether the end time is relative to the start or end of the audio.
   */
  end_time_relative_to?: 'start' | 'end'
  /**
   * Tag Guidance Scale
   *
   * Tag guidance scale for the generation.
   */
  tag_guidance_scale?: number
  /**
   * Scheduler
   *
   * Scheduler to use for the generation process.
   */
  scheduler?: 'euler' | 'heun'
  /**
   * End Time
   *
   * end time in seconds for the inpainting process.
   */
  end_time?: number
  /**
   * Guidance Type
   *
   * Type of CFG to use for the generation process.
   */
  guidance_type?: 'cfg' | 'apg' | 'cfg_star'
  /**
   * Guidance Scale
   *
   * Guidance scale for the generation.
   */
  guidance_scale?: number
  /**
   * Lyric Guidance Scale
   *
   * Lyric guidance scale for the generation.
   */
  lyric_guidance_scale?: number
  /**
   * Guidance Interval
   *
   * Guidance interval for the generation. 0.5 means only apply guidance in the middle steps (0.25 * infer_steps to 0.75 * infer_steps)
   */
  guidance_interval?: number
  /**
   * Variance
   *
   * Variance for the inpainting process. Higher values can lead to more diverse results.
   */
  variance?: number
  /**
   * Guidance Interval Decay
   *
   * Guidance interval decay for the generation. Guidance scale will decay from guidance_scale to min_guidance_scale in the interval. 0.0 means no decay.
   */
  guidance_interval_decay?: number
  /**
   * Start Time Relative To
   *
   * Whether the start time is relative to the start or end of the audio.
   */
  start_time_relative_to?: 'start' | 'end'
  /**
   * Audio Url
   *
   * URL of the audio file to be inpainted.
   */
  audio_url: string | Blob | File
  /**
   * Seed
   *
   * Random seed for reproducibility. If not provided, a random seed will be used.
   */
  seed?: number
  /**
   * Granularity Scale
   *
   * Granularity scale for the generation process. Higher values can reduce artifacts.
   */
  granularity_scale?: number
}

/**
 * ACEStepResponse
 */
export type SchemaAceStepAudioOutpaintOutput = {
  /**
   * Tags
   *
   * The genre tags used in the generation process.
   */
  tags: string
  /**
   * Lyrics
   *
   * The lyrics used in the generation process.
   */
  lyrics: string
  /**
   * Seed
   *
   * The random seed used for the generation process.
   */
  seed: number
  /**
   * Audio
   *
   * The generated audio file.
   */
  audio: SchemaFile
}

/**
 * ACEStepAudioOutpaintRequest
 */
export type SchemaAceStepAudioOutpaintInput = {
  /**
   * Number Of Steps
   *
   * Number of steps to generate the audio.
   */
  number_of_steps?: number
  /**
   * Tags
   *
   * Comma-separated list of genre tags to control the style of the generated audio.
   */
  tags: string
  /**
   * Minimum Guidance Scale
   *
   * Minimum guidance scale for the generation after the decay.
   */
  minimum_guidance_scale?: number
  /**
   * Extend After Duration
   *
   * Duration in seconds to extend the audio from the end.
   */
  extend_after_duration?: number
  /**
   * Lyrics
   *
   * Lyrics to be sung in the audio. If not provided or if [inst] or [instrumental] is the content of this field, no lyrics will be sung. Use control structures like [verse], [chorus] and [bridge] to control the structure of the song.
   */
  lyrics?: string
  /**
   * Tag Guidance Scale
   *
   * Tag guidance scale for the generation.
   */
  tag_guidance_scale?: number
  /**
   * Scheduler
   *
   * Scheduler to use for the generation process.
   */
  scheduler?: 'euler' | 'heun'
  /**
   * Extend Before Duration
   *
   * Duration in seconds to extend the audio from the start.
   */
  extend_before_duration?: number
  /**
   * Guidance Type
   *
   * Type of CFG to use for the generation process.
   */
  guidance_type?: 'cfg' | 'apg' | 'cfg_star'
  /**
   * Guidance Scale
   *
   * Guidance scale for the generation.
   */
  guidance_scale?: number
  /**
   * Lyric Guidance Scale
   *
   * Lyric guidance scale for the generation.
   */
  lyric_guidance_scale?: number
  /**
   * Guidance Interval
   *
   * Guidance interval for the generation. 0.5 means only apply guidance in the middle steps (0.25 * infer_steps to 0.75 * infer_steps)
   */
  guidance_interval?: number
  /**
   * Guidance Interval Decay
   *
   * Guidance interval decay for the generation. Guidance scale will decay from guidance_scale to min_guidance_scale in the interval. 0.0 means no decay.
   */
  guidance_interval_decay?: number
  /**
   * Audio Url
   *
   * URL of the audio file to be outpainted.
   */
  audio_url: string | Blob | File
  /**
   * Seed
   *
   * Random seed for reproducibility. If not provided, a random seed will be used.
   */
  seed?: number
  /**
   * Granularity Scale
   *
   * Granularity scale for the generation process. Higher values can reduce artifacts.
   */
  granularity_scale?: number
}

/**
 * ExtendOutput
 */
export type SchemaV2ExtendOutput = {
  /**
   * Tags
   *
   * The style tags used for generation.
   */
  tags?: Array<string> | unknown
  /**
   * Seed
   *
   * The seed used for generation. This can be used to generate an identical song by passing the same parameters with this seed in a future request.
   */
  seed: number
  /**
   * Extend Duration
   *
   * The duration in seconds that the song was extended by.
   */
  extend_duration: number
  /**
   * Audio
   *
   * The generated audio files.
   */
  audio: Array<SchemaFile>
  /**
   * Lyrics
   *
   * The lyrics used for generation.
   */
  lyrics?: string | unknown
}

/**
 * ExtendInput
 */
export type SchemaV2ExtendInput = {
  /**
   * Prompt
   *
   * A description of the track you want to generate. This prompt will be used to automatically generate the tags and lyrics unless you manually set them. For example, if you set prompt and tags, then the prompt will be used to generate only the lyrics.
   */
  prompt?: string | unknown
  /**
   * Lyrics Prompt
   *
   * The lyrics sung in the generated song. An empty string will generate an instrumental track.
   */
  lyrics_prompt?: string | unknown
  /**
   * Tags
   *
   * Tags/styles of the music to generate. You can view a list of all available tags at https://sonauto.ai/tag-explorer.
   */
  tags?: Array<string> | unknown
  /**
   * Prompt Strength
   *
   * Controls how strongly your prompt influences the output. Greater values adhere more to the prompt but sound less natural. (This is CFG.)
   */
  prompt_strength?: number
  /**
   * Output Bit Rate
   *
   * The bit rate to use for mp3 and m4a formats. Not available for other formats.
   */
  output_bit_rate?: 128 | 192 | 256 | 320 | unknown
  /**
   * Num Songs
   *
   * Generating 2 songs costs 1.5x the price of generating 1 song. Also, note that using the same seed may not result in identical songs if the number of songs generated is changed.
   */
  num_songs?: number
  /**
   * Output Format
   */
  output_format?: 'flac' | 'mp3' | 'wav' | 'ogg' | 'm4a'
  /**
   * Side
   *
   * Add more to the beginning (left) or end (right) of the song
   */
  side: 'left' | 'right'
  /**
   * Balance Strength
   *
   * Greater means more natural vocals. Lower means sharper instrumentals. We recommend 0.7.
   */
  balance_strength?: number
  /**
   * Crop Duration
   *
   * Duration in seconds to crop from the selected side before extending from that side.
   */
  crop_duration?: number
  /**
   * Audio Url
   *
   * The URL of the audio file to alter. Must be a valid publicly accessible URL.
   */
  audio_url: string | Blob | File
  /**
   * Seed
   *
   * The seed to use for generation. Will pick a random seed if not provided. Repeating a request with identical parameters (must use lyrics and tags, not prompt) and the same seed will generate the same song.
   */
  seed?: number | unknown
  /**
   * Extend Duration
   *
   * Duration in seconds to extend the song. If not provided, will attempt to automatically determine.
   */
  extend_duration?: number | unknown
}

/**
 * InpaintOutput
 */
export type SchemaStableAudio25InpaintOutput = {
  /**
   * Seed
   *
   * The random seed used for generation
   */
  seed: number
  /**
   * Audio
   *
   * The generated audio clip
   */
  audio: SchemaFile
}

/**
 * InpaintInput
 */
export type SchemaStableAudio25InpaintInput = {
  /**
   * Prompt
   *
   * The prompt to guide the audio generation
   */
  prompt: string
  /**
   * Guidance Scale
   *
   * How strictly the diffusion process adheres to the prompt text (higher values make your audio closer to your prompt).
   */
  guidance_scale?: number
  /**
   * Mask End
   *
   * The end point of the audio mask
   */
  mask_end?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Audio Url
   *
   * The audio clip to inpaint
   */
  audio_url: string | Blob | File
  /**
   * Seed
   */
  seed?: number
  /**
   * Seconds Total
   *
   * The duration of the audio clip to generate. If not provided, it will be set to the duration of the input audio.
   */
  seconds_total?: number
  /**
   * Num Inference Steps
   *
   * The number of steps to denoise the audio for
   */
  num_inference_steps?: number
  /**
   * Mask Start
   *
   * The start point of the audio mask
   */
  mask_start?: number
}

/**
 * AudioToAudioOutput
 */
export type SchemaStableAudio25AudioToAudioOutput = {
  /**
   * Seed
   *
   * The random seed used for generation
   */
  seed: number
  /**
   * Audio
   *
   * The generated audio clip
   */
  audio: SchemaFile
}

/**
 * AudioToAudioInput
 */
export type SchemaStableAudio25AudioToAudioInput = {
  /**
   * Prompt
   *
   * The prompt to guide the audio generation
   */
  prompt: string
  /**
   * Strength
   *
   * Sometimes referred to as denoising, this parameter controls how much influence the `audio_url` parameter has on the generated audio. A value of 0 would yield audio that is identical to the input. A value of 1 would be as if you passed in no audio at all.
   */
  strength?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Audio Url
   *
   * The audio clip to transform
   */
  audio_url: string | Blob | File
  /**
   * Num Inference Steps
   *
   * The number of steps to denoise the audio for
   */
  num_inference_steps?: number
  /**
   * Guidance Scale
   *
   * How strictly the diffusion process adheres to the prompt text (higher values make your audio closer to your prompt).
   */
  guidance_scale?: number
  /**
   * Seed
   */
  seed?: number
  /**
   * Total Seconds
   *
   * The duration of the audio clip to generate. If not provided, it will be set to the duration of the input audio.
   */
  total_seconds?: number
}

/**
 * AudioUnderstandingOutput
 */
export type SchemaAudioUnderstandingOutput = {
  /**
   * Output
   *
   * The analysis of the audio content based on the prompt
   */
  output: string
}

/**
 * AudioUnderstandingInput
 */
export type SchemaAudioUnderstandingInput = {
  /**
   * Prompt
   *
   * The question or prompt about the audio content.
   */
  prompt: string
  /**
   * Detailed Analysis
   *
   * Whether to request a more detailed analysis of the audio
   */
  detailed_analysis?: boolean
  /**
   * Audio Url
   *
   * URL of the audio file to analyze
   */
  audio_url: string | Blob | File
}

/**
 * DemucsOutput
 */
export type SchemaDemucsOutput = {
  /**
   * Separated vocals audio file
   */
  vocals?: SchemaFile | unknown
  /**
   * Separated guitar audio file (only available for 6s models)
   */
  guitar?: SchemaFile | unknown
  /**
   * Separated bass audio file
   */
  bass?: SchemaFile | unknown
  /**
   * Separated piano audio file (only available for 6s models)
   */
  piano?: SchemaFile | unknown
  /**
   * Separated other instruments audio file
   */
  other?: SchemaFile | unknown
  /**
   * Separated drums audio file
   */
  drums?: SchemaFile | unknown
}

/**
 * DemucsInput
 */
export type SchemaDemucsInput = {
  /**
   * Segment Length
   *
   * Length in seconds of each segment for processing. Smaller values use less memory but may reduce quality. Default is model-specific.
   */
  segment_length?: number | unknown
  /**
   * Output Format
   *
   * Output audio format for the separated stems
   */
  output_format?: 'wav' | 'mp3'
  /**
   * Stems
   *
   * Specific stems to extract. If None, extracts all available stems. Available stems depend on model: vocals, drums, bass, other, guitar, piano (for 6s model)
   */
  stems?:
    | Array<'vocals' | 'drums' | 'bass' | 'other' | 'guitar' | 'piano'>
    | unknown
  /**
   * Overlap
   *
   * Overlap between segments (0.0 to 1.0). Higher values may improve quality but increase processing time.
   */
  overlap?: number
  /**
   * Model
   *
   * Demucs model to use for separation
   */
  model?:
    | 'htdemucs'
    | 'htdemucs_ft'
    | 'htdemucs_6s'
    | 'hdemucs_mmi'
    | 'mdx'
    | 'mdx_extra'
    | 'mdx_q'
    | 'mdx_extra_q'
  /**
   * Audio Url
   *
   * URL of the audio file to separate into stems
   */
  audio_url: string | Blob | File
  /**
   * Shifts
   *
   * Number of random shifts for equivariant stabilization. Higher values improve quality but increase processing time.
   */
  shifts?: number
}

/**
 * CreateVoiceOutput
 *
 * Response model for creating a custom voice.
 */
export type SchemaKlingVideoCreateVoiceOutput = {
  /**
   * Voice Id
   *
   * Unique identifier for the created voice
   */
  voice_id: string
}

/**
 * CreateVoiceInput
 *
 * Request model for creating a custom voice.
 */
export type SchemaKlingVideoCreateVoiceInput = {
  /**
   * Voice Url
   *
   * URL of the voice audio file. Supports .mp3/.wav audio or .mp4/.mov video. Duration must be 5-30 seconds with clean, single-voice audio.
   */
  voice_url: string | Blob | File
}

/**
 * MergeAudiosOutput
 */
export type SchemaFfmpegApiMergeAudiosOutput = {
  audio: SchemaFile
}

/**
 * MergeAudiosInput
 */
export type SchemaFfmpegApiMergeAudiosInput = {
  /**
   * Audio Urls
   *
   * List of audio URLs to merge in order. The 0th stream of the audio will be considered as the merge candidate.
   */
  audio_urls: Array<string | Blob | File>
  /**
   * Output Format
   *
   * Output format of the combined audio. If not used, will be determined automatically using FFMPEG. Formatted as codec_sample_rate_bitrate.
   */
  output_format?:
    | 'mp3_22050_32'
    | 'mp3_44100_32'
    | 'mp3_44100_64'
    | 'mp3_44100_96'
    | 'mp3_44100_128'
    | 'mp3_44100_192'
    | 'pcm_8000'
    | 'pcm_16000'
    | 'pcm_22050'
    | 'pcm_24000'
    | 'pcm_44100'
    | 'pcm_48000'
    | 'ulaw_8000'
    | 'alaw_8000'
    | 'opus_48000_32'
    | 'opus_48000_64'
    | 'opus_48000_96'
    | 'opus_48000_128'
    | 'opus_48000_192'
    | unknown
}

/**
 * AudioTimeSpan
 *
 * A time span indicating where the target sound occurs.
 */
export type SchemaAudioTimeSpan = {
  /**
   * End
   *
   * End time of the span in seconds
   */
  end: number
  /**
   * Start
   *
   * Start time of the span in seconds
   */
  start: number
  /**
   * Include
   *
   * Whether to include (True) or exclude (False) sounds in this span
   */
  include?: boolean
}

/**
 * SAMAudioSpanSeparateOutput
 *
 * Output for span-based audio separation.
 */
export type SchemaSamAudioSpanSeparateOutput = {
  /**
   * Target
   *
   * The isolated target sound.
   */
  target: SchemaFile
  /**
   * Duration
   *
   * Duration of the output audio in seconds.
   */
  duration: number
  /**
   * Sample Rate
   *
   * Sample rate of the output audio in Hz.
   */
  sample_rate?: number
  /**
   * Residual
   *
   * Everything else in the audio.
   */
  residual: SchemaFile
}

/**
 * SAMAudioSpanInput
 *
 * Input for temporal span-based audio separation.
 */
export type SchemaSamAudioSpanSeparateInput = {
  /**
   * Prompt
   *
   * Text prompt describing the sound to isolate. Optional but recommended - helps the model identify what type of sound to extract from the span.
   */
  prompt?: string
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: 'fast' | 'balanced' | 'quality'
  /**
   * Spans
   *
   * Time spans where the target sound occurs which should be isolated.
   */
  spans: Array<SchemaAudioTimeSpan>
  /**
   * Output Format
   *
   * Output audio format.
   */
  output_format?: 'wav' | 'mp3'
  /**
   * Trim To Span
   *
   * Trim output audio to only include the specified span time range. If False, returns the full audio length with the target sound isolated throughout.
   */
  trim_to_span?: boolean
  /**
   * Audio Url
   *
   * URL of the audio file to process.
   */
  audio_url: string | Blob | File
  /**
   * Reranking Candidates
   *
   * Number of candidates to generate and rank. Higher improves quality but increases latency and cost. Requires text prompt; ignored for span-only separation.
   */
  reranking_candidates?: number
}

/**
 * SAMAudioSeparateOutput
 *
 * Output for text-based audio separation.
 */
export type SchemaSamAudioSeparateOutput = {
  /**
   * Target
   *
   * The isolated target sound.
   */
  target: SchemaFile
  /**
   * Duration
   *
   * Duration of the output audio in seconds.
   */
  duration: number
  /**
   * Sample Rate
   *
   * Sample rate of the output audio in Hz.
   */
  sample_rate?: number
  /**
   * Residual
   *
   * Everything else in the audio.
   */
  residual: SchemaFile
}

/**
 * SAMAudioInput
 *
 * Input for text-based audio separation.
 */
export type SchemaSamAudioSeparateInput = {
  /**
   * Prompt
   *
   * Text prompt describing the sound to isolate.
   */
  prompt: string
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: 'fast' | 'balanced' | 'quality'
  /**
   * Audio Url
   *
   * URL of the audio file to process (WAV, MP3, FLAC supported)
   */
  audio_url: string | Blob | File
  /**
   * Predict Spans
   *
   * Automatically predict temporal spans where the target sound occurs.
   */
  predict_spans?: boolean
  /**
   * Output Format
   *
   * Output audio format.
   */
  output_format?: 'wav' | 'mp3'
  /**
   * Reranking Candidates
   *
   * Number of candidates to generate and rank. Higher improves quality but increases latency and cost.
   */
  reranking_candidates?: number
}

/**
 * DeepFilterNetTimings
 */
export type SchemaDeepFilterNetTimings = {
  /**
   * Postprocess
   *
   * Postprocessing time.
   */
  postprocess: number
  /**
   * Inference
   *
   * Inference time.
   */
  inference: number
  /**
   * Preprocess
   *
   * Preprocessing time.
   */
  preprocess: number
}

/**
 * DeepFilterNet3Output
 */
export type SchemaDeepfilternet3Output = {
  /**
   * Timings
   *
   * Timings for each step in the pipeline.
   */
  timings: SchemaDeepFilterNetTimings
  /**
   * Audio File
   *
   * The audio file that was enhanced.
   */
  audio_file: SchemaAudioFile
}

/**
 * DeepFilterNet3Input
 */
export type SchemaDeepfilternet3Input = {
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Audio Format
   *
   * The format for the output audio.
   */
  audio_format?: 'mp3' | 'aac' | 'm4a' | 'ogg' | 'opus' | 'flac' | 'wav'
  /**
   * Audio URL
   *
   * The URL of the audio to enhance.
   */
  audio_url: string | Blob | File
  /**
   * Bitrate
   *
   * The bitrate of the output audio.
   */
  bitrate?: string
}

/**
 * NovaSRTimings
 */
export type SchemaNovaSrTimings = {
  /**
   * Postprocess
   *
   * Time taken to postprocess the audio in seconds.
   */
  postprocess: number
  /**
   * Inference
   *
   * Time taken to run the inference in seconds.
   */
  inference: number
  /**
   * Preprocess
   *
   * Time taken to preprocess the audio in seconds.
   */
  preprocess: number
}

/**
 * NovaSROutput
 */
export type SchemaNovaSrOutput = {
  /**
   * Timings
   *
   * Timings for each step in the pipeline.
   */
  timings: SchemaNovaSrTimings
  /**
   * Audio
   *
   * The enhanced audio file.
   */
  audio: SchemaAudioFile
}

/**
 * NovaSRInput
 */
export type SchemaNovaSrInput = {
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Bitrate
   *
   * The bitrate of the output audio.
   */
  bitrate?: string
  /**
   * Audio URL
   *
   * The URL of the audio file to enhance.
   */
  audio_url: string | Blob | File
  /**
   * Audio Format
   *
   * The format for the output audio.
   */
  audio_format?: 'mp3' | 'aac' | 'm4a' | 'ogg' | 'opus' | 'flac' | 'wav'
}

/**
 * VoiceChangerOutput
 */
export type SchemaElevenlabsVoiceChangerOutput = {
  /**
   * Seed
   *
   * Random seed for reproducibility.
   */
  seed: number
  audio: SchemaFile
}

/**
 * VoiceChangerRequest
 */
export type SchemaElevenlabsVoiceChangerInput = {
  /**
   * Voice
   *
   * The voice to use for speech generation
   */
  voice?: string
  /**
   * Audio Url
   *
   * The input audio file
   */
  audio_url: string | Blob | File
  /**
   * Seed
   *
   * Random seed for reproducibility.
   */
  seed?: number
  /**
   * Output Format
   *
   * Output format of the generated audio. Formatted as codec_sample_rate_bitrate.
   */
  output_format?:
    | 'mp3_22050_32'
    | 'mp3_44100_32'
    | 'mp3_44100_64'
    | 'mp3_44100_96'
    | 'mp3_44100_128'
    | 'mp3_44100_192'
    | 'pcm_8000'
    | 'pcm_16000'
    | 'pcm_22050'
    | 'pcm_24000'
    | 'pcm_44100'
    | 'pcm_48000'
    | 'ulaw_8000'
    | 'alaw_8000'
    | 'opus_48000_32'
    | 'opus_48000_64'
    | 'opus_48000_96'
    | 'opus_48000_128'
    | 'opus_48000_192'
  /**
   * Remove Background Noise
   *
   * If set, will remove the background noise from your audio input using our audio isolation model.
   */
  remove_background_noise?: boolean
}

export type SchemaQueueStatus = {
  status: 'IN_QUEUE' | 'IN_PROGRESS' | 'COMPLETED'
  /**
   * The request id.
   */
  request_id: string
  /**
   * The response url.
   */
  response_url?: string
  /**
   * The status url.
   */
  status_url?: string
  /**
   * The cancel url.
   */
  cancel_url?: string
  /**
   * The logs.
   */
  logs?: {
    [key: string]: unknown
  }
  /**
   * The metrics.
   */
  metrics?: {
    [key: string]: unknown
  }
  /**
   * The queue position.
   */
  queue_position?: number
}

export type GetFalAiElevenlabsVoiceChangerRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/elevenlabs/voice-changer/requests/{request_id}/status'
}

export type GetFalAiElevenlabsVoiceChangerRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiElevenlabsVoiceChangerRequestsByRequestIdStatusResponse =
  GetFalAiElevenlabsVoiceChangerRequestsByRequestIdStatusResponses[keyof GetFalAiElevenlabsVoiceChangerRequestsByRequestIdStatusResponses]

export type PutFalAiElevenlabsVoiceChangerRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/elevenlabs/voice-changer/requests/{request_id}/cancel'
}

export type PutFalAiElevenlabsVoiceChangerRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiElevenlabsVoiceChangerRequestsByRequestIdCancelResponse =
  PutFalAiElevenlabsVoiceChangerRequestsByRequestIdCancelResponses[keyof PutFalAiElevenlabsVoiceChangerRequestsByRequestIdCancelResponses]

export type PostFalAiElevenlabsVoiceChangerData = {
  body: SchemaElevenlabsVoiceChangerInput
  path?: never
  query?: never
  url: '/fal-ai/elevenlabs/voice-changer'
}

export type PostFalAiElevenlabsVoiceChangerResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiElevenlabsVoiceChangerResponse =
  PostFalAiElevenlabsVoiceChangerResponses[keyof PostFalAiElevenlabsVoiceChangerResponses]

export type GetFalAiElevenlabsVoiceChangerRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/elevenlabs/voice-changer/requests/{request_id}'
}

export type GetFalAiElevenlabsVoiceChangerRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaElevenlabsVoiceChangerOutput
}

export type GetFalAiElevenlabsVoiceChangerRequestsByRequestIdResponse =
  GetFalAiElevenlabsVoiceChangerRequestsByRequestIdResponses[keyof GetFalAiElevenlabsVoiceChangerRequestsByRequestIdResponses]

export type GetFalAiNovaSrRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/nova-sr/requests/{request_id}/status'
}

export type GetFalAiNovaSrRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiNovaSrRequestsByRequestIdStatusResponse =
  GetFalAiNovaSrRequestsByRequestIdStatusResponses[keyof GetFalAiNovaSrRequestsByRequestIdStatusResponses]

export type PutFalAiNovaSrRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/nova-sr/requests/{request_id}/cancel'
}

export type PutFalAiNovaSrRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiNovaSrRequestsByRequestIdCancelResponse =
  PutFalAiNovaSrRequestsByRequestIdCancelResponses[keyof PutFalAiNovaSrRequestsByRequestIdCancelResponses]

export type PostFalAiNovaSrData = {
  body: SchemaNovaSrInput
  path?: never
  query?: never
  url: '/fal-ai/nova-sr'
}

export type PostFalAiNovaSrResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiNovaSrResponse =
  PostFalAiNovaSrResponses[keyof PostFalAiNovaSrResponses]

export type GetFalAiNovaSrRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/nova-sr/requests/{request_id}'
}

export type GetFalAiNovaSrRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaNovaSrOutput
}

export type GetFalAiNovaSrRequestsByRequestIdResponse =
  GetFalAiNovaSrRequestsByRequestIdResponses[keyof GetFalAiNovaSrRequestsByRequestIdResponses]

export type GetFalAiDeepfilternet3RequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/deepfilternet3/requests/{request_id}/status'
}

export type GetFalAiDeepfilternet3RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiDeepfilternet3RequestsByRequestIdStatusResponse =
  GetFalAiDeepfilternet3RequestsByRequestIdStatusResponses[keyof GetFalAiDeepfilternet3RequestsByRequestIdStatusResponses]

export type PutFalAiDeepfilternet3RequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/deepfilternet3/requests/{request_id}/cancel'
}

export type PutFalAiDeepfilternet3RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiDeepfilternet3RequestsByRequestIdCancelResponse =
  PutFalAiDeepfilternet3RequestsByRequestIdCancelResponses[keyof PutFalAiDeepfilternet3RequestsByRequestIdCancelResponses]

export type PostFalAiDeepfilternet3Data = {
  body: SchemaDeepfilternet3Input
  path?: never
  query?: never
  url: '/fal-ai/deepfilternet3'
}

export type PostFalAiDeepfilternet3Responses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiDeepfilternet3Response =
  PostFalAiDeepfilternet3Responses[keyof PostFalAiDeepfilternet3Responses]

export type GetFalAiDeepfilternet3RequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/deepfilternet3/requests/{request_id}'
}

export type GetFalAiDeepfilternet3RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaDeepfilternet3Output
}

export type GetFalAiDeepfilternet3RequestsByRequestIdResponse =
  GetFalAiDeepfilternet3RequestsByRequestIdResponses[keyof GetFalAiDeepfilternet3RequestsByRequestIdResponses]

export type GetFalAiSamAudioSeparateRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/sam-audio/separate/requests/{request_id}/status'
}

export type GetFalAiSamAudioSeparateRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiSamAudioSeparateRequestsByRequestIdStatusResponse =
  GetFalAiSamAudioSeparateRequestsByRequestIdStatusResponses[keyof GetFalAiSamAudioSeparateRequestsByRequestIdStatusResponses]

export type PutFalAiSamAudioSeparateRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/sam-audio/separate/requests/{request_id}/cancel'
}

export type PutFalAiSamAudioSeparateRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiSamAudioSeparateRequestsByRequestIdCancelResponse =
  PutFalAiSamAudioSeparateRequestsByRequestIdCancelResponses[keyof PutFalAiSamAudioSeparateRequestsByRequestIdCancelResponses]

export type PostFalAiSamAudioSeparateData = {
  body: SchemaSamAudioSeparateInput
  path?: never
  query?: never
  url: '/fal-ai/sam-audio/separate'
}

export type PostFalAiSamAudioSeparateResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiSamAudioSeparateResponse =
  PostFalAiSamAudioSeparateResponses[keyof PostFalAiSamAudioSeparateResponses]

export type GetFalAiSamAudioSeparateRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/sam-audio/separate/requests/{request_id}'
}

export type GetFalAiSamAudioSeparateRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaSamAudioSeparateOutput
}

export type GetFalAiSamAudioSeparateRequestsByRequestIdResponse =
  GetFalAiSamAudioSeparateRequestsByRequestIdResponses[keyof GetFalAiSamAudioSeparateRequestsByRequestIdResponses]

export type GetFalAiSamAudioSpanSeparateRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/sam-audio/span-separate/requests/{request_id}/status'
}

export type GetFalAiSamAudioSpanSeparateRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiSamAudioSpanSeparateRequestsByRequestIdStatusResponse =
  GetFalAiSamAudioSpanSeparateRequestsByRequestIdStatusResponses[keyof GetFalAiSamAudioSpanSeparateRequestsByRequestIdStatusResponses]

export type PutFalAiSamAudioSpanSeparateRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/sam-audio/span-separate/requests/{request_id}/cancel'
}

export type PutFalAiSamAudioSpanSeparateRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiSamAudioSpanSeparateRequestsByRequestIdCancelResponse =
  PutFalAiSamAudioSpanSeparateRequestsByRequestIdCancelResponses[keyof PutFalAiSamAudioSpanSeparateRequestsByRequestIdCancelResponses]

export type PostFalAiSamAudioSpanSeparateData = {
  body: SchemaSamAudioSpanSeparateInput
  path?: never
  query?: never
  url: '/fal-ai/sam-audio/span-separate'
}

export type PostFalAiSamAudioSpanSeparateResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiSamAudioSpanSeparateResponse =
  PostFalAiSamAudioSpanSeparateResponses[keyof PostFalAiSamAudioSpanSeparateResponses]

export type GetFalAiSamAudioSpanSeparateRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/sam-audio/span-separate/requests/{request_id}'
}

export type GetFalAiSamAudioSpanSeparateRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaSamAudioSpanSeparateOutput
}

export type GetFalAiSamAudioSpanSeparateRequestsByRequestIdResponse =
  GetFalAiSamAudioSpanSeparateRequestsByRequestIdResponses[keyof GetFalAiSamAudioSpanSeparateRequestsByRequestIdResponses]

export type GetFalAiFfmpegApiMergeAudiosRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ffmpeg-api/merge-audios/requests/{request_id}/status'
}

export type GetFalAiFfmpegApiMergeAudiosRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiFfmpegApiMergeAudiosRequestsByRequestIdStatusResponse =
  GetFalAiFfmpegApiMergeAudiosRequestsByRequestIdStatusResponses[keyof GetFalAiFfmpegApiMergeAudiosRequestsByRequestIdStatusResponses]

export type PutFalAiFfmpegApiMergeAudiosRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ffmpeg-api/merge-audios/requests/{request_id}/cancel'
}

export type PutFalAiFfmpegApiMergeAudiosRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiFfmpegApiMergeAudiosRequestsByRequestIdCancelResponse =
  PutFalAiFfmpegApiMergeAudiosRequestsByRequestIdCancelResponses[keyof PutFalAiFfmpegApiMergeAudiosRequestsByRequestIdCancelResponses]

export type PostFalAiFfmpegApiMergeAudiosData = {
  body: SchemaFfmpegApiMergeAudiosInput
  path?: never
  query?: never
  url: '/fal-ai/ffmpeg-api/merge-audios'
}

export type PostFalAiFfmpegApiMergeAudiosResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiFfmpegApiMergeAudiosResponse =
  PostFalAiFfmpegApiMergeAudiosResponses[keyof PostFalAiFfmpegApiMergeAudiosResponses]

export type GetFalAiFfmpegApiMergeAudiosRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ffmpeg-api/merge-audios/requests/{request_id}'
}

export type GetFalAiFfmpegApiMergeAudiosRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaFfmpegApiMergeAudiosOutput
}

export type GetFalAiFfmpegApiMergeAudiosRequestsByRequestIdResponse =
  GetFalAiFfmpegApiMergeAudiosRequestsByRequestIdResponses[keyof GetFalAiFfmpegApiMergeAudiosRequestsByRequestIdResponses]

export type GetFalAiKlingVideoCreateVoiceRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kling-video/create-voice/requests/{request_id}/status'
}

export type GetFalAiKlingVideoCreateVoiceRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiKlingVideoCreateVoiceRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoCreateVoiceRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoCreateVoiceRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoCreateVoiceRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/create-voice/requests/{request_id}/cancel'
}

export type PutFalAiKlingVideoCreateVoiceRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiKlingVideoCreateVoiceRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoCreateVoiceRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoCreateVoiceRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoCreateVoiceData = {
  body: SchemaKlingVideoCreateVoiceInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/create-voice'
}

export type PostFalAiKlingVideoCreateVoiceResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoCreateVoiceResponse =
  PostFalAiKlingVideoCreateVoiceResponses[keyof PostFalAiKlingVideoCreateVoiceResponses]

export type GetFalAiKlingVideoCreateVoiceRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/create-voice/requests/{request_id}'
}

export type GetFalAiKlingVideoCreateVoiceRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKlingVideoCreateVoiceOutput
}

export type GetFalAiKlingVideoCreateVoiceRequestsByRequestIdResponse =
  GetFalAiKlingVideoCreateVoiceRequestsByRequestIdResponses[keyof GetFalAiKlingVideoCreateVoiceRequestsByRequestIdResponses]

export type GetFalAiDemucsRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/demucs/requests/{request_id}/status'
}

export type GetFalAiDemucsRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiDemucsRequestsByRequestIdStatusResponse =
  GetFalAiDemucsRequestsByRequestIdStatusResponses[keyof GetFalAiDemucsRequestsByRequestIdStatusResponses]

export type PutFalAiDemucsRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/demucs/requests/{request_id}/cancel'
}

export type PutFalAiDemucsRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiDemucsRequestsByRequestIdCancelResponse =
  PutFalAiDemucsRequestsByRequestIdCancelResponses[keyof PutFalAiDemucsRequestsByRequestIdCancelResponses]

export type PostFalAiDemucsData = {
  body: SchemaDemucsInput
  path?: never
  query?: never
  url: '/fal-ai/demucs'
}

export type PostFalAiDemucsResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiDemucsResponse =
  PostFalAiDemucsResponses[keyof PostFalAiDemucsResponses]

export type GetFalAiDemucsRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/demucs/requests/{request_id}'
}

export type GetFalAiDemucsRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaDemucsOutput
}

export type GetFalAiDemucsRequestsByRequestIdResponse =
  GetFalAiDemucsRequestsByRequestIdResponses[keyof GetFalAiDemucsRequestsByRequestIdResponses]

export type GetFalAiAudioUnderstandingRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/audio-understanding/requests/{request_id}/status'
}

export type GetFalAiAudioUnderstandingRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiAudioUnderstandingRequestsByRequestIdStatusResponse =
  GetFalAiAudioUnderstandingRequestsByRequestIdStatusResponses[keyof GetFalAiAudioUnderstandingRequestsByRequestIdStatusResponses]

export type PutFalAiAudioUnderstandingRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/audio-understanding/requests/{request_id}/cancel'
}

export type PutFalAiAudioUnderstandingRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiAudioUnderstandingRequestsByRequestIdCancelResponse =
  PutFalAiAudioUnderstandingRequestsByRequestIdCancelResponses[keyof PutFalAiAudioUnderstandingRequestsByRequestIdCancelResponses]

export type PostFalAiAudioUnderstandingData = {
  body: SchemaAudioUnderstandingInput
  path?: never
  query?: never
  url: '/fal-ai/audio-understanding'
}

export type PostFalAiAudioUnderstandingResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiAudioUnderstandingResponse =
  PostFalAiAudioUnderstandingResponses[keyof PostFalAiAudioUnderstandingResponses]

export type GetFalAiAudioUnderstandingRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/audio-understanding/requests/{request_id}'
}

export type GetFalAiAudioUnderstandingRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaAudioUnderstandingOutput
}

export type GetFalAiAudioUnderstandingRequestsByRequestIdResponse =
  GetFalAiAudioUnderstandingRequestsByRequestIdResponses[keyof GetFalAiAudioUnderstandingRequestsByRequestIdResponses]

export type GetFalAiStableAudio25AudioToAudioRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/stable-audio-25/audio-to-audio/requests/{request_id}/status'
}

export type GetFalAiStableAudio25AudioToAudioRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiStableAudio25AudioToAudioRequestsByRequestIdStatusResponse =
  GetFalAiStableAudio25AudioToAudioRequestsByRequestIdStatusResponses[keyof GetFalAiStableAudio25AudioToAudioRequestsByRequestIdStatusResponses]

export type PutFalAiStableAudio25AudioToAudioRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/stable-audio-25/audio-to-audio/requests/{request_id}/cancel'
}

export type PutFalAiStableAudio25AudioToAudioRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiStableAudio25AudioToAudioRequestsByRequestIdCancelResponse =
  PutFalAiStableAudio25AudioToAudioRequestsByRequestIdCancelResponses[keyof PutFalAiStableAudio25AudioToAudioRequestsByRequestIdCancelResponses]

export type PostFalAiStableAudio25AudioToAudioData = {
  body: SchemaStableAudio25AudioToAudioInput
  path?: never
  query?: never
  url: '/fal-ai/stable-audio-25/audio-to-audio'
}

export type PostFalAiStableAudio25AudioToAudioResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiStableAudio25AudioToAudioResponse =
  PostFalAiStableAudio25AudioToAudioResponses[keyof PostFalAiStableAudio25AudioToAudioResponses]

export type GetFalAiStableAudio25AudioToAudioRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/stable-audio-25/audio-to-audio/requests/{request_id}'
}

export type GetFalAiStableAudio25AudioToAudioRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaStableAudio25AudioToAudioOutput
}

export type GetFalAiStableAudio25AudioToAudioRequestsByRequestIdResponse =
  GetFalAiStableAudio25AudioToAudioRequestsByRequestIdResponses[keyof GetFalAiStableAudio25AudioToAudioRequestsByRequestIdResponses]

export type GetFalAiStableAudio25InpaintRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/stable-audio-25/inpaint/requests/{request_id}/status'
}

export type GetFalAiStableAudio25InpaintRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiStableAudio25InpaintRequestsByRequestIdStatusResponse =
  GetFalAiStableAudio25InpaintRequestsByRequestIdStatusResponses[keyof GetFalAiStableAudio25InpaintRequestsByRequestIdStatusResponses]

export type PutFalAiStableAudio25InpaintRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/stable-audio-25/inpaint/requests/{request_id}/cancel'
}

export type PutFalAiStableAudio25InpaintRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiStableAudio25InpaintRequestsByRequestIdCancelResponse =
  PutFalAiStableAudio25InpaintRequestsByRequestIdCancelResponses[keyof PutFalAiStableAudio25InpaintRequestsByRequestIdCancelResponses]

export type PostFalAiStableAudio25InpaintData = {
  body: SchemaStableAudio25InpaintInput
  path?: never
  query?: never
  url: '/fal-ai/stable-audio-25/inpaint'
}

export type PostFalAiStableAudio25InpaintResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiStableAudio25InpaintResponse =
  PostFalAiStableAudio25InpaintResponses[keyof PostFalAiStableAudio25InpaintResponses]

export type GetFalAiStableAudio25InpaintRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/stable-audio-25/inpaint/requests/{request_id}'
}

export type GetFalAiStableAudio25InpaintRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaStableAudio25InpaintOutput
}

export type GetFalAiStableAudio25InpaintRequestsByRequestIdResponse =
  GetFalAiStableAudio25InpaintRequestsByRequestIdResponses[keyof GetFalAiStableAudio25InpaintRequestsByRequestIdResponses]

export type GetSonautoV2ExtendRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/sonauto/v2/extend/requests/{request_id}/status'
}

export type GetSonautoV2ExtendRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetSonautoV2ExtendRequestsByRequestIdStatusResponse =
  GetSonautoV2ExtendRequestsByRequestIdStatusResponses[keyof GetSonautoV2ExtendRequestsByRequestIdStatusResponses]

export type PutSonautoV2ExtendRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/sonauto/v2/extend/requests/{request_id}/cancel'
}

export type PutSonautoV2ExtendRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutSonautoV2ExtendRequestsByRequestIdCancelResponse =
  PutSonautoV2ExtendRequestsByRequestIdCancelResponses[keyof PutSonautoV2ExtendRequestsByRequestIdCancelResponses]

export type PostSonautoV2ExtendData = {
  body: SchemaV2ExtendInput
  path?: never
  query?: never
  url: '/sonauto/v2/extend'
}

export type PostSonautoV2ExtendResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostSonautoV2ExtendResponse =
  PostSonautoV2ExtendResponses[keyof PostSonautoV2ExtendResponses]

export type GetSonautoV2ExtendRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/sonauto/v2/extend/requests/{request_id}'
}

export type GetSonautoV2ExtendRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaV2ExtendOutput
}

export type GetSonautoV2ExtendRequestsByRequestIdResponse =
  GetSonautoV2ExtendRequestsByRequestIdResponses[keyof GetSonautoV2ExtendRequestsByRequestIdResponses]

export type GetFalAiAceStepAudioOutpaintRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ace-step/audio-outpaint/requests/{request_id}/status'
}

export type GetFalAiAceStepAudioOutpaintRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiAceStepAudioOutpaintRequestsByRequestIdStatusResponse =
  GetFalAiAceStepAudioOutpaintRequestsByRequestIdStatusResponses[keyof GetFalAiAceStepAudioOutpaintRequestsByRequestIdStatusResponses]

export type PutFalAiAceStepAudioOutpaintRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ace-step/audio-outpaint/requests/{request_id}/cancel'
}

export type PutFalAiAceStepAudioOutpaintRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiAceStepAudioOutpaintRequestsByRequestIdCancelResponse =
  PutFalAiAceStepAudioOutpaintRequestsByRequestIdCancelResponses[keyof PutFalAiAceStepAudioOutpaintRequestsByRequestIdCancelResponses]

export type PostFalAiAceStepAudioOutpaintData = {
  body: SchemaAceStepAudioOutpaintInput
  path?: never
  query?: never
  url: '/fal-ai/ace-step/audio-outpaint'
}

export type PostFalAiAceStepAudioOutpaintResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiAceStepAudioOutpaintResponse =
  PostFalAiAceStepAudioOutpaintResponses[keyof PostFalAiAceStepAudioOutpaintResponses]

export type GetFalAiAceStepAudioOutpaintRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ace-step/audio-outpaint/requests/{request_id}'
}

export type GetFalAiAceStepAudioOutpaintRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaAceStepAudioOutpaintOutput
}

export type GetFalAiAceStepAudioOutpaintRequestsByRequestIdResponse =
  GetFalAiAceStepAudioOutpaintRequestsByRequestIdResponses[keyof GetFalAiAceStepAudioOutpaintRequestsByRequestIdResponses]

export type GetFalAiAceStepAudioInpaintRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ace-step/audio-inpaint/requests/{request_id}/status'
}

export type GetFalAiAceStepAudioInpaintRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiAceStepAudioInpaintRequestsByRequestIdStatusResponse =
  GetFalAiAceStepAudioInpaintRequestsByRequestIdStatusResponses[keyof GetFalAiAceStepAudioInpaintRequestsByRequestIdStatusResponses]

export type PutFalAiAceStepAudioInpaintRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ace-step/audio-inpaint/requests/{request_id}/cancel'
}

export type PutFalAiAceStepAudioInpaintRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiAceStepAudioInpaintRequestsByRequestIdCancelResponse =
  PutFalAiAceStepAudioInpaintRequestsByRequestIdCancelResponses[keyof PutFalAiAceStepAudioInpaintRequestsByRequestIdCancelResponses]

export type PostFalAiAceStepAudioInpaintData = {
  body: SchemaAceStepAudioInpaintInput
  path?: never
  query?: never
  url: '/fal-ai/ace-step/audio-inpaint'
}

export type PostFalAiAceStepAudioInpaintResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiAceStepAudioInpaintResponse =
  PostFalAiAceStepAudioInpaintResponses[keyof PostFalAiAceStepAudioInpaintResponses]

export type GetFalAiAceStepAudioInpaintRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ace-step/audio-inpaint/requests/{request_id}'
}

export type GetFalAiAceStepAudioInpaintRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaAceStepAudioInpaintOutput
}

export type GetFalAiAceStepAudioInpaintRequestsByRequestIdResponse =
  GetFalAiAceStepAudioInpaintRequestsByRequestIdResponses[keyof GetFalAiAceStepAudioInpaintRequestsByRequestIdResponses]

export type GetFalAiAceStepAudioToAudioRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ace-step/audio-to-audio/requests/{request_id}/status'
}

export type GetFalAiAceStepAudioToAudioRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiAceStepAudioToAudioRequestsByRequestIdStatusResponse =
  GetFalAiAceStepAudioToAudioRequestsByRequestIdStatusResponses[keyof GetFalAiAceStepAudioToAudioRequestsByRequestIdStatusResponses]

export type PutFalAiAceStepAudioToAudioRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ace-step/audio-to-audio/requests/{request_id}/cancel'
}

export type PutFalAiAceStepAudioToAudioRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiAceStepAudioToAudioRequestsByRequestIdCancelResponse =
  PutFalAiAceStepAudioToAudioRequestsByRequestIdCancelResponses[keyof PutFalAiAceStepAudioToAudioRequestsByRequestIdCancelResponses]

export type PostFalAiAceStepAudioToAudioData = {
  body: SchemaAceStepAudioToAudioInput
  path?: never
  query?: never
  url: '/fal-ai/ace-step/audio-to-audio'
}

export type PostFalAiAceStepAudioToAudioResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiAceStepAudioToAudioResponse =
  PostFalAiAceStepAudioToAudioResponses[keyof PostFalAiAceStepAudioToAudioResponses]

export type GetFalAiAceStepAudioToAudioRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ace-step/audio-to-audio/requests/{request_id}'
}

export type GetFalAiAceStepAudioToAudioRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaAceStepAudioToAudioOutput
}

export type GetFalAiAceStepAudioToAudioRequestsByRequestIdResponse =
  GetFalAiAceStepAudioToAudioRequestsByRequestIdResponses[keyof GetFalAiAceStepAudioToAudioRequestsByRequestIdResponses]

export type GetFalAiDiaTtsVoiceCloneRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/dia-tts/voice-clone/requests/{request_id}/status'
}

export type GetFalAiDiaTtsVoiceCloneRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiDiaTtsVoiceCloneRequestsByRequestIdStatusResponse =
  GetFalAiDiaTtsVoiceCloneRequestsByRequestIdStatusResponses[keyof GetFalAiDiaTtsVoiceCloneRequestsByRequestIdStatusResponses]

export type PutFalAiDiaTtsVoiceCloneRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/dia-tts/voice-clone/requests/{request_id}/cancel'
}

export type PutFalAiDiaTtsVoiceCloneRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiDiaTtsVoiceCloneRequestsByRequestIdCancelResponse =
  PutFalAiDiaTtsVoiceCloneRequestsByRequestIdCancelResponses[keyof PutFalAiDiaTtsVoiceCloneRequestsByRequestIdCancelResponses]

export type PostFalAiDiaTtsVoiceCloneData = {
  body: SchemaDiaTtsVoiceCloneInput
  path?: never
  query?: never
  url: '/fal-ai/dia-tts/voice-clone'
}

export type PostFalAiDiaTtsVoiceCloneResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiDiaTtsVoiceCloneResponse =
  PostFalAiDiaTtsVoiceCloneResponses[keyof PostFalAiDiaTtsVoiceCloneResponses]

export type GetFalAiDiaTtsVoiceCloneRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/dia-tts/voice-clone/requests/{request_id}'
}

export type GetFalAiDiaTtsVoiceCloneRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaDiaTtsVoiceCloneOutput
}

export type GetFalAiDiaTtsVoiceCloneRequestsByRequestIdResponse =
  GetFalAiDiaTtsVoiceCloneRequestsByRequestIdResponses[keyof GetFalAiDiaTtsVoiceCloneRequestsByRequestIdResponses]

export type GetFalAiElevenlabsAudioIsolationRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/elevenlabs/audio-isolation/requests/{request_id}/status'
}

export type GetFalAiElevenlabsAudioIsolationRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiElevenlabsAudioIsolationRequestsByRequestIdStatusResponse =
  GetFalAiElevenlabsAudioIsolationRequestsByRequestIdStatusResponses[keyof GetFalAiElevenlabsAudioIsolationRequestsByRequestIdStatusResponses]

export type PutFalAiElevenlabsAudioIsolationRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/elevenlabs/audio-isolation/requests/{request_id}/cancel'
}

export type PutFalAiElevenlabsAudioIsolationRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiElevenlabsAudioIsolationRequestsByRequestIdCancelResponse =
  PutFalAiElevenlabsAudioIsolationRequestsByRequestIdCancelResponses[keyof PutFalAiElevenlabsAudioIsolationRequestsByRequestIdCancelResponses]

export type PostFalAiElevenlabsAudioIsolationData = {
  body: SchemaElevenlabsAudioIsolationInput
  path?: never
  query?: never
  url: '/fal-ai/elevenlabs/audio-isolation'
}

export type PostFalAiElevenlabsAudioIsolationResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiElevenlabsAudioIsolationResponse =
  PostFalAiElevenlabsAudioIsolationResponses[keyof PostFalAiElevenlabsAudioIsolationResponses]

export type GetFalAiElevenlabsAudioIsolationRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/elevenlabs/audio-isolation/requests/{request_id}'
}

export type GetFalAiElevenlabsAudioIsolationRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaElevenlabsAudioIsolationOutput
}

export type GetFalAiElevenlabsAudioIsolationRequestsByRequestIdResponse =
  GetFalAiElevenlabsAudioIsolationRequestsByRequestIdResponses[keyof GetFalAiElevenlabsAudioIsolationRequestsByRequestIdResponses]

export type GetFalAiElevenlabsMusicRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/elevenlabs/music/requests/{request_id}/status'
}

export type GetFalAiElevenlabsMusicRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiElevenlabsMusicRequestsByRequestIdStatusResponse =
  GetFalAiElevenlabsMusicRequestsByRequestIdStatusResponses[keyof GetFalAiElevenlabsMusicRequestsByRequestIdStatusResponses]

export type PutFalAiElevenlabsMusicRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/elevenlabs/music/requests/{request_id}/cancel'
}

export type PutFalAiElevenlabsMusicRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiElevenlabsMusicRequestsByRequestIdCancelResponse =
  PutFalAiElevenlabsMusicRequestsByRequestIdCancelResponses[keyof PutFalAiElevenlabsMusicRequestsByRequestIdCancelResponses]

export type PostFalAiElevenlabsMusicData = {
  body: SchemaElevenlabsMusicInput
  path?: never
  query?: never
  url: '/fal-ai/elevenlabs/music'
}

export type PostFalAiElevenlabsMusicResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiElevenlabsMusicResponse =
  PostFalAiElevenlabsMusicResponses[keyof PostFalAiElevenlabsMusicResponses]

export type GetFalAiElevenlabsMusicRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/elevenlabs/music/requests/{request_id}'
}

export type GetFalAiElevenlabsMusicRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaElevenlabsMusicOutput
}

export type GetFalAiElevenlabsMusicRequestsByRequestIdResponse =
  GetFalAiElevenlabsMusicRequestsByRequestIdResponses[keyof GetFalAiElevenlabsMusicRequestsByRequestIdResponses]

export type GetFalAiMinimaxMusicV2RequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/minimax-music/v2/requests/{request_id}/status'
}

export type GetFalAiMinimaxMusicV2RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiMinimaxMusicV2RequestsByRequestIdStatusResponse =
  GetFalAiMinimaxMusicV2RequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxMusicV2RequestsByRequestIdStatusResponses]

export type PutFalAiMinimaxMusicV2RequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax-music/v2/requests/{request_id}/cancel'
}

export type PutFalAiMinimaxMusicV2RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiMinimaxMusicV2RequestsByRequestIdCancelResponse =
  PutFalAiMinimaxMusicV2RequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxMusicV2RequestsByRequestIdCancelResponses]

export type PostFalAiMinimaxMusicV2Data = {
  body: SchemaMinimaxMusicV2Input
  path?: never
  query?: never
  url: '/fal-ai/minimax-music/v2'
}

export type PostFalAiMinimaxMusicV2Responses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMinimaxMusicV2Response =
  PostFalAiMinimaxMusicV2Responses[keyof PostFalAiMinimaxMusicV2Responses]

export type GetFalAiMinimaxMusicV2RequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax-music/v2/requests/{request_id}'
}

export type GetFalAiMinimaxMusicV2RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaMinimaxMusicV2Output
}

export type GetFalAiMinimaxMusicV2RequestsByRequestIdResponse =
  GetFalAiMinimaxMusicV2RequestsByRequestIdResponses[keyof GetFalAiMinimaxMusicV2RequestsByRequestIdResponses]

export type GetBeatovenSoundEffectGenerationRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/beatoven/sound-effect-generation/requests/{request_id}/status'
}

export type GetBeatovenSoundEffectGenerationRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetBeatovenSoundEffectGenerationRequestsByRequestIdStatusResponse =
  GetBeatovenSoundEffectGenerationRequestsByRequestIdStatusResponses[keyof GetBeatovenSoundEffectGenerationRequestsByRequestIdStatusResponses]

export type PutBeatovenSoundEffectGenerationRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/beatoven/sound-effect-generation/requests/{request_id}/cancel'
}

export type PutBeatovenSoundEffectGenerationRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutBeatovenSoundEffectGenerationRequestsByRequestIdCancelResponse =
  PutBeatovenSoundEffectGenerationRequestsByRequestIdCancelResponses[keyof PutBeatovenSoundEffectGenerationRequestsByRequestIdCancelResponses]

export type PostBeatovenSoundEffectGenerationData = {
  body: SchemaSoundEffectGenerationInput
  path?: never
  query?: never
  url: '/beatoven/sound-effect-generation'
}

export type PostBeatovenSoundEffectGenerationResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostBeatovenSoundEffectGenerationResponse =
  PostBeatovenSoundEffectGenerationResponses[keyof PostBeatovenSoundEffectGenerationResponses]

export type GetBeatovenSoundEffectGenerationRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/beatoven/sound-effect-generation/requests/{request_id}'
}

export type GetBeatovenSoundEffectGenerationRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaSoundEffectGenerationOutput
}

export type GetBeatovenSoundEffectGenerationRequestsByRequestIdResponse =
  GetBeatovenSoundEffectGenerationRequestsByRequestIdResponses[keyof GetBeatovenSoundEffectGenerationRequestsByRequestIdResponses]

export type GetBeatovenMusicGenerationRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/beatoven/music-generation/requests/{request_id}/status'
}

export type GetBeatovenMusicGenerationRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetBeatovenMusicGenerationRequestsByRequestIdStatusResponse =
  GetBeatovenMusicGenerationRequestsByRequestIdStatusResponses[keyof GetBeatovenMusicGenerationRequestsByRequestIdStatusResponses]

export type PutBeatovenMusicGenerationRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/beatoven/music-generation/requests/{request_id}/cancel'
}

export type PutBeatovenMusicGenerationRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutBeatovenMusicGenerationRequestsByRequestIdCancelResponse =
  PutBeatovenMusicGenerationRequestsByRequestIdCancelResponses[keyof PutBeatovenMusicGenerationRequestsByRequestIdCancelResponses]

export type PostBeatovenMusicGenerationData = {
  body: SchemaMusicGenerationInput
  path?: never
  query?: never
  url: '/beatoven/music-generation'
}

export type PostBeatovenMusicGenerationResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostBeatovenMusicGenerationResponse =
  PostBeatovenMusicGenerationResponses[keyof PostBeatovenMusicGenerationResponses]

export type GetBeatovenMusicGenerationRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/beatoven/music-generation/requests/{request_id}'
}

export type GetBeatovenMusicGenerationRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaMusicGenerationOutput
}

export type GetBeatovenMusicGenerationRequestsByRequestIdResponse =
  GetBeatovenMusicGenerationRequestsByRequestIdResponses[keyof GetBeatovenMusicGenerationRequestsByRequestIdResponses]

export type GetFalAiMinimaxMusicV15RequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/minimax-music/v1.5/requests/{request_id}/status'
}

export type GetFalAiMinimaxMusicV15RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiMinimaxMusicV15RequestsByRequestIdStatusResponse =
  GetFalAiMinimaxMusicV15RequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxMusicV15RequestsByRequestIdStatusResponses]

export type PutFalAiMinimaxMusicV15RequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax-music/v1.5/requests/{request_id}/cancel'
}

export type PutFalAiMinimaxMusicV15RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiMinimaxMusicV15RequestsByRequestIdCancelResponse =
  PutFalAiMinimaxMusicV15RequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxMusicV15RequestsByRequestIdCancelResponses]

export type PostFalAiMinimaxMusicV15Data = {
  body: SchemaMinimaxMusicV15Input
  path?: never
  query?: never
  url: '/fal-ai/minimax-music/v1.5'
}

export type PostFalAiMinimaxMusicV15Responses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMinimaxMusicV15Response =
  PostFalAiMinimaxMusicV15Responses[keyof PostFalAiMinimaxMusicV15Responses]

export type GetFalAiMinimaxMusicV15RequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax-music/v1.5/requests/{request_id}'
}

export type GetFalAiMinimaxMusicV15RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaMinimaxMusicV15Output
}

export type GetFalAiMinimaxMusicV15RequestsByRequestIdResponse =
  GetFalAiMinimaxMusicV15RequestsByRequestIdResponses[keyof GetFalAiMinimaxMusicV15RequestsByRequestIdResponses]

export type GetFalAiStableAudio25TextToAudioRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/stable-audio-25/text-to-audio/requests/{request_id}/status'
}

export type GetFalAiStableAudio25TextToAudioRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiStableAudio25TextToAudioRequestsByRequestIdStatusResponse =
  GetFalAiStableAudio25TextToAudioRequestsByRequestIdStatusResponses[keyof GetFalAiStableAudio25TextToAudioRequestsByRequestIdStatusResponses]

export type PutFalAiStableAudio25TextToAudioRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/stable-audio-25/text-to-audio/requests/{request_id}/cancel'
}

export type PutFalAiStableAudio25TextToAudioRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiStableAudio25TextToAudioRequestsByRequestIdCancelResponse =
  PutFalAiStableAudio25TextToAudioRequestsByRequestIdCancelResponses[keyof PutFalAiStableAudio25TextToAudioRequestsByRequestIdCancelResponses]

export type PostFalAiStableAudio25TextToAudioData = {
  body: SchemaStableAudio25TextToAudioInput
  path?: never
  query?: never
  url: '/fal-ai/stable-audio-25/text-to-audio'
}

export type PostFalAiStableAudio25TextToAudioResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiStableAudio25TextToAudioResponse =
  PostFalAiStableAudio25TextToAudioResponses[keyof PostFalAiStableAudio25TextToAudioResponses]

export type GetFalAiStableAudio25TextToAudioRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/stable-audio-25/text-to-audio/requests/{request_id}'
}

export type GetFalAiStableAudio25TextToAudioRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaStableAudio25TextToAudioOutput
}

export type GetFalAiStableAudio25TextToAudioRequestsByRequestIdResponse =
  GetFalAiStableAudio25TextToAudioRequestsByRequestIdResponses[keyof GetFalAiStableAudio25TextToAudioRequestsByRequestIdResponses]

export type GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/elevenlabs/text-to-dialogue/eleven-v3/requests/{request_id}/status'
  }

export type GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdStatusResponse =
  GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdStatusResponses[keyof GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdStatusResponses]

export type PutFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/elevenlabs/text-to-dialogue/eleven-v3/requests/{request_id}/cancel'
  }

export type PutFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdCancelResponse =
  PutFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdCancelResponses[keyof PutFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdCancelResponses]

export type PostFalAiElevenlabsTextToDialogueElevenV3Data = {
  body: SchemaElevenlabsTextToDialogueElevenV3Input
  path?: never
  query?: never
  url: '/fal-ai/elevenlabs/text-to-dialogue/eleven-v3'
}

export type PostFalAiElevenlabsTextToDialogueElevenV3Responses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiElevenlabsTextToDialogueElevenV3Response =
  PostFalAiElevenlabsTextToDialogueElevenV3Responses[keyof PostFalAiElevenlabsTextToDialogueElevenV3Responses]

export type GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/elevenlabs/text-to-dialogue/eleven-v3/requests/{request_id}'
}

export type GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaElevenlabsTextToDialogueElevenV3Output
  }

export type GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdResponse =
  GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdResponses[keyof GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdResponses]

export type GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/elevenlabs/sound-effects/v2/requests/{request_id}/status'
}

export type GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdStatusResponse =
  GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdStatusResponses[keyof GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdStatusResponses]

export type PutFalAiElevenlabsSoundEffectsV2RequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/elevenlabs/sound-effects/v2/requests/{request_id}/cancel'
}

export type PutFalAiElevenlabsSoundEffectsV2RequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiElevenlabsSoundEffectsV2RequestsByRequestIdCancelResponse =
  PutFalAiElevenlabsSoundEffectsV2RequestsByRequestIdCancelResponses[keyof PutFalAiElevenlabsSoundEffectsV2RequestsByRequestIdCancelResponses]

export type PostFalAiElevenlabsSoundEffectsV2Data = {
  body: SchemaElevenlabsSoundEffectsV2Input
  path?: never
  query?: never
  url: '/fal-ai/elevenlabs/sound-effects/v2'
}

export type PostFalAiElevenlabsSoundEffectsV2Responses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiElevenlabsSoundEffectsV2Response =
  PostFalAiElevenlabsSoundEffectsV2Responses[keyof PostFalAiElevenlabsSoundEffectsV2Responses]

export type GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/elevenlabs/sound-effects/v2/requests/{request_id}'
}

export type GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaElevenlabsSoundEffectsV2Output
}

export type GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdResponse =
  GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdResponses[keyof GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdResponses]

export type GetSonautoV2InpaintRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/sonauto/v2/inpaint/requests/{request_id}/status'
}

export type GetSonautoV2InpaintRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetSonautoV2InpaintRequestsByRequestIdStatusResponse =
  GetSonautoV2InpaintRequestsByRequestIdStatusResponses[keyof GetSonautoV2InpaintRequestsByRequestIdStatusResponses]

export type PutSonautoV2InpaintRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/sonauto/v2/inpaint/requests/{request_id}/cancel'
}

export type PutSonautoV2InpaintRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutSonautoV2InpaintRequestsByRequestIdCancelResponse =
  PutSonautoV2InpaintRequestsByRequestIdCancelResponses[keyof PutSonautoV2InpaintRequestsByRequestIdCancelResponses]

export type PostSonautoV2InpaintData = {
  body: SchemaV2InpaintInput
  path?: never
  query?: never
  url: '/sonauto/v2/inpaint'
}

export type PostSonautoV2InpaintResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostSonautoV2InpaintResponse =
  PostSonautoV2InpaintResponses[keyof PostSonautoV2InpaintResponses]

export type GetSonautoV2InpaintRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/sonauto/v2/inpaint/requests/{request_id}'
}

export type GetSonautoV2InpaintRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaV2InpaintOutput
}

export type GetSonautoV2InpaintRequestsByRequestIdResponse =
  GetSonautoV2InpaintRequestsByRequestIdResponses[keyof GetSonautoV2InpaintRequestsByRequestIdResponses]

export type GetSonautoV2TextToMusicRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/sonauto/v2/text-to-music/requests/{request_id}/status'
}

export type GetSonautoV2TextToMusicRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetSonautoV2TextToMusicRequestsByRequestIdStatusResponse =
  GetSonautoV2TextToMusicRequestsByRequestIdStatusResponses[keyof GetSonautoV2TextToMusicRequestsByRequestIdStatusResponses]

export type PutSonautoV2TextToMusicRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/sonauto/v2/text-to-music/requests/{request_id}/cancel'
}

export type PutSonautoV2TextToMusicRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutSonautoV2TextToMusicRequestsByRequestIdCancelResponse =
  PutSonautoV2TextToMusicRequestsByRequestIdCancelResponses[keyof PutSonautoV2TextToMusicRequestsByRequestIdCancelResponses]

export type PostSonautoV2TextToMusicData = {
  body: SchemaV2TextToMusicInput
  path?: never
  query?: never
  url: '/sonauto/v2/text-to-music'
}

export type PostSonautoV2TextToMusicResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostSonautoV2TextToMusicResponse =
  PostSonautoV2TextToMusicResponses[keyof PostSonautoV2TextToMusicResponses]

export type GetSonautoV2TextToMusicRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/sonauto/v2/text-to-music/requests/{request_id}'
}

export type GetSonautoV2TextToMusicRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaV2TextToMusicOutput
}

export type GetSonautoV2TextToMusicRequestsByRequestIdResponse =
  GetSonautoV2TextToMusicRequestsByRequestIdResponses[keyof GetSonautoV2TextToMusicRequestsByRequestIdResponses]

export type GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/elevenlabs/tts/eleven-v3/requests/{request_id}/status'
}

export type GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdStatusResponse =
  GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdStatusResponses[keyof GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdStatusResponses]

export type PutFalAiElevenlabsTtsElevenV3RequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/elevenlabs/tts/eleven-v3/requests/{request_id}/cancel'
}

export type PutFalAiElevenlabsTtsElevenV3RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiElevenlabsTtsElevenV3RequestsByRequestIdCancelResponse =
  PutFalAiElevenlabsTtsElevenV3RequestsByRequestIdCancelResponses[keyof PutFalAiElevenlabsTtsElevenV3RequestsByRequestIdCancelResponses]

export type PostFalAiElevenlabsTtsElevenV3Data = {
  body: SchemaElevenlabsTtsElevenV3Input
  path?: never
  query?: never
  url: '/fal-ai/elevenlabs/tts/eleven-v3'
}

export type PostFalAiElevenlabsTtsElevenV3Responses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiElevenlabsTtsElevenV3Response =
  PostFalAiElevenlabsTtsElevenV3Responses[keyof PostFalAiElevenlabsTtsElevenV3Responses]

export type GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/elevenlabs/tts/eleven-v3/requests/{request_id}'
}

export type GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaElevenlabsTtsElevenV3Output
}

export type GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdResponse =
  GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdResponses[keyof GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdResponses]

export type GetFalAiLyria2RequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/lyria2/requests/{request_id}/status'
}

export type GetFalAiLyria2RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiLyria2RequestsByRequestIdStatusResponse =
  GetFalAiLyria2RequestsByRequestIdStatusResponses[keyof GetFalAiLyria2RequestsByRequestIdStatusResponses]

export type PutFalAiLyria2RequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/lyria2/requests/{request_id}/cancel'
}

export type PutFalAiLyria2RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiLyria2RequestsByRequestIdCancelResponse =
  PutFalAiLyria2RequestsByRequestIdCancelResponses[keyof PutFalAiLyria2RequestsByRequestIdCancelResponses]

export type PostFalAiLyria2Data = {
  body: SchemaLyria2Input
  path?: never
  query?: never
  url: '/fal-ai/lyria2'
}

export type PostFalAiLyria2Responses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLyria2Response =
  PostFalAiLyria2Responses[keyof PostFalAiLyria2Responses]

export type GetFalAiLyria2RequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/lyria2/requests/{request_id}'
}

export type GetFalAiLyria2RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLyria2Output
}

export type GetFalAiLyria2RequestsByRequestIdResponse =
  GetFalAiLyria2RequestsByRequestIdResponses[keyof GetFalAiLyria2RequestsByRequestIdResponses]

export type GetFalAiAceStepPromptToAudioRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ace-step/prompt-to-audio/requests/{request_id}/status'
}

export type GetFalAiAceStepPromptToAudioRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiAceStepPromptToAudioRequestsByRequestIdStatusResponse =
  GetFalAiAceStepPromptToAudioRequestsByRequestIdStatusResponses[keyof GetFalAiAceStepPromptToAudioRequestsByRequestIdStatusResponses]

export type PutFalAiAceStepPromptToAudioRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ace-step/prompt-to-audio/requests/{request_id}/cancel'
}

export type PutFalAiAceStepPromptToAudioRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiAceStepPromptToAudioRequestsByRequestIdCancelResponse =
  PutFalAiAceStepPromptToAudioRequestsByRequestIdCancelResponses[keyof PutFalAiAceStepPromptToAudioRequestsByRequestIdCancelResponses]

export type PostFalAiAceStepPromptToAudioData = {
  body: SchemaAceStepPromptToAudioInput
  path?: never
  query?: never
  url: '/fal-ai/ace-step/prompt-to-audio'
}

export type PostFalAiAceStepPromptToAudioResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiAceStepPromptToAudioResponse =
  PostFalAiAceStepPromptToAudioResponses[keyof PostFalAiAceStepPromptToAudioResponses]

export type GetFalAiAceStepPromptToAudioRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ace-step/prompt-to-audio/requests/{request_id}'
}

export type GetFalAiAceStepPromptToAudioRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaAceStepPromptToAudioOutput
}

export type GetFalAiAceStepPromptToAudioRequestsByRequestIdResponse =
  GetFalAiAceStepPromptToAudioRequestsByRequestIdResponses[keyof GetFalAiAceStepPromptToAudioRequestsByRequestIdResponses]

export type GetFalAiAceStepRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ace-step/requests/{request_id}/status'
}

export type GetFalAiAceStepRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiAceStepRequestsByRequestIdStatusResponse =
  GetFalAiAceStepRequestsByRequestIdStatusResponses[keyof GetFalAiAceStepRequestsByRequestIdStatusResponses]

export type PutFalAiAceStepRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ace-step/requests/{request_id}/cancel'
}

export type PutFalAiAceStepRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiAceStepRequestsByRequestIdCancelResponse =
  PutFalAiAceStepRequestsByRequestIdCancelResponses[keyof PutFalAiAceStepRequestsByRequestIdCancelResponses]

export type PostFalAiAceStepData = {
  body: SchemaAceStepInput
  path?: never
  query?: never
  url: '/fal-ai/ace-step'
}

export type PostFalAiAceStepResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiAceStepResponse =
  PostFalAiAceStepResponses[keyof PostFalAiAceStepResponses]

export type GetFalAiAceStepRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ace-step/requests/{request_id}'
}

export type GetFalAiAceStepRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaAceStepOutput
}

export type GetFalAiAceStepRequestsByRequestIdResponse =
  GetFalAiAceStepRequestsByRequestIdResponses[keyof GetFalAiAceStepRequestsByRequestIdResponses]

export type GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/cassetteai/sound-effects-generator/requests/{request_id}/status'
}

export type GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdStatusResponse =
  GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdStatusResponses[keyof GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdStatusResponses]

export type PutCassetteaiSoundEffectsGeneratorRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/cassetteai/sound-effects-generator/requests/{request_id}/cancel'
}

export type PutCassetteaiSoundEffectsGeneratorRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutCassetteaiSoundEffectsGeneratorRequestsByRequestIdCancelResponse =
  PutCassetteaiSoundEffectsGeneratorRequestsByRequestIdCancelResponses[keyof PutCassetteaiSoundEffectsGeneratorRequestsByRequestIdCancelResponses]

export type PostCassetteaiSoundEffectsGeneratorData = {
  body: SchemaSoundEffectsGeneratorInput
  path?: never
  query?: never
  url: '/cassetteai/sound-effects-generator'
}

export type PostCassetteaiSoundEffectsGeneratorResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostCassetteaiSoundEffectsGeneratorResponse =
  PostCassetteaiSoundEffectsGeneratorResponses[keyof PostCassetteaiSoundEffectsGeneratorResponses]

export type GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/cassetteai/sound-effects-generator/requests/{request_id}'
}

export type GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaSoundEffectsGeneratorOutput
}

export type GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdResponse =
  GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdResponses[keyof GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdResponses]

export type GetCassetteaiMusicGeneratorRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/cassetteai/music-generator/requests/{request_id}/status'
}

export type GetCassetteaiMusicGeneratorRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetCassetteaiMusicGeneratorRequestsByRequestIdStatusResponse =
  GetCassetteaiMusicGeneratorRequestsByRequestIdStatusResponses[keyof GetCassetteaiMusicGeneratorRequestsByRequestIdStatusResponses]

export type PutCassetteaiMusicGeneratorRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/cassetteai/music-generator/requests/{request_id}/cancel'
}

export type PutCassetteaiMusicGeneratorRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutCassetteaiMusicGeneratorRequestsByRequestIdCancelResponse =
  PutCassetteaiMusicGeneratorRequestsByRequestIdCancelResponses[keyof PutCassetteaiMusicGeneratorRequestsByRequestIdCancelResponses]

export type PostCassetteaiMusicGeneratorData = {
  body: SchemaMusicGeneratorInput
  path?: never
  query?: never
  url: '/cassetteai/music-generator'
}

export type PostCassetteaiMusicGeneratorResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostCassetteaiMusicGeneratorResponse =
  PostCassetteaiMusicGeneratorResponses[keyof PostCassetteaiMusicGeneratorResponses]

export type GetCassetteaiMusicGeneratorRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/cassetteai/music-generator/requests/{request_id}'
}

export type GetCassetteaiMusicGeneratorRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaMusicGeneratorOutput
}

export type GetCassetteaiMusicGeneratorRequestsByRequestIdResponse =
  GetCassetteaiMusicGeneratorRequestsByRequestIdResponses[keyof GetCassetteaiMusicGeneratorRequestsByRequestIdResponses]

export type GetFalAiCsm1bRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/csm-1b/requests/{request_id}/status'
}

export type GetFalAiCsm1bRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiCsm1bRequestsByRequestIdStatusResponse =
  GetFalAiCsm1bRequestsByRequestIdStatusResponses[keyof GetFalAiCsm1bRequestsByRequestIdStatusResponses]

export type PutFalAiCsm1bRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/csm-1b/requests/{request_id}/cancel'
}

export type PutFalAiCsm1bRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiCsm1bRequestsByRequestIdCancelResponse =
  PutFalAiCsm1bRequestsByRequestIdCancelResponses[keyof PutFalAiCsm1bRequestsByRequestIdCancelResponses]

export type PostFalAiCsm1bData = {
  body: SchemaCsm1bInput
  path?: never
  query?: never
  url: '/fal-ai/csm-1b'
}

export type PostFalAiCsm1bResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiCsm1bResponse =
  PostFalAiCsm1bResponses[keyof PostFalAiCsm1bResponses]

export type GetFalAiCsm1bRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/csm-1b/requests/{request_id}'
}

export type GetFalAiCsm1bRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaCsm1bOutput
}

export type GetFalAiCsm1bRequestsByRequestIdResponse =
  GetFalAiCsm1bRequestsByRequestIdResponses[keyof GetFalAiCsm1bRequestsByRequestIdResponses]

export type GetFalAiDiffrhythmRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/diffrhythm/requests/{request_id}/status'
}

export type GetFalAiDiffrhythmRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiDiffrhythmRequestsByRequestIdStatusResponse =
  GetFalAiDiffrhythmRequestsByRequestIdStatusResponses[keyof GetFalAiDiffrhythmRequestsByRequestIdStatusResponses]

export type PutFalAiDiffrhythmRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/diffrhythm/requests/{request_id}/cancel'
}

export type PutFalAiDiffrhythmRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiDiffrhythmRequestsByRequestIdCancelResponse =
  PutFalAiDiffrhythmRequestsByRequestIdCancelResponses[keyof PutFalAiDiffrhythmRequestsByRequestIdCancelResponses]

export type PostFalAiDiffrhythmData = {
  body: SchemaDiffrhythmInput
  path?: never
  query?: never
  url: '/fal-ai/diffrhythm'
}

export type PostFalAiDiffrhythmResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiDiffrhythmResponse =
  PostFalAiDiffrhythmResponses[keyof PostFalAiDiffrhythmResponses]

export type GetFalAiDiffrhythmRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/diffrhythm/requests/{request_id}'
}

export type GetFalAiDiffrhythmRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaDiffrhythmOutput
}

export type GetFalAiDiffrhythmRequestsByRequestIdResponse =
  GetFalAiDiffrhythmRequestsByRequestIdResponses[keyof GetFalAiDiffrhythmRequestsByRequestIdResponses]

export type GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/elevenlabs/tts/multilingual-v2/requests/{request_id}/status'
}

export type GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdStatusResponse =
  GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdStatusResponses[keyof GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdStatusResponses]

export type PutFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/elevenlabs/tts/multilingual-v2/requests/{request_id}/cancel'
}

export type PutFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdCancelResponse =
  PutFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdCancelResponses[keyof PutFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdCancelResponses]

export type PostFalAiElevenlabsTtsMultilingualV2Data = {
  body: SchemaElevenlabsTtsMultilingualV2Input
  path?: never
  query?: never
  url: '/fal-ai/elevenlabs/tts/multilingual-v2'
}

export type PostFalAiElevenlabsTtsMultilingualV2Responses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiElevenlabsTtsMultilingualV2Response =
  PostFalAiElevenlabsTtsMultilingualV2Responses[keyof PostFalAiElevenlabsTtsMultilingualV2Responses]

export type GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/elevenlabs/tts/multilingual-v2/requests/{request_id}'
}

export type GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaElevenlabsTtsMultilingualV2Output
}

export type GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdResponse =
  GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdResponses[keyof GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdResponses]

export type GetFalAiKokoroHindiRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kokoro/hindi/requests/{request_id}/status'
}

export type GetFalAiKokoroHindiRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiKokoroHindiRequestsByRequestIdStatusResponse =
  GetFalAiKokoroHindiRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroHindiRequestsByRequestIdStatusResponses]

export type PutFalAiKokoroHindiRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/hindi/requests/{request_id}/cancel'
}

export type PutFalAiKokoroHindiRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiKokoroHindiRequestsByRequestIdCancelResponse =
  PutFalAiKokoroHindiRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroHindiRequestsByRequestIdCancelResponses]

export type PostFalAiKokoroHindiData = {
  body: SchemaKokoroHindiInput
  path?: never
  query?: never
  url: '/fal-ai/kokoro/hindi'
}

export type PostFalAiKokoroHindiResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKokoroHindiResponse =
  PostFalAiKokoroHindiResponses[keyof PostFalAiKokoroHindiResponses]

export type GetFalAiKokoroHindiRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/hindi/requests/{request_id}'
}

export type GetFalAiKokoroHindiRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKokoroHindiOutput
}

export type GetFalAiKokoroHindiRequestsByRequestIdResponse =
  GetFalAiKokoroHindiRequestsByRequestIdResponses[keyof GetFalAiKokoroHindiRequestsByRequestIdResponses]

export type GetFalAiKokoroMandarinChineseRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kokoro/mandarin-chinese/requests/{request_id}/status'
}

export type GetFalAiKokoroMandarinChineseRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiKokoroMandarinChineseRequestsByRequestIdStatusResponse =
  GetFalAiKokoroMandarinChineseRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroMandarinChineseRequestsByRequestIdStatusResponses]

export type PutFalAiKokoroMandarinChineseRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/mandarin-chinese/requests/{request_id}/cancel'
}

export type PutFalAiKokoroMandarinChineseRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiKokoroMandarinChineseRequestsByRequestIdCancelResponse =
  PutFalAiKokoroMandarinChineseRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroMandarinChineseRequestsByRequestIdCancelResponses]

export type PostFalAiKokoroMandarinChineseData = {
  body: SchemaKokoroMandarinChineseInput
  path?: never
  query?: never
  url: '/fal-ai/kokoro/mandarin-chinese'
}

export type PostFalAiKokoroMandarinChineseResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKokoroMandarinChineseResponse =
  PostFalAiKokoroMandarinChineseResponses[keyof PostFalAiKokoroMandarinChineseResponses]

export type GetFalAiKokoroMandarinChineseRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/mandarin-chinese/requests/{request_id}'
}

export type GetFalAiKokoroMandarinChineseRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKokoroMandarinChineseOutput
}

export type GetFalAiKokoroMandarinChineseRequestsByRequestIdResponse =
  GetFalAiKokoroMandarinChineseRequestsByRequestIdResponses[keyof GetFalAiKokoroMandarinChineseRequestsByRequestIdResponses]

export type GetFalAiKokoroSpanishRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kokoro/spanish/requests/{request_id}/status'
}

export type GetFalAiKokoroSpanishRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiKokoroSpanishRequestsByRequestIdStatusResponse =
  GetFalAiKokoroSpanishRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroSpanishRequestsByRequestIdStatusResponses]

export type PutFalAiKokoroSpanishRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/spanish/requests/{request_id}/cancel'
}

export type PutFalAiKokoroSpanishRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiKokoroSpanishRequestsByRequestIdCancelResponse =
  PutFalAiKokoroSpanishRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroSpanishRequestsByRequestIdCancelResponses]

export type PostFalAiKokoroSpanishData = {
  body: SchemaKokoroSpanishInput
  path?: never
  query?: never
  url: '/fal-ai/kokoro/spanish'
}

export type PostFalAiKokoroSpanishResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKokoroSpanishResponse =
  PostFalAiKokoroSpanishResponses[keyof PostFalAiKokoroSpanishResponses]

export type GetFalAiKokoroSpanishRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/spanish/requests/{request_id}'
}

export type GetFalAiKokoroSpanishRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKokoroSpanishOutput
}

export type GetFalAiKokoroSpanishRequestsByRequestIdResponse =
  GetFalAiKokoroSpanishRequestsByRequestIdResponses[keyof GetFalAiKokoroSpanishRequestsByRequestIdResponses]

export type GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kokoro/brazilian-portuguese/requests/{request_id}/status'
}

export type GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdStatusResponse =
  GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdStatusResponses]

export type PutFalAiKokoroBrazilianPortugueseRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/brazilian-portuguese/requests/{request_id}/cancel'
}

export type PutFalAiKokoroBrazilianPortugueseRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKokoroBrazilianPortugueseRequestsByRequestIdCancelResponse =
  PutFalAiKokoroBrazilianPortugueseRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroBrazilianPortugueseRequestsByRequestIdCancelResponses]

export type PostFalAiKokoroBrazilianPortugueseData = {
  body: SchemaKokoroBrazilianPortugueseInput
  path?: never
  query?: never
  url: '/fal-ai/kokoro/brazilian-portuguese'
}

export type PostFalAiKokoroBrazilianPortugueseResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKokoroBrazilianPortugueseResponse =
  PostFalAiKokoroBrazilianPortugueseResponses[keyof PostFalAiKokoroBrazilianPortugueseResponses]

export type GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/brazilian-portuguese/requests/{request_id}'
}

export type GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKokoroBrazilianPortugueseOutput
}

export type GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdResponse =
  GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdResponses[keyof GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdResponses]

export type GetFalAiKokoroBritishEnglishRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kokoro/british-english/requests/{request_id}/status'
}

export type GetFalAiKokoroBritishEnglishRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiKokoroBritishEnglishRequestsByRequestIdStatusResponse =
  GetFalAiKokoroBritishEnglishRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroBritishEnglishRequestsByRequestIdStatusResponses]

export type PutFalAiKokoroBritishEnglishRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/british-english/requests/{request_id}/cancel'
}

export type PutFalAiKokoroBritishEnglishRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiKokoroBritishEnglishRequestsByRequestIdCancelResponse =
  PutFalAiKokoroBritishEnglishRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroBritishEnglishRequestsByRequestIdCancelResponses]

export type PostFalAiKokoroBritishEnglishData = {
  body: SchemaKokoroBritishEnglishInput
  path?: never
  query?: never
  url: '/fal-ai/kokoro/british-english'
}

export type PostFalAiKokoroBritishEnglishResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKokoroBritishEnglishResponse =
  PostFalAiKokoroBritishEnglishResponses[keyof PostFalAiKokoroBritishEnglishResponses]

export type GetFalAiKokoroBritishEnglishRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/british-english/requests/{request_id}'
}

export type GetFalAiKokoroBritishEnglishRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKokoroBritishEnglishOutput
}

export type GetFalAiKokoroBritishEnglishRequestsByRequestIdResponse =
  GetFalAiKokoroBritishEnglishRequestsByRequestIdResponses[keyof GetFalAiKokoroBritishEnglishRequestsByRequestIdResponses]

export type GetFalAiKokoroFrenchRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kokoro/french/requests/{request_id}/status'
}

export type GetFalAiKokoroFrenchRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiKokoroFrenchRequestsByRequestIdStatusResponse =
  GetFalAiKokoroFrenchRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroFrenchRequestsByRequestIdStatusResponses]

export type PutFalAiKokoroFrenchRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/french/requests/{request_id}/cancel'
}

export type PutFalAiKokoroFrenchRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiKokoroFrenchRequestsByRequestIdCancelResponse =
  PutFalAiKokoroFrenchRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroFrenchRequestsByRequestIdCancelResponses]

export type PostFalAiKokoroFrenchData = {
  body: SchemaKokoroFrenchInput
  path?: never
  query?: never
  url: '/fal-ai/kokoro/french'
}

export type PostFalAiKokoroFrenchResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKokoroFrenchResponse =
  PostFalAiKokoroFrenchResponses[keyof PostFalAiKokoroFrenchResponses]

export type GetFalAiKokoroFrenchRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/french/requests/{request_id}'
}

export type GetFalAiKokoroFrenchRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKokoroFrenchOutput
}

export type GetFalAiKokoroFrenchRequestsByRequestIdResponse =
  GetFalAiKokoroFrenchRequestsByRequestIdResponses[keyof GetFalAiKokoroFrenchRequestsByRequestIdResponses]

export type GetFalAiKokoroJapaneseRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kokoro/japanese/requests/{request_id}/status'
}

export type GetFalAiKokoroJapaneseRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiKokoroJapaneseRequestsByRequestIdStatusResponse =
  GetFalAiKokoroJapaneseRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroJapaneseRequestsByRequestIdStatusResponses]

export type PutFalAiKokoroJapaneseRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/japanese/requests/{request_id}/cancel'
}

export type PutFalAiKokoroJapaneseRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiKokoroJapaneseRequestsByRequestIdCancelResponse =
  PutFalAiKokoroJapaneseRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroJapaneseRequestsByRequestIdCancelResponses]

export type PostFalAiKokoroJapaneseData = {
  body: SchemaKokoroJapaneseInput
  path?: never
  query?: never
  url: '/fal-ai/kokoro/japanese'
}

export type PostFalAiKokoroJapaneseResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKokoroJapaneseResponse =
  PostFalAiKokoroJapaneseResponses[keyof PostFalAiKokoroJapaneseResponses]

export type GetFalAiKokoroJapaneseRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/japanese/requests/{request_id}'
}

export type GetFalAiKokoroJapaneseRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKokoroJapaneseOutput
}

export type GetFalAiKokoroJapaneseRequestsByRequestIdResponse =
  GetFalAiKokoroJapaneseRequestsByRequestIdResponses[keyof GetFalAiKokoroJapaneseRequestsByRequestIdResponses]

export type GetFalAiKokoroAmericanEnglishRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kokoro/american-english/requests/{request_id}/status'
}

export type GetFalAiKokoroAmericanEnglishRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiKokoroAmericanEnglishRequestsByRequestIdStatusResponse =
  GetFalAiKokoroAmericanEnglishRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroAmericanEnglishRequestsByRequestIdStatusResponses]

export type PutFalAiKokoroAmericanEnglishRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/american-english/requests/{request_id}/cancel'
}

export type PutFalAiKokoroAmericanEnglishRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiKokoroAmericanEnglishRequestsByRequestIdCancelResponse =
  PutFalAiKokoroAmericanEnglishRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroAmericanEnglishRequestsByRequestIdCancelResponses]

export type PostFalAiKokoroAmericanEnglishData = {
  body: SchemaKokoroAmericanEnglishInput
  path?: never
  query?: never
  url: '/fal-ai/kokoro/american-english'
}

export type PostFalAiKokoroAmericanEnglishResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKokoroAmericanEnglishResponse =
  PostFalAiKokoroAmericanEnglishResponses[keyof PostFalAiKokoroAmericanEnglishResponses]

export type GetFalAiKokoroAmericanEnglishRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/american-english/requests/{request_id}'
}

export type GetFalAiKokoroAmericanEnglishRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKokoroAmericanEnglishOutput
}

export type GetFalAiKokoroAmericanEnglishRequestsByRequestIdResponse =
  GetFalAiKokoroAmericanEnglishRequestsByRequestIdResponses[keyof GetFalAiKokoroAmericanEnglishRequestsByRequestIdResponses]

export type GetFalAiZonosRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/zonos/requests/{request_id}/status'
}

export type GetFalAiZonosRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiZonosRequestsByRequestIdStatusResponse =
  GetFalAiZonosRequestsByRequestIdStatusResponses[keyof GetFalAiZonosRequestsByRequestIdStatusResponses]

export type PutFalAiZonosRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/zonos/requests/{request_id}/cancel'
}

export type PutFalAiZonosRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiZonosRequestsByRequestIdCancelResponse =
  PutFalAiZonosRequestsByRequestIdCancelResponses[keyof PutFalAiZonosRequestsByRequestIdCancelResponses]

export type PostFalAiZonosData = {
  body: SchemaZonosInput
  path?: never
  query?: never
  url: '/fal-ai/zonos'
}

export type PostFalAiZonosResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiZonosResponse =
  PostFalAiZonosResponses[keyof PostFalAiZonosResponses]

export type GetFalAiZonosRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/zonos/requests/{request_id}'
}

export type GetFalAiZonosRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaZonosOutput
}

export type GetFalAiZonosRequestsByRequestIdResponse =
  GetFalAiZonosRequestsByRequestIdResponses[keyof GetFalAiZonosRequestsByRequestIdResponses]

export type GetFalAiKokoroItalianRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kokoro/italian/requests/{request_id}/status'
}

export type GetFalAiKokoroItalianRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiKokoroItalianRequestsByRequestIdStatusResponse =
  GetFalAiKokoroItalianRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroItalianRequestsByRequestIdStatusResponses]

export type PutFalAiKokoroItalianRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/italian/requests/{request_id}/cancel'
}

export type PutFalAiKokoroItalianRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiKokoroItalianRequestsByRequestIdCancelResponse =
  PutFalAiKokoroItalianRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroItalianRequestsByRequestIdCancelResponses]

export type PostFalAiKokoroItalianData = {
  body: SchemaKokoroItalianInput
  path?: never
  query?: never
  url: '/fal-ai/kokoro/italian'
}

export type PostFalAiKokoroItalianResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKokoroItalianResponse =
  PostFalAiKokoroItalianResponses[keyof PostFalAiKokoroItalianResponses]

export type GetFalAiKokoroItalianRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kokoro/italian/requests/{request_id}'
}

export type GetFalAiKokoroItalianRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKokoroItalianOutput
}

export type GetFalAiKokoroItalianRequestsByRequestIdResponse =
  GetFalAiKokoroItalianRequestsByRequestIdResponses[keyof GetFalAiKokoroItalianRequestsByRequestIdResponses]

export type GetFalAiYueRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/yue/requests/{request_id}/status'
}

export type GetFalAiYueRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiYueRequestsByRequestIdStatusResponse =
  GetFalAiYueRequestsByRequestIdStatusResponses[keyof GetFalAiYueRequestsByRequestIdStatusResponses]

export type PutFalAiYueRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/yue/requests/{request_id}/cancel'
}

export type PutFalAiYueRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiYueRequestsByRequestIdCancelResponse =
  PutFalAiYueRequestsByRequestIdCancelResponses[keyof PutFalAiYueRequestsByRequestIdCancelResponses]

export type PostFalAiYueData = {
  body: SchemaYueInput
  path?: never
  query?: never
  url: '/fal-ai/yue'
}

export type PostFalAiYueResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiYueResponse =
  PostFalAiYueResponses[keyof PostFalAiYueResponses]

export type GetFalAiYueRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/yue/requests/{request_id}'
}

export type GetFalAiYueRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaYueOutput
}

export type GetFalAiYueRequestsByRequestIdResponse =
  GetFalAiYueRequestsByRequestIdResponses[keyof GetFalAiYueRequestsByRequestIdResponses]

export type GetFalAiMmaudioV2TextToAudioRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/mmaudio-v2/text-to-audio/requests/{request_id}/status'
}

export type GetFalAiMmaudioV2TextToAudioRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiMmaudioV2TextToAudioRequestsByRequestIdStatusResponse =
  GetFalAiMmaudioV2TextToAudioRequestsByRequestIdStatusResponses[keyof GetFalAiMmaudioV2TextToAudioRequestsByRequestIdStatusResponses]

export type PutFalAiMmaudioV2TextToAudioRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/mmaudio-v2/text-to-audio/requests/{request_id}/cancel'
}

export type PutFalAiMmaudioV2TextToAudioRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiMmaudioV2TextToAudioRequestsByRequestIdCancelResponse =
  PutFalAiMmaudioV2TextToAudioRequestsByRequestIdCancelResponses[keyof PutFalAiMmaudioV2TextToAudioRequestsByRequestIdCancelResponses]

export type PostFalAiMmaudioV2TextToAudioData = {
  body: SchemaMmaudioV2TextToAudioInput
  path?: never
  query?: never
  url: '/fal-ai/mmaudio-v2/text-to-audio'
}

export type PostFalAiMmaudioV2TextToAudioResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMmaudioV2TextToAudioResponse =
  PostFalAiMmaudioV2TextToAudioResponses[keyof PostFalAiMmaudioV2TextToAudioResponses]

export type GetFalAiMmaudioV2TextToAudioRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/mmaudio-v2/text-to-audio/requests/{request_id}'
}

export type GetFalAiMmaudioV2TextToAudioRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaMmaudioV2TextToAudioOutput
}

export type GetFalAiMmaudioV2TextToAudioRequestsByRequestIdResponse =
  GetFalAiMmaudioV2TextToAudioRequestsByRequestIdResponses[keyof GetFalAiMmaudioV2TextToAudioRequestsByRequestIdResponses]

export type GetFalAiMinimaxMusicRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/minimax-music/requests/{request_id}/status'
}

export type GetFalAiMinimaxMusicRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiMinimaxMusicRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxMusicRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxMusicRequestsByRequestIdStatusResponses]

export type PutFalAiMinimaxMusicRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax-music/requests/{request_id}/cancel'
}

export type PutFalAiMinimaxMusicRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiMinimaxMusicRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxMusicRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxMusicRequestsByRequestIdCancelResponses]

export type PostFalAiMinimaxMusicData = {
  body: SchemaMinimaxMusicInput
  path?: never
  query?: never
  url: '/fal-ai/minimax-music'
}

export type PostFalAiMinimaxMusicResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMinimaxMusicResponse =
  PostFalAiMinimaxMusicResponses[keyof PostFalAiMinimaxMusicResponses]

export type GetFalAiMinimaxMusicRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax-music/requests/{request_id}'
}

export type GetFalAiMinimaxMusicRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaMinimaxMusicOutput
}

export type GetFalAiMinimaxMusicRequestsByRequestIdResponse =
  GetFalAiMinimaxMusicRequestsByRequestIdResponses[keyof GetFalAiMinimaxMusicRequestsByRequestIdResponses]

export type GetFalAiF5TtsRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/f5-tts/requests/{request_id}/status'
}

export type GetFalAiF5TtsRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiF5TtsRequestsByRequestIdStatusResponse =
  GetFalAiF5TtsRequestsByRequestIdStatusResponses[keyof GetFalAiF5TtsRequestsByRequestIdStatusResponses]

export type PutFalAiF5TtsRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/f5-tts/requests/{request_id}/cancel'
}

export type PutFalAiF5TtsRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiF5TtsRequestsByRequestIdCancelResponse =
  PutFalAiF5TtsRequestsByRequestIdCancelResponses[keyof PutFalAiF5TtsRequestsByRequestIdCancelResponses]

export type PostFalAiF5TtsData = {
  body: SchemaF5TtsInput
  path?: never
  query?: never
  url: '/fal-ai/f5-tts'
}

export type PostFalAiF5TtsResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiF5TtsResponse =
  PostFalAiF5TtsResponses[keyof PostFalAiF5TtsResponses]

export type GetFalAiF5TtsRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/f5-tts/requests/{request_id}'
}

export type GetFalAiF5TtsRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaF5TtsOutput
}

export type GetFalAiF5TtsRequestsByRequestIdResponse =
  GetFalAiF5TtsRequestsByRequestIdResponses[keyof GetFalAiF5TtsRequestsByRequestIdResponses]

export type GetFalAiStableAudioRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/stable-audio/requests/{request_id}/status'
}

export type GetFalAiStableAudioRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiStableAudioRequestsByRequestIdStatusResponse =
  GetFalAiStableAudioRequestsByRequestIdStatusResponses[keyof GetFalAiStableAudioRequestsByRequestIdStatusResponses]

export type PutFalAiStableAudioRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/stable-audio/requests/{request_id}/cancel'
}

export type PutFalAiStableAudioRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiStableAudioRequestsByRequestIdCancelResponse =
  PutFalAiStableAudioRequestsByRequestIdCancelResponses[keyof PutFalAiStableAudioRequestsByRequestIdCancelResponses]

export type PostFalAiStableAudioData = {
  body: SchemaStableAudioInput
  path?: never
  query?: never
  url: '/fal-ai/stable-audio'
}

export type PostFalAiStableAudioResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiStableAudioResponse =
  PostFalAiStableAudioResponses[keyof PostFalAiStableAudioResponses]

export type GetFalAiStableAudioRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/stable-audio/requests/{request_id}'
}

export type GetFalAiStableAudioRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaStableAudioOutput
}

export type GetFalAiStableAudioRequestsByRequestIdResponse =
  GetFalAiStableAudioRequestsByRequestIdResponses[keyof GetFalAiStableAudioRequestsByRequestIdResponses]

export type GetFalAiSamAudioVisualSeparateRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/sam-audio/visual-separate/requests/{request_id}/status'
}

export type GetFalAiSamAudioVisualSeparateRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiSamAudioVisualSeparateRequestsByRequestIdStatusResponse =
  GetFalAiSamAudioVisualSeparateRequestsByRequestIdStatusResponses[keyof GetFalAiSamAudioVisualSeparateRequestsByRequestIdStatusResponses]

export type PutFalAiSamAudioVisualSeparateRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/sam-audio/visual-separate/requests/{request_id}/cancel'
}

export type PutFalAiSamAudioVisualSeparateRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiSamAudioVisualSeparateRequestsByRequestIdCancelResponse =
  PutFalAiSamAudioVisualSeparateRequestsByRequestIdCancelResponses[keyof PutFalAiSamAudioVisualSeparateRequestsByRequestIdCancelResponses]

export type PostFalAiSamAudioVisualSeparateData = {
  body: SchemaSamAudioVisualSeparateInput
  path?: never
  query?: never
  url: '/fal-ai/sam-audio/visual-separate'
}

export type PostFalAiSamAudioVisualSeparateResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiSamAudioVisualSeparateResponse =
  PostFalAiSamAudioVisualSeparateResponses[keyof PostFalAiSamAudioVisualSeparateResponses]

export type GetFalAiSamAudioVisualSeparateRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/sam-audio/visual-separate/requests/{request_id}'
}

export type GetFalAiSamAudioVisualSeparateRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaSamAudioVisualSeparateOutput
}

export type GetFalAiSamAudioVisualSeparateRequestsByRequestIdResponse =
  GetFalAiSamAudioVisualSeparateRequestsByRequestIdResponses[keyof GetFalAiSamAudioVisualSeparateRequestsByRequestIdResponses]

export type GetMireloAiSfxV15VideoToAudioRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/mirelo-ai/sfx-v1.5/video-to-audio/requests/{request_id}/status'
}

export type GetMireloAiSfxV15VideoToAudioRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetMireloAiSfxV15VideoToAudioRequestsByRequestIdStatusResponse =
  GetMireloAiSfxV15VideoToAudioRequestsByRequestIdStatusResponses[keyof GetMireloAiSfxV15VideoToAudioRequestsByRequestIdStatusResponses]

export type PutMireloAiSfxV15VideoToAudioRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/mirelo-ai/sfx-v1.5/video-to-audio/requests/{request_id}/cancel'
}

export type PutMireloAiSfxV15VideoToAudioRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutMireloAiSfxV15VideoToAudioRequestsByRequestIdCancelResponse =
  PutMireloAiSfxV15VideoToAudioRequestsByRequestIdCancelResponses[keyof PutMireloAiSfxV15VideoToAudioRequestsByRequestIdCancelResponses]

export type PostMireloAiSfxV15VideoToAudioData = {
  body: SchemaSfxV15VideoToAudioInput
  path?: never
  query?: never
  url: '/mirelo-ai/sfx-v1.5/video-to-audio'
}

export type PostMireloAiSfxV15VideoToAudioResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostMireloAiSfxV15VideoToAudioResponse =
  PostMireloAiSfxV15VideoToAudioResponses[keyof PostMireloAiSfxV15VideoToAudioResponses]

export type GetMireloAiSfxV15VideoToAudioRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/mirelo-ai/sfx-v1.5/video-to-audio/requests/{request_id}'
}

export type GetMireloAiSfxV15VideoToAudioRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaSfxV15VideoToAudioOutput
}

export type GetMireloAiSfxV15VideoToAudioRequestsByRequestIdResponse =
  GetMireloAiSfxV15VideoToAudioRequestsByRequestIdResponses[keyof GetMireloAiSfxV15VideoToAudioRequestsByRequestIdResponses]

export type GetFalAiKlingVideoVideoToAudioRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kling-video/video-to-audio/requests/{request_id}/status'
}

export type GetFalAiKlingVideoVideoToAudioRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiKlingVideoVideoToAudioRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoVideoToAudioRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoVideoToAudioRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoVideoToAudioRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/video-to-audio/requests/{request_id}/cancel'
}

export type PutFalAiKlingVideoVideoToAudioRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiKlingVideoVideoToAudioRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoVideoToAudioRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoVideoToAudioRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoVideoToAudioData = {
  body: SchemaKlingVideoVideoToAudioInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/video-to-audio'
}

export type PostFalAiKlingVideoVideoToAudioResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoVideoToAudioResponse =
  PostFalAiKlingVideoVideoToAudioResponses[keyof PostFalAiKlingVideoVideoToAudioResponses]

export type GetFalAiKlingVideoVideoToAudioRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/video-to-audio/requests/{request_id}'
}

export type GetFalAiKlingVideoVideoToAudioRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKlingVideoVideoToAudioOutput
}

export type GetFalAiKlingVideoVideoToAudioRequestsByRequestIdResponse =
  GetFalAiKlingVideoVideoToAudioRequestsByRequestIdResponses[keyof GetFalAiKlingVideoVideoToAudioRequestsByRequestIdResponses]

export type GetMireloAiSfxV1VideoToAudioRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/mirelo-ai/sfx-v1/video-to-audio/requests/{request_id}/status'
}

export type GetMireloAiSfxV1VideoToAudioRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetMireloAiSfxV1VideoToAudioRequestsByRequestIdStatusResponse =
  GetMireloAiSfxV1VideoToAudioRequestsByRequestIdStatusResponses[keyof GetMireloAiSfxV1VideoToAudioRequestsByRequestIdStatusResponses]

export type PutMireloAiSfxV1VideoToAudioRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/mirelo-ai/sfx-v1/video-to-audio/requests/{request_id}/cancel'
}

export type PutMireloAiSfxV1VideoToAudioRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutMireloAiSfxV1VideoToAudioRequestsByRequestIdCancelResponse =
  PutMireloAiSfxV1VideoToAudioRequestsByRequestIdCancelResponses[keyof PutMireloAiSfxV1VideoToAudioRequestsByRequestIdCancelResponses]

export type PostMireloAiSfxV1VideoToAudioData = {
  body: SchemaSfxV1VideoToAudioInput
  path?: never
  query?: never
  url: '/mirelo-ai/sfx-v1/video-to-audio'
}

export type PostMireloAiSfxV1VideoToAudioResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostMireloAiSfxV1VideoToAudioResponse =
  PostMireloAiSfxV1VideoToAudioResponses[keyof PostMireloAiSfxV1VideoToAudioResponses]

export type GetMireloAiSfxV1VideoToAudioRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/mirelo-ai/sfx-v1/video-to-audio/requests/{request_id}'
}

export type GetMireloAiSfxV1VideoToAudioRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaSfxV1VideoToAudioOutput
}

export type GetMireloAiSfxV1VideoToAudioRequestsByRequestIdResponse =
  GetMireloAiSfxV1VideoToAudioRequestsByRequestIdResponses[keyof GetMireloAiSfxV1VideoToAudioRequestsByRequestIdResponses]
