// This file is auto-generated by @hey-api/openapi-ts

import { z } from 'zod'

/**
 * File
 */
export const zSchemaFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * AnimateDiffV2VOutput
 */
export const zSchemaFastAnimatediffVideoToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generating the video.',
  }),
  video: zSchemaFile,
})

/**
 * AnimateDiffV2VInput
 */
export const zSchemaFastAnimatediffVideoToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  video_url: z.union([z.string(), z.string()]),
  first_n_seconds: z
    .optional(
      z.int().gte(2).lte(4).register(z.globalRegistry, {
        description: 'The first N number of seconds of video to animate.',
      }),
    )
    .default(3),
  fps: z
    .optional(
      z.int().gte(1).lte(16).register(z.globalRegistry, {
        description: 'Number of frames per second to extract from the video.',
      }),
    )
    .default(8),
  strength: z
    .optional(
      z.number().gte(0.1).lte(1).register(z.globalRegistry, {
        description: 'The strength of the input video in the final output.',
      }),
    )
    .default(0.7),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(7.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(25),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default('(bad quality, worst quality:1.2), ugly faces, bad anime'),
  motions: z.optional(
    z
      .array(
        z.enum([
          'zoom-out',
          'zoom-in',
          'pan-left',
          'pan-right',
          'tilt-up',
          'tilt-down',
        ]),
      )
      .register(z.globalRegistry, {
        description: 'The motions to apply to the video.',
      }),
  ),
})

/**
 * AnimateDiffV2VOutput
 */
export const zSchemaFastAnimatediffTurboVideoToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generating the video.',
  }),
  video: zSchemaFile,
})

/**
 * AnimateDiffV2VTurboInput
 */
export const zSchemaFastAnimatediffTurboVideoToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  video_url: z.union([z.string(), z.string()]),
  first_n_seconds: z
    .optional(
      z.int().gte(2).lte(12).register(z.globalRegistry, {
        description: 'The first N number of seconds of video to animate.',
      }),
    )
    .default(3),
  fps: z
    .optional(
      z.int().gte(1).lte(16).register(z.globalRegistry, {
        description: 'Number of frames per second to extract from the video.',
      }),
    )
    .default(8),
  strength: z
    .optional(
      z.number().gte(0.1).lte(1).register(z.globalRegistry, {
        description: 'The strength of the input video in the final output.',
      }),
    )
    .default(0.7),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(1),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(32).register(z.globalRegistry, {
        description:
          'The number of inference steps to perform. 4-12 is recommended for turbo mode.',
      }),
    )
    .default(8),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default('(bad quality, worst quality:1.2), ugly faces, bad anime'),
  motions: z.optional(
    z
      .array(
        z.enum([
          'zoom-out',
          'zoom-in',
          'pan-left',
          'pan-right',
          'tilt-up',
          'tilt-down',
        ]),
      )
      .register(z.globalRegistry, {
        description: 'The motions to apply to the video.',
      }),
  ),
})

/**
 * AMTInterpolationOutput
 */
export const zSchemaAmtInterpolationOutput = z.object({
  video: zSchemaFile,
})

/**
 * AMTInterpolationInput
 */
export const zSchemaAmtInterpolationInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  recursive_interpolation_passes: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Number of recursive interpolation passes',
      }),
    )
    .default(2),
  output_fps: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Output frames per second',
      }),
    )
    .default(24),
})

/**
 * SAM2VideoOutput
 */
export const zSchemaSam2VideoOutput = z.object({
  boundingbox_frames_zip: z.optional(zSchemaFile),
  video: zSchemaFile,
})

/**
 * BoxPrompt
 */
export const zSchemaBoxPrompt = z.object({
  y_min: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Y Min Coordinate of the box',
      }),
    )
    .default(0),
  frame_index: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'The frame index to interact with.',
      }),
    )
    .default(0),
  x_max: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'X Max Coordinate of the prompt',
      }),
    )
    .default(0),
  x_min: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'X Min Coordinate of the box',
      }),
    )
    .default(0),
  y_max: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Y Max Coordinate of the prompt',
      }),
    )
    .default(0),
})

/**
 * PointPrompt
 */
export const zSchemaPointPrompt = z.object({
  y: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Y Coordinate of the prompt',
      }),
    )
    .default(350),
  label: z.optional(
    z.union([z.literal(0), z.literal(1)]).register(z.globalRegistry, {
      description: 'Label of the prompt. 1 for foreground, 0 for background',
    }),
  ),
  frame_index: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'The frame index to interact with.',
      }),
    )
    .default(0),
  x: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'X Coordinate of the prompt',
      }),
    )
    .default(305),
})

/**
 * SAM2VideoRLEInput
 */
export const zSchemaSam2VideoInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  prompts: z
    .optional(
      z.array(zSchemaPointPrompt).register(z.globalRegistry, {
        description: 'List of prompts to segment the video',
      }),
    )
    .default([]),
  boundingbox_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Return per-frame bounding box overlays as a zip archive.',
      }),
    )
    .default(false),
  mask_url: z.optional(z.union([z.string(), z.string()])),
  apply_mask: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Apply the mask on the video.',
      }),
    )
    .default(false),
  box_prompts: z
    .optional(
      z.array(zSchemaBoxPrompt).register(z.globalRegistry, {
        description: 'Coordinates for boxes',
      }),
    )
    .default([]),
})

/**
 * ControlNeXtOutput
 */
export const zSchemaControlnextOutput = z.object({
  video: zSchemaFile,
})

/**
 * ControlNeXtInput
 */
export const zSchemaControlnextInput = z.object({
  controlnext_cond_scale: z
    .optional(
      z.number().gte(0.1).lte(10).register(z.globalRegistry, {
        description: 'Condition scale for ControlNeXt.',
      }),
    )
    .default(1),
  video_url: z.union([z.string(), z.string()]),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: 'Frames per second for the output video.',
      }),
    )
    .default(7),
  max_frame_num: z
    .optional(
      z.int().gte(1).lte(1000).register(z.globalRegistry, {
        description: 'Maximum number of frames to process.',
      }),
    )
    .default(240),
  width: z
    .optional(
      z.int().gte(64).lte(1024).register(z.globalRegistry, {
        description: 'Width of the output video.',
      }),
    )
    .default(576),
  overlap: z
    .optional(
      z.int().gte(0).lte(20).register(z.globalRegistry, {
        description: 'Number of overlapping frames between batches.',
      }),
    )
    .default(6),
  guidance_scale: z
    .optional(
      z.number().gte(0.1).lte(10).register(z.globalRegistry, {
        description: 'Guidance scale for the diffusion process.',
      }),
    )
    .default(3),
  batch_frames: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'Number of frames to process in each batch.',
      }),
    )
    .default(24),
  height: z
    .optional(
      z.int().gte(64).lte(1024).register(z.globalRegistry, {
        description: 'Height of the output video.',
      }),
    )
    .default(1024),
  sample_stride: z
    .optional(
      z.int().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Stride for sampling frames from the input video.',
      }),
    )
    .default(2),
  image_url: z.union([z.string(), z.string()]),
  decode_chunk_size: z
    .optional(
      z.int().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Chunk size for decoding frames.',
      }),
    )
    .default(2),
  motion_bucket_id: z
    .optional(
      z.number().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Motion bucket ID for the pipeline.',
      }),
    )
    .default(127),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(100).register(z.globalRegistry, {
        description: 'Number of inference steps.',
      }),
    )
    .default(25),
})

/**
 * Output
 */
export const zSchemaCogvideox5bVideoToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the video.',
  }),
  timings: z.record(z.string(), z.number()),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated video. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  video: zSchemaFile,
})

/**
 * ImageSize
 */
export const zSchemaImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zSchemaLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * VideoToVideoInput
 */
export const zSchemaCogvideox5bVideoToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  video_url: z.union([z.string(), z.string()]),
  use_rife: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Use RIFE for video interpolation',
      }),
    )
    .default(true),
  loras: z
    .optional(
      z.array(zSchemaLoraWeight).register(z.globalRegistry, {
        description:
          '\n            The LoRAs to use for the image generation. We currently support one lora.\n        ',
      }),
    )
    .default([]),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  strength: z
    .optional(
      z.number().gte(0.05).lte(1).register(z.globalRegistry, {
        description:
          'The strength to use for Video to Video.  1.0 completely remakes the video while 0.0 preserves the original.',
      }),
    )
    .default(0.8),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related video to show you.\n        ',
      }),
    )
    .default(7),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(50),
  export_fps: z
    .optional(
      z.int().gte(4).lte(32).register(z.globalRegistry, {
        description: 'The target FPS of the video',
      }),
    )
    .default(16),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate video from',
      }),
    )
    .default(''),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
})

/**
 * Output
 */
export const zSchemaVideoUpscalerOutput = z.object({
  video: zSchemaFile,
})

/**
 * Input
 */
export const zSchemaVideoUpscalerInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  scale: z
    .optional(
      z.number().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The scale factor',
      }),
    )
    .default(2),
})

/**
 * OutputModel
 */
export const zSchemaDubbingOutput = z.object({
  video: zSchemaFile,
})

/**
 * InputModel
 */
export const zSchemaDubbingInput = z.object({
  do_lipsync: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to lip sync the audio to the video',
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  target_language: z.optional(
    z.enum(['hindi', 'turkish', 'english']).register(z.globalRegistry, {
      description: 'Target language to dub the video to',
    }),
  ),
})

/**
 * Output
 */
export const zSchemaAutoCaptionOutput = z.object({
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL to the caption .mp4 video.',
  }),
})

/**
 * CaptionInput
 */
export const zSchemaAutoCaptionInput = z.object({
  txt_font: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "Font for generated captions. Choose one in 'Arial','Standard','Garamond', 'Times New Roman','Georgia', or pass a url to a .ttf file",
      }),
    )
    .default('Standard'),
  video_url: z.union([z.string(), z.string()]),
  top_align: z.optional(z.union([z.string(), z.number()])),
  txt_color: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Colour of the text. Can be a RGB tuple, a color name, or an hexadecimal notation.',
      }),
    )
    .default('white'),
  stroke_width: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Width of the text strokes in pixels',
      }),
    )
    .default(1),
  refresh_interval: z
    .optional(
      z.number().gte(0.5).lte(3).register(z.globalRegistry, {
        description:
          'Number of seconds the captions should stay on screen. A higher number will also result in more text being displayed at once.',
      }),
    )
    .default(1.5),
  font_size: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Size of text in generated captions.',
      }),
    )
    .default(24),
  left_align: z.optional(z.union([z.string(), z.number()])),
})

/**
 * LipSyncOutput
 */
export const zSchemaSyncLipsyncOutput = z.object({
  video: zSchemaFile,
})

/**
 * LipSyncInput
 */
export const zSchemaSyncLipsyncInput = z.object({
  model: z.optional(
    z
      .enum(['lipsync-1.8.0', 'lipsync-1.7.1', 'lipsync-1.9.0-beta'])
      .register(z.globalRegistry, {
        description: 'The model to use for lipsyncing',
      }),
  ),
  video_url: z.union([z.string(), z.string()]),
  sync_mode: z.optional(
    z
      .enum(['cut_off', 'loop', 'bounce', 'silence', 'remap'])
      .register(z.globalRegistry, {
        description:
          'Lipsync mode when audio and video durations are out of sync.',
      }),
  ),
  audio_url: z.union([z.string(), z.string()]),
})

/**
 * Keyframe
 */
export const zSchemaKeyframe = z.object({
  duration: z.number().register(z.globalRegistry, {
    description: 'The duration in milliseconds of this keyframe',
  }),
  timestamp: z.number().register(z.globalRegistry, {
    description: 'The timestamp in milliseconds where this keyframe starts',
  }),
  url: z.string().register(z.globalRegistry, {
    description: "The URL where this keyframe's media file can be accessed",
  }),
})

/**
 * Track
 */
export const zSchemaTrack = z.object({
  type: z.string().register(z.globalRegistry, {
    description: "Type of track ('video' or 'audio')",
  }),
  id: z.string().register(z.globalRegistry, {
    description: 'Unique identifier for the track',
  }),
  keyframes: z.array(zSchemaKeyframe).register(z.globalRegistry, {
    description: 'List of keyframes that make up this track',
  }),
})

/**
 * ComposeOutput
 */
export const zSchemaFfmpegApiComposeOutput = z.object({
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the processed video file',
  }),
  thumbnail_url: z.string().register(z.globalRegistry, {
    description: "URL of the video's thumbnail image",
  }),
})

/**
 * Input
 */
export const zSchemaFfmpegApiComposeInput = z.object({
  tracks: z.array(zSchemaTrack).register(z.globalRegistry, {
    description: 'List of tracks to be combined into the final media',
  }),
})

/**
 * HunyuanV2VResponse
 */
export const zSchemaHunyuanVideoLoraVideoToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generating the video.',
  }),
  video: zSchemaFile,
})

/**
 * HunyuanV2VRequest
 */
export const zSchemaHunyuanVideoLoraVideoToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the video to generate.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'The resolution of the video to generate.',
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  loras: z
    .optional(
      z.array(zSchemaLoraWeight).register(z.globalRegistry, {
        description:
          '\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ',
      }),
    )
    .default([]),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description: 'Strength of video-to-video',
      }),
    )
    .default(0.75),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for generating the video.',
    }),
  ),
  num_frames: z.optional(
    z.enum(['129', '85']).register(z.globalRegistry, {
      description: 'The number of frames to generate.',
    }),
  ),
  pro_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'By default, generations are done with 35 steps. Pro mode does 55 steps which results in higher quality videos but will take more time and cost 2x more billing units.',
      }),
    )
    .default(false),
})

/**
 * HunyuanT2VResponse
 */
export const zSchemaHunyuanVideoVideoToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generating the video.',
  }),
  video: zSchemaFile,
})

/**
 * HunyuanV2VRequest
 */
export const zSchemaHunyuanVideoVideoToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the video to generate.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'The resolution of the video to generate.',
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description: 'Strength for Video-to-Video',
      }),
    )
    .default(0.85),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(30).register(z.globalRegistry, {
        description:
          'The number of inference steps to run. Lower gets faster results, higher gets better results.',
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for generating the video.',
    }),
  ),
  num_frames: z.optional(
    z.enum(['129', '85']).register(z.globalRegistry, {
      description: 'The number of frames to generate.',
    }),
  ),
  pro_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'By default, generations are done with 35 steps. Pro mode does 55 steps which results in higher quality videos but will take more time and cost 2x more billing units.',
      }),
    )
    .default(false),
})

/**
 * Ben2OutputVideo
 */
export const zSchemaBenV2VideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  video: zSchemaFile,
})

/**
 * Ben2InputVideo
 */
export const zSchemaBenV2VideoInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for reproducible generation.',
    }),
  ),
  background_color: z.optional(
    z
      .tuple([z.unknown(), z.unknown(), z.unknown()])
      .register(z.globalRegistry, {
        description:
          'Optional RGB values (0-255) for the background color. If not provided, the background will be transparent. For ex: [0, 0, 0]',
      }),
  ),
})

/**
 * VideoUpscaleOutput
 */
export const zSchemaTopazUpscaleVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * VideoUpscaleRequest
 */
export const zSchemaTopazUpscaleVideoInput = z.object({
  H264_output: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use H264 codec for output video. Default is H265.',
      }),
    )
    .default(false),
  video_url: z.union([z.string(), z.string()]),
  upscale_factor: z
    .optional(
      z.number().gte(1).lte(4).register(z.globalRegistry, {
        description:
          'Factor to upscale the video by (e.g. 2.0 doubles width and height)',
      }),
    )
    .default(2),
  target_fps: z.optional(
    z.int().gte(16).lte(60).register(z.globalRegistry, {
      description:
        'Target FPS for frame interpolation. If set, frame interpolation will be enabled.',
    }),
  ),
})

/**
 * ExtendVideoOutput
 */
export const zSchemaLtxVideoV095ExtendOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * VideoConditioningInput
 */
export const zSchemaVideoConditioningInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  start_frame_num: z.int().gte(0).lte(120).register(z.globalRegistry, {
    description:
      'Frame number of the video from which the conditioning starts. Must be a multiple of 8.',
  }),
})

/**
 * ExtendVideoInput
 */
export const zSchemaLtxVideoV095ExtendInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt to guide generation',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['9:16', '16:9']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video (16:9 or 9:16).',
    }),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to expand the prompt using the model's own capabilities.",
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps',
      }),
    )
    .default(40),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for generation',
      }),
    )
    .default('worst quality, inconsistent motion, blurry, jittery, distorted'),
  video: zSchemaVideoConditioningInput,
})

/**
 * MulticonditioningVideoOutput
 */
export const zSchemaLtxVideoV095MulticonditioningOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * ImageConditioningInput
 */
export const zSchemaImageConditioningInput = z.object({
  start_frame_num: z.int().gte(0).lte(120).register(z.globalRegistry, {
    description:
      'Frame number of the image from which the conditioning starts. Must be a multiple of 8.',
  }),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * MultiConditioningVideoInput
 */
export const zSchemaLtxVideoV095MulticonditioningInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt to guide generation',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['9:16', '16:9']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video (16:9 or 9:16).',
    }),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to expand the prompt using the model's own capabilities.",
      }),
    )
    .default(true),
  images: z
    .optional(
      z.array(zSchemaImageConditioningInput).register(z.globalRegistry, {
        description: 'URL of images to use as conditioning',
      }),
    )
    .default([]),
  videos: z
    .optional(
      z.array(zSchemaVideoConditioningInput).register(z.globalRegistry, {
        description: 'Videos to use as conditioning',
      }),
    )
    .default([]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps',
      }),
    )
    .default(40),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for generation',
      }),
    )
    .default('worst quality, inconsistent motion, blurry, jittery, distorted'),
})

/**
 * PikadditionsOutput
 *
 * Output from Pikadditions generation
 */
export const zSchemaPikaV2PikadditionsOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output from Pikadditions generation',
  })

/**
 * PikadditionsRequest
 *
 * Request model for Pikadditions endpoint
 */
export const zSchemaPikaV2PikadditionsInput = z
  .object({
    prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'Text prompt describing what to add',
      }),
    ),
    video_url: z.union([z.string(), z.string()]),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the random number generator',
      }),
    ),
    negative_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to guide the model',
      }),
    ),
    image_url: z.union([z.string(), z.string()]),
  })
  .register(z.globalRegistry, {
    description: 'Request model for Pikadditions endpoint',
  })

/**
 * Output
 */
export const zSchemaLatentsyncOutput = z.object({
  video: zSchemaFile,
})

/**
 * Input
 */
export const zSchemaLatentsyncInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(2).register(z.globalRegistry, {
        description: 'Guidance scale for the model inference',
      }),
    )
    .default(1),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for generation. If None, a random seed will be used.',
    }),
  ),
  audio_url: z.union([z.string(), z.string()]),
  loop_mode: z.optional(
    z.enum(['pingpong', 'loop']).register(z.globalRegistry, {
      description:
        'Video loop mode when audio is longer than video. Options: pingpong, loop',
    }),
  ),
})

/**
 * LipSyncV2Output
 */
export const zSchemaSyncLipsyncV2Output = z.object({
  video: zSchemaFile,
})

/**
 * LipSyncV2Input
 */
export const zSchemaSyncLipsyncV2Input = z.object({
  model: z.optional(
    z.enum(['lipsync-2', 'lipsync-2-pro']).register(z.globalRegistry, {
      description:
        'The model to use for lipsyncing. `lipsync-2-pro` will cost roughly 1.67 times as much as `lipsync-2` for the same duration.',
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  sync_mode: z.optional(
    z
      .enum(['cut_off', 'loop', 'bounce', 'silence', 'remap'])
      .register(z.globalRegistry, {
        description:
          'Lipsync mode when audio and video durations are out of sync.',
      }),
  ),
  audio_url: z.union([z.string(), z.string()]),
})

/**
 * VideoOutput
 *
 * Pydantic model for returning the re-sounded video back to the client.
 */
export const zSchemaVideoSoundEffectsGeneratorOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description:
      'Pydantic model for returning the re-sounded video back to the client.',
  })

/**
 * Video
 *
 * Represents a video file.
 */
export const zSchemaVideo = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    file_data: z.optional(z.union([z.string(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents a video file.',
  })

/**
 * VideoInput
 *
 * Pydantic model for receiving a video file to analyze and re-sound.
 */
export const zSchemaVideoSoundEffectsGeneratorInput = z
  .object({
    video_url: zSchemaVideo,
  })
  .register(z.globalRegistry, {
    description:
      'Pydantic model for receiving a video file to analyze and re-sound.',
  })

/**
 * WanT2VResponse
 */
export const zSchemaWanVaceOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanT2VRequest
 */
export const zSchemaWanVaceInput = z.object({
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  video_url: z.optional(z.union([z.string(), z.string()])),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'Urls to source reference image. If provided, the model will use this image as reference.',
    }),
  ),
  task: z.optional(
    z.enum(['depth', 'inpainting']).register(z.globalRegistry, {
      description: 'Task type for the model.',
    }),
  ),
  frames_per_second: z
    .optional(
      z.int().gte(5).lte(24).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 5 to 24.',
      }),
    )
    .default(16),
  mask_image_url: z.optional(z.union([z.string(), z.string()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(81).lte(240).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 100 (inclusive). Works only with only reference images as input if source video or mask video is provided output len would be same as source up to 241 frames',
      }),
    )
    .default(81),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  aspect_ratio: z.optional(
    z.enum(['auto', '9:16', '16:9']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video (16:9 or 9:16).',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p,580p, or 720p).',
    }),
  ),
  mask_video_url: z.optional(z.union([z.string(), z.string()])),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the input video.',
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
})

/**
 * MagiVideoExtensionResponse
 */
export const zSchemaMagiDistilledExtendVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * MagiVideoExtensionRequest
 */
export const zSchemaMagiDistilledExtendVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  start_frame: z.optional(
    z.int().gte(0).register(z.globalRegistry, {
      description:
        'The frame to begin the generation from, with the remaining frames will be treated as the prefix video. The final video will contain the frames up until this number unchanged, followed by the generated frames. The default start frame is 32 frames before the end of the video, which gives optimal results.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z.optional(
    z
      .union([z.literal(4), z.literal(8), z.literal(16), z.literal(32)])
      .register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(96).lte(192).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.',
      }),
    )
    .default(96),
})

/**
 * MagiVideoExtensionResponse
 */
export const zSchemaMagiExtendVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * MagiVideoExtensionRequest
 */
export const zSchemaMagiExtendVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  start_frame: z.optional(
    z.int().gte(0).register(z.globalRegistry, {
      description:
        'The frame to begin the generation from, with the remaining frames will be treated as the prefix video. The final video will contain the frames up until this number unchanged, followed by the generated frames. The default start frame is 32 frames before the end of the video, which gives optimal results.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z.optional(
    z
      .union([
        z.literal(4),
        z.literal(8),
        z.literal(16),
        z.literal(32),
        z.literal(64),
      ])
      .register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(96).lte(192).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.',
      }),
    )
    .default(96),
})

/**
 * VideoCondition
 *
 * Video condition to use for generation.
 */
export const zSchemaVideoCondition = z
  .object({
    strength: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description: 'The strength of the condition.',
        }),
      )
      .default(1),
    start_frame_number: z
      .optional(
        z.int().gte(0).lte(160).register(z.globalRegistry, {
          description: 'The frame number to start the condition on.',
        }),
      )
      .default(0),
    video_url: z.string().register(z.globalRegistry, {
      description: 'The URL of the video to use as input.',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Video condition to use for generation.',
  })

/**
 * ImageCondition
 *
 * Image condition to use for generation.
 */
export const zSchemaImageCondition = z
  .object({
    strength: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description: 'The strength of the condition.',
        }),
      )
      .default(1),
    start_frame_number: z
      .optional(
        z.int().gte(0).lte(160).register(z.globalRegistry, {
          description: 'The frame number to start the condition on.',
        }),
      )
      .default(0),
    image_url: z.string().register(z.globalRegistry, {
      description: 'The URL of the image to use as input.',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Image condition to use for generation.',
  })

/**
 * MulticonditioningVideoOutput
 */
export const zSchemaLtxVideoLoraMulticonditioningOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * LoRAWeight
 *
 * LoRA weight to use for generation.
 */
export const zSchemaLoRaWeight = z
  .object({
    path: z.string().register(z.globalRegistry, {
      description: 'URL or path to the LoRA weights.',
    }),
    scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'Scale of the LoRA weight. This is a multiplier applied to the LoRA weight when loading it.',
        }),
      )
      .default(1),
    weight_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'Name of the LoRA weight. Only used if `path` is a HuggingFace repository, and is only required when the repository contains multiple LoRA weights.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'LoRA weight to use for generation.',
  })

/**
 * MulticonditioningVideoInput
 *
 * Request model for text-to-video generation with multiple conditions.
 */
export const zSchemaLtxVideoLoraMulticonditioningInput = z
  .object({
    number_of_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to use.',
        }),
      )
      .default(30),
    prompt: z.string().register(z.globalRegistry, {
      description: 'The prompt to generate the video from.',
    }),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to reverse the video.',
        }),
      )
      .default(false),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: 'The frame rate of the video.',
        }),
      )
      .default(25),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to expand the prompt using the LLM.',
        }),
      )
      .default(false),
    number_of_frames: z
      .optional(
        z.int().gte(9).lte(161).register(z.globalRegistry, {
          description: 'The number of frames in the video.',
        }),
      )
      .default(89),
    loras: z
      .optional(
        z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
          description: 'The LoRA weights to use for generation.',
        }),
      )
      .default([]),
    images: z
      .optional(
        z.array(zSchemaImageCondition).register(z.globalRegistry, {
          description: 'The image conditions to use for generation.',
        }),
      )
      .default([]),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable the safety checker.',
        }),
      )
      .default(true),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt to use.',
        }),
      )
      .default(
        'blurry, low quality, low resolution, inconsistent motion, jittery, distorted',
      ),
    aspect_ratio: z.optional(
      z.enum(['16:9', '1:1', '9:16', 'auto']).register(z.globalRegistry, {
        description: 'The aspect ratio of the video.',
      }),
    ),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description: 'The resolution of the video.',
      }),
    ),
    videos: z
      .optional(
        z.array(zSchemaVideoCondition).register(z.globalRegistry, {
          description: 'The video conditions to use for generation.',
        }),
      )
      .default([]),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed to use for generation.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description:
      'Request model for text-to-video generation with multiple conditions.',
  })

/**
 * ExtendVideoOutput
 */
export const zSchemaLtxVideo13bDevExtendOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * ExtendVideoInput
 */
export const zSchemaLtxVideo13bDevExtendInput = z.object({
  second_pass_skip_initial_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description:
          'The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.',
      }),
    )
    .default(17),
  first_pass_num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps during the first pass.',
      }),
    )
    .default(30),
  frame_rate: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frame rate of the video.',
      }),
    )
    .default(30),
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt to guide generation',
  }),
  reverse_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to reverse the video.',
      }),
    )
    .default(false),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to expand the prompt using a language model.',
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
        description: 'LoRA weights to use for generation',
      }),
    )
    .default([]),
  second_pass_num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps during the second pass.',
      }),
    )
    .default(30),
  num_frames: z
    .optional(
      z.int().gte(9).lte(161).register(z.globalRegistry, {
        description: 'The number of frames in the video.',
      }),
    )
    .default(121),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  video: zSchemaVideoConditioningInput,
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for generation',
      }),
    )
    .default('worst quality, inconsistent motion, blurry, jittery, distorted'),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['9:16', '1:1', '16:9', 'auto']).register(z.globalRegistry, {
      description: 'The aspect ratio of the video.',
    }),
  ),
  constant_rate_factor: z
    .optional(
      z.int().gte(20).lte(60).register(z.globalRegistry, {
        description:
          "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
      }),
    )
    .default(35),
  first_pass_skip_final_steps: z
    .optional(
      z.int().gte(0).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.',
      }),
    )
    .default(3),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
})

/**
 * MultiConditioningVideoOutput
 */
export const zSchemaLtxVideo13bDevMulticonditioningOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * MultiConditioningVideoInput
 */
export const zSchemaLtxVideo13bDevMulticonditioningInput = z.object({
  second_pass_skip_initial_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description:
          'The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.',
      }),
    )
    .default(17),
  first_pass_num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps during the first pass.',
      }),
    )
    .default(30),
  frame_rate: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frame rate of the video.',
      }),
    )
    .default(30),
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt to guide generation',
  }),
  reverse_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to reverse the video.',
      }),
    )
    .default(false),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to expand the prompt using a language model.',
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
        description: 'LoRA weights to use for generation',
      }),
    )
    .default([]),
  images: z
    .optional(
      z.array(zSchemaImageConditioningInput).register(z.globalRegistry, {
        description: 'URL of images to use as conditioning',
      }),
    )
    .default([]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(9).lte(161).register(z.globalRegistry, {
        description: 'The number of frames in the video.',
      }),
    )
    .default(121),
  second_pass_num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps during the second pass.',
      }),
    )
    .default(30),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for generation',
      }),
    )
    .default('worst quality, inconsistent motion, blurry, jittery, distorted'),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['9:16', '1:1', '16:9', 'auto']).register(z.globalRegistry, {
      description: 'The aspect ratio of the video.',
    }),
  ),
  videos: z
    .optional(
      z.array(zSchemaVideoConditioningInput).register(z.globalRegistry, {
        description: 'Videos to use as conditioning',
      }),
    )
    .default([]),
  constant_rate_factor: z
    .optional(
      z.int().gte(20).lte(60).register(z.globalRegistry, {
        description:
          "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
      }),
    )
    .default(35),
  first_pass_skip_final_steps: z
    .optional(
      z.int().gte(0).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.',
      }),
    )
    .default(3),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
})

/**
 * MultiConditioningVideoOutput
 */
export const zSchemaLtxVideo13bDistilledMulticonditioningOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * DistilledMultiConditioningVideoInput
 *
 * Distilled model input
 */
export const zSchemaLtxVideo13bDistilledMulticonditioningInput = z
  .object({
    second_pass_skip_initial_steps: z
      .optional(
        z.int().gte(1).lte(20).register(z.globalRegistry, {
          description:
            'The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.',
        }),
      )
      .default(5),
    first_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(20).register(z.globalRegistry, {
          description: 'Number of inference steps during the first pass.',
        }),
      )
      .default(8),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: 'The frame rate of the video.',
        }),
      )
      .default(30),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to reverse the video.',
        }),
      )
      .default(false),
    prompt: z.string().register(z.globalRegistry, {
      description: 'Text prompt to guide generation',
    }),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to expand the prompt using a language model.',
        }),
      )
      .default(false),
    loras: z
      .optional(
        z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
          description: 'LoRA weights to use for generation',
        }),
      )
      .default([]),
    images: z
      .optional(
        z.array(zSchemaImageConditioningInput).register(z.globalRegistry, {
          description: 'URL of images to use as conditioning',
        }),
      )
      .default([]),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable the safety checker.',
        }),
      )
      .default(true),
    num_frames: z
      .optional(
        z.int().gte(9).lte(161).register(z.globalRegistry, {
          description: 'The number of frames in the video.',
        }),
      )
      .default(121),
    second_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(20).register(z.globalRegistry, {
          description: 'Number of inference steps during the second pass.',
        }),
      )
      .default(8),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'Negative prompt for generation',
        }),
      )
      .default(
        'worst quality, inconsistent motion, blurry, jittery, distorted',
      ),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description: 'Resolution of the generated video (480p or 720p).',
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(['9:16', '1:1', '16:9', 'auto']).register(z.globalRegistry, {
        description: 'The aspect ratio of the video.',
      }),
    ),
    constant_rate_factor: z
      .optional(
        z.int().gte(20).lte(60).register(z.globalRegistry, {
          description:
            "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        }),
      )
      .default(35),
    videos: z
      .optional(
        z.array(zSchemaVideoConditioningInput).register(z.globalRegistry, {
          description: 'Videos to use as conditioning',
        }),
      )
      .default([]),
    first_pass_skip_final_steps: z
      .optional(
        z.int().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.',
        }),
      )
      .default(1),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'Random seed for generation',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Distilled model input',
  })

/**
 * ExtendVideoOutput
 */
export const zSchemaLtxVideo13bDistilledExtendOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * DistilledExtendVideoInput
 *
 * Distilled model input
 */
export const zSchemaLtxVideo13bDistilledExtendInput = z
  .object({
    second_pass_skip_initial_steps: z
      .optional(
        z.int().gte(1).lte(20).register(z.globalRegistry, {
          description:
            'The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.',
        }),
      )
      .default(5),
    first_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(20).register(z.globalRegistry, {
          description: 'Number of inference steps during the first pass.',
        }),
      )
      .default(8),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: 'The frame rate of the video.',
        }),
      )
      .default(30),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to reverse the video.',
        }),
      )
      .default(false),
    prompt: z.string().register(z.globalRegistry, {
      description: 'Text prompt to guide generation',
    }),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to expand the prompt using a language model.',
        }),
      )
      .default(false),
    loras: z
      .optional(
        z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
          description: 'LoRA weights to use for generation',
        }),
      )
      .default([]),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable the safety checker.',
        }),
      )
      .default(true),
    num_frames: z
      .optional(
        z.int().gte(9).lte(161).register(z.globalRegistry, {
          description: 'The number of frames in the video.',
        }),
      )
      .default(121),
    second_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(20).register(z.globalRegistry, {
          description: 'Number of inference steps during the second pass.',
        }),
      )
      .default(8),
    video: zSchemaVideoConditioningInput,
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'Negative prompt for generation',
        }),
      )
      .default(
        'worst quality, inconsistent motion, blurry, jittery, distorted',
      ),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description: 'Resolution of the generated video (480p or 720p).',
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(['9:16', '1:1', '16:9', 'auto']).register(z.globalRegistry, {
        description: 'The aspect ratio of the video.',
      }),
    ),
    constant_rate_factor: z
      .optional(
        z.int().gte(20).lte(60).register(z.globalRegistry, {
          description:
            "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        }),
      )
      .default(35),
    first_pass_skip_final_steps: z
      .optional(
        z.int().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.',
        }),
      )
      .default(1),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'Random seed for generation',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Distilled model input',
  })

/**
 * VideoFile
 */
export const zSchemaVideoFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  duration: z.optional(z.union([z.number(), z.unknown()])),
  height: z.optional(z.union([z.int(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(z.union([z.int(), z.unknown()])),
  fps: z.optional(z.union([z.number(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  num_frames: z.optional(z.union([z.int(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * WanVACEResponse
 */
export const zSchemaWanVace14bOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  frames_zip: z.optional(z.union([zSchemaFile, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * WanVACERequest
 */
export const zSchemaWanVace14bInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  video_url: z.optional(z.union([z.string(), z.unknown()])),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between the original frames. A value of 0 means no interpolation.',
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.',
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'URLs to source reference image. If provided, the model will use this image as reference.',
    }),
  ),
  transparency_mode: z.optional(
    z.enum(['content_aware', 'white', 'black']).register(z.globalRegistry, {
      description:
        'The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 241 (inclusive).',
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.',
      }),
    )
    .default(15),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.',
      }),
    )
    .default(5),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'Sampler to use for video generation.',
    }),
  ),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  mask_video_url: z.optional(z.union([z.string(), z.unknown()])),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(['rife', 'film']).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.',
      }),
    )
    .default(false),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the input video.',
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  acceleration: z.optional(
    z.union([z.enum(['none', 'low', 'regular']), z.unknown()]),
  ),
  mask_image_url: z.optional(z.union([z.string(), z.unknown()])),
  task: z.optional(
    z
      .enum(['depth', 'pose', 'inpainting', 'outpainting', 'reframe'])
      .register(z.globalRegistry, {
        description: 'Task type for the model.',
      }),
  ),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.',
      }),
    )
    .default(false),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP file containing all generated frames.',
      }),
    )
    .default(false),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * LipsyncAppOutput
 */
export const zSchemaLipsyncOutput = z.object({
  video: zSchemaFile,
})

/**
 * LipsyncInput
 */
export const zSchemaLipsyncInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  audio_url: z.union([z.string(), z.string()]),
})

/**
 * ReframeOutput
 */
export const zSchemaLumaDreamMachineRay2ReframeOutput = z.object({
  video: zSchemaFile,
})

/**
 * ReframeVideoRequest
 */
export const zSchemaLumaDreamMachineRay2ReframeInput = z.object({
  prompt: z.optional(
    z.string().min(1).max(5000).register(z.globalRegistry, {
      description: 'Optional prompt for reframing',
    }),
  ),
  aspect_ratio: z
    .enum(['1:1', '16:9', '9:16', '4:3', '3:4', '21:9', '9:21'])
    .register(z.globalRegistry, {
      description: 'The aspect ratio of the reframed video',
    }),
  y_start: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Start Y coordinate for reframing',
    }),
  ),
  x_end: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'End X coordinate for reframing',
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  y_end: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'End Y coordinate for reframing',
    }),
  ),
  x_start: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Start X coordinate for reframing',
    }),
  ),
  grid_position_y: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Y position of the grid for reframing',
    }),
  ),
  grid_position_x: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'X position of the grid for reframing',
    }),
  ),
  image_url: z.optional(z.union([z.string(), z.string()])),
})

/**
 * ReframeOutput
 */
export const zSchemaLumaDreamMachineRay2FlashReframeOutput = z.object({
  video: zSchemaFile,
})

/**
 * ReframeVideoRequest
 */
export const zSchemaLumaDreamMachineRay2FlashReframeInput = z.object({
  prompt: z.optional(
    z.string().min(1).max(5000).register(z.globalRegistry, {
      description: 'Optional prompt for reframing',
    }),
  ),
  aspect_ratio: z
    .enum(['1:1', '16:9', '9:16', '4:3', '3:4', '21:9', '9:21'])
    .register(z.globalRegistry, {
      description: 'The aspect ratio of the reframed video',
    }),
  y_start: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Start Y coordinate for reframing',
    }),
  ),
  x_end: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'End X coordinate for reframing',
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  y_end: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'End Y coordinate for reframing',
    }),
  ),
  x_start: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Start X coordinate for reframing',
    }),
  ),
  grid_position_y: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Y position of the grid for reframing',
    }),
  ),
  grid_position_x: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'X position of the grid for reframing',
    }),
  ),
  image_url: z.optional(z.union([z.string(), z.string()])),
})

/**
 * WanT2VResponse
 */
export const zSchemaWanVace13bOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanT2VRequest
 */
export const zSchemaWanVace13bInput = z.object({
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  video_url: z.optional(z.union([z.string(), z.string()])),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  mask_image_url: z.optional(z.union([z.string(), z.string()])),
  task: z.optional(
    z.enum(['depth', 'inpainting', 'pose']).register(z.globalRegistry, {
      description: 'Task type for the model.',
    }),
  ),
  frames_per_second: z
    .optional(
      z.int().gte(5).lte(24).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 5 to 24.',
      }),
    )
    .default(16),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'Urls to source reference image. If provided, the model will use this image as reference.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(81).lte(240).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 100 (inclusive). Works only with only reference images as input if source video or mask video is provided output len would be same as source up to 241 frames',
      }),
    )
    .default(81),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p,580p, or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '9:16', '16:9']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video (16:9 or 9:16).',
    }),
  ),
  mask_video_url: z.optional(z.union([z.string(), z.string()])),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the input video.',
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
})

/**
 * CombineOutput
 */
export const zSchemaFfmpegApiMergeAudioVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * CombineInput
 */
export const zSchemaFfmpegApiMergeAudioVideoInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  start_offset: z
    .optional(
      z.number().gte(0).register(z.globalRegistry, {
        description:
          'Offset in seconds for when the audio should start relative to the video',
      }),
    )
    .default(0),
  audio_url: z.union([z.string(), z.string()]),
})

/**
 * DWPoseVideoOutput
 */
export const zSchemaDwposeVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * DWPoseVideoInput
 */
export const zSchemaDwposeVideoInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  draw_mode: z.optional(
    z
      .enum([
        'full-pose',
        'body-pose',
        'face-pose',
        'hand-pose',
        'face-hand-mask',
        'face-mask',
        'hand-mask',
      ])
      .register(z.globalRegistry, {
        description:
          "Mode of drawing the pose on the video. Options are: 'full-pose', 'body-pose', 'face-pose', 'hand-pose', 'face-hand-mask', 'face-mask', 'hand-mask'.",
      }),
  ),
})

/**
 * WanVACEDepthResponse
 */
export const zSchemaWanVace14bDepthOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  frames_zip: z.optional(z.union([zSchemaFile, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * WanVACEDepthRequest
 */
export const zSchemaWanVace14bDepthInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  video_url: z.union([z.string(), z.string()]),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between the original frames. A value of 0 means no interpolation.',
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.',
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'URLs to source reference image. If provided, the model will use this image as reference.',
    }),
  ),
  transparency_mode: z.optional(
    z.enum(['content_aware', 'white', 'black']).register(z.globalRegistry, {
      description:
        'The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 241 (inclusive).',
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.',
      }),
    )
    .default(15),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.',
      }),
    )
    .default(5),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'Sampler to use for video generation.',
    }),
  ),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(['rife', 'film']).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.',
      }),
    )
    .default(false),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the input video.',
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.union([z.enum(['none', 'low', 'regular']), z.unknown()]),
  ),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.',
      }),
    )
    .default(false),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP file containing all generated frames.',
      }),
    )
    .default(false),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * WanVACEPoseResponse
 */
export const zSchemaWanVace14bPoseOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  frames_zip: z.optional(z.union([zSchemaFile, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * WanVACEPoseRequest
 */
export const zSchemaWanVace14bPoseInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The text prompt to guide video generation. For pose task, the prompt should describe the desired pose and action of the subject in the video.',
  }),
  video_url: z.union([z.string(), z.string()]),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between the original frames. A value of 0 means no interpolation.',
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.',
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'URLs to source reference image. If provided, the model will use this image as reference.',
    }),
  ),
  transparency_mode: z.optional(
    z.enum(['content_aware', 'white', 'black']).register(z.globalRegistry, {
      description:
        'The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 241 (inclusive).',
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.',
      }),
    )
    .default(15),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.',
      }),
    )
    .default(5),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'Sampler to use for video generation.',
    }),
  ),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(['rife', 'film']).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.',
      }),
    )
    .default(false),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the input video.',
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.union([z.enum(['none', 'low', 'regular']), z.unknown()]),
  ),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.',
      }),
    )
    .default(false),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP file containing all generated frames.',
      }),
    )
    .default(false),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * WanVACEInpaintingResponse
 */
export const zSchemaWanVace14bInpaintingOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  frames_zip: z.optional(z.union([zSchemaFile, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * WanVACEInpaintingRequest
 */
export const zSchemaWanVace14bInpaintingInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  video_url: z.union([z.string(), z.string()]),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between the original frames. A value of 0 means no interpolation.',
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.',
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'Urls to source reference image. If provided, the model will use this image as reference.',
    }),
  ),
  transparency_mode: z.optional(
    z.enum(['content_aware', 'white', 'black']).register(z.globalRegistry, {
      description:
        'The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 241 (inclusive).',
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.',
      }),
    )
    .default(15),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.',
      }),
    )
    .default(5),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'Sampler to use for video generation.',
    }),
  ),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  mask_video_url: z.union([z.string(), z.unknown()]),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(['rife', 'film']).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.',
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the input video.',
      }),
    )
    .default(false),
  acceleration: z.optional(
    z.union([z.enum(['none', 'low', 'regular']), z.unknown()]),
  ),
  mask_image_url: z.optional(z.union([z.string(), z.unknown()])),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.',
      }),
    )
    .default(false),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP file containing all generated frames.',
      }),
    )
    .default(false),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * WanVACEOutpaintingResponse
 */
export const zSchemaWanVace14bOutpaintingOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  frames_zip: z.optional(z.union([zSchemaFile, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * WanVACEOutpaintingRequest
 */
export const zSchemaWanVace14bOutpaintingInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  video_url: z.union([z.string(), z.string()]),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between the original frames. A value of 0 means no interpolation.',
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.',
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'URLs to source reference image. If provided, the model will use this image as reference.',
    }),
  ),
  expand_ratio: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Amount of expansion. This is a float value between 0 and 1, where 0.25 adds 25% to the original video size on the specified sides.',
      }),
    )
    .default(0.25),
  transparency_mode: z.optional(
    z.enum(['content_aware', 'white', 'black']).register(z.globalRegistry, {
      description:
        'The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 241 (inclusive).',
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.',
      }),
    )
    .default(15),
  expand_bottom: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to expand the video to the bottom.',
      }),
    )
    .default(false),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'Sampler to use for video generation.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.',
      }),
    )
    .default(5),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(['rife', 'film']).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.',
      }),
    )
    .default(false),
  expand_top: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to expand the video to the top.',
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  expand_left: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to expand the video to the left.',
      }),
    )
    .default(false),
  acceleration: z.optional(
    z.union([z.enum(['none', 'low', 'regular']), z.unknown()]),
  ),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.',
      }),
    )
    .default(false),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP file containing all generated frames.',
      }),
    )
    .default(false),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
  ),
  expand_right: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to expand the video to the right.',
      }),
    )
    .default(false),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * WanVACEReframeResponse
 */
export const zSchemaWanVace14bReframeOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  frames_zip: z.optional(z.union([zSchemaFile, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * WanVACEReframeRequest
 */
export const zSchemaWanVace14bReframeInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'The text prompt to guide video generation. Optional for reframing.',
      }),
    )
    .default(''),
  video_url: z.union([z.string(), z.string()]),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between the original frames. A value of 0 means no interpolation.',
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.',
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  transparency_mode: z.optional(
    z.enum(['content_aware', 'white', 'black']).register(z.globalRegistry, {
      description:
        'The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 241 (inclusive).',
      }),
    )
    .default(81),
  trim_borders: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to trim borders from the video.',
      }),
    )
    .default(true),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.',
      }),
    )
    .default(15),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'Sampler to use for video generation.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.',
      }),
    )
    .default(5),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(['rife', 'film']).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.',
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.union([z.enum(['none', 'low', 'regular']), z.unknown()]),
  ),
  zoom_factor: z
    .optional(
      z.number().gte(0).lte(0.9).register(z.globalRegistry, {
        description:
          'Zoom factor for the video. When this value is greater than 0, the video will be zoomed in by this factor (in relation to the canvas size,) cutting off the edges of the video. A value of 0 means no zoom.',
      }),
    )
    .default(0),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.',
      }),
    )
    .default(true),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP file containing all generated frames.',
      }),
    )
    .default(false),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * ModifyOutput
 */
export const zSchemaLumaDreamMachineRay2ModifyOutput = z.object({
  video: zSchemaFile,
})

/**
 * ModifyVideoRequest
 */
export const zSchemaLumaDreamMachineRay2ModifyInput = z.object({
  prompt: z.optional(
    z.string().min(3).max(5000).register(z.globalRegistry, {
      description: 'Instruction for modifying the video',
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  mode: z.optional(
    z
      .enum([
        'adhere_1',
        'adhere_2',
        'adhere_3',
        'flex_1',
        'flex_2',
        'flex_3',
        'reimagine_1',
        'reimagine_2',
        'reimagine_3',
      ])
      .register(z.globalRegistry, {
        description:
          'Amount of modification to apply to the video, adhere_1 is the least amount of modification, reimagine_3 is the most',
      }),
  ),
  image_url: z.optional(z.union([z.string(), z.string()])),
})

/**
 * LipsyncOutput
 */
export const zSchemaPixverseLipsyncOutput = z.object({
  video: zSchemaFile,
})

/**
 * LipsyncRequest
 */
export const zSchemaPixverseLipsyncInput = z.object({
  text: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'Text content for TTS when audio_url is not provided',
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  audio_url: z.optional(z.union([z.string(), z.string()])),
  voice_id: z.optional(
    z
      .enum([
        'Emily',
        'James',
        'Isabella',
        'Liam',
        'Chloe',
        'Adrian',
        'Harper',
        'Ava',
        'Sophia',
        'Julia',
        'Mason',
        'Jack',
        'Oliver',
        'Ethan',
        'Auto',
      ])
      .register(z.globalRegistry, {
        description: 'Voice to use for TTS when audio_url is not provided',
      }),
  ),
})

/**
 * ExtendOutput
 */
export const zSchemaPixverseExtendOutput = z.object({
  video: zSchemaFile,
})

/**
 * ExtendRequest
 */
export const zSchemaPixverseExtendInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Prompt describing how to extend the video',
  }),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description:
        'The duration of the generated video in seconds. 1080p videos are limited to 5 seconds',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the extended video',
      }),
  ),
  video_url: z.union([z.string(), z.string()]),
  model: z.optional(
    z
      .enum(['v3.5', 'v4', 'v4.5', 'v5', 'v5.5', 'v5.6'])
      .register(z.globalRegistry, {
        description: 'The model version to use for generation',
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * ExtendOutput
 */
export const zSchemaPixverseExtendFastOutput = z.object({
  video: zSchemaFile,
})

/**
 * FastExtendRequest
 */
export const zSchemaPixverseExtendFastInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Prompt describing how to extend the video',
  }),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p']).register(z.globalRegistry, {
      description:
        "The resolution of the generated video. Fast mode doesn't support 1080p",
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the extended video',
      }),
  ),
  model: z.optional(
    z
      .enum(['v3.5', 'v4', 'v4.5', 'v5', 'v5.5', 'v5.6'])
      .register(z.globalRegistry, {
        description: 'The model version to use for generation',
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * Output
 */
export const zSchemaThinksoundOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used to generate the audio.',
  }),
  video: zSchemaFile,
})

/**
 * Input
 */
export const zSchemaThinksoundInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'A prompt to guide the audio generation. If not provided, it will be extracted from the video.',
      }),
    )
    .default(''),
  video_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(100).register(z.globalRegistry, {
        description: 'The number of inference steps for audio generation.',
      }),
    )
    .default(24),
  cfg_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description: 'The classifier-free guidance scale for audio generation.',
      }),
    )
    .default(5),
})

/**
 * AudioOutput
 */
export const zSchemaThinksoundAudioOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used to generate the audio.',
  }),
  audio: zSchemaFile,
})

/**
 * Input
 */
export const zSchemaThinksoundAudioInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'A prompt to guide the audio generation. If not provided, it will be extracted from the video.',
      }),
    )
    .default(''),
  video_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(100).register(z.globalRegistry, {
        description: 'The number of inference steps for audio generation.',
      }),
    )
    .default(24),
  cfg_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description: 'The classifier-free guidance scale for audio generation.',
      }),
    )
    .default(5),
})

/**
 * SoundEffectOutput
 */
export const zSchemaPixverseSoundEffectsOutput = z.object({
  video: zSchemaFile,
})

/**
 * SoundEffectRequest
 */
export const zSchemaPixverseSoundEffectsInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Description of the sound effect to generate. If empty, a random sound effect will be generated',
      }),
    )
    .default(''),
  video_url: z.union([z.string(), z.string()]),
  original_sound_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to keep the original audio from the video',
      }),
    )
    .default(false),
})

/**
 * MultiConditioningVideoOutput
 */
export const zSchemaLtxv13B098DistilledMulticonditioningOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * DistilledMultiConditioningVideoInput
 *
 * Distilled model input
 */
export const zSchemaLtxv13B098DistilledMulticonditioningInput = z
  .object({
    second_pass_skip_initial_steps: z
      .optional(
        z.int().gte(1).lte(11).register(z.globalRegistry, {
          description:
            'The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.',
        }),
      )
      .default(5),
    first_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(12).register(z.globalRegistry, {
          description: 'Number of inference steps during the first pass.',
        }),
      )
      .default(8),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: 'The frame rate of the video.',
        }),
      )
      .default(24),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to reverse the video.',
        }),
      )
      .default(false),
    prompt: z.string().register(z.globalRegistry, {
      description: 'Text prompt to guide generation',
    }),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to expand the prompt using a language model.',
        }),
      )
      .default(false),
    temporal_adain_factor: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            'The factor for adaptive instance normalization (AdaIN) applied to generated video chunks after the first. This can help deal with a gradual increase in saturation/contrast in the generated video by normalizing the color distribution across the video. A high value will ensure the color distribution is more consistent across the video, while a low value will allow for more variation in color distribution.',
        }),
      )
      .default(0.5),
    loras: z
      .optional(
        z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
          description: 'LoRA weights to use for generation',
        }),
      )
      .default([]),
    images: z
      .optional(
        z.array(zSchemaImageConditioningInput).register(z.globalRegistry, {
          description: 'URL of images to use as conditioning',
        }),
      )
      .default([]),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable the safety checker.',
        }),
      )
      .default(true),
    num_frames: z
      .optional(
        z.int().gte(9).lte(1441).register(z.globalRegistry, {
          description: 'The number of frames in the video.',
        }),
      )
      .default(121),
    second_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(12).register(z.globalRegistry, {
          description: 'Number of inference steps during the second pass.',
        }),
      )
      .default(8),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'Negative prompt for generation',
        }),
      )
      .default(
        'worst quality, inconsistent motion, blurry, jittery, distorted',
      ),
    enable_detail_pass: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to use a detail pass. If True, the model will perform a second pass to refine the video and enhance details. This incurs a 2.0x cost multiplier on the base price.',
        }),
      )
      .default(false),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(['9:16', '1:1', '16:9', 'auto']).register(z.globalRegistry, {
        description: 'The aspect ratio of the video.',
      }),
    ),
    tone_map_compression_ratio: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            'The compression ratio for tone mapping. This is used to compress the dynamic range of the video to improve visual quality. A value of 0.0 means no compression, while a value of 1.0 means maximum compression.',
        }),
      )
      .default(0),
    videos: z
      .optional(
        z.array(zSchemaVideoConditioningInput).register(z.globalRegistry, {
          description: 'Videos to use as conditioning',
        }),
      )
      .default([]),
    constant_rate_factor: z
      .optional(
        z.int().gte(0).lte(51).register(z.globalRegistry, {
          description:
            "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        }),
      )
      .default(29),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'Random seed for generation',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Distilled model input',
  })

/**
 * ModifyOutput
 */
export const zSchemaLumaDreamMachineRay2FlashModifyOutput = z.object({
  video: zSchemaFile,
})

/**
 * ModifyVideoRequest
 */
export const zSchemaLumaDreamMachineRay2FlashModifyInput = z.object({
  prompt: z.optional(
    z.string().min(3).max(5000).register(z.globalRegistry, {
      description: 'Instruction for modifying the video',
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  mode: z.optional(
    z
      .enum([
        'adhere_1',
        'adhere_2',
        'adhere_3',
        'flex_1',
        'flex_2',
        'flex_3',
        'reimagine_1',
        'reimagine_2',
        'reimagine_3',
      ])
      .register(z.globalRegistry, {
        description:
          'Amount of modification to apply to the video, adhere_1 is the least amount of modification, reimagine_3 is the most',
      }),
  ),
  image_url: z.optional(z.union([z.string(), z.string()])),
})

/**
 * FILMVideoOutput
 */
export const zSchemaFilmVideoOutput = z.object({
  video: zSchemaVideoFile,
})

/**
 * FILMVideoInput
 */
export const zSchemaFilmVideoInput = z.object({
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description:
        "The write mode of the output video. Only applicable if output_type is 'video'.",
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  use_calculated_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If True, the function will use the calculated FPS of the input video multiplied by the number of frames to determine the output FPS. If False, the passed FPS will be used.',
      }),
    )
    .default(true),
  loop: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If True, the final frame will be looped back to the first frame to create a seamless loop. If False, the final frame will not loop back.',
      }),
    )
    .default(false),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'Frames per second for the output video. Only applicable if use_calculated_fps is False.',
      }),
    )
    .default(8),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description:
        "The quality of the output video. Only applicable if output_type is 'video'.",
    }),
  ),
  use_scene_detection: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If True, the input video will be split into scenes before interpolation. This removes smear frames between scenes, but can result in false positives if the scene detection is not accurate. If False, the entire video will be treated as a single scene.',
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description:
          'The number of frames to generate between the input video frames.',
      }),
    )
    .default(1),
})

/**
 * RIFEVideoOutput
 */
export const zSchemaRifeVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * RIFEVideoInput
 */
export const zSchemaRifeVideoInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  use_scene_detection: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If True, the input video will be split into scenes before interpolation. This removes smear frames between scenes, but can result in false positives if the scene detection is not accurate. If False, the entire video will be treated as a single scene.',
      }),
    )
    .default(false),
  loop: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If True, the final frame will be looped back to the first frame to create a seamless loop. If False, the final frame will not loop back.',
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description:
          'The number of frames to generate between the input video frames.',
      }),
    )
    .default(1),
  use_calculated_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If True, the function will use the calculated FPS of the input video multiplied by the number of frames to determine the output FPS. If False, the passed FPS will be used.',
      }),
    )
    .default(true),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'Frames per second for the output video. Only applicable if use_calculated_fps is False.',
      }),
    )
    .default(8),
})

/**
 * ExtendVideoConditioningInput
 */
export const zSchemaExtendVideoConditioningInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  start_frame_num: z
    .optional(
      z.int().gte(0).lte(1440).register(z.globalRegistry, {
        description:
          'Frame number of the video from which the conditioning starts. Must be a multiple of 8.',
      }),
    )
    .default(0),
  reverse_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to reverse the video. This is useful for tasks where the video conditioning should be applied in reverse order.',
      }),
    )
    .default(false),
  limit_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to limit the number of frames used from the video. If True, the `max_num_frames` parameter will be used to limit the number of frames.',
      }),
    )
    .default(false),
  resample_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to resample the video to a specific FPS. If True, the `target_fps` parameter will be used to resample the video.',
      }),
    )
    .default(false),
  strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Strength of the conditioning. 0.0 means no conditioning, 1.0 means full conditioning.',
      }),
    )
    .default(1),
  target_fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'Target FPS to resample the video to. Only relevant if `resample_fps` is True.',
      }),
    )
    .default(24),
  max_num_frames: z
    .optional(
      z.int().gte(1).lte(1441).register(z.globalRegistry, {
        description:
          'Maximum number of frames to use from the video. If None, all frames will be used.',
      }),
    )
    .default(1441),
})

/**
 * ExtendVideoOutput
 */
export const zSchemaLtxv13B098DistilledExtendOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * DistilledExtendVideoInput
 *
 * Distilled model input
 */
export const zSchemaLtxv13B098DistilledExtendInput = z
  .object({
    second_pass_skip_initial_steps: z
      .optional(
        z.int().gte(1).lte(11).register(z.globalRegistry, {
          description:
            'The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.',
        }),
      )
      .default(5),
    first_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(12).register(z.globalRegistry, {
          description: 'Number of inference steps during the first pass.',
        }),
      )
      .default(8),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: 'The frame rate of the video.',
        }),
      )
      .default(24),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to reverse the video.',
        }),
      )
      .default(false),
    prompt: z.string().register(z.globalRegistry, {
      description: 'Text prompt to guide generation',
    }),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to expand the prompt using a language model.',
        }),
      )
      .default(false),
    temporal_adain_factor: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            'The factor for adaptive instance normalization (AdaIN) applied to generated video chunks after the first. This can help deal with a gradual increase in saturation/contrast in the generated video by normalizing the color distribution across the video. A high value will ensure the color distribution is more consistent across the video, while a low value will allow for more variation in color distribution.',
        }),
      )
      .default(0.5),
    loras: z
      .optional(
        z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
          description: 'LoRA weights to use for generation',
        }),
      )
      .default([]),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable the safety checker.',
        }),
      )
      .default(true),
    num_frames: z
      .optional(
        z.int().gte(9).lte(1441).register(z.globalRegistry, {
          description: 'The number of frames in the video.',
        }),
      )
      .default(121),
    second_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(12).register(z.globalRegistry, {
          description: 'Number of inference steps during the second pass.',
        }),
      )
      .default(8),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'Negative prompt for generation',
        }),
      )
      .default(
        'worst quality, inconsistent motion, blurry, jittery, distorted',
      ),
    video: zSchemaExtendVideoConditioningInput,
    enable_detail_pass: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to use a detail pass. If True, the model will perform a second pass to refine the video and enhance details. This incurs a 2.0x cost multiplier on the base price.',
        }),
      )
      .default(false),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(['9:16', '1:1', '16:9', 'auto']).register(z.globalRegistry, {
        description: 'The aspect ratio of the video.',
      }),
    ),
    tone_map_compression_ratio: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            'The compression ratio for tone mapping. This is used to compress the dynamic range of the video to improve visual quality. A value of 0.0 means no compression, while a value of 1.0 means maximum compression.',
        }),
      )
      .default(0),
    constant_rate_factor: z
      .optional(
        z.int().gte(0).lte(51).register(z.globalRegistry, {
          description:
            "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        }),
      )
      .default(29),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'Random seed for generation',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Distilled model input',
  })

/**
 * WanV2VResponse
 */
export const zSchemaWanV22A14bVideoToVideoOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The text prompt used for video generation.',
      }),
    )
    .default(''),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanV2VRequest
 */
export const zSchemaWanV22A14bVideoToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  video_url: z.union([z.string(), z.string()]),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(4).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.',
      }),
    )
    .default(1),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift value for the video. Must be between 1.0 and 10.0.',
      }),
    )
    .default(5),
  resample_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the video will be resampled to the passed frames per second. If false, the video will not be resampled.',
      }),
    )
    .default(false),
  frames_per_second: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.',
      }),
    )
    .default(16),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, input data will be checked for safety before processing.',
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(17).lte(161).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 17 to 161 (inclusive).',
      }),
    )
    .default(81),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(3.5),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(''),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description:
        'The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p, 580p, or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input video.",
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, output video will be checked for safety after generation.',
      }),
    )
    .default(false),
  guidance_scale_2: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.',
      }),
    )
    .default(4),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description:
        'The quality of the output video. Higher quality means better visual quality but larger file size.',
    }),
  ),
  strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Strength of the video transformation. A value of 1.0 means the output will be completely based on the prompt, while a value of 0.0 means the output will be identical to the input video.',
      }),
    )
    .default(0.9),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(27),
  interpolator_model: z.optional(
    z.enum(['none', 'film', 'rife']).register(z.globalRegistry, {
      description:
        'The model to use for frame interpolation. If None, no interpolation is applied.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  adjust_fps_for_interpolation: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.',
      }),
    )
    .default(true),
})

/**
 * MergeVideosOutput
 */
export const zSchemaFfmpegApiMergeVideosOutput = z.object({
  metadata: z.record(z.string(), z.unknown()).register(z.globalRegistry, {
    description:
      'Metadata about the merged video including original video info',
  }),
  video: zSchemaFile,
})

/**
 * MergeVideosInput
 */
export const zSchemaFfmpegApiMergeVideosInput = z.object({
  target_fps: z.optional(z.union([z.number().gte(1).lte(60), z.unknown()])),
  video_urls: z.array(z.string()).min(2).register(z.globalRegistry, {
    description: 'List of video URLs to merge in order',
  }),
  resolution: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
      z.unknown(),
    ]),
  ),
})

/**
 * MareyOutput
 */
export const zSchemaMareyMotionTransferOutput = z.object({
  video: zSchemaFile,
})

/**
 * MareyInputMotionTransfer
 */
export const zSchemaMareyMotionTransferInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate a video from',
  }),
  video_url: z.union([z.string(), z.string()]),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  reference_image_url: z.optional(z.union([z.string(), z.unknown()])),
  negative_prompt: z.optional(z.union([z.string(), z.unknown()])),
  first_frame_image_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * MareyOutput
 */
export const zSchemaMareyPoseTransferOutput = z.object({
  video: zSchemaFile,
})

/**
 * MareyInputPoseTransfer
 */
export const zSchemaMareyPoseTransferInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate a video from',
  }),
  video_url: z.union([z.string(), z.string()]),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  reference_image_url: z.optional(z.union([z.string(), z.unknown()])),
  negative_prompt: z.optional(z.union([z.string(), z.unknown()])),
  first_frame_image_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * VideoOutput
 */
export const zSchemaSfxV1VideoToVideoOutput = z.object({
  video: z.array(zSchemaVideo).register(z.globalRegistry, {
    description: 'The processed video with sound effects',
  }),
})

/**
 * Input
 */
export const zSchemaSfxV1VideoToVideoInput = z.object({
  num_samples: z.optional(z.union([z.int().gte(2).lte(8), z.unknown()])),
  video_url: z.union([z.string(), z.string()]),
  duration: z.optional(z.union([z.number().gte(1).lte(10), z.unknown()])),
  seed: z.optional(z.union([z.int().gte(1), z.unknown()])),
  text_prompt: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * AvatarSingleAudioResponse
 */
export const zSchemaInfinitalkOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * InfiniTalkSingleAudioRequest
 */
export const zSchemaInfinitalkInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the video to generate. Must be either 480p or 720p.',
    }),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use for generation.',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  audio_url: z.union([z.string(), z.string()]),
  num_frames: z
    .optional(
      z.int().gte(41).lte(721).register(z.globalRegistry, {
        description: 'Number of frames to generate. Must be between 41 to 721.',
      }),
    )
    .default(145),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    )
    .default(42),
})

/**
 * OutputIncreaseResolutionModel
 */
export const zSchemaVideoIncreaseResolutionOutput = z.object({
  video: z.union([zSchemaVideo, zSchemaFile]),
})

/**
 * InputIncreaseResolutionModel
 */
export const zSchemaVideoIncreaseResolutionInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  output_container_and_codec: z.optional(
    z
      .enum([
        'mp4_h265',
        'mp4_h264',
        'webm_vp9',
        'mov_h265',
        'mov_proresks',
        'mkv_h265',
        'mkv_h264',
        'mkv_vp9',
        'gif',
      ])
      .register(z.globalRegistry, {
        description:
          'Output container and codec. Options: mp4_h265, mp4_h264, webm_vp9, mov_h265, mov_proresks, mkv_h265, mkv_h264, mkv_vp9, gif.',
      }),
  ),
  desired_increase: z.optional(
    z.enum(['2', '4']).register(z.globalRegistry, {
      description: 'desired_increase factor. Options: 2x, 4x.',
    }),
  ),
})

/**
 * WanFunControlResponse
 */
export const zSchemaWanFunControlOutput = z.object({
  video: zSchemaFile,
})

/**
 * WanFunControlRequest
 */
export const zSchemaWanFunControlInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video.',
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The shift for the scheduler.',
      }),
    )
    .default(5),
  preprocess_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to preprocess the video. If True, the video will be preprocessed to depth or pose.',
      }),
    )
    .default(false),
  reference_image_url: z.optional(z.union([z.string(), z.string()])),
  fps: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          'The fps to generate. Only used when match_input_fps is False.',
      }),
    )
    .default(16),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to match the number of frames in the input video.',
      }),
    )
    .default(true),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale.',
      }),
    )
    .default(6),
  preprocess_type: z.optional(
    z.enum(['depth', 'pose']).register(z.globalRegistry, {
      description:
        'The type of preprocess to apply to the video. Only used when preprocess_video is True.',
    }),
  ),
  control_video_url: z.union([z.string(), z.string()]),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video.',
      }),
    )
    .default(''),
  num_frames: z
    .optional(
      z.int().gte(49).lte(121).register(z.globalRegistry, {
        description:
          'The number of frames to generate. Only used when match_input_num_frames is False.',
      }),
    )
    .default(81),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(4).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps.',
      }),
    )
    .default(27),
  match_input_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to match the fps in the input video.',
      }),
    )
    .default(true),
})

/**
 * LipSyncV2ProOutput
 */
export const zSchemaSyncLipsyncV2ProOutput = z.object({
  video: zSchemaFile,
})

/**
 * LipSyncV2ProInput
 */
export const zSchemaSyncLipsyncV2ProInput = z.object({
  sync_mode: z.optional(
    z
      .enum(['cut_off', 'loop', 'bounce', 'silence', 'remap'])
      .register(z.globalRegistry, {
        description:
          'Lipsync mode when audio and video durations are out of sync.',
      }),
  ),
  video_url: z.union([z.string(), z.string()]),
  audio_url: z.union([z.string(), z.string()]),
})

/**
 * HunyuanFoleyResponse
 */
export const zSchemaHunyuanVideoFoleyOutput = z.object({
  video: zSchemaFile,
})

/**
 * HunyuanFoleyRequest
 */
export const zSchemaHunyuanVideoFoleyInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Guidance scale for audio generation.',
      }),
    )
    .default(4.5),
  num_inference_steps: z
    .optional(
      z.int().gte(10).lte(100).register(z.globalRegistry, {
        description: 'Number of inference steps for generation.',
      }),
    )
    .default(50),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for reproducible generation.',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to avoid certain audio characteristics.',
      }),
    )
    .default('noisy, harsh'),
  text_prompt: z.string().register(z.globalRegistry, {
    description: 'Text description of the desired audio (optional).',
  }),
})

/**
 * WanVACEPoseResponse
 */
export const zSchemaWan22VaceFunA14bPoseOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  frames_zip: z.optional(z.union([zSchemaFile, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * WanVACEPoseRequest
 */
export const zSchemaWan22VaceFunA14bPoseInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The text prompt to guide video generation. For pose task, the prompt should describe the desired pose and action of the subject in the video.',
  }),
  video_url: z.union([z.string(), z.string()]),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between the original frames. A value of 0 means no interpolation.',
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.',
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'URLs to source reference image. If provided, the model will use this image as reference.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.',
      }),
    )
    .default(5),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 241 (inclusive).',
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.',
      }),
    )
    .default(15),
  transparency_mode: z.optional(
    z.enum(['content_aware', 'white', 'black']).register(z.globalRegistry, {
      description:
        'The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.',
    }),
  ),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'Sampler to use for video generation.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(['rife', 'film']).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.',
      }),
    )
    .default(false),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the input video.',
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.union([z.enum(['none', 'low', 'regular']), z.unknown()]),
  ),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP file containing all generated frames.',
      }),
    )
    .default(false),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * WanVACEDepthResponse
 */
export const zSchemaWan22VaceFunA14bDepthOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  frames_zip: z.optional(z.union([zSchemaFile, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * WanVACEDepthRequest
 */
export const zSchemaWan22VaceFunA14bDepthInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  video_url: z.union([z.string(), z.string()]),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between the original frames. A value of 0 means no interpolation.',
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.',
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'URLs to source reference image. If provided, the model will use this image as reference.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.',
      }),
    )
    .default(5),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 241 (inclusive).',
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.',
      }),
    )
    .default(15),
  transparency_mode: z.optional(
    z.enum(['content_aware', 'white', 'black']).register(z.globalRegistry, {
      description:
        'The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.',
    }),
  ),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'Sampler to use for video generation.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(['rife', 'film']).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.',
      }),
    )
    .default(false),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the input video.',
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.union([z.enum(['none', 'low', 'regular']), z.unknown()]),
  ),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP file containing all generated frames.',
      }),
    )
    .default(false),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * WanVACEInpaintingResponse
 */
export const zSchemaWan22VaceFunA14bInpaintingOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  frames_zip: z.optional(z.union([zSchemaFile, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * WanVACEInpaintingRequest
 */
export const zSchemaWan22VaceFunA14bInpaintingInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  video_url: z.union([z.string(), z.string()]),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between the original frames. A value of 0 means no interpolation.',
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.',
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'Urls to source reference image. If provided, the model will use this image as reference.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.',
      }),
    )
    .default(5),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 241 (inclusive).',
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.',
      }),
    )
    .default(15),
  transparency_mode: z.optional(
    z.enum(['content_aware', 'white', 'black']).register(z.globalRegistry, {
      description:
        'The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.',
    }),
  ),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'Sampler to use for video generation.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  mask_video_url: z.union([z.string(), z.unknown()]),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(['rife', 'film']).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.',
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the input video.',
      }),
    )
    .default(false),
  acceleration: z.optional(
    z.union([z.enum(['none', 'low', 'regular']), z.unknown()]),
  ),
  mask_image_url: z.optional(z.union([z.string(), z.unknown()])),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP file containing all generated frames.',
      }),
    )
    .default(false),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * WanVACEOutpaintingResponse
 */
export const zSchemaWan22VaceFunA14bOutpaintingOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  frames_zip: z.optional(z.union([zSchemaFile, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * WanVACEOutpaintingRequest
 */
export const zSchemaWan22VaceFunA14bOutpaintingInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  video_url: z.union([z.string(), z.string()]),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between the original frames. A value of 0 means no interpolation.',
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.',
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'URLs to source reference image. If provided, the model will use this image as reference.',
    }),
  ),
  expand_ratio: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Amount of expansion. This is a float value between 0 and 1, where 0.25 adds 25% to the original video size on the specified sides.',
      }),
    )
    .default(0.25),
  transparency_mode: z.optional(
    z.enum(['content_aware', 'white', 'black']).register(z.globalRegistry, {
      description:
        'The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 241 (inclusive).',
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.',
      }),
    )
    .default(15),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.',
      }),
    )
    .default(5),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'Sampler to use for video generation.',
    }),
  ),
  expand_bottom: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to expand the video to the bottom.',
      }),
    )
    .default(false),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  expand_left: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to expand the video to the left.',
      }),
    )
    .default(false),
  interpolator_model: z.optional(
    z.enum(['rife', 'film']).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.',
      }),
    )
    .default(false),
  expand_top: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to expand the video to the top.',
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  acceleration: z.optional(
    z.union([z.enum(['none', 'low', 'regular']), z.unknown()]),
  ),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  expand_right: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to expand the video to the right.',
      }),
    )
    .default(false),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP file containing all generated frames.',
      }),
    )
    .default(false),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * WanVACEReframeResponse
 */
export const zSchemaWan22VaceFunA14bReframeOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  frames_zip: z.optional(z.union([zSchemaFile, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * WanVACEReframeRequest
 */
export const zSchemaWan22VaceFunA14bReframeInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'The text prompt to guide video generation. Optional for reframing.',
      }),
    )
    .default(''),
  video_url: z.union([z.string(), z.string()]),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between the original frames. A value of 0 means no interpolation.',
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.',
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.',
      }),
    )
    .default(5),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 241 (inclusive).',
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.',
      }),
    )
    .default(15),
  trim_borders: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to trim borders from the video.',
      }),
    )
    .default(true),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'Sampler to use for video generation.',
    }),
  ),
  transparency_mode: z.optional(
    z.enum(['content_aware', 'white', 'black']).register(z.globalRegistry, {
      description:
        'The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(['rife', 'film']).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.',
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.union([z.enum(['none', 'low', 'regular']), z.unknown()]),
  ),
  zoom_factor: z
    .optional(
      z.number().gte(0).lte(0.9).register(z.globalRegistry, {
        description:
          'Zoom factor for the video. When this value is greater than 0, the video will be zoomed in by this factor (in relation to the canvas size,) cutting off the edges of the video. A value of 0 means no zoom.',
      }),
    )
    .default(0),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.',
      }),
    )
    .default(true),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP file containing all generated frames.',
      }),
    )
    .default(false),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * LucyEditDevOutput
 */
export const zSchemaLucyEditDevOutput = z.object({
  video: zSchemaFile,
})

/**
 * LucyEditDevInput
 */
export const zSchemaLucyEditDevInput = z.object({
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the video to be generated\n            and uploaded before returning the response. This will increase the\n            latency of the function but it allows you to get the video directly\n            in the response without going through the CDN.\n        ',
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text description of the desired video content',
  }),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enhance the prompt for better results.',
      }),
    )
    .default(true),
})

/**
 * LucyEditProOutput
 */
export const zSchemaLucyEditProOutput = z.object({
  video: zSchemaFile,
})

/**
 * LucyEditProInput
 */
export const zSchemaLucyEditProInput = z.object({
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the video to be generated\n            and uploaded before returning the response. This will increase the\n            latency of the function but it allows you to get the video directly\n            in the response without going through the CDN.\n        ',
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text description of the desired video content',
  }),
  resolution: z.optional(
    z.enum(['720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video',
    }),
  ),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enhance the prompt for better results.',
      }),
    )
    .default(true),
})

/**
 * WanAnimateMoveResponse
 */
export const zSchemaWanV2214bAnimateMoveOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation (auto-generated by the model)',
  }),
  frames_zip: z.optional(zSchemaFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
  video: zSchemaFile,
})

/**
 * WanAnimateMoveRequest
 */
export const zSchemaWanV2214bAnimateMoveInput = z.object({
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description:
        'The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.',
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p, 580p, or 720p).',
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP archive containing per-frame images generated on GPU (lossless).',
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift value for the video. Must be between 1.0 and 10.0.',
      }),
    )
    .default(5),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, output video will be checked for safety after generation.',
      }),
    )
    .default(false),
  image_url: z.union([z.string(), z.string()]),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description:
        'The quality of the output video. Higher quality means better visual quality but larger file size.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, input data will be checked for safety before processing.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(20),
  use_turbo: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, applies quality enhancement for faster generation with improved quality. When enabled, parameters are automatically optimized for best results.',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(1),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
})

/**
 * WanAnimateReplaceResponse
 */
export const zSchemaWanV2214bAnimateReplaceOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation (auto-generated by the model)',
  }),
  frames_zip: z.optional(zSchemaFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
  video: zSchemaFile,
})

/**
 * WanAnimateMoveRequest
 */
export const zSchemaWanV2214bAnimateReplaceInput = z.object({
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description:
        'The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.',
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p, 580p, or 720p).',
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP archive containing per-frame images generated on GPU (lossless).',
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift value for the video. Must be between 1.0 and 10.0.',
      }),
    )
    .default(5),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, output video will be checked for safety after generation.',
      }),
    )
    .default(false),
  image_url: z.union([z.string(), z.string()]),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description:
        'The quality of the output video. Higher quality means better visual quality but larger file size.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, input data will be checked for safety before processing.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(20),
  use_turbo: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, applies quality enhancement for faster generation with improved quality. When enabled, parameters are automatically optimized for best results.',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(1),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
})

/**
 * WanVACEVideoEditResponse
 */
export const zSchemaWanVaceAppsVideoEditOutput = z.object({
  frames_zip: z.optional(zSchemaFile),
  video: zSchemaVideoFile,
})

/**
 * WanVACEVideoEditRequest
 */
export const zSchemaWanVaceAppsVideoEditInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Prompt to edit the video.',
  }),
  video_url: z.union([z.string(), z.string()]),
  acceleration: z.optional(
    z.enum(['none', 'low', 'regular']).register(z.globalRegistry, {
      description:
        "Acceleration to use for inference. Options are 'none' or 'regular'. Accelerated inference will very slightly affect output, but will be significantly faster.",
    }),
  ),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the edited video.',
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'Aspect ratio of the edited video.',
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to include a ZIP archive containing all generated frames.',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  video_type: z.optional(
    z.enum(['auto', 'general', 'human']).register(z.globalRegistry, {
      description:
        "The type of video you're editing. Use 'general' for most videos, and 'human' for videos emphasizing human subjects and motions. The default value 'auto' means the model will guess based on the first frame of the video.",
    }),
  ),
  image_urls: z
    .optional(
      z.array(z.string()).register(z.globalRegistry, {
        description:
          'URLs of the input images to use as a reference for the generation.',
      }),
    )
    .default([]),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable automatic downsampling. If your video has a high frame rate or is long, enabling longer sequences to be generated. The video will be interpolated back to the original frame rate after generation.',
      }),
    )
    .default(true),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'The minimum frames per second to downsample the video to.',
      }),
    )
    .default(15),
})

/**
 * SeedVRVideoOutput
 */
export const zSchemaSeedvrUpscaleVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The random seed used for the generation process.',
  }),
  video: zSchemaFile,
})

/**
 * SeedVRVideoInput
 */
export const zSchemaSeedvrUpscaleVideoInput = z.object({
  upscale_mode: z.optional(
    z.enum(['target', 'factor']).register(z.globalRegistry, {
      description:
        "The mode to use for the upscale. If 'target', the upscale factor will be calculated based on the target resolution. If 'factor', the upscale factor will be used directly.",
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  noise_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The noise scale to use for the generation process.',
      }),
    )
    .default(0.1),
  output_format: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The format of the output video.',
      }),
  ),
  output_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the output video.',
    }),
  ),
  target_resolution: z.optional(
    z.enum(['720p', '1080p', '1440p', '2160p']).register(z.globalRegistry, {
      description:
        'The target resolution to upscale to when `upscale_mode` is `target`.',
    }),
  ),
  output_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the output video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  upscale_factor: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Upscaling factor to be used. Will multiply the dimensions with this factor when `upscale_mode` is `factor`.',
      }),
    )
    .default(2),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * InfinitalkVid2VidResponse
 */
export const zSchemaInfinitalkVideoToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * InfiniTalkVid2VidAudioRequest
 */
export const zSchemaInfinitalkVideoToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the video to generate. Must be either 480p or 720p.',
    }),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use for generation.',
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  audio_url: z.union([z.string(), z.string()]),
  num_frames: z
    .optional(
      z.int().gte(41).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.',
      }),
    )
    .default(145),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    )
    .default(42),
})

/**
 * LongWanVACEReframeResponse
 */
export const zSchemaWanVaceAppsLongReframeOutput = z.object({
  video: zSchemaVideoFile,
})

/**
 * LongWanVACEReframeRequest
 */
export const zSchemaWanVaceAppsLongReframeInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'The text prompt to guide video generation. Optional for reframing.',
      }),
    )
    .default(''),
  video_url: z.union([z.string(), z.string()]),
  acceleration: z.optional(
    z.enum(['none', 'low', 'regular']).register(z.globalRegistry, {
      description:
        "Acceleration to use for inference. Options are 'none' or 'regular'. Accelerated inference will very slightly affect output, but will be significantly faster.",
    }),
  ),
  paste_back: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to paste back the reframed scene to the original video.',
      }),
    )
    .default(true),
  zoom_factor: z
    .optional(
      z.number().gte(0).lte(0.9).register(z.globalRegistry, {
        description:
          'Zoom factor for the video. When this value is greater than 0, the video will be zoomed in by this factor (in relation to the canvas size,) cutting off the edges of the video. A value of 0 means no zoom.',
      }),
    )
    .default(0),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  scene_threshold: z
    .optional(
      z.number().gte(0).lte(100).register(z.globalRegistry, {
        description:
          'Threshold for scene detection sensitivity (0-100). Lower values detect more scenes.',
      }),
    )
    .default(30),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.',
      }),
    )
    .default(5),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'Minimum FPS for auto downsample.',
      }),
    )
    .default(6),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'Sampler to use for video generation.',
    }),
  ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP file containing all generated frames.',
      }),
    )
    .default(false),
  trim_borders: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to trim borders from the video.',
      }),
    )
    .default(true),
  transparency_mode: z.optional(
    z.enum(['content_aware', 'white', 'black']).register(z.globalRegistry, {
      description:
        'The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.',
    }),
  ),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  interpolator_model: z.optional(
    z.enum(['rife', 'film']).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable auto downsample.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
})

/**
 * ImageFile
 */
export const zSchemaImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * RemixOutput
 */
export const zSchemaSora2VideoToVideoRemixOutput = z.object({
  spritesheet: z.optional(zSchemaImageFile),
  thumbnail: z.optional(zSchemaImageFile),
  video_id: z.string().register(z.globalRegistry, {
    description: 'The ID of the generated video',
  }),
  video: zSchemaVideoFile,
})

/**
 * RemixInput
 */
export const zSchemaSora2VideoToVideoRemixInput = z.object({
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: 'Updated text prompt that directs the remix generation',
  }),
  video_id: z.string().register(z.globalRegistry, {
    description:
      'The video_id from a previous Sora 2 generation. Note: You can only remix videos that were generated by Sora (via text-to-video or image-to-video endpoints), not arbitrary uploaded videos.',
  }),
  delete_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to delete the video after generation for privacy reasons. If True, the video cannot be used for remixing and will be permanently deleted.',
      }),
    )
    .default(true),
})

/**
 * VideoToVideoOutput
 */
export const zSchemaKreaWan14bVideoToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * VideoToVideoInput
 */
export const zSchemaKreaWan14bVideoToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Prompt for the video-to-video generation.',
  }),
  video_url: z.union([z.string(), z.string()]),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'Denoising strength for the video-to-video generation. 0.0 preserves the original, 1.0 completely remakes the video.',
      }),
    )
    .default(0.85),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * Video
 */
export const zSchemaVideoOutput = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * VideoOutput
 */
export const zSchemaSfxV15VideoToVideoOutput = z.object({
  video: z.array(zSchemaVideoOutput).register(z.globalRegistry, {
    description: 'The processed video with sound effects',
  }),
})

/**
 * Input
 */
export const zSchemaSfxV15VideoToVideoInput = z.object({
  num_samples: z.optional(z.union([z.int().gte(2).lte(8), z.unknown()])),
  duration: z.optional(z.union([z.number().gte(1).lte(10), z.unknown()])),
  start_offset: z.optional(z.union([z.number().gte(0), z.unknown()])),
  video_url: z.union([z.string(), z.string()]),
  seed: z.optional(z.union([z.int().gte(1), z.unknown()])),
  text_prompt: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * Q2VideoExtensionOutput
 */
export const zSchemaViduQ2VideoExtensionProOutput = z.object({
  video: zSchemaFile,
})

/**
 * Q2VideoExtensionRequest
 */
export const zSchemaViduQ2VideoExtensionProInput = z.object({
  prompt: z.optional(
    z.string().max(3000).register(z.globalRegistry, {
      description: 'text prompt to guide the video extension',
    }),
  ),
  duration: z.optional(
    z
      .union([
        z.literal(2),
        z.literal(3),
        z.literal(4),
        z.literal(5),
        z.literal(6),
        z.literal(7),
      ])
      .register(z.globalRegistry, {
        description: 'Duration of the extension in seconds',
      }),
  ),
  video_url: z.union([z.string(), z.string()]),
  resolution: z.optional(
    z.enum(['720p', '1080p']).register(z.globalRegistry, {
      description: 'Output video resolution',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
})

/**
 * VideoOutput
 */
export const zSchemaBirefnetV2VideoOutput = z.object({
  video: zSchemaVideoFile,
  mask_video: z.optional(zSchemaVideoFile),
})

/**
 * VideoInputV2
 */
export const zSchemaBirefnetV2VideoInput = z.object({
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  operating_resolution: z.optional(
    z.enum(['1024x1024', '2048x2048', '2304x2304']).register(z.globalRegistry, {
      description:
        "The resolution to operate on. The higher the resolution, the more accurate the output will be for high res input images. The '2304x2304' option is only available for the 'General Use (Dynamic)' model.",
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  model: z.optional(
    z
      .enum([
        'General Use (Light)',
        'General Use (Light 2K)',
        'General Use (Heavy)',
        'Matting',
        'Portrait',
        'General Use (Dynamic)',
      ])
      .register(z.globalRegistry, {
        description:
          "\n            Model to use for background removal.\n            The 'General Use (Light)' model is the original model used in the BiRefNet repository.\n            The 'General Use (Light 2K)' model is the original model used in the BiRefNet repository but trained with 2K images.\n            The 'General Use (Heavy)' model is a slower but more accurate model.\n            The 'Matting' model is a model trained specifically for matting images.\n            The 'Portrait' model is a model trained specifically for portrait images.\n            The 'General Use (Dynamic)' model supports dynamic resolutions from 256x256 to 2304x2304.\n            The 'General Use (Light)' model is recommended for most use cases.\n\n            The corresponding models are as follows:\n            - 'General Use (Light)': BiRefNet\n            - 'General Use (Light 2K)': BiRefNet_lite-2K\n            - 'General Use (Heavy)': BiRefNet_lite\n            - 'Matting': BiRefNet-matting\n            - 'Portrait': BiRefNet-portrait\n            - 'General Use (Dynamic)': BiRefNet_dynamic\n        ",
      }),
  ),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  output_mask: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to output the mask used to remove the background',
      }),
    )
    .default(false),
  refine_foreground: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to refine the foreground using the estimated mask',
      }),
    )
    .default(true),
})

/**
 * VideoEffectOutput
 */
export const zSchemaVideoAsPromptOutput = z.object({
  video: zSchemaFile,
})

/**
 * VideoEffectInputWan
 */
export const zSchemaVideoAsPromptInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video.',
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description:
          "Frames per second for the output video. Only applicable if output_type is 'video'.",
      }),
    )
    .default(16),
  video_description: z.string().register(z.globalRegistry, {
    description: 'A brief description of the input video content.',
  }),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description: 'Guidance scale for generation.',
      }),
    )
    .default(5),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(1).lte(100).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(49),
})

/**
 * UpscaleOutput
 */
export const zSchemaBytedanceUpscalerUpscaleVideoOutput = z.object({
  duration: z.number().register(z.globalRegistry, {
    description: 'Duration of audio input/video output as used for billing.',
  }),
  video: zSchemaFile,
})

/**
 * UpscaleInput
 */
export const zSchemaBytedanceUpscalerUpscaleVideoInput = z.object({
  target_fps: z.optional(
    z.enum(['30fps', '60fps']).register(z.globalRegistry, {
      description: 'The target FPS of the video to upscale.',
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  target_resolution: z.optional(
    z.enum(['1080p', '2k', '4k']).register(z.globalRegistry, {
      description: 'The target resolution of the video to upscale.',
    }),
  ),
})

/**
 * AutoSubtitleOutput
 *
 * Output model for video with automatic subtitles
 */
export const zSchemaWorkflowUtilitiesAutoSubtitleOutput = z
  .object({
    transcription: z.string().register(z.globalRegistry, {
      description: 'Full transcription text',
    }),
    subtitle_count: z.int().register(z.globalRegistry, {
      description: 'Number of subtitle segments generated',
    }),
    transcription_metadata: z.optional(
      z.record(z.string(), z.unknown()).register(z.globalRegistry, {
        description:
          'Additional transcription metadata from ElevenLabs (language, segments, etc.)',
      }),
    ),
    words: z.optional(
      z.array(z.record(z.string(), z.unknown())).register(z.globalRegistry, {
        description: 'Word-level timing information from transcription service',
      }),
    ),
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output model for video with automatic subtitles',
  })

/**
 * AutoSubtitleInput
 *
 * Input model for automatic subtitle generation and styling
 */
export const zSchemaWorkflowUtilitiesAutoSubtitleInput = z
  .object({
    font_weight: z.optional(
      z.enum(['normal', 'bold', 'black']).register(z.globalRegistry, {
        description: 'Font weight (TikTok style typically uses bold or black)',
      }),
    ),
    video_url: z.union([z.string(), z.string()]),
    stroke_width: z
      .optional(
        z.int().gte(0).lte(10).register(z.globalRegistry, {
          description: 'Text stroke/outline width in pixels (0 for no stroke)',
        }),
      )
      .default(3),
    font_color: z.optional(
      z
        .enum([
          'white',
          'black',
          'red',
          'green',
          'blue',
          'yellow',
          'orange',
          'purple',
          'pink',
          'brown',
          'gray',
          'cyan',
          'magenta',
        ])
        .register(z.globalRegistry, {
          description: 'Subtitle text color for non-active words',
        }),
    ),
    font_size: z
      .optional(
        z.int().gte(20).lte(150).register(z.globalRegistry, {
          description:
            'Font size for subtitles (TikTok style uses larger text)',
        }),
      )
      .default(100),
    language: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            "Language code for transcription (e.g., 'en', 'es', 'fr', 'de', 'it', 'pt', 'nl', 'ja', 'zh', 'ko') or 3-letter ISO code (e.g., 'eng', 'spa', 'fra')",
        }),
      )
      .default('en'),
    y_offset: z
      .optional(
        z.int().gte(-200).lte(200).register(z.globalRegistry, {
          description:
            'Vertical offset in pixels (positive = move down, negative = move up)',
        }),
      )
      .default(75),
    background_opacity: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            'Background opacity (0.0 = fully transparent, 1.0 = fully opaque)',
        }),
      )
      .default(0),
    stroke_color: z.optional(
      z
        .enum([
          'black',
          'white',
          'red',
          'green',
          'blue',
          'yellow',
          'orange',
          'purple',
          'pink',
          'brown',
          'gray',
          'cyan',
          'magenta',
        ])
        .register(z.globalRegistry, {
          description: 'Text stroke/outline color',
        }),
    ),
    highlight_color: z.optional(
      z
        .enum([
          'white',
          'black',
          'red',
          'green',
          'blue',
          'yellow',
          'orange',
          'purple',
          'pink',
          'brown',
          'gray',
          'cyan',
          'magenta',
        ])
        .register(z.globalRegistry, {
          description:
            'Color for the currently speaking word (karaoke-style highlight)',
        }),
    ),
    enable_animation: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Enable animation effects for subtitles (bounce style entrance)',
        }),
      )
      .default(true),
    font_name: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            "Any Google Font name from fonts.google.com (e.g., 'Montserrat', 'Poppins', 'BBH Sans Hegarty')",
        }),
      )
      .default('Montserrat'),
    position: z.optional(
      z.enum(['top', 'center', 'bottom']).register(z.globalRegistry, {
        description: 'Vertical position of subtitles',
      }),
    ),
    words_per_subtitle: z
      .optional(
        z.int().gte(1).lte(12).register(z.globalRegistry, {
          description:
            'Maximum number of words per subtitle segment. Use 1 for single-word display, 2-3 for short phrases, or 8-12 for full sentences.',
        }),
      )
      .default(3),
    background_color: z.optional(
      z
        .enum([
          'black',
          'white',
          'red',
          'green',
          'blue',
          'yellow',
          'orange',
          'purple',
          'pink',
          'brown',
          'gray',
          'cyan',
          'magenta',
          'none',
          'transparent',
        ])
        .register(z.globalRegistry, {
          description:
            "Background color behind text ('none' or 'transparent' for no background)",
        }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Input model for automatic subtitle generation and styling',
  })

/**
 * FlashVSRPlusVideoOutput
 */
export const zSchemaFlashvsrUpscaleVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The random seed used for the generation process.',
  }),
  video: zSchemaFile,
})

/**
 * FlashVSRPlusVideoInput
 *
 * Input fields common to FlashVSR+ image/video endpoints.
 */
export const zSchemaFlashvsrUpscaleVideoInput = z
  .object({
    video_url: z.union([z.string(), z.string()]),
    acceleration: z.optional(
      z.enum(['regular', 'high', 'full']).register(z.globalRegistry, {
        description:
          'Acceleration mode for VAE decoding. Options: regular (best quality), high (balanced), full (fastest). More accerleation means longer duration videos can be processed too.',
      }),
    ),
    quality: z
      .optional(
        z.int().gte(0).lte(100).register(z.globalRegistry, {
          description:
            'Quality level for tile blending (0-100). Controls overlap between tiles to prevent grid artifacts. Higher values provide better quality with more overlap. Recommended: 70-85 for high-res videos, 50-70 for faster processing.',
        }),
      )
      .default(70),
    output_format: z.optional(
      z
        .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
        .register(z.globalRegistry, {
          description: 'The format of the output video.',
        }),
    ),
    color_fix: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Color correction enabled.',
        }),
      )
      .default(true),
    output_write_mode: z.optional(
      z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
        description: 'The write mode of the output video.',
      }),
    ),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'If `True`, the media will be returned inline and not stored in history.',
        }),
      )
      .default(false),
    output_quality: z.optional(
      z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
        description: 'The quality of the output video.',
      }),
    ),
    upscale_factor: z
      .optional(
        z.number().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Upscaling factor to be used.',
        }),
      )
      .default(2),
    preserve_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Copy the original audio tracks into the upscaled video using FFmpeg when possible.',
        }),
      )
      .default(false),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The random seed used for the generation process.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Input fields common to FlashVSR+ image/video endpoints.',
  })

/**
 * EdittoOutput
 */
export const zSchemaEdittoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  frames_zip: z.optional(z.union([zSchemaFile, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * EdittoInput
 */
export const zSchemaEdittoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  video_url: z.union([z.string(), z.string()]),
  acceleration: z.optional(
    z.union([z.enum(['none', 'low', 'regular']), z.unknown()]),
  ),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between the original frames. A value of 0 means no interpolation.',
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.',
      }),
    )
    .default(0),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.',
      }),
    )
    .default(5),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 241 (inclusive).',
      }),
    )
    .default(81),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'Sampler to use for video generation.',
    }),
  ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP file containing all generated frames.',
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.',
      }),
    )
    .default(false),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.',
      }),
    )
    .default(false),
})

/**
 * PointPromptBase
 */
export const zSchemaPointPromptBase = z.object({
  y: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Y Coordinate of the prompt',
    }),
  ),
  x: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'X Coordinate of the prompt',
    }),
  ),
  object_id: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Optional object identifier. Prompts sharing an object id refine the same object.',
    }),
  ),
  label: z.optional(
    z.union([z.literal(0), z.literal(1)]).register(z.globalRegistry, {
      description: '1 for foreground, 0 for background',
    }),
  ),
})

/**
 * BoxPromptBase
 */
export const zSchemaBoxPromptBase = z.object({
  y_min: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Y Min Coordinate of the box',
    }),
  ),
  object_id: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Optional object identifier. Boxes sharing an object id refine the same object.',
    }),
  ),
  x_max: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'X Max Coordinate of the box',
    }),
  ),
  x_min: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'X Min Coordinate of the box',
    }),
  ),
  y_max: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Y Max Coordinate of the box',
    }),
  ),
})

/**
 * SAM3VideoOutput
 */
export const zSchemaSam3VideoOutput = z.object({
  boundingbox_frames_zip: z.optional(zSchemaFile),
  video: zSchemaFile,
})

/**
 * SAM3VideoInput
 */
export const zSchemaSam3VideoInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "Text prompt for segmentation. Use commas to track multiple objects (e.g., 'person, cloth').",
      }),
    )
    .default(''),
  video_url: z.union([z.string(), z.string()]),
  detection_threshold: z
    .optional(
      z.number().gte(0.1).lte(1).register(z.globalRegistry, {
        description:
          'Detection confidence threshold (0.0-1.0). Lower = more detections but less precise. ',
      }),
    )
    .default(0.5),
  box_prompts: z
    .optional(
      z.array(zSchemaBoxPromptBase).register(z.globalRegistry, {
        description:
          'List of box prompt coordinates (x_min, y_min, x_max, y_max).',
      }),
    )
    .default([]),
  point_prompts: z
    .optional(
      z.array(zSchemaPointPromptBase).register(z.globalRegistry, {
        description: 'List of point prompts',
      }),
    )
    .default([]),
  apply_mask: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Apply the mask on the video.',
      }),
    )
    .default(true),
  text_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        "[DEPRECATED] Use 'prompt' instead. Kept for backward compatibility.",
    }),
  ),
})

/**
 * SAM3VideoOutput
 */
export const zSchemaSam3VideoRleOutput = z.object({
  boundingbox_frames_zip: z.optional(zSchemaFile),
  video: zSchemaFile,
})

/**
 * SAM3VideoRLEInput
 */
export const zSchemaSam3VideoRleInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "Text prompt for segmentation. Use commas to track multiple objects (e.g., 'person, cloth').",
      }),
    )
    .default(''),
  video_url: z.union([z.string(), z.string()]),
  detection_threshold: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'Detection confidence threshold (0.0-1.0). Lower = more detections but less precise. Defaults: 0.5 for existing, 0.7 for new objects. Try 0.2-0.3 if text prompts fail.',
      }),
    )
    .default(0.5),
  box_prompts: z
    .optional(
      z.array(zSchemaBoxPrompt).register(z.globalRegistry, {
        description: 'List of box prompts with optional frame_index.',
      }),
    )
    .default([]),
  boundingbox_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Return per-frame bounding box overlays as a zip archive.',
      }),
    )
    .default(false),
  point_prompts: z
    .optional(
      z.array(zSchemaPointPrompt).register(z.globalRegistry, {
        description: 'List of point prompts with frame indices.',
      }),
    )
    .default([]),
  frame_index: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          'Frame index used for initial interaction when mask_url is provided.',
      }),
    )
    .default(0),
  mask_url: z.optional(z.union([z.string(), z.string()])),
  apply_mask: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Apply the mask on the video.',
      }),
    )
    .default(false),
})

/**
 * LucyEditFastOutput
 */
export const zSchemaLucyEditFastOutput = z.object({
  video: zSchemaFile,
})

/**
 * LucyEditFastInput
 */
export const zSchemaLucyEditFastInput = z.object({
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the video to be generated\n            and uploaded before returning the response. This will increase the\n            latency of the function but it allows you to get the video directly\n            in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  video_url: z.union([z.string(), z.string()]),
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text description of the desired video content',
  }),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enhance the prompt for better results.',
      }),
    )
    .default(true),
})

/**
 * LTXRetakeVideoResponse
 */
export const zSchemaLtx2RetakeVideoOutput = z.object({
  video: zSchemaVideoFile,
})

/**
 * LTXRetakeVideoRequest
 */
export const zSchemaLtx2RetakeVideoInput = z.object({
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: 'The prompt to retake the video with',
  }),
  duration: z
    .optional(
      z.number().gte(2).lte(20).register(z.globalRegistry, {
        description: 'The duration of the video to retake in seconds',
      }),
    )
    .default(5),
  video_url: z.union([z.string(), z.string()]),
  start_time: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description: 'The start time of the video to retake in seconds',
      }),
    )
    .default(0),
  retake_mode: z.optional(
    z
      .enum(['replace_audio', 'replace_video', 'replace_audio_and_video'])
      .register(z.globalRegistry, {
        description: 'The retake mode to use for the retake',
      }),
  ),
})

/**
 * GreenScreenRembgOutput
 */
export const zSchemaVideoBackgroundRemovalGreenScreenOutput = z.object({
  video: z.array(zSchemaFile),
})

/**
 * GreenScreenRembgInput
 */
export const zSchemaVideoBackgroundRemovalGreenScreenInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  output_codec: z.optional(
    z.enum(['vp9', 'h264']).register(z.globalRegistry, {
      description:
        'Single VP9 video with alpha channel or two videos (rgb and alpha) in H264 format. H264 is recommended for better RGB quality.',
    }),
  ),
  spill_suppression_strength: z.optional(
    z.union([z.number().gte(0).lte(1), z.unknown()]),
  ),
})

/**
 * OmniV2VReferenceOutput
 */
export const zSchemaKlingVideoO1VideoToVideoReferenceOutput = z.object({
  video: zSchemaFile,
})

/**
 * OmniVideoElementInput
 */
export const zSchemaOmniVideoElementInput = z.object({
  reference_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'Additional reference images from different angles. 1-4 images supported. At least one image is required.',
    }),
  ),
  frontal_image_url: z.union([z.string(), z.string()]),
})

/**
 * OmniV2VReferenceInput
 *
 * Input for video editing or video-as-reference generation.
 */
export const zSchemaKlingVideoO1VideoToVideoReferenceInput = z
  .object({
    prompt: z.string().max(2500).register(z.globalRegistry, {
      description:
        'Use @Element1, @Element2 to reference elements and @Image1, @Image2 to reference images in order.',
    }),
    aspect_ratio: z.optional(
      z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
        description:
          "The aspect ratio of the generated video frame. If 'auto', the aspect ratio will be determined automatically based on the input video, and the closest aspect ratio to the input video will be used.",
      }),
    ),
    duration: z.optional(
      z
        .enum(['3', '4', '5', '6', '7', '8', '9', '10'])
        .register(z.globalRegistry, {
          description: 'Video duration in seconds.',
        }),
    ),
    video_url: z.union([z.string(), z.string()]),
    keep_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to keep the original audio from the video.',
        }),
      )
      .default(false),
    elements: z.optional(
      z.array(zSchemaOmniVideoElementInput).register(z.globalRegistry, {
        description:
          'Elements (characters/objects) to include. Reference in prompt as @Element1, @Element2, etc. Maximum 4 total (elements + reference images) when using video.',
      }),
    ),
    image_urls: z.optional(
      z.array(z.string()).register(z.globalRegistry, {
        description:
          'Reference images for style/appearance. Reference in prompt as @Image1, @Image2, etc. Maximum 4 total (elements + reference images) when using video.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Input for video editing or video-as-reference generation.',
  })

/**
 * OmniV2VEditOutput
 */
export const zSchemaKlingVideoO1VideoToVideoEditOutput = z.object({
  video: zSchemaFile,
})

/**
 * OmniV2VEditInput
 *
 * Input for video editing or video-as-reference generation.
 */
export const zSchemaKlingVideoO1VideoToVideoEditInput = z
  .object({
    prompt: z.string().max(2500).register(z.globalRegistry, {
      description:
        'Use @Element1, @Element2 to reference elements and @Image1, @Image2 to reference images in order.',
    }),
    video_url: z.union([z.string(), z.string()]),
    elements: z.optional(
      z.array(zSchemaOmniVideoElementInput).register(z.globalRegistry, {
        description:
          'Elements (characters/objects) to include. Reference in prompt as @Element1, @Element2, etc. Maximum 4 total (elements + reference images) when using video.',
      }),
    ),
    image_urls: z.optional(
      z.array(z.string()).register(z.globalRegistry, {
        description:
          'Reference images for style/appearance. Reference in prompt as @Image1, @Image2, etc. Maximum 4 total (elements + reference images) when using video.',
      }),
    ),
    keep_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to keep the original audio from the video.',
        }),
      )
      .default(false),
  })
  .register(z.globalRegistry, {
    description: 'Input for video editing or video-as-reference generation.',
  })

/**
 * FastGeneralRembgOutput
 */
export const zSchemaVideoBackgroundRemovalFastOutput = z.object({
  video: z.array(zSchemaFile),
})

/**
 * FastGeneralRembgInput
 */
export const zSchemaVideoBackgroundRemovalFastInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  subject_is_person: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Set to False if the subject is not a person.',
      }),
    )
    .default(true),
  output_codec: z.optional(
    z.enum(['vp9', 'h264']).register(z.globalRegistry, {
      description:
        'Single VP9 video with alpha channel or two videos (rgb and alpha) in H264 format. H264 is recommended for better RGB quality.',
    }),
  ),
  refine_foreground_edges: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Improves the quality of the extracted object's edges.",
      }),
    )
    .default(true),
})

/**
 * React1Output
 */
export const zSchemaSyncLipsyncReact1Output = z.object({
  video: zSchemaVideoFile,
})

/**
 * React1Input
 */
export const zSchemaSyncLipsyncReact1Input = z.object({
  emotion: z
    .enum(['happy', 'angry', 'sad', 'neutral', 'disgusted', 'surprised'])
    .register(z.globalRegistry, {
      description:
        'Emotion prompt for the generation. Currently supports single-word emotions only.',
    }),
  video_url: z.union([z.string(), z.string()]),
  lipsync_mode: z.optional(
    z
      .enum(['cut_off', 'loop', 'bounce', 'silence', 'remap'])
      .register(z.globalRegistry, {
        description:
          'Lipsync mode when audio and video durations are out of sync.',
      }),
  ),
  audio_url: z.union([z.string(), z.string()]),
  temperature: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Controls the expresiveness of the lipsync.',
      }),
    )
    .default(0.5),
  model_mode: z.optional(
    z.enum(['lips', 'face', 'head']).register(z.globalRegistry, {
      description:
        'Controls the edit region and movement scope for the model. Available options:\n- `lips`: Only lipsync using react-1 (minimal facial changes).\n- `face`: Lipsync + facial expressions without head movements.\n- `head`: Lipsync + facial expressions + natural talking head movements.',
    }),
  ),
})

/**
 * Output
 *
 * Output from Wan Vision Enhancer
 */
export const zSchemaWanVisionEnhancerOutput = z
  .object({
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed used for generation.',
    }),
    timings: z.record(z.string(), z.number()).register(z.globalRegistry, {
      description: 'The timings of the different steps in the workflow.',
    }),
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output from Wan Vision Enhancer',
  })

/**
 * Input
 *
 * Input parameters for Wan Vision Enhancer (Video-to-Video)
 */
export const zSchemaWanVisionEnhancerInput = z
  .object({
    prompt: z.optional(z.union([z.string(), z.unknown()])),
    video_url: z.union([z.string(), z.string()]),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    target_resolution: z.optional(
      z.enum(['720p', '1080p']).register(z.globalRegistry, {
        description:
          'Target output resolution for the enhanced video. 720p (native, fast) or 1080p (upscaled, slower). Processing is always done at 720p, then upscaled if 1080p selected.',
      }),
    ),
    negative_prompt: z.optional(z.union([z.string(), z.unknown()])),
    creativity: z
      .optional(
        z.int().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'Controls how much the model enhances/changes the video. 0 = Minimal change (preserves original), 1 = Subtle enhancement (default), 2 = Medium enhancement, 3 = Strong enhancement, 4 = Maximum enhancement.',
        }),
      )
      .default(1),
  })
  .register(z.globalRegistry, {
    description: 'Input parameters for Wan Vision Enhancer (Video-to-Video)',
  })

/**
 * OneToALLAnimationResponse
 */
export const zSchemaOneToAllAnimation14bOutput = z.object({
  video: zSchemaFile,
})

/**
 * OneToALLAnimationRequest
 */
export const zSchemaOneToAllAnimation14bInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'The resolution of the video to generate.',
    }),
  ),
  image_guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'The image guidance scale to use for the video generation.',
      }),
    )
    .default(2),
  pose_guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The pose guidance scale to use for the video generation.',
      }),
    )
    .default(1.5),
  video_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(30).register(z.globalRegistry, {
        description:
          'The number of inference steps to use for the video generation.',
      }),
    )
    .default(30),
  negative_prompt: z.string().register(z.globalRegistry, {
    description: 'The negative prompt to generate the video from.',
  }),
})

/**
 * OneToALLAnimationResponse
 */
export const zSchemaOneToAllAnimation13bOutput = z.object({
  video: zSchemaFile,
})

/**
 * OneToALLAnimationRequest
 */
export const zSchemaOneToAllAnimation13bInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'The resolution of the video to generate.',
    }),
  ),
  image_guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'The image guidance scale to use for the video generation.',
      }),
    )
    .default(2),
  pose_guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The pose guidance scale to use for the video generation.',
      }),
    )
    .default(1.5),
  video_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(30).register(z.globalRegistry, {
        description:
          'The number of inference steps to use for the video generation.',
      }),
    )
    .default(30),
  negative_prompt: z.string().register(z.globalRegistry, {
    description: 'The negative prompt to generate the video from.',
  }),
})

/**
 * SteadyDancerResponse
 *
 * Response model for SteadyDancer.
 */
export const zSchemaSteadyDancerOutput = z
  .object({
    num_frames: z.int().register(z.globalRegistry, {
      description:
        'The actual number of frames generated (aligned to 4k+1 pattern).',
    }),
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed used for generation.',
    }),
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Response model for SteadyDancer.',
  })

/**
 * SteadyDancerRequest
 *
 * Request model for SteadyDancer human animation.
 */
export const zSchemaSteadyDancerInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'Text prompt describing the desired animation.',
        }),
      )
      .default('A person dancing with smooth and natural movements.'),
    video_url: z.optional(z.union([z.string(), z.string()])),
    acceleration: z.optional(
      z.enum(['light', 'moderate', 'aggressive']).register(z.globalRegistry, {
        description: 'Acceleration levels.',
      }),
    ),
    pose_guidance_scale: z
      .optional(
        z.number().gte(0.5).lte(3).register(z.globalRegistry, {
          description: 'Pose guidance scale for pose control strength.',
        }),
      )
      .default(1),
    shift: z
      .optional(
        z.number().gte(1).lte(10).register(z.globalRegistry, {
          description: 'Shift parameter for video generation.',
        }),
      )
      .default(5),
    pose_guidance_end: z
      .optional(
        z.number().gte(0.2).lte(1).register(z.globalRegistry, {
          description:
            'End ratio for pose guidance. Controls when pose guidance ends.',
        }),
      )
      .default(0.4),
    frames_per_second: z.optional(
      z.int().gte(5).lte(24).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 5 to 24. If not specified, uses the FPS from the input video.',
      }),
    ),
    guidance_scale: z
      .optional(
        z.number().gte(1).lte(6).register(z.globalRegistry, {
          description: 'Classifier-free guidance scale for prompt adherence.',
        }),
      )
      .default(1),
    num_frames: z.optional(
      z.int().gte(5).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. If not specified, uses the frame count from the input video (capped at 241). Will be adjusted to nearest valid value (must satisfy 4k+1 pattern).',
      }),
    ),
    use_turbo: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'If true, applies quality enhancement for faster generation with improved quality. When enabled, parameters are automatically optimized (num_inference_steps=6, guidance_scale=1.0) and uses the LightX2V distillation LoRA.',
        }),
      )
      .default(false),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'Negative prompt for video generation.',
        }),
      )
      .default(
        'blurred, distorted face, bad anatomy, extra limbs, poorly drawn hands, poorly drawn feet, disfigured, out of frame, duplicate, watermark, signature, text',
      ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'If set to true, the safety checker will be enabled.',
        }),
      )
      .default(false),
    aspect_ratio: z.optional(
      z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
        description:
          "Aspect ratio of the generated video. If 'auto', will be determined from the reference image.",
      }),
    ),
    pose_guidance_start: z
      .optional(
        z.number().gte(0).lte(0.5).register(z.globalRegistry, {
          description:
            'Start ratio for pose guidance. Controls when pose guidance begins.',
        }),
      )
      .default(0.1),
    resolution: z.optional(
      z.enum(['480p', '576p', '720p']).register(z.globalRegistry, {
        description:
          'Resolution of the generated video. 576p is default, 720p for higher quality. 480p is lower quality.',
      }),
    ),
    image_url: z.optional(z.union([z.string(), z.string()])),
    preserve_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'If enabled, copies audio from the input driving video to the output video.',
        }),
      )
      .default(true),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    ),
    num_inference_steps: z
      .optional(
        z.int().gte(4).lte(50).register(z.globalRegistry, {
          description:
            'Number of inference steps for sampling. Higher values give better quality but take longer.',
        }),
      )
      .default(6),
  })
  .register(z.globalRegistry, {
    description: 'Request model for SteadyDancer human animation.',
  })

/**
 * OmniV2VEditOutput
 */
export const zSchemaKlingVideoO1StandardVideoToVideoEditOutput = z.object({
  video: zSchemaFile,
})

/**
 * OmniV2VEditInput
 *
 * Input for video editing or video-as-reference generation.
 */
export const zSchemaKlingVideoO1StandardVideoToVideoEditInput = z
  .object({
    prompt: z.string().max(2500).register(z.globalRegistry, {
      description:
        'Use @Element1, @Element2 to reference elements and @Image1, @Image2 to reference images in order.',
    }),
    video_url: z.union([z.string(), z.string()]),
    elements: z.optional(
      z.array(zSchemaOmniVideoElementInput).register(z.globalRegistry, {
        description:
          'Elements (characters/objects) to include. Reference in prompt as @Element1, @Element2, etc. Maximum 4 total (elements + reference images) when using video.',
      }),
    ),
    image_urls: z.optional(
      z.array(z.string()).register(z.globalRegistry, {
        description:
          'Reference images for style/appearance. Reference in prompt as @Image1, @Image2, etc. Maximum 4 total (elements + reference images) when using video.',
      }),
    ),
    keep_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to keep the original audio from the video.',
        }),
      )
      .default(false),
  })
  .register(z.globalRegistry, {
    description: 'Input for video editing or video-as-reference generation.',
  })

/**
 * OmniV2VReferenceOutput
 */
export const zSchemaKlingVideoO1StandardVideoToVideoReferenceOutput = z.object({
  video: zSchemaFile,
})

/**
 * OmniV2VReferenceInput
 *
 * Input for video editing or video-as-reference generation.
 */
export const zSchemaKlingVideoO1StandardVideoToVideoReferenceInput = z
  .object({
    prompt: z.string().max(2500).register(z.globalRegistry, {
      description:
        'Use @Element1, @Element2 to reference elements and @Image1, @Image2 to reference images in order.',
    }),
    aspect_ratio: z.optional(
      z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
        description:
          "The aspect ratio of the generated video frame. If 'auto', the aspect ratio will be determined automatically based on the input video, and the closest aspect ratio to the input video will be used.",
      }),
    ),
    duration: z.optional(
      z
        .enum(['3', '4', '5', '6', '7', '8', '9', '10'])
        .register(z.globalRegistry, {
          description: 'Video duration in seconds.',
        }),
    ),
    video_url: z.union([z.string(), z.string()]),
    keep_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to keep the original audio from the video.',
        }),
      )
      .default(false),
    elements: z.optional(
      z.array(zSchemaOmniVideoElementInput).register(z.globalRegistry, {
        description:
          'Elements (characters/objects) to include. Reference in prompt as @Element1, @Element2, etc. Maximum 4 total (elements + reference images) when using video.',
      }),
    ),
    image_urls: z.optional(
      z.array(z.string()).register(z.globalRegistry, {
        description:
          'Reference images for style/appearance. Reference in prompt as @Image1, @Image2, etc. Maximum 4 total (elements + reference images) when using video.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Input for video editing or video-as-reference generation.',
  })

/**
 * Veo31VideoToVideoOutput
 */
export const zSchemaVeo31ExtendVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Veo31VideoToVideoInput
 *
 * Input for video extension/video-to-video generation.
 */
export const zSchemaVeo31ExtendVideoInput = z
  .object({
    prompt: z.string().max(20000).register(z.globalRegistry, {
      description:
        'The text prompt describing how the video should be extended',
    }),
    duration: z.optional(
      z.enum(['7s']).register(z.globalRegistry, {
        description: 'The duration of the generated video.',
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(['auto', '16:9', '9:16']).register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video.',
      }),
    ),
    generate_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to generate audio for the video.',
        }),
      )
      .default(true),
    auto_fix: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.',
        }),
      )
      .default(false),
    video_url: z.union([z.string(), z.string()]),
    resolution: z.optional(
      z.enum(['720p']).register(z.globalRegistry, {
        description: 'The resolution of the generated video.',
      }),
    ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the random number generator.',
      }),
    ),
    negative_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'A negative prompt to guide the video generation.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Input for video extension/video-to-video generation.',
  })

/**
 * Veo31VideoToVideoOutput
 */
export const zSchemaVeo31FastExtendVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Veo31VideoToVideoInput
 *
 * Input for video extension/video-to-video generation.
 */
export const zSchemaVeo31FastExtendVideoInput = z
  .object({
    prompt: z.string().max(20000).register(z.globalRegistry, {
      description:
        'The text prompt describing how the video should be extended',
    }),
    duration: z.optional(
      z.enum(['7s']).register(z.globalRegistry, {
        description: 'The duration of the generated video.',
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(['auto', '16:9', '9:16']).register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video.',
      }),
    ),
    generate_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to generate audio for the video.',
        }),
      )
      .default(true),
    auto_fix: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.',
        }),
      )
      .default(false),
    video_url: z.union([z.string(), z.string()]),
    resolution: z.optional(
      z.enum(['720p']).register(z.globalRegistry, {
        description: 'The resolution of the generated video.',
      }),
    ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the random number generator.',
      }),
    ),
    negative_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'A negative prompt to guide the video generation.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Input for video extension/video-to-video generation.',
  })

/**
 * ReferenceToVideoOutput
 *
 * Output for reference-to-video generation
 */
export const zSchemaV26ReferenceToVideoOutput = z
  .object({
    actual_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The actual prompt used if prompt rewriting was enabled',
      }),
    ),
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed used for generation',
    }),
    video: zSchemaVideoFile,
  })
  .register(z.globalRegistry, {
    description: 'Output for reference-to-video generation',
  })

/**
 * ReferenceToVideoInput
 *
 * Input for Wan 2.6 reference-to-video generation (R2V)
 */
export const zSchemaV26ReferenceToVideoInput = z
  .object({
    prompt: z.string().min(1).register(z.globalRegistry, {
      description:
        "Use @Video1, @Video2, @Video3 to reference subjects from your videos. Works for people, animals, or objects. For multi-shot prompts: '[0-3s] Shot 1. [3-6s] Shot 2.' Max 800 characters.",
    }),
    resolution: z.optional(
      z.enum(['720p', '1080p']).register(z.globalRegistry, {
        description:
          'Video resolution tier. R2V only supports 720p and 1080p (no 480p).',
      }),
    ),
    video_urls: z.array(z.string()).register(z.globalRegistry, {
      description:
        "Reference videos for subject consistency (1-3 videos). Videos' FPS must be at least 16 FPS.Reference in prompt as @Video1, @Video2, @Video3. Works for people, animals, or objects.",
    }),
    aspect_ratio: z.optional(
      z.enum(['16:9', '9:16', '1:1', '4:3', '3:4']).register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video.',
      }),
    ),
    duration: z.optional(
      z.enum(['5', '10']).register(z.globalRegistry, {
        description:
          'Duration of the generated video in seconds. R2V supports only 5 or 10 seconds (no 15s).',
      }),
    ),
    enable_prompt_expansion: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable prompt rewriting using LLM.',
        }),
      )
      .default(true),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    ),
    multi_shots: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'When true (default), enables intelligent multi-shot segmentation for coherent narrative videos with multiple shots. When false, generates single continuous shot. Only active when enable_prompt_expansion is True.',
        }),
      )
      .default(true),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            'Negative prompt to describe content to avoid. Max 500 characters.',
        }),
      )
      .default(''),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'If set to true, the safety checker will be enabled.',
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description: 'Input for Wan 2.6 reference-to-video generation (R2V)',
  })

/**
 * VideoOutput
 */
export const zSchemaBriaVideoEraserErasePromptOutput = z.object({
  video: z.union([zSchemaVideo, zSchemaFile]),
})

/**
 * EraseByPromptInputModel
 */
export const zSchemaBriaVideoEraserErasePromptInput = z.object({
  preserve_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If true, audio will be preserved in the output video.',
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  prompt: z.string().register(z.globalRegistry, {
    description: 'Input prompt to detect object to erase',
  }),
  output_container_and_codec: z.optional(
    z
      .enum([
        'mp4_h265',
        'mp4_h264',
        'webm_vp9',
        'gif',
        'mov_h264',
        'mov_h265',
        'mov_proresks',
        'mkv_h264',
        'mkv_h265',
        'mkv_vp9',
        'mkv_mpeg4',
      ])
      .register(z.globalRegistry, {
        description:
          'Output container and codec. Options: mp4_h265, mp4_h264, webm_vp9, gif, mov_h264, mov_h265, mov_proresks, mkv_h264, mkv_h265, mkv_vp9, mkv_mpeg4.',
      }),
  ),
  auto_trim: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'auto trim the video, to working duration ( 5s )',
      }),
    )
    .default(true),
})

/**
 * VideoOutput
 */
export const zSchemaBriaVideoEraserEraseKeypointsOutput = z.object({
  video: z.union([zSchemaVideo, zSchemaFile]),
})

/**
 * EraseByKeyPointsInputModel
 */
export const zSchemaBriaVideoEraserEraseKeypointsInput = z.object({
  preserve_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If true, audio will be preserved in the output video.',
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  output_container_and_codec: z.optional(
    z
      .enum([
        'mp4_h265',
        'mp4_h264',
        'webm_vp9',
        'gif',
        'mov_h264',
        'mov_h265',
        'mov_proresks',
        'mkv_h264',
        'mkv_h265',
        'mkv_vp9',
        'mkv_mpeg4',
      ])
      .register(z.globalRegistry, {
        description:
          'Output container and codec. Options: mp4_h265, mp4_h264, webm_vp9, gif, mov_h264, mov_h265, mov_proresks, mkv_h264, mkv_h265, mkv_vp9, mkv_mpeg4.',
      }),
  ),
  keypoints: z.array(z.string()).register(z.globalRegistry, {
    description:
      "Input keypoints [x,y] to erase or keep from the video. Format like so: {'x':100, 'y':100, 'type':'positive/negative'}",
  }),
  auto_trim: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'auto trim the video, to working duration ( 5s )',
      }),
    )
    .default(true),
})

/**
 * VideoOutput
 */
export const zSchemaBriaVideoEraserEraseMaskOutput = z.object({
  video: z.union([zSchemaVideo, zSchemaFile]),
})

/**
 * EraseInputModel
 */
export const zSchemaBriaVideoEraserEraseMaskInput = z.object({
  preserve_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If true, audio will be preserved in the output video.',
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  output_container_and_codec: z.optional(
    z
      .enum([
        'mp4_h265',
        'mp4_h264',
        'webm_vp9',
        'gif',
        'mov_h264',
        'mov_h265',
        'mov_proresks',
        'mkv_h264',
        'mkv_h265',
        'mkv_vp9',
        'mkv_mpeg4',
      ])
      .register(z.globalRegistry, {
        description:
          'Output container and codec. Options: mp4_h265, mp4_h264, webm_vp9, gif, mov_h264, mov_h265, mov_proresks, mkv_h264, mkv_h265, mkv_vp9, mkv_mpeg4.',
      }),
  ),
  mask_video_url: z.union([z.string(), z.string()]),
  auto_trim: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'auto trim the video, to working duration ( 5s )',
      }),
    )
    .default(true),
})

/**
 * CrystalVideoUpscaleOutput
 */
export const zSchemaCrystalVideoUpscalerOutput = z.object({
  video: zSchemaVideoFile,
})

/**
 * CrystalVideoUpscaleInput
 */
export const zSchemaCrystalVideoUpscalerInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  scale_factor: z
    .optional(
      z.number().gte(1).lte(200).register(z.globalRegistry, {
        description:
          'Scale factor. The scale factor must be chosen such that the upscaled video does not exceed 5K resolution.',
      }),
    )
    .default(2),
})

/**
 * ScailResponse
 */
export const zSchemaScailOutput = z.object({
  video: zSchemaFile,
})

/**
 * ScailRequest
 */
export const zSchemaScailInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to guide video generation.',
  }),
  video_url: z.union([z.string(), z.string()]),
  resolution: z.optional(
    z.enum(['512p']).register(z.globalRegistry, {
      description:
        'Output resolution. Outputs 896x512 (landscape) or 512x896 (portrait) based on the input image aspect ratio.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(30).register(z.globalRegistry, {
        description:
          'The number of inference steps to use for the video generation.',
      }),
    )
    .default(28),
  multi_character: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Enable multi-character mode. Use when driving video has multiple people.',
      }),
    )
    .default(false),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * LucyRestyleOutput
 */
export const zSchemaLucyRestyleOutput = z.object({
  video: zSchemaFile,
})

/**
 * LucyRestyleInput
 */
export const zSchemaLucyRestyleInput = z.object({
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the video to be generated\n            and uploaded before returning the response. This will increase the\n            latency of the function but it allows you to get the video directly\n            in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  video_url: z.union([z.string(), z.string()]),
  resolution: z.optional(
    z.enum(['720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video',
    }),
  ),
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text description of the desired video content',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Seed for video generation',
    }),
  ),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enhance the prompt for better results.',
      }),
    )
    .default(true),
})

/**
 * MotionControlOutput
 *
 * Output model for motion control video generation.
 */
export const zSchemaKlingVideoV26ProMotionControlOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output model for motion control video generation.',
  })

/**
 * MotionControlRequest
 *
 * Request model for motion control video generation.
 */
export const zSchemaKlingVideoV26ProMotionControlInput = z
  .object({
    prompt: z.optional(z.string().max(2500)),
    video_url: z.union([z.string(), z.string()]),
    character_orientation: z
      .enum(['image', 'video'])
      .register(z.globalRegistry, {
        description:
          "Controls whether the output character's orientation matches the reference image or video. 'video': orientation matches reference video - better for complex motions (max 30s). 'image': orientation matches reference image - better for following camera movements (max 10s).",
      }),
    keep_original_sound: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to keep the original sound from the reference video.',
        }),
      )
      .default(true),
    image_url: z.union([z.string(), z.string()]),
  })
  .register(z.globalRegistry, {
    description: 'Request model for motion control video generation.',
  })

/**
 * MotionControlOutput
 *
 * Output model for motion control video generation.
 */
export const zSchemaKlingVideoV26StandardMotionControlOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output model for motion control video generation.',
  })

/**
 * MotionControlRequest
 *
 * Request model for motion control video generation.
 */
export const zSchemaKlingVideoV26StandardMotionControlInput = z
  .object({
    prompt: z.optional(z.string().max(2500)),
    video_url: z.union([z.string(), z.string()]),
    character_orientation: z
      .enum(['image', 'video'])
      .register(z.globalRegistry, {
        description:
          "Controls whether the output character's orientation matches the reference image or video. 'video': orientation matches reference video - better for complex motions (max 30s). 'image': orientation matches reference image - better for following camera movements (max 10s).",
      }),
    keep_original_sound: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to keep the original sound from the reference video.',
        }),
      )
      .default(true),
    image_url: z.union([z.string(), z.string()]),
  })
  .register(z.globalRegistry, {
    description: 'Request model for motion control video generation.',
  })

/**
 * TrajectoryParameters
 *
 * Camera trajectory parameters for re-camera operations.
 *
 * Each list represents interpolation values across frames:
 * - theta: Horizontal rotation angles (degrees)
 * - phi: Vertical rotation angles (degrees)
 * - radius: Camera distance scaling factors
 */
export const zSchemaTrajectoryParameters = z
  .object({
    theta: z.array(z.number()).register(z.globalRegistry, {
      description: 'Horizontal rotation angles (degrees) for each keyframe.',
    }),
    radius: z.array(z.number()).register(z.globalRegistry, {
      description: 'Camera distance scaling factors for each keyframe.',
    }),
    phi: z.array(z.number()).register(z.globalRegistry, {
      description: 'Vertical rotation angles (degrees) for each keyframe.',
    }),
  })
  .register(z.globalRegistry, {
    description:
      'Camera trajectory parameters for re-camera operations.\n\nEach list represents interpolation values across frames:\n- theta: Horizontal rotation angles (degrees)\n- phi: Vertical rotation angles (degrees)\n- radius: Camera distance scaling factors',
  })

/**
 * LightXOutput
 */
export const zSchemaLightxRecameraOutput = z.object({
  viz_video: z.optional(zSchemaFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  input_video: z.optional(zSchemaFile),
  video: zSchemaFile,
})

/**
 * LightXRecameraRequest
 *
 * Re-camera-only request (minimal schema).
 */
export const zSchemaLightxRecameraInput = z
  .object({
    prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'Optional text prompt. If omitted, Light-X will auto-caption the video.',
      }),
    ),
    trajectory: z.optional(zSchemaTrajectoryParameters),
    video_url: z.union([z.string(), z.string()]),
    camera: z.optional(
      z.enum(['traj', 'target']).register(z.globalRegistry, {
        description: 'Camera control mode.',
      }),
    ),
    target_pose: z.optional(
      z.array(z.number()).register(z.globalRegistry, {
        description:
          "Target camera pose [theta, phi, radius, x, y] (required when camera='target').",
      }),
    ),
    mode: z.optional(
      z
        .enum(['gradual', 'bullet', 'direct', 'dolly-zoom'])
        .register(z.globalRegistry, {
          description: 'Camera motion mode.',
        }),
    ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Re-camera-only request (minimal schema).',
  })

/**
 * RelightParameters
 *
 * Relighting parameters for video relighting operations.
 *
 * Used with relight_condition_type 'ic' (intrinsic conditioning).
 */
export const zSchemaRelightParameters = z
  .object({
    relight_prompt: z.string().register(z.globalRegistry, {
      description: 'Text prompt describing the desired lighting condition.',
    }),
    bg_source: z.optional(
      z.enum(['Left', 'Right', 'Top', 'Bottom']).register(z.globalRegistry, {
        description: 'Direction of the light source (used for IC-light).',
      }),
    ),
    use_sky_mask: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to use sky masking for outdoor scenes.',
        }),
      )
      .default(false),
    cfg: z
      .optional(
        z.number().gte(1).lte(10).register(z.globalRegistry, {
          description: 'Classifier-free guidance scale for relighting.',
        }),
      )
      .default(2),
  })
  .register(z.globalRegistry, {
    description:
      "Relighting parameters for video relighting operations.\n\nUsed with relight_condition_type 'ic' (intrinsic conditioning).",
  })

/**
 * LightXOutput
 */
export const zSchemaLightxRelightOutput = z.object({
  viz_video: z.optional(zSchemaFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  input_video: z.optional(zSchemaFile),
  video: zSchemaFile,
})

/**
 * LightXRelightRequest
 *
 * Relighting-only request (minimal schema).
 */
export const zSchemaLightxRelightInput = z
  .object({
    prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'Optional text prompt. If omitted, Light-X will auto-caption the video.',
      }),
    ),
    video_url: z.union([z.string(), z.string()]),
    relight_parameters: z.optional(zSchemaRelightParameters),
    ref_id: z
      .optional(
        z.int().gte(0).register(z.globalRegistry, {
          description:
            'Frame index to use as referencen to relight the video with reference.',
        }),
      )
      .default(0),
    relit_cond_img_url: z.optional(z.union([z.string(), z.string()])),
    relit_cond_type: z.optional(
      z.enum(['ic', 'ref', 'hdr', 'bg']).register(z.globalRegistry, {
        description: 'Relight condition type.',
      }),
    ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Relighting-only request (minimal schema).',
  })

/**
 * VideoOutput
 */
export const zSchemaVideoEraseMaskOutput = z.object({
  video: z.union([zSchemaVideo, zSchemaFile]),
})

/**
 * EraseInputModel
 */
export const zSchemaVideoEraseMaskInput = z.object({
  preserve_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If true, audio will be preserved in the output video.',
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  output_container_and_codec: z.optional(
    z
      .enum([
        'mp4_h265',
        'mp4_h264',
        'webm_vp9',
        'gif',
        'mov_h264',
        'mov_h265',
        'mov_proresks',
        'mkv_h264',
        'mkv_h265',
        'mkv_vp9',
        'mkv_mpeg4',
      ])
      .register(z.globalRegistry, {
        description:
          'Output container and codec. Options: mp4_h265, mp4_h264, webm_vp9, gif, mov_h264, mov_h265, mov_proresks, mkv_h264, mkv_h265, mkv_vp9, mkv_mpeg4.',
      }),
  ),
  mask_video_url: z.union([z.string(), z.string()]),
  auto_trim: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'auto trim the video, to working duration ( 5s )',
      }),
    )
    .default(true),
})

/**
 * VideoOutput
 */
export const zSchemaVideoErasePromptOutput = z.object({
  video: z.union([zSchemaVideo, zSchemaFile]),
})

/**
 * EraseByPromptInputModel
 */
export const zSchemaVideoErasePromptInput = z.object({
  preserve_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If true, audio will be preserved in the output video.',
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  prompt: z.string().register(z.globalRegistry, {
    description: 'Input prompt to detect object to erase',
  }),
  output_container_and_codec: z.optional(
    z
      .enum([
        'mp4_h265',
        'mp4_h264',
        'webm_vp9',
        'gif',
        'mov_h264',
        'mov_h265',
        'mov_proresks',
        'mkv_h264',
        'mkv_h265',
        'mkv_vp9',
        'mkv_mpeg4',
      ])
      .register(z.globalRegistry, {
        description:
          'Output container and codec. Options: mp4_h265, mp4_h264, webm_vp9, gif, mov_h264, mov_h265, mov_proresks, mkv_h264, mkv_h265, mkv_vp9, mkv_mpeg4.',
      }),
  ),
  auto_trim: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'auto trim the video, to working duration ( 5s )',
      }),
    )
    .default(true),
})

/**
 * VideoOutput
 */
export const zSchemaVideoEraseKeypointsOutput = z.object({
  video: z.union([zSchemaVideo, zSchemaFile]),
})

/**
 * EraseByKeyPointsInputModel
 */
export const zSchemaVideoEraseKeypointsInput = z.object({
  preserve_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If true, audio will be preserved in the output video.',
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  output_container_and_codec: z.optional(
    z
      .enum([
        'mp4_h265',
        'mp4_h264',
        'webm_vp9',
        'gif',
        'mov_h264',
        'mov_h265',
        'mov_proresks',
        'mkv_h264',
        'mkv_h265',
        'mkv_vp9',
        'mkv_mpeg4',
      ])
      .register(z.globalRegistry, {
        description:
          'Output container and codec. Options: mp4_h265, mp4_h264, webm_vp9, gif, mov_h264, mov_h265, mov_proresks, mkv_h264, mkv_h265, mkv_vp9, mkv_mpeg4.',
      }),
  ),
  keypoints: z.array(z.string()).register(z.globalRegistry, {
    description:
      "Input keypoints [x,y] to erase or keep from the video. Format like so: {'x':100, 'y':100, 'type':'positive/negative'}",
  }),
  auto_trim: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'auto trim the video, to working duration ( 5s )',
      }),
    )
    .default(true),
})

/**
 * LTX2ExtendVideoOutput
 */
export const zSchemaLtx219bExtendVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2ExtendVideoInput
 *
 * extend_direction: ExtendDirection = Field(
 * description="Direction to extend the video. 'forward' extends from the end of the video, 'backward' extends from the beginning.",
 * default="forward",
 * ui={"important": True},
 * title="Extend Direction",
 * )
 */
export const zSchemaLtx219bExtendVideoInput = z
  .object({
    use_multiscale: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
        }),
      )
      .default(true),
    video_url: z.union([z.string(), z.string()]),
    acceleration: z.optional(
      z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
        description: 'The acceleration level to use.',
      }),
    ),
    generate_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to generate audio for the video.',
        }),
      )
      .default(true),
    prompt: z.string().register(z.globalRegistry, {
      description: 'The prompt to generate the video from.',
    }),
    fps: z
      .optional(
        z.number().gte(1).lte(60).register(z.globalRegistry, {
          description: 'The frames per second of the generated video.',
        }),
      )
      .default(25),
    camera_lora: z.optional(
      z
        .enum([
          'dolly_in',
          'dolly_out',
          'dolly_left',
          'dolly_right',
          'jib_up',
          'jib_down',
          'static',
          'none',
        ])
        .register(z.globalRegistry, {
          description:
            'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
        }),
    ),
    video_size: z.optional(
      z.union([
        zSchemaImageSize,
        z.enum([
          'auto',
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
      ]),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable the safety checker.',
        }),
      )
      .default(true),
    camera_lora_scale: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
        }),
      )
      .default(1),
    guidance_scale: z
      .optional(
        z.number().gte(1).lte(10).register(z.globalRegistry, {
          description: 'The guidance scale to use.',
        }),
      )
      .default(3),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt to generate the video from.',
        }),
      )
      .default(
        'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
      ),
    num_frames: z
      .optional(
        z.int().gte(9).lte(481).register(z.globalRegistry, {
          description: 'The number of frames to generate.',
        }),
      )
      .default(121),
    video_strength: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            'Video conditioning strength. Lower values represent more freedom given to the model to change the video content.',
        }),
      )
      .default(1),
    video_output_type: z.optional(
      z
        .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
        .register(z.globalRegistry, {
          description: 'The output type of the generated video.',
        }),
    ),
    video_write_mode: z.optional(
      z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
        description: 'The write mode of the generated video.',
      }),
    ),
    num_context_frames: z
      .optional(
        z.int().gte(0).lte(121).register(z.globalRegistry, {
          description:
            'The number of frames to use as context for the extension.',
        }),
      )
      .default(25),
    video_quality: z.optional(
      z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
        description: 'The quality of the generated video.',
      }),
    ),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        }),
      )
      .default(false),
    enable_prompt_expansion: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable prompt expansion.',
        }),
      )
      .default(false),
    num_inference_steps: z
      .optional(
        z.int().gte(8).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to use.',
        }),
      )
      .default(40),
    audio_strength: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            'Audio conditioning strength. Lower values represent more freedom given to the model to change the audio content.',
        }),
      )
      .default(1),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    match_input_fps: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "When true, match the output FPS to the input video's FPS instead of using the default target FPS.",
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description:
      'extend_direction: ExtendDirection = Field(\n    description="Direction to extend the video. \'forward\' extends from the end of the video, \'backward\' extends from the beginning.",\n    default="forward",\n    ui={"important": True},\n    title="Extend Direction",\n)',
  })

/**
 * LTX2ExtendVideoOutput
 */
export const zSchemaLtx219bExtendVideoLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export const zSchemaLoRaInput = z
  .object({
    path: z.string().register(z.globalRegistry, {
      description: 'URL, HuggingFace repo ID (owner/repo) to lora weights.',
    }),
    scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description: 'Scale factor for LoRA application (0.0 to 4.0).',
        }),
      )
      .default(1),
    weight_name: z.optional(z.union([z.string(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'LoRA weight configuration.',
  })

/**
 * LTX2LoRAExtendVideoInput
 */
export const zSchemaLtx219bExtendVideoLoraInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  loras: z.array(zSchemaLoRaInput).register(z.globalRegistry, {
    description: 'The LoRAs to use for the generation.',
  }),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use.',
      }),
    )
    .default(3),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  video_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Video conditioning strength. Lower values represent more freedom given to the model to change the video content.',
      }),
    )
    .default(1),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  num_context_frames: z
    .optional(
      z.int().gte(0).lte(121).register(z.globalRegistry, {
        description:
          'The number of frames to use as context for the extension.',
      }),
    )
    .default(25),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to use.',
      }),
    )
    .default(40),
  audio_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Audio conditioning strength. Lower values represent more freedom given to the model to change the audio content.',
      }),
    )
    .default(1),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  match_input_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When true, match the output FPS to the input video's FPS instead of using the default target FPS.",
      }),
    )
    .default(true),
})

/**
 * LTX2ExtendVideoOutput
 */
export const zSchemaLtx219bDistilledExtendVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2DistilledExtendVideoInput
 */
export const zSchemaLtx219bDistilledExtendVideoInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  video_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Video conditioning strength. Lower values represent more freedom given to the model to change the video content.',
      }),
    )
    .default(1),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  num_context_frames: z
    .optional(
      z.int().gte(0).lte(121).register(z.globalRegistry, {
        description:
          'The number of frames to use as context for the extension.',
      }),
    )
    .default(25),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  audio_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Audio conditioning strength. Lower values represent more freedom given to the model to change the audio content.',
      }),
    )
    .default(1),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  match_input_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When true, match the output FPS to the input video's FPS instead of using the default target FPS.",
      }),
    )
    .default(true),
})

/**
 * LTX2ExtendVideoOutput
 */
export const zSchemaLtx219bDistilledExtendVideoLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2LoRADistilledExtendVideoInput
 */
export const zSchemaLtx219bDistilledExtendVideoLoraInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  loras: z.array(zSchemaLoRaInput).register(z.globalRegistry, {
    description: 'The LoRAs to use for the generation.',
  }),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  video_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Video conditioning strength. Lower values represent more freedom given to the model to change the video content.',
      }),
    )
    .default(1),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  num_context_frames: z
    .optional(
      z.int().gte(0).lte(121).register(z.globalRegistry, {
        description:
          'The number of frames to use as context for the extension.',
      }),
    )
    .default(25),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  audio_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Audio conditioning strength. Lower values represent more freedom given to the model to change the audio content.',
      }),
    )
    .default(1),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  match_input_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When true, match the output FPS to the input video's FPS instead of using the default target FPS.",
      }),
    )
    .default(true),
})

/**
 * LTX2VideoToVideoOutput
 */
export const zSchemaLtx219bVideoToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2VideoToVideoInput
 */
export const zSchemaLtx219bVideoToVideoInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  ic_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the IC-LoRA to use. This allows you to control the strength of the IC-LoRA.',
      }),
    )
    .default(1),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use.',
      }),
    )
    .default(3),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  video_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Video conditioning strength. Lower values represent more freedom given to the model to change the video content.',
      }),
    )
    .default(1),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  image_url: z.optional(z.union([z.string(), z.unknown()])),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  match_video_length: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'When enabled, the number of frames will be calculated based on the video duration and FPS. When disabled, use the specified num_frames.',
      }),
    )
    .default(true),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the image to use for the video generation.',
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  preprocessor: z.optional(
    z.enum(['depth', 'canny', 'pose', 'none']).register(z.globalRegistry, {
      description:
        'The preprocessor to use for the video. When a preprocessor is used and `ic_lora_type` is set to `match_preprocessor`, the IC-LoRA will be loaded based on the preprocessor type.',
    }),
  ),
  ic_lora: z.optional(
    z
      .enum([
        'match_preprocessor',
        'canny',
        'depth',
        'pose',
        'detailer',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The type of IC-LoRA to load. In-Context LoRA weights are used to condition the video based on edge, depth, or pose videos. Only change this from `match_preprocessor` if your videos are already preprocessed (or you are using the detailer.)',
      }),
  ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to use.',
      }),
    )
    .default(40),
  match_input_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When true, match the output FPS to the input video's FPS instead of using the default target FPS.",
      }),
    )
    .default(true),
})

/**
 * LTX2VideoToVideoOutput
 */
export const zSchemaLtx219bVideoToVideoLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2LoRAVideoToVideoInput
 */
export const zSchemaLtx219bVideoToVideoLoraInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  ic_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the IC-LoRA to use. This allows you to control the strength of the IC-LoRA.',
      }),
    )
    .default(1),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  loras: z.array(zSchemaLoRaInput).register(z.globalRegistry, {
    description: 'The LoRAs to use for the generation.',
  }),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use.',
      }),
    )
    .default(3),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  video_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Video conditioning strength. Lower values represent more freedom given to the model to change the video content.',
      }),
    )
    .default(1),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  image_url: z.optional(z.union([z.string(), z.unknown()])),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  match_video_length: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'When enabled, the number of frames will be calculated based on the video duration and FPS. When disabled, use the specified num_frames.',
      }),
    )
    .default(true),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the image to use for the video generation.',
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  preprocessor: z.optional(
    z.enum(['depth', 'canny', 'pose', 'none']).register(z.globalRegistry, {
      description:
        'The preprocessor to use for the video. When a preprocessor is used and `ic_lora_type` is set to `match_preprocessor`, the IC-LoRA will be loaded based on the preprocessor type.',
    }),
  ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  ic_lora: z.optional(
    z
      .enum([
        'match_preprocessor',
        'canny',
        'depth',
        'pose',
        'detailer',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The type of IC-LoRA to load. In-Context LoRA weights are used to condition the video based on edge, depth, or pose videos. Only change this from `match_preprocessor` if your videos are already preprocessed (or you are using the detailer.)',
      }),
  ),
  match_input_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When true, match the output FPS to the input video's FPS instead of using the default target FPS.",
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to use.',
      }),
    )
    .default(40),
})

/**
 * LTX2VideoToVideoOutput
 */
export const zSchemaLtx219bDistilledVideoToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2DistilledVideoToVideoInput
 */
export const zSchemaLtx219bDistilledVideoToVideoInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  ic_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the IC-LoRA to use. This allows you to control the strength of the IC-LoRA.',
      }),
    )
    .default(1),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the image to use for the video generation.',
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  preprocessor: z.optional(
    z.enum(['depth', 'canny', 'pose', 'none']).register(z.globalRegistry, {
      description:
        'The preprocessor to use for the video. When a preprocessor is used and `ic_lora_type` is set to `match_preprocessor`, the IC-LoRA will be loaded based on the preprocessor type.',
    }),
  ),
  video_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Video conditioning strength. Lower values represent more freedom given to the model to change the video content.',
      }),
    )
    .default(1),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  ic_lora: z.optional(
    z
      .enum([
        'match_preprocessor',
        'canny',
        'depth',
        'pose',
        'detailer',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The type of IC-LoRA to load. In-Context LoRA weights are used to condition the video based on edge, depth, or pose videos. Only change this from `match_preprocessor` if your videos are already preprocessed (or you are using the detailer.)',
      }),
  ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  image_url: z.optional(z.union([z.string(), z.unknown()])),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  match_input_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When true, match the output FPS to the input video's FPS instead of using the default target FPS.",
      }),
    )
    .default(true),
  match_video_length: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'When enabled, the number of frames will be calculated based on the video duration and FPS. When disabled, use the specified num_frames.',
      }),
    )
    .default(true),
})

/**
 * LTX2VideoToVideoOutput
 */
export const zSchemaLtx219bDistilledVideoToVideoLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2LoRADistilledVideoToVideoInput
 */
export const zSchemaLtx219bDistilledVideoToVideoLoraInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  ic_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the IC-LoRA to use. This allows you to control the strength of the IC-LoRA.',
      }),
    )
    .default(1),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  loras: z.array(zSchemaLoRaInput).register(z.globalRegistry, {
    description: 'The LoRAs to use for the generation.',
  }),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the image to use for the video generation.',
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  preprocessor: z.optional(
    z.enum(['depth', 'canny', 'pose', 'none']).register(z.globalRegistry, {
      description:
        'The preprocessor to use for the video. When a preprocessor is used and `ic_lora_type` is set to `match_preprocessor`, the IC-LoRA will be loaded based on the preprocessor type.',
    }),
  ),
  video_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Video conditioning strength. Lower values represent more freedom given to the model to change the video content.',
      }),
    )
    .default(1),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  ic_lora: z.optional(
    z
      .enum([
        'match_preprocessor',
        'canny',
        'depth',
        'pose',
        'detailer',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The type of IC-LoRA to load. In-Context LoRA weights are used to condition the video based on edge, depth, or pose videos. Only change this from `match_preprocessor` if your videos are already preprocessed (or you are using the detailer.)',
      }),
  ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  image_url: z.optional(z.union([z.string(), z.unknown()])),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  match_input_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When true, match the output FPS to the input video's FPS instead of using the default target FPS.",
      }),
    )
    .default(true),
  match_video_length: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'When enabled, the number of frames will be calculated based on the video duration and FPS. When disabled, use the specified num_frames.',
      }),
    )
    .default(true),
})

/**
 * FaceFusionVideoOutput
 *
 * FaceFusion output payload when video content is generated
 */
export const zSchemaAiFaceSwapFaceswapvideoOutput = z
  .object({
    processing_time_ms: z.optional(z.union([z.int(), z.unknown()])),
    video: zSchemaVideo,
  })
  .register(z.globalRegistry, {
    description: 'FaceFusion output payload when video content is generated',
  })

/**
 * FaceSwapInputVideo
 *
 * Input schema for image  video face swap
 */
export const zSchemaAiFaceSwapFaceswapvideoInput = z
  .object({
    source_face_url: z.union([z.string(), z.string()]),
    target_video_url: z.union([z.string(), z.string()]),
  })
  .register(z.globalRegistry, {
    description: 'Input schema for image  video face swap',
  })

/**
 * Output
 */
export const zSchemaMmaudioV2Output = z.object({
  video: zSchemaFile,
})

/**
 * BaseInput
 */
export const zSchemaMmaudioV2Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the audio for.',
  }),
  video_url: z.union([z.string(), z.string()]),
  num_steps: z
    .optional(
      z.int().gte(4).lte(50).register(z.globalRegistry, {
        description: 'The number of steps to generate the audio for.',
      }),
    )
    .default(25),
  duration: z
    .optional(
      z.number().gte(1).lte(30).register(z.globalRegistry, {
        description: 'The duration of the audio to generate.',
      }),
    )
    .default(8),
  cfg_strength: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description: 'The strength of Classifier Free Guidance.',
      }),
    )
    .default(4.5),
  seed: z.optional(
    z.int().gte(0).lte(65535).register(z.globalRegistry, {
      description: 'The seed for the random number generator',
    }),
  ),
  mask_away_clip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to mask away the clip.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the audio for.',
      }),
    )
    .default(''),
})

/**
 * GeneralRembgOutput
 */
export const zSchemaVideoBackgroundRemovalOutput = z.object({
  video: z.array(zSchemaFile),
})

/**
 * GeneralRembgInput
 */
export const zSchemaVideoBackgroundRemovalInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  subject_is_person: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Set to False if the subject is not a person.',
      }),
    )
    .default(true),
  output_codec: z.optional(
    z.enum(['vp9', 'h264']).register(z.globalRegistry, {
      description:
        'Single VP9 video with alpha channel or two videos (rgb and alpha) in H264 format. H264 is recommended for better RGB quality.',
    }),
  ),
  refine_foreground_edges: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Improves the quality of the extracted object's edges.",
      }),
    )
    .default(true),
})

/**
 * AnimatediffLCMOutput
 */
export const zSchemaAnimatediffSparsectrlLcmOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used to generate the video.',
  }),
  video: zSchemaFile,
})

/**
 * AnimatediffLCMInput
 */
export const zSchemaAnimatediffSparsectrlLcmInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n        The same seed and the same prompt given to the same version of Stable\n        Diffusion will output the same image every time.\n        ',
    }),
  ),
  controlnet_type: z.optional(
    z.enum(['scribble', 'rgb']).register(z.globalRegistry, {
      description:
        'The type of controlnet to use for generating the video. The controlnet determines how the video will be animated.',
    }),
  ),
  keyframe_2_index: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          'The frame index of the third keyframe to use for the generation.',
      }),
    )
    .default(0),
  keyframe_0_index: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          'The frame index of the first keyframe to use for the generation.',
      }),
    )
    .default(0),
  keyframe_1_image_url: z.optional(z.union([z.string(), z.string(), z.null()])),
  keyframe_1_index: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          'The frame index of the second keyframe to use for the generation.',
      }),
    )
    .default(0),
  guidance_scale: z
    .optional(
      z.int().gte(0).lte(2).register(z.globalRegistry, {
        description:
          'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(1),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(12).register(z.globalRegistry, {
        description:
          'Increasing the amount of steps tells Stable Diffusion that it should take more steps to generate your final result which can increase the amount of detail in your image.',
      }),
    )
    .default(4),
  keyframe_2_image_url: z.optional(z.union([z.string(), z.string(), z.null()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to specify what you don't want.\n        ",
      }),
    )
    .default(''),
  keyframe_0_image_url: z.optional(z.union([z.string(), z.string(), z.null()])),
})

/**
 * VideoOutput
 */
export const zSchemaMinimaxVideo01Output = z.object({
  video: zSchemaFile,
})

/**
 * TextToVideoRequest
 */
export const zSchemaMinimaxVideo01Input = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  prompt: z.string().max(2000),
})

/**
 * AnimateDiffT2VOutput
 */
export const zSchemaFastAnimatediffTurboTextToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generating the video.',
  }),
  video: zSchemaFile,
})

/**
 * AnimateDiffT2VTurboInput
 */
export const zSchemaFastAnimatediffTurboTextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the video. Be as descriptive as possible for best results.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  fps: z
    .optional(
      z.int().gte(1).lte(16).register(z.globalRegistry, {
        description: 'Number of frames per second to extract from the video.',
      }),
    )
    .default(8),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(1),
  num_frames: z
    .optional(
      z.int().gte(1).lte(64).register(z.globalRegistry, {
        description: 'The number of frames to generate for the video.',
      }),
    )
    .default(16),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description:
          'The number of inference steps to perform. 4-12 is recommended for turbo mode.',
      }),
    )
    .default(4),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default('(bad quality, worst quality:1.2), ugly faces, bad anime'),
  motions: z.optional(
    z
      .array(
        z.enum([
          'zoom-out',
          'zoom-in',
          'pan-left',
          'pan-right',
          'tilt-up',
          'tilt-down',
        ]),
      )
      .register(z.globalRegistry, {
        description: 'The motions to apply to the video.',
      }),
  ),
})

/**
 * AnimateDiffT2VOutput
 */
export const zSchemaFastAnimatediffTextToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generating the video.',
  }),
  video: zSchemaFile,
})

/**
 * AnimateDiffT2VInput
 */
export const zSchemaFastAnimatediffTextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the video. Be as descriptive as possible for best results.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  fps: z
    .optional(
      z.int().gte(1).lte(16).register(z.globalRegistry, {
        description: 'Number of frames per second to extract from the video.',
      }),
    )
    .default(8),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(7.5),
  num_frames: z
    .optional(
      z.int().gte(1).lte(32).register(z.globalRegistry, {
        description: 'The number of frames to generate for the video.',
      }),
    )
    .default(16),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(25),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default('(bad quality, worst quality:1.2), ugly faces, bad anime'),
  motions: z.optional(
    z
      .array(
        z.enum([
          'zoom-out',
          'zoom-in',
          'pan-left',
          'pan-right',
          'tilt-up',
          'tilt-down',
        ]),
      )
      .register(z.globalRegistry, {
        description: 'The motions to apply to the video.',
      }),
  ),
})

/**
 * Output
 */
export const zSchemaT2vTurboOutput = z.object({
  video: zSchemaFile,
})

/**
 * Input
 */
export const zSchemaT2vTurboInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate images from',
  }),
  guidance_scale: z
    .optional(
      z.number().gte(0.1).lte(30).register(z.globalRegistry, {
        description: 'The guidance scale',
      }),
    )
    .default(7.5),
  seed: z.optional(z.union([z.int().gte(0).lte(203279), z.unknown()])),
  export_fps: z
    .optional(
      z.int().gte(1).lte(24).register(z.globalRegistry, {
        description: 'The FPS of the exported video',
      }),
    )
    .default(8),
  num_frames: z
    .optional(
      z.int().gte(16).lte(32).register(z.globalRegistry, {
        description: 'The number of frames to generate',
      }),
    )
    .default(16),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(12).register(z.globalRegistry, {
        description: 'The number of steps to sample',
      }),
    )
    .default(4),
})

/**
 * FastSVDOutput
 */
export const zSchemaFastSvdLcmTextToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n\n        ',
  }),
  video: zSchemaFile,
})

/**
 * FastSVDTextInput
 */
export const zSchemaFastSvdLcmTextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to use as a starting point for the generation.',
  }),
  cond_aug: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description:
          '\n            The conditoning augmentation determines the amount of noise that will be\n            added to the conditioning frame. The higher the number, the more noise\n            there will be, and the less the video will look like the initial image.\n            Increase it for more motion.\n        ',
      }),
    )
    .default(0.02),
  fps: z
    .optional(
      z.int().gte(1).lte(25).register(z.globalRegistry, {
        description:
          '\n            The FPS of the generated video. The higher the number, the faster the video will\n            play. Total video length is 25 frames.\n        ',
      }),
    )
    .default(10),
  motion_bucket_id: z
    .optional(
      z.int().gte(1).lte(255).register(z.globalRegistry, {
        description:
          '\n            The motion bucket id determines the motion of the generated video. The\n            higher the number, the more motion there will be.\n        ',
      }),
    )
    .default(127),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  steps: z
    .optional(
      z.int().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n            The number of steps to run the model for. The higher the number the better\n            the quality and longer it will take to generate.\n        ',
      }),
    )
    .default(4),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * FastSVDOutput
 */
export const zSchemaFastSvdTextToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n\n        ',
  }),
  video: zSchemaFile,
})

/**
 * FastSVDTextInput
 */
export const zSchemaFastSvdTextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to use as a starting point for the generation.',
  }),
  cond_aug: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description:
          '\n            The conditoning augmentation determines the amount of noise that will be\n            added to the conditioning frame. The higher the number, the more noise\n            there will be, and the less the video will look like the initial image.\n            Increase it for more motion.\n        ',
      }),
    )
    .default(0.02),
  deep_cache: z.optional(
    z.enum(['none', 'minimum', 'medium', 'high']).register(z.globalRegistry, {
      description:
        '\n            Enabling [DeepCache](https://github.com/horseee/DeepCache) will make the execution\n            faster, but might sometimes degrade overall quality. The higher the setting, the\n            faster the execution will be, but the more quality might be lost.\n        ',
    }),
  ),
  fps: z
    .optional(
      z.int().gte(1).lte(25).register(z.globalRegistry, {
        description:
          '\n            The FPS of the generated video. The higher the number, the faster the video will\n            play. Total video length is 25 frames.\n        ',
      }),
    )
    .default(10),
  motion_bucket_id: z
    .optional(
      z.int().gte(1).lte(255).register(z.globalRegistry, {
        description:
          '\n            The motion bucket id determines the motion of the generated video. The\n            higher the number, the more motion there will be.\n        ',
      }),
    )
    .default(127),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  steps: z
    .optional(
      z.int().gte(1).lte(100).register(z.globalRegistry, {
        description:
          '\n            The number of steps to run the model for. The higher the number the better\n            the quality and longer it will take to generate.\n        ',
      }),
    )
    .default(20),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'The negative prompt to use as a starting point for the generation.',
      }),
    )
    .default(
      'unrealistic, saturated, high contrast, big nose, painting, drawing, sketch, cartoon, anime, manga, render, CG, 3d, watermark, signature, label',
    ),
})

/**
 * Output
 */
export const zSchemaLtxVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for random number generation.',
  }),
  video: zSchemaFile,
})

/**
 * TextToVideoInput
 */
export const zSchemaLtxVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  guidance_scale: z
    .optional(
      z.number().lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use.',
      }),
    )
    .default(3),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for random number generation.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to take.',
      }),
    )
    .default(30),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'low quality, worst quality, deformed, distorted, disfigured, motion smear, motion artifacts, fused fingers, bad anatomy, weird hand, ugly',
    ),
})

/**
 * HunyuanT2VResponse
 */
export const zSchemaHunyuanVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generating the video.',
  }),
  video: zSchemaFile,
})

/**
 * HunyuanVideoRequest
 */
export const zSchemaHunyuanVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the video to generate.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'The resolution of the video to generate.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(30).register(z.globalRegistry, {
        description:
          'The number of inference steps to run. Lower gets faster results, higher gets better results.',
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for generating the video.',
    }),
  ),
  num_frames: z.optional(
    z.enum(['129', '85']).register(z.globalRegistry, {
      description: 'The number of frames to generate.',
    }),
  ),
  pro_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'By default, generations are done with 35 steps. Pro mode does 55 steps which results in higher quality videos but will take more time and cost 2x more billing units.',
      }),
    )
    .default(false),
})

/**
 * MochiT2VOutput
 */
export const zSchemaMochiV1Output = z.object({
  video: zSchemaFile,
})

/**
 * MochiT2VInput
 */
export const zSchemaMochiV1Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate a video from.',
  }),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for generating the video.',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt for the video.',
      }),
    )
    .default(''),
})

/**
 * T2VOutput
 */
export const zSchemaKlingVideoV15ProTextToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * TextToVideoRequest
 */
export const zSchemaKlingVideoV15ProTextToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video frame',
    }),
  ),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * CameraControl
 */
export const zSchemaCameraControl = z.object({
  movement_type: z
    .enum(['horizontal', 'vertical', 'pan', 'tilt', 'roll', 'zoom'])
    .register(z.globalRegistry, {
      description: 'The type of camera movement',
    }),
  movement_value: z.int().gte(-10).lte(10).register(z.globalRegistry, {
    description: 'The value of the camera movement',
  }),
})

/**
 * T2VOutput
 */
export const zSchemaKlingVideoV1StandardTextToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * V1TextToVideoRequest
 */
export const zSchemaKlingVideoV1StandardTextToVideoInput = z.object({
  prompt: z.string().max(2500),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video frame',
    }),
  ),
  advanced_camera_control: z.optional(zSchemaCameraControl),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  camera_control: z.optional(
    z
      .enum([
        'down_back',
        'forward_up',
        'right_turn_forward',
        'left_turn_forward',
      ])
      .register(z.globalRegistry, {
        description: 'Camera control parameters',
      }),
  ),
})

/**
 * T2VLiveOutput
 */
export const zSchemaMinimaxVideo01LiveOutput = z.object({
  video: zSchemaFile,
})

/**
 * TextToVideoLiveRequest
 */
export const zSchemaMinimaxVideo01LiveInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  prompt: z.string().max(2000),
})

/**
 * T2VOutput
 */
export const zSchemaKlingVideoV16StandardTextToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * TextToVideoRequest
 */
export const zSchemaKlingVideoV16StandardTextToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video frame',
    }),
  ),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * Output
 */
export const zSchemaCogvideox5bOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the video.',
  }),
  timings: z.record(z.string(), z.number()),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated video. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  video: zSchemaFile,
})

/**
 * BaseInput
 */
export const zSchemaCogvideox5bInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  use_rife: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Use RIFE for video interpolation',
      }),
    )
    .default(true),
  loras: z
    .optional(
      z.array(zSchemaLoraWeight).register(z.globalRegistry, {
        description:
          '\n            The LoRAs to use for the image generation. We currently support one lora.\n        ',
      }),
    )
    .default([]),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related video to show you.\n        ',
      }),
    )
    .default(7),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(50),
  export_fps: z
    .optional(
      z.int().gte(4).lte(32).register(z.globalRegistry, {
        description: 'The target FPS of the video',
      }),
    )
    .default(16),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate video from',
      }),
    )
    .default(''),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
})

/**
 * Output
 */
export const zSchemaTranspixarOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the video.',
  }),
  videos: z.array(zSchemaFile).register(z.globalRegistry, {
    description: 'The URL to the generated video',
  }),
  timings: z.record(z.string(), z.number()),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated video. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * BaseInput
 */
export const zSchemaTranspixarInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related video to show you.\n        ',
      }),
    )
    .default(7),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(24),
  export_fps: z
    .optional(
      z.int().gte(4).lte(32).register(z.globalRegistry, {
        description: 'The target FPS of the video',
      }),
    )
    .default(8),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate video from',
      }),
    )
    .default(''),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * HunyuanT2VResponse
 */
export const zSchemaHunyuanVideoLoraOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generating the video.',
  }),
  video: zSchemaFile,
})

/**
 * HunyuanT2VRequest
 */
export const zSchemaHunyuanVideoLoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the video to generate.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'The resolution of the video to generate.',
    }),
  ),
  loras: z
    .optional(
      z.array(zSchemaLoraWeight).register(z.globalRegistry, {
        description:
          '\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ',
      }),
    )
    .default([]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for generating the video.',
    }),
  ),
  num_frames: z.optional(
    z.enum(['129', '85']).register(z.globalRegistry, {
      description: 'The number of frames to generate.',
    }),
  ),
  pro_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'By default, generations are done with 35 steps. Pro mode does 55 steps which results in higher quality videos but will take more time and cost 2x more billing units.',
      }),
    )
    .default(false),
})

/**
 * Ray2T2VOutput
 */
export const zSchemaLumaDreamMachineRay2Output = z.object({
  video: zSchemaFile,
})

/**
 * Ray2TextToVideoRequest
 */
export const zSchemaLumaDreamMachineRay2Input = z.object({
  prompt: z.string().min(3).max(5000),
  aspect_ratio: z.optional(
    z
      .enum(['16:9', '9:16', '4:3', '3:4', '21:9', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video',
      }),
  ),
  resolution: z.optional(
    z.enum(['540p', '720p', '1080p']).register(z.globalRegistry, {
      description:
        'The resolution of the generated video (720p costs 2x more, 1080p costs 4x more)',
    }),
  ),
  loop: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether the video should loop (end of video is blended with the beginning)',
      }),
    )
    .default(false),
  duration: z.optional(
    z.enum(['5s', '9s']).register(z.globalRegistry, {
      description: 'The duration of the generated video (9s costs 2x more)',
    }),
  ),
})

/**
 * VideoOutput
 */
export const zSchemaPixverseV35TextToVideoFastOutput = z.object({
  video: zSchemaFile,
})

/**
 * FastTextToVideoRequest
 */
export const zSchemaPixverseV35TextToVideoFastInput = z.object({
  prompt: z.string(),
  aspect_ratio: z.optional(
    z.enum(['16:9', '4:3', '1:1', '3:4', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * VideoOutput
 */
export const zSchemaPixverseV35TextToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * TextToVideoRequest
 */
export const zSchemaPixverseV35TextToVideoInput = z.object({
  prompt: z.string(),
  aspect_ratio: z.optional(
    z.enum(['16:9', '4:3', '1:1', '3:4', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description:
        'The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * T2VDirectorOutput
 */
export const zSchemaMinimaxVideo01DirectorOutput = z.object({
  video: zSchemaFile,
})

/**
 * TextToVideoDirectorRequest
 */
export const zSchemaMinimaxVideo01DirectorInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  prompt: z.string().max(2000).register(z.globalRegistry, {
    description:
      'Text prompt for video generation. Camera movement instructions can be added using square brackets (e.g. [Pan left] or [Zoom in]). You can use up to 3 combined movements per prompt. Supported movements: Truck left/right, Pan left/right, Push in/Pull out, Pedestal up/down, Tilt up/down, Zoom in/out, Shake, Tracking shot, Static shot. For example: [Truck left, Pan right, Zoom in]. For a more detailed guide, refer https://sixth-switch-2ac.notion.site/T2V-01-Director-Model-Tutorial-with-camera-movement-1886c20a98eb80f395b8e05291ad8645',
  }),
})

/**
 * TextToVideoOutput
 */
export const zSchemaVeo2Output = z.object({
  video: zSchemaFile,
})

/**
 * TextToVideoInput
 */
export const zSchemaVeo2Input = z.object({
  prompt: z.string().min(1).register(z.globalRegistry, {
    description: 'The text prompt describing the video you want to generate',
  }),
  duration: z.optional(
    z.enum(['5s', '6s', '7s', '8s']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'A seed to use for the video generation',
    }),
  ),
  negative_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'A negative prompt to guide the video generation',
    }),
  ),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enhance the video generation',
      }),
    )
    .default(true),
})

/**
 * WanT2VResponse
 */
export const zSchemaWanT2vOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanT2VRequest
 */
export const zSchemaWanT2vInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  aspect_ratio: z.optional(
    z.enum(['9:16', '16:9']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video (16:9 or 9:16).',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p, 580p, or 720p).',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  turbo_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the video will be generated faster with no noticeable degradation in the visual quality.',
      }),
    )
    .default(false),
  frames_per_second: z
    .optional(
      z.int().gte(5).lte(24).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 5 to 24.',
      }),
    )
    .default(16),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(81).lte(100).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 100 (inclusive).',
      }),
    )
    .default(81),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
})

/**
 * T2VOutput
 */
export const zSchemaKlingVideoV16ProTextToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * TextToVideoRequest
 */
export const zSchemaKlingVideoV16ProTextToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video frame',
    }),
  ),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * TextToVideoOutput
 */
export const zSchemaLtxVideoV095Output = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * TextToVideoInput
 */
export const zSchemaLtxVideoV095Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt to guide generation',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['9:16', '16:9']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video (16:9 or 9:16).',
    }),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to expand the prompt using the model's own capabilities.",
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps',
      }),
    )
    .default(40),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for generation',
      }),
    )
    .default('worst quality, inconsistent motion, blurry, jittery, distorted'),
})

/**
 * VideoEffectsOutput
 */
export const zSchemaKlingVideoV16StandardEffectsOutput = z.object({
  video: zSchemaFile,
})

/**
 * VideoEffectsRequest
 */
export const zSchemaKlingVideoV16StandardEffectsInput = z.object({
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  input_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'URL of images to be used for hug, kiss or heart_gesture video.',
    }),
  ),
  effect_scene: z
    .enum([
      'hug',
      'kiss',
      'heart_gesture',
      'squish',
      'expansion',
      'fuzzyfuzzy',
      'bloombloom',
      'dizzydizzy',
      'jelly_press',
      'jelly_slice',
      'jelly_squish',
      'jelly_jiggle',
      'pixelpixel',
      'yearbook',
      'instant_film',
      'anime_figure',
      'rocketrocket',
      'fly_fly',
      'disappear',
      'lightning_power',
      'bullet_time',
      'bullet_time_360',
      'media_interview',
      'day_to_night',
      "let's_ride",
      'jumpdrop',
      'swish_swish',
      'running_man',
      'jazz_jazz',
      'swing_swing',
      'skateskate',
      'building_sweater',
      'pure_white_wings',
      'black_wings',
      'golden_wing',
      'pink_pink_wings',
      'rampage_ape',
      'a_list_look',
      'countdown_teleport',
      'firework_2026',
      'instant_christmas',
      'birthday_star',
      'firework',
      'celebration',
      'tiger_hug_pro',
      'pet_lion_pro',
      'guardian_spirit',
      'squeeze_scream',
      'inner_voice',
      'memory_alive',
      'guess_what',
      'eagle_snatch',
      'hug_from_past',
      'instant_kid',
      'dollar_rain',
      'cry_cry',
      'building_collapse',
      'mushroom',
      'jesus_hug',
      'shark_alert',
      'lie_flat',
      'polar_bear_hug',
      'brown_bear_hug',
      'office_escape_plow',
      'watermelon_bomb',
      'boss_coming',
      'wig_out',
      'car_explosion',
      'tiger_hug',
      'siblings',
      'construction_worker',
      'snatched',
      'felt_felt',
      'plushcut',
      'drunk_dance',
      'drunk_dance_pet',
      'daoma_dance',
      'bouncy_dance',
      'smooth_sailing_dance',
      'new_year_greeting',
      'lion_dance',
      'prosperity',
      'great_success',
      'golden_horse_fortune',
      'red_packet_box',
      'lucky_horse_year',
      'lucky_red_packet',
      'lucky_money_come',
      'lion_dance_pet',
      'dumpling_making_pet',
      'fish_making_pet',
      'pet_red_packet',
      'lantern_glow',
      'expression_challenge',
      'overdrive',
      'heart_gesture_dance',
      'poping',
      'martial_arts',
      'running',
      'nezha',
      'motorcycle_dance',
      'subject_3_dance',
      'ghost_step_dance',
      'phantom_jewel',
      'zoom_out',
      'cheers_2026',
      'kiss_pro',
      'fight_pro',
      'hug_pro',
      'heart_gesture_pro',
      'dollar_rain_pro',
      'pet_bee_pro',
      'santa_random_surprise',
      'magic_match_tree',
      'happy_birthday',
      'thumbs_up_pro',
      'surprise_bouquet',
      'bouquet_drop',
      '3d_cartoon_1_pro',
      'glamour_photo_shoot',
      'box_of_joy',
      'first_toast_of_the_year',
      'my_santa_pic',
      'santa_gift',
      'steampunk_christmas',
      'snowglobe',
      'christmas_photo_shoot',
      'ornament_crash',
      'santa_express',
      'particle_santa_surround',
      'coronation_of_frost',
      'spark_in_the_snow',
      'scarlet_and_snow',
      'cozy_toon_wrap',
      'bullet_time_lite',
      'magic_cloak',
      'balloon_parade',
      'jumping_ginger_joy',
      'c4d_cartoon_pro',
      'venomous_spider',
      'throne_of_king',
      'luminous_elf',
      'woodland_elf',
      'japanese_anime_1',
      'american_comics',
      'snowboarding',
      'witch_transform',
      'vampire_transform',
      'pumpkin_head_transform',
      'demon_transform',
      'mummy_transform',
      'zombie_transform',
      'cute_pumpkin_transform',
      'cute_ghost_transform',
      'knock_knock_halloween',
      'halloween_escape',
      'baseball',
      'trampoline',
      'trampoline_night',
      'pucker_up',
      'feed_mooncake',
      'flyer',
      'dishwasher',
      'pet_chinese_opera',
      'magic_fireball',
      'gallery_ring',
      'pet_moto_rider',
      'muscle_pet',
      'pet_delivery',
      'mythic_style',
      'steampunk',
      '3d_cartoon_2',
      'pet_chef',
      'santa_gifts',
      'santa_hug',
      'girlfriend',
      'boyfriend',
      'heart_gesture_1',
      'pet_wizard',
      'smoke_smoke',
      'gun_shot',
      'double_gun',
      'pet_warrior',
      'long_hair',
      'pet_dance',
      'wool_curly',
      'pet_bee',
      'marry_me',
      'piggy_morph',
      'ski_ski',
      'magic_broom',
      'splashsplash',
      'surfsurf',
      'fairy_wing',
      'angel_wing',
      'dark_wing',
      'emoji',
    ])
    .register(z.globalRegistry, {
      description: 'The effect scene to use for the video generation',
    }),
})

/**
 * VideoEffectsOutput
 */
export const zSchemaKlingVideoV1StandardEffectsOutput = z.object({
  video: zSchemaFile,
})

/**
 * VideoEffectsRequest
 */
export const zSchemaKlingVideoV1StandardEffectsInput = z.object({
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  input_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'URL of images to be used for hug, kiss or heart_gesture video.',
    }),
  ),
  effect_scene: z
    .enum([
      'hug',
      'kiss',
      'heart_gesture',
      'squish',
      'expansion',
      'fuzzyfuzzy',
      'bloombloom',
      'dizzydizzy',
      'jelly_press',
      'jelly_slice',
      'jelly_squish',
      'jelly_jiggle',
      'pixelpixel',
      'yearbook',
      'instant_film',
      'anime_figure',
      'rocketrocket',
      'fly_fly',
      'disappear',
      'lightning_power',
      'bullet_time',
      'bullet_time_360',
      'media_interview',
      'day_to_night',
      "let's_ride",
      'jumpdrop',
      'swish_swish',
      'running_man',
      'jazz_jazz',
      'swing_swing',
      'skateskate',
      'building_sweater',
      'pure_white_wings',
      'black_wings',
      'golden_wing',
      'pink_pink_wings',
      'rampage_ape',
      'a_list_look',
      'countdown_teleport',
      'firework_2026',
      'instant_christmas',
      'birthday_star',
      'firework',
      'celebration',
      'tiger_hug_pro',
      'pet_lion_pro',
      'guardian_spirit',
      'squeeze_scream',
      'inner_voice',
      'memory_alive',
      'guess_what',
      'eagle_snatch',
      'hug_from_past',
      'instant_kid',
      'dollar_rain',
      'cry_cry',
      'building_collapse',
      'mushroom',
      'jesus_hug',
      'shark_alert',
      'lie_flat',
      'polar_bear_hug',
      'brown_bear_hug',
      'office_escape_plow',
      'watermelon_bomb',
      'boss_coming',
      'wig_out',
      'car_explosion',
      'tiger_hug',
      'siblings',
      'construction_worker',
      'snatched',
      'felt_felt',
      'plushcut',
      'drunk_dance',
      'drunk_dance_pet',
      'daoma_dance',
      'bouncy_dance',
      'smooth_sailing_dance',
      'new_year_greeting',
      'lion_dance',
      'prosperity',
      'great_success',
      'golden_horse_fortune',
      'red_packet_box',
      'lucky_horse_year',
      'lucky_red_packet',
      'lucky_money_come',
      'lion_dance_pet',
      'dumpling_making_pet',
      'fish_making_pet',
      'pet_red_packet',
      'lantern_glow',
      'expression_challenge',
      'overdrive',
      'heart_gesture_dance',
      'poping',
      'martial_arts',
      'running',
      'nezha',
      'motorcycle_dance',
      'subject_3_dance',
      'ghost_step_dance',
      'phantom_jewel',
      'zoom_out',
      'cheers_2026',
      'kiss_pro',
      'fight_pro',
      'hug_pro',
      'heart_gesture_pro',
      'dollar_rain_pro',
      'pet_bee_pro',
      'santa_random_surprise',
      'magic_match_tree',
      'happy_birthday',
      'thumbs_up_pro',
      'surprise_bouquet',
      'bouquet_drop',
      '3d_cartoon_1_pro',
      'glamour_photo_shoot',
      'box_of_joy',
      'first_toast_of_the_year',
      'my_santa_pic',
      'santa_gift',
      'steampunk_christmas',
      'snowglobe',
      'christmas_photo_shoot',
      'ornament_crash',
      'santa_express',
      'particle_santa_surround',
      'coronation_of_frost',
      'spark_in_the_snow',
      'scarlet_and_snow',
      'cozy_toon_wrap',
      'bullet_time_lite',
      'magic_cloak',
      'balloon_parade',
      'jumping_ginger_joy',
      'c4d_cartoon_pro',
      'venomous_spider',
      'throne_of_king',
      'luminous_elf',
      'woodland_elf',
      'japanese_anime_1',
      'american_comics',
      'snowboarding',
      'witch_transform',
      'vampire_transform',
      'pumpkin_head_transform',
      'demon_transform',
      'mummy_transform',
      'zombie_transform',
      'cute_pumpkin_transform',
      'cute_ghost_transform',
      'knock_knock_halloween',
      'halloween_escape',
      'baseball',
      'trampoline',
      'trampoline_night',
      'pucker_up',
      'feed_mooncake',
      'flyer',
      'dishwasher',
      'pet_chinese_opera',
      'magic_fireball',
      'gallery_ring',
      'pet_moto_rider',
      'muscle_pet',
      'pet_delivery',
      'mythic_style',
      'steampunk',
      '3d_cartoon_2',
      'pet_chef',
      'santa_gifts',
      'santa_hug',
      'girlfriend',
      'boyfriend',
      'heart_gesture_1',
      'pet_wizard',
      'smoke_smoke',
      'gun_shot',
      'double_gun',
      'pet_warrior',
      'long_hair',
      'pet_dance',
      'wool_curly',
      'pet_bee',
      'marry_me',
      'piggy_morph',
      'ski_ski',
      'magic_broom',
      'splashsplash',
      'surfsurf',
      'fairy_wing',
      'angel_wing',
      'dark_wing',
      'emoji',
    ])
    .register(z.globalRegistry, {
      description: 'The effect scene to use for the video generation',
    }),
})

/**
 * VideoEffectsOutput
 */
export const zSchemaKlingVideoV16ProEffectsOutput = z.object({
  video: zSchemaFile,
})

/**
 * VideoEffectsRequest
 */
export const zSchemaKlingVideoV16ProEffectsInput = z.object({
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  input_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'URL of images to be used for hug, kiss or heart_gesture video.',
    }),
  ),
  effect_scene: z
    .enum([
      'hug',
      'kiss',
      'heart_gesture',
      'squish',
      'expansion',
      'fuzzyfuzzy',
      'bloombloom',
      'dizzydizzy',
      'jelly_press',
      'jelly_slice',
      'jelly_squish',
      'jelly_jiggle',
      'pixelpixel',
      'yearbook',
      'instant_film',
      'anime_figure',
      'rocketrocket',
      'fly_fly',
      'disappear',
      'lightning_power',
      'bullet_time',
      'bullet_time_360',
      'media_interview',
      'day_to_night',
      "let's_ride",
      'jumpdrop',
      'swish_swish',
      'running_man',
      'jazz_jazz',
      'swing_swing',
      'skateskate',
      'building_sweater',
      'pure_white_wings',
      'black_wings',
      'golden_wing',
      'pink_pink_wings',
      'rampage_ape',
      'a_list_look',
      'countdown_teleport',
      'firework_2026',
      'instant_christmas',
      'birthday_star',
      'firework',
      'celebration',
      'tiger_hug_pro',
      'pet_lion_pro',
      'guardian_spirit',
      'squeeze_scream',
      'inner_voice',
      'memory_alive',
      'guess_what',
      'eagle_snatch',
      'hug_from_past',
      'instant_kid',
      'dollar_rain',
      'cry_cry',
      'building_collapse',
      'mushroom',
      'jesus_hug',
      'shark_alert',
      'lie_flat',
      'polar_bear_hug',
      'brown_bear_hug',
      'office_escape_plow',
      'watermelon_bomb',
      'boss_coming',
      'wig_out',
      'car_explosion',
      'tiger_hug',
      'siblings',
      'construction_worker',
      'snatched',
      'felt_felt',
      'plushcut',
      'drunk_dance',
      'drunk_dance_pet',
      'daoma_dance',
      'bouncy_dance',
      'smooth_sailing_dance',
      'new_year_greeting',
      'lion_dance',
      'prosperity',
      'great_success',
      'golden_horse_fortune',
      'red_packet_box',
      'lucky_horse_year',
      'lucky_red_packet',
      'lucky_money_come',
      'lion_dance_pet',
      'dumpling_making_pet',
      'fish_making_pet',
      'pet_red_packet',
      'lantern_glow',
      'expression_challenge',
      'overdrive',
      'heart_gesture_dance',
      'poping',
      'martial_arts',
      'running',
      'nezha',
      'motorcycle_dance',
      'subject_3_dance',
      'ghost_step_dance',
      'phantom_jewel',
      'zoom_out',
      'cheers_2026',
      'kiss_pro',
      'fight_pro',
      'hug_pro',
      'heart_gesture_pro',
      'dollar_rain_pro',
      'pet_bee_pro',
      'santa_random_surprise',
      'magic_match_tree',
      'happy_birthday',
      'thumbs_up_pro',
      'surprise_bouquet',
      'bouquet_drop',
      '3d_cartoon_1_pro',
      'glamour_photo_shoot',
      'box_of_joy',
      'first_toast_of_the_year',
      'my_santa_pic',
      'santa_gift',
      'steampunk_christmas',
      'snowglobe',
      'christmas_photo_shoot',
      'ornament_crash',
      'santa_express',
      'particle_santa_surround',
      'coronation_of_frost',
      'spark_in_the_snow',
      'scarlet_and_snow',
      'cozy_toon_wrap',
      'bullet_time_lite',
      'magic_cloak',
      'balloon_parade',
      'jumping_ginger_joy',
      'c4d_cartoon_pro',
      'venomous_spider',
      'throne_of_king',
      'luminous_elf',
      'woodland_elf',
      'japanese_anime_1',
      'american_comics',
      'snowboarding',
      'witch_transform',
      'vampire_transform',
      'pumpkin_head_transform',
      'demon_transform',
      'mummy_transform',
      'zombie_transform',
      'cute_pumpkin_transform',
      'cute_ghost_transform',
      'knock_knock_halloween',
      'halloween_escape',
      'baseball',
      'trampoline',
      'trampoline_night',
      'pucker_up',
      'feed_mooncake',
      'flyer',
      'dishwasher',
      'pet_chinese_opera',
      'magic_fireball',
      'gallery_ring',
      'pet_moto_rider',
      'muscle_pet',
      'pet_delivery',
      'mythic_style',
      'steampunk',
      '3d_cartoon_2',
      'pet_chef',
      'santa_gifts',
      'santa_hug',
      'girlfriend',
      'boyfriend',
      'heart_gesture_1',
      'pet_wizard',
      'smoke_smoke',
      'gun_shot',
      'double_gun',
      'pet_warrior',
      'long_hair',
      'pet_dance',
      'wool_curly',
      'pet_bee',
      'marry_me',
      'piggy_morph',
      'ski_ski',
      'magic_broom',
      'splashsplash',
      'surfsurf',
      'fairy_wing',
      'angel_wing',
      'dark_wing',
      'emoji',
    ])
    .register(z.globalRegistry, {
      description: 'The effect scene to use for the video generation',
    }),
})

/**
 * VideoEffectsOutput
 */
export const zSchemaKlingVideoV15ProEffectsOutput = z.object({
  video: zSchemaFile,
})

/**
 * VideoEffectsRequest
 */
export const zSchemaKlingVideoV15ProEffectsInput = z.object({
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  input_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'URL of images to be used for hug, kiss or heart_gesture video.',
    }),
  ),
  effect_scene: z
    .enum([
      'hug',
      'kiss',
      'heart_gesture',
      'squish',
      'expansion',
      'fuzzyfuzzy',
      'bloombloom',
      'dizzydizzy',
      'jelly_press',
      'jelly_slice',
      'jelly_squish',
      'jelly_jiggle',
      'pixelpixel',
      'yearbook',
      'instant_film',
      'anime_figure',
      'rocketrocket',
      'fly_fly',
      'disappear',
      'lightning_power',
      'bullet_time',
      'bullet_time_360',
      'media_interview',
      'day_to_night',
      "let's_ride",
      'jumpdrop',
      'swish_swish',
      'running_man',
      'jazz_jazz',
      'swing_swing',
      'skateskate',
      'building_sweater',
      'pure_white_wings',
      'black_wings',
      'golden_wing',
      'pink_pink_wings',
      'rampage_ape',
      'a_list_look',
      'countdown_teleport',
      'firework_2026',
      'instant_christmas',
      'birthday_star',
      'firework',
      'celebration',
      'tiger_hug_pro',
      'pet_lion_pro',
      'guardian_spirit',
      'squeeze_scream',
      'inner_voice',
      'memory_alive',
      'guess_what',
      'eagle_snatch',
      'hug_from_past',
      'instant_kid',
      'dollar_rain',
      'cry_cry',
      'building_collapse',
      'mushroom',
      'jesus_hug',
      'shark_alert',
      'lie_flat',
      'polar_bear_hug',
      'brown_bear_hug',
      'office_escape_plow',
      'watermelon_bomb',
      'boss_coming',
      'wig_out',
      'car_explosion',
      'tiger_hug',
      'siblings',
      'construction_worker',
      'snatched',
      'felt_felt',
      'plushcut',
      'drunk_dance',
      'drunk_dance_pet',
      'daoma_dance',
      'bouncy_dance',
      'smooth_sailing_dance',
      'new_year_greeting',
      'lion_dance',
      'prosperity',
      'great_success',
      'golden_horse_fortune',
      'red_packet_box',
      'lucky_horse_year',
      'lucky_red_packet',
      'lucky_money_come',
      'lion_dance_pet',
      'dumpling_making_pet',
      'fish_making_pet',
      'pet_red_packet',
      'lantern_glow',
      'expression_challenge',
      'overdrive',
      'heart_gesture_dance',
      'poping',
      'martial_arts',
      'running',
      'nezha',
      'motorcycle_dance',
      'subject_3_dance',
      'ghost_step_dance',
      'phantom_jewel',
      'zoom_out',
      'cheers_2026',
      'kiss_pro',
      'fight_pro',
      'hug_pro',
      'heart_gesture_pro',
      'dollar_rain_pro',
      'pet_bee_pro',
      'santa_random_surprise',
      'magic_match_tree',
      'happy_birthday',
      'thumbs_up_pro',
      'surprise_bouquet',
      'bouquet_drop',
      '3d_cartoon_1_pro',
      'glamour_photo_shoot',
      'box_of_joy',
      'first_toast_of_the_year',
      'my_santa_pic',
      'santa_gift',
      'steampunk_christmas',
      'snowglobe',
      'christmas_photo_shoot',
      'ornament_crash',
      'santa_express',
      'particle_santa_surround',
      'coronation_of_frost',
      'spark_in_the_snow',
      'scarlet_and_snow',
      'cozy_toon_wrap',
      'bullet_time_lite',
      'magic_cloak',
      'balloon_parade',
      'jumping_ginger_joy',
      'c4d_cartoon_pro',
      'venomous_spider',
      'throne_of_king',
      'luminous_elf',
      'woodland_elf',
      'japanese_anime_1',
      'american_comics',
      'snowboarding',
      'witch_transform',
      'vampire_transform',
      'pumpkin_head_transform',
      'demon_transform',
      'mummy_transform',
      'zombie_transform',
      'cute_pumpkin_transform',
      'cute_ghost_transform',
      'knock_knock_halloween',
      'halloween_escape',
      'baseball',
      'trampoline',
      'trampoline_night',
      'pucker_up',
      'feed_mooncake',
      'flyer',
      'dishwasher',
      'pet_chinese_opera',
      'magic_fireball',
      'gallery_ring',
      'pet_moto_rider',
      'muscle_pet',
      'pet_delivery',
      'mythic_style',
      'steampunk',
      '3d_cartoon_2',
      'pet_chef',
      'santa_gifts',
      'santa_hug',
      'girlfriend',
      'boyfriend',
      'heart_gesture_1',
      'pet_wizard',
      'smoke_smoke',
      'gun_shot',
      'double_gun',
      'pet_warrior',
      'long_hair',
      'pet_dance',
      'wool_curly',
      'pet_bee',
      'marry_me',
      'piggy_morph',
      'ski_ski',
      'magic_broom',
      'splashsplash',
      'surfsurf',
      'fairy_wing',
      'angel_wing',
      'dark_wing',
      'emoji',
    ])
    .register(z.globalRegistry, {
      description: 'The effect scene to use for the video generation',
    }),
})

/**
 * WanProT2VResponse
 */
export const zSchemaWanProTextToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * WanProT2VRequest
 */
export const zSchemaWanProTextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video',
  }),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker',
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * Pika22TextToVideoOutput
 *
 * Output model for Pika 2.2 text-to-video generation
 */
export const zSchemaPikaV22TextToVideoOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output model for Pika 2.2 text-to-video generation',
  })

/**
 * Pika22TextToVideoRequest
 *
 * Request model for Pika 2.2 text-to-video generation
 */
export const zSchemaPikaV22TextToVideoInput = z
  .object({
    prompt: z.string(),
    resolution: z.optional(
      z.enum(['1080p', '720p']).register(z.globalRegistry, {
        description: 'The resolution of the generated video',
      }),
    ),
    aspect_ratio: z.optional(
      z
        .enum(['16:9', '9:16', '1:1', '4:5', '5:4', '3:2', '2:3'])
        .register(z.globalRegistry, {
          description: 'The aspect ratio of the generated video',
        }),
    ),
    duration: z.optional(
      z.union([z.literal(5), z.literal(10)]).register(z.globalRegistry, {
        description: 'The duration of the generated video in seconds',
      }),
    ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the random number generator',
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'A negative prompt to guide the model',
        }),
      )
      .default('ugly, bad, terrible'),
  })
  .register(z.globalRegistry, {
    description: 'Request model for Pika 2.2 text-to-video generation',
  })

/**
 * TextToVideoV21Output
 *
 * Output from text-to-video generation
 */
export const zSchemaPikaV21TextToVideoOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output from text-to-video generation',
  })

/**
 * TextToVideov21Input
 *
 * Base request for text-to-video generation
 */
export const zSchemaPikaV21TextToVideoInput = z
  .object({
    prompt: z.string(),
    resolution: z.optional(
      z.enum(['720p', '1080p']).register(z.globalRegistry, {
        description: 'The resolution of the generated video',
      }),
    ),
    aspect_ratio: z.optional(
      z
        .enum(['16:9', '9:16', '1:1', '4:5', '5:4', '3:2', '2:3'])
        .register(z.globalRegistry, {
          description: 'The aspect ratio of the generated video',
        }),
    ),
    duration: z
      .optional(
        z.int().register(z.globalRegistry, {
          description: 'The duration of the generated video in seconds',
        }),
      )
      .default(5),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the random number generator',
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'A negative prompt to guide the model',
        }),
      )
      .default(''),
  })
  .register(z.globalRegistry, {
    description: 'Base request for text-to-video generation',
  })

/**
 * TurboTextToVideoOutput
 *
 * Output from text-to-video generation
 */
export const zSchemaPikaV2TurboTextToVideoOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output from text-to-video generation',
  })

/**
 * TextToVideoTurboInput
 *
 * Base request for text-to-video generation
 */
export const zSchemaPikaV2TurboTextToVideoInput = z
  .object({
    prompt: z.string(),
    resolution: z.optional(
      z.enum(['720p', '1080p']).register(z.globalRegistry, {
        description: 'The resolution of the generated video',
      }),
    ),
    aspect_ratio: z.optional(
      z
        .enum(['16:9', '9:16', '1:1', '4:5', '5:4', '3:2', '2:3'])
        .register(z.globalRegistry, {
          description: 'The aspect ratio of the generated video',
        }),
    ),
    duration: z
      .optional(
        z.int().register(z.globalRegistry, {
          description: 'The duration of the generated video in seconds',
        }),
      )
      .default(5),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the random number generator',
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'A negative prompt to guide the model',
        }),
      )
      .default(''),
  })
  .register(z.globalRegistry, {
    description: 'Base request for text-to-video generation',
  })

/**
 * Ray2T2VOutput
 */
export const zSchemaLumaDreamMachineRay2FlashOutput = z.object({
  video: zSchemaFile,
})

/**
 * Ray2TextToVideoRequest
 */
export const zSchemaLumaDreamMachineRay2FlashInput = z.object({
  prompt: z.string().min(3).max(5000),
  aspect_ratio: z.optional(
    z
      .enum(['16:9', '9:16', '4:3', '3:4', '21:9', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video',
      }),
  ),
  resolution: z.optional(
    z.enum(['540p', '720p', '1080p']).register(z.globalRegistry, {
      description:
        'The resolution of the generated video (720p costs 2x more, 1080p costs 4x more)',
    }),
  ),
  loop: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether the video should loop (end of video is blended with the beginning)',
      }),
    )
    .default(false),
  duration: z.optional(
    z.enum(['5s', '9s']).register(z.globalRegistry, {
      description: 'The duration of the generated video (9s costs 2x more)',
    }),
  ),
})

/**
 * WanT2VResponse
 */
export const zSchemaWanT2vLoraOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanLoRARequest
 */
export const zSchemaWanT2vLoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p,580p, or 720p).',
    }),
  ),
  reverse_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If true, the video will be reversed.',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['9:16', '16:9']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video (16:9 or 9:16).',
    }),
  ),
  loras: z
    .optional(
      z.array(zSchemaLoraWeight).register(z.globalRegistry, {
        description: 'LoRA weights to be used in the inference.',
      }),
    )
    .default([]),
  frames_per_second: z
    .optional(
      z.int().gte(5).lte(24).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 5 to 24.',
      }),
    )
    .default(16),
  turbo_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the video will be generated faster with no noticeable degradation in the visual quality.',
      }),
    )
    .default(true),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  num_frames: z
    .optional(
      z.int().gte(81).lte(100).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 100 (inclusive).',
      }),
    )
    .default(81),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
})

/**
 * LipsyncOutput
 */
export const zSchemaKlingVideoLipsyncTextToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * LipsyncT2VRequest
 */
export const zSchemaKlingVideoLipsyncTextToVideoInput = z.object({
  text: z.string().max(120).register(z.globalRegistry, {
    description:
      'Text content for lip-sync video generation. Max 120 characters.',
  }),
  video_url: z.union([z.string(), z.string()]),
  voice_id: z
    .enum([
      'genshin_vindi2',
      'zhinen_xuesheng',
      'AOT',
      'ai_shatang',
      'genshin_klee2',
      'genshin_kirara',
      'ai_kaiya',
      'oversea_male1',
      'ai_chenjiahao_712',
      'girlfriend_4_speech02',
      'chat1_female_new-3',
      'chat_0407_5-1',
      'cartoon-boy-07',
      'uk_boy1',
      'cartoon-girl-01',
      'PeppaPig_platform',
      'ai_huangzhong_712',
      'ai_huangyaoshi_712',
      'ai_laoguowang_712',
      'chengshu_jiejie',
      'you_pingjing',
      'calm_story1',
      'uk_man2',
      'laopopo_speech02',
      'heainainai_speech02',
      'reader_en_m-v1',
      'commercial_lady_en_f-v1',
      'tiyuxi_xuedi',
      'tiexin_nanyou',
      'girlfriend_1_speech02',
      'girlfriend_2_speech02',
      'zhuxi_speech02',
      'uk_oldman3',
      'dongbeilaotie_speech02',
      'chongqingxiaohuo_speech02',
      'chuanmeizi_speech02',
      'chaoshandashu_speech02',
      'ai_taiwan_man2_speech02',
      'xianzhanggui_speech02',
      'tianjinjiejie_speech02',
      'diyinnansang_DB_CN_M_04-v2',
      'yizhipiannan-v1',
      'guanxiaofang-v2',
      'tianmeixuemei-v1',
      'daopianyansang-v1',
      'mengwa-v1',
    ])
    .register(z.globalRegistry, {
      description: 'Voice ID to use for speech synthesis',
    }),
  voice_language: z.optional(
    z.enum(['zh', 'en']).register(z.globalRegistry, {
      description: 'The voice language corresponding to the Voice ID',
    }),
  ),
  voice_speed: z
    .optional(
      z.number().gte(0.8).lte(2).register(z.globalRegistry, {
        description: 'Speech rate for Text to Video generation',
      }),
    )
    .default(1),
})

/**
 * LipsyncA2VOutput
 */
export const zSchemaKlingVideoLipsyncAudioToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * LipsyncA2VRequest
 */
export const zSchemaKlingVideoLipsyncAudioToVideoInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  audio_url: z.union([z.string(), z.string()]),
})

/**
 * VideoOutputV4
 */
export const zSchemaPixverseV4TextToVideoFastOutput = z.object({
  video: zSchemaFile,
})

/**
 * FastTextToVideoRequest
 */
export const zSchemaPixverseV4TextToVideoFastInput = z.object({
  prompt: z.string(),
  aspect_ratio: z.optional(
    z.enum(['16:9', '4:3', '1:1', '3:4', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * VideoOutputV4
 */
export const zSchemaPixverseV4TextToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * TextToVideoRequest
 */
export const zSchemaPixverseV4TextToVideoInput = z.object({
  prompt: z.string(),
  aspect_ratio: z.optional(
    z.enum(['16:9', '4:3', '1:1', '3:4', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description:
        'The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * MagiResponse
 */
export const zSchemaMagiDistilledOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * MagiTextToVideoRequest
 */
export const zSchemaMagiDistilledInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z.optional(
    z
      .union([z.literal(4), z.literal(8), z.literal(16), z.literal(32)])
      .register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(96).lte(192).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.',
      }),
    )
    .default(96),
})

/**
 * MagiResponse
 */
export const zSchemaMagiOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * MagiTextToVideoRequest
 */
export const zSchemaMagiInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z.optional(
    z
      .union([
        z.literal(4),
        z.literal(8),
        z.literal(16),
        z.literal(32),
        z.literal(64),
      ])
      .register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(96).lte(192).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.',
      }),
    )
    .default(96),
})

/**
 * Q1TextToVideoOutput
 */
export const zSchemaViduQ1TextToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Q1TextToVideoRequest
 */
export const zSchemaViduQ1TextToVideoInput = z.object({
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text prompt for video generation, max 1500 characters',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the output video',
    }),
  ),
  style: z.optional(
    z.enum(['general', 'anime']).register(z.globalRegistry, {
      description: 'The style of output video',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Seed for the random number generator',
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(['auto', 'small', 'medium', 'large']).register(z.globalRegistry, {
      description: 'The movement amplitude of objects in the frame',
    }),
  ),
})

/**
 * VideoOutputV4
 */
export const zSchemaPixverseV45TextToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * TextToVideoRequest
 */
export const zSchemaPixverseV45TextToVideoInput = z.object({
  prompt: z.string(),
  aspect_ratio: z.optional(
    z.enum(['16:9', '4:3', '1:1', '3:4', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description:
        'The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * VideoOutputV4
 */
export const zSchemaPixverseV45TextToVideoFastOutput = z.object({
  video: zSchemaFile,
})

/**
 * FastTextToVideoRequest
 */
export const zSchemaPixverseV45TextToVideoFastInput = z.object({
  prompt: z.string(),
  aspect_ratio: z.optional(
    z.enum(['16:9', '4:3', '1:1', '3:4', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * TextToVideoOutput
 */
export const zSchemaLtxVideo13bDistilledOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * DistilledTextToVideoInput
 *
 * Distilled model input
 */
export const zSchemaLtxVideo13bDistilledInput = z
  .object({
    second_pass_skip_initial_steps: z
      .optional(
        z.int().gte(1).lte(20).register(z.globalRegistry, {
          description:
            'The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.',
        }),
      )
      .default(5),
    first_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(20).register(z.globalRegistry, {
          description: 'Number of inference steps during the first pass.',
        }),
      )
      .default(8),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: 'The frame rate of the video.',
        }),
      )
      .default(30),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to reverse the video.',
        }),
      )
      .default(false),
    prompt: z.string().register(z.globalRegistry, {
      description: 'Text prompt to guide generation',
    }),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to expand the prompt using a language model.',
        }),
      )
      .default(false),
    loras: z
      .optional(
        z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
          description: 'LoRA weights to use for generation',
        }),
      )
      .default([]),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable the safety checker.',
        }),
      )
      .default(true),
    num_frames: z
      .optional(
        z.int().gte(9).lte(161).register(z.globalRegistry, {
          description: 'The number of frames in the video.',
        }),
      )
      .default(121),
    second_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(20).register(z.globalRegistry, {
          description: 'Number of inference steps during the second pass.',
        }),
      )
      .default(8),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'Negative prompt for generation',
        }),
      )
      .default(
        'worst quality, inconsistent motion, blurry, jittery, distorted',
      ),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description: 'Resolution of the generated video (480p or 720p).',
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(['9:16', '1:1', '16:9']).register(z.globalRegistry, {
        description: 'Aspect ratio of the generated video (16:9, 1:1 or 9:16).',
      }),
    ),
    first_pass_skip_final_steps: z
      .optional(
        z.int().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.',
        }),
      )
      .default(1),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'Random seed for generation',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Distilled model input',
  })

/**
 * TextToVideoOutput
 */
export const zSchemaLtxVideo13bDevOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * TextToVideoInput
 */
export const zSchemaLtxVideo13bDevInput = z.object({
  second_pass_skip_initial_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description:
          'The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.',
      }),
    )
    .default(17),
  first_pass_num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps during the first pass.',
      }),
    )
    .default(30),
  frame_rate: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frame rate of the video.',
      }),
    )
    .default(30),
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt to guide generation',
  }),
  reverse_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to reverse the video.',
      }),
    )
    .default(false),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to expand the prompt using a language model.',
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
        description: 'LoRA weights to use for generation',
      }),
    )
    .default([]),
  second_pass_num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps during the second pass.',
      }),
    )
    .default(30),
  num_frames: z
    .optional(
      z.int().gte(9).lte(161).register(z.globalRegistry, {
        description: 'The number of frames in the video.',
      }),
    )
    .default(121),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for generation',
      }),
    )
    .default('worst quality, inconsistent motion, blurry, jittery, distorted'),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['9:16', '1:1', '16:9']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video (16:9, 1:1 or 9:16).',
    }),
  ),
  first_pass_skip_final_steps: z
    .optional(
      z.int().gte(0).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.',
      }),
    )
    .default(3),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
})

/**
 * TextToVideoV21MasterOutput
 */
export const zSchemaKlingVideoV21MasterTextToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * TextToVideoV21MasterRequest
 */
export const zSchemaKlingVideoV21MasterTextToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video frame',
    }),
  ),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * SeedanceVideoOutput
 */
export const zSchemaBytedanceSeedanceV1LiteTextToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generation',
  }),
  video: zSchemaFile,
})

/**
 * SeedanceTextToVideoInput
 */
export const zSchemaBytedanceSeedanceV1LiteTextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt used to generate the video',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p', '1080p']).register(z.globalRegistry, {
      description:
        'Video resolution - 480p for faster generation, 720p for higher quality',
    }),
  ),
  duration: z.optional(
    z
      .enum(['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'])
      .register(z.globalRegistry, {
        description: 'Duration of the video in seconds',
      }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '1:1', '3:4', '9:16', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video',
      }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed to control video generation. Use -1 for random.',
    }),
  ),
  camera_fixed: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to fix the camera position',
      }),
    )
    .default(false),
})

/**
 * SeedanceProT2VVideoOutput
 */
export const zSchemaBytedanceSeedanceV1ProTextToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generation',
  }),
  video: zSchemaFile,
})

/**
 * SeedanceProTextToVideoInput
 */
export const zSchemaBytedanceSeedanceV1ProTextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt used to generate the video',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p', '1080p']).register(z.globalRegistry, {
      description:
        'Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality',
    }),
  ),
  duration: z.optional(
    z
      .enum(['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'])
      .register(z.globalRegistry, {
        description: 'Duration of the video in seconds',
      }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '1:1', '3:4', '9:16'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video',
      }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed to control video generation. Use -1 for random.',
    }),
  ),
  camera_fixed: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to fix the camera position',
      }),
    )
    .default(false),
})

/**
 * TextToVideoHailuo02Output
 */
export const zSchemaMinimaxHailuo02ProTextToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ProTextToVideoHailuo02Input
 */
export const zSchemaMinimaxHailuo02ProTextToVideoInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  prompt: z.string().min(1).max(2000),
})

/**
 * TextToVideoOutput
 */
export const zSchemaLtxv13B098DistilledOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * DistilledTextToVideoInput
 *
 * Distilled model input
 */
export const zSchemaLtxv13B098DistilledInput = z
  .object({
    second_pass_skip_initial_steps: z
      .optional(
        z.int().gte(1).lte(11).register(z.globalRegistry, {
          description:
            'The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.',
        }),
      )
      .default(5),
    first_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(12).register(z.globalRegistry, {
          description: 'Number of inference steps during the first pass.',
        }),
      )
      .default(8),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: 'The frame rate of the video.',
        }),
      )
      .default(24),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to reverse the video.',
        }),
      )
      .default(false),
    prompt: z.string().register(z.globalRegistry, {
      description: 'Text prompt to guide generation',
    }),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to expand the prompt using a language model.',
        }),
      )
      .default(false),
    temporal_adain_factor: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            'The factor for adaptive instance normalization (AdaIN) applied to generated video chunks after the first. This can help deal with a gradual increase in saturation/contrast in the generated video by normalizing the color distribution across the video. A high value will ensure the color distribution is more consistent across the video, while a low value will allow for more variation in color distribution.',
        }),
      )
      .default(0.5),
    loras: z
      .optional(
        z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
          description: 'LoRA weights to use for generation',
        }),
      )
      .default([]),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable the safety checker.',
        }),
      )
      .default(true),
    num_frames: z
      .optional(
        z.int().gte(9).lte(1441).register(z.globalRegistry, {
          description: 'The number of frames in the video.',
        }),
      )
      .default(121),
    second_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(12).register(z.globalRegistry, {
          description: 'Number of inference steps during the second pass.',
        }),
      )
      .default(8),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'Negative prompt for generation',
        }),
      )
      .default(
        'worst quality, inconsistent motion, blurry, jittery, distorted',
      ),
    enable_detail_pass: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to use a detail pass. If True, the model will perform a second pass to refine the video and enhance details. This incurs a 2.0x cost multiplier on the base price.',
        }),
      )
      .default(false),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(['9:16', '1:1', '16:9']).register(z.globalRegistry, {
        description: 'Aspect ratio of the generated video.',
      }),
    ),
    tone_map_compression_ratio: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            'The compression ratio for tone mapping. This is used to compress the dynamic range of the video to improve visual quality. A value of 0.0 means no compression, while a value of 1.0 means maximum compression.',
        }),
      )
      .default(0),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'Random seed for generation',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Distilled model input',
  })

/**
 * WanT2VResponse
 */
export const zSchemaWanV22A14bTextToVideoOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The text prompt used for video generation.',
      }),
    )
    .default(''),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanT2VRequest
 */
export const zSchemaWanV22A14bTextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift value for the video. Must be between 1.0 and 10.0.',
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(4).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.',
      }),
    )
    .default(1),
  frames_per_second: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.',
      }),
    )
    .default(16),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(3.5),
  num_frames: z
    .optional(
      z.int().gte(17).lte(161).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 17 to 161 (inclusive).',
      }),
    )
    .default(81),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, input data will be checked for safety before processing.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(''),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description:
        'The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p, 580p, or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video (16:9 or 9:16).',
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, output video will be checked for safety after generation.',
      }),
    )
    .default(false),
  guidance_scale_2: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.',
      }),
    )
    .default(4),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description:
        'The quality of the output video. Higher quality means better visual quality but larger file size.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(27),
  interpolator_model: z.optional(
    z.enum(['none', 'film', 'rife']).register(z.globalRegistry, {
      description:
        'The model to use for frame interpolation. If None, no interpolation is applied.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  adjust_fps_for_interpolation: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.',
      }),
    )
    .default(true),
})

/**
 * WanSmallT2VResponse
 */
export const zSchemaWanV225bTextToVideoOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The text prompt used for video generation.',
      }),
    )
    .default(''),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanSmallT2VRequest
 */
export const zSchemaWanV225bTextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift value for the video. Must be between 1.0 and 10.0.',
      }),
    )
    .default(5),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(4).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.',
      }),
    )
    .default(0),
  frames_per_second: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.',
      }),
    )
    .default(24),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(3.5),
  num_frames: z
    .optional(
      z.int().gte(17).lte(161).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 17 to 161 (inclusive).',
      }),
    )
    .default(81),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, input data will be checked for safety before processing.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(''),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description:
        'The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.',
    }),
  ),
  resolution: z.optional(
    z.enum(['580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (580p or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video (16:9 or 9:16).',
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, output video will be checked for safety after generation.',
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description:
        'The quality of the output video. Higher quality means better visual quality but larger file size.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(40),
  interpolator_model: z.optional(
    z.enum(['none', 'film', 'rife']).register(z.globalRegistry, {
      description:
        'The model to use for frame interpolation. If None, no interpolation is applied.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  adjust_fps_for_interpolation: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.',
      }),
    )
    .default(true),
})

/**
 * WanTurboT2VResponse
 */
export const zSchemaWanV22A14bTextToVideoTurboOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The text prompt used for video generation.',
      }),
    )
    .default(''),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanTurboT2VRequest
 */
export const zSchemaWanV22A14bTextToVideoTurboInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p, 580p, or 720p).',
    }),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video (16:9 or 9:16).',
    }),
  ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description:
        'The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.',
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, output video will be checked for safety after generation.',
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description:
        'The quality of the output video. Higher quality means better visual quality but larger file size.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, input data will be checked for safety before processing.',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.',
      }),
    )
    .default(false),
})

/**
 * WanSmallFastVideoT2VResponse
 */
export const zSchemaWanV225bTextToVideoFastWanOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The text prompt used for video generation.',
      }),
    )
    .default(''),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanSmallFastVideoT2VRequest
 */
export const zSchemaWanV225bTextToVideoFastWanInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(4).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.',
      }),
    )
    .default(0),
  frames_per_second: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.',
      }),
    )
    .default(24),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, input data will be checked for safety before processing.',
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(17).lte(161).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 17 to 161 (inclusive).',
      }),
    )
    .default(81),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(3.5),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(''),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description:
        'The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (580p or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video (16:9 or 9:16).',
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, output video will be checked for safety after generation.',
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description:
        'The quality of the output video. Higher quality means better visual quality but larger file size.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  interpolator_model: z.optional(
    z.enum(['none', 'film', 'rife']).register(z.globalRegistry, {
      description:
        'The model to use for frame interpolation. If None, no interpolation is applied.',
    }),
  ),
  adjust_fps_for_interpolation: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.',
      }),
    )
    .default(true),
})

/**
 * WanSmallT2VResponse
 */
export const zSchemaWanV225bTextToVideoDistillOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The text prompt used for video generation.',
      }),
    )
    .default(''),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanDistillT2VRequest
 */
export const zSchemaWanV225bTextToVideoDistillInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift value for the video. Must be between 1.0 and 10.0.',
      }),
    )
    .default(5),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(4).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.',
      }),
    )
    .default(0),
  frames_per_second: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.',
      }),
    )
    .default(24),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(1),
  num_frames: z
    .optional(
      z.int().gte(17).lte(161).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 17 to 161 (inclusive).',
      }),
    )
    .default(81),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, input data will be checked for safety before processing.',
      }),
    )
    .default(false),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description:
        'The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.',
    }),
  ),
  resolution: z.optional(
    z.enum(['580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (580p or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video (16:9 or 9:16).',
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, output video will be checked for safety after generation.',
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description:
        'The quality of the output video. Higher quality means better visual quality but larger file size.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(40),
  interpolator_model: z.optional(
    z.enum(['none', 'film', 'rife']).register(z.globalRegistry, {
      description:
        'The model to use for frame interpolation. If None, no interpolation is applied.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  adjust_fps_for_interpolation: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.',
      }),
    )
    .default(true),
})

/**
 * WanT2VResponse
 */
export const zSchemaWanV22A14bTextToVideoLoraOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The text prompt used for video generation.',
      }),
    )
    .default(''),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanLoRAT2VRequest
 */
export const zSchemaWanV22A14bTextToVideoLoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift value for the video. Must be between 1.0 and 10.0.',
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(4).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.',
      }),
    )
    .default(1),
  reverse_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If true, the video will be reversed.',
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
        description: 'LoRA weights to be used in the inference.',
      }),
    )
    .default([]),
  frames_per_second: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.',
      }),
    )
    .default(16),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, input data will be checked for safety before processing.',
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(17).lte(161).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 17 to 161 (inclusive).',
      }),
    )
    .default(81),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(3.5),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(''),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description:
        'The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p, 580p, or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video (16:9 or 9:16).',
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, output video will be checked for safety after generation.',
      }),
    )
    .default(false),
  guidance_scale_2: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.',
      }),
    )
    .default(4),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description:
        'The quality of the output video. Higher quality means better visual quality but larger file size.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(27),
  interpolator_model: z.optional(
    z.enum(['none', 'film', 'rife']).register(z.globalRegistry, {
      description:
        'The model to use for frame interpolation. If None, no interpolation is applied.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  adjust_fps_for_interpolation: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.',
      }),
    )
    .default(true),
})

/**
 * MareyOutput
 */
export const zSchemaMareyT2vOutput = z.object({
  video: zSchemaFile,
})

/**
 * MareyInputT2V
 */
export const zSchemaMareyT2vInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate a video from',
  }),
  duration: z.optional(
    z.enum(['5s', '10s']).register(z.globalRegistry, {
      description: 'The duration of the generated video.',
    }),
  ),
  dimensions: z.optional(
    z
      .enum(['1920x1080', '1152x1152', '1536x1152', '1152x1536'])
      .register(z.globalRegistry, {
        description:
          'The dimensions of the generated video in width x height format.',
      }),
  ),
  guidance_scale: z.optional(z.union([z.number(), z.unknown()])),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  negative_prompt: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * AvatarSingleTextResponse
 */
export const zSchemaInfinitalkSingleTextOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * InfiniTalkSingleTextRequest
 */
export const zSchemaInfinitalkSingleTextInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the video to generate. Must be either 480p or 720p.',
    }),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use for generation.',
    }),
  ),
  text_input: z.string().register(z.globalRegistry, {
    description: 'The text input to guide video generation.',
  }),
  image_url: z.union([z.string(), z.string()]),
  voice: z
    .enum([
      'Aria',
      'Roger',
      'Sarah',
      'Laura',
      'Charlie',
      'George',
      'Callum',
      'River',
      'Liam',
      'Charlotte',
      'Alice',
      'Matilda',
      'Will',
      'Jessica',
      'Eric',
      'Chris',
      'Brian',
      'Daniel',
      'Lily',
      'Bill',
    ])
    .register(z.globalRegistry, {
      description: 'The voice to use for speech generation',
    }),
  num_frames: z
    .optional(
      z.int().gte(41).lte(721).register(z.globalRegistry, {
        description: 'Number of frames to generate. Must be between 41 to 721.',
      }),
    )
    .default(145),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    )
    .default(42),
})

/**
 * VideoOutputV5
 */
export const zSchemaPixverseV5TextToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * TextToVideoRequest
 */
export const zSchemaPixverseV5TextToVideoInput = z.object({
  prompt: z.string(),
  aspect_ratio: z.optional(
    z.enum(['16:9', '4:3', '1:1', '3:4', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description:
        'The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * AvatarsAppOutput
 */
export const zSchemaAvatarsTextToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Text2VideoInput
 */
export const zSchemaAvatarsTextToVideoInput = z.object({
  text: z.string(),
  avatar_id: z
    .enum([
      'emily_vertical_primary',
      'emily_vertical_secondary',
      'marcus_vertical_primary',
      'marcus_vertical_secondary',
      'mira_vertical_primary',
      'mira_vertical_secondary',
      'jasmine_vertical_primary',
      'jasmine_vertical_secondary',
      'jasmine_vertical_walking',
      'aisha_vertical_walking',
      'elena_vertical_primary',
      'elena_vertical_secondary',
      'any_male_vertical_primary',
      'any_female_vertical_primary',
      'any_male_vertical_secondary',
      'any_female_vertical_secondary',
      'any_female_vertical_walking',
      'emily_primary',
      'emily_side',
      'marcus_primary',
      'marcus_side',
      'aisha_walking',
      'elena_primary',
      'elena_side',
      'any_male_primary',
      'any_female_primary',
      'any_male_side',
      'any_female_side',
    ])
    .register(z.globalRegistry, {
      description: 'The avatar to use for the video',
    }),
})

/**
 * VideoOutput
 *
 * Base output for video generation
 */
export const zSchemaWan25PreviewTextToVideoOutput = z
  .object({
    actual_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The actual prompt used if prompt rewriting was enabled',
      }),
    ),
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed used for generation',
    }),
    video: zSchemaVideoFile,
  })
  .register(z.globalRegistry, {
    description: 'Base output for video generation',
  })

/**
 * TextToVideoInput
 *
 * Input for text-to-video generation
 */
export const zSchemaWan25PreviewTextToVideoInput = z
  .object({
    prompt: z.string().min(1).register(z.globalRegistry, {
      description:
        'The text prompt for video generation. Supports Chinese and English, max 800 characters.',
    }),
    resolution: z.optional(
      z.enum(['480p', '720p', '1080p']).register(z.globalRegistry, {
        description: 'Video resolution tier',
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video',
      }),
    ),
    duration: z.optional(
      z.enum(['5', '10']).register(z.globalRegistry, {
        description:
          'Duration of the generated video in seconds. Choose between 5 or 10 seconds.',
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'If set to true, the safety checker will be enabled.',
        }),
      )
      .default(true),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    ),
    audio_url: z.optional(z.union([z.string(), z.string()])),
    negative_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'Negative prompt to describe content to avoid. Max 500 characters.',
      }),
    ),
    enable_prompt_expansion: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable prompt rewriting using LLM. Improves results for short prompts but increases processing time.',
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description: 'Input for text-to-video generation',
  })

/**
 * OviT2VResponse
 */
export const zSchemaOviOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: z.optional(z.union([zSchemaFile, z.unknown()])),
})

/**
 * OviT2VRequest
 */
export const zSchemaOviInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z
      .enum([
        '512x992',
        '992x512',
        '960x512',
        '512x960',
        '720x720',
        '448x1120',
        '1120x448',
      ])
      .register(z.globalRegistry, {
        description:
          'Resolution of the generated video in W:H format. One of (512x992, 992x512, 960x512, 512x960, 720x720, or 448x1120).',
      }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps.',
      }),
    )
    .default(30),
  audio_negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for audio generation.',
      }),
    )
    .default('robotic, muffled, echo, distorted'),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default('jitter, bad hands, blur, distortion'),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * TextToVideoOutput
 */
export const zSchemaSora2TextToVideoOutput = z.object({
  spritesheet: z.optional(zSchemaImageFile),
  thumbnail: z.optional(zSchemaImageFile),
  video_id: z.string().register(z.globalRegistry, {
    description: 'The ID of the generated video',
  }),
  video: zSchemaVideoFile,
})

/**
 * TextToVideoInput
 */
export const zSchemaSora2TextToVideoInput = z.object({
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: 'The text prompt describing the video you want to generate',
  }),
  duration: z.optional(
    z
      .union([z.literal(4), z.literal(8), z.literal(12)])
      .register(z.globalRegistry, {
        description: 'Duration of the generated video in seconds',
      }),
  ),
  resolution: z.optional(
    z.enum(['720p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  model: z.optional(
    z
      .enum(['sora-2', 'sora-2-2025-12-08', 'sora-2-2025-10-06'])
      .register(z.globalRegistry, {
        description:
          'The model to use for the generation. When the default model is selected, the latest snapshot of the model will be used - otherwise, select a specific snapshot of the model.',
      }),
  ),
  delete_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to delete the video after generation for privacy reasons. If True, the video cannot be used for remixing and will be permanently deleted.',
      }),
    )
    .default(true),
  aspect_ratio: z.optional(
    z.enum(['9:16', '16:9']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
})

/**
 * ProTextToVideoOutput
 */
export const zSchemaSora2TextToVideoProOutput = z.object({
  spritesheet: z.optional(zSchemaImageFile),
  thumbnail: z.optional(zSchemaImageFile),
  video_id: z.string().register(z.globalRegistry, {
    description: 'The ID of the generated video',
  }),
  video: zSchemaVideoFile,
})

/**
 * ProTextToVideoInput
 */
export const zSchemaSora2TextToVideoProInput = z.object({
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: 'The text prompt describing the video you want to generate',
  }),
  duration: z.optional(
    z
      .union([z.literal(4), z.literal(8), z.literal(12)])
      .register(z.globalRegistry, {
        description: 'Duration of the generated video in seconds',
      }),
  ),
  resolution: z.optional(
    z.enum(['720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['9:16', '16:9']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  delete_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to delete the video after generation for privacy reasons. If True, the video cannot be used for remixing and will be permanently deleted.',
      }),
    )
    .default(true),
})

/**
 * Veo31TextToVideoOutput
 */
export const zSchemaVeo31Output = z.object({
  video: zSchemaFile,
})

/**
 * Veo31TextToVideoInput
 */
export const zSchemaVeo31Input = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: 'The text prompt describing the video you want to generate',
  }),
  duration: z.optional(
    z.enum(['4s', '6s', '8s']).register(z.globalRegistry, {
      description: 'The duration of the generated video.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.',
      }),
    )
    .default(true),
  resolution: z.optional(
    z.enum(['720p', '1080p', '4k']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
  negative_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'A negative prompt to guide the video generation.',
    }),
  ),
})

/**
 * Veo31TextToVideoOutput
 */
export const zSchemaVeo31FastOutput = z.object({
  video: zSchemaFile,
})

/**
 * Veo31TextToVideoInput
 */
export const zSchemaVeo31FastInput = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: 'The text prompt describing the video you want to generate',
  }),
  duration: z.optional(
    z.enum(['4s', '6s', '8s']).register(z.globalRegistry, {
      description: 'The duration of the generated video.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.',
      }),
    )
    .default(true),
  resolution: z.optional(
    z.enum(['720p', '1080p', '4k']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
  negative_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'A negative prompt to guide the video generation.',
    }),
  ),
})

/**
 * KandinskyT2VResponse
 */
export const zSchemaKandinsky5TextToVideoOutput = z.object({
  video: z.optional(zSchemaFile),
})

/**
 * KandinskyT2VRequest
 */
export const zSchemaKandinsky5TextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['768x512']).register(z.globalRegistry, {
      description:
        'Resolution of the generated video in W:H format. Will be calculated based on the aspect ratio(768x512, 512x512, 512x768).',
    }),
  ),
  duration: z.optional(
    z.enum(['5s', '10s']).register(z.globalRegistry, {
      description: 'The length of the video to generate (5s or 10s)',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['3:2', '1:1', '2:3']).register(z.globalRegistry, {
      description:
        'Aspect ratio of the generated video. One of (3:2, 1:1, 2:3).',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps.',
      }),
    )
    .default(30),
})

/**
 * KandinskyT2VResponse
 */
export const zSchemaKandinsky5TextToVideoDistillOutput = z.object({
  video: z.optional(zSchemaFile),
})

/**
 * KandinskyT2VDistillRequest
 */
export const zSchemaKandinsky5TextToVideoDistillInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  duration: z.optional(
    z.enum(['5s', '10s']).register(z.globalRegistry, {
      description: 'The length of the video to generate (5s or 10s)',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['3:2', '1:1', '2:3']).register(z.globalRegistry, {
      description:
        'Aspect ratio of the generated video. One of (3:2, 1:1, 2:3).',
    }),
  ),
  resolution: z.optional(
    z.enum(['768x512']).register(z.globalRegistry, {
      description:
        'Resolution of the generated video in W:H format. Will be calculated based on the aspect ratio(768x512, 512x512, 512x768).',
    }),
  ),
})

/**
 * WanAlphaResponse
 */
export const zSchemaWanAlphaOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  image: z.optional(zSchemaVideoFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  mask: z.optional(zSchemaVideoFile),
  video: z.optional(zSchemaVideoFile),
})

/**
 * WanAlphaRequest
 */
export const zSchemaWanAlphaInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to guide the video generation.',
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'The shift of the generated video.',
      }),
    )
    .default(10.5),
  mask_clamp_upper: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The upper bound of the mask clamping.',
      }),
    )
    .default(0.75),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frame rate of the generated video.',
      }),
    )
    .default(16),
  mask_clamp_lower: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The lower bound of the mask clamping.',
      }),
    )
    .default(0.1),
  num_frames: z
    .optional(
      z.int().gte(17).lte(121).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(81),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable safety checker.',
      }),
    )
    .default(true),
  mask_binarization_threshold: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The threshold for mask binarization. When binarize_mask is True, this threshold will be used to binarize the mask. This will also be used for transparency when the output type is `.webm`.',
      }),
    )
    .default(0.8),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'The sampler to use.',
    }),
  ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  resolution: z.optional(
    z
      .enum(['240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'The resolution of the generated video.',
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  binarize_mask: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to binarize the mask.',
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(16).register(z.globalRegistry, {
        description: 'The number of inference steps to use.',
      }),
    )
    .default(8),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
})

/**
 * VideoToVideoOutput
 */
export const zSchemaKreaWan14bTextToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * TextToVideoInput
 */
export const zSchemaKreaWan14bTextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Prompt for the video-to-video generation.',
  }),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.',
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(18).lte(162).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be a multiple of 12 plus 6, for example 6, 18, 30, 42, etc.',
      }),
    )
    .default(78),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * Q2TextToVideoOutput
 */
export const zSchemaViduQ2TextToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Q2TextToVideoRequest
 */
export const zSchemaViduQ2TextToVideoInput = z.object({
  prompt: z.string().max(3000).register(z.globalRegistry, {
    description: 'Text prompt for video generation, max 3000 characters',
  }),
  resolution: z.optional(
    z.enum(['360p', '520p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'Output video resolution',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the output video',
    }),
  ),
  duration: z.optional(
    z
      .union([
        z.literal(2),
        z.literal(3),
        z.literal(4),
        z.literal(5),
        z.literal(6),
        z.literal(7),
        z.literal(8),
      ])
      .register(z.globalRegistry, {
        description: 'Duration of the video in seconds',
      }),
  ),
  bgm: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to add background music to the video (only for 4-second videos)',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(['auto', 'small', 'medium', 'large']).register(z.globalRegistry, {
      description: 'The movement amplitude of objects in the frame',
    }),
  ),
})

/**
 * SeedanceFastT2VVideoOutput
 */
export const zSchemaBytedanceSeedanceV1ProFastTextToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generation',
  }),
  video: zSchemaFile,
})

/**
 * SeedanceProFastTextToVideoInput
 */
export const zSchemaBytedanceSeedanceV1ProFastTextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt used to generate the video',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p', '1080p']).register(z.globalRegistry, {
      description:
        'Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality',
    }),
  ),
  duration: z.optional(
    z
      .enum(['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'])
      .register(z.globalRegistry, {
        description: 'Duration of the video in seconds',
      }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '1:1', '3:4', '9:16'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video',
      }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed to control video generation. Use -1 for random.',
    }),
  ),
  camera_fixed: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to fix the camera position',
      }),
    )
    .default(false),
})

/**
 * ProTextToVideoHailuo23Output
 */
export const zSchemaMinimaxHailuo23ProTextToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ProTextToVideoHailuo23Input
 */
export const zSchemaMinimaxHailuo23ProTextToVideoInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  prompt: z.string().min(1).max(2000).register(z.globalRegistry, {
    description: 'Text prompt for video generation',
  }),
})

/**
 * StandardTextToVideoHailuo23Output
 */
export const zSchemaMinimaxHailuo23StandardTextToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * StandardTextToVideoHailuo23Input
 */
export const zSchemaMinimaxHailuo23StandardTextToVideoInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  duration: z.optional(
    z.enum(['6', '10']).register(z.globalRegistry, {
      description: 'The duration of the video in seconds.',
    }),
  ),
  prompt: z.string().min(1).max(2000),
})

/**
 * LongCatVideoResponse
 */
export const zSchemaLongcatVideoDistilledTextToVideo480pOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * LongCatVideoRequest
 */
export const zSchemaLongcatVideoDistilledTextToVideo480pInput = z.object({
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video.',
    }),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to guide the video generation.',
  }),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frame rate of the generated video.',
      }),
    )
    .default(15),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable safety checker.',
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(17).lte(961).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(162),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(16).register(z.globalRegistry, {
        description: 'The number of inference steps to use.',
      }),
    )
    .default(12),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
})

/**
 * LongCatVideoResponse
 */
export const zSchemaLongcatVideoDistilledTextToVideo720pOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * LongCat720PVideoRequest
 */
export const zSchemaLongcatVideoDistilledTextToVideo720pInput = z.object({
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video.',
    }),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to guide the video generation.',
  }),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frame rate of the generated video.',
      }),
    )
    .default(30),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  num_refine_inference_steps: z
    .optional(
      z.int().gte(2).lte(16).register(z.globalRegistry, {
        description: 'The number of inference steps to use for refinement.',
      }),
    )
    .default(12),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable safety checker.',
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(17).lte(961).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(162),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(16).register(z.globalRegistry, {
        description: 'The number of inference steps to use.',
      }),
    )
    .default(12),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
})

/**
 * LongCatVideoResponse
 */
export const zSchemaLongcatVideoTextToVideo480pOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * LongCatCFGVideoRequest
 */
export const zSchemaLongcatVideoTextToVideo480pInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to guide the video generation.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description: 'The acceleration level to use for the video generation.',
    }),
  ),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frame rate of the generated video.',
      }),
    )
    .default(15),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use for the video generation.',
      }),
    )
    .default(4),
  num_frames: z
    .optional(
      z.int().gte(17).lte(961).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(162),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable safety checker.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to use for the video generation.',
      }),
    )
    .default(
      'Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description:
          'The number of inference steps to use for the video generation.',
      }),
    )
    .default(40),
})

/**
 * LongCatVideoResponse
 */
export const zSchemaLongcatVideoTextToVideo720pOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * LongCat720PCFGVideoRequest
 */
export const zSchemaLongcatVideoTextToVideo720pInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to guide the video generation.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description: 'The acceleration level to use for the video generation.',
    }),
  ),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frame rate of the generated video.',
      }),
    )
    .default(30),
  num_refine_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to use for refinement.',
      }),
    )
    .default(40),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use for the video generation.',
      }),
    )
    .default(4),
  num_frames: z
    .optional(
      z.int().gte(17).lte(961).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(162),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable safety checker.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to use for the video generation.',
      }),
    )
    .default(
      'Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description:
          'The number of inference steps to use for the video generation.',
      }),
    )
    .default(40),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
})

/**
 * SanaVideoOutput
 */
export const zSchemaSanaVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The random seed used for the generation process',
  }),
  video: zSchemaFile,
})

/**
 * SanaVideoInput
 */
export const zSchemaSanaVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt describing the video to generate',
  }),
  resolution: z.optional(
    z.enum(['480p']).register(z.globalRegistry, {
      description: 'The resolution of the output video',
    }),
  ),
  fps: z
    .optional(
      z.int().gte(8).lte(30).register(z.globalRegistry, {
        description: 'Frames per second for the output video',
      }),
    )
    .default(16),
  motion_score: z
    .optional(
      z.int().gte(0).lte(100).register(z.globalRegistry, {
        description: 'Motion intensity score (higher = more motion)',
      }),
    )
    .default(30),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          'Guidance scale for generation (higher = more prompt adherence)',
      }),
    )
    .default(6),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'Number of denoising steps',
      }),
    )
    .default(28),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducible generation. If not provided, a random seed will be used.',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'The negative prompt describing what to avoid in the generation',
      }),
    )
    .default(
      'A chaotic sequence with misshapen, deformed limbs in heavy motion blur, sudden disappearance, jump cuts, jerky movements, rapid shot changes, frames out of sync, inconsistent character shapes, temporal artifacts, jitter, and ghosting effects, creating a disorienting visual experience.',
    ),
  num_frames: z
    .optional(
      z.int().gte(16).lte(200).register(z.globalRegistry, {
        description: 'Number of frames to generate',
      }),
    )
    .default(81),
})

/**
 * GenerationOutput
 *
 * Output model for text-to-video generation
 */
export const zSchemaInfinityStarTextToVideoOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output model for text-to-video generation',
  })

/**
 * GenerationInput
 *
 * Input model for text-to-video generation
 */
export const zSchemaInfinityStarTextToVideoInput = z
  .object({
    prompt: z.string().register(z.globalRegistry, {
      description: 'Text prompt for generating the video',
    }),
    aspect_ratio: z.optional(
      z.enum(['16:9', '1:1', '9:16']).register(z.globalRegistry, {
        description: 'Aspect ratio of the generated output',
      }),
    ),
    enhance_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to use an LLM to enhance the prompt.',
        }),
      )
      .default(true),
    use_apg: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to use APG',
        }),
      )
      .default(true),
    guidance_scale: z
      .optional(
        z.number().gte(1).lte(40).register(z.globalRegistry, {
          description: 'Guidance scale for generation',
        }),
      )
      .default(7.5),
    num_inference_steps: z
      .optional(
        z.int().gte(1).lte(100).register(z.globalRegistry, {
          description: 'Number of inference steps',
        }),
      )
      .default(50),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. Leave empty for random generation.',
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'Negative prompt to guide what to avoid in generation',
        }),
      )
      .default(''),
    tau_video: z
      .optional(
        z.number().gte(0.1).lte(1).register(z.globalRegistry, {
          description: 'Tau value for video scale',
        }),
      )
      .default(0.4),
  })
  .register(z.globalRegistry, {
    description: 'Input model for text-to-video generation',
  })

/**
 * HunyuanVideo15Response
 */
export const zSchemaHunyuanVideoV15TextToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * HunyuanVideo15T2VRequest
 */
export const zSchemaHunyuanVideoV15TextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video.',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the video.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p']).register(z.globalRegistry, {
      description: 'The resolution of the video.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable prompt expansion to enhance the input prompt.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for reproducibility.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps.',
      }),
    )
    .default(28),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to guide what not to generate.',
      }),
    )
    .default(''),
  num_frames: z
    .optional(
      z.int().gte(1).lte(121).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
})

/**
 * LTXVTextToVideoResponse
 */
export const zSchemaLtx2TextToVideoOutput = z.object({
  video: zSchemaVideoFile,
})

/**
 * LTXVTextToVideoRequest
 */
export const zSchemaLtx2TextToVideoInput = z.object({
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: 'The prompt to generate the video from',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  duration: z.optional(
    z
      .union([z.literal(6), z.literal(8), z.literal(10)])
      .register(z.globalRegistry, {
        description: 'The duration of the generated video in seconds',
      }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the generated video',
      }),
    )
    .default(true),
  resolution: z.optional(
    z.enum(['1080p', '1440p', '2160p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  fps: z.optional(
    z.union([z.literal(25), z.literal(50)]).register(z.globalRegistry, {
      description: 'The frames per second of the generated video',
    }),
  ),
})

/**
 * LTXVTextToVideoResponse
 */
export const zSchemaLtx2TextToVideoFastOutput = z.object({
  video: zSchemaVideoFile,
})

/**
 * LTXVTextToVideoFastRequest
 */
export const zSchemaLtx2TextToVideoFastInput = z.object({
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: 'The prompt to generate the video from',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  duration: z.optional(
    z
      .union([
        z.literal(6),
        z.literal(8),
        z.literal(10),
        z.literal(12),
        z.literal(14),
        z.literal(16),
        z.literal(18),
        z.literal(20),
      ])
      .register(z.globalRegistry, {
        description:
          'The duration of the generated video in seconds. The fast model supports 6-20 seconds. Note: Durations longer than 10 seconds (12, 14, 16, 18, 20) are only supported with 25 FPS and 1080p resolution.',
      }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the generated video',
      }),
    )
    .default(true),
  resolution: z.optional(
    z.enum(['1080p', '1440p', '2160p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  fps: z.optional(
    z.union([z.literal(25), z.literal(50)]).register(z.globalRegistry, {
      description: 'The frames per second of the generated video',
    }),
  ),
})

/**
 * VideoOutputV5_5
 */
export const zSchemaPixverseV55TextToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * TextToVideoRequestV5_5
 */
export const zSchemaPixverseV55TextToVideoInput = z.object({
  prompt: z.string(),
  aspect_ratio: z.optional(
    z.enum(['16:9', '4:3', '1:1', '3:4', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  thinking_type: z.optional(
    z.enum(['enabled', 'disabled', 'auto']).register(z.globalRegistry, {
      description:
        "Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision",
    }),
  ),
  generate_multi_clip_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable multi-clip generation with dynamic camera changes',
      }),
    )
    .default(false),
  duration: z.optional(
    z.enum(['5', '8', '10']).register(z.globalRegistry, {
      description:
        'The duration of the generated video in seconds. Longer durations cost more. 1080p videos are limited to 5 or 8 seconds',
    }),
  ),
  generate_audio_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable audio generation (BGM, SFX, dialogue)',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * TextToVideoV26ProOutput
 */
export const zSchemaKlingVideoV26ProTextToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * TextToVideoV26ProRequest
 */
export const zSchemaKlingVideoV26ProTextToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video frame',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to generate native audio for the video. Supports Chinese and English voice output. Other languages are automatically translated to English. For English speech, use lowercase letters; for acronyms or proper nouns, use uppercase.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * FabricOneTextOutput
 */
export const zSchemaFabric10TextOutput = z.object({
  video: zSchemaFile,
})

/**
 * FabricOneTextInput
 */
export const zSchemaFabric10TextInput = z.object({
  text: z.string().min(1).max(2000),
  resolution: z.enum(['720p', '480p']).register(z.globalRegistry, {
    description: 'Resolution',
  }),
  voice_description: z.optional(z.union([z.string(), z.unknown()])),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * TextToVideoOutput
 *
 * Output for text-to-video generation
 */
export const zSchemaV26TextToVideoOutput = z
  .object({
    actual_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The actual prompt used if prompt rewriting was enabled',
      }),
    ),
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed used for generation',
    }),
    video: zSchemaVideoFile,
  })
  .register(z.globalRegistry, {
    description: 'Output for text-to-video generation',
  })

/**
 * TextToVideoInput
 *
 * Input for Wan 2.6 text-to-video generation
 */
export const zSchemaV26TextToVideoInput = z
  .object({
    prompt: z.string().min(1).register(z.globalRegistry, {
      description:
        "The text prompt for video generation. Supports Chinese and English, max 800 characters. For multi-shot videos, use format: 'Overall description. First shot [0-3s] content. Second shot [3-5s] content.'",
    }),
    aspect_ratio: z.optional(
      z.enum(['16:9', '9:16', '1:1', '4:3', '3:4']).register(z.globalRegistry, {
        description:
          'The aspect ratio of the generated video. Wan 2.6 supports additional ratios.',
      }),
    ),
    resolution: z.optional(
      z.enum(['720p', '1080p']).register(z.globalRegistry, {
        description:
          'Video resolution tier. Wan 2.6 T2V only supports 720p and 1080p (no 480p).',
      }),
    ),
    duration: z.optional(
      z.enum(['5', '10', '15']).register(z.globalRegistry, {
        description:
          'Duration of the generated video in seconds. Choose between 5, 10, or 15 seconds.',
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'If set to true, the safety checker will be enabled.',
        }),
      )
      .default(true),
    audio_url: z.optional(z.union([z.string(), z.string()])),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    ),
    multi_shots: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'When true, enables intelligent multi-shot segmentation for coherent narrative videos. Only active when enable_prompt_expansion is True. Set to false for single-shot generation.',
        }),
      )
      .default(true),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            'Negative prompt to describe content to avoid. Max 500 characters.',
        }),
      )
      .default(''),
    enable_prompt_expansion: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable prompt rewriting using LLM. Improves results for short prompts but increases processing time.',
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description: 'Input for Wan 2.6 text-to-video generation',
  })

/**
 * SeedanceProv15T2VVideoOutput
 */
export const zSchemaBytedanceSeedanceV15ProTextToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generation',
  }),
  video: zSchemaFile,
})

/**
 * SeedanceProv15TextToVideoInput
 */
export const zSchemaBytedanceSeedanceV15ProTextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt used to generate the video',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p', '1080p']).register(z.globalRegistry, {
      description:
        'Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality',
    }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '1:1', '3:4', '9:16'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video',
      }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video',
      }),
    )
    .default(true),
  duration: z.optional(
    z
      .enum(['4', '5', '6', '7', '8', '9', '10', '11', '12'])
      .register(z.globalRegistry, {
        description: 'Duration of the video in seconds',
      }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  camera_fixed: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to fix the camera position',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed to control video generation. Use -1 for random.',
    }),
  ),
})

/**
 * KandinskyT2VResponse
 */
export const zSchemaKandinsky5ProTextToVideoOutput = z.object({
  video: z.optional(zSchemaFile),
})

/**
 * KandinskyT2VRequest
 */
export const zSchemaKandinsky5ProTextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['512P', '1024P']).register(z.globalRegistry, {
      description: 'Video resolution: 512p or 1024p.',
    }),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description: 'Acceleration level for faster generation.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['3:2', '1:1', '2:3']).register(z.globalRegistry, {
      description:
        'Aspect ratio of the generated video. One of (3:2, 1:1, 2:3).',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps.',
      }),
    )
    .default(28),
  duration: z.optional(
    z.enum(['5s']).register(z.globalRegistry, {
      description: 'The length of the video to generate (5s or 10s)',
    }),
  ),
})

/**
 * LTX2TextToVideoOutput
 */
export const zSchemaLtx219bTextToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2TextToVideoInput
 */
export const zSchemaLtx219bTextToVideoInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use.',
      }),
    )
    .default(3),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to use.',
      }),
    )
    .default(40),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * LTX2TextToVideoOutput
 */
export const zSchemaLtx219bTextToVideoLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2LoRATextToVideoInput
 */
export const zSchemaLtx219bTextToVideoLoraInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  loras: z.array(zSchemaLoRaInput).register(z.globalRegistry, {
    description: 'The LoRAs to use for the generation.',
  }),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use.',
      }),
    )
    .default(3),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to use.',
      }),
    )
    .default(40),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * LTX2TextToVideoOutput
 */
export const zSchemaLtx219bDistilledTextToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2DistilledTextToVideoInput
 */
export const zSchemaLtx219bDistilledTextToVideoInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * LTX2TextToVideoOutput
 */
export const zSchemaLtx219bDistilledTextToVideoLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2LoRADistilledTextToVideoInput
 */
export const zSchemaLtx219bDistilledTextToVideoLoraInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  loras: z.array(zSchemaLoRaInput).register(z.globalRegistry, {
    description: 'The LoRAs to use for the generation.',
  }),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * VideoOutputV5_5
 */
export const zSchemaPixverseV56TextToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * TextToVideoRequestV5_6
 */
export const zSchemaPixverseV56TextToVideoInput = z.object({
  prompt: z.string(),
  aspect_ratio: z.optional(
    z.enum(['16:9', '4:3', '1:1', '3:4', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  thinking_type: z.optional(
    z.enum(['enabled', 'disabled', 'auto']).register(z.globalRegistry, {
      description:
        "Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision",
    }),
  ),
  duration: z.optional(
    z.enum(['5', '8', '10']).register(z.globalRegistry, {
      description:
        'The duration of the generated video in seconds. 1080p videos are limited to 5 or 8 seconds',
    }),
  ),
  generate_audio_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable audio generation (BGM, SFX, dialogue)',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * TextToVideoV2MasterOutput
 */
export const zSchemaKlingVideoV2MasterTextToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * TextToVideoV2MasterRequest
 */
export const zSchemaKlingVideoV2MasterTextToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video frame',
    }),
  ),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * Veo3TextToVideoOutput
 */
export const zSchemaVeo3Output = z.object({
  video: zSchemaFile,
})

/**
 * Veo3TextToVideoInput
 */
export const zSchemaVeo3Input = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: 'The text prompt describing the video you want to generate',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video.',
    }),
  ),
  duration: z.optional(
    z.enum(['4s', '6s', '8s']).register(z.globalRegistry, {
      description: 'The duration of the generated video.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.',
      }),
    )
    .default(true),
  resolution: z.optional(
    z.enum(['720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
  negative_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'A negative prompt to guide the video generation.',
    }),
  ),
})

/**
 * TextToVideoHailuo02Output
 */
export const zSchemaMinimaxHailuo02StandardTextToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * StandardTextToVideoHailuo02Input
 */
export const zSchemaMinimaxHailuo02StandardTextToVideoInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  duration: z.optional(
    z.enum(['6', '10']).register(z.globalRegistry, {
      description:
        'The duration of the video in seconds. 10 seconds videos are not supported for 1080p resolution.',
    }),
  ),
  prompt: z.string().min(1).max(2000),
})

/**
 * Veo3TextToVideoOutput
 */
export const zSchemaVeo3FastOutput = z.object({
  video: zSchemaFile,
})

/**
 * Veo3TextToVideoInput
 */
export const zSchemaVeo3FastInput = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: 'The text prompt describing the video you want to generate',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video.',
    }),
  ),
  duration: z.optional(
    z.enum(['4s', '6s', '8s']).register(z.globalRegistry, {
      description: 'The duration of the generated video.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.',
      }),
    )
    .default(true),
  resolution: z.optional(
    z.enum(['720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
  negative_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'A negative prompt to guide the video generation.',
    }),
  ),
})

/**
 * TextToVideoV25ProOutput
 */
export const zSchemaKlingVideoV25TurboProTextToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * TextToVideoV25ProRequest
 */
export const zSchemaKlingVideoV25TurboProTextToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video frame',
    }),
  ),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * FastSVDOutput
 */
export const zSchemaFastSvdLcmOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n\n        ',
  }),
  video: zSchemaFile,
})

/**
 * FastSVDImageInput
 */
export const zSchemaFastSvdLcmInput = z.object({
  motion_bucket_id: z
    .optional(
      z.int().gte(1).lte(255).register(z.globalRegistry, {
        description:
          '\n            The motion bucket id determines the motion of the generated video. The\n            higher the number, the more motion there will be.\n        ',
      }),
    )
    .default(127),
  fps: z
    .optional(
      z.int().gte(1).lte(25).register(z.globalRegistry, {
        description:
          '\n            The FPS of the generated video. The higher the number, the faster the video will\n            play. Total video length is 25 frames.\n        ',
      }),
    )
    .default(10),
  steps: z
    .optional(
      z.int().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n            The number of steps to run the model for. The higher the number the better\n            the quality and longer it will take to generate.\n        ',
      }),
    )
    .default(4),
  cond_aug: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description:
          '\n            The conditoning augmentation determines the amount of noise that will be\n            added to the conditioning frame. The higher the number, the more noise\n            there will be, and the less the video will look like the initial image.\n            Increase it for more motion.\n        ',
      }),
    )
    .default(0.02),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * SadTalkerOutput
 */
export const zSchemaSadtalkerOutput = z.object({
  video: zSchemaFile,
})

/**
 * SadTalkerInput
 */
export const zSchemaSadtalkerInput = z.object({
  pose_style: z
    .optional(
      z.int().gte(0).lte(45).register(z.globalRegistry, {
        description: 'The style of the pose',
      }),
    )
    .default(0),
  source_image_url: z.union([z.string(), z.string()]),
  driven_audio_url: z.union([z.string(), z.string()]),
  face_enhancer: z.optional(
    z.enum(['gfpgan']).register(z.globalRegistry, {
      description: 'The type of face enhancer to use',
    }),
  ),
  expression_scale: z
    .optional(
      z.number().gte(0).lte(3).register(z.globalRegistry, {
        description: 'The scale of the expression',
      }),
    )
    .default(1),
  face_model_resolution: z.optional(
    z.enum(['256', '512']).register(z.globalRegistry, {
      description: 'The resolution of the face model',
    }),
  ),
  still_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use still mode. Fewer head motion, works with preprocess `full`.',
      }),
    )
    .default(false),
  preprocess: z.optional(
    z
      .enum(['crop', 'extcrop', 'resize', 'full', 'extfull'])
      .register(z.globalRegistry, {
        description: 'The type of preprocessing to use',
      }),
  ),
})

/**
 * MuseTalkOutput
 */
export const zSchemaMusetalkOutput = z.object({
  video: zSchemaFile,
})

/**
 * MuseTalkInput
 */
export const zSchemaMusetalkInput = z.object({
  source_video_url: z.union([z.string(), z.string()]),
  audio_url: z.union([z.string(), z.string()]),
})

/**
 * LivePortraitOutput
 */
export const zSchemaLivePortraitOutput = z.object({
  video: zSchemaFile,
})

/**
 * LivePortraitInput
 */
export const zSchemaLivePortraitInput = z.object({
  smile: z
    .optional(
      z.number().gte(-2).lte(2).register(z.globalRegistry, {
        description: 'Amount to smile',
      }),
    )
    .default(0),
  video_url: z.union([z.string(), z.string()]),
  eyebrow: z
    .optional(
      z.number().gte(-30).lte(30).register(z.globalRegistry, {
        description: 'Amount to raise or lower eyebrows',
      }),
    )
    .default(0),
  flag_stitching: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable stitching. Recommended to set to True.',
      }),
    )
    .default(true),
  wink: z
    .optional(
      z.number().gte(0).lte(25).register(z.globalRegistry, {
        description: 'Amount to wink',
      }),
    )
    .default(0),
  rotate_pitch: z
    .optional(
      z.number().gte(-45).lte(45).register(z.globalRegistry, {
        description: 'Amount to rotate the face in pitch',
      }),
    )
    .default(0),
  blink: z
    .optional(
      z.number().gte(-30).lte(30).register(z.globalRegistry, {
        description: 'Amount to blink the eyes',
      }),
    )
    .default(0),
  scale: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: 'Scaling factor for the face crop.',
      }),
    )
    .default(2.3),
  eee: z
    .optional(
      z.number().gte(-40).lte(40).register(z.globalRegistry, {
        description: "Amount to shape mouth in 'eee' position",
      }),
    )
    .default(0),
  flag_pasteback: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to paste-back/stitch the animated face cropping from the face-cropping space to the original image space.',
      }),
    )
    .default(true),
  pupil_y: z
    .optional(
      z.number().gte(-45).lte(45).register(z.globalRegistry, {
        description: 'Amount to move pupils vertically',
      }),
    )
    .default(0),
  rotate_yaw: z
    .optional(
      z.number().gte(-45).lte(45).register(z.globalRegistry, {
        description: 'Amount to rotate the face in yaw',
      }),
    )
    .default(0),
  flag_do_rot: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to conduct the rotation when flag_do_crop is True.',
      }),
    )
    .default(true),
  woo: z
    .optional(
      z.number().gte(-100).lte(100).register(z.globalRegistry, {
        description: "Amount to shape mouth in 'woo' position",
      }),
    )
    .default(0),
  aaa: z
    .optional(
      z.number().gte(-200).lte(200).register(z.globalRegistry, {
        description: "Amount to open mouth in 'aaa' shape",
      }),
    )
    .default(0),
  image_url: z.union([z.string(), z.string()]),
  flag_relative: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to use relative motion.',
      }),
    )
    .default(true),
  flag_eye_retargeting: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable eye retargeting.',
      }),
    )
    .default(false),
  flag_lip_zero: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to set the lip to closed state before animation. Only takes effect when flag_eye_retargeting and flag_lip_retargeting are False.',
      }),
    )
    .default(true),
  batch_size: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          'Batch size for the model. The larger the batch size, the faster the model will run, but the more memory it will consume.',
      }),
    )
    .default(32),
  rotate_roll: z
    .optional(
      z.number().gte(-45).lte(45).register(z.globalRegistry, {
        description: 'Amount to rotate the face in roll',
      }),
    )
    .default(0),
  pupil_x: z
    .optional(
      z.number().gte(-45).lte(45).register(z.globalRegistry, {
        description: 'Amount to move pupils horizontally',
      }),
    )
    .default(0),
  vy_ratio: z
    .optional(
      z.number().register(z.globalRegistry, {
        description:
          'Vertical offset ratio for face crop. Positive values move up, negative values move down.',
      }),
    )
    .default(-0.125),
  dsize: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Size of the output image.',
      }),
    )
    .default(512),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n        Whether to enable the safety checker. If enabled, the model will check if the input image contains a face before processing it.\n        The safety checker will process the input image\n        ',
      }),
    )
    .default(false),
  vx_ratio: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: 'Horizontal offset ratio for face crop.',
      }),
    )
    .default(0),
  flag_lip_retargeting: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable lip retargeting.',
      }),
    )
    .default(false),
  flag_do_crop: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to crop the source portrait to the face-cropping space.',
      }),
    )
    .default(true),
})

/**
 * Frame
 */
export const zSchemaFrame = z.object({
  url: z.string().register(z.globalRegistry, {
    description: 'URL of the frame',
  }),
})

/**
 * AMTInterpolationOutput
 */
export const zSchemaAmtInterpolationFrameInterpolationOutput = z.object({
  video: zSchemaFile,
})

/**
 * AMTFrameInterpolationInput
 */
export const zSchemaAmtInterpolationFrameInterpolationInput = z.object({
  frames: z.array(zSchemaFrame).register(z.globalRegistry, {
    description: 'Frames to interpolate',
  }),
  recursive_interpolation_passes: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Number of recursive interpolation passes',
      }),
    )
    .default(4),
  output_fps: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Output frames per second',
      }),
    )
    .default(24),
})

/**
 * VideoOutput
 */
export const zSchemaStableVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed for random number generator',
  }),
  video: zSchemaFile,
})

/**
 * ImageInput
 */
export const zSchemaStableVideoInput = z.object({
  motion_bucket_id: z
    .optional(
      z.int().gte(1).lte(255).register(z.globalRegistry, {
        description:
          '\n            The motion bucket id determines the motion of the generated video. The\n            higher the number, the more motion there will be.\n        ',
      }),
    )
    .default(127),
  fps: z
    .optional(
      z.int().gte(10).lte(100).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  cond_aug: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description:
          '\n            The conditoning augmentation determines the amount of noise that will be\n            added to the conditioning frame. The higher the number, the more noise\n            there will be, and the less the video will look like the initial image.\n            Increase it for more motion.\n        ',
      }),
    )
    .default(0.02),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * KlingV1I2VOutput
 */
export const zSchemaKlingVideoV1StandardImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Trajectory
 */
export const zSchemaTrajectory = z.object({
  y: z.int().register(z.globalRegistry, {
    description: 'Y coordinate of the motion trajectory',
  }),
  x: z.int().register(z.globalRegistry, {
    description: 'X coordinate of the motion trajectory',
  }),
})

/**
 * DynamicMask
 */
export const zSchemaDynamicMask = z.object({
  trajectories: z.optional(
    z.array(zSchemaTrajectory).register(z.globalRegistry, {
      description: 'List of trajectories',
    }),
  ),
  mask_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the image for Dynamic Brush Application Area (Mask image created by users using the motion brush)',
  }),
})

/**
 * V1ImageToVideoRequest
 */
export const zSchemaKlingVideoV1StandardImageToVideoInput = z.object({
  prompt: z.string().max(2500).register(z.globalRegistry, {
    description: 'The prompt for the video',
  }),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  image_url: z.union([z.string(), z.string()]),
  static_mask_url: z.optional(z.union([z.string(), z.string()])),
  dynamic_masks: z.optional(
    z.array(zSchemaDynamicMask).register(z.globalRegistry, {
      description: 'List of dynamic masks',
    }),
  ),
  tail_image_url: z.optional(z.union([z.string(), z.string()])),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * I2VOutput
 */
export const zSchemaKlingVideoV15ProImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * KlingV15ProImageToVideoRequest
 */
export const zSchemaKlingVideoV15ProImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video frame',
    }),
  ),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  image_url: z.union([z.string(), z.string()]),
  static_mask_url: z.optional(z.union([z.string(), z.string()])),
  dynamic_masks: z.optional(
    z.array(zSchemaDynamicMask).register(z.globalRegistry, {
      description: 'List of dynamic masks',
    }),
  ),
  tail_image_url: z.optional(z.union([z.string(), z.string()])),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * Output
 */
export const zSchemaCogvideox5bImageToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the video.',
  }),
  timings: z.record(z.string(), z.number()),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated video. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  video: zSchemaFile,
})

/**
 * ImageToVideoInput
 */
export const zSchemaCogvideox5bImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  use_rife: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Use RIFE for video interpolation',
      }),
    )
    .default(true),
  image_url: z.union([z.string(), z.string()]),
  loras: z
    .optional(
      z.array(zSchemaLoraWeight).register(z.globalRegistry, {
        description:
          '\n            The LoRAs to use for the image generation. We currently support one lora.\n        ',
      }),
    )
    .default([]),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related video to show you.\n        ',
      }),
    )
    .default(7),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(50),
  export_fps: z
    .optional(
      z.int().gte(4).lte(32).register(z.globalRegistry, {
        description: 'The target FPS of the video',
      }),
    )
    .default(16),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate video from',
      }),
    )
    .default(''),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
})

/**
 * Output
 */
export const zSchemaLtxVideoImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for random number generation.',
  }),
  video: zSchemaFile,
})

/**
 * ImageToVideoInput
 */
export const zSchemaLtxVideoImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  guidance_scale: z
    .optional(
      z.number().lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use.',
      }),
    )
    .default(3),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for random number generation.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to take.',
      }),
    )
    .default(30),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'low quality, worst quality, deformed, distorted, disfigured, motion smear, motion artifacts, fused fingers, bad anatomy, weird hand, ugly',
    ),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * I2VLiveOutput
 */
export const zSchemaMinimaxVideo01LiveImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoRequest
 */
export const zSchemaMinimaxVideo01LiveImageToVideoInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  prompt: z.string().max(2000),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * SadTalkerOutput
 */
export const zSchemaSadtalkerReferenceOutput = z.object({
  video: zSchemaFile,
})

/**
 * SadTalkerRefVideoInput
 */
export const zSchemaSadtalkerReferenceInput = z.object({
  pose_style: z
    .optional(
      z.int().gte(0).lte(45).register(z.globalRegistry, {
        description: 'The style of the pose',
      }),
    )
    .default(0),
  source_image_url: z.union([z.string(), z.string()]),
  reference_pose_video_url: z.union([z.string(), z.string()]),
  driven_audio_url: z.union([z.string(), z.string()]),
  face_enhancer: z.optional(
    z.enum(['gfpgan']).register(z.globalRegistry, {
      description: 'The type of face enhancer to use',
    }),
  ),
  expression_scale: z
    .optional(
      z.number().gte(0).lte(3).register(z.globalRegistry, {
        description: 'The scale of the expression',
      }),
    )
    .default(1),
  face_model_resolution: z.optional(
    z.enum(['256', '512']).register(z.globalRegistry, {
      description: 'The resolution of the face model',
    }),
  ),
  still_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use still mode. Fewer head motion, works with preprocess `full`.',
      }),
    )
    .default(false),
  preprocess: z.optional(
    z
      .enum(['crop', 'extcrop', 'resize', 'full', 'extfull'])
      .register(z.globalRegistry, {
        description: 'The type of preprocessing to use',
      }),
  ),
})

/**
 * I2VOutput
 */
export const zSchemaKlingVideoV16StandardImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoRequest
 */
export const zSchemaKlingVideoV16StandardImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * SubjectReferenceOutput
 */
export const zSchemaMinimaxVideo01SubjectReferenceOutput = z.object({
  video: zSchemaFile,
})

/**
 * SubjectReferenceRequest
 */
export const zSchemaMinimaxVideo01SubjectReferenceInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  prompt: z.string().max(2000),
  subject_reference_image_url: z.union([z.string(), z.string()]),
})

/**
 * I2VOutput
 */
export const zSchemaPixverseV35ImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoRequest
 */
export const zSchemaPixverseV35ImageToVideoInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description:
        'The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * I2VOutput
 */
export const zSchemaPixverseV35ImageToVideoFastOutput = z.object({
  video: zSchemaFile,
})

/**
 * FastImageToVideoRequest
 */
export const zSchemaPixverseV35ImageToVideoFastInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * Output
 */
export const zSchemaHunyuanVideoImg2VidLoraOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generating the video.',
  }),
  video: zSchemaFile,
})

/**
 * Input
 */
export const zSchemaHunyuanVideoImg2VidLoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for generating the video.',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * Ray2I2VOutput
 */
export const zSchemaLumaDreamMachineRay2ImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Ray2ImageToVideoRequest
 */
export const zSchemaLumaDreamMachineRay2ImageToVideoInput = z.object({
  prompt: z.string().min(3).max(5000),
  aspect_ratio: z.optional(
    z
      .enum(['16:9', '9:16', '4:3', '3:4', '21:9', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video',
      }),
  ),
  resolution: z.optional(
    z.enum(['540p', '720p', '1080p']).register(z.globalRegistry, {
      description:
        'The resolution of the generated video (720p costs 2x more, 1080p costs 4x more)',
    }),
  ),
  loop: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether the video should loop (end of video is blended with the beginning)',
      }),
    )
    .default(false),
  duration: z.optional(
    z.enum(['5s', '9s']).register(z.globalRegistry, {
      description: 'The duration of the generated video',
    }),
  ),
  image_url: z.optional(z.union([z.string(), z.string()])),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
})

/**
 * SkyreelsI2VResponse
 */
export const zSchemaSkyreelsI2vOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
  video: zSchemaFile,
})

/**
 * SkyreelsI2VRequest
 */
export const zSchemaSkyreelsI2vInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the output video',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description: 'Guidance scale for generation (between 1.0 and 20.0)',
      }),
    )
    .default(6),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for generation. If not provided, a random seed will be used.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description:
          'Number of denoising steps (between 1 and 50). Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  negative_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'Negative prompt to guide generation away from certain attributes.',
    }),
  ),
})

/**
 * I2VDirectorOutput
 */
export const zSchemaMinimaxVideo01DirectorImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoDirectorRequest
 */
export const zSchemaMinimaxVideo01DirectorImageToVideoInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  prompt: z.string().max(2000).register(z.globalRegistry, {
    description:
      'Text prompt for video generation. Camera movement instructions can be added using square brackets (e.g. [Pan left] or [Zoom in]). You can use up to 3 combined movements per prompt. Supported movements: Truck left/right, Pan left/right, Push in/Pull out, Pedestal up/down, Tilt up/down, Zoom in/out, Shake, Tracking shot, Static shot. For example: [Truck left, Pan right, Zoom in]. For a more detailed guide, refer https://sixth-switch-2ac.notion.site/T2V-01-Director-Model-Tutorial-with-camera-movement-1886c20a98eb80f395b8e05291ad8645',
  }),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * HunyuanI2VResponse
 */
export const zSchemaHunyuanVideoImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generating the video.',
  }),
  video: zSchemaFile,
})

/**
 * HunyuanVideoRequest
 */
export const zSchemaHunyuanVideoImageToVideoInput = z.object({
  prompt: z.string().max(1000).register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the video to generate.',
    }),
  ),
  resolution: z.optional(
    z.enum(['720p']).register(z.globalRegistry, {
      description: 'The resolution of the video to generate.',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for generating the video.',
    }),
  ),
  num_frames: z.optional(
    z.enum(['129']).register(z.globalRegistry, {
      description: 'The number of frames to generate.',
    }),
  ),
  i2v_stability: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Turning on I2V Stability reduces hallucination but also reduces motion.',
      }),
    )
    .default(false),
})

/**
 * WanI2VResponse
 */
export const zSchemaWanI2vLoraOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanLoRAI2VRequest
 */
export const zSchemaWanI2vLoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  reverse_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If true, the video will be reversed.',
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zSchemaLoraWeight).register(z.globalRegistry, {
        description: 'LoRA weights to be used in the inference.',
      }),
    )
    .default([]),
  frames_per_second: z
    .optional(
      z.int().gte(5).lte(24).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 5 to 24.',
      }),
    )
    .default(16),
  turbo_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the video will be generated faster with no noticeable degradation in the visual quality.',
      }),
    )
    .default(true),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(81).lte(100).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 100 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.',
      }),
    )
    .default(81),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'Aspect ratio of the output video.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  guide_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(5),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
})

/**
 * TemplateToVideoOutput
 */
export const zSchemaViduTemplateToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * TemplateToVideoRequest
 */
export const zSchemaViduTemplateToVideoInput = z.object({
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the output video',
    }),
  ),
  template: z.optional(
    z
      .enum([
        'dreamy_wedding',
        'romantic_lift',
        'sweet_proposal',
        'couple_arrival',
        'cupid_arrow',
        'pet_lovers',
        'lunar_newyear',
        'hug',
        'kiss',
        'dynasty_dress',
        'wish_sender',
        'love_pose',
        'hair_swap',
        'youth_rewind',
        'morphlab',
        'live_photo',
        'emotionlab',
        'live_memory',
        'interaction',
        'christmas',
        'pet_finger',
        'eat_mushrooms',
        'beast_chase_library',
        'beast_chase_supermarket',
        'petal_scattered',
        'emoji_figure',
        'hair_color_change',
        'multiple_people_kissing',
        'beast_chase_amazon',
        'beast_chase_mountain',
        'balloonman_explodes_pro',
        'get_thinner',
        'jump2pool',
        'bodyshake',
        'jiggle_up',
        'shake_it_dance',
        'subject_3',
        'pubg_winner_hit',
        'shake_it_down',
        'blueprint_supreme',
        'hip_twist',
        'motor_dance',
        'rat_dance',
        'kwok_dance',
        'leg_sweep_dance',
        'heeseung_march',
        'shake_to_max',
        'dame_un_grrr',
        'i_know',
        'lit_bounce',
        'wave_dance',
        'chill_dance',
        'hip_flicking',
        'sakura_season',
        'zongzi_wrap',
        'zongzi_drop',
        'dragonboat_shot',
        'rain_kiss',
        'child_memory',
        'couple_drop',
        'couple_walk',
        'flower_receive',
        'love_drop',
        'cheek_kiss',
        'carry_me',
        'blow_kiss',
        'love_fall',
        'french_kiss_8s',
        'workday_feels',
        'love_story',
        'bloom_magic',
        'ghibli',
        'minecraft',
        'box_me',
        'claw_me',
        'clayshot',
        'manga_meme',
        'quad_meme',
        'pixel_me',
        'clayshot_duo',
        'irasutoya',
        'american_comic',
        'simpsons_comic',
        'yayoi_kusama_style',
        'pop_art',
        'jojo_style',
        'slice_therapy',
        'balloon_flyaway',
        'flying',
        'paperman',
        'pinch',
        'bloom_doorobear',
        'gender_swap',
        'nap_me',
        'sexy_me',
        'spin360',
        'smooth_shift',
        'paper_fall',
        'jump_to_cloud',
        'pilot',
        'sweet_dreams',
        'soul_depart',
        'punch_hit',
        'watermelon_hit',
        'split_stance_pet',
        'make_face',
        'break_glass',
        'split_stance_human',
        'covered_liquid_metal',
        'fluffy_plunge',
        'pet_belly_dance',
        'water_float',
        'relax_cut',
        'head_to_balloon',
        'cloning',
        'across_the_universe_jungle',
        'clothes_spinning_remnant',
        'across_the_universe_jurassic',
        'across_the_universe_moon',
        'fisheye_pet',
        'hitchcock_zoom',
        'cute_bangs',
        'earth_zoom_out',
        'fisheye_human',
        'drive_yacht',
        'virtual_singer',
        'earth_zoom_in',
        'aliens_coming',
        'drive_ferrari',
        'bjd_style',
        'virtual_fitting',
        'orbit',
        'zoom_in',
        'ai_outfit',
        'spin180',
        'orbit_dolly',
        'orbit_dolly_fast',
        'auto_spin',
        'walk_forward',
        'outfit_show',
        'zoom_in_fast',
        'zoom_out_image',
        'zoom_out_startend',
        'muscling',
        'captain_america',
        'hulk',
        'cap_walk',
        'hulk_dive',
        'exotic_princess',
        'beast_companion',
        'cartoon_doll',
        'golden_epoch',
        'oscar_gala',
        'fashion_stride',
        'star_carpet',
        'flame_carpet',
        'frost_carpet',
        'mecha_x',
        'style_me',
        'tap_me',
        'saber_warrior',
        'pet2human',
        'graduation',
        'fishermen',
        'happy_birthday',
        'fairy_me',
        'ladudu_me',
        'ladudu_me_random',
        'squid_game',
        'superman',
        'grow_wings',
        'clevage',
        'fly_with_doraemon',
        'creatice_product_down',
        'pole_dance',
        'hug_from_behind',
        'creatice_product_up_cybercity',
        'creatice_product_up_bluecircuit',
        'creatice_product_up',
        'run_fast',
        'background_explosion',
      ])
      .register(z.globalRegistry, {
        description:
          'AI video template to use. Pricing varies by template: Standard templates (hug, kiss, love_pose, etc.) cost 4 credits ($0.20), Premium templates (lunar_newyear, dynasty_dress, dreamy_wedding, etc.) cost 6 credits ($0.30), and Advanced templates (live_photo) cost 10 credits ($0.50).',
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
  input_image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      "URLs of the images to use with the template. Number of images required varies by template: 'dynasty_dress' and 'shop_frame' accept 1-2 images, 'wish_sender' requires exactly 3 images, all other templates accept only 1 image.",
  }),
})

/**
 * ReferenceToVideoOutput
 */
export const zSchemaViduReferenceToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ReferenceToVideoRequest
 */
export const zSchemaViduReferenceToVideoInput = z.object({
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text prompt for video generation, max 1500 characters',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the output video',
    }),
  ),
  reference_image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'URLs of the reference images to use for consistent subject appearance',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(['auto', 'small', 'medium', 'large']).register(z.globalRegistry, {
      description: 'The movement amplitude of objects in the frame',
    }),
  ),
})

/**
 * StartEndToVideoOutput
 */
export const zSchemaViduStartEndToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * StartEndToVideoRequest
 */
export const zSchemaViduStartEndToVideoInput = z.object({
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text prompt for video generation, max 1500 characters',
  }),
  start_image_url: z.union([z.string(), z.string()]),
  movement_amplitude: z.optional(
    z.enum(['auto', 'small', 'medium', 'large']).register(z.globalRegistry, {
      description: 'The movement amplitude of objects in the frame',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
  end_image_url: z.union([z.string(), z.string()]),
})

/**
 * VideoOutput
 */
export const zSchemaViduImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoRequest
 */
export const zSchemaViduImageToVideoInput = z.object({
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text prompt for video generation, max 1500 characters',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(['auto', 'small', 'medium', 'large']).register(z.globalRegistry, {
      description: 'The movement amplitude of objects in the frame',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * ImageToVideoV21Output
 *
 * Output from image-to-video generation
 */
export const zSchemaPikaV21ImageToVideoOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output from image-to-video generation',
  })

/**
 * ImageToVideov21Input
 *
 * Base request for image-to-video generation
 */
export const zSchemaPikaV21ImageToVideoInput = z
  .object({
    prompt: z.string(),
    resolution: z.optional(
      z.enum(['720p', '1080p']).register(z.globalRegistry, {
        description: 'The resolution of the generated video',
      }),
    ),
    duration: z
      .optional(
        z.int().register(z.globalRegistry, {
          description: 'The duration of the generated video in seconds',
        }),
      )
      .default(5),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the random number generator',
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'A negative prompt to guide the model',
        }),
      )
      .default(''),
    image_url: z.union([z.string(), z.string()]),
  })
  .register(z.globalRegistry, {
    description: 'Base request for image-to-video generation',
  })

/**
 * Pika22ImageToVideoOutput
 *
 * Output model for Pika 2.2 image-to-video generation
 */
export const zSchemaPikaV22ImageToVideoOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output model for Pika 2.2 image-to-video generation',
  })

/**
 * Pika22ImageToVideoRequest
 *
 * Request model for Pika 2.2 image-to-video generation
 */
export const zSchemaPikaV22ImageToVideoInput = z
  .object({
    prompt: z.string(),
    resolution: z.optional(
      z.enum(['720p', '1080p']).register(z.globalRegistry, {
        description: 'The resolution of the generated video',
      }),
    ),
    duration: z.optional(
      z.union([z.literal(5), z.literal(10)]).register(z.globalRegistry, {
        description: 'The duration of the generated video in seconds',
      }),
    ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the random number generator',
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'A negative prompt to guide the model',
        }),
      )
      .default(''),
    image_url: z.union([z.string(), z.string()]),
  })
  .register(z.globalRegistry, {
    description: 'Request model for Pika 2.2 image-to-video generation',
  })

/**
 * Pika22PikascenesOutput
 *
 * Output model for Pika 2.2 Pikascenes generation
 */
export const zSchemaPikaV22PikascenesOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output model for Pika 2.2 Pikascenes generation',
  })

/**
 * Pika22PikascenesRequest
 *
 * Request model for Pika 2.2 Pikascenes (collection-to-video) generation
 */
export const zSchemaPikaV22PikascenesInput = z
  .object({
    prompt: z.string().register(z.globalRegistry, {
      description: 'Text prompt describing the desired video',
    }),
    resolution: z.optional(
      z.enum(['720p', '1080p']).register(z.globalRegistry, {
        description: 'The resolution of the generated video',
      }),
    ),
    aspect_ratio: z.optional(
      z
        .enum(['16:9', '9:16', '1:1', '4:5', '5:4', '3:2', '2:3'])
        .register(z.globalRegistry, {
          description: 'The aspect ratio of the generated video',
        }),
    ),
    duration: z.optional(
      z.union([z.literal(5), z.literal(10)]).register(z.globalRegistry, {
        description: 'The duration of the generated video in seconds',
      }),
    ),
    ingredients_mode: z.optional(
      z.enum(['precise', 'creative']).register(z.globalRegistry, {
        description:
          'Mode for integrating multiple images. Precise mode is more accurate, creative mode is more creative.',
      }),
    ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the random number generator',
      }),
    ),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description: 'URLs of images to combine into a video',
    }),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'A negative prompt to guide the model',
        }),
      )
      .default('ugly, bad, terrible'),
  })
  .register(z.globalRegistry, {
    description:
      'Request model for Pika 2.2 Pikascenes (collection-to-video) generation',
  })

/**
 * TurboImageToVideoOutput
 *
 * Output model for all video generation endpoints
 */
export const zSchemaPikaV2TurboImageToVideoOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output model for all video generation endpoints',
  })

/**
 * ImageToVideoTurboInput
 *
 * Base request for image-to-video generation
 */
export const zSchemaPikaV2TurboImageToVideoInput = z
  .object({
    prompt: z.string(),
    resolution: z.optional(
      z.enum(['720p', '1080p']).register(z.globalRegistry, {
        description: 'The resolution of the generated video',
      }),
    ),
    duration: z
      .optional(
        z.int().register(z.globalRegistry, {
          description: 'The duration of the generated video in seconds',
        }),
      )
      .default(5),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the random number generator',
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'A negative prompt to guide the model',
        }),
      )
      .default(''),
    image_url: z.union([z.string(), z.string()]),
  })
  .register(z.globalRegistry, {
    description: 'Base request for image-to-video generation',
  })

/**
 * PikaffectsOutput
 *
 * Output from Pikaffects generation
 */
export const zSchemaPikaV15PikaffectsOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output from Pikaffects generation',
  })

/**
 * PikaffectsRequest
 *
 * Request model for Pikaffects endpoint
 */
export const zSchemaPikaV15PikaffectsInput = z
  .object({
    pikaffect: z
      .enum([
        'Cake-ify',
        'Crumble',
        'Crush',
        'Decapitate',
        'Deflate',
        'Dissolve',
        'Explode',
        'Eye-pop',
        'Inflate',
        'Levitate',
        'Melt',
        'Peel',
        'Poke',
        'Squish',
        'Ta-da',
        'Tear',
      ])
      .register(z.globalRegistry, {
        description: 'The Pikaffect to apply',
      }),
    prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'Text prompt to guide the effect',
      }),
    ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the random number generator',
      }),
    ),
    negative_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to guide the model',
      }),
    ),
    image_url: z.union([z.string(), z.string()]),
  })
  .register(z.globalRegistry, {
    description: 'Request model for Pikaffects endpoint',
  })

/**
 * Ray2I2VOutput
 */
export const zSchemaLumaDreamMachineRay2FlashImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Ray2ImageToVideoRequest
 */
export const zSchemaLumaDreamMachineRay2FlashImageToVideoInput = z.object({
  prompt: z.string().min(3).max(5000),
  aspect_ratio: z.optional(
    z
      .enum(['16:9', '9:16', '4:3', '3:4', '21:9', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video',
      }),
  ),
  resolution: z.optional(
    z.enum(['540p', '720p', '1080p']).register(z.globalRegistry, {
      description:
        'The resolution of the generated video (720p costs 2x more, 1080p costs 4x more)',
    }),
  ),
  loop: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether the video should loop (end of video is blended with the beginning)',
      }),
    )
    .default(false),
  duration: z.optional(
    z.enum(['5s', '9s']).register(z.globalRegistry, {
      description: 'The duration of the generated video',
    }),
  ),
  image_url: z.optional(z.union([z.string(), z.string()])),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
})

/**
 * TransitionOutput
 */
export const zSchemaPixverseV35TransitionOutput = z.object({
  video: zSchemaFile,
})

/**
 * TransitionRequest
 */
export const zSchemaPixverseV35TransitionInput = z.object({
  first_image_url: z.union([z.string(), z.string()]),
  aspect_ratio: z.optional(
    z.enum(['16:9', '4:3', '1:1', '3:4', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt for the transition',
  }),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * EffectOutput
 */
export const zSchemaPixverseV35EffectsOutput = z.object({
  video: zSchemaFile,
})

/**
 * EffectInput
 */
export const zSchemaPixverseV35EffectsInput = z.object({
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  effect: z
    .enum([
      'Kiss Me AI',
      'Kiss',
      'Muscle Surge',
      'Warmth of Jesus',
      'Anything, Robot',
      'The Tiger Touch',
      'Hug',
      'Holy Wings',
      'Microwave',
      'Zombie Mode',
      'Squid Game',
      'Baby Face',
      'Black Myth: Wukong',
      'Long Hair Magic',
      'Leggy Run',
      'Fin-tastic Mermaid',
      'Punch Face',
      'Creepy Devil Smile',
      'Thunder God',
      'Eye Zoom Challenge',
      "Who's Arrested?",
      'Baby Arrived',
      'Werewolf Rage',
      'Bald Swipe',
      'BOOM DROP',
      'Huge Cutie',
      'Liquid Metal',
      'Sharksnap!',
      'Dust Me Away',
      '3D Figurine Factor',
      'Bikini Up',
      'My Girlfriends',
      'My Boyfriends',
      'Subject 3 Fever',
      'Earth Zoom',
      'Pole Dance',
      'Vroom Dance',
      'GhostFace Terror',
      'Dragon Evoker',
      'Skeletal Bae',
      'Summoning succubus',
      'Halloween Voodoo Doll',
      '3D Naked-Eye AD',
      'Package Explosion',
      'Dishes Served',
      'Ocean ad',
      'Supermarket AD',
      'Tree doll',
      'Come Feel My Abs',
      'The Bicep Flex',
      'London Elite Vibe',
      'Flora Nymph Gown',
      'Christmas Costume',
      "It's Snowy",
      'Reindeer Cruiser',
      'Snow Globe Maker',
      'Pet Christmas Outfit',
      'Adopt a Polar Pal',
      'Cat Christmas Box',
      'Starlight Gift Box',
      'Xmas Poster',
      'Pet Christmas Tree',
      'City Santa Hat',
      'Stocking Sweetie',
      'Christmas Night',
      'Xmas Front Page Karma',
      "Grinch's Xmas Hijack",
      'Giant Product',
      'Truck Fashion Shoot',
      'Beach AD',
      'Shoal Surround',
      'Mechanical Assembly',
      'Lighting AD',
      'Billboard AD',
      'Product close-up',
      'Parachute Delivery',
      'Dreamlike Cloud',
      'Macaron Machine',
      'Poster AD',
      'Truck AD',
      'Graffiti AD',
      '3D Figurine Factory',
      'The Exclusive First Class',
      'Art Zoom Challenge',
      'I Quit',
      'Hitchcock Dolly Zoom',
      'Smell the Lens',
      'I believe I can fly',
      'Strikout Dance',
      'Pixel World',
      'Mint in Box',
      'Hands up, Hand',
      'Flora Nymph Go',
      'Somber Embrace',
      'Beam me up',
      'Suit Swagger',
    ])
    .register(z.globalRegistry, {
      description: 'The effect to apply to the video',
    }),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * I2VOutputV4
 */
export const zSchemaPixverseV4ImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoRequestV4
 */
export const zSchemaPixverseV4ImageToVideoInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description:
        'The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  camera_movement: z.optional(
    z
      .enum([
        'horizontal_left',
        'horizontal_right',
        'vertical_up',
        'vertical_down',
        'zoom_in',
        'zoom_out',
        'crane_up',
        'quickly_zoom_in',
        'quickly_zoom_out',
        'smooth_zoom_in',
        'camera_rotation',
        'robo_arm',
        'super_dolly_out',
        'whip_pan',
        'hitchcock',
        'left_follow',
        'right_follow',
        'pan_left',
        'pan_right',
        'fix_bg',
      ])
      .register(z.globalRegistry, {
        description: 'The type of camera movement to apply to the video',
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * I2VOutputV4
 */
export const zSchemaPixverseV4ImageToVideoFastOutput = z.object({
  video: zSchemaFile,
})

/**
 * FastImageToVideoRequestV4
 */
export const zSchemaPixverseV4ImageToVideoFastInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  camera_movement: z.optional(
    z
      .enum([
        'horizontal_left',
        'horizontal_right',
        'vertical_up',
        'vertical_down',
        'zoom_in',
        'zoom_out',
        'crane_up',
        'quickly_zoom_in',
        'quickly_zoom_out',
        'smooth_zoom_in',
        'camera_rotation',
        'robo_arm',
        'super_dolly_out',
        'whip_pan',
        'hitchcock',
        'left_follow',
        'right_follow',
        'pan_left',
        'pan_right',
        'fix_bg',
      ])
      .register(z.globalRegistry, {
        description: 'The type of camera movement to apply to the video',
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * FramePackResponse
 */
export const zSchemaFramepackOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generating the video.',
  }),
  video: zSchemaFile,
})

/**
 * FramePackRequest
 */
export const zSchemaFramepackInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt for video generation (max 500 characters).',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the video to generate.',
    }),
  ),
  resolution: z.optional(
    z.enum(['720p', '480p']).register(z.globalRegistry, {
      description:
        'The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(30).lte(900).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(180),
  image_url: z.union([z.string(), z.string()]),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(32).register(z.globalRegistry, {
        description: 'Guidance scale for the generation.',
      }),
    )
    .default(10),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(''),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(7).register(z.globalRegistry, {
        description: 'Classifier-Free Guidance scale for the generation.',
      }),
    )
    .default(1),
})

/**
 * WanFLF2VResponse
 */
export const zSchemaWanFlf2vOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanFLF2VRequest
 */
export const zSchemaWanFlf2vInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  frames_per_second: z
    .optional(
      z.int().gte(5).lte(24).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 5 to 24.',
      }),
    )
    .default(16),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  start_image_url: z.union([z.string(), z.string()]),
  end_image_url: z.union([z.string(), z.string()]),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  num_frames: z
    .optional(
      z.int().gte(81).lte(100).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 100 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.',
      }),
    )
    .default(81),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  guide_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(5),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
})

/**
 * FramePackFLF2VResponse
 */
export const zSchemaFramepackFlf2vOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generating the video.',
  }),
  video: zSchemaFile,
})

/**
 * FramePackF2LFRequest
 */
export const zSchemaFramepackFlf2vInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt for video generation (max 500 characters).',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the video to generate.',
    }),
  ),
  resolution: z.optional(
    z.enum(['720p', '480p']).register(z.globalRegistry, {
      description:
        'The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(30).lte(1800).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(240),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  image_url: z.union([z.string(), z.string()]),
  strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Determines the influence of the final frame on the generated video. Higher values result in the output being more heavily influenced by the last frame.',
      }),
    )
    .default(0.8),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(32).register(z.globalRegistry, {
        description: 'Guidance scale for the generation.',
      }),
    )
    .default(10),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  end_image_url: z.union([z.string(), z.string()]),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(''),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(7).register(z.globalRegistry, {
        description: 'Classifier-Free Guidance scale for the generation.',
      }),
    )
    .default(1),
})

/**
 * MagiImageToVideoResponse
 */
export const zSchemaMagiDistilledImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * MagiImageToVideoRequest
 */
export const zSchemaMagiDistilledImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z.optional(
    z
      .union([z.literal(4), z.literal(8), z.literal(16), z.literal(32)])
      .register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(96).lte(192).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.',
      }),
    )
    .default(96),
})

/**
 * EffectOutput
 */
export const zSchemaPixverseV4EffectsOutput = z.object({
  video: zSchemaFile,
})

/**
 * EffectInput
 */
export const zSchemaPixverseV4EffectsInput = z.object({
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  effect: z
    .enum([
      'Kiss Me AI',
      'Kiss',
      'Muscle Surge',
      'Warmth of Jesus',
      'Anything, Robot',
      'The Tiger Touch',
      'Hug',
      'Holy Wings',
      'Microwave',
      'Zombie Mode',
      'Squid Game',
      'Baby Face',
      'Black Myth: Wukong',
      'Long Hair Magic',
      'Leggy Run',
      'Fin-tastic Mermaid',
      'Punch Face',
      'Creepy Devil Smile',
      'Thunder God',
      'Eye Zoom Challenge',
      "Who's Arrested?",
      'Baby Arrived',
      'Werewolf Rage',
      'Bald Swipe',
      'BOOM DROP',
      'Huge Cutie',
      'Liquid Metal',
      'Sharksnap!',
      'Dust Me Away',
      '3D Figurine Factor',
      'Bikini Up',
      'My Girlfriends',
      'My Boyfriends',
      'Subject 3 Fever',
      'Earth Zoom',
      'Pole Dance',
      'Vroom Dance',
      'GhostFace Terror',
      'Dragon Evoker',
      'Skeletal Bae',
      'Summoning succubus',
      'Halloween Voodoo Doll',
      '3D Naked-Eye AD',
      'Package Explosion',
      'Dishes Served',
      'Ocean ad',
      'Supermarket AD',
      'Tree doll',
      'Come Feel My Abs',
      'The Bicep Flex',
      'London Elite Vibe',
      'Flora Nymph Gown',
      'Christmas Costume',
      "It's Snowy",
      'Reindeer Cruiser',
      'Snow Globe Maker',
      'Pet Christmas Outfit',
      'Adopt a Polar Pal',
      'Cat Christmas Box',
      'Starlight Gift Box',
      'Xmas Poster',
      'Pet Christmas Tree',
      'City Santa Hat',
      'Stocking Sweetie',
      'Christmas Night',
      'Xmas Front Page Karma',
      "Grinch's Xmas Hijack",
      'Giant Product',
      'Truck Fashion Shoot',
      'Beach AD',
      'Shoal Surround',
      'Mechanical Assembly',
      'Lighting AD',
      'Billboard AD',
      'Product close-up',
      'Parachute Delivery',
      'Dreamlike Cloud',
      'Macaron Machine',
      'Poster AD',
      'Truck AD',
      'Graffiti AD',
      '3D Figurine Factory',
      'The Exclusive First Class',
      'Art Zoom Challenge',
      'I Quit',
      'Hitchcock Dolly Zoom',
      'Smell the Lens',
      'I believe I can fly',
      'Strikout Dance',
      'Pixel World',
      'Mint in Box',
      'Hands up, Hand',
      'Flora Nymph Go',
      'Somber Embrace',
      'Beam me up',
      'Suit Swagger',
    ])
    .register(z.globalRegistry, {
      description: 'The effect to apply to the video',
    }),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * MagiImageToVideoResponse
 */
export const zSchemaMagiImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * MagiImageToVideoRequest
 */
export const zSchemaMagiImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z.optional(
    z
      .union([
        z.literal(4),
        z.literal(8),
        z.literal(16),
        z.literal(32),
        z.literal(64),
      ])
      .register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(96).lte(192).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.',
      }),
    )
    .default(96),
})

/**
 * Q1ImageToVideoOutput
 */
export const zSchemaViduQ1ImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Q1ImageToVideoRequest
 */
export const zSchemaViduQ1ImageToVideoInput = z.object({
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text prompt for video generation, max 1500 characters',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Seed for the random number generator',
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(['auto', 'small', 'medium', 'large']).register(z.globalRegistry, {
      description: 'The movement amplitude of objects in the frame',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * Q1StartEndToVideoOutput
 */
export const zSchemaViduQ1StartEndToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Q1StartEndToVideoRequest
 */
export const zSchemaViduQ1StartEndToVideoInput = z.object({
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text prompt for video generation, max 1500 characters',
  }),
  start_image_url: z.union([z.string(), z.string()]),
  movement_amplitude: z.optional(
    z.enum(['auto', 'small', 'medium', 'large']).register(z.globalRegistry, {
      description: 'The movement amplitude of objects in the frame',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Seed for the random number generator',
    }),
  ),
  end_image_url: z.union([z.string(), z.string()]),
})

/**
 * FramePackF1Response
 */
export const zSchemaFramepackF1Output = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generating the video.',
  }),
  video: zSchemaFile,
})

/**
 * FramePackF1Request
 */
export const zSchemaFramepackF1Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt for video generation (max 500 characters).',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the video to generate.',
    }),
  ),
  resolution: z.optional(
    z.enum(['720p', '480p']).register(z.globalRegistry, {
      description:
        'The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(30).lte(900).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(180),
  image_url: z.union([z.string(), z.string()]),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(32).register(z.globalRegistry, {
        description: 'Guidance scale for the generation.',
      }),
    )
    .default(10),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(''),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(7).register(z.globalRegistry, {
        description: 'Classifier-Free Guidance scale for the generation.',
      }),
    )
    .default(1),
})

/**
 * HunyuanCustomResponse
 */
export const zSchemaHunyuanCustomOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generating the video.',
  }),
  video: zSchemaFile,
})

/**
 * HunyuanCustomRequest
 */
export const zSchemaHunyuanCustomInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt for video generation (max 500 characters).',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the video to generate.',
    }),
  ),
  resolution: z.optional(
    z.enum(['512p', '720p']).register(z.globalRegistry, {
      description:
        'The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(81).lte(129).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(129),
  image_url: z.union([z.string(), z.string()]),
  fps: z
    .optional(
      z.int().gte(16).lte(30).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for generating the video.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(10).lte(30).register(z.globalRegistry, {
        description:
          'The number of inference steps to run. Lower gets faster results, higher gets better results.',
      }),
    )
    .default(30),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion, blurring, text, subtitles, static, picture, black border.',
    ),
  cfg_scale: z
    .optional(
      z.number().gte(1.5).lte(13).register(z.globalRegistry, {
        description: 'Classifier-Free Guidance scale for the generation.',
      }),
    )
    .default(7.5),
})

/**
 * EffectOutput
 */
export const zSchemaPixverseV45EffectsOutput = z.object({
  video: zSchemaFile,
})

/**
 * EffectInput
 */
export const zSchemaPixverseV45EffectsInput = z.object({
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  effect: z
    .enum([
      'Kiss Me AI',
      'Kiss',
      'Muscle Surge',
      'Warmth of Jesus',
      'Anything, Robot',
      'The Tiger Touch',
      'Hug',
      'Holy Wings',
      'Microwave',
      'Zombie Mode',
      'Squid Game',
      'Baby Face',
      'Black Myth: Wukong',
      'Long Hair Magic',
      'Leggy Run',
      'Fin-tastic Mermaid',
      'Punch Face',
      'Creepy Devil Smile',
      'Thunder God',
      'Eye Zoom Challenge',
      "Who's Arrested?",
      'Baby Arrived',
      'Werewolf Rage',
      'Bald Swipe',
      'BOOM DROP',
      'Huge Cutie',
      'Liquid Metal',
      'Sharksnap!',
      'Dust Me Away',
      '3D Figurine Factor',
      'Bikini Up',
      'My Girlfriends',
      'My Boyfriends',
      'Subject 3 Fever',
      'Earth Zoom',
      'Pole Dance',
      'Vroom Dance',
      'GhostFace Terror',
      'Dragon Evoker',
      'Skeletal Bae',
      'Summoning succubus',
      'Halloween Voodoo Doll',
      '3D Naked-Eye AD',
      'Package Explosion',
      'Dishes Served',
      'Ocean ad',
      'Supermarket AD',
      'Tree doll',
      'Come Feel My Abs',
      'The Bicep Flex',
      'London Elite Vibe',
      'Flora Nymph Gown',
      'Christmas Costume',
      "It's Snowy",
      'Reindeer Cruiser',
      'Snow Globe Maker',
      'Pet Christmas Outfit',
      'Adopt a Polar Pal',
      'Cat Christmas Box',
      'Starlight Gift Box',
      'Xmas Poster',
      'Pet Christmas Tree',
      'City Santa Hat',
      'Stocking Sweetie',
      'Christmas Night',
      'Xmas Front Page Karma',
      "Grinch's Xmas Hijack",
      'Giant Product',
      'Truck Fashion Shoot',
      'Beach AD',
      'Shoal Surround',
      'Mechanical Assembly',
      'Lighting AD',
      'Billboard AD',
      'Product close-up',
      'Parachute Delivery',
      'Dreamlike Cloud',
      'Macaron Machine',
      'Poster AD',
      'Truck AD',
      'Graffiti AD',
      '3D Figurine Factory',
      'The Exclusive First Class',
      'Art Zoom Challenge',
      'I Quit',
      'Hitchcock Dolly Zoom',
      'Smell the Lens',
      'I believe I can fly',
      'Strikout Dance',
      'Pixel World',
      'Mint in Box',
      'Hands up, Hand',
      'Flora Nymph Go',
      'Somber Embrace',
      'Beam me up',
      'Suit Swagger',
    ])
    .register(z.globalRegistry, {
      description: 'The effect to apply to the video',
    }),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * I2VOutputV4
 */
export const zSchemaPixverseV45ImageToVideoFastOutput = z.object({
  video: zSchemaFile,
})

/**
 * FastImageToVideoRequestV4
 */
export const zSchemaPixverseV45ImageToVideoFastInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  camera_movement: z.optional(
    z
      .enum([
        'horizontal_left',
        'horizontal_right',
        'vertical_up',
        'vertical_down',
        'zoom_in',
        'zoom_out',
        'crane_up',
        'quickly_zoom_in',
        'quickly_zoom_out',
        'smooth_zoom_in',
        'camera_rotation',
        'robo_arm',
        'super_dolly_out',
        'whip_pan',
        'hitchcock',
        'left_follow',
        'right_follow',
        'pan_left',
        'pan_right',
        'fix_bg',
      ])
      .register(z.globalRegistry, {
        description: 'The type of camera movement to apply to the video',
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * TransitionOutput
 */
export const zSchemaPixverseV45TransitionOutput = z.object({
  video: zSchemaFile,
})

/**
 * TransitionRequest
 */
export const zSchemaPixverseV45TransitionInput = z.object({
  first_image_url: z.union([z.string(), z.string()]),
  aspect_ratio: z.optional(
    z.enum(['16:9', '4:3', '1:1', '3:4', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt for the transition',
  }),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * ImageToVideoOutput
 */
export const zSchemaLtxVideoLoraImageToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * ImageToVideoInput
 *
 * Request model for image-to-video generation.
 */
export const zSchemaLtxVideoLoraImageToVideoInput = z
  .object({
    number_of_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to use.',
        }),
      )
      .default(30),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description: 'The resolution of the video.',
      }),
    ),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to reverse the video.',
        }),
      )
      .default(false),
    aspect_ratio: z.optional(
      z.enum(['16:9', '1:1', '9:16', 'auto']).register(z.globalRegistry, {
        description: 'The aspect ratio of the video.',
      }),
    ),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: 'The frame rate of the video.',
        }),
      )
      .default(25),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to expand the prompt using the LLM.',
        }),
      )
      .default(false),
    number_of_frames: z
      .optional(
        z.int().gte(9).lte(161).register(z.globalRegistry, {
          description: 'The number of frames in the video.',
        }),
      )
      .default(89),
    image_url: z.union([z.string(), z.string()]),
    loras: z
      .optional(
        z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
          description: 'The LoRA weights to use for generation.',
        }),
      )
      .default([]),
    prompt: z.string().register(z.globalRegistry, {
      description: 'The prompt to generate the video from.',
    }),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable the safety checker.',
        }),
      )
      .default(true),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed to use for generation.',
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt to use.',
        }),
      )
      .default(
        'blurry, low quality, low resolution, inconsistent motion, jittery, distorted',
      ),
  })
  .register(z.globalRegistry, {
    description: 'Request model for image-to-video generation.',
  })

/**
 * ImageToVideoOutput
 */
export const zSchemaLtxVideo13bDevImageToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * ImageToVideoInput
 */
export const zSchemaLtxVideo13bDevImageToVideoInput = z.object({
  second_pass_skip_initial_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description:
          'The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.',
      }),
    )
    .default(17),
  first_pass_num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps during the first pass.',
      }),
    )
    .default(30),
  frame_rate: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frame rate of the video.',
      }),
    )
    .default(30),
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt to guide generation',
  }),
  reverse_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to reverse the video.',
      }),
    )
    .default(false),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to expand the prompt using a language model.',
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
        description: 'LoRA weights to use for generation',
      }),
    )
    .default([]),
  second_pass_num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps during the second pass.',
      }),
    )
    .default(30),
  num_frames: z
    .optional(
      z.int().gte(9).lte(161).register(z.globalRegistry, {
        description: 'The number of frames in the video.',
      }),
    )
    .default(121),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for generation',
      }),
    )
    .default('worst quality, inconsistent motion, blurry, jittery, distorted'),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['9:16', '1:1', '16:9', 'auto']).register(z.globalRegistry, {
      description: 'The aspect ratio of the video.',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  constant_rate_factor: z
    .optional(
      z.int().gte(20).lte(60).register(z.globalRegistry, {
        description:
          "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
      }),
    )
    .default(35),
  first_pass_skip_final_steps: z
    .optional(
      z.int().gte(0).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.',
      }),
    )
    .default(3),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
})

/**
 * ImageToVideoOutput
 */
export const zSchemaLtxVideo13bDistilledImageToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * DistilledImageToVideoInput
 *
 * Distilled model input
 */
export const zSchemaLtxVideo13bDistilledImageToVideoInput = z
  .object({
    second_pass_skip_initial_steps: z
      .optional(
        z.int().gte(1).lte(20).register(z.globalRegistry, {
          description:
            'The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.',
        }),
      )
      .default(5),
    first_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(20).register(z.globalRegistry, {
          description: 'Number of inference steps during the first pass.',
        }),
      )
      .default(8),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: 'The frame rate of the video.',
        }),
      )
      .default(30),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to reverse the video.',
        }),
      )
      .default(false),
    prompt: z.string().register(z.globalRegistry, {
      description: 'Text prompt to guide generation',
    }),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to expand the prompt using a language model.',
        }),
      )
      .default(false),
    loras: z
      .optional(
        z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
          description: 'LoRA weights to use for generation',
        }),
      )
      .default([]),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable the safety checker.',
        }),
      )
      .default(true),
    num_frames: z
      .optional(
        z.int().gte(9).lte(161).register(z.globalRegistry, {
          description: 'The number of frames in the video.',
        }),
      )
      .default(121),
    second_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(20).register(z.globalRegistry, {
          description: 'Number of inference steps during the second pass.',
        }),
      )
      .default(8),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'Negative prompt for generation',
        }),
      )
      .default(
        'worst quality, inconsistent motion, blurry, jittery, distorted',
      ),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description: 'Resolution of the generated video (480p or 720p).',
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(['9:16', '1:1', '16:9', 'auto']).register(z.globalRegistry, {
        description: 'The aspect ratio of the video.',
      }),
    ),
    image_url: z.union([z.string(), z.string()]),
    constant_rate_factor: z
      .optional(
        z.int().gte(20).lte(60).register(z.globalRegistry, {
          description:
            "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        }),
      )
      .default(35),
    first_pass_skip_final_steps: z
      .optional(
        z.int().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.',
        }),
      )
      .default(1),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'Random seed for generation',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Distilled model input',
  })

/**
 * ElementsOutput
 */
export const zSchemaKlingVideoV16ProElementsOutput = z.object({
  video: zSchemaFile,
})

/**
 * MultiImageToVideoRequest
 */
export const zSchemaKlingVideoV16ProElementsInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video frame',
    }),
  ),
  input_image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'List of image URLs to use for video generation. Supports up to 4 images.',
  }),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
})

/**
 * ElementsOutput
 */
export const zSchemaKlingVideoV16StandardElementsOutput = z.object({
  video: zSchemaFile,
})

/**
 * MultiImageToVideoRequest
 */
export const zSchemaKlingVideoV16StandardElementsInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video frame',
    }),
  ),
  input_image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'List of image URLs to use for video generation. Supports up to 4 images.',
  }),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
})

/**
 * Output
 */
export const zSchemaHunyuanPortraitOutput = z.object({
  video: zSchemaFile,
})

/**
 * Input
 */
export const zSchemaHunyuanPortraitInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for generation. If None, a random seed will be used.',
    }),
  ),
  use_arcface: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to use ArcFace for face recognition.',
      }),
    )
    .default(true),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * ImageToVideoV21ProOutput
 */
export const zSchemaKlingVideoV21ProImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoV21ProRequest
 */
export const zSchemaKlingVideoV21ProImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  tail_image_url: z.optional(z.union([z.string(), z.string()])),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * Output
 */
export const zSchemaHunyuanAvatarOutput = z.object({
  video: zSchemaFile,
})

/**
 * Input
 */
export const zSchemaHunyuanAvatarInput = z.object({
  text: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Text prompt describing the scene.',
      }),
    )
    .default('A cat is singing.'),
  image_url: z.union([z.string(), z.string()]),
  turbo_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the video will be generated faster with no noticeable degradation in the visual quality.',
      }),
    )
    .default(true),
  audio_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(30).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  num_frames: z
    .optional(
      z.int().gte(129).lte(401).register(z.globalRegistry, {
        description:
          'Number of video frames to generate at 25 FPS. If greater than the input audio length, it will capped to the length of the input audio.',
      }),
    )
    .default(129),
})

/**
 * SeedanceVideoOutput
 */
export const zSchemaBytedanceSeedanceV1LiteImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generation',
  }),
  video: zSchemaFile,
})

/**
 * SeedanceImageToVideoInput
 */
export const zSchemaBytedanceSeedanceV1LiteImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt used to generate the video',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p', '1080p']).register(z.globalRegistry, {
      description:
        'Video resolution - 480p for faster generation, 720p for higher quality',
    }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '1:1', '3:4', '9:16', 'auto'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video',
      }),
  ),
  duration: z.optional(
    z
      .enum(['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'])
      .register(z.globalRegistry, {
        description: 'Duration of the video in seconds',
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  camera_fixed: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to fix the camera position',
      }),
    )
    .default(false),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed to control video generation. Use -1 for random.',
    }),
  ),
})

/**
 * ImageToVideoHailuo02Output
 */
export const zSchemaMinimaxHailuo02ProImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ProImageToVideoHailuo02Input
 */
export const zSchemaMinimaxHailuo02ProImageToVideoInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  prompt: z.string().max(2000),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * AvatarMultiAudioResponse
 */
export const zSchemaAiAvatarMultiOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * AvatarMultiAudioPersonRequest
 */
export const zSchemaAiAvatarMultiInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the video to generate. Must be either 480p or 720p.',
    }),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use for generation.',
    }),
  ),
  first_audio_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
  second_audio_url: z.optional(z.union([z.string(), z.string()])),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    )
    .default(81),
  use_only_first_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to use only the first audio file.',
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(41).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.',
      }),
    )
    .default(181),
})

/**
 * AvatarMultiTextResponse
 */
export const zSchemaAiAvatarMultiTextOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * AvatarMultiTextRequest
 */
export const zSchemaAiAvatarMultiTextInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  second_text_input: z.string().register(z.globalRegistry, {
    description: 'The text input to guide video generation.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use for generation.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the video to generate. Must be either 480p or 720p.',
    }),
  ),
  first_text_input: z.string().register(z.globalRegistry, {
    description: 'The text input to guide video generation.',
  }),
  image_url: z.union([z.string(), z.string()]),
  voice2: z.optional(
    z
      .enum([
        'Aria',
        'Roger',
        'Sarah',
        'Laura',
        'Charlie',
        'George',
        'Callum',
        'River',
        'Liam',
        'Charlotte',
        'Alice',
        'Matilda',
        'Will',
        'Jessica',
        'Eric',
        'Chris',
        'Brian',
        'Daniel',
        'Lily',
        'Bill',
      ])
      .register(z.globalRegistry, {
        description: "The second person's voice to use for speech generation",
      }),
  ),
  voice1: z.optional(
    z
      .enum([
        'Aria',
        'Roger',
        'Sarah',
        'Laura',
        'Charlie',
        'George',
        'Callum',
        'River',
        'Liam',
        'Charlotte',
        'Alice',
        'Matilda',
        'Will',
        'Jessica',
        'Eric',
        'Chris',
        'Brian',
        'Daniel',
        'Lily',
        'Bill',
      ])
      .register(z.globalRegistry, {
        description: "The first person's voice to use for speech generation",
      }),
  ),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    )
    .default(81),
  num_frames: z
    .optional(
      z.int().gte(41).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.',
      }),
    )
    .default(191),
})

/**
 * AvatarSingleAudioResponse
 */
export const zSchemaAiAvatarOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * AvatarSingleAudioRequest
 */
export const zSchemaAiAvatarInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the video to generate. Must be either 480p or 720p.',
    }),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use for generation.',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  audio_url: z.union([z.string(), z.string()]),
  num_frames: z
    .optional(
      z.int().gte(41).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.',
      }),
    )
    .default(145),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    )
    .default(42),
})

/**
 * AvatarSingleTextResponse
 */
export const zSchemaAiAvatarSingleTextOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * AvatarSingleTextRequest
 */
export const zSchemaAiAvatarSingleTextInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the video to generate. Must be either 480p or 720p.',
    }),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use for generation.',
    }),
  ),
  text_input: z.string().register(z.globalRegistry, {
    description: 'The text input to guide video generation.',
  }),
  image_url: z.union([z.string(), z.string()]),
  voice: z
    .enum([
      'Aria',
      'Roger',
      'Sarah',
      'Laura',
      'Charlie',
      'George',
      'Callum',
      'River',
      'Liam',
      'Charlotte',
      'Alice',
      'Matilda',
      'Will',
      'Jessica',
      'Eric',
      'Chris',
      'Brian',
      'Daniel',
      'Lily',
      'Bill',
    ])
    .register(z.globalRegistry, {
      description: 'The voice to use for speech generation',
    }),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    )
    .default(42),
  num_frames: z
    .optional(
      z.int().gte(41).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.',
      }),
    )
    .default(136),
})

/**
 * Q1ReferenceToVideoOutput
 */
export const zSchemaViduQ1ReferenceToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Q1ReferenceToVideoRequest
 */
export const zSchemaViduQ1ReferenceToVideoInput = z.object({
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text prompt for video generation, max 1500 characters',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the output video',
    }),
  ),
  bgm: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to add background music to the generated video',
      }),
    )
    .default(false),
  reference_image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'URLs of the reference images to use for consistent subject appearance. Q1 model supports up to 7 reference images.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(['auto', 'small', 'medium', 'large']).register(z.globalRegistry, {
      description: 'The movement amplitude of objects in the frame',
    }),
  ),
})

/**
 * Veo3ImageToVideoOutput
 */
export const zSchemaVeo3FastImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Veo3ImageToVideoInput
 */
export const zSchemaVeo3FastImageToVideoInput = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: 'The text prompt describing how the image should be animated',
  }),
  resolution: z.optional(
    z.enum(['720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.',
      }),
    )
    .default(false),
  duration: z.optional(
    z.enum(['4s', '6s', '8s']).register(z.globalRegistry, {
      description: 'The duration of the generated video.',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * ImageToVideoOutput
 */
export const zSchemaLtxv13B098DistilledImageToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * DistilledImageToVideoInput
 *
 * Distilled model input
 */
export const zSchemaLtxv13B098DistilledImageToVideoInput = z
  .object({
    second_pass_skip_initial_steps: z
      .optional(
        z.int().gte(1).lte(11).register(z.globalRegistry, {
          description:
            'The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.',
        }),
      )
      .default(5),
    first_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(12).register(z.globalRegistry, {
          description: 'Number of inference steps during the first pass.',
        }),
      )
      .default(8),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: 'The frame rate of the video.',
        }),
      )
      .default(24),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to reverse the video.',
        }),
      )
      .default(false),
    prompt: z.string().register(z.globalRegistry, {
      description: 'Text prompt to guide generation',
    }),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to expand the prompt using a language model.',
        }),
      )
      .default(false),
    temporal_adain_factor: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            'The factor for adaptive instance normalization (AdaIN) applied to generated video chunks after the first. This can help deal with a gradual increase in saturation/contrast in the generated video by normalizing the color distribution across the video. A high value will ensure the color distribution is more consistent across the video, while a low value will allow for more variation in color distribution.',
        }),
      )
      .default(0.5),
    loras: z
      .optional(
        z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
          description: 'LoRA weights to use for generation',
        }),
      )
      .default([]),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable the safety checker.',
        }),
      )
      .default(true),
    num_frames: z
      .optional(
        z.int().gte(9).lte(1441).register(z.globalRegistry, {
          description: 'The number of frames in the video.',
        }),
      )
      .default(121),
    second_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(12).register(z.globalRegistry, {
          description: 'Number of inference steps during the second pass.',
        }),
      )
      .default(8),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'Negative prompt for generation',
        }),
      )
      .default(
        'worst quality, inconsistent motion, blurry, jittery, distorted',
      ),
    enable_detail_pass: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to use a detail pass. If True, the model will perform a second pass to refine the video and enhance details. This incurs a 2.0x cost multiplier on the base price.',
        }),
      )
      .default(false),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(['9:16', '1:1', '16:9', 'auto']).register(z.globalRegistry, {
        description: 'The aspect ratio of the video.',
      }),
    ),
    tone_map_compression_ratio: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            'The compression ratio for tone mapping. This is used to compress the dynamic range of the video to improve visual quality. A value of 0.0 means no compression, while a value of 1.0 means maximum compression.',
        }),
      )
      .default(0),
    image_url: z.union([z.string(), z.string()]),
    constant_rate_factor: z
      .optional(
        z.int().gte(0).lte(51).register(z.globalRegistry, {
          description:
            "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        }),
      )
      .default(29),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'Random seed for generation',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Distilled model input',
  })

/**
 * OmniHumanOutput
 */
export const zSchemaBytedanceOmnihumanOutput = z.object({
  duration: z.number().register(z.globalRegistry, {
    description: 'Duration of audio input/video output as used for billing.',
  }),
  video: zSchemaFile,
})

/**
 * OmniHumanInput
 */
export const zSchemaBytedanceOmnihumanInput = z.object({
  audio_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * WanI2VResponse
 */
export const zSchemaWanV22A14bImageToVideoOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The text prompt used for video generation.',
      }),
    )
    .default(''),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanI2VRequest
 */
export const zSchemaWanV22A14bImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift value for the video. Must be between 1.0 and 10.0.',
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(4).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.',
      }),
    )
    .default(1),
  frames_per_second: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.',
      }),
    )
    .default(16),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(3.5),
  num_frames: z
    .optional(
      z.int().gte(17).lte(161).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 17 to 161 (inclusive).',
      }),
    )
    .default(81),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(''),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, input data will be checked for safety before processing.',
      }),
    )
    .default(false),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description:
        'The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p, 580p, or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, output video will be checked for safety after generation.',
      }),
    )
    .default(false),
  image_url: z.union([z.string(), z.string()]),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description:
        'The quality of the output video. Higher quality means better visual quality but larger file size.',
    }),
  ),
  guidance_scale_2: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.',
      }),
    )
    .default(3.5),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  interpolator_model: z.optional(
    z.enum(['none', 'film', 'rife']).register(z.globalRegistry, {
      description:
        'The model to use for frame interpolation. If None, no interpolation is applied.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(27),
  adjust_fps_for_interpolation: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.',
      }),
    )
    .default(true),
})

/**
 * WanSmallI2VResponse
 */
export const zSchemaWanV225bImageToVideoOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The text prompt used for video generation.',
      }),
    )
    .default(''),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanSmallI2VRequest
 */
export const zSchemaWanV225bImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift value for the video. Must be between 1.0 and 10.0.',
      }),
    )
    .default(5),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(4).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.',
      }),
    )
    .default(0),
  frames_per_second: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.',
      }),
    )
    .default(24),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(3.5),
  num_frames: z
    .optional(
      z.int().gte(17).lte(161).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 17 to 161 (inclusive).',
      }),
    )
    .default(81),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, input data will be checked for safety before processing.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(''),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description:
        'The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.',
    }),
  ),
  resolution: z.optional(
    z.enum(['580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (580p or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, output video will be checked for safety after generation.',
      }),
    )
    .default(false),
  image_url: z.union([z.string(), z.string()]),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description:
        'The quality of the output video. Higher quality means better visual quality but larger file size.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(40),
  interpolator_model: z.optional(
    z.enum(['none', 'film', 'rife']).register(z.globalRegistry, {
      description:
        'The model to use for frame interpolation. If None, no interpolation is applied.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  adjust_fps_for_interpolation: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.',
      }),
    )
    .default(true),
})

/**
 * WanTurboI2VResponse
 */
export const zSchemaWanV22A14bImageToVideoTurboOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The text prompt used for video generation.',
      }),
    )
    .default(''),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanTurboI2VRequest
 */
export const zSchemaWanV22A14bImageToVideoTurboInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p, 580p, or 720p).',
    }),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description:
        'The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.',
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, output video will be checked for safety after generation.',
      }),
    )
    .default(false),
  image_url: z.union([z.string(), z.string()]),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description:
        'The quality of the output video. Higher quality means better visual quality but larger file size.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, input data will be checked for safety before processing.',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.',
      }),
    )
    .default(false),
})

/**
 * Veo3ImageToVideoOutput
 */
export const zSchemaVeo3ImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Veo3ImageToVideoInput
 */
export const zSchemaVeo3ImageToVideoInput = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: 'The text prompt describing how the image should be animated',
  }),
  resolution: z.optional(
    z.enum(['720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.',
      }),
    )
    .default(false),
  duration: z.optional(
    z.enum(['4s', '6s', '8s']).register(z.globalRegistry, {
      description: 'The duration of the generated video.',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * ImageToVideoHailuo02FastOutput
 */
export const zSchemaMinimaxHailuo02FastImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * FastImageToVideoHailuo02Input
 */
export const zSchemaMinimaxHailuo02FastImageToVideoInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  duration: z.optional(
    z.enum(['6', '10']).register(z.globalRegistry, {
      description:
        'The duration of the video in seconds. 10 seconds videos are not supported for 1080p resolution.',
    }),
  ),
  prompt: z.string().max(2000),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * WanI2VResponse
 */
export const zSchemaWanV22A14bImageToVideoLoraOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The text prompt used for video generation.',
      }),
    )
    .default(''),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanLoRAI2VRequest
 */
export const zSchemaWanV22A14bImageToVideoLoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift value for the video. Must be between 1.0 and 10.0.',
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(4).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.',
      }),
    )
    .default(1),
  reverse_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If true, the video will be reversed.',
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
        description: 'LoRA weights to be used in the inference.',
      }),
    )
    .default([]),
  frames_per_second: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.',
      }),
    )
    .default(16),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, input data will be checked for safety before processing.',
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(17).lte(161).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 17 to 161 (inclusive).',
      }),
    )
    .default(81),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(''),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(3.5),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description:
        'The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p, 580p, or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, output video will be checked for safety after generation.',
      }),
    )
    .default(false),
  image_url: z.union([z.string(), z.string()]),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description:
        'The quality of the output video. Higher quality means better visual quality but larger file size.',
    }),
  ),
  guidance_scale_2: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.',
      }),
    )
    .default(4),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(27),
  interpolator_model: z.optional(
    z.enum(['none', 'film', 'rife']).register(z.globalRegistry, {
      description:
        'The model to use for frame interpolation. If None, no interpolation is applied.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  adjust_fps_for_interpolation: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.',
      }),
    )
    .default(true),
})

export const zSchemaBytedanceVideoStylizeOutput = z.unknown()

/**
 * StylizeInput
 */
export const zSchemaBytedanceVideoStylizeInput = z.object({
  style: z.string().max(100).register(z.globalRegistry, {
    description:
      'The style for your character in the video. Please use a short description.',
  }),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * MareyOutput
 */
export const zSchemaMareyI2vOutput = z.object({
  video: zSchemaFile,
})

/**
 * MareyInputI2V
 */
export const zSchemaMareyI2vInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate a video from',
  }),
  duration: z.optional(
    z.enum(['5s', '10s']).register(z.globalRegistry, {
      description: 'The duration of the generated video.',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  dimensions: z.optional(
    z
      .enum(['1920x1080', '1080x1920', '1152x1152', '1536x1152', '1152x1536'])
      .register(z.globalRegistry, {
        description:
          'The dimensions of the generated video in width x height format.',
      }),
  ),
  guidance_scale: z.optional(z.union([z.number(), z.unknown()])),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  negative_prompt: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * I2VOutputV5
 */
export const zSchemaPixverseV5ImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoRequestV5
 */
export const zSchemaPixverseV5ImageToVideoInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description:
        'The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * EffectOutput
 */
export const zSchemaPixverseV5EffectsOutput = z.object({
  video: zSchemaFile,
})

/**
 * EffectInput
 */
export const zSchemaPixverseV5EffectsInput = z.object({
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  effect: z
    .enum([
      'Kiss Me AI',
      'Kiss',
      'Muscle Surge',
      'Warmth of Jesus',
      'Anything, Robot',
      'The Tiger Touch',
      'Hug',
      'Holy Wings',
      'Microwave',
      'Zombie Mode',
      'Squid Game',
      'Baby Face',
      'Black Myth: Wukong',
      'Long Hair Magic',
      'Leggy Run',
      'Fin-tastic Mermaid',
      'Punch Face',
      'Creepy Devil Smile',
      'Thunder God',
      'Eye Zoom Challenge',
      "Who's Arrested?",
      'Baby Arrived',
      'Werewolf Rage',
      'Bald Swipe',
      'BOOM DROP',
      'Huge Cutie',
      'Liquid Metal',
      'Sharksnap!',
      'Dust Me Away',
      '3D Figurine Factor',
      'Bikini Up',
      'My Girlfriends',
      'My Boyfriends',
      'Subject 3 Fever',
      'Earth Zoom',
      'Pole Dance',
      'Vroom Dance',
      'GhostFace Terror',
      'Dragon Evoker',
      'Skeletal Bae',
      'Summoning succubus',
      'Halloween Voodoo Doll',
      '3D Naked-Eye AD',
      'Package Explosion',
      'Dishes Served',
      'Ocean ad',
      'Supermarket AD',
      'Tree doll',
      'Come Feel My Abs',
      'The Bicep Flex',
      'London Elite Vibe',
      'Flora Nymph Gown',
      'Christmas Costume',
      "It's Snowy",
      'Reindeer Cruiser',
      'Snow Globe Maker',
      'Pet Christmas Outfit',
      'Adopt a Polar Pal',
      'Cat Christmas Box',
      'Starlight Gift Box',
      'Xmas Poster',
      'Pet Christmas Tree',
      'City Santa Hat',
      'Stocking Sweetie',
      'Christmas Night',
      'Xmas Front Page Karma',
      "Grinch's Xmas Hijack",
      'Giant Product',
      'Truck Fashion Shoot',
      'Beach AD',
      'Shoal Surround',
      'Mechanical Assembly',
      'Lighting AD',
      'Billboard AD',
      'Product close-up',
      'Parachute Delivery',
      'Dreamlike Cloud',
      'Macaron Machine',
      'Poster AD',
      'Truck AD',
      'Graffiti AD',
      '3D Figurine Factory',
      'The Exclusive First Class',
      'Art Zoom Challenge',
      'I Quit',
      'Hitchcock Dolly Zoom',
      'Smell the Lens',
      'I believe I can fly',
      'Strikout Dance',
      'Pixel World',
      'Mint in Box',
      'Hands up, Hand',
      'Flora Nymph Go',
      'Somber Embrace',
      'Beam me up',
      'Suit Swagger',
    ])
    .register(z.globalRegistry, {
      description: 'The effect to apply to the video',
    }),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * TransitionOutputV5
 */
export const zSchemaPixverseV5TransitionOutput = z.object({
  video: zSchemaFile,
})

/**
 * TransitionRequest
 */
export const zSchemaPixverseV5TransitionInput = z.object({
  first_image_url: z.union([z.string(), z.string()]),
  aspect_ratio: z.optional(
    z.enum(['16:9', '4:3', '1:1', '3:4', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt for the transition',
  }),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * ProcessOutput
 */
export const zSchemaDecartLucy5bImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ProcessRequest
 */
export const zSchemaDecartLucy5bImageToVideoInput = z.object({
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text description of the desired video content',
  }),
  aspect_ratio: z.optional(
    z.enum(['9:16', '16:9']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(true),
  resolution: z.optional(
    z.enum(['720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * A coordinate point with x and y values for motion tracking
 */
export const zSchemaTrackPoint = z
  .object({
    x: z.number().register(z.globalRegistry, {
      description: 'X coordinate',
    }),
    y: z.number().register(z.globalRegistry, {
      description: 'Y coordinate',
    }),
  })
  .register(z.globalRegistry, {
    description: 'A coordinate point with x and y values for motion tracking',
  })

/**
 * WanATIResponse
 */
export const zSchemaWanAtiOutput = z.object({
  video: zSchemaFile,
})

/**
 * WanATIRequest
 */
export const zSchemaWanAtiInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p, 580p, 720p).',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  track: z.array(z.array(zSchemaTrackPoint)).register(z.globalRegistry, {
    description:
      "Motion tracks to guide video generation. Each track is a sequence of points defining a motion trajectory. Multiple tracks can control different elements or objects in the video. Expected format: array of tracks, where each track is an array of points with 'x' and 'y' coordinates (up to 121 points per track). Points will be automatically padded to 121 if fewer are provided. Coordinates should be within the image dimensions.",
  }),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(5),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(40),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
})

/**
 * SeedanceReferenceToVideoOutput
 */
export const zSchemaBytedanceSeedanceV1LiteReferenceToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generation',
  }),
  video: zSchemaFile,
})

/**
 * SeedanceReferenceToVideoInput
 */
export const zSchemaBytedanceSeedanceV1LiteReferenceToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt used to generate the video',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Video resolution - 480p for faster generation, 720p for higher quality',
    }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '1:1', '3:4', '9:16', 'auto'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video',
      }),
  ),
  duration: z.optional(
    z
      .enum(['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'])
      .register(z.globalRegistry, {
        description: 'Duration of the video in seconds',
      }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  camera_fixed: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to fix the camera position',
      }),
    )
    .default(false),
  reference_image_urls: z.array(z.string()).register(z.globalRegistry, {
    description: 'Reference images to generate the video with.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed to control video generation. Use -1 for random.',
    }),
  ),
})

/**
 * Lucy14BOutput
 */
export const zSchemaLucy14bImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Lucy14BImageToVideoInput
 */
export const zSchemaLucy14bImageToVideoInput = z.object({
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated\n            and uploaded before returning the response. This will increase the\n            latency of the function but it allows you to get the image directly\n            in the response without going through the CDN.\n        ',
      }),
    )
    .default(true),
  aspect_ratio: z.optional(
    z.enum(['9:16', '16:9']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text description of the desired video content',
  }),
  resolution: z.optional(
    z.enum(['720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * AIAvatarOutput
 */
export const zSchemaKlingVideoV1ProAiAvatarOutput = z.object({
  duration: z.number().register(z.globalRegistry, {
    description: 'Duration of the output video in seconds.',
  }),
  video: zSchemaFile,
})

/**
 * AIAvatarInput
 */
export const zSchemaKlingVideoV1ProAiAvatarInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The prompt to use for the video generation.',
      }),
    )
    .default('.'),
  audio_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * AIAvatarOutput
 */
export const zSchemaKlingVideoV1StandardAiAvatarOutput = z.object({
  duration: z.number().register(z.globalRegistry, {
    description: 'Duration of the output video in seconds.',
  }),
  video: zSchemaFile,
})

/**
 * AIAvatarInput
 */
export const zSchemaKlingVideoV1StandardAiAvatarInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The prompt to use for the video generation.',
      }),
    )
    .default('.'),
  audio_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * FabricOneOutput
 */
export const zSchemaFabric10Output = z.object({
  video: zSchemaFile,
})

/**
 * FabricOneLipsyncInput
 */
export const zSchemaFabric10Input = z.object({
  resolution: z.enum(['720p', '480p']).register(z.globalRegistry, {
    description: 'Resolution',
  }),
  audio_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * OmniHumanv15Output
 */
export const zSchemaBytedanceOmnihumanV15Output = z.object({
  duration: z.number().register(z.globalRegistry, {
    description: 'Duration of audio input/video output as used for billing.',
  }),
  video: zSchemaFile,
})

/**
 * OmniHumanv15Input
 */
export const zSchemaBytedanceOmnihumanV15Input = z.object({
  turbo_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Generate a video at a faster rate with a slight quality trade-off.',
      }),
    )
    .default(false),
  resolution: z.optional(
    z.enum(['720p', '1080p']).register(z.globalRegistry, {
      description:
        'The resolution of the generated video. Defaults to 1080p. 720p generation is faster and higher in quality. 1080p generation is limited to 30s audio and 720p generation is limited to 60s audio.',
    }),
  ),
  prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The text prompt used to guide the video generation.',
    }),
  ),
  audio_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * FabricOneOutput
 */
export const zSchemaFabric10FastOutput = z.object({
  video: zSchemaFile,
})

/**
 * FabricOneLipsyncInput
 */
export const zSchemaFabric10FastInput = z.object({
  resolution: z.enum(['720p', '480p']).register(z.globalRegistry, {
    description: 'Resolution',
  }),
  audio_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * OviI2VResponse
 */
export const zSchemaOviImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: z.optional(z.union([zSchemaFile, z.unknown()])),
})

/**
 * OviI2VRequest
 */
export const zSchemaOviImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps.',
      }),
    )
    .default(30),
  audio_negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for audio generation.',
      }),
    )
    .default('robotic, muffled, echo, distorted'),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default('jitter, bad hands, blur, distortion'),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * ImageToVideoOutput
 */
export const zSchemaSora2ImageToVideoOutput = z.object({
  spritesheet: z.optional(zSchemaImageFile),
  thumbnail: z.optional(zSchemaImageFile),
  video_id: z.string().register(z.globalRegistry, {
    description: 'The ID of the generated video',
  }),
  video: zSchemaVideoFile,
})

/**
 * ImageToVideoInput
 */
export const zSchemaSora2ImageToVideoInput = z.object({
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: 'The text prompt describing the video you want to generate',
  }),
  duration: z.optional(
    z
      .union([z.literal(4), z.literal(8), z.literal(12)])
      .register(z.globalRegistry, {
        description: 'Duration of the generated video in seconds',
      }),
  ),
  resolution: z.optional(
    z.enum(['auto', '720p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '9:16', '16:9']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  model: z.optional(
    z
      .enum(['sora-2', 'sora-2-2025-12-08', 'sora-2-2025-10-06'])
      .register(z.globalRegistry, {
        description:
          'The model to use for the generation. When the default model is selected, the latest snapshot of the model will be used - otherwise, select a specific snapshot of the model.',
      }),
  ),
  delete_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to delete the video after generation for privacy reasons. If True, the video cannot be used for remixing and will be permanently deleted.',
      }),
    )
    .default(true),
})

/**
 * ProImageToVideoOutput
 */
export const zSchemaSora2ImageToVideoProOutput = z.object({
  spritesheet: z.optional(zSchemaImageFile),
  thumbnail: z.optional(zSchemaImageFile),
  video_id: z.string().register(z.globalRegistry, {
    description: 'The ID of the generated video',
  }),
  video: zSchemaVideoFile,
})

/**
 * ProImageToVideoInput
 */
export const zSchemaSora2ImageToVideoProInput = z.object({
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: 'The text prompt describing the video you want to generate',
  }),
  duration: z.optional(
    z
      .union([z.literal(4), z.literal(8), z.literal(12)])
      .register(z.globalRegistry, {
        description: 'Duration of the generated video in seconds',
      }),
  ),
  resolution: z.optional(
    z.enum(['auto', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '9:16', '16:9']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  delete_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to delete the video after generation for privacy reasons. If True, the video cannot be used for remixing and will be permanently deleted.',
      }),
    )
    .default(true),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * Veo31ImageToVideoOutput
 */
export const zSchemaVeo31ImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Veo31ImageToVideoInput
 */
export const zSchemaVeo31ImageToVideoInput = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: 'The text prompt describing the video you want to generate',
  }),
  duration: z.optional(
    z.enum(['4s', '6s', '8s']).register(z.globalRegistry, {
      description: 'The duration of the generated video.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16']).register(z.globalRegistry, {
      description:
        'The aspect ratio of the generated video. Only 16:9 and 9:16 are supported.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.',
      }),
    )
    .default(false),
  resolution: z.optional(
    z.enum(['720p', '1080p', '4k']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
  negative_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'A negative prompt to guide the video generation.',
    }),
  ),
})

/**
 * Veo31ImageToVideoOutput
 */
export const zSchemaVeo31FastImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Veo31ImageToVideoInput
 */
export const zSchemaVeo31FastImageToVideoInput = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: 'The text prompt describing the video you want to generate',
  }),
  duration: z.optional(
    z.enum(['4s', '6s', '8s']).register(z.globalRegistry, {
      description: 'The duration of the generated video.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16']).register(z.globalRegistry, {
      description:
        'The aspect ratio of the generated video. Only 16:9 and 9:16 are supported.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.',
      }),
    )
    .default(false),
  resolution: z.optional(
    z.enum(['720p', '1080p', '4k']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
  negative_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'A negative prompt to guide the video generation.',
    }),
  ),
})

/**
 * Veo31ReferenceToVideoOutput
 */
export const zSchemaVeo31ReferenceToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Veo31ReferenceToVideoInput
 */
export const zSchemaVeo31ReferenceToVideoInput = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: 'The text prompt describing the video you want to generate',
  }),
  duration: z.optional(
    z.enum(['8s']).register(z.globalRegistry, {
      description: 'The duration of the generated video.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  resolution: z.optional(
    z.enum(['720p', '1080p', '4k']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.',
      }),
    )
    .default(false),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'URLs of the reference images to use for consistent subject appearance',
  }),
})

/**
 * Veo31FirstLastFrameToVideoOutput
 */
export const zSchemaVeo31FirstLastFrameToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Veo31FirstLastFrameToVideoInput
 */
export const zSchemaVeo31FirstLastFrameToVideoInput = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: 'The text prompt describing the video you want to generate',
  }),
  duration: z.optional(
    z.enum(['4s', '6s', '8s']).register(z.globalRegistry, {
      description: 'The duration of the generated video.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.',
      }),
    )
    .default(false),
  resolution: z.optional(
    z.enum(['720p', '1080p', '4k']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  first_frame_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
  last_frame_url: z.union([z.string(), z.string()]),
  negative_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'A negative prompt to guide the video generation.',
    }),
  ),
})

/**
 * Veo31FirstLastFrameToVideoOutput
 */
export const zSchemaVeo31FastFirstLastFrameToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Veo31FirstLastFrameToVideoInput
 */
export const zSchemaVeo31FastFirstLastFrameToVideoInput = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: 'The text prompt describing the video you want to generate',
  }),
  duration: z.optional(
    z.enum(['4s', '6s', '8s']).register(z.globalRegistry, {
      description: 'The duration of the generated video.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.',
      }),
    )
    .default(false),
  resolution: z.optional(
    z.enum(['720p', '1080p', '4k']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  first_frame_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
  last_frame_url: z.union([z.string(), z.string()]),
  negative_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'A negative prompt to guide the video generation.',
    }),
  ),
})

/**
 * ImageToVideoV25StandardOutput
 */
export const zSchemaKlingVideoV25TurboStandardImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoV25StandardRequest
 */
export const zSchemaKlingVideoV25TurboStandardImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * Q2ImageToVideoOutput
 */
export const zSchemaViduQ2ImageToVideoProOutput = z.object({
  video: zSchemaFile,
})

/**
 * Q2ImageToVideoRequest
 */
export const zSchemaViduQ2ImageToVideoProInput = z.object({
  prompt: z.string().max(3000).register(z.globalRegistry, {
    description: 'Text prompt for video generation, max 3000 characters',
  }),
  resolution: z.optional(
    z.enum(['720p', '1080p']).register(z.globalRegistry, {
      description: 'Output video resolution',
    }),
  ),
  duration: z.optional(
    z
      .union([
        z.literal(2),
        z.literal(3),
        z.literal(4),
        z.literal(5),
        z.literal(6),
        z.literal(7),
        z.literal(8),
      ])
      .register(z.globalRegistry, {
        description: 'Duration of the video in seconds',
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  bgm: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to add background music to the video (only for 4-second videos)',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(['auto', 'small', 'medium', 'large']).register(z.globalRegistry, {
      description: 'The movement amplitude of objects in the frame',
    }),
  ),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
})

/**
 * Q2ImageToVideoOutput
 */
export const zSchemaViduQ2ImageToVideoTurboOutput = z.object({
  video: zSchemaFile,
})

/**
 * Q2ImageToVideoRequest
 */
export const zSchemaViduQ2ImageToVideoTurboInput = z.object({
  prompt: z.string().max(3000).register(z.globalRegistry, {
    description: 'Text prompt for video generation, max 3000 characters',
  }),
  resolution: z.optional(
    z.enum(['720p', '1080p']).register(z.globalRegistry, {
      description: 'Output video resolution',
    }),
  ),
  duration: z.optional(
    z
      .union([
        z.literal(2),
        z.literal(3),
        z.literal(4),
        z.literal(5),
        z.literal(6),
        z.literal(7),
        z.literal(8),
      ])
      .register(z.globalRegistry, {
        description: 'Duration of the video in seconds',
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  bgm: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to add background music to the video (only for 4-second videos)',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(['auto', 'small', 'medium', 'large']).register(z.globalRegistry, {
      description: 'The movement amplitude of objects in the frame',
    }),
  ),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
})

/**
 * SeedanceFastI2VVideoOutput
 */
export const zSchemaBytedanceSeedanceV1ProFastImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generation',
  }),
  video: zSchemaFile,
})

/**
 * SeedanceProFastImageToVideoInput
 */
export const zSchemaBytedanceSeedanceV1ProFastImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt used to generate the video',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p', '1080p']).register(z.globalRegistry, {
      description:
        'Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality',
    }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '1:1', '3:4', '9:16', 'auto'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video',
      }),
  ),
  duration: z.optional(
    z
      .enum(['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'])
      .register(z.globalRegistry, {
        description: 'Duration of the video in seconds',
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  camera_fixed: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to fix the camera position',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed to control video generation. Use -1 for random.',
    }),
  ),
})

/**
 * ProFastImageToVideoHailuo23Output
 */
export const zSchemaMinimaxHailuo23FastProImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ProFastImageToVideoHailuo23Input
 */
export const zSchemaMinimaxHailuo23FastProImageToVideoInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  prompt: z.string().min(1).max(2000).register(z.globalRegistry, {
    description: 'Text prompt for video generation',
  }),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * StandardImageToVideoHailuo23Output
 */
export const zSchemaMinimaxHailuo23StandardImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * StandardImageToVideoHailuo23Input
 */
export const zSchemaMinimaxHailuo23StandardImageToVideoInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  duration: z.optional(
    z.enum(['6', '10']).register(z.globalRegistry, {
      description: 'The duration of the video in seconds.',
    }),
  ),
  prompt: z.string().min(1).max(2000).register(z.globalRegistry, {
    description: 'Text prompt for video generation',
  }),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * StandardFastImageToVideoHailuo23Output
 */
export const zSchemaMinimaxHailuo23FastStandardImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * StandardFastImageToVideoHailuo23Input
 */
export const zSchemaMinimaxHailuo23FastStandardImageToVideoInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  duration: z.optional(
    z.enum(['6', '10']).register(z.globalRegistry, {
      description: 'The duration of the video in seconds.',
    }),
  ),
  prompt: z.string().min(1).max(2000).register(z.globalRegistry, {
    description: 'Text prompt for video generation',
  }),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * LongCatImageToVideoResponse
 */
export const zSchemaLongcatVideoDistilledImageToVideo480pOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * LongCatImageToVideoRequest
 */
export const zSchemaLongcatVideoDistilledImageToVideo480pInput = z.object({
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The prompt to guide the video generation.',
      }),
    )
    .default(
      "First-person view from the cockpit of a Formula 1 car. The driver's gloved hands firmly grip the intricate, carbon-fiber steering wheel adorned with numerous colorful buttons and a vibrant digital display showing race data. Beyond the windshield, a sun-drenched racetrack stretches ahead, lined with cheering spectators in the grandstands. Several rival cars are visible in the distance, creating a dynamic sense of competition. The sky above is a clear, brilliant blue, reflecting the exhilarating atmosphere of a high-speed race. high resolution 4k",
    ),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frame rate of the generated video.',
      }),
    )
    .default(15),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  image_url: z.union([z.string(), z.string()]),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable safety checker.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(16).register(z.globalRegistry, {
        description: 'The number of inference steps to use.',
      }),
    )
    .default(12),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(961).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(162),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
})

/**
 * LongCatImageToVideoResponse
 */
export const zSchemaLongcatVideoDistilledImageToVideo720pOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * LongCat720PImageToVideoRequest
 */
export const zSchemaLongcatVideoDistilledImageToVideo720pInput = z.object({
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The prompt to guide the video generation.',
      }),
    )
    .default(
      "First-person view from the cockpit of a Formula 1 car. The driver's gloved hands firmly grip the intricate, carbon-fiber steering wheel adorned with numerous colorful buttons and a vibrant digital display showing race data. Beyond the windshield, a sun-drenched racetrack stretches ahead, lined with cheering spectators in the grandstands. Several rival cars are visible in the distance, creating a dynamic sense of competition. The sky above is a clear, brilliant blue, reflecting the exhilarating atmosphere of a high-speed race. high resolution 4k",
    ),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frame rate of the generated video.',
      }),
    )
    .default(30),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  num_refine_inference_steps: z
    .optional(
      z.int().gte(2).lte(16).register(z.globalRegistry, {
        description: 'The number of inference steps to use for refinement.',
      }),
    )
    .default(12),
  image_url: z.union([z.string(), z.string()]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable safety checker.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(16).register(z.globalRegistry, {
        description: 'The number of inference steps to use.',
      }),
    )
    .default(12),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(961).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(162),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
})

/**
 * LongCatImageToVideoResponse
 */
export const zSchemaLongcatVideoImageToVideo480pOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * LongCatCFGImageToVideoRequest
 */
export const zSchemaLongcatVideoImageToVideo480pInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The prompt to guide the video generation.',
      }),
    )
    .default(
      "First-person view from the cockpit of a Formula 1 car. The driver's gloved hands firmly grip the intricate, carbon-fiber steering wheel adorned with numerous colorful buttons and a vibrant digital display showing race data. Beyond the windshield, a sun-drenched racetrack stretches ahead, lined with cheering spectators in the grandstands. Several rival cars are visible in the distance, creating a dynamic sense of competition. The sky above is a clear, brilliant blue, reflecting the exhilarating atmosphere of a high-speed race. high resolution 4k",
    ),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description: 'The acceleration level to use for the video generation.',
    }),
  ),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frame rate of the generated video.',
      }),
    )
    .default(15),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use for the video generation.',
      }),
    )
    .default(4),
  num_frames: z
    .optional(
      z.int().gte(17).lte(961).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(162),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable safety checker.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to use for the video generation.',
      }),
    )
    .default(
      'Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description:
          'The number of inference steps to use for the video generation.',
      }),
    )
    .default(40),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
})

/**
 * LongCatImageToVideoResponse
 */
export const zSchemaLongcatVideoImageToVideo720pOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * LongCat720PCFGImageToVideoRequest
 */
export const zSchemaLongcatVideoImageToVideo720pInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The prompt to guide the video generation.',
      }),
    )
    .default(
      "First-person view from the cockpit of a Formula 1 car. The driver's gloved hands firmly grip the intricate, carbon-fiber steering wheel adorned with numerous colorful buttons and a vibrant digital display showing race data. Beyond the windshield, a sun-drenched racetrack stretches ahead, lined with cheering spectators in the grandstands. Several rival cars are visible in the distance, creating a dynamic sense of competition. The sky above is a clear, brilliant blue, reflecting the exhilarating atmosphere of a high-speed race. high resolution 4k",
    ),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description: 'The acceleration level to use for the video generation.',
    }),
  ),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frame rate of the generated video.',
      }),
    )
    .default(30),
  num_refine_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to use for refinement.',
      }),
    )
    .default(40),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use for the video generation.',
      }),
    )
    .default(4),
  num_frames: z
    .optional(
      z.int().gte(17).lte(961).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(162),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable safety checker.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to use for the video generation.',
      }),
    )
    .default(
      'Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description:
          'The number of inference steps to use for the video generation.',
      }),
    )
    .default(40),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
})

/**
 * KeyframeTransition
 *
 * Configuration for a transition between two keyframes
 */
export const zSchemaKeyframeTransition = z
  .object({
    prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'Specific prompt for this transition. Overrides the global prompt if provided.',
      }),
    ),
    duration: z
      .optional(
        z.int().gte(1).lte(25).register(z.globalRegistry, {
          description: 'Duration of this transition in seconds',
        }),
      )
      .default(5),
  })
  .register(z.globalRegistry, {
    description: 'Configuration for a transition between two keyframes',
  })

/**
 * Pika22KeyframesToVideoOutput
 *
 * Output model for Pika 2.2 keyframes-to-video generation
 */
export const zSchemaPikaV22PikaframesOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output model for Pika 2.2 keyframes-to-video generation',
  })

/**
 * Pika22KeyframesToVideoRequest
 */
export const zSchemaPikaV22PikaframesInput = z.object({
  prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'Default prompt for all transitions. Individual transition prompts override this.',
    }),
  ),
  resolution: z.optional(
    z.enum(['720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  transitions: z.optional(
    z.array(zSchemaKeyframeTransition).register(z.globalRegistry, {
      description:
        'Configuration for each transition. Length must be len(image_urls) - 1. Total duration of all transitions must not exceed 25 seconds. If not provided, uses default 5-second transitions with the global prompt.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator',
    }),
  ),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      'URLs of keyframe images (2-5 images) to create transitions between',
  }),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'A negative prompt to guide the model',
      }),
    )
    .default(''),
})

/**
 * SwapOutput
 */
export const zSchemaPixverseSwapOutput = z.object({
  video: zSchemaFile,
})

/**
 * SwapRequest
 */
export const zSchemaPixverseSwapInput = z.object({
  original_sound_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to keep the original audio',
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  keyframe_id: z
    .optional(
      z.int().gte(1).register(z.globalRegistry, {
        description: 'The keyframe ID (from 1 to the last frame position)',
      }),
    )
    .default(1),
  mode: z.optional(
    z.enum(['person', 'object', 'background']).register(z.globalRegistry, {
      description: 'The swap mode to use',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p']).register(z.globalRegistry, {
      description: 'The output resolution (1080p not supported)',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * LynxOutput
 */
export const zSchemaLynxOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
  video: zSchemaVideoFile,
})

/**
 * LynxInput
 */
export const zSchemaLynxInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt to guide video generation',
  }),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p, 580p, or 720p)',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video (16:9, 9:16, or 1:1)',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(75).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(50),
  guidance_scale_2: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description:
          'Image guidance scale. Controls how closely the generated video follows the reference image. Higher values increase adherence to the reference image but may decrease quality.',
      }),
    )
    .default(2),
  strength: z
    .optional(
      z.number().gte(0).lte(2).register(z.globalRegistry, {
        description:
          'Reference image scale. Controls the influence of the reference image on the generated video.',
      }),
    )
    .default(1),
  frames_per_second: z
    .optional(
      z.int().gte(5).lte(30).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 5 to 30.',
      }),
    )
    .default(16),
  image_url: z.union([z.string(), z.string()]),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(9).lte(81).register(z.globalRegistry, {
        description:
          'Number of frames in the generated video. Must be between 9 to 100.',
      }),
    )
    .default(81),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Negative prompt to guide what should not appear in the generated video',
      }),
    )
    .default(
      'Bright tones, overexposed, blurred background, static, subtitles, style, works, paintings, images, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards',
    ),
  ip_scale: z
    .optional(
      z.number().gte(0).lte(2).register(z.globalRegistry, {
        description:
          "Identity preservation scale. Controls how closely the generated video preserves the subject's identity from the reference image.",
      }),
    )
    .default(1),
})

/**
 * LTXVImageToVideoResponse
 */
export const zSchemaLtx2ImageToVideoOutput = z.object({
  video: zSchemaVideoFile,
})

/**
 * LTXVImageToVideoRequest
 */
export const zSchemaLtx2ImageToVideoInput = z.object({
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: 'The prompt to generate the video from',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  duration: z.optional(
    z
      .union([z.literal(6), z.literal(8), z.literal(10)])
      .register(z.globalRegistry, {
        description: 'The duration of the generated video in seconds',
      }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the generated video',
      }),
    )
    .default(true),
  resolution: z.optional(
    z.enum(['1080p', '1440p', '2160p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  fps: z.optional(
    z.union([z.literal(25), z.literal(50)]).register(z.globalRegistry, {
      description: 'The frames per second of the generated video',
    }),
  ),
})

/**
 * LTXVImageToVideoResponse
 */
export const zSchemaLtx2ImageToVideoFastOutput = z.object({
  video: zSchemaVideoFile,
})

/**
 * LTXVImageToVideoFastRequest
 */
export const zSchemaLtx2ImageToVideoFastInput = z.object({
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: 'The prompt to generate the video from',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  duration: z.optional(
    z
      .union([
        z.literal(6),
        z.literal(8),
        z.literal(10),
        z.literal(12),
        z.literal(14),
        z.literal(16),
        z.literal(18),
        z.literal(20),
      ])
      .register(z.globalRegistry, {
        description:
          'The duration of the generated video in seconds. The fast model supports 6-20 seconds. Note: Durations longer than 10 seconds (12, 14, 16, 18, 20) are only supported with 25 FPS and 1080p resolution.',
      }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the generated video',
      }),
    )
    .default(true),
  resolution: z.optional(
    z.enum(['1080p', '1440p', '2160p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  fps: z.optional(
    z.union([z.literal(25), z.literal(50)]).register(z.globalRegistry, {
      description: 'The frames per second of the generated video',
    }),
  ),
})

/**
 * OmniVideoReferenceToVideoOutput
 */
export const zSchemaKlingVideoO1ReferenceToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * OmniVideoReferenceToVideoInput
 *
 * Input for start-frame video generation with optional reference images and elements.
 */
export const zSchemaKlingVideoO1ReferenceToVideoInput = z
  .object({
    prompt: z.string().max(2500).register(z.globalRegistry, {
      description:
        'Take @Element1, @Element2 to reference elements and @Image1, @Image2 to reference images in order.',
    }),
    duration: z.optional(
      z
        .enum(['3', '4', '5', '6', '7', '8', '9', '10'])
        .register(z.globalRegistry, {
          description: 'Video duration in seconds.',
        }),
    ),
    aspect_ratio: z.optional(
      z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video frame.',
      }),
    ),
    elements: z.optional(
      z.array(zSchemaOmniVideoElementInput).register(z.globalRegistry, {
        description:
          'Elements (characters/objects) to include in the video. Reference in prompt as @Element1, @Element2, etc. Maximum 7 total (elements + reference images + start image).',
      }),
    ),
    image_urls: z.optional(
      z.array(z.string()).register(z.globalRegistry, {
        description:
          'Additional reference images for style/appearance. Reference in prompt as @Image1, @Image2, etc. Maximum 7 total (elements + reference images + start image).',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description:
      'Input for start-frame video generation with optional reference images and elements.',
  })

/**
 * OmniVideoImageToVideoOutput
 *
 * Output for Kling Omni Video generation.
 */
export const zSchemaKlingVideoO1ImageToVideoOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output for Kling Omni Video generation.',
  })

/**
 * OmniVideoImageToVideoInput
 */
export const zSchemaKlingVideoO1ImageToVideoInput = z.object({
  prompt: z.string().max(2500).register(z.globalRegistry, {
    description:
      'Use @Image1 to reference the start frame, @Image2 to reference the end frame.',
  }),
  duration: z.optional(
    z
      .enum(['3', '4', '5', '6', '7', '8', '9', '10'])
      .register(z.globalRegistry, {
        description: 'Video duration in seconds.',
      }),
  ),
  start_image_url: z.union([z.string(), z.string()]),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
})

/**
 * I2VOutputV5_5
 */
export const zSchemaPixverseV55ImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoRequestV5_5
 */
export const zSchemaPixverseV55ImageToVideoInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  duration: z.optional(
    z.enum(['5', '8', '10']).register(z.globalRegistry, {
      description:
        'The duration of the generated video in seconds. Longer durations cost more. 1080p videos are limited to 5 or 8 seconds',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  thinking_type: z.optional(
    z.enum(['enabled', 'disabled', 'auto']).register(z.globalRegistry, {
      description:
        "Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision",
    }),
  ),
  generate_multi_clip_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable multi-clip generation with dynamic camera changes',
      }),
    )
    .default(false),
  image_url: z.union([z.string(), z.string()]),
  generate_audio_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable audio generation (BGM, SFX, dialogue)',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * TransitionOutputV5_5
 */
export const zSchemaPixverseV55TransitionOutput = z.object({
  video: zSchemaFile,
})

/**
 * TransitionRequestV5_5
 */
export const zSchemaPixverseV55TransitionInput = z.object({
  first_image_url: z.union([z.string(), z.string()]),
  aspect_ratio: z.optional(
    z.enum(['16:9', '4:3', '1:1', '3:4', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  thinking_type: z.optional(
    z.enum(['enabled', 'disabled', 'auto']).register(z.globalRegistry, {
      description:
        "Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision",
    }),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt for the transition',
  }),
  duration: z.optional(
    z.enum(['5', '8', '10']).register(z.globalRegistry, {
      description:
        'The duration of the generated video in seconds. Longer durations cost more. 1080p videos are limited to 5 or 8 seconds',
    }),
  ),
  generate_audio_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable audio generation (BGM, SFX, dialogue)',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * EffectOutput
 */
export const zSchemaPixverseV55EffectsOutput = z.object({
  video: zSchemaFile,
})

/**
 * EffectInputV5_5
 */
export const zSchemaPixverseV55EffectsInput = z.object({
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
  duration: z.optional(
    z.enum(['5', '8', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  thinking_type: z.optional(
    z.enum(['enabled', 'disabled', 'auto']).register(z.globalRegistry, {
      description:
        "Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision",
    }),
  ),
  effect: z
    .enum([
      'Kiss Me AI',
      'Kiss',
      'Muscle Surge',
      'Warmth of Jesus',
      'Anything, Robot',
      'The Tiger Touch',
      'Hug',
      'Holy Wings',
      'Microwave',
      'Zombie Mode',
      'Squid Game',
      'Baby Face',
      'Black Myth: Wukong',
      'Long Hair Magic',
      'Leggy Run',
      'Fin-tastic Mermaid',
      'Punch Face',
      'Creepy Devil Smile',
      'Thunder God',
      'Eye Zoom Challenge',
      "Who's Arrested?",
      'Baby Arrived',
      'Werewolf Rage',
      'Bald Swipe',
      'BOOM DROP',
      'Huge Cutie',
      'Liquid Metal',
      'Sharksnap!',
      'Dust Me Away',
      '3D Figurine Factor',
      'Bikini Up',
      'My Girlfriends',
      'My Boyfriends',
      'Subject 3 Fever',
      'Earth Zoom',
      'Pole Dance',
      'Vroom Dance',
      'GhostFace Terror',
      'Dragon Evoker',
      'Skeletal Bae',
      'Summoning succubus',
      'Halloween Voodoo Doll',
      '3D Naked-Eye AD',
      'Package Explosion',
      'Dishes Served',
      'Ocean ad',
      'Supermarket AD',
      'Tree doll',
      'Come Feel My Abs',
      'The Bicep Flex',
      'London Elite Vibe',
      'Flora Nymph Gown',
      'Christmas Costume',
      "It's Snowy",
      'Reindeer Cruiser',
      'Snow Globe Maker',
      'Pet Christmas Outfit',
      'Adopt a Polar Pal',
      'Cat Christmas Box',
      'Starlight Gift Box',
      'Xmas Poster',
      'Pet Christmas Tree',
      'City Santa Hat',
      'Stocking Sweetie',
      'Christmas Night',
      'Xmas Front Page Karma',
      "Grinch's Xmas Hijack",
      'Giant Product',
      'Truck Fashion Shoot',
      'Beach AD',
      'Shoal Surround',
      'Mechanical Assembly',
      'Lighting AD',
      'Billboard AD',
      'Product close-up',
      'Parachute Delivery',
      'Dreamlike Cloud',
      'Macaron Machine',
      'Poster AD',
      'Truck AD',
      'Graffiti AD',
      '3D Figurine Factory',
      'The Exclusive First Class',
      'Art Zoom Challenge',
      'I Quit',
      'Hitchcock Dolly Zoom',
      'Smell the Lens',
      'I believe I can fly',
      'Strikout Dance',
      'Pixel World',
      'Mint in Box',
      'Hands up, Hand',
      'Flora Nymph Go',
      'Somber Embrace',
      'Beam me up',
      'Suit Swagger',
    ])
    .register(z.globalRegistry, {
      description: 'The effect to apply to the video',
    }),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * ImageToVideoV26ProOutput
 */
export const zSchemaKlingVideoV26ProImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoV26ProRequest
 */
export const zSchemaKlingVideoV26ProImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  voice_ids: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'List of voice IDs to use for voice control. Reference voices in the prompt using <<<voice_1>>>, <<<voice_2>>>. Maximum 2 voices allowed. When provided and referenced in prompt, enables voice control billing.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to generate native audio for the video. Supports Chinese and English voice output. Other languages are automatically translated to English. For English speech, use lowercase letters; for acronyms or proper nouns, use uppercase.',
      }),
    )
    .default(true),
  start_image_url: z.union([z.string(), z.string()]),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
})

/**
 * AIAvatarOutput
 */
export const zSchemaKlingVideoAiAvatarV2StandardOutput = z.object({
  duration: z.number().register(z.globalRegistry, {
    description: 'Duration of the output video in seconds.',
  }),
  video: zSchemaFile,
})

/**
 * AIAvatarInput
 */
export const zSchemaKlingVideoAiAvatarV2StandardInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The prompt to use for the video generation.',
      }),
    )
    .default('.'),
  audio_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * AIAvatarOutput
 */
export const zSchemaKlingVideoAiAvatarV2ProOutput = z.object({
  duration: z.number().register(z.globalRegistry, {
    description: 'Duration of the output video in seconds.',
  }),
  video: zSchemaFile,
})

/**
 * AIAvatarInput
 */
export const zSchemaKlingVideoAiAvatarV2ProInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The prompt to use for the video generation.',
      }),
    )
    .default('.'),
  audio_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * AuroraOutputModel
 */
export const zSchemaCreatifyAuroraOutput = z.object({
  video: zSchemaVideoFile,
})

/**
 * AuroraInputModel
 */
export const zSchemaCreatifyAuroraInput = z.object({
  prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'A text prompt to guide the video generation process.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(5).register(z.globalRegistry, {
        description: 'Guidance scale to be used for text prompt adherence.',
      }),
    )
    .default(1),
  audio_guidance_scale: z
    .optional(
      z.number().gte(0).lte(5).register(z.globalRegistry, {
        description: 'Guidance scale to be used for audio adherence.',
      }),
    )
    .default(2),
  audio_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * OmniVideoImageToVideoOutput
 *
 * Output for Kling Omni Video generation.
 */
export const zSchemaKlingVideoO1StandardImageToVideoOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output for Kling Omni Video generation.',
  })

/**
 * OmniVideoImageToVideoInput
 */
export const zSchemaKlingVideoO1StandardImageToVideoInput = z.object({
  prompt: z.string().max(2500).register(z.globalRegistry, {
    description:
      'Use @Image1 to reference the start frame, @Image2 to reference the end frame.',
  }),
  duration: z.optional(
    z
      .enum(['3', '4', '5', '6', '7', '8', '9', '10'])
      .register(z.globalRegistry, {
        description: 'Video duration in seconds.',
      }),
  ),
  start_image_url: z.union([z.string(), z.string()]),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
})

/**
 * OmniVideoReferenceToVideoOutput
 */
export const zSchemaKlingVideoO1StandardReferenceToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * OmniVideoReferenceToVideoInput
 *
 * Input for start-frame video generation with optional reference images and elements.
 */
export const zSchemaKlingVideoO1StandardReferenceToVideoInput = z
  .object({
    prompt: z.string().max(2500).register(z.globalRegistry, {
      description:
        'Take @Element1, @Element2 to reference elements and @Image1, @Image2 to reference images in order.',
    }),
    duration: z.optional(
      z
        .enum(['3', '4', '5', '6', '7', '8', '9', '10'])
        .register(z.globalRegistry, {
          description: 'Video duration in seconds.',
        }),
    ),
    aspect_ratio: z.optional(
      z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video frame.',
      }),
    ),
    elements: z.optional(
      z.array(zSchemaOmniVideoElementInput).register(z.globalRegistry, {
        description:
          'Elements (characters/objects) to include in the video. Reference in prompt as @Element1, @Element2, etc. Maximum 7 total (elements + reference images + start image).',
      }),
    ),
    image_urls: z.optional(
      z.array(z.string()).register(z.globalRegistry, {
        description:
          'Additional reference images for style/appearance. Reference in prompt as @Image1, @Image2, etc. Maximum 7 total (elements + reference images + start image).',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description:
      'Input for start-frame video generation with optional reference images and elements.',
  })

/**
 * ImageToVideoOutput
 *
 * Output for image-to-video generation
 */
export const zSchemaV26ImageToVideoOutput = z
  .object({
    actual_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The actual prompt used if prompt rewriting was enabled',
      }),
    ),
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed used for generation',
    }),
    video: zSchemaVideoFile,
  })
  .register(z.globalRegistry, {
    description: 'Output for image-to-video generation',
  })

/**
 * ImageToVideoInput
 *
 * Input for Wan 2.6 image-to-video generation
 */
export const zSchemaV26ImageToVideoInput = z
  .object({
    prompt: z.string().min(1).register(z.globalRegistry, {
      description:
        'The text prompt describing the desired video motion. Max 800 characters.',
    }),
    resolution: z.optional(
      z.enum(['720p', '1080p']).register(z.globalRegistry, {
        description: 'Video resolution. Valid values: 720p, 1080p',
      }),
    ),
    duration: z.optional(
      z.enum(['5', '10', '15']).register(z.globalRegistry, {
        description:
          'Duration of the generated video in seconds. Choose between 5, 10 or 15 seconds.',
      }),
    ),
    audio_url: z.optional(z.union([z.string(), z.string()])),
    image_url: z.union([z.string(), z.string()]),
    enable_prompt_expansion: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable prompt rewriting using LLM.',
        }),
      )
      .default(true),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    ),
    multi_shots: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'When true, enables intelligent multi-shot segmentation. Only active when enable_prompt_expansion is True. Set to false for single-shot generation.',
        }),
      )
      .default(false),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            'Negative prompt to describe content to avoid. Max 500 characters.',
        }),
      )
      .default(''),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'If set to true, the safety checker will be enabled.',
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description: 'Input for Wan 2.6 image-to-video generation',
  })

/**
 * HunyuanVideo15Response
 */
export const zSchemaHunyuanVideoV15ImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * HunyuanVideo15I2VRequest
 */
export const zSchemaHunyuanVideoV15ImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the video.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p']).register(z.globalRegistry, {
      description: 'The resolution of the video.',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable prompt expansion to enhance the input prompt.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for reproducibility.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps.',
      }),
    )
    .default(28),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to guide what not to generate.',
      }),
    )
    .default(''),
  num_frames: z
    .optional(
      z.int().gte(1).lte(121).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
})

/**
 * LiveAvatarResponse
 */
export const zSchemaLiveAvatarOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LiveAvatarRequest
 */
export const zSchemaLiveAvatarInput = z.object({
  frames_per_clip: z
    .optional(
      z.int().gte(16).lte(80).register(z.globalRegistry, {
        description:
          'Number of frames per clip. Must be a multiple of 4. Higher values = smoother but slower generation.',
      }),
    )
    .default(48),
  prompt: z.string().register(z.globalRegistry, {
    description:
      'A text prompt describing the scene and character. Helps guide the video generation style and context.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'light', 'regular', 'high']).register(z.globalRegistry, {
      description: 'Acceleration level for faster video decoding ',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  num_clips: z
    .optional(
      z.int().gte(1).lte(100).register(z.globalRegistry, {
        description:
          'Number of video clips to generate. Each clip is approximately 3 seconds. Set higher for longer videos.',
      }),
    )
    .default(10),
  audio_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for reproducible generation.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values follow the prompt more closely.',
      }),
    )
    .default(0),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable safety checker for content moderation.',
      }),
    )
    .default(true),
})

/**
 * SeedanceProv15I2VVideoOutput
 */
export const zSchemaBytedanceSeedanceV15ProImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generation',
  }),
  video: zSchemaFile,
})

/**
 * SeedanceProv15ImageToVideoInput
 */
export const zSchemaBytedanceSeedanceV15ProImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt used to generate the video',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p', '1080p']).register(z.globalRegistry, {
      description:
        'Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality',
    }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '1:1', '3:4', '9:16'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video',
      }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video',
      }),
    )
    .default(true),
  duration: z.optional(
    z
      .enum(['4', '5', '6', '7', '8', '9', '10', '11', '12'])
      .register(z.globalRegistry, {
        description: 'Duration of the video in seconds',
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  camera_fixed: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to fix the camera position',
      }),
    )
    .default(false),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed to control video generation. Use -1 for random.',
    }),
  ),
})

/**
 * KandinskyI2VResponse
 */
export const zSchemaKandinsky5ProImageToVideoOutput = z.object({
  video: z.optional(zSchemaFile),
})

/**
 * KandinskyI2VRequest
 */
export const zSchemaKandinsky5ProImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  resolution: z.optional(
    z.enum(['512P', '1024P']).register(z.globalRegistry, {
      description: 'Video resolution: 512p or 1024p.',
    }),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description: 'Acceleration level for faster generation.',
    }),
  ),
  duration: z.optional(
    z.enum(['5s']).register(z.globalRegistry, {
      description: 'Video duration.',
    }),
  ),
  num_inference_steps: z.optional(z.int().gte(1).lte(40)).default(28),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * Schema referenced but not defined by fal.ai (missing from source OpenAPI spec)
 */
export const zSchemaTrajectoryPoint = z
  .record(z.string(), z.unknown())
  .register(z.globalRegistry, {
    description:
      'Schema referenced but not defined by fal.ai (missing from source OpenAPI spec)',
  })

/**
 * WanMoveOutput
 */
export const zSchemaWanMoveOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'Random seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * WANMoveInput
 */
export const zSchemaWanMoveInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt to guide the video generation.',
  }),
  trajectories: z
    .array(z.array(zSchemaTrajectoryPoint))
    .register(z.globalRegistry, {
      description:
        'A list of trajectories. Each trajectory list means the movement of one object.',
    }),
  image_url: z.union([z.string(), z.string()]),
  guidance_scale: z
    .optional(
      z.number().gte(1).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(40),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to guide the video generation.',
      }),
    )
    .default(
      'JPEG',
    ),
})

/**
 * LTX2ImageToVideoOutput
 */
export const zSchemaLtx219bImageToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2ImageToVideoInput
 */
export const zSchemaLtx219bImageToVideoInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the image to use for the video generation.',
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use.',
      }),
    )
    .default(3),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  image_url: z.union([z.string(), z.string()]),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to use.',
      }),
    )
    .default(40),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * LTX2ImageToVideoOutput
 */
export const zSchemaLtx219bImageToVideoLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2LoRAImageToVideoInput
 */
export const zSchemaLtx219bImageToVideoLoraInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  loras: z.array(zSchemaLoRaInput).register(z.globalRegistry, {
    description: 'The LoRAs to use for the generation.',
  }),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the image to use for the video generation.',
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use.',
      }),
    )
    .default(3),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  image_url: z.union([z.string(), z.string()]),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to use.',
      }),
    )
    .default(40),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * LTX2ImageToVideoOutput
 */
export const zSchemaLtx219bDistilledImageToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2DistilledImageToVideoInput
 */
export const zSchemaLtx219bDistilledImageToVideoInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the image to use for the video generation.',
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * LTX2ImageToVideoOutput
 */
export const zSchemaLtx219bDistilledImageToVideoLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2LoRADistilledImageToVideoInput
 */
export const zSchemaLtx219bDistilledImageToVideoLoraInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  loras: z.array(zSchemaLoRaInput).register(z.globalRegistry, {
    description: 'The LoRAs to use for the generation.',
  }),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the image to use for the video generation.',
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * ImageToVideoOutput
 *
 * Output for image-to-video generation
 */
export const zSchemaV26ImageToVideoFlashOutput = z
  .object({
    actual_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The actual prompt used if prompt rewriting was enabled',
      }),
    ),
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed used for generation',
    }),
    video: zSchemaVideoFile,
  })
  .register(z.globalRegistry, {
    description: 'Output for image-to-video generation',
  })

/**
 * ImageToVideoInput
 *
 * Input for Wan 2.6 image-to-video generation
 */
export const zSchemaV26ImageToVideoFlashInput = z
  .object({
    prompt: z.string().min(1).register(z.globalRegistry, {
      description:
        'The text prompt describing the desired video motion. Max 800 characters.',
    }),
    resolution: z.optional(
      z.enum(['720p', '1080p']).register(z.globalRegistry, {
        description: 'Video resolution. Valid values: 720p, 1080p',
      }),
    ),
    duration: z.optional(
      z.enum(['5', '10', '15']).register(z.globalRegistry, {
        description:
          'Duration of the generated video in seconds. Choose between 5, 10 or 15 seconds.',
      }),
    ),
    audio_url: z.optional(z.union([z.string(), z.string()])),
    image_url: z.union([z.string(), z.string()]),
    enable_prompt_expansion: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable prompt rewriting using LLM.',
        }),
      )
      .default(true),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    ),
    multi_shots: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'When true, enables intelligent multi-shot segmentation. Only active when enable_prompt_expansion is True. Set to false for single-shot generation.',
        }),
      )
      .default(false),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            'Negative prompt to describe content to avoid. Max 500 characters.',
        }),
      )
      .default(''),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'If set to true, the safety checker will be enabled.',
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description: 'Input for Wan 2.6 image-to-video generation',
  })

/**
 * Q2ProReferenceToVideoOutput
 */
export const zSchemaViduQ2ReferenceToVideoProOutput = z.object({
  video: zSchemaFile,
})

/**
 * Q2ProReferenceToVideoRequest
 */
export const zSchemaViduQ2ReferenceToVideoProInput = z.object({
  prompt: z.string().max(2000).register(z.globalRegistry, {
    description: 'Text prompt for video generation, max 2000 characters',
  }),
  resolution: z.optional(
    z.enum(['540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'Output video resolution',
    }),
  ),
  aspect_ratio: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Aspect ratio of the output video (e.g., auto, 16:9, 9:16, 1:1, or any W:H)',
      }),
    )
    .default('16:9'),
  duration: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description:
          'Duration of the video in seconds (0 for automatic duration)',
      }),
    )
    .default(4),
  reference_video_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'URLs of the reference videos for video editing or motion reference. Supports up to 2 videos.',
    }),
  ),
  bgm: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to add background music to the generated video',
      }),
    )
    .default(false),
  reference_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'URLs of the reference images for subject appearance. If videos are provided, up to 4 images are allowed; otherwise up to 7 images.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(['auto', 'small', 'medium', 'large']).register(z.globalRegistry, {
      description: 'The movement amplitude of objects in the frame',
    }),
  ),
})

/**
 * I2VOutputV5_5
 */
export const zSchemaPixverseV56ImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoRequestV5_6
 */
export const zSchemaPixverseV56ImageToVideoInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  duration: z.optional(
    z.enum(['5', '8', '10']).register(z.globalRegistry, {
      description:
        'The duration of the generated video in seconds. 1080p videos are limited to 5 or 8 seconds',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  thinking_type: z.optional(
    z.enum(['enabled', 'disabled', 'auto']).register(z.globalRegistry, {
      description:
        "Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  generate_audio_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable audio generation (BGM, SFX, dialogue)',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * TransitionOutputV5_5
 */
export const zSchemaPixverseV56TransitionOutput = z.object({
  video: zSchemaFile,
})

/**
 * TransitionRequestV5_6
 */
export const zSchemaPixverseV56TransitionInput = z.object({
  first_image_url: z.union([z.string(), z.string()]),
  aspect_ratio: z.optional(
    z.enum(['16:9', '4:3', '1:1', '3:4', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video',
    }),
  ),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  thinking_type: z.optional(
    z.enum(['enabled', 'disabled', 'auto']).register(z.globalRegistry, {
      description:
        "Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision",
    }),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt for the transition',
  }),
  duration: z.optional(
    z.enum(['5', '8', '10']).register(z.globalRegistry, {
      description:
        'The duration of the generated video in seconds. 1080p videos are limited to 5 or 8 seconds',
    }),
  ),
  generate_audio_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable audio generation (BGM, SFX, dialogue)',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * WanI2VResponse
 */
export const zSchemaWanI2vOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanI2VRequest
 */
export const zSchemaWanI2vInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  frames_per_second: z
    .optional(
      z.int().gte(5).lte(24).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 5 to 24.',
      }),
    )
    .default(16),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(81).lte(100).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 100 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.',
      }),
    )
    .default(81),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  guide_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
})

/**
 * ImageToVideoV2MasterOutput
 */
export const zSchemaKlingVideoV2MasterImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoV2MasterRequest
 */
export const zSchemaKlingVideoV2MasterImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * I2VOutputV4
 */
export const zSchemaPixverseV45ImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoRequestV4
 */
export const zSchemaPixverseV45ImageToVideoInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description:
        'The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the generated video',
      }),
  ),
  camera_movement: z.optional(
    z
      .enum([
        'horizontal_left',
        'horizontal_right',
        'vertical_up',
        'vertical_down',
        'zoom_in',
        'zoom_out',
        'crane_up',
        'quickly_zoom_in',
        'quickly_zoom_out',
        'smooth_zoom_in',
        'camera_rotation',
        'robo_arm',
        'super_dolly_out',
        'whip_pan',
        'hitchcock',
        'left_follow',
        'right_follow',
        'pan_left',
        'pan_right',
        'fix_bg',
      ])
      .register(z.globalRegistry, {
        description: 'The type of camera movement to apply to the video',
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * ImageToVideoV21StandardOutput
 */
export const zSchemaKlingVideoV21StandardImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoV21StandardRequest
 */
export const zSchemaKlingVideoV21StandardImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * ImageToVideoV21MasterOutput
 */
export const zSchemaKlingVideoV21MasterImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoV21MasterRequest
 */
export const zSchemaKlingVideoV21MasterImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * SeedanceProI2VVideoOutput
 */
export const zSchemaBytedanceSeedanceV1ProImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generation',
  }),
  video: zSchemaFile,
})

/**
 * SeedanceProImageToVideoInput
 */
export const zSchemaBytedanceSeedanceV1ProImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt used to generate the video',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p', '1080p']).register(z.globalRegistry, {
      description:
        'Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality',
    }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '1:1', '3:4', '9:16', 'auto'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video',
      }),
  ),
  duration: z.optional(
    z
      .enum(['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'])
      .register(z.globalRegistry, {
        description: 'Duration of the video in seconds',
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  camera_fixed: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to fix the camera position',
      }),
    )
    .default(false),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed to control video generation. Use -1 for random.',
    }),
  ),
})

/**
 * ImageToVideoHailuo02Output
 */
export const zSchemaMinimaxHailuo02StandardImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * StandardImageToVideoHailuo02Input
 */
export const zSchemaMinimaxHailuo02StandardImageToVideoInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  duration: z.optional(
    z.enum(['6', '10']).register(z.globalRegistry, {
      description:
        'The duration of the video in seconds. 10 seconds videos are not supported for 1080p resolution.',
    }),
  ),
  resolution: z.optional(
    z.enum(['512P', '768P']).register(z.globalRegistry, {
      description: 'The resolution of the generated video.',
    }),
  ),
  prompt: z.string().max(2000),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * ImageToVideoV25ProOutput
 */
export const zSchemaKlingVideoV25TurboProImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoV25ProRequest
 */
export const zSchemaKlingVideoV25TurboProImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  tail_image_url: z.optional(z.union([z.string(), z.string()])),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * VideoOutput
 *
 * Base output for video generation
 */
export const zSchemaWan25PreviewImageToVideoOutput = z
  .object({
    actual_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The actual prompt used if prompt rewriting was enabled',
      }),
    ),
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed used for generation',
    }),
    video: zSchemaVideoFile,
  })
  .register(z.globalRegistry, {
    description: 'Base output for video generation',
  })

/**
 * ImageToVideoInput
 *
 * Input for image-to-video generation
 */
export const zSchemaWan25PreviewImageToVideoInput = z
  .object({
    prompt: z.string().min(1).register(z.globalRegistry, {
      description:
        'The text prompt describing the desired video motion. Max 800 characters.',
    }),
    resolution: z.optional(
      z.enum(['480p', '720p', '1080p']).register(z.globalRegistry, {
        description: 'Video resolution. Valid values: 480p, 720p, 1080p',
      }),
    ),
    duration: z.optional(
      z.enum(['5', '10']).register(z.globalRegistry, {
        description:
          'Duration of the generated video in seconds. Choose between 5 or 10 seconds.',
      }),
    ),
    image_url: z.union([z.string(), z.string()]),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'If set to true, the safety checker will be enabled.',
        }),
      )
      .default(true),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    ),
    audio_url: z.optional(z.union([z.string(), z.string()])),
    negative_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'Negative prompt to describe content to avoid. Max 500 characters.',
      }),
    ),
    enable_prompt_expansion: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable prompt rewriting using LLM.',
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description: 'Input for image-to-video generation',
  })

/**
 * ProImageToVideoHailuo23Output
 */
export const zSchemaMinimaxHailuo23ProImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ProImageToVideoHailuo23Input
 */
export const zSchemaMinimaxHailuo23ProImageToVideoInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  prompt: z.string().min(1).max(2000).register(z.globalRegistry, {
    description: 'Text prompt for video generation',
  }),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * VideoOutput
 */
export const zSchemaMinimaxVideo01ImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoRequest
 */
export const zSchemaMinimaxVideo01ImageToVideoInput = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  prompt: z.string().max(2000),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * I2VOutput
 */
export const zSchemaKlingVideoV16ProImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ProImageToVideoRequest
 */
export const zSchemaKlingVideoV16ProImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated video frame',
    }),
  ),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default('blur, distort, and low quality'),
  duration: z.optional(
    z.enum(['5', '10']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  tail_image_url: z.optional(z.union([z.string(), z.string()])),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ',
      }),
    )
    .default(0.5),
})

/**
 * ImageToVideoOutput
 */
export const zSchemaVeo2ImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * ImageToVideoInput
 */
export const zSchemaVeo2ImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt describing how the image should be animated',
  }),
  duration: z.optional(
    z.enum(['5s', '6s', '7s', '8s']).register(z.globalRegistry, {
      description: 'The duration of the generated video in seconds',
    }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(['auto', 'auto_prefer_portrait', '16:9', '9:16'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video',
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * WanProI2VResponse
 */
export const zSchemaWanProImageToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * WanProI2VRequest
 */
export const zSchemaWanProImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video',
  }),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker',
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  image_url: z.union([z.string(), z.string()]),
})

/**
 * WanEffectsOutput
 */
export const zSchemaWanEffectsOutput = z.object({
  seed: z.int(),
  video: zSchemaFile,
})

/**
 * BaseInput
 */
export const zSchemaWanEffectsInput = z.object({
  effect_type: z.optional(
    z
      .enum([
        'squish',
        'muscle',
        'inflate',
        'crush',
        'rotate',
        'gun-shooting',
        'deflate',
        'cakeify',
        'hulk',
        'baby',
        'bride',
        'classy',
        'puppy',
        'snow-white',
        'disney-princess',
        'mona-lisa',
        'painting',
        'pirate-captain',
        'princess',
        'jungle',
        'samurai',
        'vip',
        'warrior',
        'zen',
        'assassin',
        'timelapse',
        'tsunami',
        'fire',
        'zoom-call',
        'doom-fps',
        'fus-ro-dah',
        'hug-jesus',
        'robot-face-reveal',
        'super-saiyan',
        'jumpscare',
        'laughing',
        'cartoon-jaw-drop',
        'crying',
        'kissing',
        'angry-face',
        'selfie-younger-self',
        'animeify',
        'blast',
      ])
      .register(z.globalRegistry, {
        description: 'The type of effect to apply to the video.',
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'Aspect ratio of the output video.',
    }),
  ),
  subject: z.string().register(z.globalRegistry, {
    description:
      'The subject to insert into the predefined prompt template for the selected effect.',
  }),
  lora_scale: z
    .optional(
      z.number().gte(0.1).lte(2).register(z.globalRegistry, {
        description:
          'The scale of the LoRA weight. Used to adjust effect intensity.',
      }),
    )
    .default(1),
  image_url: z.union([z.string(), z.string()]),
  turbo_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use turbo mode. If True, the video will be generated faster but with lower quality.',
      }),
    )
    .default(false),
  frames_per_second: z
    .optional(
      z.int().gte(5).lte(24).register(z.globalRegistry, {
        description: 'Frames per second of the generated video.',
      }),
    )
    .default(16),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(81).lte(100).register(z.globalRegistry, {
        description: 'Number of frames to generate.',
      }),
    )
    .default(81),
})

/**
 * EchoMimicResponse
 */
export const zSchemaEchomimicV3Output = z.object({
  video: zSchemaFile,
})

/**
 * EchoMimicRequest
 */
export const zSchemaEchomimicV3Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to use for the video generation.',
  }),
  audio_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use for the video generation.',
      }),
    )
    .default(4.5),
  audio_guidance_scale: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description:
          'The audio guidance scale to use for the video generation.',
      }),
    )
    .default(2.5),
  num_frames_per_generation: z
    .optional(
      z.int().gte(49).lte(161).register(z.globalRegistry, {
        description: 'The number of frames to generate at once.',
      }),
    )
    .default(121),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to use for the video generation.',
      }),
    )
    .default(''),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for the video generation.',
    }),
  ),
})

/**
 * StableAvatarResponse
 */
export const zSchemaStableAvatarOutput = z.object({
  video: zSchemaFile,
})

/**
 * StableAvatarRequest
 */
export const zSchemaStableAvatarInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to use for the video generation.',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '1:1', '9:16', 'auto']).register(z.globalRegistry, {
      description:
        "The aspect ratio of the video to generate. If 'auto', the aspect ratio will be determined by the reference image.",
    }),
  ),
  perturbation: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The amount of perturbation to use for the video generation. 0.0 means no perturbation, 1.0 means full perturbation.',
      }),
    )
    .default(0.1),
  image_url: z.union([z.string(), z.string()]),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use for the video generation.',
      }),
    )
    .default(5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for the video generation.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(10).lte(50).register(z.globalRegistry, {
        description:
          'The number of inference steps to use for the video generation.',
      }),
    )
    .default(50),
  audio_url: z.union([z.string(), z.string()]),
  audio_guidance_scale: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description:
          'The audio guidance scale to use for the video generation.',
      }),
    )
    .default(4),
})

/**
 * WanS2VResponse
 */
export const zSchemaWanV2214bSpeechToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * WanS2VRequest
 */
export const zSchemaWanV2214bSpeechToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt used for video generation.',
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift value for the video. Must be between 1.0 and 10.0.',
      }),
    )
    .default(5),
  frames_per_second: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.',
      }),
    )
    .default(16),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(3.5),
  num_frames: z
    .optional(
      z.int().gte(40).lte(120).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 40 to 120, (must be multiple of 4).',
      }),
    )
    .default(80),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, input data will be checked for safety before processing.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(''),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description:
        'The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p, 580p, or 720p).',
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, output video will be checked for safety after generation.',
      }),
    )
    .default(false),
  image_url: z.union([z.string(), z.string()]),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description:
        'The quality of the output video. Higher quality means better visual quality but larger file size.',
    }),
  ),
  audio_url: z.union([z.string(), z.string()]),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(27),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
})

/**
 * AvatarsAppOutput
 */
export const zSchemaAvatarsAudioToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Audio2VideoInput
 */
export const zSchemaAvatarsAudioToVideoInput = z.object({
  audio_url: z.union([z.string(), z.string()]),
  avatar_id: z
    .enum([
      'emily_vertical_primary',
      'emily_vertical_secondary',
      'marcus_vertical_primary',
      'marcus_vertical_secondary',
      'mira_vertical_primary',
      'mira_vertical_secondary',
      'jasmine_vertical_primary',
      'jasmine_vertical_secondary',
      'jasmine_vertical_walking',
      'aisha_vertical_walking',
      'elena_vertical_primary',
      'elena_vertical_secondary',
      'any_male_vertical_primary',
      'any_female_vertical_primary',
      'any_male_vertical_secondary',
      'any_female_vertical_secondary',
      'any_female_vertical_walking',
      'emily_primary',
      'emily_side',
      'marcus_primary',
      'marcus_side',
      'aisha_walking',
      'elena_primary',
      'elena_side',
      'any_male_primary',
      'any_female_primary',
      'any_male_side',
      'any_female_side',
    ])
    .register(z.globalRegistry, {
      description: 'The avatar to use for the video',
    }),
})

/**
 * AudioToVideoResponse
 *
 * Response model for audio-to-video generation (no reference image).
 */
export const zSchemaLongcatSingleAvatarAudioToVideoOutput = z
  .object({
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed used for generation.',
    }),
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description:
      'Response model for audio-to-video generation (no reference image).',
  })

/**
 * AudioToVideoRequest
 *
 * Request model for audio-to-video generation.
 */
export const zSchemaLongcatSingleAvatarAudioToVideoInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The prompt to guide the video generation.',
        }),
      )
      .default(
        'A person is talking naturally with natural expressions and movements.',
      ),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description:
          'Resolution of the generated video (480p or 720p). Billing is per video-second (16 frames): 480p is 1 unit per second and 720p is 4 units per second.',
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable safety checker.',
        }),
      )
      .default(true),
    audio_guidance_scale: z
      .optional(
        z.number().gte(1).lte(10).register(z.globalRegistry, {
          description:
            'The audio guidance scale. Higher values may lead to exaggerated mouth movements.',
        }),
      )
      .default(4),
    num_segments: z
      .optional(
        z.int().gte(1).lte(10).register(z.globalRegistry, {
          description:
            'Number of video segments to generate. Each segment adds ~5 seconds of video. First segment is ~5.8s, additional segments are 5s each.',
        }),
      )
      .default(1),
    audio_url: z.union([z.string(), z.string()]),
    num_inference_steps: z
      .optional(
        z.int().gte(10).lte(100).register(z.globalRegistry, {
          description: 'The number of inference steps to use.',
        }),
      )
      .default(30),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the random number generator.',
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt to avoid in the video generation.',
        }),
      )
      .default(
        'Close-up, Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards',
      ),
    text_guidance_scale: z
      .optional(
        z.number().gte(1).lte(10).register(z.globalRegistry, {
          description: 'The text guidance scale for classifier-free guidance.',
        }),
      )
      .default(4),
  })
  .register(z.globalRegistry, {
    description: 'Request model for audio-to-video generation.',
  })

/**
 * ImageAudioToVideoResponse
 *
 * Response model for image+audio to video generation.
 */
export const zSchemaLongcatSingleAvatarImageAudioToVideoOutput = z
  .object({
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed used for generation.',
    }),
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Response model for image+audio to video generation.',
  })

/**
 * ImageAudioToVideoRequest
 *
 * Request model for image+audio to video generation.
 */
export const zSchemaLongcatSingleAvatarImageAudioToVideoInput = z
  .object({
    prompt: z.string().register(z.globalRegistry, {
      description: 'The prompt to guide the video generation.',
    }),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description:
          'Resolution of the generated video (480p or 720p). Billing is per video-second (16 frames): 480p is 1 unit per second and 720p is 4 units per second.',
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable safety checker.',
        }),
      )
      .default(true),
    audio_guidance_scale: z
      .optional(
        z.number().gte(1).lte(10).register(z.globalRegistry, {
          description:
            'The audio guidance scale. Higher values may lead to exaggerated mouth movements.',
        }),
      )
      .default(4),
    num_segments: z
      .optional(
        z.int().gte(1).lte(10).register(z.globalRegistry, {
          description:
            'Number of video segments to generate. Each segment adds ~5 seconds of video. First segment is ~5.8s, additional segments are 5s each.',
        }),
      )
      .default(1),
    image_url: z.union([z.string(), z.string()]),
    audio_url: z.union([z.string(), z.string()]),
    num_inference_steps: z
      .optional(
        z.int().gte(10).lte(100).register(z.globalRegistry, {
          description: 'The number of inference steps to use.',
        }),
      )
      .default(30),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the random number generator.',
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt to avoid in the video generation.',
        }),
      )
      .default(
        'Close-up, Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards',
      ),
    text_guidance_scale: z
      .optional(
        z.number().gte(1).lte(10).register(z.globalRegistry, {
          description: 'The text guidance scale for classifier-free guidance.',
        }),
      )
      .default(4),
  })
  .register(z.globalRegistry, {
    description: 'Request model for image+audio to video generation.',
  })

/**
 * BoundingBox
 */
export const zSchemaBoundingBox = z.object({
  y: z.number().register(z.globalRegistry, {
    description: 'Y-coordinate of the top-left corner',
  }),
  x: z.number().register(z.globalRegistry, {
    description: 'X-coordinate of the top-left corner',
  }),
  h: z.number().register(z.globalRegistry, {
    description: 'Height of the bounding box',
  }),
  w: z.number().register(z.globalRegistry, {
    description: 'Width of the bounding box',
  }),
  label: z.string().register(z.globalRegistry, {
    description: 'Label of the bounding box',
  }),
})

/**
 * MultiSpeakerImageAudioToVideoResponse
 *
 * Response model for multi-speaker image+audio to video generation.
 */
export const zSchemaLongcatMultiAvatarImageAudioToVideoOutput = z
  .object({
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed used for generation.',
    }),
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description:
      'Response model for multi-speaker image+audio to video generation.',
  })

/**
 * MultiSpeakerImageAudioToVideoRequest
 *
 * Request model for multi-speaker image+audio to video generation.
 */
export const zSchemaLongcatMultiAvatarImageAudioToVideoInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The prompt to guide the video generation.',
        }),
      )
      .default(
        'Two people are having a conversation with natural expressions and movements.',
      ),
    num_inference_steps: z
      .optional(
        z.int().gte(10).lte(100).register(z.globalRegistry, {
          description: 'The number of inference steps to use.',
        }),
      )
      .default(30),
    audio_url_person2: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The URL of the audio file for person 2 (right side).',
        }),
      )
      .default(
        'https://raw.githubusercontent.com/meituan-longcat/LongCat-Video/refs/heads/main/assets/avatar/multi/sing_woman.WAV',
      ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable safety checker.',
        }),
      )
      .default(true),
    bbox_person1: z.optional(zSchemaBoundingBox),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt to avoid in the video generation.',
        }),
      )
      .default(
        'Close-up, Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards',
      ),
    text_guidance_scale: z
      .optional(
        z.number().gte(1).lte(10).register(z.globalRegistry, {
          description: 'The text guidance scale for classifier-free guidance.',
        }),
      )
      .default(4),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description:
          'Resolution of the generated video (480p or 720p). Billing is per video-second (16 frames): 480p is 1 unit per second and 720p is 4 units per second.',
      }),
    ),
    audio_type: z.optional(
      z.enum(['para', 'add']).register(z.globalRegistry, {
        description:
          "How to combine the two audio tracks. 'para' (parallel) plays both simultaneously, 'add' (sequential) plays person 1 first then person 2.",
      }),
    ),
    image_url: z.union([z.string(), z.string()]),
    audio_url_person1: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The URL of the audio file for person 1 (left side).',
        }),
      )
      .default(
        'https://raw.githubusercontent.com/meituan-longcat/LongCat-Video/refs/heads/main/assets/avatar/multi/sing_man.WAV',
      ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the random number generator.',
      }),
    ),
    audio_guidance_scale: z
      .optional(
        z.number().gte(1).lte(10).register(z.globalRegistry, {
          description:
            'The audio guidance scale. Higher values may lead to exaggerated mouth movements.',
        }),
      )
      .default(4),
    bbox_person2: z.optional(zSchemaBoundingBox),
    num_segments: z
      .optional(
        z.int().gte(1).lte(10).register(z.globalRegistry, {
          description:
            'Number of video segments to generate. Each segment adds ~5 seconds of video. First segment is ~5.8s, additional segments are 5s each.',
        }),
      )
      .default(1),
  })
  .register(z.globalRegistry, {
    description:
      'Request model for multi-speaker image+audio to video generation.',
  })

/**
 * DubbingVideoOutput
 */
export const zSchemaElevenlabsDubbingOutput = z.object({
  target_lang: z.string().register(z.globalRegistry, {
    description: 'The target language of the dubbed content',
  }),
  video: zSchemaFile,
})

/**
 * DubbingRequest
 */
export const zSchemaElevenlabsDubbingInput = z.object({
  video_url: z.optional(z.union([z.string(), z.unknown()])),
  audio_url: z.optional(z.union([z.string(), z.unknown()])),
  highest_resolution: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to use the highest resolution for dubbing.',
      }),
    )
    .default(true),
  target_lang: z.string().register(z.globalRegistry, {
    description: 'Target language code for dubbing (ISO 639-1)',
  }),
  source_lang: z.optional(z.union([z.string(), z.unknown()])),
  num_speakers: z.optional(z.union([z.int().gte(1).lte(50), z.unknown()])),
})

/**
 * LTX2AudioToVideoOutput
 */
export const zSchemaLtx219bAudioToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2AudioToVideoInput
 */
export const zSchemaLtx219bAudioToVideoInput = z.object({
  match_audio_length: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'When enabled, the number of frames will be calculated based on the audio duration and FPS. When disabled, use the specified num_frames.',
      }),
    )
    .default(true),
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the image to use for the video generation.',
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use.',
      }),
    )
    .default(3),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  preprocess_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to preprocess the audio before using it as conditioning.',
      }),
    )
    .default(true),
  image_url: z.optional(z.union([z.string(), z.unknown()])),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  audio_url: z.union([z.string(), z.string()]),
  audio_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Audio conditioning strength. Values below 1.0 will allow the model to change the audio, while a value of exactly 1.0 will use the input audio without modification.',
      }),
    )
    .default(1),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to use.',
      }),
    )
    .default(40),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
})

/**
 * LTX2AudioToVideoOutput
 */
export const zSchemaLtx219bDistilledAudioToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2DistilledAudioToVideoInput
 */
export const zSchemaLtx219bDistilledAudioToVideoInput = z.object({
  match_audio_length: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'When enabled, the number of frames will be calculated based on the audio duration and FPS. When disabled, use the specified num_frames.',
      }),
    )
    .default(true),
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the image to use for the video generation.',
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  preprocess_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to preprocess the audio before using it as conditioning.',
      }),
    )
    .default(true),
  image_url: z.optional(z.union([z.string(), z.unknown()])),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  audio_url: z.union([z.string(), z.string()]),
  audio_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Audio conditioning strength. Values below 1.0 will allow the model to change the audio, while a value of exactly 1.0 will use the input audio without modification.',
      }),
    )
    .default(1),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
})

/**
 * LTX2AudioToVideoOutput
 */
export const zSchemaLtx219bAudioToVideoLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2LoRAAudioToVideoInput
 */
export const zSchemaLtx219bAudioToVideoLoraInput = z.object({
  match_audio_length: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'When enabled, the number of frames will be calculated based on the audio duration and FPS. When disabled, use the specified num_frames.',
      }),
    )
    .default(true),
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  loras: z.array(zSchemaLoRaInput).register(z.globalRegistry, {
    description: 'The LoRAs to use for the generation.',
  }),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the image to use for the video generation.',
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use.',
      }),
    )
    .default(3),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  preprocess_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to preprocess the audio before using it as conditioning.',
      }),
    )
    .default(true),
  image_url: z.optional(z.union([z.string(), z.unknown()])),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  audio_url: z.union([z.string(), z.string()]),
  audio_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Audio conditioning strength. Values below 1.0 will allow the model to change the audio, while a value of exactly 1.0 will use the input audio without modification.',
      }),
    )
    .default(1),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to use.',
      }),
    )
    .default(40),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
})

/**
 * LTX2AudioToVideoOutput
 */
export const zSchemaLtx219bDistilledAudioToVideoLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2LoRADistilledAudioToVideoInput
 */
export const zSchemaLtx219bDistilledAudioToVideoLoraInput = z.object({
  match_audio_length: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'When enabled, the number of frames will be calculated based on the audio duration and FPS. When disabled, use the specified num_frames.',
      }),
    )
    .default(true),
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  loras: z.array(zSchemaLoRaInput).register(z.globalRegistry, {
    description: 'The LoRAs to use for the generation.',
  }),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the image to use for the video generation.',
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  preprocess_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to preprocess the audio before using it as conditioning.',
      }),
    )
    .default(true),
  image_url: z.optional(z.union([z.string(), z.unknown()])),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  audio_url: z.union([z.string(), z.string()]),
  audio_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Audio conditioning strength. Values below 1.0 will allow the model to change the audio, while a value of exactly 1.0 will use the input audio without modification.',
      }),
    )
    .default(1),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
})

export const zSchemaQueueStatus = z.object({
  status: z.enum(['IN_QUEUE', 'IN_PROGRESS', 'COMPLETED']),
  request_id: z.string().register(z.globalRegistry, {
    description: 'The request id.',
  }),
  response_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The response url.',
    }),
  ),
  status_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The status url.',
    }),
  ),
  cancel_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The cancel url.',
    }),
  ),
  logs: z.optional(
    z.record(z.string(), z.unknown()).register(z.globalRegistry, {
      description: 'The logs.',
    }),
  ),
  metrics: z.optional(
    z.record(z.string(), z.unknown()).register(z.globalRegistry, {
      description: 'The metrics.',
    }),
  ),
  queue_position: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The queue position.',
    }),
  ),
})

export const zGetFalAiLtx219bDistilledAudioToVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bDistilledAudioToVideoLoraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bDistilledAudioToVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bDistilledAudioToVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtx219bDistilledAudioToVideoLoraData = z.object({
  body: zSchemaLtx219bDistilledAudioToVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bDistilledAudioToVideoLoraResponse =
  zSchemaQueueStatus

export const zGetFalAiLtx219bDistilledAudioToVideoLoraRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bDistilledAudioToVideoLoraRequestsByRequestIdResponse =
  zSchemaLtx219bDistilledAudioToVideoLoraOutput

export const zGetFalAiLtx219bAudioToVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bAudioToVideoLoraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bAudioToVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bAudioToVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtx219bAudioToVideoLoraData = z.object({
  body: zSchemaLtx219bAudioToVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bAudioToVideoLoraResponse = zSchemaQueueStatus

export const zGetFalAiLtx219bAudioToVideoLoraRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bAudioToVideoLoraRequestsByRequestIdResponse =
  zSchemaLtx219bAudioToVideoLoraOutput

export const zGetFalAiLtx219bDistilledAudioToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bDistilledAudioToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bDistilledAudioToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bDistilledAudioToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtx219bDistilledAudioToVideoData = z.object({
  body: zSchemaLtx219bDistilledAudioToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bDistilledAudioToVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtx219bDistilledAudioToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bDistilledAudioToVideoRequestsByRequestIdResponse =
  zSchemaLtx219bDistilledAudioToVideoOutput

export const zGetFalAiLtx219bAudioToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bAudioToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bAudioToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bAudioToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtx219bAudioToVideoData = z.object({
  body: zSchemaLtx219bAudioToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bAudioToVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtx219bAudioToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bAudioToVideoRequestsByRequestIdResponse =
  zSchemaLtx219bAudioToVideoOutput

export const zGetFalAiElevenlabsDubbingRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiElevenlabsDubbingRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiElevenlabsDubbingRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiElevenlabsDubbingRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiElevenlabsDubbingData = z.object({
  body: zSchemaElevenlabsDubbingInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiElevenlabsDubbingResponse = zSchemaQueueStatus

export const zGetFalAiElevenlabsDubbingRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiElevenlabsDubbingRequestsByRequestIdResponse =
  zSchemaElevenlabsDubbingOutput

export const zGetFalAiLongcatMultiAvatarImageAudioToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLongcatMultiAvatarImageAudioToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLongcatMultiAvatarImageAudioToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLongcatMultiAvatarImageAudioToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLongcatMultiAvatarImageAudioToVideoData = z.object({
  body: zSchemaLongcatMultiAvatarImageAudioToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLongcatMultiAvatarImageAudioToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiLongcatMultiAvatarImageAudioToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLongcatMultiAvatarImageAudioToVideoRequestsByRequestIdResponse =
  zSchemaLongcatMultiAvatarImageAudioToVideoOutput

export const zGetFalAiLongcatSingleAvatarImageAudioToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLongcatSingleAvatarImageAudioToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLongcatSingleAvatarImageAudioToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLongcatSingleAvatarImageAudioToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLongcatSingleAvatarImageAudioToVideoData = z.object({
  body: zSchemaLongcatSingleAvatarImageAudioToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLongcatSingleAvatarImageAudioToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiLongcatSingleAvatarImageAudioToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLongcatSingleAvatarImageAudioToVideoRequestsByRequestIdResponse =
  zSchemaLongcatSingleAvatarImageAudioToVideoOutput

export const zGetFalAiLongcatSingleAvatarAudioToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLongcatSingleAvatarAudioToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLongcatSingleAvatarAudioToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLongcatSingleAvatarAudioToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLongcatSingleAvatarAudioToVideoData = z.object({
  body: zSchemaLongcatSingleAvatarAudioToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLongcatSingleAvatarAudioToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiLongcatSingleAvatarAudioToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLongcatSingleAvatarAudioToVideoRequestsByRequestIdResponse =
  zSchemaLongcatSingleAvatarAudioToVideoOutput

export const zGetArgilAvatarsAudioToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetArgilAvatarsAudioToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutArgilAvatarsAudioToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutArgilAvatarsAudioToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostArgilAvatarsAudioToVideoData = z.object({
  body: zSchemaAvatarsAudioToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostArgilAvatarsAudioToVideoResponse = zSchemaQueueStatus

export const zGetArgilAvatarsAudioToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetArgilAvatarsAudioToVideoRequestsByRequestIdResponse =
  zSchemaAvatarsAudioToVideoOutput

export const zGetFalAiWanV2214bSpeechToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanV2214bSpeechToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanV2214bSpeechToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV2214bSpeechToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWanV2214bSpeechToVideoData = z.object({
  body: zSchemaWanV2214bSpeechToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanV2214bSpeechToVideoResponse = zSchemaQueueStatus

export const zGetFalAiWanV2214bSpeechToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanV2214bSpeechToVideoRequestsByRequestIdResponse =
  zSchemaWanV2214bSpeechToVideoOutput

export const zGetFalAiStableAvatarRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiStableAvatarRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiStableAvatarRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiStableAvatarRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiStableAvatarData = z.object({
  body: zSchemaStableAvatarInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiStableAvatarResponse = zSchemaQueueStatus

export const zGetFalAiStableAvatarRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiStableAvatarRequestsByRequestIdResponse =
  zSchemaStableAvatarOutput

export const zGetFalAiEchomimicV3RequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiEchomimicV3RequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiEchomimicV3RequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiEchomimicV3RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiEchomimicV3Data = z.object({
  body: zSchemaEchomimicV3Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiEchomimicV3Response = zSchemaQueueStatus

export const zGetFalAiEchomimicV3RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiEchomimicV3RequestsByRequestIdResponse =
  zSchemaEchomimicV3Output

export const zGetVeedAvatarsAudioToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetVeedAvatarsAudioToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutVeedAvatarsAudioToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutVeedAvatarsAudioToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostVeedAvatarsAudioToVideoData = z.object({
  body: zSchemaAvatarsAudioToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostVeedAvatarsAudioToVideoResponse = zSchemaQueueStatus

export const zGetVeedAvatarsAudioToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetVeedAvatarsAudioToVideoRequestsByRequestIdResponse =
  zSchemaAvatarsAudioToVideoOutput

export const zGetFalAiWanEffectsRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanEffectsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanEffectsRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanEffectsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanEffectsData = z.object({
  body: zSchemaWanEffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanEffectsResponse = zSchemaQueueStatus

export const zGetFalAiWanEffectsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanEffectsRequestsByRequestIdResponse =
  zSchemaWanEffectsOutput

export const zGetFalAiWanProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanProImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanProImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanProImageToVideoData = z.object({
  body: zSchemaWanProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanProImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiWanProImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanProImageToVideoRequestsByRequestIdResponse =
  zSchemaWanProImageToVideoOutput

export const zGetFalAiVeo2ImageToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiVeo2ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVeo2ImageToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo2ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiVeo2ImageToVideoData = z.object({
  body: zSchemaVeo2ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVeo2ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiVeo2ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiVeo2ImageToVideoRequestsByRequestIdResponse =
  zSchemaVeo2ImageToVideoOutput

export const zGetFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV16ProImageToVideoData = z.object({
  body: zSchemaKlingVideoV16ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV16ProImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV16ProImageToVideoOutput

export const zGetFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxVideo01ImageToVideoData = z.object({
  body: zSchemaMinimaxVideo01ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxVideo01ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdResponse =
  zSchemaMinimaxVideo01ImageToVideoOutput

export const zGetFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxHailuo23ProImageToVideoData = z.object({
  body: zSchemaMinimaxHailuo23ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo23ProImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdResponse =
  zSchemaMinimaxHailuo23ProImageToVideoOutput

export const zGetFalAiWan25PreviewImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWan25PreviewImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWan25PreviewImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWan25PreviewImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWan25PreviewImageToVideoData = z.object({
  body: zSchemaWan25PreviewImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWan25PreviewImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiWan25PreviewImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiWan25PreviewImageToVideoRequestsByRequestIdResponse =
  zSchemaWan25PreviewImageToVideoOutput

export const zGetFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV25TurboProImageToVideoData = z.object({
  body: zSchemaKlingVideoV25TurboProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV25TurboProImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV25TurboProImageToVideoOutput

export const zGetFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxHailuo02StandardImageToVideoData = z.object({
  body: zSchemaMinimaxHailuo02StandardImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo02StandardImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdResponse =
  zSchemaMinimaxHailuo02StandardImageToVideoOutput

export const zGetFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiBytedanceSeedanceV1ProImageToVideoData = z.object({
  body: zSchemaBytedanceSeedanceV1ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiBytedanceSeedanceV1ProImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdResponse =
  zSchemaBytedanceSeedanceV1ProImageToVideoOutput

export const zGetFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV21MasterImageToVideoData = z.object({
  body: zSchemaKlingVideoV21MasterImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV21MasterImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV21MasterImageToVideoOutput

export const zGetFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV21StandardImageToVideoData = z.object({
  body: zSchemaKlingVideoV21StandardImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV21StandardImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV21StandardImageToVideoOutput

export const zGetFalAiPixverseV45ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV45ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV45ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV45ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPixverseV45ImageToVideoData = z.object({
  body: zSchemaPixverseV45ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV45ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV45ImageToVideoRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV45ImageToVideoRequestsByRequestIdResponse =
  zSchemaPixverseV45ImageToVideoOutput

export const zGetFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV2MasterImageToVideoData = z.object({
  body: zSchemaKlingVideoV2MasterImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV2MasterImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV2MasterImageToVideoOutput

export const zGetFalAiWanI2vRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanI2vRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanI2vRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanI2vRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanI2vData = z.object({
  body: zSchemaWanI2vInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanI2vResponse = zSchemaQueueStatus

export const zGetFalAiWanI2vRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanI2vRequestsByRequestIdResponse = zSchemaWanI2vOutput

export const zGetFalAiPixverseV56TransitionRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV56TransitionRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV56TransitionRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV56TransitionRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseV56TransitionData = z.object({
  body: zSchemaPixverseV56TransitionInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV56TransitionResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV56TransitionRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV56TransitionRequestsByRequestIdResponse =
  zSchemaPixverseV56TransitionOutput

export const zGetFalAiPixverseV56ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV56ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV56ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV56ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPixverseV56ImageToVideoData = z.object({
  body: zSchemaPixverseV56ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV56ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV56ImageToVideoRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV56ImageToVideoRequestsByRequestIdResponse =
  zSchemaPixverseV56ImageToVideoOutput

export const zGetFalAiViduQ2ReferenceToVideoProRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiViduQ2ReferenceToVideoProRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiViduQ2ReferenceToVideoProRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ2ReferenceToVideoProRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiViduQ2ReferenceToVideoProData = z.object({
  body: zSchemaViduQ2ReferenceToVideoProInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiViduQ2ReferenceToVideoProResponse = zSchemaQueueStatus

export const zGetFalAiViduQ2ReferenceToVideoProRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiViduQ2ReferenceToVideoProRequestsByRequestIdResponse =
  zSchemaViduQ2ReferenceToVideoProOutput

export const zGetWanV26ImageToVideoFlashRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetWanV26ImageToVideoFlashRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutWanV26ImageToVideoFlashRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutWanV26ImageToVideoFlashRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostWanV26ImageToVideoFlashData = z.object({
  body: zSchemaV26ImageToVideoFlashInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostWanV26ImageToVideoFlashResponse = zSchemaQueueStatus

export const zGetWanV26ImageToVideoFlashRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetWanV26ImageToVideoFlashRequestsByRequestIdResponse =
  zSchemaV26ImageToVideoFlashOutput

export const zGetFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtx219bDistilledImageToVideoLoraData = z.object({
  body: zSchemaLtx219bDistilledImageToVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bDistilledImageToVideoLoraResponse =
  zSchemaQueueStatus

export const zGetFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdResponse =
  zSchemaLtx219bDistilledImageToVideoLoraOutput

export const zGetFalAiLtx219bDistilledImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bDistilledImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bDistilledImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bDistilledImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtx219bDistilledImageToVideoData = z.object({
  body: zSchemaLtx219bDistilledImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bDistilledImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtx219bDistilledImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bDistilledImageToVideoRequestsByRequestIdResponse =
  zSchemaLtx219bDistilledImageToVideoOutput

export const zGetFalAiLtx219bImageToVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bImageToVideoLoraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bImageToVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bImageToVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtx219bImageToVideoLoraData = z.object({
  body: zSchemaLtx219bImageToVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bImageToVideoLoraResponse = zSchemaQueueStatus

export const zGetFalAiLtx219bImageToVideoLoraRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bImageToVideoLoraRequestsByRequestIdResponse =
  zSchemaLtx219bImageToVideoLoraOutput

export const zGetFalAiLtx219bImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtx219bImageToVideoData = z.object({
  body: zSchemaLtx219bImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtx219bImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bImageToVideoRequestsByRequestIdResponse =
  zSchemaLtx219bImageToVideoOutput

export const zGetFalAiWanMoveRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanMoveRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanMoveRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanMoveRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanMoveData = z.object({
  body: zSchemaWanMoveInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanMoveResponse = zSchemaQueueStatus

export const zGetFalAiWanMoveRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanMoveRequestsByRequestIdResponse = zSchemaWanMoveOutput

export const zGetFalAiKandinsky5ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKandinsky5ProImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKandinsky5ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKandinsky5ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKandinsky5ProImageToVideoData = z.object({
  body: zSchemaKandinsky5ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKandinsky5ProImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiKandinsky5ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKandinsky5ProImageToVideoRequestsByRequestIdResponse =
  zSchemaKandinsky5ProImageToVideoOutput

export const zGetFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiBytedanceSeedanceV15ProImageToVideoData = z.object({
  body: zSchemaBytedanceSeedanceV15ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiBytedanceSeedanceV15ProImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdResponse =
  zSchemaBytedanceSeedanceV15ProImageToVideoOutput

export const zGetFalAiLiveAvatarRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiLiveAvatarRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLiveAvatarRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiLiveAvatarRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLiveAvatarData = z.object({
  body: zSchemaLiveAvatarInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLiveAvatarResponse = zSchemaQueueStatus

export const zGetFalAiLiveAvatarRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLiveAvatarRequestsByRequestIdResponse =
  zSchemaLiveAvatarOutput

export const zGetFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiHunyuanVideoV15ImageToVideoData = z.object({
  body: zSchemaHunyuanVideoV15ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiHunyuanVideoV15ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdResponse =
  zSchemaHunyuanVideoV15ImageToVideoOutput

export const zGetWanV26ImageToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetWanV26ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutWanV26ImageToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutWanV26ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostWanV26ImageToVideoData = z.object({
  body: zSchemaV26ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostWanV26ImageToVideoResponse = zSchemaQueueStatus

export const zGetWanV26ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetWanV26ImageToVideoRequestsByRequestIdResponse =
  zSchemaV26ImageToVideoOutput

export const zGetFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoO1StandardReferenceToVideoData = z.object({
  body: zSchemaKlingVideoO1StandardReferenceToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoO1StandardReferenceToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoO1StandardReferenceToVideoOutput

export const zGetFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoO1StandardImageToVideoData = z.object({
  body: zSchemaKlingVideoO1StandardImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoO1StandardImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoO1StandardImageToVideoOutput

export const zGetFalAiCreatifyAuroraRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiCreatifyAuroraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiCreatifyAuroraRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiCreatifyAuroraRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiCreatifyAuroraData = z.object({
  body: zSchemaCreatifyAuroraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiCreatifyAuroraResponse = zSchemaQueueStatus

export const zGetFalAiCreatifyAuroraRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiCreatifyAuroraRequestsByRequestIdResponse =
  zSchemaCreatifyAuroraOutput

export const zGetFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoAiAvatarV2ProData = z.object({
  body: zSchemaKlingVideoAiAvatarV2ProInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoAiAvatarV2ProResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdResponse =
  zSchemaKlingVideoAiAvatarV2ProOutput

export const zGetFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoAiAvatarV2StandardData = z.object({
  body: zSchemaKlingVideoAiAvatarV2StandardInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoAiAvatarV2StandardResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdResponse =
  zSchemaKlingVideoAiAvatarV2StandardOutput

export const zGetFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV26ProImageToVideoData = z.object({
  body: zSchemaKlingVideoV26ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV26ProImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV26ProImageToVideoOutput

export const zGetFalAiPixverseV55EffectsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV55EffectsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV55EffectsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV55EffectsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseV55EffectsData = z.object({
  body: zSchemaPixverseV55EffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV55EffectsResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV55EffectsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV55EffectsRequestsByRequestIdResponse =
  zSchemaPixverseV55EffectsOutput

export const zGetFalAiPixverseV55TransitionRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV55TransitionRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV55TransitionRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV55TransitionRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseV55TransitionData = z.object({
  body: zSchemaPixverseV55TransitionInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV55TransitionResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV55TransitionRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV55TransitionRequestsByRequestIdResponse =
  zSchemaPixverseV55TransitionOutput

export const zGetFalAiPixverseV55ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV55ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV55ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV55ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPixverseV55ImageToVideoData = z.object({
  body: zSchemaPixverseV55ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV55ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV55ImageToVideoRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV55ImageToVideoRequestsByRequestIdResponse =
  zSchemaPixverseV55ImageToVideoOutput

export const zGetFalAiKlingVideoO1ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoO1ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoO1ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoO1ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoO1ImageToVideoData = z.object({
  body: zSchemaKlingVideoO1ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoO1ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoO1ImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoO1ImageToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoO1ImageToVideoOutput

export const zGetFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoO1ReferenceToVideoData = z.object({
  body: zSchemaKlingVideoO1ReferenceToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoO1ReferenceToVideoResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoO1ReferenceToVideoOutput

export const zGetFalAiLtx2ImageToVideoFastRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx2ImageToVideoFastRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx2ImageToVideoFastRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx2ImageToVideoFastRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtx2ImageToVideoFastData = z.object({
  body: zSchemaLtx2ImageToVideoFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx2ImageToVideoFastResponse = zSchemaQueueStatus

export const zGetFalAiLtx2ImageToVideoFastRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtx2ImageToVideoFastRequestsByRequestIdResponse =
  zSchemaLtx2ImageToVideoFastOutput

export const zGetFalAiLtx2ImageToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiLtx2ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx2ImageToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx2ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtx2ImageToVideoData = z.object({
  body: zSchemaLtx2ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx2ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtx2ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtx2ImageToVideoRequestsByRequestIdResponse =
  zSchemaLtx2ImageToVideoOutput

export const zGetBytedanceLynxRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetBytedanceLynxRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutBytedanceLynxRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutBytedanceLynxRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostBytedanceLynxData = z.object({
  body: zSchemaLynxInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostBytedanceLynxResponse = zSchemaQueueStatus

export const zGetBytedanceLynxRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetBytedanceLynxRequestsByRequestIdResponse = zSchemaLynxOutput

export const zGetFalAiPixverseSwapRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiPixverseSwapRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseSwapRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseSwapRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseSwapData = z.object({
  body: zSchemaPixverseSwapInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseSwapResponse = zSchemaQueueStatus

export const zGetFalAiPixverseSwapRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseSwapRequestsByRequestIdResponse =
  zSchemaPixverseSwapOutput

export const zGetFalAiPikaV22PikaframesRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiPikaV22PikaframesRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPikaV22PikaframesRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV22PikaframesRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPikaV22PikaframesData = z.object({
  body: zSchemaPikaV22PikaframesInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPikaV22PikaframesResponse = zSchemaQueueStatus

export const zGetFalAiPikaV22PikaframesRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPikaV22PikaframesRequestsByRequestIdResponse =
  zSchemaPikaV22PikaframesOutput

export const zGetFalAiLongcatVideoImageToVideo720pRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLongcatVideoImageToVideo720pRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLongcatVideoImageToVideo720pRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLongcatVideoImageToVideo720pRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLongcatVideoImageToVideo720pData = z.object({
  body: zSchemaLongcatVideoImageToVideo720pInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLongcatVideoImageToVideo720pResponse = zSchemaQueueStatus

export const zGetFalAiLongcatVideoImageToVideo720pRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLongcatVideoImageToVideo720pRequestsByRequestIdResponse =
  zSchemaLongcatVideoImageToVideo720pOutput

export const zGetFalAiLongcatVideoImageToVideo480pRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLongcatVideoImageToVideo480pRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLongcatVideoImageToVideo480pRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLongcatVideoImageToVideo480pRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLongcatVideoImageToVideo480pData = z.object({
  body: zSchemaLongcatVideoImageToVideo480pInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLongcatVideoImageToVideo480pResponse = zSchemaQueueStatus

export const zGetFalAiLongcatVideoImageToVideo480pRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLongcatVideoImageToVideo480pRequestsByRequestIdResponse =
  zSchemaLongcatVideoImageToVideo480pOutput

export const zGetFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLongcatVideoDistilledImageToVideo720pData = z.object({
  body: zSchemaLongcatVideoDistilledImageToVideo720pInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLongcatVideoDistilledImageToVideo720pResponse =
  zSchemaQueueStatus

export const zGetFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdResponse =
  zSchemaLongcatVideoDistilledImageToVideo720pOutput

export const zGetFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLongcatVideoDistilledImageToVideo480pData = z.object({
  body: zSchemaLongcatVideoDistilledImageToVideo480pInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLongcatVideoDistilledImageToVideo480pResponse =
  zSchemaQueueStatus

export const zGetFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdResponse =
  zSchemaLongcatVideoDistilledImageToVideo480pOutput

export const zGetFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxHailuo23FastStandardImageToVideoData = z.object({
  body: zSchemaMinimaxHailuo23FastStandardImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo23FastStandardImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdResponse =
  zSchemaMinimaxHailuo23FastStandardImageToVideoOutput

export const zGetFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxHailuo23StandardImageToVideoData = z.object({
  body: zSchemaMinimaxHailuo23StandardImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo23StandardImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdResponse =
  zSchemaMinimaxHailuo23StandardImageToVideoOutput

export const zGetFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxHailuo23FastProImageToVideoData = z.object({
  body: zSchemaMinimaxHailuo23FastProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo23FastProImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdResponse =
  zSchemaMinimaxHailuo23FastProImageToVideoOutput

export const zGetFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiBytedanceSeedanceV1ProFastImageToVideoData = z.object({
  body: zSchemaBytedanceSeedanceV1ProFastImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiBytedanceSeedanceV1ProFastImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdResponse =
  zSchemaBytedanceSeedanceV1ProFastImageToVideoOutput

export const zGetFalAiViduQ2ImageToVideoTurboRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiViduQ2ImageToVideoTurboRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiViduQ2ImageToVideoTurboRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ2ImageToVideoTurboRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiViduQ2ImageToVideoTurboData = z.object({
  body: zSchemaViduQ2ImageToVideoTurboInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiViduQ2ImageToVideoTurboResponse = zSchemaQueueStatus

export const zGetFalAiViduQ2ImageToVideoTurboRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiViduQ2ImageToVideoTurboRequestsByRequestIdResponse =
  zSchemaViduQ2ImageToVideoTurboOutput

export const zGetFalAiViduQ2ImageToVideoProRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiViduQ2ImageToVideoProRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiViduQ2ImageToVideoProRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ2ImageToVideoProRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiViduQ2ImageToVideoProData = z.object({
  body: zSchemaViduQ2ImageToVideoProInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiViduQ2ImageToVideoProResponse = zSchemaQueueStatus

export const zGetFalAiViduQ2ImageToVideoProRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiViduQ2ImageToVideoProRequestsByRequestIdResponse =
  zSchemaViduQ2ImageToVideoProOutput

export const zGetFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV25TurboStandardImageToVideoData = z.object({
  body: zSchemaKlingVideoV25TurboStandardImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV25TurboStandardImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV25TurboStandardImageToVideoOutput

export const zGetFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiVeo31FastFirstLastFrameToVideoData = z.object({
  body: zSchemaVeo31FastFirstLastFrameToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVeo31FastFirstLastFrameToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdResponse =
  zSchemaVeo31FastFirstLastFrameToVideoOutput

export const zGetFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiVeo31FirstLastFrameToVideoData = z.object({
  body: zSchemaVeo31FirstLastFrameToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVeo31FirstLastFrameToVideoResponse = zSchemaQueueStatus

export const zGetFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdResponse =
  zSchemaVeo31FirstLastFrameToVideoOutput

export const zGetFalAiVeo31ReferenceToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiVeo31ReferenceToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVeo31ReferenceToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo31ReferenceToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiVeo31ReferenceToVideoData = z.object({
  body: zSchemaVeo31ReferenceToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVeo31ReferenceToVideoResponse = zSchemaQueueStatus

export const zGetFalAiVeo31ReferenceToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiVeo31ReferenceToVideoRequestsByRequestIdResponse =
  zSchemaVeo31ReferenceToVideoOutput

export const zGetFalAiVeo31FastImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiVeo31FastImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVeo31FastImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo31FastImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiVeo31FastImageToVideoData = z.object({
  body: zSchemaVeo31FastImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVeo31FastImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiVeo31FastImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiVeo31FastImageToVideoRequestsByRequestIdResponse =
  zSchemaVeo31FastImageToVideoOutput

export const zGetFalAiVeo31ImageToVideoRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiVeo31ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVeo31ImageToVideoRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo31ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiVeo31ImageToVideoData = z.object({
  body: zSchemaVeo31ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVeo31ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiVeo31ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiVeo31ImageToVideoRequestsByRequestIdResponse =
  zSchemaVeo31ImageToVideoOutput

export const zGetFalAiSora2ImageToVideoProRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiSora2ImageToVideoProRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSora2ImageToVideoProRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiSora2ImageToVideoProRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSora2ImageToVideoProData = z.object({
  body: zSchemaSora2ImageToVideoProInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSora2ImageToVideoProResponse = zSchemaQueueStatus

export const zGetFalAiSora2ImageToVideoProRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSora2ImageToVideoProRequestsByRequestIdResponse =
  zSchemaSora2ImageToVideoProOutput

export const zGetFalAiSora2ImageToVideoRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiSora2ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSora2ImageToVideoRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiSora2ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSora2ImageToVideoData = z.object({
  body: zSchemaSora2ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSora2ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiSora2ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSora2ImageToVideoRequestsByRequestIdResponse =
  zSchemaSora2ImageToVideoOutput

export const zGetFalAiOviImageToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiOviImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiOviImageToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiOviImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiOviImageToVideoData = z.object({
  body: zSchemaOviImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiOviImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiOviImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiOviImageToVideoRequestsByRequestIdResponse =
  zSchemaOviImageToVideoOutput

export const zGetVeedFabric10FastRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetVeedFabric10FastRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutVeedFabric10FastRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutVeedFabric10FastRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostVeedFabric10FastData = z.object({
  body: zSchemaFabric10FastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostVeedFabric10FastResponse = zSchemaQueueStatus

export const zGetVeedFabric10FastRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetVeedFabric10FastRequestsByRequestIdResponse =
  zSchemaFabric10FastOutput

export const zGetFalAiBytedanceOmnihumanV15RequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiBytedanceOmnihumanV15RequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiBytedanceOmnihumanV15RequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceOmnihumanV15RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiBytedanceOmnihumanV15Data = z.object({
  body: zSchemaBytedanceOmnihumanV15Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiBytedanceOmnihumanV15Response = zSchemaQueueStatus

export const zGetFalAiBytedanceOmnihumanV15RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceOmnihumanV15RequestsByRequestIdResponse =
  zSchemaBytedanceOmnihumanV15Output

export const zGetVeedFabric10RequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetVeedFabric10RequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutVeedFabric10RequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutVeedFabric10RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostVeedFabric10Data = z.object({
  body: zSchemaFabric10Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostVeedFabric10Response = zSchemaQueueStatus

export const zGetVeedFabric10RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetVeedFabric10RequestsByRequestIdResponse = zSchemaFabric10Output

export const zGetFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV1StandardAiAvatarData = z.object({
  body: zSchemaKlingVideoV1StandardAiAvatarInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV1StandardAiAvatarResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdResponse =
  zSchemaKlingVideoV1StandardAiAvatarOutput

export const zGetFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV1ProAiAvatarData = z.object({
  body: zSchemaKlingVideoV1ProAiAvatarInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV1ProAiAvatarResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdResponse =
  zSchemaKlingVideoV1ProAiAvatarOutput

export const zGetDecartLucy14bImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetDecartLucy14bImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutDecartLucy14bImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutDecartLucy14bImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostDecartLucy14bImageToVideoData = z.object({
  body: zSchemaLucy14bImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostDecartLucy14bImageToVideoResponse = zSchemaQueueStatus

export const zGetDecartLucy14bImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetDecartLucy14bImageToVideoRequestsByRequestIdResponse =
  zSchemaLucy14bImageToVideoOutput

export const zGetFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiBytedanceSeedanceV1LiteReferenceToVideoData = z.object({
  body: zSchemaBytedanceSeedanceV1LiteReferenceToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiBytedanceSeedanceV1LiteReferenceToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdResponse =
  zSchemaBytedanceSeedanceV1LiteReferenceToVideoOutput

export const zGetFalAiWanAtiRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanAtiRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanAtiRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanAtiRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanAtiData = z.object({
  body: zSchemaWanAtiInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanAtiResponse = zSchemaQueueStatus

export const zGetFalAiWanAtiRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanAtiRequestsByRequestIdResponse = zSchemaWanAtiOutput

export const zGetFalAiDecartLucy5bImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiDecartLucy5bImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiDecartLucy5bImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiDecartLucy5bImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiDecartLucy5bImageToVideoData = z.object({
  body: zSchemaDecartLucy5bImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiDecartLucy5bImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiDecartLucy5bImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiDecartLucy5bImageToVideoRequestsByRequestIdResponse =
  zSchemaDecartLucy5bImageToVideoOutput

export const zGetFalAiPixverseV5TransitionRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV5TransitionRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV5TransitionRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV5TransitionRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseV5TransitionData = z.object({
  body: zSchemaPixverseV5TransitionInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV5TransitionResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV5TransitionRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV5TransitionRequestsByRequestIdResponse =
  zSchemaPixverseV5TransitionOutput

export const zGetFalAiPixverseV5EffectsRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiPixverseV5EffectsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV5EffectsRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV5EffectsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseV5EffectsData = z.object({
  body: zSchemaPixverseV5EffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV5EffectsResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV5EffectsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV5EffectsRequestsByRequestIdResponse =
  zSchemaPixverseV5EffectsOutput

export const zGetFalAiPixverseV5ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV5ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV5ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV5ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPixverseV5ImageToVideoData = z.object({
  body: zSchemaPixverseV5ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV5ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV5ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV5ImageToVideoRequestsByRequestIdResponse =
  zSchemaPixverseV5ImageToVideoOutput

export const zGetMoonvalleyMareyI2vRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetMoonvalleyMareyI2vRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutMoonvalleyMareyI2vRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutMoonvalleyMareyI2vRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostMoonvalleyMareyI2vData = z.object({
  body: zSchemaMareyI2vInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostMoonvalleyMareyI2vResponse = zSchemaQueueStatus

export const zGetMoonvalleyMareyI2vRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetMoonvalleyMareyI2vRequestsByRequestIdResponse =
  zSchemaMareyI2vOutput

export const zGetFalAiBytedanceVideoStylizeRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiBytedanceVideoStylizeRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiBytedanceVideoStylizeRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceVideoStylizeRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiBytedanceVideoStylizeData = z.object({
  body: zSchemaBytedanceVideoStylizeInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiBytedanceVideoStylizeResponse = zSchemaQueueStatus

export const zGetFalAiBytedanceVideoStylizeRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceVideoStylizeRequestsByRequestIdResponse =
  zSchemaBytedanceVideoStylizeOutput

export const zGetFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWanV22A14bImageToVideoLoraData = z.object({
  body: zSchemaWanV22A14bImageToVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanV22A14bImageToVideoLoraResponse = zSchemaQueueStatus

export const zGetFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdResponse =
  zSchemaWanV22A14bImageToVideoLoraOutput

export const zGetFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxHailuo02FastImageToVideoData = z.object({
  body: zSchemaMinimaxHailuo02FastImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo02FastImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdResponse =
  zSchemaMinimaxHailuo02FastImageToVideoOutput

export const zGetFalAiVeo3ImageToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiVeo3ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVeo3ImageToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo3ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiVeo3ImageToVideoData = z.object({
  body: zSchemaVeo3ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVeo3ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiVeo3ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiVeo3ImageToVideoRequestsByRequestIdResponse =
  zSchemaVeo3ImageToVideoOutput

export const zGetFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWanV22A14bImageToVideoTurboData = z.object({
  body: zSchemaWanV22A14bImageToVideoTurboInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanV22A14bImageToVideoTurboResponse = zSchemaQueueStatus

export const zGetFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdResponse =
  zSchemaWanV22A14bImageToVideoTurboOutput

export const zGetFalAiWanV225bImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanV225bImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanV225bImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV225bImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanV225bImageToVideoData = z.object({
  body: zSchemaWanV225bImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanV225bImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiWanV225bImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanV225bImageToVideoRequestsByRequestIdResponse =
  zSchemaWanV225bImageToVideoOutput

export const zGetFalAiWanV22A14bImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanV22A14bImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanV22A14bImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV22A14bImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWanV22A14bImageToVideoData = z.object({
  body: zSchemaWanV22A14bImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanV22A14bImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiWanV22A14bImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanV22A14bImageToVideoRequestsByRequestIdResponse =
  zSchemaWanV22A14bImageToVideoOutput

export const zGetFalAiBytedanceOmnihumanRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiBytedanceOmnihumanRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiBytedanceOmnihumanRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceOmnihumanRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiBytedanceOmnihumanData = z.object({
  body: zSchemaBytedanceOmnihumanInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiBytedanceOmnihumanResponse = zSchemaQueueStatus

export const zGetFalAiBytedanceOmnihumanRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceOmnihumanRequestsByRequestIdResponse =
  zSchemaBytedanceOmnihumanOutput

export const zGetFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtxv13B098DistilledImageToVideoData = z.object({
  body: zSchemaLtxv13B098DistilledImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxv13B098DistilledImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdResponse =
  zSchemaLtxv13B098DistilledImageToVideoOutput

export const zGetFalAiVeo3FastImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiVeo3FastImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVeo3FastImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo3FastImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiVeo3FastImageToVideoData = z.object({
  body: zSchemaVeo3FastImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVeo3FastImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiVeo3FastImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiVeo3FastImageToVideoRequestsByRequestIdResponse =
  zSchemaVeo3FastImageToVideoOutput

export const zGetFalAiViduQ1ReferenceToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiViduQ1ReferenceToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiViduQ1ReferenceToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ1ReferenceToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiViduQ1ReferenceToVideoData = z.object({
  body: zSchemaViduQ1ReferenceToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiViduQ1ReferenceToVideoResponse = zSchemaQueueStatus

export const zGetFalAiViduQ1ReferenceToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiViduQ1ReferenceToVideoRequestsByRequestIdResponse =
  zSchemaViduQ1ReferenceToVideoOutput

export const zGetFalAiAiAvatarSingleTextRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiAiAvatarSingleTextRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiAiAvatarSingleTextRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiAiAvatarSingleTextRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiAiAvatarSingleTextData = z.object({
  body: zSchemaAiAvatarSingleTextInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiAiAvatarSingleTextResponse = zSchemaQueueStatus

export const zGetFalAiAiAvatarSingleTextRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiAiAvatarSingleTextRequestsByRequestIdResponse =
  zSchemaAiAvatarSingleTextOutput

export const zGetFalAiAiAvatarRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiAiAvatarRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiAiAvatarRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiAiAvatarRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiAiAvatarData = z.object({
  body: zSchemaAiAvatarInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiAiAvatarResponse = zSchemaQueueStatus

export const zGetFalAiAiAvatarRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiAiAvatarRequestsByRequestIdResponse =
  zSchemaAiAvatarOutput

export const zGetFalAiAiAvatarMultiTextRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiAiAvatarMultiTextRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiAiAvatarMultiTextRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiAiAvatarMultiTextRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiAiAvatarMultiTextData = z.object({
  body: zSchemaAiAvatarMultiTextInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiAiAvatarMultiTextResponse = zSchemaQueueStatus

export const zGetFalAiAiAvatarMultiTextRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiAiAvatarMultiTextRequestsByRequestIdResponse =
  zSchemaAiAvatarMultiTextOutput

export const zGetFalAiAiAvatarMultiRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiAiAvatarMultiRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiAiAvatarMultiRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiAiAvatarMultiRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiAiAvatarMultiData = z.object({
  body: zSchemaAiAvatarMultiInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiAiAvatarMultiResponse = zSchemaQueueStatus

export const zGetFalAiAiAvatarMultiRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiAiAvatarMultiRequestsByRequestIdResponse =
  zSchemaAiAvatarMultiOutput

export const zGetFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxHailuo02ProImageToVideoData = z.object({
  body: zSchemaMinimaxHailuo02ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo02ProImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdResponse =
  zSchemaMinimaxHailuo02ProImageToVideoOutput

export const zGetFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiBytedanceSeedanceV1LiteImageToVideoData = z.object({
  body: zSchemaBytedanceSeedanceV1LiteImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiBytedanceSeedanceV1LiteImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdResponse =
  zSchemaBytedanceSeedanceV1LiteImageToVideoOutput

export const zGetFalAiHunyuanAvatarRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiHunyuanAvatarRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiHunyuanAvatarRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanAvatarRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiHunyuanAvatarData = z.object({
  body: zSchemaHunyuanAvatarInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiHunyuanAvatarResponse = zSchemaQueueStatus

export const zGetFalAiHunyuanAvatarRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanAvatarRequestsByRequestIdResponse =
  zSchemaHunyuanAvatarOutput

export const zGetFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV21ProImageToVideoData = z.object({
  body: zSchemaKlingVideoV21ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV21ProImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV21ProImageToVideoOutput

export const zGetFalAiHunyuanPortraitRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiHunyuanPortraitRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiHunyuanPortraitRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanPortraitRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiHunyuanPortraitData = z.object({
  body: zSchemaHunyuanPortraitInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiHunyuanPortraitResponse = zSchemaQueueStatus

export const zGetFalAiHunyuanPortraitRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanPortraitRequestsByRequestIdResponse =
  zSchemaHunyuanPortraitOutput

export const zGetFalAiKlingVideoV16StandardElementsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV16StandardElementsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV16StandardElementsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV16StandardElementsRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV16StandardElementsData = z.object({
  body: zSchemaKlingVideoV16StandardElementsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV16StandardElementsResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoV16StandardElementsRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV16StandardElementsRequestsByRequestIdResponse =
  zSchemaKlingVideoV16StandardElementsOutput

export const zGetFalAiKlingVideoV16ProElementsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV16ProElementsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV16ProElementsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV16ProElementsRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV16ProElementsData = z.object({
  body: zSchemaKlingVideoV16ProElementsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV16ProElementsResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoV16ProElementsRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV16ProElementsRequestsByRequestIdResponse =
  zSchemaKlingVideoV16ProElementsOutput

export const zGetFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtxVideo13bDistilledImageToVideoData = z.object({
  body: zSchemaLtxVideo13bDistilledImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxVideo13bDistilledImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdResponse =
  zSchemaLtxVideo13bDistilledImageToVideoOutput

export const zGetFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtxVideo13bDevImageToVideoData = z.object({
  body: zSchemaLtxVideo13bDevImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxVideo13bDevImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdResponse =
  zSchemaLtxVideo13bDevImageToVideoOutput

export const zGetFalAiLtxVideoLoraImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxVideoLoraImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxVideoLoraImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideoLoraImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtxVideoLoraImageToVideoData = z.object({
  body: zSchemaLtxVideoLoraImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxVideoLoraImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtxVideoLoraImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideoLoraImageToVideoRequestsByRequestIdResponse =
  zSchemaLtxVideoLoraImageToVideoOutput

export const zGetFalAiPixverseV45TransitionRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV45TransitionRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV45TransitionRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV45TransitionRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseV45TransitionData = z.object({
  body: zSchemaPixverseV45TransitionInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV45TransitionResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV45TransitionRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV45TransitionRequestsByRequestIdResponse =
  zSchemaPixverseV45TransitionOutput

export const zGetFalAiPixverseV45ImageToVideoFastRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV45ImageToVideoFastRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV45ImageToVideoFastRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV45ImageToVideoFastRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPixverseV45ImageToVideoFastData = z.object({
  body: zSchemaPixverseV45ImageToVideoFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV45ImageToVideoFastResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV45ImageToVideoFastRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV45ImageToVideoFastRequestsByRequestIdResponse =
  zSchemaPixverseV45ImageToVideoFastOutput

export const zGetFalAiPixverseV45EffectsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV45EffectsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV45EffectsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV45EffectsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseV45EffectsData = z.object({
  body: zSchemaPixverseV45EffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV45EffectsResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV45EffectsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV45EffectsRequestsByRequestIdResponse =
  zSchemaPixverseV45EffectsOutput

export const zGetFalAiHunyuanCustomRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiHunyuanCustomRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiHunyuanCustomRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanCustomRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiHunyuanCustomData = z.object({
  body: zSchemaHunyuanCustomInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiHunyuanCustomResponse = zSchemaQueueStatus

export const zGetFalAiHunyuanCustomRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanCustomRequestsByRequestIdResponse =
  zSchemaHunyuanCustomOutput

export const zGetFalAiFramepackF1RequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiFramepackF1RequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiFramepackF1RequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiFramepackF1RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiFramepackF1Data = z.object({
  body: zSchemaFramepackF1Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiFramepackF1Response = zSchemaQueueStatus

export const zGetFalAiFramepackF1RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiFramepackF1RequestsByRequestIdResponse =
  zSchemaFramepackF1Output

export const zGetFalAiViduQ1StartEndToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiViduQ1StartEndToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiViduQ1StartEndToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ1StartEndToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiViduQ1StartEndToVideoData = z.object({
  body: zSchemaViduQ1StartEndToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiViduQ1StartEndToVideoResponse = zSchemaQueueStatus

export const zGetFalAiViduQ1StartEndToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiViduQ1StartEndToVideoRequestsByRequestIdResponse =
  zSchemaViduQ1StartEndToVideoOutput

export const zGetFalAiViduQ1ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiViduQ1ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiViduQ1ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ1ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiViduQ1ImageToVideoData = z.object({
  body: zSchemaViduQ1ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiViduQ1ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiViduQ1ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiViduQ1ImageToVideoRequestsByRequestIdResponse =
  zSchemaViduQ1ImageToVideoOutput

export const zGetFalAiMagiImageToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiMagiImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMagiImageToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiMagiImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiMagiImageToVideoData = z.object({
  body: zSchemaMagiImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMagiImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiMagiImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiMagiImageToVideoRequestsByRequestIdResponse =
  zSchemaMagiImageToVideoOutput

export const zGetFalAiPixverseV4EffectsRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiPixverseV4EffectsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV4EffectsRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV4EffectsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseV4EffectsData = z.object({
  body: zSchemaPixverseV4EffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV4EffectsResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV4EffectsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV4EffectsRequestsByRequestIdResponse =
  zSchemaPixverseV4EffectsOutput

export const zGetFalAiMagiDistilledImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMagiDistilledImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMagiDistilledImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMagiDistilledImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMagiDistilledImageToVideoData = z.object({
  body: zSchemaMagiDistilledImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMagiDistilledImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiMagiDistilledImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMagiDistilledImageToVideoRequestsByRequestIdResponse =
  zSchemaMagiDistilledImageToVideoOutput

export const zGetFalAiFramepackFlf2vRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiFramepackFlf2vRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiFramepackFlf2vRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiFramepackFlf2vRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiFramepackFlf2vData = z.object({
  body: zSchemaFramepackFlf2vInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiFramepackFlf2vResponse = zSchemaQueueStatus

export const zGetFalAiFramepackFlf2vRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiFramepackFlf2vRequestsByRequestIdResponse =
  zSchemaFramepackFlf2vOutput

export const zGetFalAiWanFlf2vRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanFlf2vRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanFlf2vRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanFlf2vRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanFlf2vData = z.object({
  body: zSchemaWanFlf2vInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanFlf2vResponse = zSchemaQueueStatus

export const zGetFalAiWanFlf2vRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanFlf2vRequestsByRequestIdResponse =
  zSchemaWanFlf2vOutput

export const zGetFalAiFramepackRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiFramepackRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiFramepackRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiFramepackRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiFramepackData = z.object({
  body: zSchemaFramepackInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiFramepackResponse = zSchemaQueueStatus

export const zGetFalAiFramepackRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiFramepackRequestsByRequestIdResponse =
  zSchemaFramepackOutput

export const zGetFalAiPixverseV4ImageToVideoFastRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV4ImageToVideoFastRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV4ImageToVideoFastRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV4ImageToVideoFastRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPixverseV4ImageToVideoFastData = z.object({
  body: zSchemaPixverseV4ImageToVideoFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV4ImageToVideoFastResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV4ImageToVideoFastRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV4ImageToVideoFastRequestsByRequestIdResponse =
  zSchemaPixverseV4ImageToVideoFastOutput

export const zGetFalAiPixverseV4ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV4ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV4ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV4ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPixverseV4ImageToVideoData = z.object({
  body: zSchemaPixverseV4ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV4ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV4ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV4ImageToVideoRequestsByRequestIdResponse =
  zSchemaPixverseV4ImageToVideoOutput

export const zGetFalAiPixverseV35EffectsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV35EffectsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV35EffectsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV35EffectsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseV35EffectsData = z.object({
  body: zSchemaPixverseV35EffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV35EffectsResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV35EffectsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV35EffectsRequestsByRequestIdResponse =
  zSchemaPixverseV35EffectsOutput

export const zGetFalAiPixverseV35TransitionRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV35TransitionRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV35TransitionRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV35TransitionRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseV35TransitionData = z.object({
  body: zSchemaPixverseV35TransitionInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV35TransitionResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV35TransitionRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV35TransitionRequestsByRequestIdResponse =
  zSchemaPixverseV35TransitionOutput

export const zGetFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLumaDreamMachineRay2FlashImageToVideoData = z.object({
  body: zSchemaLumaDreamMachineRay2FlashImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLumaDreamMachineRay2FlashImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdResponse =
  zSchemaLumaDreamMachineRay2FlashImageToVideoOutput

export const zGetFalAiPikaV15PikaffectsRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiPikaV15PikaffectsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPikaV15PikaffectsRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV15PikaffectsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPikaV15PikaffectsData = z.object({
  body: zSchemaPikaV15PikaffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPikaV15PikaffectsResponse = zSchemaQueueStatus

export const zGetFalAiPikaV15PikaffectsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPikaV15PikaffectsRequestsByRequestIdResponse =
  zSchemaPikaV15PikaffectsOutput

export const zGetFalAiPikaV2TurboImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPikaV2TurboImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPikaV2TurboImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV2TurboImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPikaV2TurboImageToVideoData = z.object({
  body: zSchemaPikaV2TurboImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPikaV2TurboImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPikaV2TurboImageToVideoRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiPikaV2TurboImageToVideoRequestsByRequestIdResponse =
  zSchemaPikaV2TurboImageToVideoOutput

export const zGetFalAiPikaV22PikascenesRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiPikaV22PikascenesRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPikaV22PikascenesRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV22PikascenesRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPikaV22PikascenesData = z.object({
  body: zSchemaPikaV22PikascenesInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPikaV22PikascenesResponse = zSchemaQueueStatus

export const zGetFalAiPikaV22PikascenesRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPikaV22PikascenesRequestsByRequestIdResponse =
  zSchemaPikaV22PikascenesOutput

export const zGetFalAiPikaV22ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPikaV22ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPikaV22ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV22ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPikaV22ImageToVideoData = z.object({
  body: zSchemaPikaV22ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPikaV22ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPikaV22ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPikaV22ImageToVideoRequestsByRequestIdResponse =
  zSchemaPikaV22ImageToVideoOutput

export const zGetFalAiPikaV21ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPikaV21ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPikaV21ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV21ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPikaV21ImageToVideoData = z.object({
  body: zSchemaPikaV21ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPikaV21ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPikaV21ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPikaV21ImageToVideoRequestsByRequestIdResponse =
  zSchemaPikaV21ImageToVideoOutput

export const zGetFalAiViduImageToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiViduImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiViduImageToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiViduImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiViduImageToVideoData = z.object({
  body: zSchemaViduImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiViduImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiViduImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiViduImageToVideoRequestsByRequestIdResponse =
  zSchemaViduImageToVideoOutput

export const zGetFalAiViduStartEndToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiViduStartEndToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiViduStartEndToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiViduStartEndToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiViduStartEndToVideoData = z.object({
  body: zSchemaViduStartEndToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiViduStartEndToVideoResponse = zSchemaQueueStatus

export const zGetFalAiViduStartEndToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiViduStartEndToVideoRequestsByRequestIdResponse =
  zSchemaViduStartEndToVideoOutput

export const zGetFalAiViduReferenceToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiViduReferenceToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiViduReferenceToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiViduReferenceToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiViduReferenceToVideoData = z.object({
  body: zSchemaViduReferenceToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiViduReferenceToVideoResponse = zSchemaQueueStatus

export const zGetFalAiViduReferenceToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiViduReferenceToVideoRequestsByRequestIdResponse =
  zSchemaViduReferenceToVideoOutput

export const zGetFalAiViduTemplateToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiViduTemplateToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiViduTemplateToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiViduTemplateToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiViduTemplateToVideoData = z.object({
  body: zSchemaViduTemplateToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiViduTemplateToVideoResponse = zSchemaQueueStatus

export const zGetFalAiViduTemplateToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiViduTemplateToVideoRequestsByRequestIdResponse =
  zSchemaViduTemplateToVideoOutput

export const zGetFalAiWanI2vLoraRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanI2vLoraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanI2vLoraRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanI2vLoraRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanI2vLoraData = z.object({
  body: zSchemaWanI2vLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanI2vLoraResponse = zSchemaQueueStatus

export const zGetFalAiWanI2vLoraRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanI2vLoraRequestsByRequestIdResponse =
  zSchemaWanI2vLoraOutput

export const zGetFalAiHunyuanVideoImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiHunyuanVideoImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiHunyuanVideoImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanVideoImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiHunyuanVideoImageToVideoData = z.object({
  body: zSchemaHunyuanVideoImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiHunyuanVideoImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiHunyuanVideoImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanVideoImageToVideoRequestsByRequestIdResponse =
  zSchemaHunyuanVideoImageToVideoOutput

export const zGetFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxVideo01DirectorImageToVideoData = z.object({
  body: zSchemaMinimaxVideo01DirectorImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxVideo01DirectorImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdResponse =
  zSchemaMinimaxVideo01DirectorImageToVideoOutput

export const zGetFalAiSkyreelsI2vRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiSkyreelsI2vRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSkyreelsI2vRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiSkyreelsI2vRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSkyreelsI2vData = z.object({
  body: zSchemaSkyreelsI2vInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSkyreelsI2vResponse = zSchemaQueueStatus

export const zGetFalAiSkyreelsI2vRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSkyreelsI2vRequestsByRequestIdResponse =
  zSchemaSkyreelsI2vOutput

export const zGetFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLumaDreamMachineRay2ImageToVideoData = z.object({
  body: zSchemaLumaDreamMachineRay2ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLumaDreamMachineRay2ImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdResponse =
  zSchemaLumaDreamMachineRay2ImageToVideoOutput

export const zGetFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiHunyuanVideoImg2VidLoraData = z.object({
  body: zSchemaHunyuanVideoImg2VidLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiHunyuanVideoImg2VidLoraResponse = zSchemaQueueStatus

export const zGetFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdResponse =
  zSchemaHunyuanVideoImg2VidLoraOutput

export const zGetFalAiPixverseV35ImageToVideoFastRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV35ImageToVideoFastRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV35ImageToVideoFastRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV35ImageToVideoFastRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPixverseV35ImageToVideoFastData = z.object({
  body: zSchemaPixverseV35ImageToVideoFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV35ImageToVideoFastResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV35ImageToVideoFastRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV35ImageToVideoFastRequestsByRequestIdResponse =
  zSchemaPixverseV35ImageToVideoFastOutput

export const zGetFalAiPixverseV35ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV35ImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV35ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV35ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPixverseV35ImageToVideoData = z.object({
  body: zSchemaPixverseV35ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV35ImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV35ImageToVideoRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV35ImageToVideoRequestsByRequestIdResponse =
  zSchemaPixverseV35ImageToVideoOutput

export const zGetFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxVideo01SubjectReferenceData = z.object({
  body: zSchemaMinimaxVideo01SubjectReferenceInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxVideo01SubjectReferenceResponse =
  zSchemaQueueStatus

export const zGetFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdResponse =
  zSchemaMinimaxVideo01SubjectReferenceOutput

export const zGetFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV16StandardImageToVideoData = z.object({
  body: zSchemaKlingVideoV16StandardImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV16StandardImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV16StandardImageToVideoOutput

export const zGetFalAiSadtalkerReferenceRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiSadtalkerReferenceRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSadtalkerReferenceRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiSadtalkerReferenceRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSadtalkerReferenceData = z.object({
  body: zSchemaSadtalkerReferenceInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSadtalkerReferenceResponse = zSchemaQueueStatus

export const zGetFalAiSadtalkerReferenceRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSadtalkerReferenceRequestsByRequestIdResponse =
  zSchemaSadtalkerReferenceOutput

export const zGetFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxVideo01LiveImageToVideoData = z.object({
  body: zSchemaMinimaxVideo01LiveImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxVideo01LiveImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdResponse =
  zSchemaMinimaxVideo01LiveImageToVideoOutput

export const zGetFalAiLtxVideoImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxVideoImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxVideoImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideoImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtxVideoImageToVideoData = z.object({
  body: zSchemaLtxVideoImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxVideoImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtxVideoImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideoImageToVideoRequestsByRequestIdResponse =
  zSchemaLtxVideoImageToVideoOutput

export const zGetFalAiCogvideox5bImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiCogvideox5bImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiCogvideox5bImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiCogvideox5bImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiCogvideox5bImageToVideoData = z.object({
  body: zSchemaCogvideox5bImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiCogvideox5bImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiCogvideox5bImageToVideoRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiCogvideox5bImageToVideoRequestsByRequestIdResponse =
  zSchemaCogvideox5bImageToVideoOutput

export const zGetFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV15ProImageToVideoData = z.object({
  body: zSchemaKlingVideoV15ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV15ProImageToVideoResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV15ProImageToVideoOutput

export const zGetFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV1StandardImageToVideoData = z.object({
  body: zSchemaKlingVideoV1StandardImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV1StandardImageToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV1StandardImageToVideoOutput

export const zGetFalAiStableVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiStableVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiStableVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiStableVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiStableVideoData = z.object({
  body: zSchemaStableVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiStableVideoResponse = zSchemaQueueStatus

export const zGetFalAiStableVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiStableVideoRequestsByRequestIdResponse =
  zSchemaStableVideoOutput

export const zGetFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiAmtInterpolationFrameInterpolationData = z.object({
  body: zSchemaAmtInterpolationFrameInterpolationInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiAmtInterpolationFrameInterpolationResponse =
  zSchemaQueueStatus

export const zGetFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdResponse =
  zSchemaAmtInterpolationFrameInterpolationOutput

export const zGetFalAiLivePortraitRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiLivePortraitRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLivePortraitRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiLivePortraitRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLivePortraitData = z.object({
  body: zSchemaLivePortraitInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLivePortraitResponse = zSchemaQueueStatus

export const zGetFalAiLivePortraitRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLivePortraitRequestsByRequestIdResponse =
  zSchemaLivePortraitOutput

export const zGetFalAiMusetalkRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiMusetalkRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMusetalkRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiMusetalkRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiMusetalkData = z.object({
  body: zSchemaMusetalkInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMusetalkResponse = zSchemaQueueStatus

export const zGetFalAiMusetalkRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiMusetalkRequestsByRequestIdResponse =
  zSchemaMusetalkOutput

export const zGetFalAiSadtalkerRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiSadtalkerRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSadtalkerRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiSadtalkerRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSadtalkerData = z.object({
  body: zSchemaSadtalkerInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSadtalkerResponse = zSchemaQueueStatus

export const zGetFalAiSadtalkerRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSadtalkerRequestsByRequestIdResponse =
  zSchemaSadtalkerOutput

export const zGetFalAiFastSvdLcmRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiFastSvdLcmRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiFastSvdLcmRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiFastSvdLcmRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiFastSvdLcmData = z.object({
  body: zSchemaFastSvdLcmInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiFastSvdLcmResponse = zSchemaQueueStatus

export const zGetFalAiFastSvdLcmRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiFastSvdLcmRequestsByRequestIdResponse =
  zSchemaFastSvdLcmOutput

export const zGetFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV25TurboProTextToVideoData = z.object({
  body: zSchemaKlingVideoV25TurboProTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV25TurboProTextToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV25TurboProTextToVideoOutput

export const zGetFalAiVeo3FastRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiVeo3FastRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVeo3FastRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo3FastRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiVeo3FastData = z.object({
  body: zSchemaVeo3FastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVeo3FastResponse = zSchemaQueueStatus

export const zGetFalAiVeo3FastRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiVeo3FastRequestsByRequestIdResponse =
  zSchemaVeo3FastOutput

export const zGetFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxHailuo02StandardTextToVideoData = z.object({
  body: zSchemaMinimaxHailuo02StandardTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo02StandardTextToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdResponse =
  zSchemaMinimaxHailuo02StandardTextToVideoOutput

export const zGetFalAiVeo3RequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiVeo3RequestsByRequestIdStatusResponse = zSchemaQueueStatus

export const zPutFalAiVeo3RequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo3RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiVeo3Data = z.object({
  body: zSchemaVeo3Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVeo3Response = zSchemaQueueStatus

export const zGetFalAiVeo3RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiVeo3RequestsByRequestIdResponse = zSchemaVeo3Output

export const zGetFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV2MasterTextToVideoData = z.object({
  body: zSchemaKlingVideoV2MasterTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV2MasterTextToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV2MasterTextToVideoOutput

export const zGetFalAiPixverseV56TextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV56TextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV56TextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV56TextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPixverseV56TextToVideoData = z.object({
  body: zSchemaPixverseV56TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV56TextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV56TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV56TextToVideoRequestsByRequestIdResponse =
  zSchemaPixverseV56TextToVideoOutput

export const zGetFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtx219bDistilledTextToVideoLoraData = z.object({
  body: zSchemaLtx219bDistilledTextToVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bDistilledTextToVideoLoraResponse =
  zSchemaQueueStatus

export const zGetFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdResponse =
  zSchemaLtx219bDistilledTextToVideoLoraOutput

export const zGetFalAiLtx219bDistilledTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bDistilledTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bDistilledTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bDistilledTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtx219bDistilledTextToVideoData = z.object({
  body: zSchemaLtx219bDistilledTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bDistilledTextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtx219bDistilledTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bDistilledTextToVideoRequestsByRequestIdResponse =
  zSchemaLtx219bDistilledTextToVideoOutput

export const zGetFalAiLtx219bTextToVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bTextToVideoLoraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bTextToVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bTextToVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtx219bTextToVideoLoraData = z.object({
  body: zSchemaLtx219bTextToVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bTextToVideoLoraResponse = zSchemaQueueStatus

export const zGetFalAiLtx219bTextToVideoLoraRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bTextToVideoLoraRequestsByRequestIdResponse =
  zSchemaLtx219bTextToVideoLoraOutput

export const zGetFalAiLtx219bTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bTextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtx219bTextToVideoData = z.object({
  body: zSchemaLtx219bTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bTextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtx219bTextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bTextToVideoRequestsByRequestIdResponse =
  zSchemaLtx219bTextToVideoOutput

export const zGetFalAiKandinsky5ProTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKandinsky5ProTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKandinsky5ProTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKandinsky5ProTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKandinsky5ProTextToVideoData = z.object({
  body: zSchemaKandinsky5ProTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKandinsky5ProTextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiKandinsky5ProTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKandinsky5ProTextToVideoRequestsByRequestIdResponse =
  zSchemaKandinsky5ProTextToVideoOutput

export const zGetFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiBytedanceSeedanceV15ProTextToVideoData = z.object({
  body: zSchemaBytedanceSeedanceV15ProTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiBytedanceSeedanceV15ProTextToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdResponse =
  zSchemaBytedanceSeedanceV15ProTextToVideoOutput

export const zGetWanV26TextToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetWanV26TextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutWanV26TextToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutWanV26TextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostWanV26TextToVideoData = z.object({
  body: zSchemaV26TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostWanV26TextToVideoResponse = zSchemaQueueStatus

export const zGetWanV26TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetWanV26TextToVideoRequestsByRequestIdResponse =
  zSchemaV26TextToVideoOutput

export const zGetVeedFabric10TextRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetVeedFabric10TextRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutVeedFabric10TextRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutVeedFabric10TextRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostVeedFabric10TextData = z.object({
  body: zSchemaFabric10TextInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostVeedFabric10TextResponse = zSchemaQueueStatus

export const zGetVeedFabric10TextRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetVeedFabric10TextRequestsByRequestIdResponse =
  zSchemaFabric10TextOutput

export const zGetFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV26ProTextToVideoData = z.object({
  body: zSchemaKlingVideoV26ProTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV26ProTextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV26ProTextToVideoOutput

export const zGetFalAiPixverseV55TextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV55TextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV55TextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV55TextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPixverseV55TextToVideoData = z.object({
  body: zSchemaPixverseV55TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV55TextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV55TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV55TextToVideoRequestsByRequestIdResponse =
  zSchemaPixverseV55TextToVideoOutput

export const zGetFalAiLtx2TextToVideoFastRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx2TextToVideoFastRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx2TextToVideoFastRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx2TextToVideoFastRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtx2TextToVideoFastData = z.object({
  body: zSchemaLtx2TextToVideoFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx2TextToVideoFastResponse = zSchemaQueueStatus

export const zGetFalAiLtx2TextToVideoFastRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtx2TextToVideoFastRequestsByRequestIdResponse =
  zSchemaLtx2TextToVideoFastOutput

export const zGetFalAiLtx2TextToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiLtx2TextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx2TextToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx2TextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtx2TextToVideoData = z.object({
  body: zSchemaLtx2TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx2TextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtx2TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtx2TextToVideoRequestsByRequestIdResponse =
  zSchemaLtx2TextToVideoOutput

export const zGetFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiHunyuanVideoV15TextToVideoData = z.object({
  body: zSchemaHunyuanVideoV15TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiHunyuanVideoV15TextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdResponse =
  zSchemaHunyuanVideoV15TextToVideoOutput

export const zGetFalAiInfinityStarTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiInfinityStarTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiInfinityStarTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiInfinityStarTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiInfinityStarTextToVideoData = z.object({
  body: zSchemaInfinityStarTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiInfinityStarTextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiInfinityStarTextToVideoRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiInfinityStarTextToVideoRequestsByRequestIdResponse =
  zSchemaInfinityStarTextToVideoOutput

export const zGetFalAiSanaVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiSanaVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSanaVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiSanaVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSanaVideoData = z.object({
  body: zSchemaSanaVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSanaVideoResponse = zSchemaQueueStatus

export const zGetFalAiSanaVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSanaVideoRequestsByRequestIdResponse =
  zSchemaSanaVideoOutput

export const zGetFalAiLongcatVideoTextToVideo720pRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLongcatVideoTextToVideo720pRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLongcatVideoTextToVideo720pRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLongcatVideoTextToVideo720pRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLongcatVideoTextToVideo720pData = z.object({
  body: zSchemaLongcatVideoTextToVideo720pInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLongcatVideoTextToVideo720pResponse = zSchemaQueueStatus

export const zGetFalAiLongcatVideoTextToVideo720pRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLongcatVideoTextToVideo720pRequestsByRequestIdResponse =
  zSchemaLongcatVideoTextToVideo720pOutput

export const zGetFalAiLongcatVideoTextToVideo480pRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLongcatVideoTextToVideo480pRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLongcatVideoTextToVideo480pRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLongcatVideoTextToVideo480pRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLongcatVideoTextToVideo480pData = z.object({
  body: zSchemaLongcatVideoTextToVideo480pInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLongcatVideoTextToVideo480pResponse = zSchemaQueueStatus

export const zGetFalAiLongcatVideoTextToVideo480pRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLongcatVideoTextToVideo480pRequestsByRequestIdResponse =
  zSchemaLongcatVideoTextToVideo480pOutput

export const zGetFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLongcatVideoDistilledTextToVideo720pData = z.object({
  body: zSchemaLongcatVideoDistilledTextToVideo720pInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLongcatVideoDistilledTextToVideo720pResponse =
  zSchemaQueueStatus

export const zGetFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdResponse =
  zSchemaLongcatVideoDistilledTextToVideo720pOutput

export const zGetFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLongcatVideoDistilledTextToVideo480pData = z.object({
  body: zSchemaLongcatVideoDistilledTextToVideo480pInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLongcatVideoDistilledTextToVideo480pResponse =
  zSchemaQueueStatus

export const zGetFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdResponse =
  zSchemaLongcatVideoDistilledTextToVideo480pOutput

export const zGetFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxHailuo23StandardTextToVideoData = z.object({
  body: zSchemaMinimaxHailuo23StandardTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo23StandardTextToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdResponse =
  zSchemaMinimaxHailuo23StandardTextToVideoOutput

export const zGetFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxHailuo23ProTextToVideoData = z.object({
  body: zSchemaMinimaxHailuo23ProTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo23ProTextToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdResponse =
  zSchemaMinimaxHailuo23ProTextToVideoOutput

export const zGetFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiBytedanceSeedanceV1ProFastTextToVideoData = z.object({
  body: zSchemaBytedanceSeedanceV1ProFastTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiBytedanceSeedanceV1ProFastTextToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdResponse =
  zSchemaBytedanceSeedanceV1ProFastTextToVideoOutput

export const zGetFalAiViduQ2TextToVideoRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiViduQ2TextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiViduQ2TextToVideoRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ2TextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiViduQ2TextToVideoData = z.object({
  body: zSchemaViduQ2TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiViduQ2TextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiViduQ2TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiViduQ2TextToVideoRequestsByRequestIdResponse =
  zSchemaViduQ2TextToVideoOutput

export const zGetFalAiKreaWan14bTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKreaWan14bTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKreaWan14bTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKreaWan14bTextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiKreaWan14bTextToVideoData = z.object({
  body: zSchemaKreaWan14bTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKreaWan14bTextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiKreaWan14bTextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiKreaWan14bTextToVideoRequestsByRequestIdResponse =
  zSchemaKreaWan14bTextToVideoOutput

export const zGetFalAiWanAlphaRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanAlphaRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanAlphaRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanAlphaRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanAlphaData = z.object({
  body: zSchemaWanAlphaInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanAlphaResponse = zSchemaQueueStatus

export const zGetFalAiWanAlphaRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanAlphaRequestsByRequestIdResponse =
  zSchemaWanAlphaOutput

export const zGetFalAiKandinsky5TextToVideoDistillRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKandinsky5TextToVideoDistillRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKandinsky5TextToVideoDistillRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKandinsky5TextToVideoDistillRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKandinsky5TextToVideoDistillData = z.object({
  body: zSchemaKandinsky5TextToVideoDistillInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKandinsky5TextToVideoDistillResponse = zSchemaQueueStatus

export const zGetFalAiKandinsky5TextToVideoDistillRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKandinsky5TextToVideoDistillRequestsByRequestIdResponse =
  zSchemaKandinsky5TextToVideoDistillOutput

export const zGetFalAiKandinsky5TextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKandinsky5TextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKandinsky5TextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKandinsky5TextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiKandinsky5TextToVideoData = z.object({
  body: zSchemaKandinsky5TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKandinsky5TextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiKandinsky5TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiKandinsky5TextToVideoRequestsByRequestIdResponse =
  zSchemaKandinsky5TextToVideoOutput

export const zGetFalAiVeo31FastRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiVeo31FastRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVeo31FastRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo31FastRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiVeo31FastData = z.object({
  body: zSchemaVeo31FastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVeo31FastResponse = zSchemaQueueStatus

export const zGetFalAiVeo31FastRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiVeo31FastRequestsByRequestIdResponse =
  zSchemaVeo31FastOutput

export const zGetFalAiVeo31RequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiVeo31RequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVeo31RequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo31RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiVeo31Data = z.object({
  body: zSchemaVeo31Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVeo31Response = zSchemaQueueStatus

export const zGetFalAiVeo31RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiVeo31RequestsByRequestIdResponse = zSchemaVeo31Output

export const zGetFalAiSora2TextToVideoProRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiSora2TextToVideoProRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSora2TextToVideoProRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiSora2TextToVideoProRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSora2TextToVideoProData = z.object({
  body: zSchemaSora2TextToVideoProInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSora2TextToVideoProResponse = zSchemaQueueStatus

export const zGetFalAiSora2TextToVideoProRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSora2TextToVideoProRequestsByRequestIdResponse =
  zSchemaSora2TextToVideoProOutput

export const zGetFalAiSora2TextToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiSora2TextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSora2TextToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiSora2TextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSora2TextToVideoData = z.object({
  body: zSchemaSora2TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSora2TextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiSora2TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSora2TextToVideoRequestsByRequestIdResponse =
  zSchemaSora2TextToVideoOutput

export const zGetFalAiOviRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiOviRequestsByRequestIdStatusResponse = zSchemaQueueStatus

export const zPutFalAiOviRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiOviRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiOviData = z.object({
  body: zSchemaOviInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiOviResponse = zSchemaQueueStatus

export const zGetFalAiOviRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiOviRequestsByRequestIdResponse = zSchemaOviOutput

export const zGetFalAiWan25PreviewTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWan25PreviewTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWan25PreviewTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWan25PreviewTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWan25PreviewTextToVideoData = z.object({
  body: zSchemaWan25PreviewTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWan25PreviewTextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiWan25PreviewTextToVideoRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiWan25PreviewTextToVideoRequestsByRequestIdResponse =
  zSchemaWan25PreviewTextToVideoOutput

export const zGetArgilAvatarsTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetArgilAvatarsTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutArgilAvatarsTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutArgilAvatarsTextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostArgilAvatarsTextToVideoData = z.object({
  body: zSchemaAvatarsTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostArgilAvatarsTextToVideoResponse = zSchemaQueueStatus

export const zGetArgilAvatarsTextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetArgilAvatarsTextToVideoRequestsByRequestIdResponse =
  zSchemaAvatarsTextToVideoOutput

export const zGetFalAiPixverseV5TextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV5TextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV5TextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV5TextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseV5TextToVideoData = z.object({
  body: zSchemaPixverseV5TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV5TextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV5TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV5TextToVideoRequestsByRequestIdResponse =
  zSchemaPixverseV5TextToVideoOutput

export const zGetFalAiInfinitalkSingleTextRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiInfinitalkSingleTextRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiInfinitalkSingleTextRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiInfinitalkSingleTextRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiInfinitalkSingleTextData = z.object({
  body: zSchemaInfinitalkSingleTextInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiInfinitalkSingleTextResponse = zSchemaQueueStatus

export const zGetFalAiInfinitalkSingleTextRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiInfinitalkSingleTextRequestsByRequestIdResponse =
  zSchemaInfinitalkSingleTextOutput

export const zGetMoonvalleyMareyT2vRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetMoonvalleyMareyT2vRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutMoonvalleyMareyT2vRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutMoonvalleyMareyT2vRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostMoonvalleyMareyT2vData = z.object({
  body: zSchemaMareyT2vInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostMoonvalleyMareyT2vResponse = zSchemaQueueStatus

export const zGetMoonvalleyMareyT2vRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetMoonvalleyMareyT2vRequestsByRequestIdResponse =
  zSchemaMareyT2vOutput

export const zGetFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWanV22A14bTextToVideoLoraData = z.object({
  body: zSchemaWanV22A14bTextToVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanV22A14bTextToVideoLoraResponse = zSchemaQueueStatus

export const zGetFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdResponse =
  zSchemaWanV22A14bTextToVideoLoraOutput

export const zGetFalAiWanV225bTextToVideoDistillRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanV225bTextToVideoDistillRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanV225bTextToVideoDistillRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV225bTextToVideoDistillRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWanV225bTextToVideoDistillData = z.object({
  body: zSchemaWanV225bTextToVideoDistillInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanV225bTextToVideoDistillResponse = zSchemaQueueStatus

export const zGetFalAiWanV225bTextToVideoDistillRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiWanV225bTextToVideoDistillRequestsByRequestIdResponse =
  zSchemaWanV225bTextToVideoDistillOutput

export const zGetFalAiWanV225bTextToVideoFastWanRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanV225bTextToVideoFastWanRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanV225bTextToVideoFastWanRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV225bTextToVideoFastWanRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWanV225bTextToVideoFastWanData = z.object({
  body: zSchemaWanV225bTextToVideoFastWanInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanV225bTextToVideoFastWanResponse = zSchemaQueueStatus

export const zGetFalAiWanV225bTextToVideoFastWanRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiWanV225bTextToVideoFastWanRequestsByRequestIdResponse =
  zSchemaWanV225bTextToVideoFastWanOutput

export const zGetFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWanV22A14bTextToVideoTurboData = z.object({
  body: zSchemaWanV22A14bTextToVideoTurboInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanV22A14bTextToVideoTurboResponse = zSchemaQueueStatus

export const zGetFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdResponse =
  zSchemaWanV22A14bTextToVideoTurboOutput

export const zGetFalAiWanV225bTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanV225bTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanV225bTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV225bTextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanV225bTextToVideoData = z.object({
  body: zSchemaWanV225bTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanV225bTextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiWanV225bTextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanV225bTextToVideoRequestsByRequestIdResponse =
  zSchemaWanV225bTextToVideoOutput

export const zGetFalAiWanV22A14bTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanV22A14bTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanV22A14bTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV22A14bTextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanV22A14bTextToVideoData = z.object({
  body: zSchemaWanV22A14bTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanV22A14bTextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiWanV22A14bTextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanV22A14bTextToVideoRequestsByRequestIdResponse =
  zSchemaWanV22A14bTextToVideoOutput

export const zGetFalAiLtxv13B098DistilledRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxv13B098DistilledRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxv13B098DistilledRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxv13B098DistilledRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtxv13B098DistilledData = z.object({
  body: zSchemaLtxv13B098DistilledInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxv13B098DistilledResponse = zSchemaQueueStatus

export const zGetFalAiLtxv13B098DistilledRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtxv13B098DistilledRequestsByRequestIdResponse =
  zSchemaLtxv13B098DistilledOutput

export const zGetFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxHailuo02ProTextToVideoData = z.object({
  body: zSchemaMinimaxHailuo02ProTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo02ProTextToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdResponse =
  zSchemaMinimaxHailuo02ProTextToVideoOutput

export const zGetFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiBytedanceSeedanceV1ProTextToVideoData = z.object({
  body: zSchemaBytedanceSeedanceV1ProTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiBytedanceSeedanceV1ProTextToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdResponse =
  zSchemaBytedanceSeedanceV1ProTextToVideoOutput

export const zGetFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiBytedanceSeedanceV1LiteTextToVideoData = z.object({
  body: zSchemaBytedanceSeedanceV1LiteTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiBytedanceSeedanceV1LiteTextToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdResponse =
  zSchemaBytedanceSeedanceV1LiteTextToVideoOutput

export const zGetFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV21MasterTextToVideoData = z.object({
  body: zSchemaKlingVideoV21MasterTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV21MasterTextToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV21MasterTextToVideoOutput

export const zGetVeedAvatarsTextToVideoRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetVeedAvatarsTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutVeedAvatarsTextToVideoRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutVeedAvatarsTextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostVeedAvatarsTextToVideoData = z.object({
  body: zSchemaAvatarsTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostVeedAvatarsTextToVideoResponse = zSchemaQueueStatus

export const zGetVeedAvatarsTextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetVeedAvatarsTextToVideoRequestsByRequestIdResponse =
  zSchemaAvatarsTextToVideoOutput

export const zGetFalAiLtxVideo13bDevRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiLtxVideo13bDevRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxVideo13bDevRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideo13bDevRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtxVideo13bDevData = z.object({
  body: zSchemaLtxVideo13bDevInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxVideo13bDevResponse = zSchemaQueueStatus

export const zGetFalAiLtxVideo13bDevRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideo13bDevRequestsByRequestIdResponse =
  zSchemaLtxVideo13bDevOutput

export const zGetFalAiLtxVideo13bDistilledRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxVideo13bDistilledRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxVideo13bDistilledRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideo13bDistilledRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtxVideo13bDistilledData = z.object({
  body: zSchemaLtxVideo13bDistilledInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxVideo13bDistilledResponse = zSchemaQueueStatus

export const zGetFalAiLtxVideo13bDistilledRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideo13bDistilledRequestsByRequestIdResponse =
  zSchemaLtxVideo13bDistilledOutput

export const zGetFalAiPixverseV45TextToVideoFastRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV45TextToVideoFastRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV45TextToVideoFastRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV45TextToVideoFastRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPixverseV45TextToVideoFastData = z.object({
  body: zSchemaPixverseV45TextToVideoFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV45TextToVideoFastResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV45TextToVideoFastRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV45TextToVideoFastRequestsByRequestIdResponse =
  zSchemaPixverseV45TextToVideoFastOutput

export const zGetFalAiPixverseV45TextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV45TextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV45TextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV45TextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPixverseV45TextToVideoData = z.object({
  body: zSchemaPixverseV45TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV45TextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV45TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV45TextToVideoRequestsByRequestIdResponse =
  zSchemaPixverseV45TextToVideoOutput

export const zGetFalAiViduQ1TextToVideoRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiViduQ1TextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiViduQ1TextToVideoRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ1TextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiViduQ1TextToVideoData = z.object({
  body: zSchemaViduQ1TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiViduQ1TextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiViduQ1TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiViduQ1TextToVideoRequestsByRequestIdResponse =
  zSchemaViduQ1TextToVideoOutput

export const zGetFalAiMagiRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiMagiRequestsByRequestIdStatusResponse = zSchemaQueueStatus

export const zPutFalAiMagiRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiMagiRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiMagiData = z.object({
  body: zSchemaMagiInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMagiResponse = zSchemaQueueStatus

export const zGetFalAiMagiRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiMagiRequestsByRequestIdResponse = zSchemaMagiOutput

export const zGetFalAiMagiDistilledRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiMagiDistilledRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMagiDistilledRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiMagiDistilledRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiMagiDistilledData = z.object({
  body: zSchemaMagiDistilledInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMagiDistilledResponse = zSchemaQueueStatus

export const zGetFalAiMagiDistilledRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiMagiDistilledRequestsByRequestIdResponse =
  zSchemaMagiDistilledOutput

export const zGetFalAiPixverseV4TextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV4TextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV4TextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV4TextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseV4TextToVideoData = z.object({
  body: zSchemaPixverseV4TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV4TextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV4TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV4TextToVideoRequestsByRequestIdResponse =
  zSchemaPixverseV4TextToVideoOutput

export const zGetFalAiPixverseV4TextToVideoFastRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV4TextToVideoFastRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV4TextToVideoFastRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV4TextToVideoFastRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPixverseV4TextToVideoFastData = z.object({
  body: zSchemaPixverseV4TextToVideoFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV4TextToVideoFastResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV4TextToVideoFastRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV4TextToVideoFastRequestsByRequestIdResponse =
  zSchemaPixverseV4TextToVideoFastOutput

export const zGetFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoLipsyncAudioToVideoData = z.object({
  body: zSchemaKlingVideoLipsyncAudioToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoLipsyncAudioToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoLipsyncAudioToVideoOutput

export const zGetFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoLipsyncTextToVideoData = z.object({
  body: zSchemaKlingVideoLipsyncTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoLipsyncTextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoLipsyncTextToVideoOutput

export const zGetFalAiWanT2vLoraRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanT2vLoraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanT2vLoraRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanT2vLoraRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanT2vLoraData = z.object({
  body: zSchemaWanT2vLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanT2vLoraResponse = zSchemaQueueStatus

export const zGetFalAiWanT2vLoraRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanT2vLoraRequestsByRequestIdResponse =
  zSchemaWanT2vLoraOutput

export const zGetFalAiLumaDreamMachineRay2FlashRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLumaDreamMachineRay2FlashRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLumaDreamMachineRay2FlashRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLumaDreamMachineRay2FlashRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLumaDreamMachineRay2FlashData = z.object({
  body: zSchemaLumaDreamMachineRay2FlashInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLumaDreamMachineRay2FlashResponse = zSchemaQueueStatus

export const zGetFalAiLumaDreamMachineRay2FlashRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLumaDreamMachineRay2FlashRequestsByRequestIdResponse =
  zSchemaLumaDreamMachineRay2FlashOutput

export const zGetFalAiPikaV2TurboTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPikaV2TurboTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPikaV2TurboTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV2TurboTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPikaV2TurboTextToVideoData = z.object({
  body: zSchemaPikaV2TurboTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPikaV2TurboTextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPikaV2TurboTextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPikaV2TurboTextToVideoRequestsByRequestIdResponse =
  zSchemaPikaV2TurboTextToVideoOutput

export const zGetFalAiPikaV21TextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPikaV21TextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPikaV21TextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV21TextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPikaV21TextToVideoData = z.object({
  body: zSchemaPikaV21TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPikaV21TextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPikaV21TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPikaV21TextToVideoRequestsByRequestIdResponse =
  zSchemaPikaV21TextToVideoOutput

export const zGetFalAiPikaV22TextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPikaV22TextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPikaV22TextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV22TextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPikaV22TextToVideoData = z.object({
  body: zSchemaPikaV22TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPikaV22TextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPikaV22TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPikaV22TextToVideoRequestsByRequestIdResponse =
  zSchemaPikaV22TextToVideoOutput

export const zGetFalAiWanProTextToVideoRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiWanProTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanProTextToVideoRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiWanProTextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanProTextToVideoData = z.object({
  body: zSchemaWanProTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanProTextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiWanProTextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanProTextToVideoRequestsByRequestIdResponse =
  zSchemaWanProTextToVideoOutput

export const zGetFalAiKlingVideoV15ProEffectsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV15ProEffectsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV15ProEffectsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV15ProEffectsRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV15ProEffectsData = z.object({
  body: zSchemaKlingVideoV15ProEffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV15ProEffectsResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoV15ProEffectsRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV15ProEffectsRequestsByRequestIdResponse =
  zSchemaKlingVideoV15ProEffectsOutput

export const zGetFalAiKlingVideoV16ProEffectsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV16ProEffectsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV16ProEffectsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV16ProEffectsRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV16ProEffectsData = z.object({
  body: zSchemaKlingVideoV16ProEffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV16ProEffectsResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoV16ProEffectsRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV16ProEffectsRequestsByRequestIdResponse =
  zSchemaKlingVideoV16ProEffectsOutput

export const zGetFalAiKlingVideoV1StandardEffectsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV1StandardEffectsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV1StandardEffectsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV1StandardEffectsRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV1StandardEffectsData = z.object({
  body: zSchemaKlingVideoV1StandardEffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV1StandardEffectsResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoV1StandardEffectsRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV1StandardEffectsRequestsByRequestIdResponse =
  zSchemaKlingVideoV1StandardEffectsOutput

export const zGetFalAiKlingVideoV16StandardEffectsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV16StandardEffectsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV16StandardEffectsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV16StandardEffectsRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV16StandardEffectsData = z.object({
  body: zSchemaKlingVideoV16StandardEffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV16StandardEffectsResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoV16StandardEffectsRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV16StandardEffectsRequestsByRequestIdResponse =
  zSchemaKlingVideoV16StandardEffectsOutput

export const zGetFalAiLtxVideoV095RequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiLtxVideoV095RequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxVideoV095RequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideoV095RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtxVideoV095Data = z.object({
  body: zSchemaLtxVideoV095Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxVideoV095Response = zSchemaQueueStatus

export const zGetFalAiLtxVideoV095RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideoV095RequestsByRequestIdResponse =
  zSchemaLtxVideoV095Output

export const zGetFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV16ProTextToVideoData = z.object({
  body: zSchemaKlingVideoV16ProTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV16ProTextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV16ProTextToVideoOutput

export const zGetFalAiWanT2vRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanT2vRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanT2vRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanT2vRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanT2vData = z.object({
  body: zSchemaWanT2vInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanT2vResponse = zSchemaQueueStatus

export const zGetFalAiWanT2vRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanT2vRequestsByRequestIdResponse = zSchemaWanT2vOutput

export const zGetFalAiVeo2RequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiVeo2RequestsByRequestIdStatusResponse = zSchemaQueueStatus

export const zPutFalAiVeo2RequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo2RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiVeo2Data = z.object({
  body: zSchemaVeo2Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVeo2Response = zSchemaQueueStatus

export const zGetFalAiVeo2RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiVeo2RequestsByRequestIdResponse = zSchemaVeo2Output

export const zGetFalAiMinimaxVideo01DirectorRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxVideo01DirectorRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxVideo01DirectorRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxVideo01DirectorRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMinimaxVideo01DirectorData = z.object({
  body: zSchemaMinimaxVideo01DirectorInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxVideo01DirectorResponse = zSchemaQueueStatus

export const zGetFalAiMinimaxVideo01DirectorRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxVideo01DirectorRequestsByRequestIdResponse =
  zSchemaMinimaxVideo01DirectorOutput

export const zGetFalAiPixverseV35TextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV35TextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV35TextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV35TextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPixverseV35TextToVideoData = z.object({
  body: zSchemaPixverseV35TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV35TextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV35TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV35TextToVideoRequestsByRequestIdResponse =
  zSchemaPixverseV35TextToVideoOutput

export const zGetFalAiPixverseV35TextToVideoFastRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseV35TextToVideoFastRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseV35TextToVideoFastRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV35TextToVideoFastRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiPixverseV35TextToVideoFastData = z.object({
  body: zSchemaPixverseV35TextToVideoFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseV35TextToVideoFastResponse = zSchemaQueueStatus

export const zGetFalAiPixverseV35TextToVideoFastRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV35TextToVideoFastRequestsByRequestIdResponse =
  zSchemaPixverseV35TextToVideoFastOutput

export const zGetFalAiLumaDreamMachineRay2RequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLumaDreamMachineRay2RequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLumaDreamMachineRay2RequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLumaDreamMachineRay2RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLumaDreamMachineRay2Data = z.object({
  body: zSchemaLumaDreamMachineRay2Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLumaDreamMachineRay2Response = zSchemaQueueStatus

export const zGetFalAiLumaDreamMachineRay2RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLumaDreamMachineRay2RequestsByRequestIdResponse =
  zSchemaLumaDreamMachineRay2Output

export const zGetFalAiHunyuanVideoLoraRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiHunyuanVideoLoraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiHunyuanVideoLoraRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanVideoLoraRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiHunyuanVideoLoraData = z.object({
  body: zSchemaHunyuanVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiHunyuanVideoLoraResponse = zSchemaQueueStatus

export const zGetFalAiHunyuanVideoLoraRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanVideoLoraRequestsByRequestIdResponse =
  zSchemaHunyuanVideoLoraOutput

export const zGetFalAiTranspixarRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiTranspixarRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiTranspixarRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiTranspixarRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiTranspixarData = z.object({
  body: zSchemaTranspixarInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiTranspixarResponse = zSchemaQueueStatus

export const zGetFalAiTranspixarRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiTranspixarRequestsByRequestIdResponse =
  zSchemaTranspixarOutput

export const zGetFalAiCogvideox5bRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiCogvideox5bRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiCogvideox5bRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiCogvideox5bRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiCogvideox5bData = z.object({
  body: zSchemaCogvideox5bInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiCogvideox5bResponse = zSchemaQueueStatus

export const zGetFalAiCogvideox5bRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiCogvideox5bRequestsByRequestIdResponse =
  zSchemaCogvideox5bOutput

export const zGetFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV16StandardTextToVideoData = z.object({
  body: zSchemaKlingVideoV16StandardTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV16StandardTextToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV16StandardTextToVideoOutput

export const zGetFalAiMinimaxVideo01LiveRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMinimaxVideo01LiveRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxVideo01LiveRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxVideo01LiveRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiMinimaxVideo01LiveData = z.object({
  body: zSchemaMinimaxVideo01LiveInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxVideo01LiveResponse = zSchemaQueueStatus

export const zGetFalAiMinimaxVideo01LiveRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxVideo01LiveRequestsByRequestIdResponse =
  zSchemaMinimaxVideo01LiveOutput

export const zGetFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV1StandardTextToVideoData = z.object({
  body: zSchemaKlingVideoV1StandardTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV1StandardTextToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV1StandardTextToVideoOutput

export const zGetFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV15ProTextToVideoData = z.object({
  body: zSchemaKlingVideoV15ProTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV15ProTextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdResponse =
  zSchemaKlingVideoV15ProTextToVideoOutput

export const zGetFalAiMochiV1RequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiMochiV1RequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMochiV1RequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiMochiV1RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiMochiV1Data = z.object({
  body: zSchemaMochiV1Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMochiV1Response = zSchemaQueueStatus

export const zGetFalAiMochiV1RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiMochiV1RequestsByRequestIdResponse = zSchemaMochiV1Output

export const zGetFalAiHunyuanVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiHunyuanVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiHunyuanVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiHunyuanVideoData = z.object({
  body: zSchemaHunyuanVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiHunyuanVideoResponse = zSchemaQueueStatus

export const zGetFalAiHunyuanVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanVideoRequestsByRequestIdResponse =
  zSchemaHunyuanVideoOutput

export const zGetFalAiLtxVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiLtxVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtxVideoData = z.object({
  body: zSchemaLtxVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtxVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideoRequestsByRequestIdResponse =
  zSchemaLtxVideoOutput

export const zGetFalAiFastSvdTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiFastSvdTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiFastSvdTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiFastSvdTextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiFastSvdTextToVideoData = z.object({
  body: zSchemaFastSvdTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiFastSvdTextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiFastSvdTextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiFastSvdTextToVideoRequestsByRequestIdResponse =
  zSchemaFastSvdTextToVideoOutput

export const zGetFalAiFastSvdLcmTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiFastSvdLcmTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiFastSvdLcmTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiFastSvdLcmTextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiFastSvdLcmTextToVideoData = z.object({
  body: zSchemaFastSvdLcmTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiFastSvdLcmTextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiFastSvdLcmTextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiFastSvdLcmTextToVideoRequestsByRequestIdResponse =
  zSchemaFastSvdLcmTextToVideoOutput

export const zGetFalAiT2vTurboRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiT2vTurboRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiT2vTurboRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiT2vTurboRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiT2vTurboData = z.object({
  body: zSchemaT2vTurboInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiT2vTurboResponse = zSchemaQueueStatus

export const zGetFalAiT2vTurboRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiT2vTurboRequestsByRequestIdResponse =
  zSchemaT2vTurboOutput

export const zGetFalAiFastAnimatediffTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiFastAnimatediffTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiFastAnimatediffTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiFastAnimatediffTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiFastAnimatediffTextToVideoData = z.object({
  body: zSchemaFastAnimatediffTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiFastAnimatediffTextToVideoResponse = zSchemaQueueStatus

export const zGetFalAiFastAnimatediffTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiFastAnimatediffTextToVideoRequestsByRequestIdResponse =
  zSchemaFastAnimatediffTextToVideoOutput

export const zGetFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiFastAnimatediffTurboTextToVideoData = z.object({
  body: zSchemaFastAnimatediffTurboTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiFastAnimatediffTurboTextToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdResponse =
  zSchemaFastAnimatediffTurboTextToVideoOutput

export const zGetFalAiMinimaxVideo01RequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiMinimaxVideo01RequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMinimaxVideo01RequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxVideo01RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiMinimaxVideo01Data = z.object({
  body: zSchemaMinimaxVideo01Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMinimaxVideo01Response = zSchemaQueueStatus

export const zGetFalAiMinimaxVideo01RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxVideo01RequestsByRequestIdResponse =
  zSchemaMinimaxVideo01Output

export const zGetFalAiAnimatediffSparsectrlLcmRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiAnimatediffSparsectrlLcmRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiAnimatediffSparsectrlLcmRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiAnimatediffSparsectrlLcmRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiAnimatediffSparsectrlLcmData = z.object({
  body: zSchemaAnimatediffSparsectrlLcmInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiAnimatediffSparsectrlLcmResponse = zSchemaQueueStatus

export const zGetFalAiAnimatediffSparsectrlLcmRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiAnimatediffSparsectrlLcmRequestsByRequestIdResponse =
  zSchemaAnimatediffSparsectrlLcmOutput

export const zGetBriaVideoBackgroundRemovalRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetBriaVideoBackgroundRemovalRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutBriaVideoBackgroundRemovalRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutBriaVideoBackgroundRemovalRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostBriaVideoBackgroundRemovalData = z.object({
  body: zSchemaVideoBackgroundRemovalInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostBriaVideoBackgroundRemovalResponse = zSchemaQueueStatus

export const zGetBriaVideoBackgroundRemovalRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetBriaVideoBackgroundRemovalRequestsByRequestIdResponse =
  zSchemaVideoBackgroundRemovalOutput

export const zGetFalAiMmaudioV2RequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiMmaudioV2RequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMmaudioV2RequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiMmaudioV2RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiMmaudioV2Data = z.object({
  body: zSchemaMmaudioV2Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMmaudioV2Response = zSchemaQueueStatus

export const zGetFalAiMmaudioV2RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiMmaudioV2RequestsByRequestIdResponse =
  zSchemaMmaudioV2Output

export const zGetHalfMoonAiAiFaceSwapFaceswapvideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetHalfMoonAiAiFaceSwapFaceswapvideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutHalfMoonAiAiFaceSwapFaceswapvideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutHalfMoonAiAiFaceSwapFaceswapvideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostHalfMoonAiAiFaceSwapFaceswapvideoData = z.object({
  body: zSchemaAiFaceSwapFaceswapvideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostHalfMoonAiAiFaceSwapFaceswapvideoResponse = zSchemaQueueStatus

export const zGetHalfMoonAiAiFaceSwapFaceswapvideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetHalfMoonAiAiFaceSwapFaceswapvideoRequestsByRequestIdResponse =
  zSchemaAiFaceSwapFaceswapvideoOutput

export const zGetFalAiLtx219bDistilledVideoToVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bDistilledVideoToVideoLoraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bDistilledVideoToVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bDistilledVideoToVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtx219bDistilledVideoToVideoLoraData = z.object({
  body: zSchemaLtx219bDistilledVideoToVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bDistilledVideoToVideoLoraResponse =
  zSchemaQueueStatus

export const zGetFalAiLtx219bDistilledVideoToVideoLoraRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bDistilledVideoToVideoLoraRequestsByRequestIdResponse =
  zSchemaLtx219bDistilledVideoToVideoLoraOutput

export const zGetFalAiLtx219bDistilledVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bDistilledVideoToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bDistilledVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bDistilledVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtx219bDistilledVideoToVideoData = z.object({
  body: zSchemaLtx219bDistilledVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bDistilledVideoToVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtx219bDistilledVideoToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bDistilledVideoToVideoRequestsByRequestIdResponse =
  zSchemaLtx219bDistilledVideoToVideoOutput

export const zGetFalAiLtx219bVideoToVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bVideoToVideoLoraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bVideoToVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bVideoToVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtx219bVideoToVideoLoraData = z.object({
  body: zSchemaLtx219bVideoToVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bVideoToVideoLoraResponse = zSchemaQueueStatus

export const zGetFalAiLtx219bVideoToVideoLoraRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bVideoToVideoLoraRequestsByRequestIdResponse =
  zSchemaLtx219bVideoToVideoLoraOutput

export const zGetFalAiLtx219bVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bVideoToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bVideoToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtx219bVideoToVideoData = z.object({
  body: zSchemaLtx219bVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bVideoToVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtx219bVideoToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bVideoToVideoRequestsByRequestIdResponse =
  zSchemaLtx219bVideoToVideoOutput

export const zGetFalAiLtx219bDistilledExtendVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bDistilledExtendVideoLoraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bDistilledExtendVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bDistilledExtendVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtx219bDistilledExtendVideoLoraData = z.object({
  body: zSchemaLtx219bDistilledExtendVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bDistilledExtendVideoLoraResponse =
  zSchemaQueueStatus

export const zGetFalAiLtx219bDistilledExtendVideoLoraRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bDistilledExtendVideoLoraRequestsByRequestIdResponse =
  zSchemaLtx219bDistilledExtendVideoLoraOutput

export const zGetFalAiLtx219bDistilledExtendVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bDistilledExtendVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bDistilledExtendVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bDistilledExtendVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtx219bDistilledExtendVideoData = z.object({
  body: zSchemaLtx219bDistilledExtendVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bDistilledExtendVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtx219bDistilledExtendVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bDistilledExtendVideoRequestsByRequestIdResponse =
  zSchemaLtx219bDistilledExtendVideoOutput

export const zGetFalAiLtx219bExtendVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bExtendVideoLoraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bExtendVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bExtendVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtx219bExtendVideoLoraData = z.object({
  body: zSchemaLtx219bExtendVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bExtendVideoLoraResponse = zSchemaQueueStatus

export const zGetFalAiLtx219bExtendVideoLoraRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bExtendVideoLoraRequestsByRequestIdResponse =
  zSchemaLtx219bExtendVideoLoraOutput

export const zGetFalAiLtx219bExtendVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bExtendVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bExtendVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bExtendVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtx219bExtendVideoData = z.object({
  body: zSchemaLtx219bExtendVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bExtendVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtx219bExtendVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bExtendVideoRequestsByRequestIdResponse =
  zSchemaLtx219bExtendVideoOutput

export const zGetBriaVideoEraseKeypointsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetBriaVideoEraseKeypointsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutBriaVideoEraseKeypointsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutBriaVideoEraseKeypointsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostBriaVideoEraseKeypointsData = z.object({
  body: zSchemaVideoEraseKeypointsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostBriaVideoEraseKeypointsResponse = zSchemaQueueStatus

export const zGetBriaVideoEraseKeypointsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetBriaVideoEraseKeypointsRequestsByRequestIdResponse =
  zSchemaVideoEraseKeypointsOutput

export const zGetBriaVideoErasePromptRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetBriaVideoErasePromptRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutBriaVideoErasePromptRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutBriaVideoErasePromptRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostBriaVideoErasePromptData = z.object({
  body: zSchemaVideoErasePromptInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostBriaVideoErasePromptResponse = zSchemaQueueStatus

export const zGetBriaVideoErasePromptRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetBriaVideoErasePromptRequestsByRequestIdResponse =
  zSchemaVideoErasePromptOutput

export const zGetBriaVideoEraseMaskRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetBriaVideoEraseMaskRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutBriaVideoEraseMaskRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutBriaVideoEraseMaskRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostBriaVideoEraseMaskData = z.object({
  body: zSchemaVideoEraseMaskInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostBriaVideoEraseMaskResponse = zSchemaQueueStatus

export const zGetBriaVideoEraseMaskRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetBriaVideoEraseMaskRequestsByRequestIdResponse =
  zSchemaVideoEraseMaskOutput

export const zGetFalAiLightxRelightRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiLightxRelightRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLightxRelightRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiLightxRelightRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLightxRelightData = z.object({
  body: zSchemaLightxRelightInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLightxRelightResponse = zSchemaQueueStatus

export const zGetFalAiLightxRelightRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLightxRelightRequestsByRequestIdResponse =
  zSchemaLightxRelightOutput

export const zGetFalAiLightxRecameraRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiLightxRecameraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLightxRecameraRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiLightxRecameraRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLightxRecameraData = z.object({
  body: zSchemaLightxRecameraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLightxRecameraResponse = zSchemaQueueStatus

export const zGetFalAiLightxRecameraRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLightxRecameraRequestsByRequestIdResponse =
  zSchemaLightxRecameraOutput

export const zGetFalAiKlingVideoV26StandardMotionControlRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV26StandardMotionControlRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV26StandardMotionControlRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV26StandardMotionControlRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV26StandardMotionControlData = z.object({
  body: zSchemaKlingVideoV26StandardMotionControlInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV26StandardMotionControlResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoV26StandardMotionControlRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV26StandardMotionControlRequestsByRequestIdResponse =
  zSchemaKlingVideoV26StandardMotionControlOutput

export const zGetFalAiKlingVideoV26ProMotionControlRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV26ProMotionControlRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV26ProMotionControlRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV26ProMotionControlRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV26ProMotionControlData = z.object({
  body: zSchemaKlingVideoV26ProMotionControlInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV26ProMotionControlResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoV26ProMotionControlRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV26ProMotionControlRequestsByRequestIdResponse =
  zSchemaKlingVideoV26ProMotionControlOutput

export const zGetDecartLucyRestyleRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetDecartLucyRestyleRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutDecartLucyRestyleRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutDecartLucyRestyleRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostDecartLucyRestyleData = z.object({
  body: zSchemaLucyRestyleInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostDecartLucyRestyleResponse = zSchemaQueueStatus

export const zGetDecartLucyRestyleRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetDecartLucyRestyleRequestsByRequestIdResponse =
  zSchemaLucyRestyleOutput

export const zGetFalAiScailRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiScailRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiScailRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiScailRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiScailData = z.object({
  body: zSchemaScailInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiScailResponse = zSchemaQueueStatus

export const zGetFalAiScailRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiScailRequestsByRequestIdResponse = zSchemaScailOutput

export const zGetClarityaiCrystalVideoUpscalerRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetClarityaiCrystalVideoUpscalerRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutClarityaiCrystalVideoUpscalerRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutClarityaiCrystalVideoUpscalerRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostClarityaiCrystalVideoUpscalerData = z.object({
  body: zSchemaCrystalVideoUpscalerInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostClarityaiCrystalVideoUpscalerResponse = zSchemaQueueStatus

export const zGetClarityaiCrystalVideoUpscalerRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetClarityaiCrystalVideoUpscalerRequestsByRequestIdResponse =
  zSchemaCrystalVideoUpscalerOutput

export const zGetBriaBriaVideoEraserEraseMaskRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetBriaBriaVideoEraserEraseMaskRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutBriaBriaVideoEraserEraseMaskRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutBriaBriaVideoEraserEraseMaskRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostBriaBriaVideoEraserEraseMaskData = z.object({
  body: zSchemaBriaVideoEraserEraseMaskInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostBriaBriaVideoEraserEraseMaskResponse = zSchemaQueueStatus

export const zGetBriaBriaVideoEraserEraseMaskRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetBriaBriaVideoEraserEraseMaskRequestsByRequestIdResponse =
  zSchemaBriaVideoEraserEraseMaskOutput

export const zGetBriaBriaVideoEraserEraseKeypointsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetBriaBriaVideoEraserEraseKeypointsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutBriaBriaVideoEraserEraseKeypointsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutBriaBriaVideoEraserEraseKeypointsRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostBriaBriaVideoEraserEraseKeypointsData = z.object({
  body: zSchemaBriaVideoEraserEraseKeypointsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostBriaBriaVideoEraserEraseKeypointsResponse = zSchemaQueueStatus

export const zGetBriaBriaVideoEraserEraseKeypointsRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetBriaBriaVideoEraserEraseKeypointsRequestsByRequestIdResponse =
  zSchemaBriaVideoEraserEraseKeypointsOutput

export const zGetBriaBriaVideoEraserErasePromptRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetBriaBriaVideoEraserErasePromptRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutBriaBriaVideoEraserErasePromptRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutBriaBriaVideoEraserErasePromptRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostBriaBriaVideoEraserErasePromptData = z.object({
  body: zSchemaBriaVideoEraserErasePromptInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostBriaBriaVideoEraserErasePromptResponse = zSchemaQueueStatus

export const zGetBriaBriaVideoEraserErasePromptRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetBriaBriaVideoEraserErasePromptRequestsByRequestIdResponse =
  zSchemaBriaVideoEraserErasePromptOutput

export const zGetWanV26ReferenceToVideoRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetWanV26ReferenceToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutWanV26ReferenceToVideoRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutWanV26ReferenceToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostWanV26ReferenceToVideoData = z.object({
  body: zSchemaV26ReferenceToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostWanV26ReferenceToVideoResponse = zSchemaQueueStatus

export const zGetWanV26ReferenceToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetWanV26ReferenceToVideoRequestsByRequestIdResponse =
  zSchemaV26ReferenceToVideoOutput

export const zGetFalAiVeo31FastExtendVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiVeo31FastExtendVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVeo31FastExtendVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo31FastExtendVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiVeo31FastExtendVideoData = z.object({
  body: zSchemaVeo31FastExtendVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVeo31FastExtendVideoResponse = zSchemaQueueStatus

export const zGetFalAiVeo31FastExtendVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiVeo31FastExtendVideoRequestsByRequestIdResponse =
  zSchemaVeo31FastExtendVideoOutput

export const zGetFalAiVeo31ExtendVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiVeo31ExtendVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVeo31ExtendVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo31ExtendVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiVeo31ExtendVideoData = z.object({
  body: zSchemaVeo31ExtendVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVeo31ExtendVideoResponse = zSchemaQueueStatus

export const zGetFalAiVeo31ExtendVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiVeo31ExtendVideoRequestsByRequestIdResponse =
  zSchemaVeo31ExtendVideoOutput

export const zGetFalAiKlingVideoO1StandardVideoToVideoReferenceRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoO1StandardVideoToVideoReferenceRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoO1StandardVideoToVideoReferenceRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoO1StandardVideoToVideoReferenceRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoO1StandardVideoToVideoReferenceData = z.object(
  {
    body: zSchemaKlingVideoO1StandardVideoToVideoReferenceInput,
    path: z.optional(z.never()),
    query: z.optional(z.never()),
  },
)

/**
 * The request status.
 */
export const zPostFalAiKlingVideoO1StandardVideoToVideoReferenceResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoO1StandardVideoToVideoReferenceRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoO1StandardVideoToVideoReferenceRequestsByRequestIdResponse =
  zSchemaKlingVideoO1StandardVideoToVideoReferenceOutput

export const zGetFalAiKlingVideoO1StandardVideoToVideoEditRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoO1StandardVideoToVideoEditRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoO1StandardVideoToVideoEditRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoO1StandardVideoToVideoEditRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoO1StandardVideoToVideoEditData = z.object({
  body: zSchemaKlingVideoO1StandardVideoToVideoEditInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoO1StandardVideoToVideoEditResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoO1StandardVideoToVideoEditRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoO1StandardVideoToVideoEditRequestsByRequestIdResponse =
  zSchemaKlingVideoO1StandardVideoToVideoEditOutput

export const zGetFalAiSteadyDancerRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiSteadyDancerRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSteadyDancerRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiSteadyDancerRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSteadyDancerData = z.object({
  body: zSchemaSteadyDancerInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSteadyDancerResponse = zSchemaQueueStatus

export const zGetFalAiSteadyDancerRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSteadyDancerRequestsByRequestIdResponse =
  zSchemaSteadyDancerOutput

export const zGetFalAiOneToAllAnimation13bRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiOneToAllAnimation13bRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiOneToAllAnimation13bRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiOneToAllAnimation13bRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiOneToAllAnimation13bData = z.object({
  body: zSchemaOneToAllAnimation13bInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiOneToAllAnimation13bResponse = zSchemaQueueStatus

export const zGetFalAiOneToAllAnimation13bRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiOneToAllAnimation13bRequestsByRequestIdResponse =
  zSchemaOneToAllAnimation13bOutput

export const zGetFalAiOneToAllAnimation14bRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiOneToAllAnimation14bRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiOneToAllAnimation14bRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiOneToAllAnimation14bRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiOneToAllAnimation14bData = z.object({
  body: zSchemaOneToAllAnimation14bInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiOneToAllAnimation14bResponse = zSchemaQueueStatus

export const zGetFalAiOneToAllAnimation14bRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiOneToAllAnimation14bRequestsByRequestIdResponse =
  zSchemaOneToAllAnimation14bOutput

export const zGetFalAiWanVisionEnhancerRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiWanVisionEnhancerRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanVisionEnhancerRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVisionEnhancerRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanVisionEnhancerData = z.object({
  body: zSchemaWanVisionEnhancerInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanVisionEnhancerResponse = zSchemaQueueStatus

export const zGetFalAiWanVisionEnhancerRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanVisionEnhancerRequestsByRequestIdResponse =
  zSchemaWanVisionEnhancerOutput

export const zGetFalAiSyncLipsyncReact1RequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiSyncLipsyncReact1RequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSyncLipsyncReact1RequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiSyncLipsyncReact1RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSyncLipsyncReact1Data = z.object({
  body: zSchemaSyncLipsyncReact1Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSyncLipsyncReact1Response = zSchemaQueueStatus

export const zGetFalAiSyncLipsyncReact1RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSyncLipsyncReact1RequestsByRequestIdResponse =
  zSchemaSyncLipsyncReact1Output

export const zGetVeedVideoBackgroundRemovalFastRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetVeedVideoBackgroundRemovalFastRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutVeedVideoBackgroundRemovalFastRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutVeedVideoBackgroundRemovalFastRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostVeedVideoBackgroundRemovalFastData = z.object({
  body: zSchemaVideoBackgroundRemovalFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostVeedVideoBackgroundRemovalFastResponse = zSchemaQueueStatus

export const zGetVeedVideoBackgroundRemovalFastRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetVeedVideoBackgroundRemovalFastRequestsByRequestIdResponse =
  zSchemaVideoBackgroundRemovalFastOutput

export const zGetFalAiKlingVideoO1VideoToVideoEditRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoO1VideoToVideoEditRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoO1VideoToVideoEditRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoO1VideoToVideoEditRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoO1VideoToVideoEditData = z.object({
  body: zSchemaKlingVideoO1VideoToVideoEditInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoO1VideoToVideoEditResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoO1VideoToVideoEditRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoO1VideoToVideoEditRequestsByRequestIdResponse =
  zSchemaKlingVideoO1VideoToVideoEditOutput

export const zGetFalAiKlingVideoO1VideoToVideoReferenceRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoO1VideoToVideoReferenceRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoO1VideoToVideoReferenceRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoO1VideoToVideoReferenceRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoO1VideoToVideoReferenceData = z.object({
  body: zSchemaKlingVideoO1VideoToVideoReferenceInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoO1VideoToVideoReferenceResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoO1VideoToVideoReferenceRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoO1VideoToVideoReferenceRequestsByRequestIdResponse =
  zSchemaKlingVideoO1VideoToVideoReferenceOutput

export const zGetVeedVideoBackgroundRemovalRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetVeedVideoBackgroundRemovalRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutVeedVideoBackgroundRemovalRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutVeedVideoBackgroundRemovalRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostVeedVideoBackgroundRemovalData = z.object({
  body: zSchemaVideoBackgroundRemovalInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostVeedVideoBackgroundRemovalResponse = zSchemaQueueStatus

export const zGetVeedVideoBackgroundRemovalRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetVeedVideoBackgroundRemovalRequestsByRequestIdResponse =
  zSchemaVideoBackgroundRemovalOutput

export const zGetVeedVideoBackgroundRemovalGreenScreenRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetVeedVideoBackgroundRemovalGreenScreenRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutVeedVideoBackgroundRemovalGreenScreenRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutVeedVideoBackgroundRemovalGreenScreenRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostVeedVideoBackgroundRemovalGreenScreenData = z.object({
  body: zSchemaVideoBackgroundRemovalGreenScreenInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostVeedVideoBackgroundRemovalGreenScreenResponse =
  zSchemaQueueStatus

export const zGetVeedVideoBackgroundRemovalGreenScreenRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetVeedVideoBackgroundRemovalGreenScreenRequestsByRequestIdResponse =
  zSchemaVideoBackgroundRemovalGreenScreenOutput

export const zGetFalAiLtx2RetakeVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiLtx2RetakeVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx2RetakeVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx2RetakeVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtx2RetakeVideoData = z.object({
  body: zSchemaLtx2RetakeVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx2RetakeVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtx2RetakeVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtx2RetakeVideoRequestsByRequestIdResponse =
  zSchemaLtx2RetakeVideoOutput

export const zGetDecartLucyEditFastRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetDecartLucyEditFastRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutDecartLucyEditFastRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutDecartLucyEditFastRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostDecartLucyEditFastData = z.object({
  body: zSchemaLucyEditFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostDecartLucyEditFastResponse = zSchemaQueueStatus

export const zGetDecartLucyEditFastRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetDecartLucyEditFastRequestsByRequestIdResponse =
  zSchemaLucyEditFastOutput

export const zGetFalAiSam3VideoRleRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiSam3VideoRleRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSam3VideoRleRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiSam3VideoRleRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSam3VideoRleData = z.object({
  body: zSchemaSam3VideoRleInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSam3VideoRleResponse = zSchemaQueueStatus

export const zGetFalAiSam3VideoRleRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSam3VideoRleRequestsByRequestIdResponse =
  zSchemaSam3VideoRleOutput

export const zGetFalAiSam3VideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiSam3VideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSam3VideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiSam3VideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSam3VideoData = z.object({
  body: zSchemaSam3VideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSam3VideoResponse = zSchemaQueueStatus

export const zGetFalAiSam3VideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSam3VideoRequestsByRequestIdResponse =
  zSchemaSam3VideoOutput

export const zGetFalAiEdittoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiEdittoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiEdittoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiEdittoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiEdittoData = z.object({
  body: zSchemaEdittoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiEdittoResponse = zSchemaQueueStatus

export const zGetFalAiEdittoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiEdittoRequestsByRequestIdResponse = zSchemaEdittoOutput

export const zGetFalAiFlashvsrUpscaleVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiFlashvsrUpscaleVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiFlashvsrUpscaleVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiFlashvsrUpscaleVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiFlashvsrUpscaleVideoData = z.object({
  body: zSchemaFlashvsrUpscaleVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiFlashvsrUpscaleVideoResponse = zSchemaQueueStatus

export const zGetFalAiFlashvsrUpscaleVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiFlashvsrUpscaleVideoRequestsByRequestIdResponse =
  zSchemaFlashvsrUpscaleVideoOutput

export const zGetFalAiWorkflowUtilitiesAutoSubtitleRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWorkflowUtilitiesAutoSubtitleRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWorkflowUtilitiesAutoSubtitleRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWorkflowUtilitiesAutoSubtitleRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWorkflowUtilitiesAutoSubtitleData = z.object({
  body: zSchemaWorkflowUtilitiesAutoSubtitleInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWorkflowUtilitiesAutoSubtitleResponse =
  zSchemaQueueStatus

export const zGetFalAiWorkflowUtilitiesAutoSubtitleRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiWorkflowUtilitiesAutoSubtitleRequestsByRequestIdResponse =
  zSchemaWorkflowUtilitiesAutoSubtitleOutput

export const zGetFalAiBytedanceUpscalerUpscaleVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiBytedanceUpscalerUpscaleVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiBytedanceUpscalerUpscaleVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceUpscalerUpscaleVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiBytedanceUpscalerUpscaleVideoData = z.object({
  body: zSchemaBytedanceUpscalerUpscaleVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiBytedanceUpscalerUpscaleVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiBytedanceUpscalerUpscaleVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceUpscalerUpscaleVideoRequestsByRequestIdResponse =
  zSchemaBytedanceUpscalerUpscaleVideoOutput

export const zGetFalAiVideoAsPromptRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiVideoAsPromptRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVideoAsPromptRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiVideoAsPromptRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiVideoAsPromptData = z.object({
  body: zSchemaVideoAsPromptInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVideoAsPromptResponse = zSchemaQueueStatus

export const zGetFalAiVideoAsPromptRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiVideoAsPromptRequestsByRequestIdResponse =
  zSchemaVideoAsPromptOutput

export const zGetFalAiBirefnetV2VideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiBirefnetV2VideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiBirefnetV2VideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiBirefnetV2VideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiBirefnetV2VideoData = z.object({
  body: zSchemaBirefnetV2VideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiBirefnetV2VideoResponse = zSchemaQueueStatus

export const zGetFalAiBirefnetV2VideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiBirefnetV2VideoRequestsByRequestIdResponse =
  zSchemaBirefnetV2VideoOutput

export const zGetFalAiViduQ2VideoExtensionProRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiViduQ2VideoExtensionProRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiViduQ2VideoExtensionProRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ2VideoExtensionProRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiViduQ2VideoExtensionProData = z.object({
  body: zSchemaViduQ2VideoExtensionProInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiViduQ2VideoExtensionProResponse = zSchemaQueueStatus

export const zGetFalAiViduQ2VideoExtensionProRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiViduQ2VideoExtensionProRequestsByRequestIdResponse =
  zSchemaViduQ2VideoExtensionProOutput

export const zGetMireloAiSfxV15VideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetMireloAiSfxV15VideoToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutMireloAiSfxV15VideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutMireloAiSfxV15VideoToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostMireloAiSfxV15VideoToVideoData = z.object({
  body: zSchemaSfxV15VideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostMireloAiSfxV15VideoToVideoResponse = zSchemaQueueStatus

export const zGetMireloAiSfxV15VideoToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetMireloAiSfxV15VideoToVideoRequestsByRequestIdResponse =
  zSchemaSfxV15VideoToVideoOutput

export const zGetFalAiKreaWan14bVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKreaWan14bVideoToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKreaWan14bVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKreaWan14bVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKreaWan14bVideoToVideoData = z.object({
  body: zSchemaKreaWan14bVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKreaWan14bVideoToVideoResponse = zSchemaQueueStatus

export const zGetFalAiKreaWan14bVideoToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiKreaWan14bVideoToVideoRequestsByRequestIdResponse =
  zSchemaKreaWan14bVideoToVideoOutput

export const zGetFalAiSora2VideoToVideoRemixRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiSora2VideoToVideoRemixRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSora2VideoToVideoRemixRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiSora2VideoToVideoRemixRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiSora2VideoToVideoRemixData = z.object({
  body: zSchemaSora2VideoToVideoRemixInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSora2VideoToVideoRemixResponse = zSchemaQueueStatus

export const zGetFalAiSora2VideoToVideoRemixRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSora2VideoToVideoRemixRequestsByRequestIdResponse =
  zSchemaSora2VideoToVideoRemixOutput

export const zGetFalAiWanVaceAppsLongReframeRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanVaceAppsLongReframeRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanVaceAppsLongReframeRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVaceAppsLongReframeRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWanVaceAppsLongReframeData = z.object({
  body: zSchemaWanVaceAppsLongReframeInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanVaceAppsLongReframeResponse = zSchemaQueueStatus

export const zGetFalAiWanVaceAppsLongReframeRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanVaceAppsLongReframeRequestsByRequestIdResponse =
  zSchemaWanVaceAppsLongReframeOutput

export const zGetFalAiInfinitalkVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiInfinitalkVideoToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiInfinitalkVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiInfinitalkVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiInfinitalkVideoToVideoData = z.object({
  body: zSchemaInfinitalkVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiInfinitalkVideoToVideoResponse = zSchemaQueueStatus

export const zGetFalAiInfinitalkVideoToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiInfinitalkVideoToVideoRequestsByRequestIdResponse =
  zSchemaInfinitalkVideoToVideoOutput

export const zGetFalAiSeedvrUpscaleVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiSeedvrUpscaleVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSeedvrUpscaleVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiSeedvrUpscaleVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSeedvrUpscaleVideoData = z.object({
  body: zSchemaSeedvrUpscaleVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSeedvrUpscaleVideoResponse = zSchemaQueueStatus

export const zGetFalAiSeedvrUpscaleVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSeedvrUpscaleVideoRequestsByRequestIdResponse =
  zSchemaSeedvrUpscaleVideoOutput

export const zGetFalAiWanVaceAppsVideoEditRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanVaceAppsVideoEditRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanVaceAppsVideoEditRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVaceAppsVideoEditRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanVaceAppsVideoEditData = z.object({
  body: zSchemaWanVaceAppsVideoEditInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanVaceAppsVideoEditResponse = zSchemaQueueStatus

export const zGetFalAiWanVaceAppsVideoEditRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanVaceAppsVideoEditRequestsByRequestIdResponse =
  zSchemaWanVaceAppsVideoEditOutput

export const zGetFalAiWanV2214bAnimateReplaceRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanV2214bAnimateReplaceRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanV2214bAnimateReplaceRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV2214bAnimateReplaceRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWanV2214bAnimateReplaceData = z.object({
  body: zSchemaWanV2214bAnimateReplaceInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanV2214bAnimateReplaceResponse = zSchemaQueueStatus

export const zGetFalAiWanV2214bAnimateReplaceRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiWanV2214bAnimateReplaceRequestsByRequestIdResponse =
  zSchemaWanV2214bAnimateReplaceOutput

export const zGetFalAiWanV2214bAnimateMoveRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanV2214bAnimateMoveRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanV2214bAnimateMoveRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV2214bAnimateMoveRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanV2214bAnimateMoveData = z.object({
  body: zSchemaWanV2214bAnimateMoveInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanV2214bAnimateMoveResponse = zSchemaQueueStatus

export const zGetFalAiWanV2214bAnimateMoveRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanV2214bAnimateMoveRequestsByRequestIdResponse =
  zSchemaWanV2214bAnimateMoveOutput

export const zGetDecartLucyEditProRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetDecartLucyEditProRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutDecartLucyEditProRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutDecartLucyEditProRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostDecartLucyEditProData = z.object({
  body: zSchemaLucyEditProInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostDecartLucyEditProResponse = zSchemaQueueStatus

export const zGetDecartLucyEditProRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetDecartLucyEditProRequestsByRequestIdResponse =
  zSchemaLucyEditProOutput

export const zGetDecartLucyEditDevRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetDecartLucyEditDevRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutDecartLucyEditDevRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutDecartLucyEditDevRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostDecartLucyEditDevData = z.object({
  body: zSchemaLucyEditDevInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostDecartLucyEditDevResponse = zSchemaQueueStatus

export const zGetDecartLucyEditDevRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetDecartLucyEditDevRequestsByRequestIdResponse =
  zSchemaLucyEditDevOutput

export const zGetFalAiWan22VaceFunA14bReframeRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWan22VaceFunA14bReframeRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWan22VaceFunA14bReframeRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWan22VaceFunA14bReframeRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWan22VaceFunA14bReframeData = z.object({
  body: zSchemaWan22VaceFunA14bReframeInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWan22VaceFunA14bReframeResponse = zSchemaQueueStatus

export const zGetFalAiWan22VaceFunA14bReframeRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiWan22VaceFunA14bReframeRequestsByRequestIdResponse =
  zSchemaWan22VaceFunA14bReframeOutput

export const zGetFalAiWan22VaceFunA14bOutpaintingRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWan22VaceFunA14bOutpaintingRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWan22VaceFunA14bOutpaintingRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWan22VaceFunA14bOutpaintingRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWan22VaceFunA14bOutpaintingData = z.object({
  body: zSchemaWan22VaceFunA14bOutpaintingInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWan22VaceFunA14bOutpaintingResponse = zSchemaQueueStatus

export const zGetFalAiWan22VaceFunA14bOutpaintingRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiWan22VaceFunA14bOutpaintingRequestsByRequestIdResponse =
  zSchemaWan22VaceFunA14bOutpaintingOutput

export const zGetFalAiWan22VaceFunA14bInpaintingRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWan22VaceFunA14bInpaintingRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWan22VaceFunA14bInpaintingRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWan22VaceFunA14bInpaintingRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWan22VaceFunA14bInpaintingData = z.object({
  body: zSchemaWan22VaceFunA14bInpaintingInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWan22VaceFunA14bInpaintingResponse = zSchemaQueueStatus

export const zGetFalAiWan22VaceFunA14bInpaintingRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiWan22VaceFunA14bInpaintingRequestsByRequestIdResponse =
  zSchemaWan22VaceFunA14bInpaintingOutput

export const zGetFalAiWan22VaceFunA14bDepthRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWan22VaceFunA14bDepthRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWan22VaceFunA14bDepthRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWan22VaceFunA14bDepthRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWan22VaceFunA14bDepthData = z.object({
  body: zSchemaWan22VaceFunA14bDepthInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWan22VaceFunA14bDepthResponse = zSchemaQueueStatus

export const zGetFalAiWan22VaceFunA14bDepthRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWan22VaceFunA14bDepthRequestsByRequestIdResponse =
  zSchemaWan22VaceFunA14bDepthOutput

export const zGetFalAiWan22VaceFunA14bPoseRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWan22VaceFunA14bPoseRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWan22VaceFunA14bPoseRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWan22VaceFunA14bPoseRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWan22VaceFunA14bPoseData = z.object({
  body: zSchemaWan22VaceFunA14bPoseInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWan22VaceFunA14bPoseResponse = zSchemaQueueStatus

export const zGetFalAiWan22VaceFunA14bPoseRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWan22VaceFunA14bPoseRequestsByRequestIdResponse =
  zSchemaWan22VaceFunA14bPoseOutput

export const zGetFalAiHunyuanVideoFoleyRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiHunyuanVideoFoleyRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiHunyuanVideoFoleyRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanVideoFoleyRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiHunyuanVideoFoleyData = z.object({
  body: zSchemaHunyuanVideoFoleyInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiHunyuanVideoFoleyResponse = zSchemaQueueStatus

export const zGetFalAiHunyuanVideoFoleyRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanVideoFoleyRequestsByRequestIdResponse =
  zSchemaHunyuanVideoFoleyOutput

export const zGetFalAiSyncLipsyncV2ProRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiSyncLipsyncV2ProRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSyncLipsyncV2ProRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiSyncLipsyncV2ProRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSyncLipsyncV2ProData = z.object({
  body: zSchemaSyncLipsyncV2ProInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSyncLipsyncV2ProResponse = zSchemaQueueStatus

export const zGetFalAiSyncLipsyncV2ProRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSyncLipsyncV2ProRequestsByRequestIdResponse =
  zSchemaSyncLipsyncV2ProOutput

export const zGetFalAiWanFunControlRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanFunControlRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanFunControlRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanFunControlRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanFunControlData = z.object({
  body: zSchemaWanFunControlInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanFunControlResponse = zSchemaQueueStatus

export const zGetFalAiWanFunControlRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanFunControlRequestsByRequestIdResponse =
  zSchemaWanFunControlOutput

export const zGetBriaVideoIncreaseResolutionRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetBriaVideoIncreaseResolutionRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutBriaVideoIncreaseResolutionRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutBriaVideoIncreaseResolutionRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostBriaVideoIncreaseResolutionData = z.object({
  body: zSchemaVideoIncreaseResolutionInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostBriaVideoIncreaseResolutionResponse = zSchemaQueueStatus

export const zGetBriaVideoIncreaseResolutionRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetBriaVideoIncreaseResolutionRequestsByRequestIdResponse =
  zSchemaVideoIncreaseResolutionOutput

export const zGetFalAiInfinitalkRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiInfinitalkRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiInfinitalkRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiInfinitalkRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiInfinitalkData = z.object({
  body: zSchemaInfinitalkInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiInfinitalkResponse = zSchemaQueueStatus

export const zGetFalAiInfinitalkRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiInfinitalkRequestsByRequestIdResponse =
  zSchemaInfinitalkOutput

export const zGetMireloAiSfxV1VideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetMireloAiSfxV1VideoToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutMireloAiSfxV1VideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutMireloAiSfxV1VideoToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostMireloAiSfxV1VideoToVideoData = z.object({
  body: zSchemaSfxV1VideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostMireloAiSfxV1VideoToVideoResponse = zSchemaQueueStatus

export const zGetMireloAiSfxV1VideoToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetMireloAiSfxV1VideoToVideoRequestsByRequestIdResponse =
  zSchemaSfxV1VideoToVideoOutput

export const zGetMoonvalleyMareyPoseTransferRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetMoonvalleyMareyPoseTransferRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutMoonvalleyMareyPoseTransferRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutMoonvalleyMareyPoseTransferRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostMoonvalleyMareyPoseTransferData = z.object({
  body: zSchemaMareyPoseTransferInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostMoonvalleyMareyPoseTransferResponse = zSchemaQueueStatus

export const zGetMoonvalleyMareyPoseTransferRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetMoonvalleyMareyPoseTransferRequestsByRequestIdResponse =
  zSchemaMareyPoseTransferOutput

export const zGetMoonvalleyMareyMotionTransferRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetMoonvalleyMareyMotionTransferRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutMoonvalleyMareyMotionTransferRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutMoonvalleyMareyMotionTransferRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostMoonvalleyMareyMotionTransferData = z.object({
  body: zSchemaMareyMotionTransferInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostMoonvalleyMareyMotionTransferResponse = zSchemaQueueStatus

export const zGetMoonvalleyMareyMotionTransferRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetMoonvalleyMareyMotionTransferRequestsByRequestIdResponse =
  zSchemaMareyMotionTransferOutput

export const zGetFalAiFfmpegApiMergeVideosRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiFfmpegApiMergeVideosRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiFfmpegApiMergeVideosRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiFfmpegApiMergeVideosRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiFfmpegApiMergeVideosData = z.object({
  body: zSchemaFfmpegApiMergeVideosInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiFfmpegApiMergeVideosResponse = zSchemaQueueStatus

export const zGetFalAiFfmpegApiMergeVideosRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiFfmpegApiMergeVideosRequestsByRequestIdResponse =
  zSchemaFfmpegApiMergeVideosOutput

export const zGetFalAiWanV22A14bVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanV22A14bVideoToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanV22A14bVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV22A14bVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWanV22A14bVideoToVideoData = z.object({
  body: zSchemaWanV22A14bVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanV22A14bVideoToVideoResponse = zSchemaQueueStatus

export const zGetFalAiWanV22A14bVideoToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanV22A14bVideoToVideoRequestsByRequestIdResponse =
  zSchemaWanV22A14bVideoToVideoOutput

export const zGetFalAiLtxv13B098DistilledExtendRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxv13B098DistilledExtendRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxv13B098DistilledExtendRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxv13B098DistilledExtendRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtxv13B098DistilledExtendData = z.object({
  body: zSchemaLtxv13B098DistilledExtendInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxv13B098DistilledExtendResponse = zSchemaQueueStatus

export const zGetFalAiLtxv13B098DistilledExtendRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtxv13B098DistilledExtendRequestsByRequestIdResponse =
  zSchemaLtxv13B098DistilledExtendOutput

export const zGetFalAiRifeVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiRifeVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiRifeVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiRifeVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiRifeVideoData = z.object({
  body: zSchemaRifeVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiRifeVideoResponse = zSchemaQueueStatus

export const zGetFalAiRifeVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiRifeVideoRequestsByRequestIdResponse =
  zSchemaRifeVideoOutput

export const zGetFalAiFilmVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiFilmVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiFilmVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiFilmVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiFilmVideoData = z.object({
  body: zSchemaFilmVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiFilmVideoResponse = zSchemaQueueStatus

export const zGetFalAiFilmVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiFilmVideoRequestsByRequestIdResponse =
  zSchemaFilmVideoOutput

export const zGetFalAiLumaDreamMachineRay2FlashModifyRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLumaDreamMachineRay2FlashModifyRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLumaDreamMachineRay2FlashModifyRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLumaDreamMachineRay2FlashModifyRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLumaDreamMachineRay2FlashModifyData = z.object({
  body: zSchemaLumaDreamMachineRay2FlashModifyInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLumaDreamMachineRay2FlashModifyResponse =
  zSchemaQueueStatus

export const zGetFalAiLumaDreamMachineRay2FlashModifyRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLumaDreamMachineRay2FlashModifyRequestsByRequestIdResponse =
  zSchemaLumaDreamMachineRay2FlashModifyOutput

export const zGetFalAiLtxv13B098DistilledMulticonditioningRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxv13B098DistilledMulticonditioningRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxv13B098DistilledMulticonditioningRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxv13B098DistilledMulticonditioningRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtxv13B098DistilledMulticonditioningData = z.object({
  body: zSchemaLtxv13B098DistilledMulticonditioningInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxv13B098DistilledMulticonditioningResponse =
  zSchemaQueueStatus

export const zGetFalAiLtxv13B098DistilledMulticonditioningRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtxv13B098DistilledMulticonditioningRequestsByRequestIdResponse =
  zSchemaLtxv13B098DistilledMulticonditioningOutput

export const zGetFalAiPixverseSoundEffectsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseSoundEffectsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseSoundEffectsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseSoundEffectsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseSoundEffectsData = z.object({
  body: zSchemaPixverseSoundEffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseSoundEffectsResponse = zSchemaQueueStatus

export const zGetFalAiPixverseSoundEffectsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseSoundEffectsRequestsByRequestIdResponse =
  zSchemaPixverseSoundEffectsOutput

export const zGetFalAiThinksoundAudioRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiThinksoundAudioRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiThinksoundAudioRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiThinksoundAudioRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiThinksoundAudioData = z.object({
  body: zSchemaThinksoundAudioInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiThinksoundAudioResponse = zSchemaQueueStatus

export const zGetFalAiThinksoundAudioRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiThinksoundAudioRequestsByRequestIdResponse =
  zSchemaThinksoundAudioOutput

export const zGetFalAiThinksoundRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiThinksoundRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiThinksoundRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiThinksoundRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiThinksoundData = z.object({
  body: zSchemaThinksoundInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiThinksoundResponse = zSchemaQueueStatus

export const zGetFalAiThinksoundRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiThinksoundRequestsByRequestIdResponse =
  zSchemaThinksoundOutput

export const zGetFalAiPixverseExtendFastRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseExtendFastRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseExtendFastRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseExtendFastRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseExtendFastData = z.object({
  body: zSchemaPixverseExtendFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseExtendFastResponse = zSchemaQueueStatus

export const zGetFalAiPixverseExtendFastRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseExtendFastRequestsByRequestIdResponse =
  zSchemaPixverseExtendFastOutput

export const zGetFalAiPixverseExtendRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiPixverseExtendRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseExtendRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseExtendRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseExtendData = z.object({
  body: zSchemaPixverseExtendInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseExtendResponse = zSchemaQueueStatus

export const zGetFalAiPixverseExtendRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseExtendRequestsByRequestIdResponse =
  zSchemaPixverseExtendOutput

export const zGetFalAiPixverseLipsyncRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiPixverseLipsyncRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseLipsyncRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseLipsyncRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseLipsyncData = z.object({
  body: zSchemaPixverseLipsyncInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseLipsyncResponse = zSchemaQueueStatus

export const zGetFalAiPixverseLipsyncRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseLipsyncRequestsByRequestIdResponse =
  zSchemaPixverseLipsyncOutput

export const zGetFalAiLumaDreamMachineRay2ModifyRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLumaDreamMachineRay2ModifyRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLumaDreamMachineRay2ModifyRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLumaDreamMachineRay2ModifyRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLumaDreamMachineRay2ModifyData = z.object({
  body: zSchemaLumaDreamMachineRay2ModifyInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLumaDreamMachineRay2ModifyResponse = zSchemaQueueStatus

export const zGetFalAiLumaDreamMachineRay2ModifyRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLumaDreamMachineRay2ModifyRequestsByRequestIdResponse =
  zSchemaLumaDreamMachineRay2ModifyOutput

export const zGetFalAiWanVace14bReframeRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiWanVace14bReframeRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanVace14bReframeRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVace14bReframeRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanVace14bReframeData = z.object({
  body: zSchemaWanVace14bReframeInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanVace14bReframeResponse = zSchemaQueueStatus

export const zGetFalAiWanVace14bReframeRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanVace14bReframeRequestsByRequestIdResponse =
  zSchemaWanVace14bReframeOutput

export const zGetFalAiWanVace14bOutpaintingRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanVace14bOutpaintingRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanVace14bOutpaintingRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVace14bOutpaintingRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanVace14bOutpaintingData = z.object({
  body: zSchemaWanVace14bOutpaintingInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanVace14bOutpaintingResponse = zSchemaQueueStatus

export const zGetFalAiWanVace14bOutpaintingRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanVace14bOutpaintingRequestsByRequestIdResponse =
  zSchemaWanVace14bOutpaintingOutput

export const zGetFalAiWanVace14bInpaintingRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanVace14bInpaintingRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanVace14bInpaintingRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVace14bInpaintingRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanVace14bInpaintingData = z.object({
  body: zSchemaWanVace14bInpaintingInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanVace14bInpaintingResponse = zSchemaQueueStatus

export const zGetFalAiWanVace14bInpaintingRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanVace14bInpaintingRequestsByRequestIdResponse =
  zSchemaWanVace14bInpaintingOutput

export const zGetFalAiWanVace14bPoseRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanVace14bPoseRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanVace14bPoseRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVace14bPoseRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanVace14bPoseData = z.object({
  body: zSchemaWanVace14bPoseInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanVace14bPoseResponse = zSchemaQueueStatus

export const zGetFalAiWanVace14bPoseRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanVace14bPoseRequestsByRequestIdResponse =
  zSchemaWanVace14bPoseOutput

export const zGetFalAiWanVace14bDepthRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanVace14bDepthRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanVace14bDepthRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVace14bDepthRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanVace14bDepthData = z.object({
  body: zSchemaWanVace14bDepthInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanVace14bDepthResponse = zSchemaQueueStatus

export const zGetFalAiWanVace14bDepthRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanVace14bDepthRequestsByRequestIdResponse =
  zSchemaWanVace14bDepthOutput

export const zGetFalAiDwposeVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiDwposeVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiDwposeVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiDwposeVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiDwposeVideoData = z.object({
  body: zSchemaDwposeVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiDwposeVideoResponse = zSchemaQueueStatus

export const zGetFalAiDwposeVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiDwposeVideoRequestsByRequestIdResponse =
  zSchemaDwposeVideoOutput

export const zGetFalAiFfmpegApiMergeAudioVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiFfmpegApiMergeAudioVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiFfmpegApiMergeAudioVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiFfmpegApiMergeAudioVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiFfmpegApiMergeAudioVideoData = z.object({
  body: zSchemaFfmpegApiMergeAudioVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiFfmpegApiMergeAudioVideoResponse = zSchemaQueueStatus

export const zGetFalAiFfmpegApiMergeAudioVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiFfmpegApiMergeAudioVideoRequestsByRequestIdResponse =
  zSchemaFfmpegApiMergeAudioVideoOutput

export const zGetFalAiWanVace13bRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanVace13bRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanVace13bRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVace13bRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanVace13bData = z.object({
  body: zSchemaWanVace13bInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanVace13bResponse = zSchemaQueueStatus

export const zGetFalAiWanVace13bRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanVace13bRequestsByRequestIdResponse =
  zSchemaWanVace13bOutput

export const zGetFalAiLumaDreamMachineRay2FlashReframeRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLumaDreamMachineRay2FlashReframeRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLumaDreamMachineRay2FlashReframeRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLumaDreamMachineRay2FlashReframeRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLumaDreamMachineRay2FlashReframeData = z.object({
  body: zSchemaLumaDreamMachineRay2FlashReframeInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLumaDreamMachineRay2FlashReframeResponse =
  zSchemaQueueStatus

export const zGetFalAiLumaDreamMachineRay2FlashReframeRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLumaDreamMachineRay2FlashReframeRequestsByRequestIdResponse =
  zSchemaLumaDreamMachineRay2FlashReframeOutput

export const zGetFalAiLumaDreamMachineRay2ReframeRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLumaDreamMachineRay2ReframeRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLumaDreamMachineRay2ReframeRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLumaDreamMachineRay2ReframeRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLumaDreamMachineRay2ReframeData = z.object({
  body: zSchemaLumaDreamMachineRay2ReframeInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLumaDreamMachineRay2ReframeResponse = zSchemaQueueStatus

export const zGetFalAiLumaDreamMachineRay2ReframeRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLumaDreamMachineRay2ReframeRequestsByRequestIdResponse =
  zSchemaLumaDreamMachineRay2ReframeOutput

export const zGetVeedLipsyncRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetVeedLipsyncRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutVeedLipsyncRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutVeedLipsyncRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostVeedLipsyncData = z.object({
  body: zSchemaLipsyncInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostVeedLipsyncResponse = zSchemaQueueStatus

export const zGetVeedLipsyncRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetVeedLipsyncRequestsByRequestIdResponse = zSchemaLipsyncOutput

export const zGetFalAiWanVace14bRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanVace14bRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanVace14bRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVace14bRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanVace14bData = z.object({
  body: zSchemaWanVace14bInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanVace14bResponse = zSchemaQueueStatus

export const zGetFalAiWanVace14bRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanVace14bRequestsByRequestIdResponse =
  zSchemaWanVace14bOutput

export const zGetFalAiLtxVideo13bDistilledExtendRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxVideo13bDistilledExtendRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxVideo13bDistilledExtendRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideo13bDistilledExtendRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtxVideo13bDistilledExtendData = z.object({
  body: zSchemaLtxVideo13bDistilledExtendInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxVideo13bDistilledExtendResponse = zSchemaQueueStatus

export const zGetFalAiLtxVideo13bDistilledExtendRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideo13bDistilledExtendRequestsByRequestIdResponse =
  zSchemaLtxVideo13bDistilledExtendOutput

export const zGetFalAiLtxVideo13bDistilledMulticonditioningRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxVideo13bDistilledMulticonditioningRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxVideo13bDistilledMulticonditioningRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideo13bDistilledMulticonditioningRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtxVideo13bDistilledMulticonditioningData = z.object({
  body: zSchemaLtxVideo13bDistilledMulticonditioningInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxVideo13bDistilledMulticonditioningResponse =
  zSchemaQueueStatus

export const zGetFalAiLtxVideo13bDistilledMulticonditioningRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideo13bDistilledMulticonditioningRequestsByRequestIdResponse =
  zSchemaLtxVideo13bDistilledMulticonditioningOutput

export const zGetFalAiLtxVideo13bDevMulticonditioningRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxVideo13bDevMulticonditioningRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxVideo13bDevMulticonditioningRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideo13bDevMulticonditioningRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtxVideo13bDevMulticonditioningData = z.object({
  body: zSchemaLtxVideo13bDevMulticonditioningInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxVideo13bDevMulticonditioningResponse =
  zSchemaQueueStatus

export const zGetFalAiLtxVideo13bDevMulticonditioningRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideo13bDevMulticonditioningRequestsByRequestIdResponse =
  zSchemaLtxVideo13bDevMulticonditioningOutput

export const zGetFalAiLtxVideo13bDevExtendRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxVideo13bDevExtendRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxVideo13bDevExtendRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideo13bDevExtendRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtxVideo13bDevExtendData = z.object({
  body: zSchemaLtxVideo13bDevExtendInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxVideo13bDevExtendResponse = zSchemaQueueStatus

export const zGetFalAiLtxVideo13bDevExtendRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideo13bDevExtendRequestsByRequestIdResponse =
  zSchemaLtxVideo13bDevExtendOutput

export const zGetFalAiLtxVideoLoraMulticonditioningRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxVideoLoraMulticonditioningRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxVideoLoraMulticonditioningRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideoLoraMulticonditioningRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtxVideoLoraMulticonditioningData = z.object({
  body: zSchemaLtxVideoLoraMulticonditioningInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxVideoLoraMulticonditioningResponse =
  zSchemaQueueStatus

export const zGetFalAiLtxVideoLoraMulticonditioningRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideoLoraMulticonditioningRequestsByRequestIdResponse =
  zSchemaLtxVideoLoraMulticonditioningOutput

export const zGetFalAiMagiExtendVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiMagiExtendVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMagiExtendVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiMagiExtendVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiMagiExtendVideoData = z.object({
  body: zSchemaMagiExtendVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMagiExtendVideoResponse = zSchemaQueueStatus

export const zGetFalAiMagiExtendVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiMagiExtendVideoRequestsByRequestIdResponse =
  zSchemaMagiExtendVideoOutput

export const zGetFalAiMagiDistilledExtendVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMagiDistilledExtendVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMagiDistilledExtendVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMagiDistilledExtendVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMagiDistilledExtendVideoData = z.object({
  body: zSchemaMagiDistilledExtendVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMagiDistilledExtendVideoResponse = zSchemaQueueStatus

export const zGetFalAiMagiDistilledExtendVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMagiDistilledExtendVideoRequestsByRequestIdResponse =
  zSchemaMagiDistilledExtendVideoOutput

export const zGetFalAiWanVaceRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanVaceRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanVaceRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVaceRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanVaceData = z.object({
  body: zSchemaWanVaceInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanVaceResponse = zSchemaQueueStatus

export const zGetFalAiWanVaceRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanVaceRequestsByRequestIdResponse = zSchemaWanVaceOutput

export const zGetCassetteaiVideoSoundEffectsGeneratorRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetCassetteaiVideoSoundEffectsGeneratorRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutCassetteaiVideoSoundEffectsGeneratorRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutCassetteaiVideoSoundEffectsGeneratorRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostCassetteaiVideoSoundEffectsGeneratorData = z.object({
  body: zSchemaVideoSoundEffectsGeneratorInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostCassetteaiVideoSoundEffectsGeneratorResponse =
  zSchemaQueueStatus

export const zGetCassetteaiVideoSoundEffectsGeneratorRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetCassetteaiVideoSoundEffectsGeneratorRequestsByRequestIdResponse =
  zSchemaVideoSoundEffectsGeneratorOutput

export const zGetFalAiSyncLipsyncV2RequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiSyncLipsyncV2RequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSyncLipsyncV2RequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiSyncLipsyncV2RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSyncLipsyncV2Data = z.object({
  body: zSchemaSyncLipsyncV2Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSyncLipsyncV2Response = zSchemaQueueStatus

export const zGetFalAiSyncLipsyncV2RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSyncLipsyncV2RequestsByRequestIdResponse =
  zSchemaSyncLipsyncV2Output

export const zGetFalAiLatentsyncRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiLatentsyncRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLatentsyncRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiLatentsyncRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLatentsyncData = z.object({
  body: zSchemaLatentsyncInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLatentsyncResponse = zSchemaQueueStatus

export const zGetFalAiLatentsyncRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLatentsyncRequestsByRequestIdResponse =
  zSchemaLatentsyncOutput

export const zGetFalAiPikaV2PikadditionsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPikaV2PikadditionsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPikaV2PikadditionsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV2PikadditionsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPikaV2PikadditionsData = z.object({
  body: zSchemaPikaV2PikadditionsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPikaV2PikadditionsResponse = zSchemaQueueStatus

export const zGetFalAiPikaV2PikadditionsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPikaV2PikadditionsRequestsByRequestIdResponse =
  zSchemaPikaV2PikadditionsOutput

export const zGetFalAiLtxVideoV095MulticonditioningRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxVideoV095MulticonditioningRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxVideoV095MulticonditioningRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideoV095MulticonditioningRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtxVideoV095MulticonditioningData = z.object({
  body: zSchemaLtxVideoV095MulticonditioningInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxVideoV095MulticonditioningResponse =
  zSchemaQueueStatus

export const zGetFalAiLtxVideoV095MulticonditioningRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideoV095MulticonditioningRequestsByRequestIdResponse =
  zSchemaLtxVideoV095MulticonditioningOutput

export const zGetFalAiLtxVideoV095ExtendRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxVideoV095ExtendRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxVideoV095ExtendRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideoV095ExtendRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtxVideoV095ExtendData = z.object({
  body: zSchemaLtxVideoV095ExtendInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxVideoV095ExtendResponse = zSchemaQueueStatus

export const zGetFalAiLtxVideoV095ExtendRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideoV095ExtendRequestsByRequestIdResponse =
  zSchemaLtxVideoV095ExtendOutput

export const zGetFalAiTopazUpscaleVideoRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiTopazUpscaleVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiTopazUpscaleVideoRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiTopazUpscaleVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiTopazUpscaleVideoData = z.object({
  body: zSchemaTopazUpscaleVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiTopazUpscaleVideoResponse = zSchemaQueueStatus

export const zGetFalAiTopazUpscaleVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiTopazUpscaleVideoRequestsByRequestIdResponse =
  zSchemaTopazUpscaleVideoOutput

export const zGetFalAiBenV2VideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiBenV2VideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiBenV2VideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiBenV2VideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiBenV2VideoData = z.object({
  body: zSchemaBenV2VideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiBenV2VideoResponse = zSchemaQueueStatus

export const zGetFalAiBenV2VideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiBenV2VideoRequestsByRequestIdResponse =
  zSchemaBenV2VideoOutput

export const zGetFalAiHunyuanVideoVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiHunyuanVideoVideoToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiHunyuanVideoVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanVideoVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiHunyuanVideoVideoToVideoData = z.object({
  body: zSchemaHunyuanVideoVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiHunyuanVideoVideoToVideoResponse = zSchemaQueueStatus

export const zGetFalAiHunyuanVideoVideoToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanVideoVideoToVideoRequestsByRequestIdResponse =
  zSchemaHunyuanVideoVideoToVideoOutput

export const zGetFalAiHunyuanVideoLoraVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiHunyuanVideoLoraVideoToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiHunyuanVideoLoraVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanVideoLoraVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiHunyuanVideoLoraVideoToVideoData = z.object({
  body: zSchemaHunyuanVideoLoraVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiHunyuanVideoLoraVideoToVideoResponse = zSchemaQueueStatus

export const zGetFalAiHunyuanVideoLoraVideoToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanVideoLoraVideoToVideoRequestsByRequestIdResponse =
  zSchemaHunyuanVideoLoraVideoToVideoOutput

export const zGetFalAiFfmpegApiComposeRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiFfmpegApiComposeRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiFfmpegApiComposeRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiFfmpegApiComposeRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiFfmpegApiComposeData = z.object({
  body: zSchemaFfmpegApiComposeInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiFfmpegApiComposeResponse = zSchemaQueueStatus

export const zGetFalAiFfmpegApiComposeRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiFfmpegApiComposeRequestsByRequestIdResponse =
  zSchemaFfmpegApiComposeOutput

export const zGetFalAiSyncLipsyncRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiSyncLipsyncRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSyncLipsyncRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiSyncLipsyncRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSyncLipsyncData = z.object({
  body: zSchemaSyncLipsyncInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSyncLipsyncResponse = zSchemaQueueStatus

export const zGetFalAiSyncLipsyncRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSyncLipsyncRequestsByRequestIdResponse =
  zSchemaSyncLipsyncOutput

export const zGetFalAiAutoCaptionRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiAutoCaptionRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiAutoCaptionRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiAutoCaptionRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiAutoCaptionData = z.object({
  body: zSchemaAutoCaptionInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiAutoCaptionResponse = zSchemaQueueStatus

export const zGetFalAiAutoCaptionRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiAutoCaptionRequestsByRequestIdResponse =
  zSchemaAutoCaptionOutput

export const zGetFalAiDubbingRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiDubbingRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiDubbingRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiDubbingRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiDubbingData = z.object({
  body: zSchemaDubbingInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiDubbingResponse = zSchemaQueueStatus

export const zGetFalAiDubbingRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiDubbingRequestsByRequestIdResponse = zSchemaDubbingOutput

export const zGetFalAiVideoUpscalerRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiVideoUpscalerRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVideoUpscalerRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiVideoUpscalerRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiVideoUpscalerData = z.object({
  body: zSchemaVideoUpscalerInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVideoUpscalerResponse = zSchemaQueueStatus

export const zGetFalAiVideoUpscalerRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiVideoUpscalerRequestsByRequestIdResponse =
  zSchemaVideoUpscalerOutput

export const zGetFalAiCogvideox5bVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiCogvideox5bVideoToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiCogvideox5bVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiCogvideox5bVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiCogvideox5bVideoToVideoData = z.object({
  body: zSchemaCogvideox5bVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiCogvideox5bVideoToVideoResponse = zSchemaQueueStatus

export const zGetFalAiCogvideox5bVideoToVideoRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiCogvideox5bVideoToVideoRequestsByRequestIdResponse =
  zSchemaCogvideox5bVideoToVideoOutput

export const zGetFalAiControlnextRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiControlnextRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiControlnextRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiControlnextRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiControlnextData = z.object({
  body: zSchemaControlnextInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiControlnextResponse = zSchemaQueueStatus

export const zGetFalAiControlnextRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiControlnextRequestsByRequestIdResponse =
  zSchemaControlnextOutput

export const zGetFalAiSam2VideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiSam2VideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSam2VideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiSam2VideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSam2VideoData = z.object({
  body: zSchemaSam2VideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSam2VideoResponse = zSchemaQueueStatus

export const zGetFalAiSam2VideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSam2VideoRequestsByRequestIdResponse =
  zSchemaSam2VideoOutput

export const zGetFalAiAmtInterpolationRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiAmtInterpolationRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiAmtInterpolationRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiAmtInterpolationRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiAmtInterpolationData = z.object({
  body: zSchemaAmtInterpolationInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiAmtInterpolationResponse = zSchemaQueueStatus

export const zGetFalAiAmtInterpolationRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiAmtInterpolationRequestsByRequestIdResponse =
  zSchemaAmtInterpolationOutput

export const zGetFalAiFastAnimatediffTurboVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiFastAnimatediffTurboVideoToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiFastAnimatediffTurboVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiFastAnimatediffTurboVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiFastAnimatediffTurboVideoToVideoData = z.object({
  body: zSchemaFastAnimatediffTurboVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiFastAnimatediffTurboVideoToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiFastAnimatediffTurboVideoToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiFastAnimatediffTurboVideoToVideoRequestsByRequestIdResponse =
  zSchemaFastAnimatediffTurboVideoToVideoOutput

export const zGetFalAiFastAnimatediffVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiFastAnimatediffVideoToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiFastAnimatediffVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiFastAnimatediffVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiFastAnimatediffVideoToVideoData = z.object({
  body: zSchemaFastAnimatediffVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiFastAnimatediffVideoToVideoResponse = zSchemaQueueStatus

export const zGetFalAiFastAnimatediffVideoToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiFastAnimatediffVideoToVideoRequestsByRequestIdResponse =
  zSchemaFastAnimatediffVideoToVideoOutput
