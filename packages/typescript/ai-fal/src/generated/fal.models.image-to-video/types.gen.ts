// This file is auto-generated by @hey-api/openapi-ts

export type ClientOptions = {
  baseUrl: 'https://queue.fal.run' | (string & {})
}

export type SchemaQueueStatus = {
  status: 'IN_QUEUE' | 'IN_PROGRESS' | 'COMPLETED'
  /**
   * The request id.
   */
  request_id: string
  /**
   * The response url.
   */
  response_url?: string
  /**
   * The status url.
   */
  status_url?: string
  /**
   * The cancel url.
   */
  cancel_url?: string
  /**
   * The logs.
   */
  logs?: {
    [key: string]: unknown
  }
  /**
   * The metrics.
   */
  metrics?: {
    [key: string]: unknown
  }
  /**
   * The queue position.
   */
  queue_position?: number
}

/**
 * BaseInput
 */
export type SchemaWanEffectsInput = {
  /**
   * Effect Type
   *
   * The type of effect to apply to the video.
   */
  effect_type?:
    | 'squish'
    | 'muscle'
    | 'inflate'
    | 'crush'
    | 'rotate'
    | 'gun-shooting'
    | 'deflate'
    | 'cakeify'
    | 'hulk'
    | 'baby'
    | 'bride'
    | 'classy'
    | 'puppy'
    | 'snow-white'
    | 'disney-princess'
    | 'mona-lisa'
    | 'painting'
    | 'pirate-captain'
    | 'princess'
    | 'jungle'
    | 'samurai'
    | 'vip'
    | 'warrior'
    | 'zen'
    | 'assassin'
    | 'timelapse'
    | 'tsunami'
    | 'fire'
    | 'zoom-call'
    | 'doom-fps'
    | 'fus-ro-dah'
    | 'hug-jesus'
    | 'robot-face-reveal'
    | 'super-saiyan'
    | 'jumpscare'
    | 'laughing'
    | 'cartoon-jaw-drop'
    | 'crying'
    | 'kissing'
    | 'angry-face'
    | 'selfie-younger-self'
    | 'animeify'
    | 'blast'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the output video.
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Subject
   *
   * The subject to insert into the predefined prompt template for the selected effect.
   */
  subject: string
  /**
   * Lora Scale
   *
   * The scale of the LoRA weight. Used to adjust effect intensity.
   */
  lora_scale?: number
  /**
   * Image URL
   *
   * URL of the input image.
   */
  image_url: string
  /**
   * Turbo Mode
   *
   * Whether to use turbo mode. If True, the video will be generated faster but with lower quality.
   */
  turbo_mode?: boolean
  /**
   * Frames Per Second
   *
   * Frames per second of the generated video.
   */
  frames_per_second?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Num Frames
   *
   * Number of frames to generate.
   */
  num_frames?: number
}

/**
 * WanEffectsOutput
 */
export type SchemaWanEffectsOutput = {
  /**
   * Seed
   */
  seed: number
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * File
 */
export type SchemaFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * WanProI2VRequest
 */
export type SchemaWanProImageToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video
   */
  prompt: string
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number | unknown
  /**
   * Image Url
   *
   * The URL of the image to generate the video from
   */
  image_url: string
}

/**
 * WanProI2VResponse
 */
export type SchemaWanProImageToVideoOutput = {
  video: SchemaFile
}

/**
 * ImageToVideoInput
 */
export type SchemaVeo2ImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt describing how the image should be animated
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5s' | '6s' | '7s' | '8s'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: 'auto' | 'auto_prefer_portrait' | '16:9' | '9:16'
  /**
   * Image Url
   *
   * URL of the input image to animate. Should be 720p or higher resolution.
   */
  image_url: string
}

/**
 * ImageToVideoOutput
 */
export type SchemaVeo2ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * ProImageToVideoRequest
 */
export type SchemaKlingVideoV16ProImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video frame
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Image Url
   */
  image_url: string
  /**
   * Tail Image Url
   *
   * URL of the image to be used for the end of the video
   */
  tail_image_url?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * I2VOutput
 */
export type SchemaKlingVideoV16ProImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * ImageToVideoRequest
 */
export type SchemaMinimaxVideo01ImageToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Prompt
   */
  prompt: string
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * VideoOutput
 */
export type SchemaMinimaxVideo01ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * ProImageToVideoHailuo23Input
 */
export type SchemaMinimaxHailuo23ProImageToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Prompt
   *
   * Text prompt for video generation
   */
  prompt: string
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * ProImageToVideoHailuo23Output
 */
export type SchemaMinimaxHailuo23ProImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * ImageToVideoInput
 *
 * Input for image-to-video generation
 */
export type SchemaWan25PreviewImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt describing the desired video motion. Max 800 characters.
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution. Valid values: 480p, 720p, 1080p
   */
  resolution?: '480p' | '720p' | '1080p'
  /**
   * Duration
   *
   * Duration of the generated video in seconds. Choose between 5 or 10 seconds.
   */
  duration?: '5' | '10'
  /**
   * Image URL
   *
   * URL of the image to use as the first frame. Must be publicly accessible or base64 data URI.
   *
   * Max file size: 25.0MB, Min width: 360px, Min height: 360px, Max width: 2000px, Max height: 2000px, Timeout: 20.0s
   */
  image_url: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Audio Url
   *
   *
   * URL of the audio to use as the background music. Must be publicly accessible.
   * Limit handling: If the audio duration exceeds the duration value (5 or 10 seconds),
   * the audio is truncated to the first 5 or 10 seconds, and the rest is discarded. If
   * the audio is shorter than the video, the remaining part of the video will be silent.
   * For example, if the audio is 3 seconds long and the video duration is 5 seconds, the
   * first 3 seconds of the output video will have sound, and the last 2 seconds will be silent.
   * - Format: WAV, MP3.
   * - Duration: 3 to 30 s.
   * - File size: Up to 15 MB.
   *
   */
  audio_url?: string
  /**
   * Negative Prompt
   *
   * Negative prompt to describe content to avoid. Max 500 characters.
   */
  negative_prompt?: string
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt rewriting using LLM.
   */
  enable_prompt_expansion?: boolean
}

/**
 * VideoOutput
 *
 * Base output for video generation
 */
export type SchemaWan25PreviewImageToVideoOutput = {
  /**
   * Actual Prompt
   *
   * The actual prompt used if prompt rewriting was enabled
   */
  actual_prompt?: string
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * The generated video file
   */
  video: SchemaVideoFile
}

/**
 * VideoFile
 */
export type SchemaVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number
  /**
   * Height
   *
   * The height of the video
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number
  /**
   * Width
   *
   * The width of the video
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoV25ProRequest
 */
export type SchemaKlingVideoV25TurboProImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Image Url
   *
   * URL of the image to be used for the video
   */
  image_url: string
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Tail Image Url
   *
   * URL of the image to be used for the end of the video
   */
  tail_image_url?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * ImageToVideoV25ProOutput
 */
export type SchemaKlingVideoV25TurboProImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * StandardImageToVideoHailuo02Input
 */
export type SchemaMinimaxHailuo02StandardImageToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Duration
   *
   * The duration of the video in seconds. 10 seconds videos are not supported for 1080p resolution.
   */
  duration?: '6' | '10'
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '512P' | '768P'
  /**
   * Prompt
   */
  prompt: string
  /**
   * End Image Url
   *
   * Optional URL of the image to use as the last frame of the video
   */
  end_image_url?: string
  /**
   * Image Url
   */
  image_url: string
}

/**
 * ImageToVideoHailuo02Output
 */
export type SchemaMinimaxHailuo02StandardImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * SeedanceProImageToVideoInput
 */
export type SchemaBytedanceSeedanceV1ProImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt used to generate the video
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality
   */
  resolution?: '480p' | '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '21:9' | '16:9' | '4:3' | '1:1' | '3:4' | '9:16' | 'auto'
  /**
   * Duration
   *
   * Duration of the video in seconds
   */
  duration?: '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9' | '10' | '11' | '12'
  /**
   * Image Url
   *
   * The URL of the image used to generate video
   */
  image_url: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Camera Fixed
   *
   * Whether to fix the camera position
   */
  camera_fixed?: boolean
  /**
   * End Image Url
   *
   * The URL of the image the video ends with. Defaults to None.
   */
  end_image_url?: string
  /**
   * Seed
   *
   * Random seed to control video generation. Use -1 for random.
   */
  seed?: number
}

/**
 * SeedanceProI2VVideoOutput
 */
export type SchemaBytedanceSeedanceV1ProImageToVideoOutput = {
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * Generated video file
   */
  video: SchemaFile
}

/**
 * ImageToVideoV21MasterRequest
 */
export type SchemaKlingVideoV21MasterImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Image Url
   *
   * URL of the image to be used for the video
   */
  image_url: string
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * ImageToVideoV21MasterOutput
 */
export type SchemaKlingVideoV21MasterImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * ImageToVideoV21StandardRequest
 */
export type SchemaKlingVideoV21StandardImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Image Url
   *
   * URL of the image to be used for the video
   */
  image_url: string
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * ImageToVideoV21StandardOutput
 */
export type SchemaKlingVideoV21StandardImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * ImageToVideoRequestV4
 */
export type SchemaPixverseV45ImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Duration
   *
   * The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds
   */
  duration?: '5' | '8'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Camera Movement
   *
   * The type of camera movement to apply to the video
   */
  camera_movement?:
    | 'horizontal_left'
    | 'horizontal_right'
    | 'vertical_up'
    | 'vertical_down'
    | 'zoom_in'
    | 'zoom_out'
    | 'crane_up'
    | 'quickly_zoom_in'
    | 'quickly_zoom_out'
    | 'smooth_zoom_in'
    | 'camera_rotation'
    | 'robo_arm'
    | 'super_dolly_out'
    | 'whip_pan'
    | 'hitchcock'
    | 'left_follow'
    | 'right_follow'
    | 'pan_left'
    | 'pan_right'
    | 'fix_bg'
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * I2VOutputV4
 */
export type SchemaPixverseV45ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * ImageToVideoV2MasterRequest
 */
export type SchemaKlingVideoV2MasterImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Image Url
   *
   * URL of the image to be used for the video
   */
  image_url: string
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * ImageToVideoV2MasterOutput
 */
export type SchemaKlingVideoV2MasterImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * WanI2VRequest
 */
export type SchemaWanI2vInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Shift
   *
   * Shift parameter for video generation.
   */
  shift?: number
  /**
   * Acceleration
   *
   * Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Frames Per Second
   *
   * Frames per second of the generated video. Must be between 5 to 24.
   */
  frames_per_second?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Frames
   *
   * Number of frames to generate. Must be between 81 to 100 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.
   */
  num_frames?: number
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16' | '1:1'
  /**
   * Resolution
   *
   * Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.
   */
  resolution?: '480p' | '720p'
  /**
   * Image Url
   *
   * URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Guide Scale
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guide_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
}

/**
 * WanI2VResponse
 */
export type SchemaWanI2vOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * TransitionRequestV5_6
 */
export type SchemaPixverseV56TransitionInput = {
  /**
   * First Image Url
   *
   * URL of the image to use as the first frame
   */
  first_image_url: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Thinking Type
   *
   * Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision
   */
  thinking_type?: 'enabled' | 'disabled' | 'auto'
  /**
   * Prompt
   *
   * The prompt for the transition
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds. 1080p videos are limited to 5 or 8 seconds
   */
  duration?: '5' | '8' | '10'
  /**
   * Generate Audio Switch
   *
   * Enable audio generation (BGM, SFX, dialogue)
   */
  generate_audio_switch?: boolean
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * End Image Url
   *
   * URL of the image to use as the last frame
   */
  end_image_url?: string
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * TransitionOutputV5_5
 */
export type SchemaPixverseV56TransitionOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * ImageToVideoRequestV5_6
 */
export type SchemaPixverseV56ImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Duration
   *
   * The duration of the generated video in seconds. 1080p videos are limited to 5 or 8 seconds
   */
  duration?: '5' | '8' | '10'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Thinking Type
   *
   * Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision
   */
  thinking_type?: 'enabled' | 'disabled' | 'auto'
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
  /**
   * Generate Audio Switch
   *
   * Enable audio generation (BGM, SFX, dialogue)
   */
  generate_audio_switch?: boolean
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * I2VOutputV5_5
 */
export type SchemaPixverseV56ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * Q2ProReferenceToVideoRequest
 */
export type SchemaViduQ2ReferenceToVideoProInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 2000 characters
   */
  prompt: string
  /**
   * Resolution
   *
   * Output video resolution
   */
  resolution?: '540p' | '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the output video (e.g., auto, 16:9, 9:16, 1:1, or any W:H)
   */
  aspect_ratio?: string
  /**
   * Duration
   *
   * Duration of the video in seconds (0 for automatic duration)
   */
  duration?: number
  /**
   * Reference Video Urls
   *
   * URLs of the reference videos for video editing or motion reference. Supports up to 2 videos.
   */
  reference_video_urls?: Array<string>
  /**
   * Bgm
   *
   * Whether to add background music to the generated video
   */
  bgm?: boolean
  /**
   * Reference Image Urls
   *
   * URLs of the reference images for subject appearance. If videos are provided, up to 4 images are allowed; otherwise up to 7 images.
   */
  reference_image_urls?: Array<string>
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Movement Amplitude
   *
   * The movement amplitude of objects in the frame
   */
  movement_amplitude?: 'auto' | 'small' | 'medium' | 'large'
}

/**
 * Q2ProReferenceToVideoOutput
 */
export type SchemaViduQ2ReferenceToVideoProOutput = {
  /**
   * Video
   *
   * The generated video with video/image references using the Q2 Pro model
   */
  video: SchemaFile
}

/**
 * ImageToVideoInput
 *
 * Input for Wan 2.6 image-to-video generation
 */
export type SchemaV26ImageToVideoFlashInput = {
  /**
   * Prompt
   *
   * The text prompt describing the desired video motion. Max 800 characters.
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution. Valid values: 720p, 1080p
   */
  resolution?: '720p' | '1080p'
  /**
   * Duration
   *
   * Duration of the generated video in seconds. Choose between 5, 10 or 15 seconds.
   */
  duration?: '5' | '10' | '15'
  /**
   * Audio Url
   *
   *
   * URL of the audio to use as the background music. Must be publicly accessible.
   * Limit handling: If the audio duration exceeds the duration value (5, 10, or 15 seconds),
   * the audio is truncated to the first N seconds, and the rest is discarded. If
   * the audio is shorter than the video, the remaining part of the video will be silent.
   * For example, if the audio is 3 seconds long and the video duration is 5 seconds, the
   * first 3 seconds of the output video will have sound, and the last 2 seconds will be silent.
   * - Format: WAV, MP3.
   * - Duration: 3 to 30 s.
   * - File size: Up to 15 MB.
   *
   */
  audio_url?: string
  /**
   * Image URL
   *
   * URL of the image to use as the first frame. Must be publicly accessible or base64 data URI. Image dimensions must be between 240 and 7680.
   */
  image_url: string
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt rewriting using LLM.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Multi Shots
   *
   * When true, enables intelligent multi-shot segmentation. Only active when enable_prompt_expansion is True. Set to false for single-shot generation.
   */
  multi_shots?: boolean
  /**
   * Negative Prompt
   *
   * Negative prompt to describe content to avoid. Max 500 characters.
   */
  negative_prompt?: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
}

/**
 * ImageToVideoOutput
 *
 * Output for image-to-video generation
 */
export type SchemaV26ImageToVideoFlashOutput = {
  /**
   * Actual Prompt
   *
   * The actual prompt used if prompt rewriting was enabled
   */
  actual_prompt?: string
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * The generated video file
   */
  video: SchemaVideoFile
}

/**
 * LTX2LoRADistilledImageToVideoInput
 */
export type SchemaLtx219bDistilledImageToVideoLoraInput = {
  /**
   * Use Multi-Scale
   *
   * Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.
   */
  use_multiscale?: boolean
  /**
   * Prompt
   *
   * The prompt used for the generation.
   */
  prompt: string
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: 'none' | 'regular' | 'high' | 'full'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * FPS
   *
   * The frames per second of the generated video.
   */
  fps?: number
  /**
   * LoRAs
   *
   * The LoRAs to use for the generation.
   */
  loras: Array<SchemaLoRaInput>
  /**
   * Camera LoRA
   *
   * The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.
   */
  camera_lora?:
    | 'dolly_in'
    | 'dolly_out'
    | 'dolly_left'
    | 'dolly_right'
    | 'jib_up'
    | 'jib_down'
    | 'static'
    | 'none'
  /**
   * Video Size
   *
   * The size of the generated video.
   */
  video_size?:
    | SchemaImageSize
    | 'auto'
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Image Strength
   *
   * The strength of the image to use for the video generation.
   */
  image_strength?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to generate the video from.
   */
  negative_prompt?: string
  /**
   * Camera LoRA Scale
   *
   * The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.
   */
  camera_lora_scale?: number
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * Image URL
   *
   * The URL of the image to generate the video from.
   */
  image_url: string
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number | unknown
}

/**
 * LTX2ImageToVideoOutput
 */
export type SchemaLtx219bDistilledImageToVideoLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for the generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for the random number generator.
   */
  seed: number
  video: SchemaVideoFile
}

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export type SchemaLoRaInput = {
  /**
   * Path
   *
   * URL, HuggingFace repo ID (owner/repo) to lora weights.
   */
  path: string
  /**
   * Scale
   *
   * Scale factor for LoRA application (0.0 to 4.0).
   */
  scale?: number
  /**
   * Weight Name
   *
   * Name of the LoRA weight. Only used if `path` is a HuggingFace repository, and is only required when the repository contains multiple LoRA weights.
   */
  weight_name?: string | unknown
}

/**
 * ImageSize
 */
export type SchemaImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * LTX2DistilledImageToVideoInput
 */
export type SchemaLtx219bDistilledImageToVideoInput = {
  /**
   * Use Multi-Scale
   *
   * Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.
   */
  use_multiscale?: boolean
  /**
   * Prompt
   *
   * The prompt used for the generation.
   */
  prompt: string
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: 'none' | 'regular' | 'high' | 'full'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * FPS
   *
   * The frames per second of the generated video.
   */
  fps?: number
  /**
   * Camera LoRA
   *
   * The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.
   */
  camera_lora?:
    | 'dolly_in'
    | 'dolly_out'
    | 'dolly_left'
    | 'dolly_right'
    | 'jib_up'
    | 'jib_down'
    | 'static'
    | 'none'
  /**
   * Video Size
   *
   * The size of the generated video.
   */
  video_size?:
    | SchemaImageSize
    | 'auto'
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Image Strength
   *
   * The strength of the image to use for the video generation.
   */
  image_strength?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to generate the video from.
   */
  negative_prompt?: string
  /**
   * Camera LoRA Scale
   *
   * The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.
   */
  camera_lora_scale?: number
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * Image URL
   *
   * The URL of the image to generate the video from.
   */
  image_url: string
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number | unknown
}

/**
 * LTX2ImageToVideoOutput
 */
export type SchemaLtx219bDistilledImageToVideoOutput = {
  /**
   * Prompt
   *
   * The prompt used for the generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for the random number generator.
   */
  seed: number
  video: SchemaVideoFile
}

/**
 * LTX2LoRAImageToVideoInput
 */
export type SchemaLtx219bImageToVideoLoraInput = {
  /**
   * Use Multi-Scale
   *
   * Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.
   */
  use_multiscale?: boolean
  /**
   * Prompt
   *
   * The prompt used for the generation.
   */
  prompt: string
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: 'none' | 'regular' | 'high' | 'full'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * FPS
   *
   * The frames per second of the generated video.
   */
  fps?: number
  /**
   * LoRAs
   *
   * The LoRAs to use for the generation.
   */
  loras: Array<SchemaLoRaInput>
  /**
   * Camera LoRA
   *
   * The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.
   */
  camera_lora?:
    | 'dolly_in'
    | 'dolly_out'
    | 'dolly_left'
    | 'dolly_right'
    | 'jib_up'
    | 'jib_down'
    | 'static'
    | 'none'
  /**
   * Video Size
   *
   * The size of the generated video.
   */
  video_size?:
    | SchemaImageSize
    | 'auto'
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Camera LoRA Scale
   *
   * The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.
   */
  camera_lora_scale?: number
  /**
   * Image Strength
   *
   * The strength of the image to use for the video generation.
   */
  image_strength?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to generate the video from.
   */
  negative_prompt?: string
  /**
   * Guidance Scale
   *
   * The guidance scale to use.
   */
  guidance_scale?: number
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Image URL
   *
   * The URL of the image to generate the video from.
   */
  image_url: string
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number | unknown
}

/**
 * LTX2ImageToVideoOutput
 */
export type SchemaLtx219bImageToVideoLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for the generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for the random number generator.
   */
  seed: number
  video: SchemaVideoFile
}

/**
 * LTX2ImageToVideoInput
 */
export type SchemaLtx219bImageToVideoInput = {
  /**
   * Use Multi-Scale
   *
   * Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.
   */
  use_multiscale?: boolean
  /**
   * Prompt
   *
   * The prompt used for the generation.
   */
  prompt: string
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: 'none' | 'regular' | 'high' | 'full'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * FPS
   *
   * The frames per second of the generated video.
   */
  fps?: number
  /**
   * Camera LoRA
   *
   * The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.
   */
  camera_lora?:
    | 'dolly_in'
    | 'dolly_out'
    | 'dolly_left'
    | 'dolly_right'
    | 'jib_up'
    | 'jib_down'
    | 'static'
    | 'none'
  /**
   * Video Size
   *
   * The size of the generated video.
   */
  video_size?:
    | SchemaImageSize
    | 'auto'
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Camera LoRA Scale
   *
   * The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.
   */
  camera_lora_scale?: number
  /**
   * Image Strength
   *
   * The strength of the image to use for the video generation.
   */
  image_strength?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to generate the video from.
   */
  negative_prompt?: string
  /**
   * Guidance Scale
   *
   * The guidance scale to use.
   */
  guidance_scale?: number
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Image URL
   *
   * The URL of the image to generate the video from.
   */
  image_url: string
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number | unknown
}

/**
 * LTX2ImageToVideoOutput
 */
export type SchemaLtx219bImageToVideoOutput = {
  /**
   * Prompt
   *
   * The prompt used for the generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for the random number generator.
   */
  seed: number
  video: SchemaVideoFile
}

/**
 * WANMoveInput
 */
export type SchemaWanMoveInput = {
  /**
   * Prompt
   *
   * Text prompt to guide the video generation.
   */
  prompt: string
  /**
   * Trajectories
   *
   * A list of trajectories. Each trajectory list means the movement of one object.
   */
  trajectories: Array<Array<SchemaTrajectoryPoint>>
  /**
   * Image Url
   *
   * URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Guidance Scale
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to guide the video generation.
   */
  negative_prompt?: string
}

/**
 * WanMoveOutput
 */
export type SchemaWanMoveOutput = {
  /**
   * Seed
   *
   * Random seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * Generated Video File
   */
  video: SchemaVideoFile
}

/**
 * Schema referenced but not defined by fal.ai (missing from source OpenAPI spec)
 */
export type SchemaTrajectoryPoint = {
  [key: string]: unknown
}

/**
 * KandinskyI2VRequest
 */
export type SchemaKandinsky5ProImageToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution: 512p or 1024p.
   */
  resolution?: '512P' | '1024P'
  /**
   * Acceleration
   *
   * Acceleration level for faster generation.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Duration
   *
   * Video duration.
   */
  duration?: '5s'
  /**
   * Num Inference Steps
   */
  num_inference_steps?: number
  /**
   * Image Url
   *
   * The URL of the image to use as a reference for the video generation.
   */
  image_url: string
}

/**
 * KandinskyI2VResponse
 */
export type SchemaKandinsky5ProImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video file.
   */
  video?: SchemaFile
}

/**
 * SeedanceProv15ImageToVideoInput
 */
export type SchemaBytedanceSeedanceV15ProImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt used to generate the video
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality
   */
  resolution?: '480p' | '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '21:9' | '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video
   */
  generate_audio?: boolean
  /**
   * Duration
   *
   * Duration of the video in seconds
   */
  duration?: '4' | '5' | '6' | '7' | '8' | '9' | '10' | '11' | '12'
  /**
   * Image Url
   *
   * The URL of the image used to generate video
   */
  image_url: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Camera Fixed
   *
   * Whether to fix the camera position
   */
  camera_fixed?: boolean
  /**
   * End Image Url
   *
   * The URL of the image the video ends with. Defaults to None.
   */
  end_image_url?: string
  /**
   * Seed
   *
   * Random seed to control video generation. Use -1 for random.
   */
  seed?: number
}

/**
 * SeedanceProv15I2VVideoOutput
 */
export type SchemaBytedanceSeedanceV15ProImageToVideoOutput = {
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * Generated video file
   */
  video: SchemaFile
}

/**
 * LiveAvatarRequest
 */
export type SchemaLiveAvatarInput = {
  /**
   * Frames per Clip
   *
   * Number of frames per clip. Must be a multiple of 4. Higher values = smoother but slower generation.
   */
  frames_per_clip?: number
  /**
   * Prompt
   *
   * A text prompt describing the scene and character. Helps guide the video generation style and context.
   */
  prompt: string
  /**
   * Acceleration
   *
   * Acceleration level for faster video decoding
   */
  acceleration?: 'none' | 'light' | 'regular' | 'high'
  /**
   * Reference Image URL
   *
   * The URL of the reference image for avatar generation. The character in this image will be animated.
   */
  image_url: string
  /**
   * Number of Clips
   *
   * Number of video clips to generate. Each clip is approximately 3 seconds. Set higher for longer videos.
   */
  num_clips?: number
  /**
   * Audio URL
   *
   * The URL of the driving audio file (WAV or MP3). The avatar will be animated to match this audio.
   */
  audio_url: string
  /**
   * Seed
   *
   * Random seed for reproducible generation.
   */
  seed?: number
  /**
   * Guidance Scale
   *
   * Classifier-free guidance scale. Higher values follow the prompt more closely.
   */
  guidance_scale?: number
  /**
   * Enable Safety Checker
   *
   * Enable safety checker for content moderation.
   */
  enable_safety_checker?: boolean
}

/**
 * LiveAvatarResponse
 */
export type SchemaLiveAvatarOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated avatar video file with synchronized audio.
   */
  video: SchemaVideoFile
}

/**
 * HunyuanVideo15I2VRequest
 */
export type SchemaHunyuanVideoV15ImageToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the video.
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the video.
   */
  resolution?: '480p'
  /**
   * Image Url
   *
   * URL of the reference image for image-to-video generation.
   */
  image_url: string
  /**
   * Enable Prompt Expansion
   *
   * Enable prompt expansion to enhance the input prompt.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility.
   */
  seed?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps.
   */
  num_inference_steps?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to guide what not to generate.
   */
  negative_prompt?: string
  /**
   * Num Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
}

/**
 * HunyuanVideo15Response
 */
export type SchemaHunyuanVideoV15ImageToVideoOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * ImageToVideoInput
 *
 * Input for Wan 2.6 image-to-video generation
 */
export type SchemaV26ImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt describing the desired video motion. Max 800 characters.
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution. Valid values: 720p, 1080p
   */
  resolution?: '720p' | '1080p'
  /**
   * Duration
   *
   * Duration of the generated video in seconds. Choose between 5, 10 or 15 seconds.
   */
  duration?: '5' | '10' | '15'
  /**
   * Audio Url
   *
   *
   * URL of the audio to use as the background music. Must be publicly accessible.
   * Limit handling: If the audio duration exceeds the duration value (5, 10, or 15 seconds),
   * the audio is truncated to the first N seconds, and the rest is discarded. If
   * the audio is shorter than the video, the remaining part of the video will be silent.
   * For example, if the audio is 3 seconds long and the video duration is 5 seconds, the
   * first 3 seconds of the output video will have sound, and the last 2 seconds will be silent.
   * - Format: WAV, MP3.
   * - Duration: 3 to 30 s.
   * - File size: Up to 15 MB.
   *
   */
  audio_url?: string
  /**
   * Image URL
   *
   * URL of the image to use as the first frame. Must be publicly accessible or base64 data URI. Image dimensions must be between 240 and 7680.
   */
  image_url: string
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt rewriting using LLM.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Multi Shots
   *
   * When true, enables intelligent multi-shot segmentation. Only active when enable_prompt_expansion is True. Set to false for single-shot generation.
   */
  multi_shots?: boolean
  /**
   * Negative Prompt
   *
   * Negative prompt to describe content to avoid. Max 500 characters.
   */
  negative_prompt?: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
}

/**
 * ImageToVideoOutput
 *
 * Output for image-to-video generation
 */
export type SchemaV26ImageToVideoOutput = {
  /**
   * Actual Prompt
   *
   * The actual prompt used if prompt rewriting was enabled
   */
  actual_prompt?: string
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * The generated video file
   */
  video: SchemaVideoFile
}

/**
 * OmniVideoReferenceToVideoInput
 *
 * Input for start-frame video generation with optional reference images and elements.
 */
export type SchemaKlingVideoO1StandardReferenceToVideoInput = {
  /**
   * Prompt
   *
   * Take @Element1, @Element2 to reference elements and @Image1, @Image2 to reference images in order.
   */
  prompt: string
  /**
   * Duration
   *
   * Video duration in seconds.
   */
  duration?: '3' | '4' | '5' | '6' | '7' | '8' | '9' | '10'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video frame.
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Elements
   *
   * Elements (characters/objects) to include in the video. Reference in prompt as @Element1, @Element2, etc. Maximum 7 total (elements + reference images + start image).
   */
  elements?: Array<SchemaOmniVideoElementInput>
  /**
   * Image Urls
   *
   * Additional reference images for style/appearance. Reference in prompt as @Image1, @Image2, etc. Maximum 7 total (elements + reference images + start image).
   */
  image_urls?: Array<string>
}

/**
 * OmniVideoReferenceToVideoOutput
 */
export type SchemaKlingVideoO1StandardReferenceToVideoOutput = {
  /**
   * Video
   *
   * The generated video.
   */
  video: SchemaFile
}

/**
 * OmniVideoElementInput
 */
export type SchemaOmniVideoElementInput = {
  /**
   * Reference Image Urls
   *
   * Additional reference images from different angles. 1-4 images supported. At least one image is required.
   */
  reference_image_urls?: Array<string>
  /**
   * Frontal Image Url
   *
   * The frontal image of the element (main view).
   *
   * Max file size: 10.0MB, Min width: 300px, Min height: 300px, Min aspect ratio: 0.40, Max aspect ratio: 2.50, Timeout: 20.0s
   */
  frontal_image_url: string
}

/**
 * OmniVideoImageToVideoInput
 */
export type SchemaKlingVideoO1StandardImageToVideoInput = {
  /**
   * Prompt
   *
   * Use @Image1 to reference the start frame, @Image2 to reference the end frame.
   */
  prompt: string
  /**
   * Duration
   *
   * Video duration in seconds.
   */
  duration?: '3' | '4' | '5' | '6' | '7' | '8' | '9' | '10'
  /**
   * Start Image Url
   *
   * Image to use as the first frame of the video.
   *
   * Max file size: 10.0MB, Min width: 300px, Min height: 300px, Min aspect ratio: 0.40, Max aspect ratio: 2.50, Timeout: 20.0s
   */
  start_image_url: string
  /**
   * End Image Url
   *
   * Image to use as the last frame of the video.
   *
   * Max file size: 10.0MB, Min width: 300px, Min height: 300px, Min aspect ratio: 0.40, Max aspect ratio: 2.50, Timeout: 20.0s
   */
  end_image_url?: string
}

/**
 * OmniVideoImageToVideoOutput
 *
 * Output for Kling Omni Video generation.
 */
export type SchemaKlingVideoO1StandardImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video.
   */
  video: SchemaFile
}

/**
 * AuroraInputModel
 */
export type SchemaCreatifyAuroraInput = {
  /**
   * Prompt
   *
   * A text prompt to guide the video generation process.
   */
  prompt?: string
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '480p' | '720p'
  /**
   * Guidance Scale
   *
   * Guidance scale to be used for text prompt adherence.
   */
  guidance_scale?: number
  /**
   * Audio Guidance Scale
   *
   * Guidance scale to be used for audio adherence.
   */
  audio_guidance_scale?: number
  /**
   * Audio Url
   *
   * The URL of the audio file to be used for video generation.
   */
  audio_url: string
  /**
   * Image Url
   *
   * The URL of the image file to be used for video generation.
   */
  image_url: string
}

/**
 * AuroraOutputModel
 */
export type SchemaCreatifyAuroraOutput = {
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaVideoFile
}

/**
 * AIAvatarInput
 */
export type SchemaKlingVideoAiAvatarV2ProInput = {
  /**
   * Prompt
   *
   * The prompt to use for the video generation.
   */
  prompt?: string
  /**
   * Audio Url
   *
   * The URL of the audio file.
   */
  audio_url: string
  /**
   * Image Url
   *
   * The URL of the image to use as your avatar
   */
  image_url: string
}

/**
 * AIAvatarOutput
 */
export type SchemaKlingVideoAiAvatarV2ProOutput = {
  /**
   * Duration
   *
   * Duration of the output video in seconds.
   */
  duration: number
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * AIAvatarInput
 */
export type SchemaKlingVideoAiAvatarV2StandardInput = {
  /**
   * Prompt
   *
   * The prompt to use for the video generation.
   */
  prompt?: string
  /**
   * Audio Url
   *
   * The URL of the audio file.
   */
  audio_url: string
  /**
   * Image Url
   *
   * The URL of the image to use as your avatar
   */
  image_url: string
}

/**
 * AIAvatarOutput
 */
export type SchemaKlingVideoAiAvatarV2StandardOutput = {
  /**
   * Duration
   *
   * Duration of the output video in seconds.
   */
  duration: number
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * ImageToVideoV26ProRequest
 */
export type SchemaKlingVideoV26ProImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Voice Ids
   *
   * List of voice IDs to use for voice control. Reference voices in the prompt using <<<voice_1>>>, <<<voice_2>>>. Maximum 2 voices allowed. When provided and referenced in prompt, enables voice control billing.
   */
  voice_ids?: Array<string>
  /**
   * Generate Audio
   *
   * Whether to generate native audio for the video. Supports Chinese and English voice output. Other languages are automatically translated to English. For English speech, use lowercase letters; for acronyms or proper nouns, use uppercase.
   */
  generate_audio?: boolean
  /**
   * Start Image Url
   *
   * URL of the image to be used for the video
   */
  start_image_url: string
  /**
   * End Image Url
   *
   * URL of the image to be used for the end of the video
   */
  end_image_url?: string
  /**
   * Negative Prompt
   */
  negative_prompt?: string
}

/**
 * ImageToVideoV26ProOutput
 */
export type SchemaKlingVideoV26ProImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * EffectInputV5_5
 */
export type SchemaPixverseV55EffectsInput = {
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '8' | '10'
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Thinking Type
   *
   * Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision
   */
  thinking_type?: 'enabled' | 'disabled' | 'auto'
  /**
   * Effect
   *
   * The effect to apply to the video
   */
  effect:
    | 'Kiss Me AI'
    | 'Kiss'
    | 'Muscle Surge'
    | 'Warmth of Jesus'
    | 'Anything, Robot'
    | 'The Tiger Touch'
    | 'Hug'
    | 'Holy Wings'
    | 'Microwave'
    | 'Zombie Mode'
    | 'Squid Game'
    | 'Baby Face'
    | 'Black Myth: Wukong'
    | 'Long Hair Magic'
    | 'Leggy Run'
    | 'Fin-tastic Mermaid'
    | 'Punch Face'
    | 'Creepy Devil Smile'
    | 'Thunder God'
    | 'Eye Zoom Challenge'
    | "Who's Arrested?"
    | 'Baby Arrived'
    | 'Werewolf Rage'
    | 'Bald Swipe'
    | 'BOOM DROP'
    | 'Huge Cutie'
    | 'Liquid Metal'
    | 'Sharksnap!'
    | 'Dust Me Away'
    | '3D Figurine Factor'
    | 'Bikini Up'
    | 'My Girlfriends'
    | 'My Boyfriends'
    | 'Subject 3 Fever'
    | 'Earth Zoom'
    | 'Pole Dance'
    | 'Vroom Dance'
    | 'GhostFace Terror'
    | 'Dragon Evoker'
    | 'Skeletal Bae'
    | 'Summoning succubus'
    | 'Halloween Voodoo Doll'
    | '3D Naked-Eye AD'
    | 'Package Explosion'
    | 'Dishes Served'
    | 'Ocean ad'
    | 'Supermarket AD'
    | 'Tree doll'
    | 'Come Feel My Abs'
    | 'The Bicep Flex'
    | 'London Elite Vibe'
    | 'Flora Nymph Gown'
    | 'Christmas Costume'
    | "It's Snowy"
    | 'Reindeer Cruiser'
    | 'Snow Globe Maker'
    | 'Pet Christmas Outfit'
    | 'Adopt a Polar Pal'
    | 'Cat Christmas Box'
    | 'Starlight Gift Box'
    | 'Xmas Poster'
    | 'Pet Christmas Tree'
    | 'City Santa Hat'
    | 'Stocking Sweetie'
    | 'Christmas Night'
    | 'Xmas Front Page Karma'
    | "Grinch's Xmas Hijack"
    | 'Giant Product'
    | 'Truck Fashion Shoot'
    | 'Beach AD'
    | 'Shoal Surround'
    | 'Mechanical Assembly'
    | 'Lighting AD'
    | 'Billboard AD'
    | 'Product close-up'
    | 'Parachute Delivery'
    | 'Dreamlike Cloud'
    | 'Macaron Machine'
    | 'Poster AD'
    | 'Truck AD'
    | 'Graffiti AD'
    | '3D Figurine Factory'
    | 'The Exclusive First Class'
    | 'Art Zoom Challenge'
    | 'I Quit'
    | 'Hitchcock Dolly Zoom'
    | 'Smell the Lens'
    | 'I believe I can fly'
    | 'Strikout Dance'
    | 'Pixel World'
    | 'Mint in Box'
    | 'Hands up, Hand'
    | 'Flora Nymph Go'
    | 'Somber Embrace'
    | 'Beam me up'
    | 'Suit Swagger'
  /**
   * Image Url
   *
   * Optional URL of the image to use as the first frame. If not provided, generates from text
   */
  image_url: string
}

/**
 * EffectOutput
 */
export type SchemaPixverseV55EffectsOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * TransitionRequestV5_5
 */
export type SchemaPixverseV55TransitionInput = {
  /**
   * First Image Url
   *
   * URL of the image to use as the first frame
   */
  first_image_url: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Thinking Type
   *
   * Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision
   */
  thinking_type?: 'enabled' | 'disabled' | 'auto'
  /**
   * Prompt
   *
   * The prompt for the transition
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds. Longer durations cost more. 1080p videos are limited to 5 or 8 seconds
   */
  duration?: '5' | '8' | '10'
  /**
   * Generate Audio Switch
   *
   * Enable audio generation (BGM, SFX, dialogue)
   */
  generate_audio_switch?: boolean
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * End Image Url
   *
   * URL of the image to use as the last frame
   */
  end_image_url?: string
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * TransitionOutputV5_5
 */
export type SchemaPixverseV55TransitionOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * ImageToVideoRequestV5_5
 */
export type SchemaPixverseV55ImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Duration
   *
   * The duration of the generated video in seconds. Longer durations cost more. 1080p videos are limited to 5 or 8 seconds
   */
  duration?: '5' | '8' | '10'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Thinking Type
   *
   * Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision
   */
  thinking_type?: 'enabled' | 'disabled' | 'auto'
  /**
   * Generate Multi Clip Switch
   *
   * Enable multi-clip generation with dynamic camera changes
   */
  generate_multi_clip_switch?: boolean
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
  /**
   * Generate Audio Switch
   *
   * Enable audio generation (BGM, SFX, dialogue)
   */
  generate_audio_switch?: boolean
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * I2VOutputV5_5
 */
export type SchemaPixverseV55ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * OmniVideoImageToVideoInput
 */
export type SchemaKlingVideoO1ImageToVideoInput = {
  /**
   * Prompt
   *
   * Use @Image1 to reference the start frame, @Image2 to reference the end frame.
   */
  prompt: string
  /**
   * Duration
   *
   * Video duration in seconds.
   */
  duration?: '3' | '4' | '5' | '6' | '7' | '8' | '9' | '10'
  /**
   * Start Image Url
   *
   * Image to use as the first frame of the video.
   *
   * Max file size: 10.0MB, Min width: 300px, Min height: 300px, Min aspect ratio: 0.40, Max aspect ratio: 2.50, Timeout: 20.0s
   */
  start_image_url: string
  /**
   * End Image Url
   *
   * Image to use as the last frame of the video.
   *
   * Max file size: 10.0MB, Min width: 300px, Min height: 300px, Min aspect ratio: 0.40, Max aspect ratio: 2.50, Timeout: 20.0s
   */
  end_image_url?: string
}

/**
 * OmniVideoImageToVideoOutput
 *
 * Output for Kling Omni Video generation.
 */
export type SchemaKlingVideoO1ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video.
   */
  video: SchemaFile
}

/**
 * OmniVideoReferenceToVideoInput
 *
 * Input for start-frame video generation with optional reference images and elements.
 */
export type SchemaKlingVideoO1ReferenceToVideoInput = {
  /**
   * Prompt
   *
   * Take @Element1, @Element2 to reference elements and @Image1, @Image2 to reference images in order.
   */
  prompt: string
  /**
   * Duration
   *
   * Video duration in seconds.
   */
  duration?: '3' | '4' | '5' | '6' | '7' | '8' | '9' | '10'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video frame.
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Elements
   *
   * Elements (characters/objects) to include in the video. Reference in prompt as @Element1, @Element2, etc. Maximum 7 total (elements + reference images + start image).
   */
  elements?: Array<SchemaOmniVideoElementInput>
  /**
   * Image Urls
   *
   * Additional reference images for style/appearance. Reference in prompt as @Image1, @Image2, etc. Maximum 7 total (elements + reference images + start image).
   */
  image_urls?: Array<string>
}

/**
 * OmniVideoReferenceToVideoOutput
 */
export type SchemaKlingVideoO1ReferenceToVideoOutput = {
  /**
   * Video
   *
   * The generated video.
   */
  video: SchemaFile
}

/**
 * LTXVImageToVideoFastRequest
 */
export type SchemaLtx2ImageToVideoFastInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9'
  /**
   * Duration
   *
   * The duration of the generated video in seconds. The fast model supports 6-20 seconds. Note: Durations longer than 10 seconds (12, 14, 16, 18, 20) are only supported with 25 FPS and 1080p resolution.
   */
  duration?: 6 | 8 | 10 | 12 | 14 | 16 | 18 | 20
  /**
   * Generate Audio
   *
   * Whether to generate audio for the generated video
   */
  generate_audio?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '1080p' | '1440p' | '2160p'
  /**
   * Image URL
   *
   * URL of the image to generate the video from. Must be publicly accessible or base64 data URI. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.
   */
  image_url: string
  /**
   * Frames per Second
   *
   * The frames per second of the generated video
   */
  fps?: 25 | 50
}

/**
 * LTXVImageToVideoResponse
 */
export type SchemaLtx2ImageToVideoFastOutput = {
  /**
   * Video
   *
   * The generated video file
   */
  video: SchemaVideoFile
}

/**
 * LTXVImageToVideoRequest
 */
export type SchemaLtx2ImageToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: 6 | 8 | 10
  /**
   * Generate Audio
   *
   * Whether to generate audio for the generated video
   */
  generate_audio?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '1080p' | '1440p' | '2160p'
  /**
   * Image URL
   *
   * URL of the image to generate the video from. Must be publicly accessible or base64 data URI. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.
   */
  image_url: string
  /**
   * Frames per Second
   *
   * The frames per second of the generated video
   */
  fps?: 25 | 50
}

/**
 * LTXVImageToVideoResponse
 */
export type SchemaLtx2ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video file
   */
  video: SchemaVideoFile
}

/**
 * LynxInput
 */
export type SchemaLynxInput = {
  /**
   * Prompt
   *
   * Text prompt to guide video generation
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p, 580p, or 720p)
   */
  resolution?: '480p' | '580p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video (16:9, 9:16, or 1:1)
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Guidance Scale 2
   *
   * Image guidance scale. Controls how closely the generated video follows the reference image. Higher values increase adherence to the reference image but may decrease quality.
   */
  guidance_scale_2?: number
  /**
   * Strength
   *
   * Reference image scale. Controls the influence of the reference image on the generated video.
   */
  strength?: number
  /**
   * Frames Per Second
   *
   * Frames per second of the generated video. Must be between 5 to 30.
   */
  frames_per_second?: number
  /**
   * Image Url
   *
   * The URL of the subject image to be used for video generation
   */
  image_url: string
  /**
   * Guidance Scale
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Num Frames
   *
   * Number of frames in the generated video. Must be between 9 to 100.
   */
  num_frames?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to guide what should not appear in the generated video
   */
  negative_prompt?: string
  /**
   * Ip Scale
   *
   * Identity preservation scale. Controls how closely the generated video preserves the subject's identity from the reference image.
   */
  ip_scale?: number
}

/**
 * LynxOutput
 */
export type SchemaLynxOutput = {
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * The generated video file
   */
  video: SchemaVideoFile
}

/**
 * SwapRequest
 */
export type SchemaPixverseSwapInput = {
  /**
   * Original Sound Switch
   *
   * Whether to keep the original audio
   */
  original_sound_switch?: boolean
  /**
   * Video Url
   *
   * URL of the external video to swap
   */
  video_url: string
  /**
   * Keyframe Id
   *
   * The keyframe ID (from 1 to the last frame position)
   */
  keyframe_id?: number
  /**
   * Mode
   *
   * The swap mode to use
   */
  mode?: 'person' | 'object' | 'background'
  /**
   * Resolution
   *
   * The output resolution (1080p not supported)
   */
  resolution?: '360p' | '540p' | '720p'
  /**
   * Image Url
   *
   * URL of the target image for swapping
   */
  image_url: string
}

/**
 * SwapOutput
 */
export type SchemaPixverseSwapOutput = {
  /**
   * Video
   *
   * The generated swapped video
   */
  video: SchemaFile
}

/**
 * Pika22KeyframesToVideoRequest
 */
export type SchemaPikaV22PikaframesInput = {
  /**
   * Prompt
   *
   * Default prompt for all transitions. Individual transition prompts override this.
   */
  prompt?: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '720p' | '1080p'
  /**
   * Transitions
   *
   * Configuration for each transition. Length must be len(image_urls) - 1. Total duration of all transitions must not exceed 25 seconds. If not provided, uses default 5-second transitions with the global prompt.
   */
  transitions?: Array<SchemaKeyframeTransition>
  /**
   * Seed
   *
   * The seed for the random number generator
   */
  seed?: number
  /**
   * Image Urls
   *
   * URLs of keyframe images (2-5 images) to create transitions between
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the model
   */
  negative_prompt?: string
}

/**
 * Pika22KeyframesToVideoOutput
 *
 * Output model for Pika 2.2 keyframes-to-video generation
 */
export type SchemaPikaV22PikaframesOutput = {
  /**
   * Video
   *
   * The generated video with transitions between keyframes
   */
  video: SchemaFile
}

/**
 * KeyframeTransition
 *
 * Configuration for a transition between two keyframes
 */
export type SchemaKeyframeTransition = {
  /**
   * Prompt
   *
   * Specific prompt for this transition. Overrides the global prompt if provided.
   */
  prompt?: string
  /**
   * Duration
   *
   * Duration of this transition in seconds
   */
  duration?: number
}

/**
 * LongCat720PCFGImageToVideoRequest
 */
export type SchemaLongcatVideoImageToVideo720pInput = {
  /**
   * Prompt
   *
   * The prompt to guide the video generation.
   */
  prompt?: string
  /**
   * Acceleration
   *
   * The acceleration level to use for the video generation.
   */
  acceleration?: 'none' | 'regular'
  /**
   * FPS
   *
   * The frame rate of the generated video.
   */
  fps?: number
  /**
   * Number of Refinement Inference Steps
   *
   * The number of inference steps to use for refinement.
   */
  num_refine_inference_steps?: number
  /**
   * Guidance Scale
   *
   * The guidance scale to use for the video generation.
   */
  guidance_scale?: number
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * The negative prompt to use for the video generation.
   */
  negative_prompt?: string
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * Image URL
   *
   * The URL of the image to generate a video from.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use for the video generation.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
}

/**
 * LongCatImageToVideoResponse
 */
export type SchemaLongcatVideoImageToVideo720pOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * LongCatCFGImageToVideoRequest
 */
export type SchemaLongcatVideoImageToVideo480pInput = {
  /**
   * Prompt
   *
   * The prompt to guide the video generation.
   */
  prompt?: string
  /**
   * Acceleration
   *
   * The acceleration level to use for the video generation.
   */
  acceleration?: 'none' | 'regular'
  /**
   * FPS
   *
   * The frame rate of the generated video.
   */
  fps?: number
  /**
   * Guidance Scale
   *
   * The guidance scale to use for the video generation.
   */
  guidance_scale?: number
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * The negative prompt to use for the video generation.
   */
  negative_prompt?: string
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * Image URL
   *
   * The URL of the image to generate a video from.
   */
  image_url: string
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use for the video generation.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
}

/**
 * LongCatImageToVideoResponse
 */
export type SchemaLongcatVideoImageToVideo480pOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * LongCat720PImageToVideoRequest
 */
export type SchemaLongcatVideoDistilledImageToVideo720pInput = {
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Prompt
   *
   * The prompt to guide the video generation.
   */
  prompt?: string
  /**
   * FPS
   *
   * The frame rate of the generated video.
   */
  fps?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Number of Refinement Inference Steps
   *
   * The number of inference steps to use for refinement.
   */
  num_refine_inference_steps?: number
  /**
   * Image URL
   *
   * The URL of the image to generate a video from.
   */
  image_url: string
  /**
   * Enable Safety Checker
   *
   * Whether to enable safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
}

/**
 * LongCatImageToVideoResponse
 */
export type SchemaLongcatVideoDistilledImageToVideo720pOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * LongCatImageToVideoRequest
 */
export type SchemaLongcatVideoDistilledImageToVideo480pInput = {
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * Prompt
   *
   * The prompt to guide the video generation.
   */
  prompt?: string
  /**
   * FPS
   *
   * The frame rate of the generated video.
   */
  fps?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Image URL
   *
   * The URL of the image to generate a video from.
   */
  image_url: string
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Safety Checker
   *
   * Whether to enable safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
}

/**
 * LongCatImageToVideoResponse
 */
export type SchemaLongcatVideoDistilledImageToVideo480pOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * StandardFastImageToVideoHailuo23Input
 */
export type SchemaMinimaxHailuo23FastStandardImageToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Duration
   *
   * The duration of the video in seconds.
   */
  duration?: '6' | '10'
  /**
   * Prompt
   *
   * Text prompt for video generation
   */
  prompt: string
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * StandardFastImageToVideoHailuo23Output
 */
export type SchemaMinimaxHailuo23FastStandardImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * StandardImageToVideoHailuo23Input
 */
export type SchemaMinimaxHailuo23StandardImageToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Duration
   *
   * The duration of the video in seconds.
   */
  duration?: '6' | '10'
  /**
   * Prompt
   *
   * Text prompt for video generation
   */
  prompt: string
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * StandardImageToVideoHailuo23Output
 */
export type SchemaMinimaxHailuo23StandardImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * ProFastImageToVideoHailuo23Input
 */
export type SchemaMinimaxHailuo23FastProImageToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Prompt
   *
   * Text prompt for video generation
   */
  prompt: string
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * ProFastImageToVideoHailuo23Output
 */
export type SchemaMinimaxHailuo23FastProImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * SeedanceProFastImageToVideoInput
 */
export type SchemaBytedanceSeedanceV1ProFastImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt used to generate the video
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality
   */
  resolution?: '480p' | '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '21:9' | '16:9' | '4:3' | '1:1' | '3:4' | '9:16' | 'auto'
  /**
   * Duration
   *
   * Duration of the video in seconds
   */
  duration?: '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9' | '10' | '11' | '12'
  /**
   * Image Url
   *
   * The URL of the image used to generate video
   */
  image_url: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Camera Fixed
   *
   * Whether to fix the camera position
   */
  camera_fixed?: boolean
  /**
   * Seed
   *
   * Random seed to control video generation. Use -1 for random.
   */
  seed?: number
}

/**
 * SeedanceFastI2VVideoOutput
 */
export type SchemaBytedanceSeedanceV1ProFastImageToVideoOutput = {
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * Generated video file
   */
  video: SchemaFile
}

/**
 * Q2ImageToVideoRequest
 */
export type SchemaViduQ2ImageToVideoTurboInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 3000 characters
   */
  prompt: string
  /**
   * Resolution
   *
   * Output video resolution
   */
  resolution?: '720p' | '1080p'
  /**
   * Duration
   *
   * Duration of the video in seconds
   */
  duration?: 2 | 3 | 4 | 5 | 6 | 7 | 8
  /**
   * Image Url
   *
   * URL of the image to use as the starting frame
   */
  image_url: string
  /**
   * Bgm
   *
   * Whether to add background music to the video (only for 4-second videos)
   */
  bgm?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Movement Amplitude
   *
   * The movement amplitude of objects in the frame
   */
  movement_amplitude?: 'auto' | 'small' | 'medium' | 'large'
  /**
   * End Image Url
   *
   * URL of the image to use as the ending frame. When provided, generates a transition video between start and end frames.
   */
  end_image_url?: string
}

/**
 * Q2ImageToVideoOutput
 */
export type SchemaViduQ2ImageToVideoTurboOutput = {
  /**
   * Video
   *
   * The generated video from image using the Q2 model
   */
  video: SchemaFile
}

/**
 * Q2ImageToVideoRequest
 */
export type SchemaViduQ2ImageToVideoProInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 3000 characters
   */
  prompt: string
  /**
   * Resolution
   *
   * Output video resolution
   */
  resolution?: '720p' | '1080p'
  /**
   * Duration
   *
   * Duration of the video in seconds
   */
  duration?: 2 | 3 | 4 | 5 | 6 | 7 | 8
  /**
   * Image Url
   *
   * URL of the image to use as the starting frame
   */
  image_url: string
  /**
   * Bgm
   *
   * Whether to add background music to the video (only for 4-second videos)
   */
  bgm?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Movement Amplitude
   *
   * The movement amplitude of objects in the frame
   */
  movement_amplitude?: 'auto' | 'small' | 'medium' | 'large'
  /**
   * End Image Url
   *
   * URL of the image to use as the ending frame. When provided, generates a transition video between start and end frames.
   */
  end_image_url?: string
}

/**
 * Q2ImageToVideoOutput
 */
export type SchemaViduQ2ImageToVideoProOutput = {
  /**
   * Video
   *
   * The generated video from image using the Q2 model
   */
  video: SchemaFile
}

/**
 * ImageToVideoV25StandardRequest
 */
export type SchemaKlingVideoV25TurboStandardImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Image Url
   *
   * URL of the image to be used for the video
   */
  image_url: string
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * ImageToVideoV25StandardOutput
 */
export type SchemaKlingVideoV25TurboStandardImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * Veo31FirstLastFrameToVideoInput
 */
export type SchemaVeo31FastFirstLastFrameToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video.
   */
  duration?: '4s' | '6s' | '8s'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * Auto Fix
   *
   * Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.
   */
  auto_fix?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '720p' | '1080p' | '4k'
  /**
   * First Frame URL
   *
   * URL of the first frame of the video
   */
  first_frame_url: string
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Last Frame URL
   *
   * URL of the last frame of the video
   */
  last_frame_url: string
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the video generation.
   */
  negative_prompt?: string
}

/**
 * Veo31FirstLastFrameToVideoOutput
 */
export type SchemaVeo31FastFirstLastFrameToVideoOutput = {
  /**
   * Video
   *
   * The generated video.
   */
  video: SchemaFile
}

/**
 * Veo31FirstLastFrameToVideoInput
 */
export type SchemaVeo31FirstLastFrameToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video.
   */
  duration?: '4s' | '6s' | '8s'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * Auto Fix
   *
   * Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.
   */
  auto_fix?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '720p' | '1080p' | '4k'
  /**
   * First Frame URL
   *
   * URL of the first frame of the video
   */
  first_frame_url: string
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Last Frame URL
   *
   * URL of the last frame of the video
   */
  last_frame_url: string
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the video generation.
   */
  negative_prompt?: string
}

/**
 * Veo31FirstLastFrameToVideoOutput
 */
export type SchemaVeo31FirstLastFrameToVideoOutput = {
  /**
   * Video
   *
   * The generated video.
   */
  video: SchemaFile
}

/**
 * Veo31ReferenceToVideoInput
 */
export type SchemaVeo31ReferenceToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video.
   */
  duration?: '8s'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video.
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '720p' | '1080p' | '4k'
  /**
   * Auto Fix
   *
   * Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.
   */
  auto_fix?: boolean
  /**
   * Image Urls
   *
   * URLs of the reference images to use for consistent subject appearance
   */
  image_urls: Array<string>
}

/**
 * Veo31ReferenceToVideoOutput
 */
export type SchemaVeo31ReferenceToVideoOutput = {
  /**
   * Video
   *
   * The generated video.
   */
  video: SchemaFile
}

/**
 * Veo31ImageToVideoInput
 */
export type SchemaVeo31FastImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video.
   */
  duration?: '4s' | '6s' | '8s'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video. Only 16:9 and 9:16 are supported.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * Auto Fix
   *
   * Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.
   */
  auto_fix?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '720p' | '1080p' | '4k'
  /**
   * Image URL
   *
   * URL of the input image to animate. Should be 720p or higher resolution in 16:9 or 9:16 aspect ratio. If the image is not in 16:9 or 9:16 aspect ratio, it will be cropped to fit.
   */
  image_url: string
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the video generation.
   */
  negative_prompt?: string
}

/**
 * Veo31ImageToVideoOutput
 */
export type SchemaVeo31FastImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video.
   */
  video: SchemaFile
}

/**
 * Veo31ImageToVideoInput
 */
export type SchemaVeo31ImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video.
   */
  duration?: '4s' | '6s' | '8s'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video. Only 16:9 and 9:16 are supported.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * Auto Fix
   *
   * Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.
   */
  auto_fix?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '720p' | '1080p' | '4k'
  /**
   * Image URL
   *
   * URL of the input image to animate. Should be 720p or higher resolution in 16:9 or 9:16 aspect ratio. If the image is not in 16:9 or 9:16 aspect ratio, it will be cropped to fit.
   */
  image_url: string
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the video generation.
   */
  negative_prompt?: string
}

/**
 * Veo31ImageToVideoOutput
 */
export type SchemaVeo31ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video.
   */
  video: SchemaFile
}

/**
 * ProImageToVideoInput
 */
export type SchemaSora2ImageToVideoProInput = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * Duration of the generated video in seconds
   */
  duration?: 4 | 8 | 12
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: 'auto' | '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: 'auto' | '9:16' | '16:9'
  /**
   * Delete Video
   *
   * Whether to delete the video after generation for privacy reasons. If True, the video cannot be used for remixing and will be permanently deleted.
   */
  delete_video?: boolean
  /**
   * Image URL
   *
   * The URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * ProImageToVideoOutput
 */
export type SchemaSora2ImageToVideoProOutput = {
  /**
   * Spritesheet
   *
   * Spritesheet image for the video
   */
  spritesheet?: SchemaImageFile
  /**
   * Thumbnail
   *
   * Thumbnail image for the video
   */
  thumbnail?: SchemaImageFile
  /**
   * Video ID
   *
   * The ID of the generated video
   */
  video_id: string
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaVideoFile
}

/**
 * ImageFile
 */
export type SchemaImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ImageToVideoInput
 */
export type SchemaSora2ImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * Duration of the generated video in seconds
   */
  duration?: 4 | 8 | 12
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: 'auto' | '720p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: 'auto' | '9:16' | '16:9'
  /**
   * Image URL
   *
   * The URL of the image to use as the first frame
   */
  image_url: string
  /**
   * Model
   *
   * The model to use for the generation. When the default model is selected, the latest snapshot of the model will be used - otherwise, select a specific snapshot of the model.
   */
  model?: 'sora-2' | 'sora-2-2025-12-08' | 'sora-2-2025-10-06'
  /**
   * Delete Video
   *
   * Whether to delete the video after generation for privacy reasons. If True, the video cannot be used for remixing and will be permanently deleted.
   */
  delete_video?: boolean
}

/**
 * ImageToVideoOutput
 */
export type SchemaSora2ImageToVideoOutput = {
  /**
   * Spritesheet
   *
   * Spritesheet image for the video
   */
  spritesheet?: SchemaImageFile
  /**
   * Thumbnail
   *
   * Thumbnail image for the video
   */
  thumbnail?: SchemaImageFile
  /**
   * Video ID
   *
   * The ID of the generated video
   */
  video_id: string
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaVideoFile
}

/**
 * OviI2VRequest
 */
export type SchemaOviImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number | unknown
  /**
   * Num Inference Steps
   *
   * The number of inference steps.
   */
  num_inference_steps?: number
  /**
   * Audio Negative Prompt
   *
   * Negative prompt for audio generation.
   */
  audio_negative_prompt?: string
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Image Url
   *
   * The image URL to guide video generation.
   */
  image_url: string
}

/**
 * OviI2VResponse
 */
export type SchemaOviImageToVideoOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * The generated video file.
   */
  video?: SchemaFile | unknown
}

/**
 * FabricOneLipsyncInput
 */
export type SchemaFabric10FastInput = {
  /**
   * Resolution
   *
   * Resolution
   */
  resolution: '720p' | '480p'
  /**
   * Audio Url
   */
  audio_url: string
  /**
   * Image Url
   */
  image_url: string
}

/**
 * FabricOneOutput
 */
export type SchemaFabric10FastOutput = {
  video: SchemaFile
}

/**
 * OmniHumanv15Input
 */
export type SchemaBytedanceOmnihumanV15Input = {
  /**
   * Turbo Mode
   *
   * Generate a video at a faster rate with a slight quality trade-off.
   */
  turbo_mode?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video. Defaults to 1080p. 720p generation is faster and higher in quality. 1080p generation is limited to 30s audio and 720p generation is limited to 60s audio.
   */
  resolution?: '720p' | '1080p'
  /**
   * Prompt
   *
   * The text prompt used to guide the video generation.
   */
  prompt?: string
  /**
   * Audio Url
   *
   * The URL of the audio file to generate the video. Audio must be under 30s long for 1080p generation and under 60s long for 720p generation.
   */
  audio_url: string
  /**
   * Image Url
   *
   * The URL of the image used to generate the video
   */
  image_url: string
}

/**
 * OmniHumanv15Output
 */
export type SchemaBytedanceOmnihumanV15Output = {
  /**
   * Duration
   *
   * Duration of audio input/video output as used for billing.
   */
  duration: number
  /**
   * Video
   *
   * Generated video file
   */
  video: SchemaFile
}

/**
 * FabricOneLipsyncInput
 */
export type SchemaFabric10Input = {
  /**
   * Resolution
   *
   * Resolution
   */
  resolution: '720p' | '480p'
  /**
   * Audio Url
   */
  audio_url: string
  /**
   * Image Url
   */
  image_url: string
}

/**
 * FabricOneOutput
 */
export type SchemaFabric10Output = {
  video: SchemaFile
}

/**
 * AIAvatarInput
 */
export type SchemaKlingVideoV1StandardAiAvatarInput = {
  /**
   * Prompt
   *
   * The prompt to use for the video generation.
   */
  prompt?: string
  /**
   * Audio Url
   *
   * The URL of the audio file.
   */
  audio_url: string
  /**
   * Image Url
   *
   * The URL of the image to use as your avatar
   */
  image_url: string
}

/**
 * AIAvatarOutput
 */
export type SchemaKlingVideoV1StandardAiAvatarOutput = {
  /**
   * Duration
   *
   * Duration of the output video in seconds.
   */
  duration: number
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * AIAvatarInput
 */
export type SchemaKlingVideoV1ProAiAvatarInput = {
  /**
   * Prompt
   *
   * The prompt to use for the video generation.
   */
  prompt?: string
  /**
   * Audio Url
   *
   * The URL of the audio file.
   */
  audio_url: string
  /**
   * Image Url
   *
   * The URL of the image to use as your avatar
   */
  image_url: string
}

/**
 * AIAvatarOutput
 */
export type SchemaKlingVideoV1ProAiAvatarOutput = {
  /**
   * Duration
   *
   * Duration of the output video in seconds.
   */
  duration: number
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * Lucy14BImageToVideoInput
 */
export type SchemaLucy14bImageToVideoInput = {
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated
   * and uploaded before returning the response. This will increase the
   * latency of the function but it allows you to get the image directly
   * in the response without going through the CDN.
   *
   */
  sync_mode?: boolean
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video.
   */
  aspect_ratio?: '9:16' | '16:9'
  /**
   * Prompt
   *
   * Text description of the desired video content
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the generated video
   */
  resolution?: '720p'
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * Lucy14BOutput
 */
export type SchemaLucy14bImageToVideoOutput = {
  /**
   * Video
   *
   * The generated MP4 video with H.264 encoding
   */
  video: SchemaFile
}

/**
 * SeedanceReferenceToVideoInput
 */
export type SchemaBytedanceSeedanceV1LiteReferenceToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt used to generate the video
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution - 480p for faster generation, 720p for higher quality
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '21:9' | '16:9' | '4:3' | '1:1' | '3:4' | '9:16' | 'auto'
  /**
   * Duration
   *
   * Duration of the video in seconds
   */
  duration?: '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9' | '10' | '11' | '12'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Camera Fixed
   *
   * Whether to fix the camera position
   */
  camera_fixed?: boolean
  /**
   * Reference Image Urls
   *
   * Reference images to generate the video with.
   */
  reference_image_urls: Array<string>
  /**
   * Seed
   *
   * Random seed to control video generation. Use -1 for random.
   */
  seed?: number
}

/**
 * SeedanceReferenceToVideoOutput
 */
export type SchemaBytedanceSeedanceV1LiteReferenceToVideoOutput = {
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * Generated video file
   */
  video: SchemaFile
}

/**
 * WanATIRequest
 */
export type SchemaWanAtiInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p, 580p, 720p).
   */
  resolution?: '480p' | '580p' | '720p'
  /**
   * Image URL
   *
   * URL of the input image.
   */
  image_url: string
  /**
   * Track
   *
   * Motion tracks to guide video generation. Each track is a sequence of points defining a motion trajectory. Multiple tracks can control different elements or objects in the video. Expected format: array of tracks, where each track is an array of points with 'x' and 'y' coordinates (up to 121 points per track). Points will be automatically padded to 121 if fewer are provided. Coordinates should be within the image dimensions.
   */
  track: Array<Array<SchemaTrackPoint>>
  /**
   * Guidance Scale (1st Stage)
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guidance_scale?: number
  /**
   * Number of Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
}

/**
 * WanATIResponse
 */
export type SchemaWanAtiOutput = {
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * A coordinate point with x and y values for motion tracking
 */
export type SchemaTrackPoint = {
  /**
   * X coordinate
   */
  x: number
  /**
   * Y coordinate
   */
  y: number
}

/**
 * ProcessRequest
 */
export type SchemaDecartLucy5bImageToVideoInput = {
  /**
   * Prompt
   *
   * Text description of the desired video content
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video.
   */
  aspect_ratio?: '9:16' | '16:9'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Resolution
   *
   * Resolution of the generated video
   */
  resolution?: '720p'
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * ProcessOutput
 */
export type SchemaDecartLucy5bImageToVideoOutput = {
  /**
   * Video
   *
   * The generated MP4 video with H.264 encoding
   */
  video: SchemaFile
}

/**
 * TransitionRequest
 */
export type SchemaPixverseV5TransitionInput = {
  /**
   * First Image Url
   *
   * URL of the image to use as the first frame
   */
  first_image_url: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Prompt
   *
   * The prompt for the transition
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '8'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * End Image Url
   *
   * URL of the image to use as the last frame
   */
  end_image_url?: string
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * TransitionOutputV5
 */
export type SchemaPixverseV5TransitionOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * EffectInput
 */
export type SchemaPixverseV5EffectsInput = {
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '8'
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Effect
   *
   * The effect to apply to the video
   */
  effect:
    | 'Kiss Me AI'
    | 'Kiss'
    | 'Muscle Surge'
    | 'Warmth of Jesus'
    | 'Anything, Robot'
    | 'The Tiger Touch'
    | 'Hug'
    | 'Holy Wings'
    | 'Microwave'
    | 'Zombie Mode'
    | 'Squid Game'
    | 'Baby Face'
    | 'Black Myth: Wukong'
    | 'Long Hair Magic'
    | 'Leggy Run'
    | 'Fin-tastic Mermaid'
    | 'Punch Face'
    | 'Creepy Devil Smile'
    | 'Thunder God'
    | 'Eye Zoom Challenge'
    | "Who's Arrested?"
    | 'Baby Arrived'
    | 'Werewolf Rage'
    | 'Bald Swipe'
    | 'BOOM DROP'
    | 'Huge Cutie'
    | 'Liquid Metal'
    | 'Sharksnap!'
    | 'Dust Me Away'
    | '3D Figurine Factor'
    | 'Bikini Up'
    | 'My Girlfriends'
    | 'My Boyfriends'
    | 'Subject 3 Fever'
    | 'Earth Zoom'
    | 'Pole Dance'
    | 'Vroom Dance'
    | 'GhostFace Terror'
    | 'Dragon Evoker'
    | 'Skeletal Bae'
    | 'Summoning succubus'
    | 'Halloween Voodoo Doll'
    | '3D Naked-Eye AD'
    | 'Package Explosion'
    | 'Dishes Served'
    | 'Ocean ad'
    | 'Supermarket AD'
    | 'Tree doll'
    | 'Come Feel My Abs'
    | 'The Bicep Flex'
    | 'London Elite Vibe'
    | 'Flora Nymph Gown'
    | 'Christmas Costume'
    | "It's Snowy"
    | 'Reindeer Cruiser'
    | 'Snow Globe Maker'
    | 'Pet Christmas Outfit'
    | 'Adopt a Polar Pal'
    | 'Cat Christmas Box'
    | 'Starlight Gift Box'
    | 'Xmas Poster'
    | 'Pet Christmas Tree'
    | 'City Santa Hat'
    | 'Stocking Sweetie'
    | 'Christmas Night'
    | 'Xmas Front Page Karma'
    | "Grinch's Xmas Hijack"
    | 'Giant Product'
    | 'Truck Fashion Shoot'
    | 'Beach AD'
    | 'Shoal Surround'
    | 'Mechanical Assembly'
    | 'Lighting AD'
    | 'Billboard AD'
    | 'Product close-up'
    | 'Parachute Delivery'
    | 'Dreamlike Cloud'
    | 'Macaron Machine'
    | 'Poster AD'
    | 'Truck AD'
    | 'Graffiti AD'
    | '3D Figurine Factory'
    | 'The Exclusive First Class'
    | 'Art Zoom Challenge'
    | 'I Quit'
    | 'Hitchcock Dolly Zoom'
    | 'Smell the Lens'
    | 'I believe I can fly'
    | 'Strikout Dance'
    | 'Pixel World'
    | 'Mint in Box'
    | 'Hands up, Hand'
    | 'Flora Nymph Go'
    | 'Somber Embrace'
    | 'Beam me up'
    | 'Suit Swagger'
  /**
   * Image Url
   *
   * Optional URL of the image to use as the first frame. If not provided, generates from text
   */
  image_url: string
}

/**
 * EffectOutput
 */
export type SchemaPixverseV5EffectsOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * ImageToVideoRequestV5
 */
export type SchemaPixverseV5ImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Duration
   *
   * The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds
   */
  duration?: '5' | '8'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * I2VOutputV5
 */
export type SchemaPixverseV5ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * MareyInputI2V
 */
export type SchemaMareyI2vInput = {
  /**
   * Prompt
   *
   * The prompt to generate a video from
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video.
   */
  duration?: '5s' | '10s'
  /**
   * Image Url
   *
   * The URL of the image to use as the first frame of the video.
   */
  image_url: string
  /**
   * Dimensions
   *
   * The dimensions of the generated video in width x height format.
   */
  dimensions?:
    | '1920x1080'
    | '1080x1920'
    | '1152x1152'
    | '1536x1152'
    | '1152x1536'
  /**
   * Guidance Scale
   *
   * Controls how strongly the generation is guided by the prompt (0-20). Higher values follow the prompt more closely.
   */
  guidance_scale?: number | unknown
  /**
   * Seed
   *
   * Seed for random number generation. Use -1 for random seed each run.
   */
  seed?: number | unknown
  /**
   * Negative Prompt
   *
   * Negative prompt used to guide the model away from undesirable features.
   */
  negative_prompt?: string | unknown
}

/**
 * MareyOutput
 */
export type SchemaMareyI2vOutput = {
  video: SchemaFile
}

/**
 * StylizeInput
 */
export type SchemaBytedanceVideoStylizeInput = {
  /**
   * Style
   *
   * The style for your character in the video. Please use a short description.
   */
  style: string
  /**
   * Image Url
   *
   * URL of the image to make the stylized video from.
   */
  image_url: string
}

export type SchemaBytedanceVideoStylizeOutput = unknown

/**
 * WanLoRAI2VRequest
 */
export type SchemaWanV22A14bImageToVideoLoraInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Shift
   *
   * Shift value for the video. Must be between 1.0 and 10.0.
   */
  shift?: number
  /**
   * Acceleration
   *
   * Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Number of Interpolated Frames
   *
   * Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.
   */
  num_interpolated_frames?: number
  /**
   * Reverse Video
   *
   * If true, the video will be reversed.
   */
  reverse_video?: boolean
  /**
   * Loras
   *
   * LoRA weights to be used in the inference.
   */
  loras?: Array<SchemaLoRaWeight>
  /**
   * Frames per Second
   *
   * Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.
   */
  frames_per_second?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, input data will be checked for safety before processing.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Frames
   *
   * Number of frames to generate. Must be between 17 to 161 (inclusive).
   */
  num_frames?: number
  /**
   * End Image URL
   *
   * URL of the end image.
   */
  end_image_url?: string
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Guidance Scale (1st Stage)
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guidance_scale?: number
  /**
   * Video Write Mode
   *
   * The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Resolution
   *
   * Resolution of the generated video (480p, 580p, or 720p).
   */
  resolution?: '480p' | '580p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16' | '1:1'
  /**
   * Enable Output Safety Checker
   *
   * If set to true, output video will be checked for safety after generation.
   */
  enable_output_safety_checker?: boolean
  /**
   * Image URL
   *
   * URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Video Quality
   *
   * The quality of the output video. Higher quality means better visual quality but larger file size.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Guidance Scale (2nd Stage)
   *
   * Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.
   */
  guidance_scale_2?: number
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean
  /**
   * Number of Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Interpolator Model
   *
   * The model to use for frame interpolation. If None, no interpolation is applied.
   */
  interpolator_model?: 'none' | 'film' | 'rife'
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Adjust FPS for Interpolation
   *
   * If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.
   */
  adjust_fps_for_interpolation?: boolean
}

/**
 * WanI2VResponse
 */
export type SchemaWanV22A14bImageToVideoLoraOutput = {
  /**
   * Prompt
   *
   * The text prompt used for video generation.
   */
  prompt?: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * LoRAWeight
 *
 * LoRA weight to use for generation.
 */
export type SchemaLoRaWeight = {
  /**
   * Path
   *
   * URL or path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   * Scale of the LoRA weight. This is a multiplier applied to the LoRA weight when loading it.
   */
  scale?: number
  /**
   * Weight Name
   *
   * Name of the LoRA weight. Only used if `path` is a HuggingFace repository, and is only required when the repository contains multiple LoRA weights.
   */
  weight_name?: string
}

/**
 * FastImageToVideoHailuo02Input
 */
export type SchemaMinimaxHailuo02FastImageToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Duration
   *
   * The duration of the video in seconds. 10 seconds videos are not supported for 1080p resolution.
   */
  duration?: '6' | '10'
  /**
   * Prompt
   */
  prompt: string
  /**
   * Image Url
   */
  image_url: string
}

/**
 * ImageToVideoHailuo02FastOutput
 */
export type SchemaMinimaxHailuo02FastImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * Veo3ImageToVideoInput
 */
export type SchemaVeo3ImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt describing how the image should be animated
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * Auto Fix
   *
   * Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.
   */
  auto_fix?: boolean
  /**
   * Duration
   *
   * The duration of the generated video.
   */
  duration?: '4s' | '6s' | '8s'
  /**
   * Image URL
   *
   * URL of the input image to animate. Should be 720p or higher resolution in 16:9 or 9:16 aspect ratio. If the image is not in 16:9 or 9:16 aspect ratio, it will be cropped to fit.
   */
  image_url: string
}

/**
 * Veo3ImageToVideoOutput
 */
export type SchemaVeo3ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video.
   */
  video: SchemaFile
}

/**
 * WanTurboI2VRequest
 */
export type SchemaWanV22A14bImageToVideoTurboInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p, 580p, or 720p).
   */
  resolution?: '480p' | '580p' | '720p'
  /**
   * Acceleration
   *
   * Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16' | '1:1'
  /**
   * Video Write Mode
   *
   * The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Enable Output Safety Checker
   *
   * If set to true, output video will be checked for safety after generation.
   */
  enable_output_safety_checker?: boolean
  /**
   * Image URL
   *
   * URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Video Quality
   *
   * The quality of the output video. Higher quality means better visual quality but larger file size.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Safety Checker
   *
   * If set to true, input data will be checked for safety before processing.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * End Image URL
   *
   * URL of the end image.
   */
  end_image_url?: string
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean
}

/**
 * WanTurboI2VResponse
 */
export type SchemaWanV22A14bImageToVideoTurboOutput = {
  /**
   * Prompt
   *
   * The text prompt used for video generation.
   */
  prompt?: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * WanSmallI2VRequest
 */
export type SchemaWanV225bImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Shift
   *
   * Shift value for the video. Must be between 1.0 and 10.0.
   */
  shift?: number
  /**
   * Number of Interpolated Frames
   *
   * Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.
   */
  num_interpolated_frames?: number
  /**
   * Frames per Second
   *
   * Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.
   */
  frames_per_second?: number
  /**
   * Guidance Scale
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guidance_scale?: number
  /**
   * Number of Frames
   *
   * Number of frames to generate. Must be between 17 to 161 (inclusive).
   */
  num_frames?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, input data will be checked for safety before processing.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Video Write Mode
   *
   * The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Resolution
   *
   * Resolution of the generated video (580p or 720p).
   */
  resolution?: '580p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16' | '1:1'
  /**
   * Enable Output Safety Checker
   *
   * If set to true, output video will be checked for safety after generation.
   */
  enable_output_safety_checker?: boolean
  /**
   * Image URL
   *
   * URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Video Quality
   *
   * The quality of the output video. Higher quality means better visual quality but larger file size.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean
  /**
   * Number of Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Interpolator Model
   *
   * The model to use for frame interpolation. If None, no interpolation is applied.
   */
  interpolator_model?: 'none' | 'film' | 'rife'
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Adjust FPS for Interpolation
   *
   * If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.
   */
  adjust_fps_for_interpolation?: boolean
}

/**
 * WanSmallI2VResponse
 */
export type SchemaWanV225bImageToVideoOutput = {
  /**
   * Prompt
   *
   * The text prompt used for video generation.
   */
  prompt?: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * WanI2VRequest
 */
export type SchemaWanV22A14bImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Shift
   *
   * Shift value for the video. Must be between 1.0 and 10.0.
   */
  shift?: number
  /**
   * Acceleration
   *
   * Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Number of Interpolated Frames
   *
   * Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.
   */
  num_interpolated_frames?: number
  /**
   * Frames per Second
   *
   * Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.
   */
  frames_per_second?: number
  /**
   * Guidance Scale (1st Stage)
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guidance_scale?: number
  /**
   * Number of Frames
   *
   * Number of frames to generate. Must be between 17 to 161 (inclusive).
   */
  num_frames?: number
  /**
   * End Image URL
   *
   * URL of the end image.
   */
  end_image_url?: string
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Enable Safety Checker
   *
   * If set to true, input data will be checked for safety before processing.
   */
  enable_safety_checker?: boolean
  /**
   * Video Write Mode
   *
   * The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Resolution
   *
   * Resolution of the generated video (480p, 580p, or 720p).
   */
  resolution?: '480p' | '580p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16' | '1:1'
  /**
   * Enable Output Safety Checker
   *
   * If set to true, output video will be checked for safety after generation.
   */
  enable_output_safety_checker?: boolean
  /**
   * Image URL
   *
   * URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Video Quality
   *
   * The quality of the output video. Higher quality means better visual quality but larger file size.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Guidance Scale (2nd Stage)
   *
   * Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.
   */
  guidance_scale_2?: number
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Interpolator Model
   *
   * The model to use for frame interpolation. If None, no interpolation is applied.
   */
  interpolator_model?: 'none' | 'film' | 'rife'
  /**
   * Number of Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Adjust FPS for Interpolation
   *
   * If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.
   */
  adjust_fps_for_interpolation?: boolean
}

/**
 * WanI2VResponse
 */
export type SchemaWanV22A14bImageToVideoOutput = {
  /**
   * Prompt
   *
   * The text prompt used for video generation.
   */
  prompt?: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * OmniHumanInput
 */
export type SchemaBytedanceOmnihumanInput = {
  /**
   * Audio Url
   *
   * The URL of the audio file to generate the video. Audio must be under 30s long.
   */
  audio_url: string
  /**
   * Image Url
   *
   * The URL of the image used to generate the video
   */
  image_url: string
}

/**
 * OmniHumanOutput
 */
export type SchemaBytedanceOmnihumanOutput = {
  /**
   * Duration
   *
   * Duration of audio input/video output as used for billing.
   */
  duration: number
  /**
   * Video
   *
   * Generated video file
   */
  video: SchemaFile
}

/**
 * DistilledImageToVideoInput
 *
 * Distilled model input
 */
export type SchemaLtxv13B098DistilledImageToVideoInput = {
  /**
   * Second Pass Skip Initial Steps
   *
   * The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.
   */
  second_pass_skip_initial_steps?: number
  /**
   * Number of Inference Steps
   *
   * Number of inference steps during the first pass.
   */
  first_pass_num_inference_steps?: number
  /**
   * Frame Rate
   *
   * The frame rate of the video.
   */
  frame_rate?: number
  /**
   * Reverse Video
   *
   * Whether to reverse the video.
   */
  reverse_video?: boolean
  /**
   * Prompt
   *
   * Text prompt to guide generation
   */
  prompt: string
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt using a language model.
   */
  expand_prompt?: boolean
  /**
   * Temporal AdaIN Factor
   *
   * The factor for adaptive instance normalization (AdaIN) applied to generated video chunks after the first. This can help deal with a gradual increase in saturation/contrast in the generated video by normalizing the color distribution across the video. A high value will ensure the color distribution is more consistent across the video, while a low value will allow for more variation in color distribution.
   */
  temporal_adain_factor?: number
  /**
   * Loras
   *
   * LoRA weights to use for generation
   */
  loras?: Array<SchemaLoRaWeight>
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Frames
   *
   * The number of frames in the video.
   */
  num_frames?: number
  /**
   * Second Pass Number of Inference Steps
   *
   * Number of inference steps during the second pass.
   */
  second_pass_num_inference_steps?: number
  /**
   * Negative Prompt
   *
   * Negative prompt for generation
   */
  negative_prompt?: string
  /**
   * Enable Detail Pass
   *
   * Whether to use a detail pass. If True, the model will perform a second pass to refine the video and enhance details. This incurs a 2.0x cost multiplier on the base price.
   */
  enable_detail_pass?: boolean
  /**
   * Resolution
   *
   * Resolution of the generated video.
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the video.
   */
  aspect_ratio?: '9:16' | '1:1' | '16:9' | 'auto'
  /**
   * Tone Map Compression Ratio
   *
   * The compression ratio for tone mapping. This is used to compress the dynamic range of the video to improve visual quality. A value of 0.0 means no compression, while a value of 1.0 means maximum compression.
   */
  tone_map_compression_ratio?: number
  /**
   * Image URL
   *
   * Image URL for Image-to-Video task
   */
  image_url: string
  /**
   * Constant Rate Factor
   *
   * The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.
   */
  constant_rate_factor?: number
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number
}

/**
 * ImageToVideoOutput
 */
export type SchemaLtxv13B098DistilledImageToVideoOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * Veo3ImageToVideoInput
 */
export type SchemaVeo3FastImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt describing how the image should be animated
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * Auto Fix
   *
   * Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.
   */
  auto_fix?: boolean
  /**
   * Duration
   *
   * The duration of the generated video.
   */
  duration?: '4s' | '6s' | '8s'
  /**
   * Image URL
   *
   * URL of the input image to animate. Should be 720p or higher resolution in 16:9 or 9:16 aspect ratio. If the image is not in 16:9 or 9:16 aspect ratio, it will be cropped to fit.
   */
  image_url: string
}

/**
 * Veo3ImageToVideoOutput
 */
export type SchemaVeo3FastImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video.
   */
  video: SchemaFile
}

/**
 * Q1ReferenceToVideoRequest
 */
export type SchemaViduQ1ReferenceToVideoInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 1500 characters
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the output video
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Bgm
   *
   * Whether to add background music to the generated video
   */
  bgm?: boolean
  /**
   * Reference Image Urls
   *
   * URLs of the reference images to use for consistent subject appearance. Q1 model supports up to 7 reference images.
   */
  reference_image_urls: Array<string>
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number
  /**
   * Movement Amplitude
   *
   * The movement amplitude of objects in the frame
   */
  movement_amplitude?: 'auto' | 'small' | 'medium' | 'large'
}

/**
 * Q1ReferenceToVideoOutput
 */
export type SchemaViduQ1ReferenceToVideoOutput = {
  /**
   * Video
   *
   * The generated video with consistent subjects from reference images using the Q1 model
   */
  video: SchemaFile
}

/**
 * AvatarSingleTextRequest
 */
export type SchemaAiAvatarSingleTextInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the video to generate. Must be either 480p or 720p.
   */
  resolution?: '480p' | '720p'
  /**
   * Acceleration
   *
   * The acceleration level to use for generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Text Input
   *
   * The text input to guide video generation.
   */
  text_input: string
  /**
   * Image URL
   *
   * URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Voice
   *
   * The voice to use for speech generation
   */
  voice:
    | 'Aria'
    | 'Roger'
    | 'Sarah'
    | 'Laura'
    | 'Charlie'
    | 'George'
    | 'Callum'
    | 'River'
    | 'Liam'
    | 'Charlotte'
    | 'Alice'
    | 'Matilda'
    | 'Will'
    | 'Jessica'
    | 'Eric'
    | 'Chris'
    | 'Brian'
    | 'Daniel'
    | 'Lily'
    | 'Bill'
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Number of Frames
   *
   * Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.
   */
  num_frames?: number
}

/**
 * AvatarSingleTextResponse
 */
export type SchemaAiAvatarSingleTextOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * AvatarSingleAudioRequest
 */
export type SchemaAiAvatarInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the video to generate. Must be either 480p or 720p.
   */
  resolution?: '480p' | '720p'
  /**
   * Acceleration
   *
   * The acceleration level to use for generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Image URL
   *
   * URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Audio URL
   *
   * The URL of the audio file.
   */
  audio_url: string
  /**
   * Number of Frames
   *
   * Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.
   */
  num_frames?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
}

/**
 * AvatarSingleAudioResponse
 */
export type SchemaAiAvatarOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * AvatarMultiTextRequest
 */
export type SchemaAiAvatarMultiTextInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Second Text Input
   *
   * The text input to guide video generation.
   */
  second_text_input: string
  /**
   * Acceleration
   *
   * The acceleration level to use for generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Resolution
   *
   * Resolution of the video to generate. Must be either 480p or 720p.
   */
  resolution?: '480p' | '720p'
  /**
   * First Text Input
   *
   * The text input to guide video generation.
   */
  first_text_input: string
  /**
   * Image URL
   *
   * URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Voice2
   *
   * The second person's voice to use for speech generation
   */
  voice2?:
    | 'Aria'
    | 'Roger'
    | 'Sarah'
    | 'Laura'
    | 'Charlie'
    | 'George'
    | 'Callum'
    | 'River'
    | 'Liam'
    | 'Charlotte'
    | 'Alice'
    | 'Matilda'
    | 'Will'
    | 'Jessica'
    | 'Eric'
    | 'Chris'
    | 'Brian'
    | 'Daniel'
    | 'Lily'
    | 'Bill'
  /**
   * Voice1
   *
   * The first person's voice to use for speech generation
   */
  voice1?:
    | 'Aria'
    | 'Roger'
    | 'Sarah'
    | 'Laura'
    | 'Charlie'
    | 'George'
    | 'Callum'
    | 'River'
    | 'Liam'
    | 'Charlotte'
    | 'Alice'
    | 'Matilda'
    | 'Will'
    | 'Jessica'
    | 'Eric'
    | 'Chris'
    | 'Brian'
    | 'Daniel'
    | 'Lily'
    | 'Bill'
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Number of Frames
   *
   * Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.
   */
  num_frames?: number
}

/**
 * AvatarMultiTextResponse
 */
export type SchemaAiAvatarMultiTextOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * AvatarMultiAudioPersonRequest
 */
export type SchemaAiAvatarMultiInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the video to generate. Must be either 480p or 720p.
   */
  resolution?: '480p' | '720p'
  /**
   * Acceleration
   *
   * The acceleration level to use for generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * First Audio URL
   *
   * The URL of the Person 1 audio file.
   */
  first_audio_url: string
  /**
   * Image URL
   *
   * URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Second Audio URL
   *
   * The URL of the Person 2 audio file.
   */
  second_audio_url?: string
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Use Only First Audio
   *
   * Whether to use only the first audio file.
   */
  use_only_first_audio?: boolean
  /**
   * Number of Frames
   *
   * Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.
   */
  num_frames?: number
}

/**
 * AvatarMultiAudioResponse
 */
export type SchemaAiAvatarMultiOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * ProImageToVideoHailuo02Input
 */
export type SchemaMinimaxHailuo02ProImageToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Prompt
   */
  prompt: string
  /**
   * End Image Url
   *
   * Optional URL of the image to use as the last frame of the video
   */
  end_image_url?: string
  /**
   * Image Url
   */
  image_url: string
}

/**
 * ImageToVideoHailuo02Output
 */
export type SchemaMinimaxHailuo02ProImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * SeedanceImageToVideoInput
 */
export type SchemaBytedanceSeedanceV1LiteImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt used to generate the video
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution - 480p for faster generation, 720p for higher quality
   */
  resolution?: '480p' | '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '21:9' | '16:9' | '4:3' | '1:1' | '3:4' | '9:16' | 'auto'
  /**
   * Duration
   *
   * Duration of the video in seconds
   */
  duration?: '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9' | '10' | '11' | '12'
  /**
   * Image Url
   *
   * The URL of the image used to generate video
   */
  image_url: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Camera Fixed
   *
   * Whether to fix the camera position
   */
  camera_fixed?: boolean
  /**
   * End Image Url
   *
   * The URL of the image the video ends with. Defaults to None.
   */
  end_image_url?: string
  /**
   * Seed
   *
   * Random seed to control video generation. Use -1 for random.
   */
  seed?: number
}

/**
 * SeedanceVideoOutput
 */
export type SchemaBytedanceSeedanceV1LiteImageToVideoOutput = {
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * Generated video file
   */
  video: SchemaFile
}

/**
 * Input
 */
export type SchemaHunyuanAvatarInput = {
  /**
   * Text
   *
   * Text prompt describing the scene.
   */
  text?: string
  /**
   * Image Url
   *
   * The URL of the reference image.
   */
  image_url: string
  /**
   * Turbo Mode
   *
   * If true, the video will be generated faster with no noticeable degradation in the visual quality.
   */
  turbo_mode?: boolean
  /**
   * Audio Url
   *
   * The URL of the audio file.
   */
  audio_url: string
  /**
   * Seed
   *
   * Random seed for generation.
   */
  seed?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Num Frames
   *
   * Number of video frames to generate at 25 FPS. If greater than the input audio length, it will capped to the length of the input audio.
   */
  num_frames?: number
}

/**
 * Output
 */
export type SchemaHunyuanAvatarOutput = {
  /**
   * Video
   *
   * The generated video with the avatar animation.
   */
  video: SchemaFile
}

/**
 * ImageToVideoV21ProRequest
 */
export type SchemaKlingVideoV21ProImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Image Url
   *
   * URL of the image to be used for the video
   */
  image_url: string
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Tail Image Url
   *
   * URL of the image to be used for the end of the video
   */
  tail_image_url?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * ImageToVideoV21ProOutput
 */
export type SchemaKlingVideoV21ProImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * Input
 */
export type SchemaHunyuanPortraitInput = {
  /**
   * Video Url
   *
   * The URL of the driving video.
   */
  video_url: string
  /**
   * Seed
   *
   * Random seed for generation. If None, a random seed will be used.
   */
  seed?: number
  /**
   * Use Arcface
   *
   * Whether to use ArcFace for face recognition.
   */
  use_arcface?: boolean
  /**
   * Image Url
   *
   * The URL of the source image.
   */
  image_url: string
}

/**
 * Output
 */
export type SchemaHunyuanPortraitOutput = {
  /**
   * Video
   *
   * The generated video with the portrait animation.
   */
  video: SchemaFile
}

/**
 * MultiImageToVideoRequest
 */
export type SchemaKlingVideoV16StandardElementsInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video frame
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Input Image Urls
   *
   * List of image URLs to use for video generation. Supports up to 4 images.
   */
  input_image_urls: Array<string>
  /**
   * Negative Prompt
   */
  negative_prompt?: string
}

/**
 * ElementsOutput
 */
export type SchemaKlingVideoV16StandardElementsOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * MultiImageToVideoRequest
 */
export type SchemaKlingVideoV16ProElementsInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video frame
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Input Image Urls
   *
   * List of image URLs to use for video generation. Supports up to 4 images.
   */
  input_image_urls: Array<string>
  /**
   * Negative Prompt
   */
  negative_prompt?: string
}

/**
 * ElementsOutput
 */
export type SchemaKlingVideoV16ProElementsOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * DistilledImageToVideoInput
 *
 * Distilled model input
 */
export type SchemaLtxVideo13bDistilledImageToVideoInput = {
  /**
   * Second Pass Skip Initial Steps
   *
   * The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.
   */
  second_pass_skip_initial_steps?: number
  /**
   * First Pass Num Inference Steps
   *
   * Number of inference steps during the first pass.
   */
  first_pass_num_inference_steps?: number
  /**
   * Frame Rate
   *
   * The frame rate of the video.
   */
  frame_rate?: number
  /**
   * Reverse Video
   *
   * Whether to reverse the video.
   */
  reverse_video?: boolean
  /**
   * Prompt
   *
   * Text prompt to guide generation
   */
  prompt: string
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt using a language model.
   */
  expand_prompt?: boolean
  /**
   * Loras
   *
   * LoRA weights to use for generation
   */
  loras?: Array<SchemaLoRaWeight>
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Num Frames
   *
   * The number of frames in the video.
   */
  num_frames?: number
  /**
   * Second Pass Num Inference Steps
   *
   * Number of inference steps during the second pass.
   */
  second_pass_num_inference_steps?: number
  /**
   * Negative Prompt
   *
   * Negative prompt for generation
   */
  negative_prompt?: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p or 720p).
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the video.
   */
  aspect_ratio?: '9:16' | '1:1' | '16:9' | 'auto'
  /**
   * Image Url
   *
   * Image URL for Image-to-Video task
   */
  image_url: string
  /**
   * Constant Rate Factor
   *
   * The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.
   */
  constant_rate_factor?: number
  /**
   * First Pass Skip Final Steps
   *
   * Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.
   */
  first_pass_skip_final_steps?: number
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number
}

/**
 * ImageToVideoOutput
 */
export type SchemaLtxVideo13bDistilledImageToVideoOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * ImageToVideoInput
 */
export type SchemaLtxVideo13bDevImageToVideoInput = {
  /**
   * Second Pass Skip Initial Steps
   *
   * The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.
   */
  second_pass_skip_initial_steps?: number
  /**
   * First Pass Num Inference Steps
   *
   * Number of inference steps during the first pass.
   */
  first_pass_num_inference_steps?: number
  /**
   * Frame Rate
   *
   * The frame rate of the video.
   */
  frame_rate?: number
  /**
   * Prompt
   *
   * Text prompt to guide generation
   */
  prompt: string
  /**
   * Reverse Video
   *
   * Whether to reverse the video.
   */
  reverse_video?: boolean
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt using a language model.
   */
  expand_prompt?: boolean
  /**
   * Loras
   *
   * LoRA weights to use for generation
   */
  loras?: Array<SchemaLoRaWeight>
  /**
   * Second Pass Num Inference Steps
   *
   * Number of inference steps during the second pass.
   */
  second_pass_num_inference_steps?: number
  /**
   * Num Frames
   *
   * The number of frames in the video.
   */
  num_frames?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * Negative prompt for generation
   */
  negative_prompt?: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p or 720p).
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the video.
   */
  aspect_ratio?: '9:16' | '1:1' | '16:9' | 'auto'
  /**
   * Image Url
   *
   * Image URL for Image-to-Video task
   */
  image_url: string
  /**
   * Constant Rate Factor
   *
   * The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.
   */
  constant_rate_factor?: number
  /**
   * First Pass Skip Final Steps
   *
   * Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.
   */
  first_pass_skip_final_steps?: number
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number
}

/**
 * ImageToVideoOutput
 */
export type SchemaLtxVideo13bDevImageToVideoOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * ImageToVideoInput
 *
 * Request model for image-to-video generation.
 */
export type SchemaLtxVideoLoraImageToVideoInput = {
  /**
   * Number Of Steps
   *
   * The number of inference steps to use.
   */
  number_of_steps?: number
  /**
   * Resolution
   *
   * The resolution of the video.
   */
  resolution?: '480p' | '720p'
  /**
   * Reverse Video
   *
   * Whether to reverse the video.
   */
  reverse_video?: boolean
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the video.
   */
  aspect_ratio?: '16:9' | '1:1' | '9:16' | 'auto'
  /**
   * Frame Rate
   *
   * The frame rate of the video.
   */
  frame_rate?: number
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt using the LLM.
   */
  expand_prompt?: boolean
  /**
   * Number Of Frames
   *
   * The number of frames in the video.
   */
  number_of_frames?: number
  /**
   * Image Url
   *
   * The URL of the image to use as input.
   */
  image_url: string
  /**
   * Loras
   *
   * The LoRA weights to use for generation.
   */
  loras?: Array<SchemaLoRaWeight>
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * The seed to use for generation.
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to use.
   */
  negative_prompt?: string
}

/**
 * ImageToVideoOutput
 */
export type SchemaLtxVideoLoraImageToVideoOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video.
   */
  video: SchemaFile
}

/**
 * TransitionRequest
 */
export type SchemaPixverseV45TransitionInput = {
  /**
   * First Image Url
   *
   * URL of the image to use as the first frame
   */
  first_image_url: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Prompt
   *
   * The prompt for the transition
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '8'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * End Image Url
   *
   * URL of the image to use as the last frame
   */
  end_image_url?: string
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * TransitionOutput
 */
export type SchemaPixverseV45TransitionOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * FastImageToVideoRequestV4
 */
export type SchemaPixverseV45ImageToVideoFastInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Camera Movement
   *
   * The type of camera movement to apply to the video
   */
  camera_movement?:
    | 'horizontal_left'
    | 'horizontal_right'
    | 'vertical_up'
    | 'vertical_down'
    | 'zoom_in'
    | 'zoom_out'
    | 'crane_up'
    | 'quickly_zoom_in'
    | 'quickly_zoom_out'
    | 'smooth_zoom_in'
    | 'camera_rotation'
    | 'robo_arm'
    | 'super_dolly_out'
    | 'whip_pan'
    | 'hitchcock'
    | 'left_follow'
    | 'right_follow'
    | 'pan_left'
    | 'pan_right'
    | 'fix_bg'
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * I2VOutputV4
 */
export type SchemaPixverseV45ImageToVideoFastOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * EffectInput
 */
export type SchemaPixverseV45EffectsInput = {
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '8'
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Effect
   *
   * The effect to apply to the video
   */
  effect:
    | 'Kiss Me AI'
    | 'Kiss'
    | 'Muscle Surge'
    | 'Warmth of Jesus'
    | 'Anything, Robot'
    | 'The Tiger Touch'
    | 'Hug'
    | 'Holy Wings'
    | 'Microwave'
    | 'Zombie Mode'
    | 'Squid Game'
    | 'Baby Face'
    | 'Black Myth: Wukong'
    | 'Long Hair Magic'
    | 'Leggy Run'
    | 'Fin-tastic Mermaid'
    | 'Punch Face'
    | 'Creepy Devil Smile'
    | 'Thunder God'
    | 'Eye Zoom Challenge'
    | "Who's Arrested?"
    | 'Baby Arrived'
    | 'Werewolf Rage'
    | 'Bald Swipe'
    | 'BOOM DROP'
    | 'Huge Cutie'
    | 'Liquid Metal'
    | 'Sharksnap!'
    | 'Dust Me Away'
    | '3D Figurine Factor'
    | 'Bikini Up'
    | 'My Girlfriends'
    | 'My Boyfriends'
    | 'Subject 3 Fever'
    | 'Earth Zoom'
    | 'Pole Dance'
    | 'Vroom Dance'
    | 'GhostFace Terror'
    | 'Dragon Evoker'
    | 'Skeletal Bae'
    | 'Summoning succubus'
    | 'Halloween Voodoo Doll'
    | '3D Naked-Eye AD'
    | 'Package Explosion'
    | 'Dishes Served'
    | 'Ocean ad'
    | 'Supermarket AD'
    | 'Tree doll'
    | 'Come Feel My Abs'
    | 'The Bicep Flex'
    | 'London Elite Vibe'
    | 'Flora Nymph Gown'
    | 'Christmas Costume'
    | "It's Snowy"
    | 'Reindeer Cruiser'
    | 'Snow Globe Maker'
    | 'Pet Christmas Outfit'
    | 'Adopt a Polar Pal'
    | 'Cat Christmas Box'
    | 'Starlight Gift Box'
    | 'Xmas Poster'
    | 'Pet Christmas Tree'
    | 'City Santa Hat'
    | 'Stocking Sweetie'
    | 'Christmas Night'
    | 'Xmas Front Page Karma'
    | "Grinch's Xmas Hijack"
    | 'Giant Product'
    | 'Truck Fashion Shoot'
    | 'Beach AD'
    | 'Shoal Surround'
    | 'Mechanical Assembly'
    | 'Lighting AD'
    | 'Billboard AD'
    | 'Product close-up'
    | 'Parachute Delivery'
    | 'Dreamlike Cloud'
    | 'Macaron Machine'
    | 'Poster AD'
    | 'Truck AD'
    | 'Graffiti AD'
    | '3D Figurine Factory'
    | 'The Exclusive First Class'
    | 'Art Zoom Challenge'
    | 'I Quit'
    | 'Hitchcock Dolly Zoom'
    | 'Smell the Lens'
    | 'I believe I can fly'
    | 'Strikout Dance'
    | 'Pixel World'
    | 'Mint in Box'
    | 'Hands up, Hand'
    | 'Flora Nymph Go'
    | 'Somber Embrace'
    | 'Beam me up'
    | 'Suit Swagger'
  /**
   * Image Url
   *
   * Optional URL of the image to use as the first frame. If not provided, generates from text
   */
  image_url: string
}

/**
 * EffectOutput
 */
export type SchemaPixverseV45EffectsOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * HunyuanCustomRequest
 */
export type SchemaHunyuanCustomInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation (max 500 characters).
   */
  prompt: string
  /**
   * Aspect Ratio (W:H)
   *
   * The aspect ratio of the video to generate.
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.
   */
  resolution?: '512p' | '720p'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Image Url
   *
   * URL of the image input.
   */
  image_url: string
  /**
   * Frames per second
   *
   * The frames per second of the generated video.
   */
  fps?: number
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * The seed to use for generating the video.
   */
  seed?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to run. Lower gets faster results, higher gets better results.
   */
  num_inference_steps?: number
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * CFG Scale
   *
   * Classifier-Free Guidance scale for the generation.
   */
  cfg_scale?: number
}

/**
 * HunyuanCustomResponse
 */
export type SchemaHunyuanCustomOutput = {
  /**
   * Seed
   *
   * The seed used for generating the video.
   */
  seed: number
  /**
   * Video
   */
  video: SchemaFile
}

/**
 * FramePackF1Request
 */
export type SchemaFramepackF1Input = {
  /**
   * Prompt
   *
   * Text prompt for video generation (max 500 characters).
   */
  prompt: string
  /**
   * Aspect Ratio (W:H)
   *
   * The aspect ratio of the video to generate.
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.
   */
  resolution?: '720p' | '480p'
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Image Url
   *
   * URL of the image input.
   */
  image_url: string
  /**
   * Guidance Scale
   *
   * Guidance scale for the generation.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * The seed to use for generating the video.
   */
  seed?: number | unknown
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * CFG Scale
   *
   * Classifier-Free Guidance scale for the generation.
   */
  cfg_scale?: number
}

/**
 * FramePackF1Response
 */
export type SchemaFramepackF1Output = {
  /**
   * Seed
   *
   * The seed used for generating the video.
   */
  seed: number
  video: SchemaFile
}

/**
 * Q1StartEndToVideoRequest
 */
export type SchemaViduQ1StartEndToVideoInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 1500 characters
   */
  prompt: string
  /**
   * Start Image Url
   *
   * URL of the image to use as the first frame
   */
  start_image_url: string
  /**
   * Movement Amplitude
   *
   * The movement amplitude of objects in the frame
   */
  movement_amplitude?: 'auto' | 'small' | 'medium' | 'large'
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number
  /**
   * End Image Url
   *
   * URL of the image to use as the last frame
   */
  end_image_url: string
}

/**
 * Q1StartEndToVideoOutput
 */
export type SchemaViduQ1StartEndToVideoOutput = {
  /**
   * Video
   *
   * The generated transition video between start and end frames using the Q1 model
   */
  video: SchemaFile
}

/**
 * Q1ImageToVideoRequest
 */
export type SchemaViduQ1ImageToVideoInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 1500 characters
   */
  prompt: string
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number
  /**
   * Movement Amplitude
   *
   * The movement amplitude of objects in the frame
   */
  movement_amplitude?: 'auto' | 'small' | 'medium' | 'large'
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * Q1ImageToVideoOutput
 */
export type SchemaViduQ1ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video using the Q1 model from a single image
   */
  video: SchemaFile
}

/**
 * MagiImageToVideoRequest
 */
export type SchemaMagiImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16' | '1:1'
  /**
   * Image Url
   *
   * URL of the input image to represent the first frame of the video. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: 4 | 8 | 16 | 32 | 64
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Num Frames
   *
   * Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.
   */
  num_frames?: number
}

/**
 * MagiImageToVideoResponse
 */
export type SchemaMagiImageToVideoOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * EffectInput
 */
export type SchemaPixverseV4EffectsInput = {
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '8'
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Effect
   *
   * The effect to apply to the video
   */
  effect:
    | 'Kiss Me AI'
    | 'Kiss'
    | 'Muscle Surge'
    | 'Warmth of Jesus'
    | 'Anything, Robot'
    | 'The Tiger Touch'
    | 'Hug'
    | 'Holy Wings'
    | 'Microwave'
    | 'Zombie Mode'
    | 'Squid Game'
    | 'Baby Face'
    | 'Black Myth: Wukong'
    | 'Long Hair Magic'
    | 'Leggy Run'
    | 'Fin-tastic Mermaid'
    | 'Punch Face'
    | 'Creepy Devil Smile'
    | 'Thunder God'
    | 'Eye Zoom Challenge'
    | "Who's Arrested?"
    | 'Baby Arrived'
    | 'Werewolf Rage'
    | 'Bald Swipe'
    | 'BOOM DROP'
    | 'Huge Cutie'
    | 'Liquid Metal'
    | 'Sharksnap!'
    | 'Dust Me Away'
    | '3D Figurine Factor'
    | 'Bikini Up'
    | 'My Girlfriends'
    | 'My Boyfriends'
    | 'Subject 3 Fever'
    | 'Earth Zoom'
    | 'Pole Dance'
    | 'Vroom Dance'
    | 'GhostFace Terror'
    | 'Dragon Evoker'
    | 'Skeletal Bae'
    | 'Summoning succubus'
    | 'Halloween Voodoo Doll'
    | '3D Naked-Eye AD'
    | 'Package Explosion'
    | 'Dishes Served'
    | 'Ocean ad'
    | 'Supermarket AD'
    | 'Tree doll'
    | 'Come Feel My Abs'
    | 'The Bicep Flex'
    | 'London Elite Vibe'
    | 'Flora Nymph Gown'
    | 'Christmas Costume'
    | "It's Snowy"
    | 'Reindeer Cruiser'
    | 'Snow Globe Maker'
    | 'Pet Christmas Outfit'
    | 'Adopt a Polar Pal'
    | 'Cat Christmas Box'
    | 'Starlight Gift Box'
    | 'Xmas Poster'
    | 'Pet Christmas Tree'
    | 'City Santa Hat'
    | 'Stocking Sweetie'
    | 'Christmas Night'
    | 'Xmas Front Page Karma'
    | "Grinch's Xmas Hijack"
    | 'Giant Product'
    | 'Truck Fashion Shoot'
    | 'Beach AD'
    | 'Shoal Surround'
    | 'Mechanical Assembly'
    | 'Lighting AD'
    | 'Billboard AD'
    | 'Product close-up'
    | 'Parachute Delivery'
    | 'Dreamlike Cloud'
    | 'Macaron Machine'
    | 'Poster AD'
    | 'Truck AD'
    | 'Graffiti AD'
    | '3D Figurine Factory'
    | 'The Exclusive First Class'
    | 'Art Zoom Challenge'
    | 'I Quit'
    | 'Hitchcock Dolly Zoom'
    | 'Smell the Lens'
    | 'I believe I can fly'
    | 'Strikout Dance'
    | 'Pixel World'
    | 'Mint in Box'
    | 'Hands up, Hand'
    | 'Flora Nymph Go'
    | 'Somber Embrace'
    | 'Beam me up'
    | 'Suit Swagger'
  /**
   * Image Url
   *
   * Optional URL of the image to use as the first frame. If not provided, generates from text
   */
  image_url: string
}

/**
 * EffectOutput
 */
export type SchemaPixverseV4EffectsOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * MagiImageToVideoRequest
 */
export type SchemaMagiDistilledImageToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16' | '1:1'
  /**
   * Image Url
   *
   * URL of the input image to represent the first frame of the video. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: 4 | 8 | 16 | 32
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Num Frames
   *
   * Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.
   */
  num_frames?: number
}

/**
 * MagiImageToVideoResponse
 */
export type SchemaMagiDistilledImageToVideoOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * FramePackF2LFRequest
 */
export type SchemaFramepackFlf2vInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation (max 500 characters).
   */
  prompt: string
  /**
   * Aspect Ratio (W:H)
   *
   * The aspect ratio of the video to generate.
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.
   */
  resolution?: '720p' | '480p'
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Image Url
   *
   * URL of the image input.
   */
  image_url: string
  /**
   * Strength of last frame
   *
   * Determines the influence of the final frame on the generated video. Higher values result in the output being more heavily influenced by the last frame.
   */
  strength?: number
  /**
   * Guidance Scale
   *
   * Guidance scale for the generation.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * The seed to use for generating the video.
   */
  seed?: number | unknown
  /**
   * End Image Url
   *
   * URL of the end image input.
   */
  end_image_url: string
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * CFG Scale
   *
   * Classifier-Free Guidance scale for the generation.
   */
  cfg_scale?: number
}

/**
 * FramePackFLF2VResponse
 */
export type SchemaFramepackFlf2vOutput = {
  /**
   * Seed
   *
   * The seed used for generating the video.
   */
  seed: number
  video: SchemaFile
}

/**
 * WanFLF2VRequest
 */
export type SchemaWanFlf2vInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Shift
   *
   * Shift parameter for video generation.
   */
  shift?: number
  /**
   * Acceleration
   *
   * Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Frames Per Second
   *
   * Frames per second of the generated video. Must be between 5 to 24.
   */
  frames_per_second?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Start Image Url
   *
   * URL of the starting image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  start_image_url: string
  /**
   * End Image Url
   *
   * URL of the ending image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  end_image_url: string
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Num Frames
   *
   * Number of frames to generate. Must be between 81 to 100 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.
   */
  num_frames?: number
  /**
   * Resolution
   *
   * Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16' | '1:1'
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Guide Scale
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guide_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
}

/**
 * WanFLF2VResponse
 */
export type SchemaWanFlf2vOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * FramePackRequest
 */
export type SchemaFramepackInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation (max 500 characters).
   */
  prompt: string
  /**
   * Aspect Ratio (W:H)
   *
   * The aspect ratio of the video to generate.
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.
   */
  resolution?: '720p' | '480p'
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Image Url
   *
   * URL of the image input.
   */
  image_url: string
  /**
   * Guidance Scale
   *
   * Guidance scale for the generation.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * The seed to use for generating the video.
   */
  seed?: number | unknown
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * CFG Scale
   *
   * Classifier-Free Guidance scale for the generation.
   */
  cfg_scale?: number
}

/**
 * FramePackResponse
 */
export type SchemaFramepackOutput = {
  /**
   * Seed
   *
   * The seed used for generating the video.
   */
  seed: number
  video: SchemaFile
}

/**
 * FastImageToVideoRequestV4
 */
export type SchemaPixverseV4ImageToVideoFastInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Camera Movement
   *
   * The type of camera movement to apply to the video
   */
  camera_movement?:
    | 'horizontal_left'
    | 'horizontal_right'
    | 'vertical_up'
    | 'vertical_down'
    | 'zoom_in'
    | 'zoom_out'
    | 'crane_up'
    | 'quickly_zoom_in'
    | 'quickly_zoom_out'
    | 'smooth_zoom_in'
    | 'camera_rotation'
    | 'robo_arm'
    | 'super_dolly_out'
    | 'whip_pan'
    | 'hitchcock'
    | 'left_follow'
    | 'right_follow'
    | 'pan_left'
    | 'pan_right'
    | 'fix_bg'
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * I2VOutputV4
 */
export type SchemaPixverseV4ImageToVideoFastOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * ImageToVideoRequestV4
 */
export type SchemaPixverseV4ImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Duration
   *
   * The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds
   */
  duration?: '5' | '8'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Camera Movement
   *
   * The type of camera movement to apply to the video
   */
  camera_movement?:
    | 'horizontal_left'
    | 'horizontal_right'
    | 'vertical_up'
    | 'vertical_down'
    | 'zoom_in'
    | 'zoom_out'
    | 'crane_up'
    | 'quickly_zoom_in'
    | 'quickly_zoom_out'
    | 'smooth_zoom_in'
    | 'camera_rotation'
    | 'robo_arm'
    | 'super_dolly_out'
    | 'whip_pan'
    | 'hitchcock'
    | 'left_follow'
    | 'right_follow'
    | 'pan_left'
    | 'pan_right'
    | 'fix_bg'
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * I2VOutputV4
 */
export type SchemaPixverseV4ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * EffectInput
 */
export type SchemaPixverseV35EffectsInput = {
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '8'
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Effect
   *
   * The effect to apply to the video
   */
  effect:
    | 'Kiss Me AI'
    | 'Kiss'
    | 'Muscle Surge'
    | 'Warmth of Jesus'
    | 'Anything, Robot'
    | 'The Tiger Touch'
    | 'Hug'
    | 'Holy Wings'
    | 'Microwave'
    | 'Zombie Mode'
    | 'Squid Game'
    | 'Baby Face'
    | 'Black Myth: Wukong'
    | 'Long Hair Magic'
    | 'Leggy Run'
    | 'Fin-tastic Mermaid'
    | 'Punch Face'
    | 'Creepy Devil Smile'
    | 'Thunder God'
    | 'Eye Zoom Challenge'
    | "Who's Arrested?"
    | 'Baby Arrived'
    | 'Werewolf Rage'
    | 'Bald Swipe'
    | 'BOOM DROP'
    | 'Huge Cutie'
    | 'Liquid Metal'
    | 'Sharksnap!'
    | 'Dust Me Away'
    | '3D Figurine Factor'
    | 'Bikini Up'
    | 'My Girlfriends'
    | 'My Boyfriends'
    | 'Subject 3 Fever'
    | 'Earth Zoom'
    | 'Pole Dance'
    | 'Vroom Dance'
    | 'GhostFace Terror'
    | 'Dragon Evoker'
    | 'Skeletal Bae'
    | 'Summoning succubus'
    | 'Halloween Voodoo Doll'
    | '3D Naked-Eye AD'
    | 'Package Explosion'
    | 'Dishes Served'
    | 'Ocean ad'
    | 'Supermarket AD'
    | 'Tree doll'
    | 'Come Feel My Abs'
    | 'The Bicep Flex'
    | 'London Elite Vibe'
    | 'Flora Nymph Gown'
    | 'Christmas Costume'
    | "It's Snowy"
    | 'Reindeer Cruiser'
    | 'Snow Globe Maker'
    | 'Pet Christmas Outfit'
    | 'Adopt a Polar Pal'
    | 'Cat Christmas Box'
    | 'Starlight Gift Box'
    | 'Xmas Poster'
    | 'Pet Christmas Tree'
    | 'City Santa Hat'
    | 'Stocking Sweetie'
    | 'Christmas Night'
    | 'Xmas Front Page Karma'
    | "Grinch's Xmas Hijack"
    | 'Giant Product'
    | 'Truck Fashion Shoot'
    | 'Beach AD'
    | 'Shoal Surround'
    | 'Mechanical Assembly'
    | 'Lighting AD'
    | 'Billboard AD'
    | 'Product close-up'
    | 'Parachute Delivery'
    | 'Dreamlike Cloud'
    | 'Macaron Machine'
    | 'Poster AD'
    | 'Truck AD'
    | 'Graffiti AD'
    | '3D Figurine Factory'
    | 'The Exclusive First Class'
    | 'Art Zoom Challenge'
    | 'I Quit'
    | 'Hitchcock Dolly Zoom'
    | 'Smell the Lens'
    | 'I believe I can fly'
    | 'Strikout Dance'
    | 'Pixel World'
    | 'Mint in Box'
    | 'Hands up, Hand'
    | 'Flora Nymph Go'
    | 'Somber Embrace'
    | 'Beam me up'
    | 'Suit Swagger'
  /**
   * Image Url
   *
   * Optional URL of the image to use as the first frame. If not provided, generates from text
   */
  image_url: string
}

/**
 * EffectOutput
 */
export type SchemaPixverseV35EffectsOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * TransitionRequest
 */
export type SchemaPixverseV35TransitionInput = {
  /**
   * First Image Url
   *
   * URL of the image to use as the first frame
   */
  first_image_url: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Prompt
   *
   * The prompt for the transition
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '8'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * End Image Url
   *
   * URL of the image to use as the last frame
   */
  end_image_url?: string
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * TransitionOutput
 */
export type SchemaPixverseV35TransitionOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * Ray2ImageToVideoRequest
 */
export type SchemaLumaDreamMachineRay2FlashImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '9:16' | '4:3' | '3:4' | '21:9' | '9:21'
  /**
   * Resolution
   *
   * The resolution of the generated video (720p costs 2x more, 1080p costs 4x more)
   */
  resolution?: '540p' | '720p' | '1080p'
  /**
   * Loop
   *
   * Whether the video should loop (end of video is blended with the beginning)
   */
  loop?: boolean
  /**
   * Duration
   *
   * The duration of the generated video
   */
  duration?: '5s' | '9s'
  /**
   * Image Url
   *
   * Initial image to start the video from. Can be used together with end_image_url.
   */
  image_url?: string
  /**
   * End Image Url
   *
   * Final image to end the video with. Can be used together with image_url.
   */
  end_image_url?: string
}

/**
 * Ray2I2VOutput
 */
export type SchemaLumaDreamMachineRay2FlashImageToVideoOutput = {
  /**
   * Video
   *
   * URL of the generated video
   */
  video: SchemaFile
}

/**
 * PikaffectsRequest
 *
 * Request model for Pikaffects endpoint
 */
export type SchemaPikaV15PikaffectsInput = {
  /**
   * Pikaffect
   *
   * The Pikaffect to apply
   */
  pikaffect:
    | 'Cake-ify'
    | 'Crumble'
    | 'Crush'
    | 'Decapitate'
    | 'Deflate'
    | 'Dissolve'
    | 'Explode'
    | 'Eye-pop'
    | 'Inflate'
    | 'Levitate'
    | 'Melt'
    | 'Peel'
    | 'Poke'
    | 'Squish'
    | 'Ta-da'
    | 'Tear'
  /**
   * Prompt
   *
   * Text prompt to guide the effect
   */
  prompt?: string
  /**
   * Seed
   *
   * The seed for the random number generator
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to guide the model
   */
  negative_prompt?: string
  /**
   * Image Url
   *
   * URL of the input image
   */
  image_url: string
}

/**
 * PikaffectsOutput
 *
 * Output from Pikaffects generation
 */
export type SchemaPikaV15PikaffectsOutput = {
  /**
   * Video
   *
   * The generated video with applied effect
   */
  video: SchemaFile
}

/**
 * ImageToVideoTurboInput
 *
 * Base request for image-to-video generation
 */
export type SchemaPikaV2TurboImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '720p' | '1080p'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: number
  /**
   * Seed
   *
   * The seed for the random number generator
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the model
   */
  negative_prompt?: string
  /**
   * Image Url
   */
  image_url: string
}

/**
 * TurboImageToVideoOutput
 *
 * Output model for all video generation endpoints
 */
export type SchemaPikaV2TurboImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * Pika22PikascenesRequest
 *
 * Request model for Pika 2.2 Pikascenes (collection-to-video) generation
 */
export type SchemaPikaV22PikascenesInput = {
  /**
   * Prompt
   *
   * Text prompt describing the desired video
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1' | '4:5' | '5:4' | '3:2' | '2:3'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: 5 | 10
  /**
   * Ingredients Mode
   *
   * Mode for integrating multiple images. Precise mode is more accurate, creative mode is more creative.
   */
  ingredients_mode?: 'precise' | 'creative'
  /**
   * Seed
   *
   * The seed for the random number generator
   */
  seed?: number
  /**
   * Image Urls
   *
   * URLs of images to combine into a video
   */
  image_urls: Array<string>
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the model
   */
  negative_prompt?: string
}

/**
 * Pika22PikascenesOutput
 *
 * Output model for Pika 2.2 Pikascenes generation
 */
export type SchemaPikaV22PikascenesOutput = {
  /**
   * Video
   *
   * The generated video combining multiple images
   */
  video: SchemaFile
}

/**
 * Pika22ImageToVideoRequest
 *
 * Request model for Pika 2.2 image-to-video generation
 */
export type SchemaPikaV22ImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '720p' | '1080p'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: 5 | 10
  /**
   * Seed
   *
   * The seed for the random number generator
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the model
   */
  negative_prompt?: string
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * Pika22ImageToVideoOutput
 *
 * Output model for Pika 2.2 image-to-video generation
 */
export type SchemaPikaV22ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * ImageToVideov21Input
 *
 * Base request for image-to-video generation
 */
export type SchemaPikaV21ImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '720p' | '1080p'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: number
  /**
   * Seed
   *
   * The seed for the random number generator
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the model
   */
  negative_prompt?: string
  /**
   * Image Url
   */
  image_url: string
}

/**
 * ImageToVideoV21Output
 *
 * Output from image-to-video generation
 */
export type SchemaPikaV21ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * ImageToVideoRequest
 */
export type SchemaViduImageToVideoInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 1500 characters
   */
  prompt: string
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number
  /**
   * Movement Amplitude
   *
   * The movement amplitude of objects in the frame
   */
  movement_amplitude?: 'auto' | 'small' | 'medium' | 'large'
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * VideoOutput
 */
export type SchemaViduImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * StartEndToVideoRequest
 */
export type SchemaViduStartEndToVideoInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 1500 characters
   */
  prompt: string
  /**
   * Start Image Url
   *
   * URL of the image to use as the first frame
   */
  start_image_url: string
  /**
   * Movement Amplitude
   *
   * The movement amplitude of objects in the frame
   */
  movement_amplitude?: 'auto' | 'small' | 'medium' | 'large'
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number
  /**
   * End Image Url
   *
   * URL of the image to use as the last frame
   */
  end_image_url: string
}

/**
 * StartEndToVideoOutput
 */
export type SchemaViduStartEndToVideoOutput = {
  /**
   * Video
   *
   * The generated transition video between start and end frames
   */
  video: SchemaFile
}

/**
 * ReferenceToVideoRequest
 */
export type SchemaViduReferenceToVideoInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 1500 characters
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the output video
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Reference Image Urls
   *
   * URLs of the reference images to use for consistent subject appearance
   */
  reference_image_urls: Array<string>
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number
  /**
   * Movement Amplitude
   *
   * The movement amplitude of objects in the frame
   */
  movement_amplitude?: 'auto' | 'small' | 'medium' | 'large'
}

/**
 * ReferenceToVideoOutput
 */
export type SchemaViduReferenceToVideoOutput = {
  /**
   * Video
   *
   * The generated video with consistent subjects from reference images
   */
  video: SchemaFile
}

/**
 * TemplateToVideoRequest
 */
export type SchemaViduTemplateToVideoInput = {
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the output video
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Template
   *
   * AI video template to use. Pricing varies by template: Standard templates (hug, kiss, love_pose, etc.) cost 4 credits ($0.20), Premium templates (lunar_newyear, dynasty_dress, dreamy_wedding, etc.) cost 6 credits ($0.30), and Advanced templates (live_photo) cost 10 credits ($0.50).
   */
  template?:
    | 'dreamy_wedding'
    | 'romantic_lift'
    | 'sweet_proposal'
    | 'couple_arrival'
    | 'cupid_arrow'
    | 'pet_lovers'
    | 'lunar_newyear'
    | 'hug'
    | 'kiss'
    | 'dynasty_dress'
    | 'wish_sender'
    | 'love_pose'
    | 'hair_swap'
    | 'youth_rewind'
    | 'morphlab'
    | 'live_photo'
    | 'emotionlab'
    | 'live_memory'
    | 'interaction'
    | 'christmas'
    | 'pet_finger'
    | 'eat_mushrooms'
    | 'beast_chase_library'
    | 'beast_chase_supermarket'
    | 'petal_scattered'
    | 'emoji_figure'
    | 'hair_color_change'
    | 'multiple_people_kissing'
    | 'beast_chase_amazon'
    | 'beast_chase_mountain'
    | 'balloonman_explodes_pro'
    | 'get_thinner'
    | 'jump2pool'
    | 'bodyshake'
    | 'jiggle_up'
    | 'shake_it_dance'
    | 'subject_3'
    | 'pubg_winner_hit'
    | 'shake_it_down'
    | 'blueprint_supreme'
    | 'hip_twist'
    | 'motor_dance'
    | 'rat_dance'
    | 'kwok_dance'
    | 'leg_sweep_dance'
    | 'heeseung_march'
    | 'shake_to_max'
    | 'dame_un_grrr'
    | 'i_know'
    | 'lit_bounce'
    | 'wave_dance'
    | 'chill_dance'
    | 'hip_flicking'
    | 'sakura_season'
    | 'zongzi_wrap'
    | 'zongzi_drop'
    | 'dragonboat_shot'
    | 'rain_kiss'
    | 'child_memory'
    | 'couple_drop'
    | 'couple_walk'
    | 'flower_receive'
    | 'love_drop'
    | 'cheek_kiss'
    | 'carry_me'
    | 'blow_kiss'
    | 'love_fall'
    | 'french_kiss_8s'
    | 'workday_feels'
    | 'love_story'
    | 'bloom_magic'
    | 'ghibli'
    | 'minecraft'
    | 'box_me'
    | 'claw_me'
    | 'clayshot'
    | 'manga_meme'
    | 'quad_meme'
    | 'pixel_me'
    | 'clayshot_duo'
    | 'irasutoya'
    | 'american_comic'
    | 'simpsons_comic'
    | 'yayoi_kusama_style'
    | 'pop_art'
    | 'jojo_style'
    | 'slice_therapy'
    | 'balloon_flyaway'
    | 'flying'
    | 'paperman'
    | 'pinch'
    | 'bloom_doorobear'
    | 'gender_swap'
    | 'nap_me'
    | 'sexy_me'
    | 'spin360'
    | 'smooth_shift'
    | 'paper_fall'
    | 'jump_to_cloud'
    | 'pilot'
    | 'sweet_dreams'
    | 'soul_depart'
    | 'punch_hit'
    | 'watermelon_hit'
    | 'split_stance_pet'
    | 'make_face'
    | 'break_glass'
    | 'split_stance_human'
    | 'covered_liquid_metal'
    | 'fluffy_plunge'
    | 'pet_belly_dance'
    | 'water_float'
    | 'relax_cut'
    | 'head_to_balloon'
    | 'cloning'
    | 'across_the_universe_jungle'
    | 'clothes_spinning_remnant'
    | 'across_the_universe_jurassic'
    | 'across_the_universe_moon'
    | 'fisheye_pet'
    | 'hitchcock_zoom'
    | 'cute_bangs'
    | 'earth_zoom_out'
    | 'fisheye_human'
    | 'drive_yacht'
    | 'virtual_singer'
    | 'earth_zoom_in'
    | 'aliens_coming'
    | 'drive_ferrari'
    | 'bjd_style'
    | 'virtual_fitting'
    | 'orbit'
    | 'zoom_in'
    | 'ai_outfit'
    | 'spin180'
    | 'orbit_dolly'
    | 'orbit_dolly_fast'
    | 'auto_spin'
    | 'walk_forward'
    | 'outfit_show'
    | 'zoom_in_fast'
    | 'zoom_out_image'
    | 'zoom_out_startend'
    | 'muscling'
    | 'captain_america'
    | 'hulk'
    | 'cap_walk'
    | 'hulk_dive'
    | 'exotic_princess'
    | 'beast_companion'
    | 'cartoon_doll'
    | 'golden_epoch'
    | 'oscar_gala'
    | 'fashion_stride'
    | 'star_carpet'
    | 'flame_carpet'
    | 'frost_carpet'
    | 'mecha_x'
    | 'style_me'
    | 'tap_me'
    | 'saber_warrior'
    | 'pet2human'
    | 'graduation'
    | 'fishermen'
    | 'happy_birthday'
    | 'fairy_me'
    | 'ladudu_me'
    | 'ladudu_me_random'
    | 'squid_game'
    | 'superman'
    | 'grow_wings'
    | 'clevage'
    | 'fly_with_doraemon'
    | 'creatice_product_down'
    | 'pole_dance'
    | 'hug_from_behind'
    | 'creatice_product_up_cybercity'
    | 'creatice_product_up_bluecircuit'
    | 'creatice_product_up'
    | 'run_fast'
    | 'background_explosion'
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number
  /**
   * Input Image Urls
   *
   * URLs of the images to use with the template. Number of images required varies by template: 'dynasty_dress' and 'shop_frame' accept 1-2 images, 'wish_sender' requires exactly 3 images, all other templates accept only 1 image.
   */
  input_image_urls: Array<string>
}

/**
 * TemplateToVideoOutput
 */
export type SchemaViduTemplateToVideoOutput = {
  /**
   * Video
   *
   * The generated video using a predefined template
   */
  video: SchemaFile
}

/**
 * WanLoRAI2VRequest
 */
export type SchemaWanI2vLoraInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Shift
   *
   * Shift parameter for video generation.
   */
  shift?: number
  /**
   * Reverse Video
   *
   * If true, the video will be reversed.
   */
  reverse_video?: boolean
  /**
   * Loras
   *
   * LoRA weights to be used in the inference.
   */
  loras?: Array<SchemaLoraWeight>
  /**
   * Frames Per Second
   *
   * Frames per second of the generated video. Must be between 5 to 24.
   */
  frames_per_second?: number
  /**
   * Turbo Mode
   *
   * If true, the video will be generated faster with no noticeable degradation in the visual quality.
   */
  turbo_mode?: boolean
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Frames
   *
   * Number of frames to generate. Must be between 81 to 100 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.
   */
  num_frames?: number
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the output video.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16' | '1:1'
  /**
   * Resolution
   *
   * Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.
   */
  resolution?: '480p' | '720p'
  /**
   * Image Url
   *
   * URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Guide Scale
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guide_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
}

/**
 * WanI2VResponse
 */
export type SchemaWanI2vLoraOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * LoraWeight
 */
export type SchemaLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
}

/**
 * HunyuanVideoRequest
 */
export type SchemaHunyuanVideoImageToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Aspect Ratio (W:H)
   *
   * The aspect ratio of the video to generate.
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the video to generate.
   */
  resolution?: '720p'
  /**
   * Image Url
   *
   * URL of the image input.
   */
  image_url: string
  /**
   * Seed
   *
   * The seed to use for generating the video.
   */
  seed?: number
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: '129'
  /**
   * I2V Stability
   *
   * Turning on I2V Stability reduces hallucination but also reduces motion.
   */
  i2v_stability?: boolean
}

/**
 * HunyuanI2VResponse
 */
export type SchemaHunyuanVideoImageToVideoOutput = {
  /**
   * Seed
   *
   * The seed used for generating the video.
   */
  seed: number
  video: SchemaFile
}

/**
 * ImageToVideoDirectorRequest
 */
export type SchemaMinimaxVideo01DirectorImageToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Prompt
   *
   * Text prompt for video generation. Camera movement instructions can be added using square brackets (e.g. [Pan left] or [Zoom in]). You can use up to 3 combined movements per prompt. Supported movements: Truck left/right, Pan left/right, Push in/Pull out, Pedestal up/down, Tilt up/down, Zoom in/out, Shake, Tracking shot, Static shot. For example: [Truck left, Pan right, Zoom in]. For a more detailed guide, refer https://sixth-switch-2ac.notion.site/T2V-01-Director-Model-Tutorial-with-camera-movement-1886c20a98eb80f395b8e05291ad8645
   */
  prompt: string
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * I2VDirectorOutput
 */
export type SchemaMinimaxVideo01DirectorImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * SkyreelsI2VRequest
 */
export type SchemaSkyreelsI2vInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the output video
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Image Url
   *
   * URL of the image input.
   */
  image_url: string
  /**
   * Guidance Scale
   *
   * Guidance scale for generation (between 1.0 and 20.0)
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * Random seed for generation. If not provided, a random seed will be used.
   */
  seed?: number
  /**
   * Num Inference Steps
   *
   * Number of denoising steps (between 1 and 50). Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to guide generation away from certain attributes.
   */
  negative_prompt?: string
}

/**
 * SkyreelsI2VResponse
 */
export type SchemaSkyreelsI2vOutput = {
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
  /**
   * Video
   */
  video: SchemaFile
}

/**
 * Ray2ImageToVideoRequest
 */
export type SchemaLumaDreamMachineRay2ImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '9:16' | '4:3' | '3:4' | '21:9' | '9:21'
  /**
   * Resolution
   *
   * The resolution of the generated video (720p costs 2x more, 1080p costs 4x more)
   */
  resolution?: '540p' | '720p' | '1080p'
  /**
   * Loop
   *
   * Whether the video should loop (end of video is blended with the beginning)
   */
  loop?: boolean
  /**
   * Duration
   *
   * The duration of the generated video
   */
  duration?: '5s' | '9s'
  /**
   * Image Url
   *
   * Initial image to start the video from. Can be used together with end_image_url.
   */
  image_url?: string
  /**
   * End Image Url
   *
   * Final image to end the video with. Can be used together with image_url.
   */
  end_image_url?: string
}

/**
 * Ray2I2VOutput
 */
export type SchemaLumaDreamMachineRay2ImageToVideoOutput = {
  /**
   * Video
   *
   * URL of the generated video
   */
  video: SchemaFile
}

/**
 * Input
 */
export type SchemaHunyuanVideoImg2VidLoraInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed to use for generating the video.
   */
  seed?: number
  /**
   * Image URL
   *
   * The URL to the image to generate the video from. The image must be 960x544 or it will get cropped and resized to that size.
   */
  image_url: string
}

/**
 * Output
 */
export type SchemaHunyuanVideoImg2VidLoraOutput = {
  /**
   * Seed
   *
   * The seed used for generating the video.
   */
  seed: number
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * FastImageToVideoRequest
 */
export type SchemaPixverseV35ImageToVideoFastInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * I2VOutput
 */
export type SchemaPixverseV35ImageToVideoFastOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * ImageToVideoRequest
 */
export type SchemaPixverseV35ImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Duration
   *
   * The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds
   */
  duration?: '5' | '8'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * I2VOutput
 */
export type SchemaPixverseV35ImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * SubjectReferenceRequest
 */
export type SchemaMinimaxVideo01SubjectReferenceInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Prompt
   */
  prompt: string
  /**
   * Subject Reference Image Url
   *
   * URL of the subject reference image to use for consistent subject appearance
   */
  subject_reference_image_url: string
}

/**
 * SubjectReferenceOutput
 */
export type SchemaMinimaxVideo01SubjectReferenceOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * ImageToVideoRequest
 */
export type SchemaKlingVideoV16StandardImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Image Url
   */
  image_url: string
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * I2VOutput
 */
export type SchemaKlingVideoV16StandardImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * SadTalkerRefVideoInput
 */
export type SchemaSadtalkerReferenceInput = {
  /**
   * Pose Style
   *
   * The style of the pose
   */
  pose_style?: number
  /**
   * Source Image Url
   *
   * URL of the source image
   */
  source_image_url: string
  /**
   * Reference Pose Video Url
   *
   * URL of the reference video
   */
  reference_pose_video_url: string
  /**
   * Driven Audio Url
   *
   * URL of the driven audio
   */
  driven_audio_url: string
  /**
   * Face Enhancer
   *
   * The type of face enhancer to use
   */
  face_enhancer?: 'gfpgan'
  /**
   * Expression Scale
   *
   * The scale of the expression
   */
  expression_scale?: number
  /**
   * Face Model Resolution
   *
   * The resolution of the face model
   */
  face_model_resolution?: '256' | '512'
  /**
   * Still Mode
   *
   * Whether to use still mode. Fewer head motion, works with preprocess `full`.
   */
  still_mode?: boolean
  /**
   * Preprocess
   *
   * The type of preprocessing to use
   */
  preprocess?: 'crop' | 'extcrop' | 'resize' | 'full' | 'extfull'
}

/**
 * SadTalkerOutput
 */
export type SchemaSadtalkerReferenceOutput = {
  /**
   * Video
   *
   * URL of the generated video
   */
  video: SchemaFile
}

/**
 * ImageToVideoRequest
 */
export type SchemaMinimaxVideo01LiveImageToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Prompt
   */
  prompt: string
  /**
   * Image Url
   *
   * URL of the image to use as the first frame
   */
  image_url: string
}

/**
 * I2VLiveOutput
 */
export type SchemaMinimaxVideo01LiveImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * ImageToVideoInput
 */
export type SchemaLtxVideoImageToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Guidance Scale
   *
   * The guidance scale to use.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * The seed to use for random number generation.
   */
  seed?: number
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to take.
   */
  num_inference_steps?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to generate the video from.
   */
  negative_prompt?: string
  /**
   * Image URL
   *
   * The URL of the image to generate the video from.
   */
  image_url: string
}

/**
 * Output
 */
export type SchemaLtxVideoImageToVideoOutput = {
  /**
   * Seed
   *
   * The seed used for random number generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video.
   */
  video: SchemaFile
}

/**
 * ImageToVideoInput
 */
export type SchemaCogvideox5bImageToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Use Rife
   *
   * Use RIFE for video interpolation
   */
  use_rife?: boolean
  /**
   * Image URL
   *
   * The URL to the image to generate the video from.
   */
  image_url: string
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. We currently support one lora.
   *
   */
  loras?: Array<SchemaLoraWeight>
  /**
   * Video Size
   *
   * The size of the generated video.
   */
  video_size?:
    | SchemaImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related video to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Export Fps
   *
   * The target FPS of the video
   */
  export_fps?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to generate video from
   */
  negative_prompt?: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
}

/**
 * Output
 */
export type SchemaCogvideox5bImageToVideoOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the video.
   */
  prompt: string
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Seed
   *
   *
   * Seed of the generated video. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
  /**
   * Video
   *
   * The URL to the generated video
   */
  video: SchemaFile
}

/**
 * KlingV15ProImageToVideoRequest
 */
export type SchemaKlingVideoV15ProImageToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video frame
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Image Url
   */
  image_url: string
  /**
   * Static Mask Url
   *
   * URL of the image for Static Brush Application Area (Mask image created by users using the motion brush)
   */
  static_mask_url?: string
  /**
   * Dynamic Masks
   *
   * List of dynamic masks
   */
  dynamic_masks?: Array<SchemaDynamicMask>
  /**
   * Tail Image Url
   *
   * URL of the image to be used for the end of the video
   */
  tail_image_url?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * I2VOutput
 */
export type SchemaKlingVideoV15ProImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * DynamicMask
 */
export type SchemaDynamicMask = {
  /**
   * Trajectories
   *
   * List of trajectories
   */
  trajectories?: Array<SchemaTrajectory>
  /**
   * Mask Url
   *
   * URL of the image for Dynamic Brush Application Area (Mask image created by users using the motion brush)
   */
  mask_url: string
}

/**
 * Trajectory
 */
export type SchemaTrajectory = {
  /**
   * Y
   *
   * Y coordinate of the motion trajectory
   */
  y: number
  /**
   * X
   *
   * X coordinate of the motion trajectory
   */
  x: number
}

/**
 * V1ImageToVideoRequest
 */
export type SchemaKlingVideoV1StandardImageToVideoInput = {
  /**
   * Prompt
   *
   * The prompt for the video
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Image Url
   *
   * URL of the image to be used for the video
   */
  image_url: string
  /**
   * Static Mask Url
   *
   * URL of the image for Static Brush Application Area (Mask image created by users using the motion brush)
   */
  static_mask_url?: string
  /**
   * Dynamic Masks
   *
   * List of dynamic masks
   */
  dynamic_masks?: Array<SchemaDynamicMask>
  /**
   * Tail Image Url
   *
   * URL of the image to be used for the end of the video
   */
  tail_image_url?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * KlingV1I2VOutput
 */
export type SchemaKlingVideoV1StandardImageToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * ImageInput
 */
export type SchemaStableVideoInput = {
  /**
   * Motion Bucket Id
   *
   *
   * The motion bucket id determines the motion of the generated video. The
   * higher the number, the more motion there will be.
   *
   */
  motion_bucket_id?: number
  /**
   * Fps
   *
   * The frames per second of the generated video.
   */
  fps?: number
  /**
   * Cond Aug
   *
   *
   * The conditoning augmentation determines the amount of noise that will be
   * added to the conditioning frame. The higher the number, the more noise
   * there will be, and the less the video will look like the initial image.
   * Increase it for more motion.
   *
   */
  cond_aug?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string
}

/**
 * VideoOutput
 */
export type SchemaStableVideoOutput = {
  /**
   * Seed
   *
   * Seed for random number generator
   */
  seed: number
  /**
   * Video
   *
   * Generated video
   */
  video: SchemaFile
}

/**
 * AMTFrameInterpolationInput
 */
export type SchemaAmtInterpolationFrameInterpolationInput = {
  /**
   * Frames
   *
   * Frames to interpolate
   */
  frames: Array<SchemaFrame>
  /**
   * Recursive Interpolation Passes
   *
   * Number of recursive interpolation passes
   */
  recursive_interpolation_passes?: number
  /**
   * Output FPS
   *
   * Output frames per second
   */
  output_fps?: number
}

/**
 * AMTInterpolationOutput
 */
export type SchemaAmtInterpolationFrameInterpolationOutput = {
  /**
   * Video
   *
   * Generated video
   */
  video: SchemaFile
}

/**
 * Frame
 */
export type SchemaFrame = {
  /**
   * URL
   *
   * URL of the frame
   */
  url: string
}

/**
 * LivePortraitInput
 */
export type SchemaLivePortraitInput = {
  /**
   * Smile
   *
   * Amount to smile
   */
  smile?: number
  /**
   * Video Url
   *
   * URL of the video to drive the lip syncing.
   */
  video_url: string
  /**
   * Eyebrow
   *
   * Amount to raise or lower eyebrows
   */
  eyebrow?: number
  /**
   * Flag Stitching
   *
   * Whether to enable stitching. Recommended to set to True.
   */
  flag_stitching?: boolean
  /**
   * Wink
   *
   * Amount to wink
   */
  wink?: number
  /**
   * Rotate Pitch
   *
   * Amount to rotate the face in pitch
   */
  rotate_pitch?: number
  /**
   * Blink
   *
   * Amount to blink the eyes
   */
  blink?: number
  /**
   * Scale
   *
   * Scaling factor for the face crop.
   */
  scale?: number
  /**
   * Eee
   *
   * Amount to shape mouth in 'eee' position
   */
  eee?: number
  /**
   * Flag Pasteback
   *
   * Whether to paste-back/stitch the animated face cropping from the face-cropping space to the original image space.
   */
  flag_pasteback?: boolean
  /**
   * Pupil Y
   *
   * Amount to move pupils vertically
   */
  pupil_y?: number
  /**
   * Rotate Yaw
   *
   * Amount to rotate the face in yaw
   */
  rotate_yaw?: number
  /**
   * Flag Do Rot
   *
   * Whether to conduct the rotation when flag_do_crop is True.
   */
  flag_do_rot?: boolean
  /**
   * Woo
   *
   * Amount to shape mouth in 'woo' position
   */
  woo?: number
  /**
   * Aaa
   *
   * Amount to open mouth in 'aaa' shape
   */
  aaa?: number
  /**
   * Image Url
   *
   * URL of the image to be animated
   */
  image_url: string
  /**
   * Flag Relative
   *
   * Whether to use relative motion.
   */
  flag_relative?: boolean
  /**
   * Flag Eye Retargeting
   *
   * Whether to enable eye retargeting.
   */
  flag_eye_retargeting?: boolean
  /**
   * Flag Lip Zero
   *
   * Whether to set the lip to closed state before animation. Only takes effect when flag_eye_retargeting and flag_lip_retargeting are False.
   */
  flag_lip_zero?: boolean
  /**
   * Batch Size
   *
   * Batch size for the model. The larger the batch size, the faster the model will run, but the more memory it will consume.
   */
  batch_size?: number
  /**
   * Rotate Roll
   *
   * Amount to rotate the face in roll
   */
  rotate_roll?: number
  /**
   * Pupil X
   *
   * Amount to move pupils horizontally
   */
  pupil_x?: number
  /**
   * Vy Ratio
   *
   * Vertical offset ratio for face crop. Positive values move up, negative values move down.
   */
  vy_ratio?: number
  /**
   * Dsize
   *
   * Size of the output image.
   */
  dsize?: number
  /**
   * Enable Safety Checker
   *
   *
   * Whether to enable the safety checker. If enabled, the model will check if the input image contains a face before processing it.
   * The safety checker will process the input image
   *
   */
  enable_safety_checker?: boolean
  /**
   * Vx Ratio
   *
   * Horizontal offset ratio for face crop.
   */
  vx_ratio?: number
  /**
   * Flag Lip Retargeting
   *
   * Whether to enable lip retargeting.
   */
  flag_lip_retargeting?: boolean
  /**
   * Flag Do Crop
   *
   * Whether to crop the source portrait to the face-cropping space.
   */
  flag_do_crop?: boolean
}

/**
 * LivePortraitOutput
 */
export type SchemaLivePortraitOutput = {
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * MuseTalkInput
 */
export type SchemaMusetalkInput = {
  /**
   * Source Video Url
   *
   * URL of the source video
   */
  source_video_url: string
  /**
   * Audio Url
   *
   * URL of the audio
   */
  audio_url: string
}

/**
 * MuseTalkOutput
 */
export type SchemaMusetalkOutput = {
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * SadTalkerInput
 */
export type SchemaSadtalkerInput = {
  /**
   * Pose Style
   *
   * The style of the pose
   */
  pose_style?: number
  /**
   * Source Image Url
   *
   * URL of the source image
   */
  source_image_url: string
  /**
   * Driven Audio Url
   *
   * URL of the driven audio
   */
  driven_audio_url: string
  /**
   * Face Enhancer
   *
   * The type of face enhancer to use
   */
  face_enhancer?: 'gfpgan'
  /**
   * Expression Scale
   *
   * The scale of the expression
   */
  expression_scale?: number
  /**
   * Face Model Resolution
   *
   * The resolution of the face model
   */
  face_model_resolution?: '256' | '512'
  /**
   * Still Mode
   *
   * Whether to use still mode. Fewer head motion, works with preprocess `full`.
   */
  still_mode?: boolean
  /**
   * Preprocess
   *
   * The type of preprocessing to use
   */
  preprocess?: 'crop' | 'extcrop' | 'resize' | 'full' | 'extfull'
}

/**
 * SadTalkerOutput
 */
export type SchemaSadtalkerOutput = {
  /**
   * Video
   *
   * URL of the generated video
   */
  video: SchemaFile
}

/**
 * FastSVDImageInput
 */
export type SchemaFastSvdLcmInput = {
  /**
   * Motion Bucket Id
   *
   *
   * The motion bucket id determines the motion of the generated video. The
   * higher the number, the more motion there will be.
   *
   */
  motion_bucket_id?: number
  /**
   * Fps
   *
   *
   * The FPS of the generated video. The higher the number, the faster the video will
   * play. Total video length is 25 frames.
   *
   */
  fps?: number
  /**
   * Steps
   *
   *
   * The number of steps to run the model for. The higher the number the better
   * the quality and longer it will take to generate.
   *
   */
  steps?: number
  /**
   * Cond Aug
   *
   *
   * The conditoning augmentation determines the amount of noise that will be
   * added to the conditioning frame. The higher the number, the more noise
   * there will be, and the less the video will look like the initial image.
   * Increase it for more motion.
   *
   */
  cond_aug?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string
}

/**
 * FastSVDOutput
 */
export type SchemaFastSvdLcmOutput = {
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   *
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

export type GetFalAiWanEffectsRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/wan-effects/requests/{request_id}/status'
}

export type GetFalAiWanEffectsRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiWanEffectsRequestsByRequestIdStatusResponse =
  GetFalAiWanEffectsRequestsByRequestIdStatusResponses[keyof GetFalAiWanEffectsRequestsByRequestIdStatusResponses]

export type PutFalAiWanEffectsRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan-effects/requests/{request_id}/cancel'
}

export type PutFalAiWanEffectsRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiWanEffectsRequestsByRequestIdCancelResponse =
  PutFalAiWanEffectsRequestsByRequestIdCancelResponses[keyof PutFalAiWanEffectsRequestsByRequestIdCancelResponses]

export type PostFalAiWanEffectsData = {
  body: SchemaWanEffectsInput
  path?: never
  query?: never
  url: '/fal-ai/wan-effects'
}

export type PostFalAiWanEffectsResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiWanEffectsResponse =
  PostFalAiWanEffectsResponses[keyof PostFalAiWanEffectsResponses]

export type GetFalAiWanEffectsRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan-effects/requests/{request_id}'
}

export type GetFalAiWanEffectsRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaWanEffectsOutput
}

export type GetFalAiWanEffectsRequestsByRequestIdResponse =
  GetFalAiWanEffectsRequestsByRequestIdResponses[keyof GetFalAiWanEffectsRequestsByRequestIdResponses]

export type GetFalAiWanProImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/wan-pro/image-to-video/requests/{request_id}/status'
}

export type GetFalAiWanProImageToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiWanProImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiWanProImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiWanProImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiWanProImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan-pro/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiWanProImageToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiWanProImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiWanProImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiWanProImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiWanProImageToVideoData = {
  body: SchemaWanProImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/wan-pro/image-to-video'
}

export type PostFalAiWanProImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiWanProImageToVideoResponse =
  PostFalAiWanProImageToVideoResponses[keyof PostFalAiWanProImageToVideoResponses]

export type GetFalAiWanProImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan-pro/image-to-video/requests/{request_id}'
}

export type GetFalAiWanProImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaWanProImageToVideoOutput
}

export type GetFalAiWanProImageToVideoRequestsByRequestIdResponse =
  GetFalAiWanProImageToVideoRequestsByRequestIdResponses[keyof GetFalAiWanProImageToVideoRequestsByRequestIdResponses]

export type GetFalAiVeo2ImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/veo2/image-to-video/requests/{request_id}/status'
}

export type GetFalAiVeo2ImageToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiVeo2ImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiVeo2ImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiVeo2ImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiVeo2ImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/veo2/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiVeo2ImageToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiVeo2ImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiVeo2ImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiVeo2ImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiVeo2ImageToVideoData = {
  body: SchemaVeo2ImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/veo2/image-to-video'
}

export type PostFalAiVeo2ImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiVeo2ImageToVideoResponse =
  PostFalAiVeo2ImageToVideoResponses[keyof PostFalAiVeo2ImageToVideoResponses]

export type GetFalAiVeo2ImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/veo2/image-to-video/requests/{request_id}'
}

export type GetFalAiVeo2ImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaVeo2ImageToVideoOutput
}

export type GetFalAiVeo2ImageToVideoRequestsByRequestIdResponse =
  GetFalAiVeo2ImageToVideoRequestsByRequestIdResponses[keyof GetFalAiVeo2ImageToVideoRequestsByRequestIdResponses]

export type GetFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/kling-video/v1.6/pro/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/v1.6/pro/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV16ProImageToVideoData = {
  body: SchemaKlingVideoV16ProImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v1.6/pro/image-to-video'
}

export type PostFalAiKlingVideoV16ProImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV16ProImageToVideoResponse =
  PostFalAiKlingVideoV16ProImageToVideoResponses[keyof PostFalAiKlingVideoV16ProImageToVideoResponses]

export type GetFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v1.6/pro/image-to-video/requests/{request_id}'
}

export type GetFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKlingVideoV16ProImageToVideoOutput
}

export type GetFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdResponse =
  GetFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdResponses]

export type GetFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/minimax/video-01/image-to-video/requests/{request_id}/status'
}

export type GetFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax/video-01/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiMinimaxVideo01ImageToVideoData = {
  body: SchemaMinimaxVideo01ImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/minimax/video-01/image-to-video'
}

export type PostFalAiMinimaxVideo01ImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMinimaxVideo01ImageToVideoResponse =
  PostFalAiMinimaxVideo01ImageToVideoResponses[keyof PostFalAiMinimaxVideo01ImageToVideoResponses]

export type GetFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax/video-01/image-to-video/requests/{request_id}'
}

export type GetFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaMinimaxVideo01ImageToVideoOutput
}

export type GetFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdResponse =
  GetFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdResponses[keyof GetFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdResponses]

export type GetFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/minimax/hailuo-2.3/pro/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/minimax/hailuo-2.3/pro/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiMinimaxHailuo23ProImageToVideoData = {
  body: SchemaMinimaxHailuo23ProImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/minimax/hailuo-2.3/pro/image-to-video'
}

export type PostFalAiMinimaxHailuo23ProImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMinimaxHailuo23ProImageToVideoResponse =
  PostFalAiMinimaxHailuo23ProImageToVideoResponses[keyof PostFalAiMinimaxHailuo23ProImageToVideoResponses]

export type GetFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax/hailuo-2.3/pro/image-to-video/requests/{request_id}'
}

export type GetFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaMinimaxHailuo23ProImageToVideoOutput
  }

export type GetFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdResponse =
  GetFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdResponses[keyof GetFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdResponses]

export type GetFalAiWan25PreviewImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/wan-25-preview/image-to-video/requests/{request_id}/status'
}

export type GetFalAiWan25PreviewImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiWan25PreviewImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiWan25PreviewImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiWan25PreviewImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiWan25PreviewImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan-25-preview/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiWan25PreviewImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiWan25PreviewImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiWan25PreviewImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiWan25PreviewImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiWan25PreviewImageToVideoData = {
  body: SchemaWan25PreviewImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/wan-25-preview/image-to-video'
}

export type PostFalAiWan25PreviewImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiWan25PreviewImageToVideoResponse =
  PostFalAiWan25PreviewImageToVideoResponses[keyof PostFalAiWan25PreviewImageToVideoResponses]

export type GetFalAiWan25PreviewImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan-25-preview/image-to-video/requests/{request_id}'
}

export type GetFalAiWan25PreviewImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaWan25PreviewImageToVideoOutput
}

export type GetFalAiWan25PreviewImageToVideoRequestsByRequestIdResponse =
  GetFalAiWan25PreviewImageToVideoRequestsByRequestIdResponses[keyof GetFalAiWan25PreviewImageToVideoRequestsByRequestIdResponses]

export type GetFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/kling-video/v2.5-turbo/pro/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/v2.5-turbo/pro/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV25TurboProImageToVideoData = {
  body: SchemaKlingVideoV25TurboProImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v2.5-turbo/pro/image-to-video'
}

export type PostFalAiKlingVideoV25TurboProImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV25TurboProImageToVideoResponse =
  PostFalAiKlingVideoV25TurboProImageToVideoResponses[keyof PostFalAiKlingVideoV25TurboProImageToVideoResponses]

export type GetFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v2.5-turbo/pro/image-to-video/requests/{request_id}'
}

export type GetFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaKlingVideoV25TurboProImageToVideoOutput
  }

export type GetFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdResponse =
  GetFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdResponses]

export type GetFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/minimax/hailuo-02/standard/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/minimax/hailuo-02/standard/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiMinimaxHailuo02StandardImageToVideoData = {
  body: SchemaMinimaxHailuo02StandardImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/minimax/hailuo-02/standard/image-to-video'
}

export type PostFalAiMinimaxHailuo02StandardImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMinimaxHailuo02StandardImageToVideoResponse =
  PostFalAiMinimaxHailuo02StandardImageToVideoResponses[keyof PostFalAiMinimaxHailuo02StandardImageToVideoResponses]

export type GetFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/minimax/hailuo-02/standard/image-to-video/requests/{request_id}'
  }

export type GetFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaMinimaxHailuo02StandardImageToVideoOutput
  }

export type GetFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdResponse =
  GetFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdResponses[keyof GetFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdResponses]

export type GetFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/bytedance/seedance/v1/pro/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/bytedance/seedance/v1/pro/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiBytedanceSeedanceV1ProImageToVideoData = {
  body: SchemaBytedanceSeedanceV1ProImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/bytedance/seedance/v1/pro/image-to-video'
}

export type PostFalAiBytedanceSeedanceV1ProImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiBytedanceSeedanceV1ProImageToVideoResponse =
  PostFalAiBytedanceSeedanceV1ProImageToVideoResponses[keyof PostFalAiBytedanceSeedanceV1ProImageToVideoResponses]

export type GetFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/bytedance/seedance/v1/pro/image-to-video/requests/{request_id}'
  }

export type GetFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaBytedanceSeedanceV1ProImageToVideoOutput
  }

export type GetFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdResponse =
  GetFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdResponses[keyof GetFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdResponses]

export type GetFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/kling-video/v2.1/master/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/v2.1/master/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV21MasterImageToVideoData = {
  body: SchemaKlingVideoV21MasterImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v2.1/master/image-to-video'
}

export type PostFalAiKlingVideoV21MasterImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV21MasterImageToVideoResponse =
  PostFalAiKlingVideoV21MasterImageToVideoResponses[keyof PostFalAiKlingVideoV21MasterImageToVideoResponses]

export type GetFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v2.1/master/image-to-video/requests/{request_id}'
}

export type GetFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaKlingVideoV21MasterImageToVideoOutput
  }

export type GetFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdResponse =
  GetFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdResponses]

export type GetFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/kling-video/v2.1/standard/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/v2.1/standard/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV21StandardImageToVideoData = {
  body: SchemaKlingVideoV21StandardImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v2.1/standard/image-to-video'
}

export type PostFalAiKlingVideoV21StandardImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV21StandardImageToVideoResponse =
  PostFalAiKlingVideoV21StandardImageToVideoResponses[keyof PostFalAiKlingVideoV21StandardImageToVideoResponses]

export type GetFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v2.1/standard/image-to-video/requests/{request_id}'
}

export type GetFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaKlingVideoV21StandardImageToVideoOutput
  }

export type GetFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdResponse =
  GetFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdResponses]

export type GetFalAiPixverseV45ImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v4.5/image-to-video/requests/{request_id}/status'
}

export type GetFalAiPixverseV45ImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiPixverseV45ImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV45ImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV45ImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV45ImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v4.5/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV45ImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiPixverseV45ImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV45ImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV45ImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV45ImageToVideoData = {
  body: SchemaPixverseV45ImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v4.5/image-to-video'
}

export type PostFalAiPixverseV45ImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV45ImageToVideoResponse =
  PostFalAiPixverseV45ImageToVideoResponses[keyof PostFalAiPixverseV45ImageToVideoResponses]

export type GetFalAiPixverseV45ImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v4.5/image-to-video/requests/{request_id}'
}

export type GetFalAiPixverseV45ImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV45ImageToVideoOutput
}

export type GetFalAiPixverseV45ImageToVideoRequestsByRequestIdResponse =
  GetFalAiPixverseV45ImageToVideoRequestsByRequestIdResponses[keyof GetFalAiPixverseV45ImageToVideoRequestsByRequestIdResponses]

export type GetFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/kling-video/v2/master/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/v2/master/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV2MasterImageToVideoData = {
  body: SchemaKlingVideoV2MasterImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v2/master/image-to-video'
}

export type PostFalAiKlingVideoV2MasterImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV2MasterImageToVideoResponse =
  PostFalAiKlingVideoV2MasterImageToVideoResponses[keyof PostFalAiKlingVideoV2MasterImageToVideoResponses]

export type GetFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v2/master/image-to-video/requests/{request_id}'
}

export type GetFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaKlingVideoV2MasterImageToVideoOutput
  }

export type GetFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdResponse =
  GetFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdResponses]

export type GetFalAiWanI2vRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/wan-i2v/requests/{request_id}/status'
}

export type GetFalAiWanI2vRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiWanI2vRequestsByRequestIdStatusResponse =
  GetFalAiWanI2vRequestsByRequestIdStatusResponses[keyof GetFalAiWanI2vRequestsByRequestIdStatusResponses]

export type PutFalAiWanI2vRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan-i2v/requests/{request_id}/cancel'
}

export type PutFalAiWanI2vRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiWanI2vRequestsByRequestIdCancelResponse =
  PutFalAiWanI2vRequestsByRequestIdCancelResponses[keyof PutFalAiWanI2vRequestsByRequestIdCancelResponses]

export type PostFalAiWanI2vData = {
  body: SchemaWanI2vInput
  path?: never
  query?: never
  url: '/fal-ai/wan-i2v'
}

export type PostFalAiWanI2vResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiWanI2vResponse =
  PostFalAiWanI2vResponses[keyof PostFalAiWanI2vResponses]

export type GetFalAiWanI2vRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan-i2v/requests/{request_id}'
}

export type GetFalAiWanI2vRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaWanI2vOutput
}

export type GetFalAiWanI2vRequestsByRequestIdResponse =
  GetFalAiWanI2vRequestsByRequestIdResponses[keyof GetFalAiWanI2vRequestsByRequestIdResponses]

export type GetFalAiPixverseV56TransitionRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v5.6/transition/requests/{request_id}/status'
}

export type GetFalAiPixverseV56TransitionRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPixverseV56TransitionRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV56TransitionRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV56TransitionRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV56TransitionRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v5.6/transition/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV56TransitionRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPixverseV56TransitionRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV56TransitionRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV56TransitionRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV56TransitionData = {
  body: SchemaPixverseV56TransitionInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v5.6/transition'
}

export type PostFalAiPixverseV56TransitionResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV56TransitionResponse =
  PostFalAiPixverseV56TransitionResponses[keyof PostFalAiPixverseV56TransitionResponses]

export type GetFalAiPixverseV56TransitionRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v5.6/transition/requests/{request_id}'
}

export type GetFalAiPixverseV56TransitionRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV56TransitionOutput
}

export type GetFalAiPixverseV56TransitionRequestsByRequestIdResponse =
  GetFalAiPixverseV56TransitionRequestsByRequestIdResponses[keyof GetFalAiPixverseV56TransitionRequestsByRequestIdResponses]

export type GetFalAiPixverseV56ImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v5.6/image-to-video/requests/{request_id}/status'
}

export type GetFalAiPixverseV56ImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiPixverseV56ImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV56ImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV56ImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV56ImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v5.6/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV56ImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiPixverseV56ImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV56ImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV56ImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV56ImageToVideoData = {
  body: SchemaPixverseV56ImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v5.6/image-to-video'
}

export type PostFalAiPixverseV56ImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV56ImageToVideoResponse =
  PostFalAiPixverseV56ImageToVideoResponses[keyof PostFalAiPixverseV56ImageToVideoResponses]

export type GetFalAiPixverseV56ImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v5.6/image-to-video/requests/{request_id}'
}

export type GetFalAiPixverseV56ImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV56ImageToVideoOutput
}

export type GetFalAiPixverseV56ImageToVideoRequestsByRequestIdResponse =
  GetFalAiPixverseV56ImageToVideoRequestsByRequestIdResponses[keyof GetFalAiPixverseV56ImageToVideoRequestsByRequestIdResponses]

export type GetFalAiViduQ2ReferenceToVideoProRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/vidu/q2/reference-to-video/pro/requests/{request_id}/status'
}

export type GetFalAiViduQ2ReferenceToVideoProRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiViduQ2ReferenceToVideoProRequestsByRequestIdStatusResponse =
  GetFalAiViduQ2ReferenceToVideoProRequestsByRequestIdStatusResponses[keyof GetFalAiViduQ2ReferenceToVideoProRequestsByRequestIdStatusResponses]

export type PutFalAiViduQ2ReferenceToVideoProRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/vidu/q2/reference-to-video/pro/requests/{request_id}/cancel'
}

export type PutFalAiViduQ2ReferenceToVideoProRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiViduQ2ReferenceToVideoProRequestsByRequestIdCancelResponse =
  PutFalAiViduQ2ReferenceToVideoProRequestsByRequestIdCancelResponses[keyof PutFalAiViduQ2ReferenceToVideoProRequestsByRequestIdCancelResponses]

export type PostFalAiViduQ2ReferenceToVideoProData = {
  body: SchemaViduQ2ReferenceToVideoProInput
  path?: never
  query?: never
  url: '/fal-ai/vidu/q2/reference-to-video/pro'
}

export type PostFalAiViduQ2ReferenceToVideoProResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiViduQ2ReferenceToVideoProResponse =
  PostFalAiViduQ2ReferenceToVideoProResponses[keyof PostFalAiViduQ2ReferenceToVideoProResponses]

export type GetFalAiViduQ2ReferenceToVideoProRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/vidu/q2/reference-to-video/pro/requests/{request_id}'
}

export type GetFalAiViduQ2ReferenceToVideoProRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaViduQ2ReferenceToVideoProOutput
}

export type GetFalAiViduQ2ReferenceToVideoProRequestsByRequestIdResponse =
  GetFalAiViduQ2ReferenceToVideoProRequestsByRequestIdResponses[keyof GetFalAiViduQ2ReferenceToVideoProRequestsByRequestIdResponses]

export type GetWanV26ImageToVideoFlashRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/wan/v2.6/image-to-video/flash/requests/{request_id}/status'
}

export type GetWanV26ImageToVideoFlashRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetWanV26ImageToVideoFlashRequestsByRequestIdStatusResponse =
  GetWanV26ImageToVideoFlashRequestsByRequestIdStatusResponses[keyof GetWanV26ImageToVideoFlashRequestsByRequestIdStatusResponses]

export type PutWanV26ImageToVideoFlashRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/wan/v2.6/image-to-video/flash/requests/{request_id}/cancel'
}

export type PutWanV26ImageToVideoFlashRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutWanV26ImageToVideoFlashRequestsByRequestIdCancelResponse =
  PutWanV26ImageToVideoFlashRequestsByRequestIdCancelResponses[keyof PutWanV26ImageToVideoFlashRequestsByRequestIdCancelResponses]

export type PostWanV26ImageToVideoFlashData = {
  body: SchemaV26ImageToVideoFlashInput
  path?: never
  query?: never
  url: '/wan/v2.6/image-to-video/flash'
}

export type PostWanV26ImageToVideoFlashResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostWanV26ImageToVideoFlashResponse =
  PostWanV26ImageToVideoFlashResponses[keyof PostWanV26ImageToVideoFlashResponses]

export type GetWanV26ImageToVideoFlashRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/wan/v2.6/image-to-video/flash/requests/{request_id}'
}

export type GetWanV26ImageToVideoFlashRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaV26ImageToVideoFlashOutput
}

export type GetWanV26ImageToVideoFlashRequestsByRequestIdResponse =
  GetWanV26ImageToVideoFlashRequestsByRequestIdResponses[keyof GetWanV26ImageToVideoFlashRequestsByRequestIdResponses]

export type GetFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/ltx-2-19b/distilled/image-to-video/lora/requests/{request_id}/status'
  }

export type GetFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdStatusResponse =
  GetFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdStatusResponses[keyof GetFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdStatusResponses]

export type PutFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/ltx-2-19b/distilled/image-to-video/lora/requests/{request_id}/cancel'
  }

export type PutFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdCancelResponse =
  PutFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdCancelResponses[keyof PutFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdCancelResponses]

export type PostFalAiLtx219bDistilledImageToVideoLoraData = {
  body: SchemaLtx219bDistilledImageToVideoLoraInput
  path?: never
  query?: never
  url: '/fal-ai/ltx-2-19b/distilled/image-to-video/lora'
}

export type PostFalAiLtx219bDistilledImageToVideoLoraResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLtx219bDistilledImageToVideoLoraResponse =
  PostFalAiLtx219bDistilledImageToVideoLoraResponses[keyof PostFalAiLtx219bDistilledImageToVideoLoraResponses]

export type GetFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-2-19b/distilled/image-to-video/lora/requests/{request_id}'
}

export type GetFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaLtx219bDistilledImageToVideoLoraOutput
  }

export type GetFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdResponse =
  GetFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdResponses[keyof GetFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdResponses]

export type GetFalAiLtx219bDistilledImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/ltx-2-19b/distilled/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiLtx219bDistilledImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiLtx219bDistilledImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiLtx219bDistilledImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiLtx219bDistilledImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiLtx219bDistilledImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/ltx-2-19b/distilled/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiLtx219bDistilledImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiLtx219bDistilledImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiLtx219bDistilledImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiLtx219bDistilledImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiLtx219bDistilledImageToVideoData = {
  body: SchemaLtx219bDistilledImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/ltx-2-19b/distilled/image-to-video'
}

export type PostFalAiLtx219bDistilledImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLtx219bDistilledImageToVideoResponse =
  PostFalAiLtx219bDistilledImageToVideoResponses[keyof PostFalAiLtx219bDistilledImageToVideoResponses]

export type GetFalAiLtx219bDistilledImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-2-19b/distilled/image-to-video/requests/{request_id}'
}

export type GetFalAiLtx219bDistilledImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLtx219bDistilledImageToVideoOutput
}

export type GetFalAiLtx219bDistilledImageToVideoRequestsByRequestIdResponse =
  GetFalAiLtx219bDistilledImageToVideoRequestsByRequestIdResponses[keyof GetFalAiLtx219bDistilledImageToVideoRequestsByRequestIdResponses]

export type GetFalAiLtx219bImageToVideoLoraRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ltx-2-19b/image-to-video/lora/requests/{request_id}/status'
}

export type GetFalAiLtx219bImageToVideoLoraRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiLtx219bImageToVideoLoraRequestsByRequestIdStatusResponse =
  GetFalAiLtx219bImageToVideoLoraRequestsByRequestIdStatusResponses[keyof GetFalAiLtx219bImageToVideoLoraRequestsByRequestIdStatusResponses]

export type PutFalAiLtx219bImageToVideoLoraRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-2-19b/image-to-video/lora/requests/{request_id}/cancel'
}

export type PutFalAiLtx219bImageToVideoLoraRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiLtx219bImageToVideoLoraRequestsByRequestIdCancelResponse =
  PutFalAiLtx219bImageToVideoLoraRequestsByRequestIdCancelResponses[keyof PutFalAiLtx219bImageToVideoLoraRequestsByRequestIdCancelResponses]

export type PostFalAiLtx219bImageToVideoLoraData = {
  body: SchemaLtx219bImageToVideoLoraInput
  path?: never
  query?: never
  url: '/fal-ai/ltx-2-19b/image-to-video/lora'
}

export type PostFalAiLtx219bImageToVideoLoraResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLtx219bImageToVideoLoraResponse =
  PostFalAiLtx219bImageToVideoLoraResponses[keyof PostFalAiLtx219bImageToVideoLoraResponses]

export type GetFalAiLtx219bImageToVideoLoraRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-2-19b/image-to-video/lora/requests/{request_id}'
}

export type GetFalAiLtx219bImageToVideoLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLtx219bImageToVideoLoraOutput
}

export type GetFalAiLtx219bImageToVideoLoraRequestsByRequestIdResponse =
  GetFalAiLtx219bImageToVideoLoraRequestsByRequestIdResponses[keyof GetFalAiLtx219bImageToVideoLoraRequestsByRequestIdResponses]

export type GetFalAiLtx219bImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ltx-2-19b/image-to-video/requests/{request_id}/status'
}

export type GetFalAiLtx219bImageToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiLtx219bImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiLtx219bImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiLtx219bImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiLtx219bImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-2-19b/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiLtx219bImageToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiLtx219bImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiLtx219bImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiLtx219bImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiLtx219bImageToVideoData = {
  body: SchemaLtx219bImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/ltx-2-19b/image-to-video'
}

export type PostFalAiLtx219bImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLtx219bImageToVideoResponse =
  PostFalAiLtx219bImageToVideoResponses[keyof PostFalAiLtx219bImageToVideoResponses]

export type GetFalAiLtx219bImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-2-19b/image-to-video/requests/{request_id}'
}

export type GetFalAiLtx219bImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLtx219bImageToVideoOutput
}

export type GetFalAiLtx219bImageToVideoRequestsByRequestIdResponse =
  GetFalAiLtx219bImageToVideoRequestsByRequestIdResponses[keyof GetFalAiLtx219bImageToVideoRequestsByRequestIdResponses]

export type GetFalAiWanMoveRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/wan-move/requests/{request_id}/status'
}

export type GetFalAiWanMoveRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiWanMoveRequestsByRequestIdStatusResponse =
  GetFalAiWanMoveRequestsByRequestIdStatusResponses[keyof GetFalAiWanMoveRequestsByRequestIdStatusResponses]

export type PutFalAiWanMoveRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan-move/requests/{request_id}/cancel'
}

export type PutFalAiWanMoveRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiWanMoveRequestsByRequestIdCancelResponse =
  PutFalAiWanMoveRequestsByRequestIdCancelResponses[keyof PutFalAiWanMoveRequestsByRequestIdCancelResponses]

export type PostFalAiWanMoveData = {
  body: SchemaWanMoveInput
  path?: never
  query?: never
  url: '/fal-ai/wan-move'
}

export type PostFalAiWanMoveResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiWanMoveResponse =
  PostFalAiWanMoveResponses[keyof PostFalAiWanMoveResponses]

export type GetFalAiWanMoveRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan-move/requests/{request_id}'
}

export type GetFalAiWanMoveRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaWanMoveOutput
}

export type GetFalAiWanMoveRequestsByRequestIdResponse =
  GetFalAiWanMoveRequestsByRequestIdResponses[keyof GetFalAiWanMoveRequestsByRequestIdResponses]

export type GetFalAiKandinsky5ProImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kandinsky5-pro/image-to-video/requests/{request_id}/status'
}

export type GetFalAiKandinsky5ProImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKandinsky5ProImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKandinsky5ProImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKandinsky5ProImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKandinsky5ProImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kandinsky5-pro/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiKandinsky5ProImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKandinsky5ProImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKandinsky5ProImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKandinsky5ProImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKandinsky5ProImageToVideoData = {
  body: SchemaKandinsky5ProImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kandinsky5-pro/image-to-video'
}

export type PostFalAiKandinsky5ProImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKandinsky5ProImageToVideoResponse =
  PostFalAiKandinsky5ProImageToVideoResponses[keyof PostFalAiKandinsky5ProImageToVideoResponses]

export type GetFalAiKandinsky5ProImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kandinsky5-pro/image-to-video/requests/{request_id}'
}

export type GetFalAiKandinsky5ProImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKandinsky5ProImageToVideoOutput
}

export type GetFalAiKandinsky5ProImageToVideoRequestsByRequestIdResponse =
  GetFalAiKandinsky5ProImageToVideoRequestsByRequestIdResponses[keyof GetFalAiKandinsky5ProImageToVideoRequestsByRequestIdResponses]

export type GetFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/bytedance/seedance/v1.5/pro/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/bytedance/seedance/v1.5/pro/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiBytedanceSeedanceV15ProImageToVideoData = {
  body: SchemaBytedanceSeedanceV15ProImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/bytedance/seedance/v1.5/pro/image-to-video'
}

export type PostFalAiBytedanceSeedanceV15ProImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiBytedanceSeedanceV15ProImageToVideoResponse =
  PostFalAiBytedanceSeedanceV15ProImageToVideoResponses[keyof PostFalAiBytedanceSeedanceV15ProImageToVideoResponses]

export type GetFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/bytedance/seedance/v1.5/pro/image-to-video/requests/{request_id}'
  }

export type GetFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaBytedanceSeedanceV15ProImageToVideoOutput
  }

export type GetFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdResponse =
  GetFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdResponses[keyof GetFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdResponses]

export type GetFalAiLiveAvatarRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/live-avatar/requests/{request_id}/status'
}

export type GetFalAiLiveAvatarRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiLiveAvatarRequestsByRequestIdStatusResponse =
  GetFalAiLiveAvatarRequestsByRequestIdStatusResponses[keyof GetFalAiLiveAvatarRequestsByRequestIdStatusResponses]

export type PutFalAiLiveAvatarRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/live-avatar/requests/{request_id}/cancel'
}

export type PutFalAiLiveAvatarRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiLiveAvatarRequestsByRequestIdCancelResponse =
  PutFalAiLiveAvatarRequestsByRequestIdCancelResponses[keyof PutFalAiLiveAvatarRequestsByRequestIdCancelResponses]

export type PostFalAiLiveAvatarData = {
  body: SchemaLiveAvatarInput
  path?: never
  query?: never
  url: '/fal-ai/live-avatar'
}

export type PostFalAiLiveAvatarResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLiveAvatarResponse =
  PostFalAiLiveAvatarResponses[keyof PostFalAiLiveAvatarResponses]

export type GetFalAiLiveAvatarRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/live-avatar/requests/{request_id}'
}

export type GetFalAiLiveAvatarRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLiveAvatarOutput
}

export type GetFalAiLiveAvatarRequestsByRequestIdResponse =
  GetFalAiLiveAvatarRequestsByRequestIdResponses[keyof GetFalAiLiveAvatarRequestsByRequestIdResponses]

export type GetFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/hunyuan-video-v1.5/image-to-video/requests/{request_id}/status'
}

export type GetFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/hunyuan-video-v1.5/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiHunyuanVideoV15ImageToVideoData = {
  body: SchemaHunyuanVideoV15ImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/hunyuan-video-v1.5/image-to-video'
}

export type PostFalAiHunyuanVideoV15ImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiHunyuanVideoV15ImageToVideoResponse =
  PostFalAiHunyuanVideoV15ImageToVideoResponses[keyof PostFalAiHunyuanVideoV15ImageToVideoResponses]

export type GetFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/hunyuan-video-v1.5/image-to-video/requests/{request_id}'
}

export type GetFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaHunyuanVideoV15ImageToVideoOutput
}

export type GetFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdResponse =
  GetFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdResponses[keyof GetFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdResponses]

export type GetWanV26ImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/wan/v2.6/image-to-video/requests/{request_id}/status'
}

export type GetWanV26ImageToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetWanV26ImageToVideoRequestsByRequestIdStatusResponse =
  GetWanV26ImageToVideoRequestsByRequestIdStatusResponses[keyof GetWanV26ImageToVideoRequestsByRequestIdStatusResponses]

export type PutWanV26ImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/wan/v2.6/image-to-video/requests/{request_id}/cancel'
}

export type PutWanV26ImageToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutWanV26ImageToVideoRequestsByRequestIdCancelResponse =
  PutWanV26ImageToVideoRequestsByRequestIdCancelResponses[keyof PutWanV26ImageToVideoRequestsByRequestIdCancelResponses]

export type PostWanV26ImageToVideoData = {
  body: SchemaV26ImageToVideoInput
  path?: never
  query?: never
  url: '/wan/v2.6/image-to-video'
}

export type PostWanV26ImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostWanV26ImageToVideoResponse =
  PostWanV26ImageToVideoResponses[keyof PostWanV26ImageToVideoResponses]

export type GetWanV26ImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/wan/v2.6/image-to-video/requests/{request_id}'
}

export type GetWanV26ImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaV26ImageToVideoOutput
}

export type GetWanV26ImageToVideoRequestsByRequestIdResponse =
  GetWanV26ImageToVideoRequestsByRequestIdResponses[keyof GetWanV26ImageToVideoRequestsByRequestIdResponses]

export type GetFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/kling-video/o1/standard/reference-to-video/requests/{request_id}/status'
  }

export type GetFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/o1/standard/reference-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoO1StandardReferenceToVideoData = {
  body: SchemaKlingVideoO1StandardReferenceToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/o1/standard/reference-to-video'
}

export type PostFalAiKlingVideoO1StandardReferenceToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoO1StandardReferenceToVideoResponse =
  PostFalAiKlingVideoO1StandardReferenceToVideoResponses[keyof PostFalAiKlingVideoO1StandardReferenceToVideoResponses]

export type GetFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/o1/standard/reference-to-video/requests/{request_id}'
  }

export type GetFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaKlingVideoO1StandardReferenceToVideoOutput
  }

export type GetFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdResponse =
  GetFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdResponses[keyof GetFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdResponses]

export type GetFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/kling-video/o1/standard/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/o1/standard/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoO1StandardImageToVideoData = {
  body: SchemaKlingVideoO1StandardImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/o1/standard/image-to-video'
}

export type PostFalAiKlingVideoO1StandardImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoO1StandardImageToVideoResponse =
  PostFalAiKlingVideoO1StandardImageToVideoResponses[keyof PostFalAiKlingVideoO1StandardImageToVideoResponses]

export type GetFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/o1/standard/image-to-video/requests/{request_id}'
}

export type GetFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaKlingVideoO1StandardImageToVideoOutput
  }

export type GetFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdResponse =
  GetFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdResponses[keyof GetFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdResponses]

export type GetFalAiCreatifyAuroraRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/creatify/aurora/requests/{request_id}/status'
}

export type GetFalAiCreatifyAuroraRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiCreatifyAuroraRequestsByRequestIdStatusResponse =
  GetFalAiCreatifyAuroraRequestsByRequestIdStatusResponses[keyof GetFalAiCreatifyAuroraRequestsByRequestIdStatusResponses]

export type PutFalAiCreatifyAuroraRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/creatify/aurora/requests/{request_id}/cancel'
}

export type PutFalAiCreatifyAuroraRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiCreatifyAuroraRequestsByRequestIdCancelResponse =
  PutFalAiCreatifyAuroraRequestsByRequestIdCancelResponses[keyof PutFalAiCreatifyAuroraRequestsByRequestIdCancelResponses]

export type PostFalAiCreatifyAuroraData = {
  body: SchemaCreatifyAuroraInput
  path?: never
  query?: never
  url: '/fal-ai/creatify/aurora'
}

export type PostFalAiCreatifyAuroraResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiCreatifyAuroraResponse =
  PostFalAiCreatifyAuroraResponses[keyof PostFalAiCreatifyAuroraResponses]

export type GetFalAiCreatifyAuroraRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/creatify/aurora/requests/{request_id}'
}

export type GetFalAiCreatifyAuroraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaCreatifyAuroraOutput
}

export type GetFalAiCreatifyAuroraRequestsByRequestIdResponse =
  GetFalAiCreatifyAuroraRequestsByRequestIdResponses[keyof GetFalAiCreatifyAuroraRequestsByRequestIdResponses]

export type GetFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kling-video/ai-avatar/v2/pro/requests/{request_id}/status'
}

export type GetFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/ai-avatar/v2/pro/requests/{request_id}/cancel'
}

export type PutFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoAiAvatarV2ProData = {
  body: SchemaKlingVideoAiAvatarV2ProInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/ai-avatar/v2/pro'
}

export type PostFalAiKlingVideoAiAvatarV2ProResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoAiAvatarV2ProResponse =
  PostFalAiKlingVideoAiAvatarV2ProResponses[keyof PostFalAiKlingVideoAiAvatarV2ProResponses]

export type GetFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/ai-avatar/v2/pro/requests/{request_id}'
}

export type GetFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKlingVideoAiAvatarV2ProOutput
}

export type GetFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdResponse =
  GetFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdResponses[keyof GetFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdResponses]

export type GetFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/kling-video/ai-avatar/v2/standard/requests/{request_id}/status'
  }

export type GetFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/ai-avatar/v2/standard/requests/{request_id}/cancel'
  }

export type PutFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoAiAvatarV2StandardData = {
  body: SchemaKlingVideoAiAvatarV2StandardInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/ai-avatar/v2/standard'
}

export type PostFalAiKlingVideoAiAvatarV2StandardResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoAiAvatarV2StandardResponse =
  PostFalAiKlingVideoAiAvatarV2StandardResponses[keyof PostFalAiKlingVideoAiAvatarV2StandardResponses]

export type GetFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/ai-avatar/v2/standard/requests/{request_id}'
}

export type GetFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKlingVideoAiAvatarV2StandardOutput
}

export type GetFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdResponse =
  GetFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdResponses[keyof GetFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdResponses]

export type GetFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/kling-video/v2.6/pro/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/v2.6/pro/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV26ProImageToVideoData = {
  body: SchemaKlingVideoV26ProImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v2.6/pro/image-to-video'
}

export type PostFalAiKlingVideoV26ProImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV26ProImageToVideoResponse =
  PostFalAiKlingVideoV26ProImageToVideoResponses[keyof PostFalAiKlingVideoV26ProImageToVideoResponses]

export type GetFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v2.6/pro/image-to-video/requests/{request_id}'
}

export type GetFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKlingVideoV26ProImageToVideoOutput
}

export type GetFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdResponse =
  GetFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdResponses]

export type GetFalAiPixverseV55EffectsRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v5.5/effects/requests/{request_id}/status'
}

export type GetFalAiPixverseV55EffectsRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPixverseV55EffectsRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV55EffectsRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV55EffectsRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV55EffectsRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v5.5/effects/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV55EffectsRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPixverseV55EffectsRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV55EffectsRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV55EffectsRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV55EffectsData = {
  body: SchemaPixverseV55EffectsInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v5.5/effects'
}

export type PostFalAiPixverseV55EffectsResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV55EffectsResponse =
  PostFalAiPixverseV55EffectsResponses[keyof PostFalAiPixverseV55EffectsResponses]

export type GetFalAiPixverseV55EffectsRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v5.5/effects/requests/{request_id}'
}

export type GetFalAiPixverseV55EffectsRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV55EffectsOutput
}

export type GetFalAiPixverseV55EffectsRequestsByRequestIdResponse =
  GetFalAiPixverseV55EffectsRequestsByRequestIdResponses[keyof GetFalAiPixverseV55EffectsRequestsByRequestIdResponses]

export type GetFalAiPixverseV55TransitionRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v5.5/transition/requests/{request_id}/status'
}

export type GetFalAiPixverseV55TransitionRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPixverseV55TransitionRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV55TransitionRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV55TransitionRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV55TransitionRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v5.5/transition/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV55TransitionRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPixverseV55TransitionRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV55TransitionRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV55TransitionRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV55TransitionData = {
  body: SchemaPixverseV55TransitionInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v5.5/transition'
}

export type PostFalAiPixverseV55TransitionResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV55TransitionResponse =
  PostFalAiPixverseV55TransitionResponses[keyof PostFalAiPixverseV55TransitionResponses]

export type GetFalAiPixverseV55TransitionRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v5.5/transition/requests/{request_id}'
}

export type GetFalAiPixverseV55TransitionRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV55TransitionOutput
}

export type GetFalAiPixverseV55TransitionRequestsByRequestIdResponse =
  GetFalAiPixverseV55TransitionRequestsByRequestIdResponses[keyof GetFalAiPixverseV55TransitionRequestsByRequestIdResponses]

export type GetFalAiPixverseV55ImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v5.5/image-to-video/requests/{request_id}/status'
}

export type GetFalAiPixverseV55ImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiPixverseV55ImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV55ImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV55ImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV55ImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v5.5/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV55ImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiPixverseV55ImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV55ImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV55ImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV55ImageToVideoData = {
  body: SchemaPixverseV55ImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v5.5/image-to-video'
}

export type PostFalAiPixverseV55ImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV55ImageToVideoResponse =
  PostFalAiPixverseV55ImageToVideoResponses[keyof PostFalAiPixverseV55ImageToVideoResponses]

export type GetFalAiPixverseV55ImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v5.5/image-to-video/requests/{request_id}'
}

export type GetFalAiPixverseV55ImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV55ImageToVideoOutput
}

export type GetFalAiPixverseV55ImageToVideoRequestsByRequestIdResponse =
  GetFalAiPixverseV55ImageToVideoRequestsByRequestIdResponses[keyof GetFalAiPixverseV55ImageToVideoRequestsByRequestIdResponses]

export type GetFalAiKlingVideoO1ImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kling-video/o1/image-to-video/requests/{request_id}/status'
}

export type GetFalAiKlingVideoO1ImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoO1ImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoO1ImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoO1ImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoO1ImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/o1/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiKlingVideoO1ImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoO1ImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoO1ImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoO1ImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoO1ImageToVideoData = {
  body: SchemaKlingVideoO1ImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/o1/image-to-video'
}

export type PostFalAiKlingVideoO1ImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoO1ImageToVideoResponse =
  PostFalAiKlingVideoO1ImageToVideoResponses[keyof PostFalAiKlingVideoO1ImageToVideoResponses]

export type GetFalAiKlingVideoO1ImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/o1/image-to-video/requests/{request_id}'
}

export type GetFalAiKlingVideoO1ImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKlingVideoO1ImageToVideoOutput
}

export type GetFalAiKlingVideoO1ImageToVideoRequestsByRequestIdResponse =
  GetFalAiKlingVideoO1ImageToVideoRequestsByRequestIdResponses[keyof GetFalAiKlingVideoO1ImageToVideoRequestsByRequestIdResponses]

export type GetFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/kling-video/o1/reference-to-video/requests/{request_id}/status'
  }

export type GetFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/o1/reference-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoO1ReferenceToVideoData = {
  body: SchemaKlingVideoO1ReferenceToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/o1/reference-to-video'
}

export type PostFalAiKlingVideoO1ReferenceToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoO1ReferenceToVideoResponse =
  PostFalAiKlingVideoO1ReferenceToVideoResponses[keyof PostFalAiKlingVideoO1ReferenceToVideoResponses]

export type GetFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/o1/reference-to-video/requests/{request_id}'
}

export type GetFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKlingVideoO1ReferenceToVideoOutput
}

export type GetFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdResponse =
  GetFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdResponses[keyof GetFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdResponses]

export type GetFalAiLtx2ImageToVideoFastRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ltx-2/image-to-video/fast/requests/{request_id}/status'
}

export type GetFalAiLtx2ImageToVideoFastRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiLtx2ImageToVideoFastRequestsByRequestIdStatusResponse =
  GetFalAiLtx2ImageToVideoFastRequestsByRequestIdStatusResponses[keyof GetFalAiLtx2ImageToVideoFastRequestsByRequestIdStatusResponses]

export type PutFalAiLtx2ImageToVideoFastRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-2/image-to-video/fast/requests/{request_id}/cancel'
}

export type PutFalAiLtx2ImageToVideoFastRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiLtx2ImageToVideoFastRequestsByRequestIdCancelResponse =
  PutFalAiLtx2ImageToVideoFastRequestsByRequestIdCancelResponses[keyof PutFalAiLtx2ImageToVideoFastRequestsByRequestIdCancelResponses]

export type PostFalAiLtx2ImageToVideoFastData = {
  body: SchemaLtx2ImageToVideoFastInput
  path?: never
  query?: never
  url: '/fal-ai/ltx-2/image-to-video/fast'
}

export type PostFalAiLtx2ImageToVideoFastResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLtx2ImageToVideoFastResponse =
  PostFalAiLtx2ImageToVideoFastResponses[keyof PostFalAiLtx2ImageToVideoFastResponses]

export type GetFalAiLtx2ImageToVideoFastRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-2/image-to-video/fast/requests/{request_id}'
}

export type GetFalAiLtx2ImageToVideoFastRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLtx2ImageToVideoFastOutput
}

export type GetFalAiLtx2ImageToVideoFastRequestsByRequestIdResponse =
  GetFalAiLtx2ImageToVideoFastRequestsByRequestIdResponses[keyof GetFalAiLtx2ImageToVideoFastRequestsByRequestIdResponses]

export type GetFalAiLtx2ImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ltx-2/image-to-video/requests/{request_id}/status'
}

export type GetFalAiLtx2ImageToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiLtx2ImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiLtx2ImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiLtx2ImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiLtx2ImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-2/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiLtx2ImageToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiLtx2ImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiLtx2ImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiLtx2ImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiLtx2ImageToVideoData = {
  body: SchemaLtx2ImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/ltx-2/image-to-video'
}

export type PostFalAiLtx2ImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLtx2ImageToVideoResponse =
  PostFalAiLtx2ImageToVideoResponses[keyof PostFalAiLtx2ImageToVideoResponses]

export type GetFalAiLtx2ImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-2/image-to-video/requests/{request_id}'
}

export type GetFalAiLtx2ImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLtx2ImageToVideoOutput
}

export type GetFalAiLtx2ImageToVideoRequestsByRequestIdResponse =
  GetFalAiLtx2ImageToVideoRequestsByRequestIdResponses[keyof GetFalAiLtx2ImageToVideoRequestsByRequestIdResponses]

export type GetBytedanceLynxRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/bytedance/lynx/requests/{request_id}/status'
}

export type GetBytedanceLynxRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetBytedanceLynxRequestsByRequestIdStatusResponse =
  GetBytedanceLynxRequestsByRequestIdStatusResponses[keyof GetBytedanceLynxRequestsByRequestIdStatusResponses]

export type PutBytedanceLynxRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/bytedance/lynx/requests/{request_id}/cancel'
}

export type PutBytedanceLynxRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutBytedanceLynxRequestsByRequestIdCancelResponse =
  PutBytedanceLynxRequestsByRequestIdCancelResponses[keyof PutBytedanceLynxRequestsByRequestIdCancelResponses]

export type PostBytedanceLynxData = {
  body: SchemaLynxInput
  path?: never
  query?: never
  url: '/bytedance/lynx'
}

export type PostBytedanceLynxResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostBytedanceLynxResponse =
  PostBytedanceLynxResponses[keyof PostBytedanceLynxResponses]

export type GetBytedanceLynxRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/bytedance/lynx/requests/{request_id}'
}

export type GetBytedanceLynxRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLynxOutput
}

export type GetBytedanceLynxRequestsByRequestIdResponse =
  GetBytedanceLynxRequestsByRequestIdResponses[keyof GetBytedanceLynxRequestsByRequestIdResponses]

export type GetFalAiPixverseSwapRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/swap/requests/{request_id}/status'
}

export type GetFalAiPixverseSwapRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPixverseSwapRequestsByRequestIdStatusResponse =
  GetFalAiPixverseSwapRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseSwapRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseSwapRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/swap/requests/{request_id}/cancel'
}

export type PutFalAiPixverseSwapRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPixverseSwapRequestsByRequestIdCancelResponse =
  PutFalAiPixverseSwapRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseSwapRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseSwapData = {
  body: SchemaPixverseSwapInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/swap'
}

export type PostFalAiPixverseSwapResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseSwapResponse =
  PostFalAiPixverseSwapResponses[keyof PostFalAiPixverseSwapResponses]

export type GetFalAiPixverseSwapRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/swap/requests/{request_id}'
}

export type GetFalAiPixverseSwapRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseSwapOutput
}

export type GetFalAiPixverseSwapRequestsByRequestIdResponse =
  GetFalAiPixverseSwapRequestsByRequestIdResponses[keyof GetFalAiPixverseSwapRequestsByRequestIdResponses]

export type GetFalAiPikaV22PikaframesRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pika/v2.2/pikaframes/requests/{request_id}/status'
}

export type GetFalAiPikaV22PikaframesRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPikaV22PikaframesRequestsByRequestIdStatusResponse =
  GetFalAiPikaV22PikaframesRequestsByRequestIdStatusResponses[keyof GetFalAiPikaV22PikaframesRequestsByRequestIdStatusResponses]

export type PutFalAiPikaV22PikaframesRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pika/v2.2/pikaframes/requests/{request_id}/cancel'
}

export type PutFalAiPikaV22PikaframesRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPikaV22PikaframesRequestsByRequestIdCancelResponse =
  PutFalAiPikaV22PikaframesRequestsByRequestIdCancelResponses[keyof PutFalAiPikaV22PikaframesRequestsByRequestIdCancelResponses]

export type PostFalAiPikaV22PikaframesData = {
  body: SchemaPikaV22PikaframesInput
  path?: never
  query?: never
  url: '/fal-ai/pika/v2.2/pikaframes'
}

export type PostFalAiPikaV22PikaframesResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPikaV22PikaframesResponse =
  PostFalAiPikaV22PikaframesResponses[keyof PostFalAiPikaV22PikaframesResponses]

export type GetFalAiPikaV22PikaframesRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pika/v2.2/pikaframes/requests/{request_id}'
}

export type GetFalAiPikaV22PikaframesRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPikaV22PikaframesOutput
}

export type GetFalAiPikaV22PikaframesRequestsByRequestIdResponse =
  GetFalAiPikaV22PikaframesRequestsByRequestIdResponses[keyof GetFalAiPikaV22PikaframesRequestsByRequestIdResponses]

export type GetFalAiLongcatVideoImageToVideo720pRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/longcat-video/image-to-video/720p/requests/{request_id}/status'
  }

export type GetFalAiLongcatVideoImageToVideo720pRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiLongcatVideoImageToVideo720pRequestsByRequestIdStatusResponse =
  GetFalAiLongcatVideoImageToVideo720pRequestsByRequestIdStatusResponses[keyof GetFalAiLongcatVideoImageToVideo720pRequestsByRequestIdStatusResponses]

export type PutFalAiLongcatVideoImageToVideo720pRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/longcat-video/image-to-video/720p/requests/{request_id}/cancel'
  }

export type PutFalAiLongcatVideoImageToVideo720pRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiLongcatVideoImageToVideo720pRequestsByRequestIdCancelResponse =
  PutFalAiLongcatVideoImageToVideo720pRequestsByRequestIdCancelResponses[keyof PutFalAiLongcatVideoImageToVideo720pRequestsByRequestIdCancelResponses]

export type PostFalAiLongcatVideoImageToVideo720pData = {
  body: SchemaLongcatVideoImageToVideo720pInput
  path?: never
  query?: never
  url: '/fal-ai/longcat-video/image-to-video/720p'
}

export type PostFalAiLongcatVideoImageToVideo720pResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLongcatVideoImageToVideo720pResponse =
  PostFalAiLongcatVideoImageToVideo720pResponses[keyof PostFalAiLongcatVideoImageToVideo720pResponses]

export type GetFalAiLongcatVideoImageToVideo720pRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/longcat-video/image-to-video/720p/requests/{request_id}'
}

export type GetFalAiLongcatVideoImageToVideo720pRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLongcatVideoImageToVideo720pOutput
}

export type GetFalAiLongcatVideoImageToVideo720pRequestsByRequestIdResponse =
  GetFalAiLongcatVideoImageToVideo720pRequestsByRequestIdResponses[keyof GetFalAiLongcatVideoImageToVideo720pRequestsByRequestIdResponses]

export type GetFalAiLongcatVideoImageToVideo480pRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/longcat-video/image-to-video/480p/requests/{request_id}/status'
  }

export type GetFalAiLongcatVideoImageToVideo480pRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiLongcatVideoImageToVideo480pRequestsByRequestIdStatusResponse =
  GetFalAiLongcatVideoImageToVideo480pRequestsByRequestIdStatusResponses[keyof GetFalAiLongcatVideoImageToVideo480pRequestsByRequestIdStatusResponses]

export type PutFalAiLongcatVideoImageToVideo480pRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/longcat-video/image-to-video/480p/requests/{request_id}/cancel'
  }

export type PutFalAiLongcatVideoImageToVideo480pRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiLongcatVideoImageToVideo480pRequestsByRequestIdCancelResponse =
  PutFalAiLongcatVideoImageToVideo480pRequestsByRequestIdCancelResponses[keyof PutFalAiLongcatVideoImageToVideo480pRequestsByRequestIdCancelResponses]

export type PostFalAiLongcatVideoImageToVideo480pData = {
  body: SchemaLongcatVideoImageToVideo480pInput
  path?: never
  query?: never
  url: '/fal-ai/longcat-video/image-to-video/480p'
}

export type PostFalAiLongcatVideoImageToVideo480pResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLongcatVideoImageToVideo480pResponse =
  PostFalAiLongcatVideoImageToVideo480pResponses[keyof PostFalAiLongcatVideoImageToVideo480pResponses]

export type GetFalAiLongcatVideoImageToVideo480pRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/longcat-video/image-to-video/480p/requests/{request_id}'
}

export type GetFalAiLongcatVideoImageToVideo480pRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLongcatVideoImageToVideo480pOutput
}

export type GetFalAiLongcatVideoImageToVideo480pRequestsByRequestIdResponse =
  GetFalAiLongcatVideoImageToVideo480pRequestsByRequestIdResponses[keyof GetFalAiLongcatVideoImageToVideo480pRequestsByRequestIdResponses]

export type GetFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/longcat-video/distilled/image-to-video/720p/requests/{request_id}/status'
  }

export type GetFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdStatusResponse =
  GetFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdStatusResponses[keyof GetFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdStatusResponses]

export type PutFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/longcat-video/distilled/image-to-video/720p/requests/{request_id}/cancel'
  }

export type PutFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdCancelResponse =
  PutFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdCancelResponses[keyof PutFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdCancelResponses]

export type PostFalAiLongcatVideoDistilledImageToVideo720pData = {
  body: SchemaLongcatVideoDistilledImageToVideo720pInput
  path?: never
  query?: never
  url: '/fal-ai/longcat-video/distilled/image-to-video/720p'
}

export type PostFalAiLongcatVideoDistilledImageToVideo720pResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLongcatVideoDistilledImageToVideo720pResponse =
  PostFalAiLongcatVideoDistilledImageToVideo720pResponses[keyof PostFalAiLongcatVideoDistilledImageToVideo720pResponses]

export type GetFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/longcat-video/distilled/image-to-video/720p/requests/{request_id}'
  }

export type GetFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaLongcatVideoDistilledImageToVideo720pOutput
  }

export type GetFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdResponse =
  GetFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdResponses[keyof GetFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdResponses]

export type GetFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/longcat-video/distilled/image-to-video/480p/requests/{request_id}/status'
  }

export type GetFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdStatusResponse =
  GetFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdStatusResponses[keyof GetFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdStatusResponses]

export type PutFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/longcat-video/distilled/image-to-video/480p/requests/{request_id}/cancel'
  }

export type PutFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdCancelResponse =
  PutFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdCancelResponses[keyof PutFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdCancelResponses]

export type PostFalAiLongcatVideoDistilledImageToVideo480pData = {
  body: SchemaLongcatVideoDistilledImageToVideo480pInput
  path?: never
  query?: never
  url: '/fal-ai/longcat-video/distilled/image-to-video/480p'
}

export type PostFalAiLongcatVideoDistilledImageToVideo480pResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLongcatVideoDistilledImageToVideo480pResponse =
  PostFalAiLongcatVideoDistilledImageToVideo480pResponses[keyof PostFalAiLongcatVideoDistilledImageToVideo480pResponses]

export type GetFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/longcat-video/distilled/image-to-video/480p/requests/{request_id}'
  }

export type GetFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaLongcatVideoDistilledImageToVideo480pOutput
  }

export type GetFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdResponse =
  GetFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdResponses[keyof GetFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdResponses]

export type GetFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/minimax/hailuo-2.3-fast/standard/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/minimax/hailuo-2.3-fast/standard/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiMinimaxHailuo23FastStandardImageToVideoData = {
  body: SchemaMinimaxHailuo23FastStandardImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/minimax/hailuo-2.3-fast/standard/image-to-video'
}

export type PostFalAiMinimaxHailuo23FastStandardImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMinimaxHailuo23FastStandardImageToVideoResponse =
  PostFalAiMinimaxHailuo23FastStandardImageToVideoResponses[keyof PostFalAiMinimaxHailuo23FastStandardImageToVideoResponses]

export type GetFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/minimax/hailuo-2.3-fast/standard/image-to-video/requests/{request_id}'
  }

export type GetFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaMinimaxHailuo23FastStandardImageToVideoOutput
  }

export type GetFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdResponse =
  GetFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdResponses[keyof GetFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdResponses]

export type GetFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/minimax/hailuo-2.3/standard/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/minimax/hailuo-2.3/standard/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiMinimaxHailuo23StandardImageToVideoData = {
  body: SchemaMinimaxHailuo23StandardImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/minimax/hailuo-2.3/standard/image-to-video'
}

export type PostFalAiMinimaxHailuo23StandardImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMinimaxHailuo23StandardImageToVideoResponse =
  PostFalAiMinimaxHailuo23StandardImageToVideoResponses[keyof PostFalAiMinimaxHailuo23StandardImageToVideoResponses]

export type GetFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/minimax/hailuo-2.3/standard/image-to-video/requests/{request_id}'
  }

export type GetFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaMinimaxHailuo23StandardImageToVideoOutput
  }

export type GetFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdResponse =
  GetFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdResponses[keyof GetFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdResponses]

export type GetFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/minimax/hailuo-2.3-fast/pro/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/minimax/hailuo-2.3-fast/pro/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiMinimaxHailuo23FastProImageToVideoData = {
  body: SchemaMinimaxHailuo23FastProImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/minimax/hailuo-2.3-fast/pro/image-to-video'
}

export type PostFalAiMinimaxHailuo23FastProImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMinimaxHailuo23FastProImageToVideoResponse =
  PostFalAiMinimaxHailuo23FastProImageToVideoResponses[keyof PostFalAiMinimaxHailuo23FastProImageToVideoResponses]

export type GetFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/minimax/hailuo-2.3-fast/pro/image-to-video/requests/{request_id}'
  }

export type GetFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaMinimaxHailuo23FastProImageToVideoOutput
  }

export type GetFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdResponse =
  GetFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdResponses[keyof GetFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdResponses]

export type GetFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/bytedance/seedance/v1/pro/fast/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/bytedance/seedance/v1/pro/fast/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiBytedanceSeedanceV1ProFastImageToVideoData = {
  body: SchemaBytedanceSeedanceV1ProFastImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/bytedance/seedance/v1/pro/fast/image-to-video'
}

export type PostFalAiBytedanceSeedanceV1ProFastImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiBytedanceSeedanceV1ProFastImageToVideoResponse =
  PostFalAiBytedanceSeedanceV1ProFastImageToVideoResponses[keyof PostFalAiBytedanceSeedanceV1ProFastImageToVideoResponses]

export type GetFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/bytedance/seedance/v1/pro/fast/image-to-video/requests/{request_id}'
  }

export type GetFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaBytedanceSeedanceV1ProFastImageToVideoOutput
  }

export type GetFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdResponse =
  GetFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdResponses[keyof GetFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdResponses]

export type GetFalAiViduQ2ImageToVideoTurboRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/vidu/q2/image-to-video/turbo/requests/{request_id}/status'
}

export type GetFalAiViduQ2ImageToVideoTurboRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiViduQ2ImageToVideoTurboRequestsByRequestIdStatusResponse =
  GetFalAiViduQ2ImageToVideoTurboRequestsByRequestIdStatusResponses[keyof GetFalAiViduQ2ImageToVideoTurboRequestsByRequestIdStatusResponses]

export type PutFalAiViduQ2ImageToVideoTurboRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/vidu/q2/image-to-video/turbo/requests/{request_id}/cancel'
}

export type PutFalAiViduQ2ImageToVideoTurboRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiViduQ2ImageToVideoTurboRequestsByRequestIdCancelResponse =
  PutFalAiViduQ2ImageToVideoTurboRequestsByRequestIdCancelResponses[keyof PutFalAiViduQ2ImageToVideoTurboRequestsByRequestIdCancelResponses]

export type PostFalAiViduQ2ImageToVideoTurboData = {
  body: SchemaViduQ2ImageToVideoTurboInput
  path?: never
  query?: never
  url: '/fal-ai/vidu/q2/image-to-video/turbo'
}

export type PostFalAiViduQ2ImageToVideoTurboResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiViduQ2ImageToVideoTurboResponse =
  PostFalAiViduQ2ImageToVideoTurboResponses[keyof PostFalAiViduQ2ImageToVideoTurboResponses]

export type GetFalAiViduQ2ImageToVideoTurboRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/vidu/q2/image-to-video/turbo/requests/{request_id}'
}

export type GetFalAiViduQ2ImageToVideoTurboRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaViduQ2ImageToVideoTurboOutput
}

export type GetFalAiViduQ2ImageToVideoTurboRequestsByRequestIdResponse =
  GetFalAiViduQ2ImageToVideoTurboRequestsByRequestIdResponses[keyof GetFalAiViduQ2ImageToVideoTurboRequestsByRequestIdResponses]

export type GetFalAiViduQ2ImageToVideoProRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/vidu/q2/image-to-video/pro/requests/{request_id}/status'
}

export type GetFalAiViduQ2ImageToVideoProRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiViduQ2ImageToVideoProRequestsByRequestIdStatusResponse =
  GetFalAiViduQ2ImageToVideoProRequestsByRequestIdStatusResponses[keyof GetFalAiViduQ2ImageToVideoProRequestsByRequestIdStatusResponses]

export type PutFalAiViduQ2ImageToVideoProRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/vidu/q2/image-to-video/pro/requests/{request_id}/cancel'
}

export type PutFalAiViduQ2ImageToVideoProRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiViduQ2ImageToVideoProRequestsByRequestIdCancelResponse =
  PutFalAiViduQ2ImageToVideoProRequestsByRequestIdCancelResponses[keyof PutFalAiViduQ2ImageToVideoProRequestsByRequestIdCancelResponses]

export type PostFalAiViduQ2ImageToVideoProData = {
  body: SchemaViduQ2ImageToVideoProInput
  path?: never
  query?: never
  url: '/fal-ai/vidu/q2/image-to-video/pro'
}

export type PostFalAiViduQ2ImageToVideoProResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiViduQ2ImageToVideoProResponse =
  PostFalAiViduQ2ImageToVideoProResponses[keyof PostFalAiViduQ2ImageToVideoProResponses]

export type GetFalAiViduQ2ImageToVideoProRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/vidu/q2/image-to-video/pro/requests/{request_id}'
}

export type GetFalAiViduQ2ImageToVideoProRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaViduQ2ImageToVideoProOutput
}

export type GetFalAiViduQ2ImageToVideoProRequestsByRequestIdResponse =
  GetFalAiViduQ2ImageToVideoProRequestsByRequestIdResponses[keyof GetFalAiViduQ2ImageToVideoProRequestsByRequestIdResponses]

export type GetFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/kling-video/v2.5-turbo/standard/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/v2.5-turbo/standard/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV25TurboStandardImageToVideoData = {
  body: SchemaKlingVideoV25TurboStandardImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v2.5-turbo/standard/image-to-video'
}

export type PostFalAiKlingVideoV25TurboStandardImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV25TurboStandardImageToVideoResponse =
  PostFalAiKlingVideoV25TurboStandardImageToVideoResponses[keyof PostFalAiKlingVideoV25TurboStandardImageToVideoResponses]

export type GetFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/v2.5-turbo/standard/image-to-video/requests/{request_id}'
  }

export type GetFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaKlingVideoV25TurboStandardImageToVideoOutput
  }

export type GetFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdResponse =
  GetFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdResponses]

export type GetFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/veo3.1/fast/first-last-frame-to-video/requests/{request_id}/status'
  }

export type GetFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdStatusResponse =
  GetFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/veo3.1/fast/first-last-frame-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdCancelResponse =
  PutFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiVeo31FastFirstLastFrameToVideoData = {
  body: SchemaVeo31FastFirstLastFrameToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/veo3.1/fast/first-last-frame-to-video'
}

export type PostFalAiVeo31FastFirstLastFrameToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiVeo31FastFirstLastFrameToVideoResponse =
  PostFalAiVeo31FastFirstLastFrameToVideoResponses[keyof PostFalAiVeo31FastFirstLastFrameToVideoResponses]

export type GetFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/veo3.1/fast/first-last-frame-to-video/requests/{request_id}'
}

export type GetFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaVeo31FastFirstLastFrameToVideoOutput
  }

export type GetFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdResponse =
  GetFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdResponses[keyof GetFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdResponses]

export type GetFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/veo3.1/first-last-frame-to-video/requests/{request_id}/status'
}

export type GetFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdStatusResponse =
  GetFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/veo3.1/first-last-frame-to-video/requests/{request_id}/cancel'
}

export type PutFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdCancelResponse =
  PutFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiVeo31FirstLastFrameToVideoData = {
  body: SchemaVeo31FirstLastFrameToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/veo3.1/first-last-frame-to-video'
}

export type PostFalAiVeo31FirstLastFrameToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiVeo31FirstLastFrameToVideoResponse =
  PostFalAiVeo31FirstLastFrameToVideoResponses[keyof PostFalAiVeo31FirstLastFrameToVideoResponses]

export type GetFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/veo3.1/first-last-frame-to-video/requests/{request_id}'
}

export type GetFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaVeo31FirstLastFrameToVideoOutput
}

export type GetFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdResponse =
  GetFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdResponses[keyof GetFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdResponses]

export type GetFalAiVeo31ReferenceToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/veo3.1/reference-to-video/requests/{request_id}/status'
}

export type GetFalAiVeo31ReferenceToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiVeo31ReferenceToVideoRequestsByRequestIdStatusResponse =
  GetFalAiVeo31ReferenceToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiVeo31ReferenceToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiVeo31ReferenceToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/veo3.1/reference-to-video/requests/{request_id}/cancel'
}

export type PutFalAiVeo31ReferenceToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiVeo31ReferenceToVideoRequestsByRequestIdCancelResponse =
  PutFalAiVeo31ReferenceToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiVeo31ReferenceToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiVeo31ReferenceToVideoData = {
  body: SchemaVeo31ReferenceToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/veo3.1/reference-to-video'
}

export type PostFalAiVeo31ReferenceToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiVeo31ReferenceToVideoResponse =
  PostFalAiVeo31ReferenceToVideoResponses[keyof PostFalAiVeo31ReferenceToVideoResponses]

export type GetFalAiVeo31ReferenceToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/veo3.1/reference-to-video/requests/{request_id}'
}

export type GetFalAiVeo31ReferenceToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaVeo31ReferenceToVideoOutput
}

export type GetFalAiVeo31ReferenceToVideoRequestsByRequestIdResponse =
  GetFalAiVeo31ReferenceToVideoRequestsByRequestIdResponses[keyof GetFalAiVeo31ReferenceToVideoRequestsByRequestIdResponses]

export type GetFalAiVeo31FastImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/veo3.1/fast/image-to-video/requests/{request_id}/status'
}

export type GetFalAiVeo31FastImageToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiVeo31FastImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiVeo31FastImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiVeo31FastImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiVeo31FastImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/veo3.1/fast/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiVeo31FastImageToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiVeo31FastImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiVeo31FastImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiVeo31FastImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiVeo31FastImageToVideoData = {
  body: SchemaVeo31FastImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/veo3.1/fast/image-to-video'
}

export type PostFalAiVeo31FastImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiVeo31FastImageToVideoResponse =
  PostFalAiVeo31FastImageToVideoResponses[keyof PostFalAiVeo31FastImageToVideoResponses]

export type GetFalAiVeo31FastImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/veo3.1/fast/image-to-video/requests/{request_id}'
}

export type GetFalAiVeo31FastImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaVeo31FastImageToVideoOutput
}

export type GetFalAiVeo31FastImageToVideoRequestsByRequestIdResponse =
  GetFalAiVeo31FastImageToVideoRequestsByRequestIdResponses[keyof GetFalAiVeo31FastImageToVideoRequestsByRequestIdResponses]

export type GetFalAiVeo31ImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/veo3.1/image-to-video/requests/{request_id}/status'
}

export type GetFalAiVeo31ImageToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiVeo31ImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiVeo31ImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiVeo31ImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiVeo31ImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/veo3.1/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiVeo31ImageToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiVeo31ImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiVeo31ImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiVeo31ImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiVeo31ImageToVideoData = {
  body: SchemaVeo31ImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/veo3.1/image-to-video'
}

export type PostFalAiVeo31ImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiVeo31ImageToVideoResponse =
  PostFalAiVeo31ImageToVideoResponses[keyof PostFalAiVeo31ImageToVideoResponses]

export type GetFalAiVeo31ImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/veo3.1/image-to-video/requests/{request_id}'
}

export type GetFalAiVeo31ImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaVeo31ImageToVideoOutput
}

export type GetFalAiVeo31ImageToVideoRequestsByRequestIdResponse =
  GetFalAiVeo31ImageToVideoRequestsByRequestIdResponses[keyof GetFalAiVeo31ImageToVideoRequestsByRequestIdResponses]

export type GetFalAiSora2ImageToVideoProRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/sora-2/image-to-video/pro/requests/{request_id}/status'
}

export type GetFalAiSora2ImageToVideoProRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiSora2ImageToVideoProRequestsByRequestIdStatusResponse =
  GetFalAiSora2ImageToVideoProRequestsByRequestIdStatusResponses[keyof GetFalAiSora2ImageToVideoProRequestsByRequestIdStatusResponses]

export type PutFalAiSora2ImageToVideoProRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/sora-2/image-to-video/pro/requests/{request_id}/cancel'
}

export type PutFalAiSora2ImageToVideoProRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiSora2ImageToVideoProRequestsByRequestIdCancelResponse =
  PutFalAiSora2ImageToVideoProRequestsByRequestIdCancelResponses[keyof PutFalAiSora2ImageToVideoProRequestsByRequestIdCancelResponses]

export type PostFalAiSora2ImageToVideoProData = {
  body: SchemaSora2ImageToVideoProInput
  path?: never
  query?: never
  url: '/fal-ai/sora-2/image-to-video/pro'
}

export type PostFalAiSora2ImageToVideoProResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiSora2ImageToVideoProResponse =
  PostFalAiSora2ImageToVideoProResponses[keyof PostFalAiSora2ImageToVideoProResponses]

export type GetFalAiSora2ImageToVideoProRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/sora-2/image-to-video/pro/requests/{request_id}'
}

export type GetFalAiSora2ImageToVideoProRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaSora2ImageToVideoProOutput
}

export type GetFalAiSora2ImageToVideoProRequestsByRequestIdResponse =
  GetFalAiSora2ImageToVideoProRequestsByRequestIdResponses[keyof GetFalAiSora2ImageToVideoProRequestsByRequestIdResponses]

export type GetFalAiSora2ImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/sora-2/image-to-video/requests/{request_id}/status'
}

export type GetFalAiSora2ImageToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiSora2ImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiSora2ImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiSora2ImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiSora2ImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/sora-2/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiSora2ImageToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiSora2ImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiSora2ImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiSora2ImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiSora2ImageToVideoData = {
  body: SchemaSora2ImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/sora-2/image-to-video'
}

export type PostFalAiSora2ImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiSora2ImageToVideoResponse =
  PostFalAiSora2ImageToVideoResponses[keyof PostFalAiSora2ImageToVideoResponses]

export type GetFalAiSora2ImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/sora-2/image-to-video/requests/{request_id}'
}

export type GetFalAiSora2ImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaSora2ImageToVideoOutput
}

export type GetFalAiSora2ImageToVideoRequestsByRequestIdResponse =
  GetFalAiSora2ImageToVideoRequestsByRequestIdResponses[keyof GetFalAiSora2ImageToVideoRequestsByRequestIdResponses]

export type GetFalAiOviImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ovi/image-to-video/requests/{request_id}/status'
}

export type GetFalAiOviImageToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiOviImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiOviImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiOviImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiOviImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ovi/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiOviImageToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiOviImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiOviImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiOviImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiOviImageToVideoData = {
  body: SchemaOviImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/ovi/image-to-video'
}

export type PostFalAiOviImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiOviImageToVideoResponse =
  PostFalAiOviImageToVideoResponses[keyof PostFalAiOviImageToVideoResponses]

export type GetFalAiOviImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ovi/image-to-video/requests/{request_id}'
}

export type GetFalAiOviImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaOviImageToVideoOutput
}

export type GetFalAiOviImageToVideoRequestsByRequestIdResponse =
  GetFalAiOviImageToVideoRequestsByRequestIdResponses[keyof GetFalAiOviImageToVideoRequestsByRequestIdResponses]

export type GetVeedFabric10FastRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/veed/fabric-1.0/fast/requests/{request_id}/status'
}

export type GetVeedFabric10FastRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetVeedFabric10FastRequestsByRequestIdStatusResponse =
  GetVeedFabric10FastRequestsByRequestIdStatusResponses[keyof GetVeedFabric10FastRequestsByRequestIdStatusResponses]

export type PutVeedFabric10FastRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/veed/fabric-1.0/fast/requests/{request_id}/cancel'
}

export type PutVeedFabric10FastRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutVeedFabric10FastRequestsByRequestIdCancelResponse =
  PutVeedFabric10FastRequestsByRequestIdCancelResponses[keyof PutVeedFabric10FastRequestsByRequestIdCancelResponses]

export type PostVeedFabric10FastData = {
  body: SchemaFabric10FastInput
  path?: never
  query?: never
  url: '/veed/fabric-1.0/fast'
}

export type PostVeedFabric10FastResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostVeedFabric10FastResponse =
  PostVeedFabric10FastResponses[keyof PostVeedFabric10FastResponses]

export type GetVeedFabric10FastRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/veed/fabric-1.0/fast/requests/{request_id}'
}

export type GetVeedFabric10FastRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaFabric10FastOutput
}

export type GetVeedFabric10FastRequestsByRequestIdResponse =
  GetVeedFabric10FastRequestsByRequestIdResponses[keyof GetVeedFabric10FastRequestsByRequestIdResponses]

export type GetFalAiBytedanceOmnihumanV15RequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/bytedance/omnihuman/v1.5/requests/{request_id}/status'
}

export type GetFalAiBytedanceOmnihumanV15RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiBytedanceOmnihumanV15RequestsByRequestIdStatusResponse =
  GetFalAiBytedanceOmnihumanV15RequestsByRequestIdStatusResponses[keyof GetFalAiBytedanceOmnihumanV15RequestsByRequestIdStatusResponses]

export type PutFalAiBytedanceOmnihumanV15RequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/bytedance/omnihuman/v1.5/requests/{request_id}/cancel'
}

export type PutFalAiBytedanceOmnihumanV15RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiBytedanceOmnihumanV15RequestsByRequestIdCancelResponse =
  PutFalAiBytedanceOmnihumanV15RequestsByRequestIdCancelResponses[keyof PutFalAiBytedanceOmnihumanV15RequestsByRequestIdCancelResponses]

export type PostFalAiBytedanceOmnihumanV15Data = {
  body: SchemaBytedanceOmnihumanV15Input
  path?: never
  query?: never
  url: '/fal-ai/bytedance/omnihuman/v1.5'
}

export type PostFalAiBytedanceOmnihumanV15Responses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiBytedanceOmnihumanV15Response =
  PostFalAiBytedanceOmnihumanV15Responses[keyof PostFalAiBytedanceOmnihumanV15Responses]

export type GetFalAiBytedanceOmnihumanV15RequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/bytedance/omnihuman/v1.5/requests/{request_id}'
}

export type GetFalAiBytedanceOmnihumanV15RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaBytedanceOmnihumanV15Output
}

export type GetFalAiBytedanceOmnihumanV15RequestsByRequestIdResponse =
  GetFalAiBytedanceOmnihumanV15RequestsByRequestIdResponses[keyof GetFalAiBytedanceOmnihumanV15RequestsByRequestIdResponses]

export type GetVeedFabric10RequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/veed/fabric-1.0/requests/{request_id}/status'
}

export type GetVeedFabric10RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetVeedFabric10RequestsByRequestIdStatusResponse =
  GetVeedFabric10RequestsByRequestIdStatusResponses[keyof GetVeedFabric10RequestsByRequestIdStatusResponses]

export type PutVeedFabric10RequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/veed/fabric-1.0/requests/{request_id}/cancel'
}

export type PutVeedFabric10RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutVeedFabric10RequestsByRequestIdCancelResponse =
  PutVeedFabric10RequestsByRequestIdCancelResponses[keyof PutVeedFabric10RequestsByRequestIdCancelResponses]

export type PostVeedFabric10Data = {
  body: SchemaFabric10Input
  path?: never
  query?: never
  url: '/veed/fabric-1.0'
}

export type PostVeedFabric10Responses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostVeedFabric10Response =
  PostVeedFabric10Responses[keyof PostVeedFabric10Responses]

export type GetVeedFabric10RequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/veed/fabric-1.0/requests/{request_id}'
}

export type GetVeedFabric10RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaFabric10Output
}

export type GetVeedFabric10RequestsByRequestIdResponse =
  GetVeedFabric10RequestsByRequestIdResponses[keyof GetVeedFabric10RequestsByRequestIdResponses]

export type GetFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/kling-video/v1/standard/ai-avatar/requests/{request_id}/status'
  }

export type GetFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/v1/standard/ai-avatar/requests/{request_id}/cancel'
  }

export type PutFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV1StandardAiAvatarData = {
  body: SchemaKlingVideoV1StandardAiAvatarInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v1/standard/ai-avatar'
}

export type PostFalAiKlingVideoV1StandardAiAvatarResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV1StandardAiAvatarResponse =
  PostFalAiKlingVideoV1StandardAiAvatarResponses[keyof PostFalAiKlingVideoV1StandardAiAvatarResponses]

export type GetFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v1/standard/ai-avatar/requests/{request_id}'
}

export type GetFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKlingVideoV1StandardAiAvatarOutput
}

export type GetFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdResponse =
  GetFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdResponses]

export type GetFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kling-video/v1/pro/ai-avatar/requests/{request_id}/status'
}

export type GetFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v1/pro/ai-avatar/requests/{request_id}/cancel'
}

export type PutFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV1ProAiAvatarData = {
  body: SchemaKlingVideoV1ProAiAvatarInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v1/pro/ai-avatar'
}

export type PostFalAiKlingVideoV1ProAiAvatarResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV1ProAiAvatarResponse =
  PostFalAiKlingVideoV1ProAiAvatarResponses[keyof PostFalAiKlingVideoV1ProAiAvatarResponses]

export type GetFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v1/pro/ai-avatar/requests/{request_id}'
}

export type GetFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKlingVideoV1ProAiAvatarOutput
}

export type GetFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdResponse =
  GetFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdResponses]

export type GetDecartLucy14bImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/decart/lucy-14b/image-to-video/requests/{request_id}/status'
}

export type GetDecartLucy14bImageToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetDecartLucy14bImageToVideoRequestsByRequestIdStatusResponse =
  GetDecartLucy14bImageToVideoRequestsByRequestIdStatusResponses[keyof GetDecartLucy14bImageToVideoRequestsByRequestIdStatusResponses]

export type PutDecartLucy14bImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/decart/lucy-14b/image-to-video/requests/{request_id}/cancel'
}

export type PutDecartLucy14bImageToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutDecartLucy14bImageToVideoRequestsByRequestIdCancelResponse =
  PutDecartLucy14bImageToVideoRequestsByRequestIdCancelResponses[keyof PutDecartLucy14bImageToVideoRequestsByRequestIdCancelResponses]

export type PostDecartLucy14bImageToVideoData = {
  body: SchemaLucy14bImageToVideoInput
  path?: never
  query?: never
  url: '/decart/lucy-14b/image-to-video'
}

export type PostDecartLucy14bImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostDecartLucy14bImageToVideoResponse =
  PostDecartLucy14bImageToVideoResponses[keyof PostDecartLucy14bImageToVideoResponses]

export type GetDecartLucy14bImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/decart/lucy-14b/image-to-video/requests/{request_id}'
}

export type GetDecartLucy14bImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLucy14bImageToVideoOutput
}

export type GetDecartLucy14bImageToVideoRequestsByRequestIdResponse =
  GetDecartLucy14bImageToVideoRequestsByRequestIdResponses[keyof GetDecartLucy14bImageToVideoRequestsByRequestIdResponses]

export type GetFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/bytedance/seedance/v1/lite/reference-to-video/requests/{request_id}/status'
  }

export type GetFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdStatusResponse =
  GetFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/bytedance/seedance/v1/lite/reference-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdCancelResponse =
  PutFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiBytedanceSeedanceV1LiteReferenceToVideoData = {
  body: SchemaBytedanceSeedanceV1LiteReferenceToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/bytedance/seedance/v1/lite/reference-to-video'
}

export type PostFalAiBytedanceSeedanceV1LiteReferenceToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiBytedanceSeedanceV1LiteReferenceToVideoResponse =
  PostFalAiBytedanceSeedanceV1LiteReferenceToVideoResponses[keyof PostFalAiBytedanceSeedanceV1LiteReferenceToVideoResponses]

export type GetFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/bytedance/seedance/v1/lite/reference-to-video/requests/{request_id}'
  }

export type GetFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaBytedanceSeedanceV1LiteReferenceToVideoOutput
  }

export type GetFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdResponse =
  GetFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdResponses[keyof GetFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdResponses]

export type GetFalAiWanAtiRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/wan-ati/requests/{request_id}/status'
}

export type GetFalAiWanAtiRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiWanAtiRequestsByRequestIdStatusResponse =
  GetFalAiWanAtiRequestsByRequestIdStatusResponses[keyof GetFalAiWanAtiRequestsByRequestIdStatusResponses]

export type PutFalAiWanAtiRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan-ati/requests/{request_id}/cancel'
}

export type PutFalAiWanAtiRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiWanAtiRequestsByRequestIdCancelResponse =
  PutFalAiWanAtiRequestsByRequestIdCancelResponses[keyof PutFalAiWanAtiRequestsByRequestIdCancelResponses]

export type PostFalAiWanAtiData = {
  body: SchemaWanAtiInput
  path?: never
  query?: never
  url: '/fal-ai/wan-ati'
}

export type PostFalAiWanAtiResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiWanAtiResponse =
  PostFalAiWanAtiResponses[keyof PostFalAiWanAtiResponses]

export type GetFalAiWanAtiRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan-ati/requests/{request_id}'
}

export type GetFalAiWanAtiRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaWanAtiOutput
}

export type GetFalAiWanAtiRequestsByRequestIdResponse =
  GetFalAiWanAtiRequestsByRequestIdResponses[keyof GetFalAiWanAtiRequestsByRequestIdResponses]

export type GetFalAiDecartLucy5bImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/decart/lucy-5b/image-to-video/requests/{request_id}/status'
}

export type GetFalAiDecartLucy5bImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiDecartLucy5bImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiDecartLucy5bImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiDecartLucy5bImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiDecartLucy5bImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/decart/lucy-5b/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiDecartLucy5bImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiDecartLucy5bImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiDecartLucy5bImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiDecartLucy5bImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiDecartLucy5bImageToVideoData = {
  body: SchemaDecartLucy5bImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/decart/lucy-5b/image-to-video'
}

export type PostFalAiDecartLucy5bImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiDecartLucy5bImageToVideoResponse =
  PostFalAiDecartLucy5bImageToVideoResponses[keyof PostFalAiDecartLucy5bImageToVideoResponses]

export type GetFalAiDecartLucy5bImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/decart/lucy-5b/image-to-video/requests/{request_id}'
}

export type GetFalAiDecartLucy5bImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaDecartLucy5bImageToVideoOutput
}

export type GetFalAiDecartLucy5bImageToVideoRequestsByRequestIdResponse =
  GetFalAiDecartLucy5bImageToVideoRequestsByRequestIdResponses[keyof GetFalAiDecartLucy5bImageToVideoRequestsByRequestIdResponses]

export type GetFalAiPixverseV5TransitionRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v5/transition/requests/{request_id}/status'
}

export type GetFalAiPixverseV5TransitionRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPixverseV5TransitionRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV5TransitionRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV5TransitionRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV5TransitionRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v5/transition/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV5TransitionRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPixverseV5TransitionRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV5TransitionRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV5TransitionRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV5TransitionData = {
  body: SchemaPixverseV5TransitionInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v5/transition'
}

export type PostFalAiPixverseV5TransitionResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV5TransitionResponse =
  PostFalAiPixverseV5TransitionResponses[keyof PostFalAiPixverseV5TransitionResponses]

export type GetFalAiPixverseV5TransitionRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v5/transition/requests/{request_id}'
}

export type GetFalAiPixverseV5TransitionRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV5TransitionOutput
}

export type GetFalAiPixverseV5TransitionRequestsByRequestIdResponse =
  GetFalAiPixverseV5TransitionRequestsByRequestIdResponses[keyof GetFalAiPixverseV5TransitionRequestsByRequestIdResponses]

export type GetFalAiPixverseV5EffectsRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v5/effects/requests/{request_id}/status'
}

export type GetFalAiPixverseV5EffectsRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPixverseV5EffectsRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV5EffectsRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV5EffectsRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV5EffectsRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v5/effects/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV5EffectsRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPixverseV5EffectsRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV5EffectsRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV5EffectsRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV5EffectsData = {
  body: SchemaPixverseV5EffectsInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v5/effects'
}

export type PostFalAiPixverseV5EffectsResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV5EffectsResponse =
  PostFalAiPixverseV5EffectsResponses[keyof PostFalAiPixverseV5EffectsResponses]

export type GetFalAiPixverseV5EffectsRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v5/effects/requests/{request_id}'
}

export type GetFalAiPixverseV5EffectsRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV5EffectsOutput
}

export type GetFalAiPixverseV5EffectsRequestsByRequestIdResponse =
  GetFalAiPixverseV5EffectsRequestsByRequestIdResponses[keyof GetFalAiPixverseV5EffectsRequestsByRequestIdResponses]

export type GetFalAiPixverseV5ImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v5/image-to-video/requests/{request_id}/status'
}

export type GetFalAiPixverseV5ImageToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPixverseV5ImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV5ImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV5ImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV5ImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v5/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV5ImageToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPixverseV5ImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV5ImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV5ImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV5ImageToVideoData = {
  body: SchemaPixverseV5ImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v5/image-to-video'
}

export type PostFalAiPixverseV5ImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV5ImageToVideoResponse =
  PostFalAiPixverseV5ImageToVideoResponses[keyof PostFalAiPixverseV5ImageToVideoResponses]

export type GetFalAiPixverseV5ImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v5/image-to-video/requests/{request_id}'
}

export type GetFalAiPixverseV5ImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV5ImageToVideoOutput
}

export type GetFalAiPixverseV5ImageToVideoRequestsByRequestIdResponse =
  GetFalAiPixverseV5ImageToVideoRequestsByRequestIdResponses[keyof GetFalAiPixverseV5ImageToVideoRequestsByRequestIdResponses]

export type GetMoonvalleyMareyI2vRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/moonvalley/marey/i2v/requests/{request_id}/status'
}

export type GetMoonvalleyMareyI2vRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetMoonvalleyMareyI2vRequestsByRequestIdStatusResponse =
  GetMoonvalleyMareyI2vRequestsByRequestIdStatusResponses[keyof GetMoonvalleyMareyI2vRequestsByRequestIdStatusResponses]

export type PutMoonvalleyMareyI2vRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/moonvalley/marey/i2v/requests/{request_id}/cancel'
}

export type PutMoonvalleyMareyI2vRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutMoonvalleyMareyI2vRequestsByRequestIdCancelResponse =
  PutMoonvalleyMareyI2vRequestsByRequestIdCancelResponses[keyof PutMoonvalleyMareyI2vRequestsByRequestIdCancelResponses]

export type PostMoonvalleyMareyI2vData = {
  body: SchemaMareyI2vInput
  path?: never
  query?: never
  url: '/moonvalley/marey/i2v'
}

export type PostMoonvalleyMareyI2vResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostMoonvalleyMareyI2vResponse =
  PostMoonvalleyMareyI2vResponses[keyof PostMoonvalleyMareyI2vResponses]

export type GetMoonvalleyMareyI2vRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/moonvalley/marey/i2v/requests/{request_id}'
}

export type GetMoonvalleyMareyI2vRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaMareyI2vOutput
}

export type GetMoonvalleyMareyI2vRequestsByRequestIdResponse =
  GetMoonvalleyMareyI2vRequestsByRequestIdResponses[keyof GetMoonvalleyMareyI2vRequestsByRequestIdResponses]

export type GetFalAiBytedanceVideoStylizeRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/bytedance/video-stylize/requests/{request_id}/status'
}

export type GetFalAiBytedanceVideoStylizeRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiBytedanceVideoStylizeRequestsByRequestIdStatusResponse =
  GetFalAiBytedanceVideoStylizeRequestsByRequestIdStatusResponses[keyof GetFalAiBytedanceVideoStylizeRequestsByRequestIdStatusResponses]

export type PutFalAiBytedanceVideoStylizeRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/bytedance/video-stylize/requests/{request_id}/cancel'
}

export type PutFalAiBytedanceVideoStylizeRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiBytedanceVideoStylizeRequestsByRequestIdCancelResponse =
  PutFalAiBytedanceVideoStylizeRequestsByRequestIdCancelResponses[keyof PutFalAiBytedanceVideoStylizeRequestsByRequestIdCancelResponses]

export type PostFalAiBytedanceVideoStylizeData = {
  body: SchemaBytedanceVideoStylizeInput
  path?: never
  query?: never
  url: '/fal-ai/bytedance/video-stylize'
}

export type PostFalAiBytedanceVideoStylizeResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiBytedanceVideoStylizeResponse =
  PostFalAiBytedanceVideoStylizeResponses[keyof PostFalAiBytedanceVideoStylizeResponses]

export type GetFalAiBytedanceVideoStylizeRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/bytedance/video-stylize/requests/{request_id}'
}

export type GetFalAiBytedanceVideoStylizeRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaBytedanceVideoStylizeOutput
}

export type GetFalAiBytedanceVideoStylizeRequestsByRequestIdResponse =
  GetFalAiBytedanceVideoStylizeRequestsByRequestIdResponses[keyof GetFalAiBytedanceVideoStylizeRequestsByRequestIdResponses]

export type GetFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/wan/v2.2-a14b/image-to-video/lora/requests/{request_id}/status'
}

export type GetFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdStatusResponse =
  GetFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdStatusResponses[keyof GetFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdStatusResponses]

export type PutFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan/v2.2-a14b/image-to-video/lora/requests/{request_id}/cancel'
}

export type PutFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdCancelResponse =
  PutFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdCancelResponses[keyof PutFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdCancelResponses]

export type PostFalAiWanV22A14bImageToVideoLoraData = {
  body: SchemaWanV22A14bImageToVideoLoraInput
  path?: never
  query?: never
  url: '/fal-ai/wan/v2.2-a14b/image-to-video/lora'
}

export type PostFalAiWanV22A14bImageToVideoLoraResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiWanV22A14bImageToVideoLoraResponse =
  PostFalAiWanV22A14bImageToVideoLoraResponses[keyof PostFalAiWanV22A14bImageToVideoLoraResponses]

export type GetFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan/v2.2-a14b/image-to-video/lora/requests/{request_id}'
}

export type GetFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaWanV22A14bImageToVideoLoraOutput
}

export type GetFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdResponse =
  GetFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdResponses[keyof GetFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdResponses]

export type GetFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/minimax/hailuo-02-fast/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/minimax/hailuo-02-fast/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiMinimaxHailuo02FastImageToVideoData = {
  body: SchemaMinimaxHailuo02FastImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/minimax/hailuo-02-fast/image-to-video'
}

export type PostFalAiMinimaxHailuo02FastImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMinimaxHailuo02FastImageToVideoResponse =
  PostFalAiMinimaxHailuo02FastImageToVideoResponses[keyof PostFalAiMinimaxHailuo02FastImageToVideoResponses]

export type GetFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax/hailuo-02-fast/image-to-video/requests/{request_id}'
}

export type GetFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaMinimaxHailuo02FastImageToVideoOutput
  }

export type GetFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdResponse =
  GetFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdResponses[keyof GetFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdResponses]

export type GetFalAiVeo3ImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/veo3/image-to-video/requests/{request_id}/status'
}

export type GetFalAiVeo3ImageToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiVeo3ImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiVeo3ImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiVeo3ImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiVeo3ImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/veo3/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiVeo3ImageToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiVeo3ImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiVeo3ImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiVeo3ImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiVeo3ImageToVideoData = {
  body: SchemaVeo3ImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/veo3/image-to-video'
}

export type PostFalAiVeo3ImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiVeo3ImageToVideoResponse =
  PostFalAiVeo3ImageToVideoResponses[keyof PostFalAiVeo3ImageToVideoResponses]

export type GetFalAiVeo3ImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/veo3/image-to-video/requests/{request_id}'
}

export type GetFalAiVeo3ImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaVeo3ImageToVideoOutput
}

export type GetFalAiVeo3ImageToVideoRequestsByRequestIdResponse =
  GetFalAiVeo3ImageToVideoRequestsByRequestIdResponses[keyof GetFalAiVeo3ImageToVideoRequestsByRequestIdResponses]

export type GetFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/wan/v2.2-a14b/image-to-video/turbo/requests/{request_id}/status'
}

export type GetFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdStatusResponse =
  GetFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdStatusResponses[keyof GetFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdStatusResponses]

export type PutFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan/v2.2-a14b/image-to-video/turbo/requests/{request_id}/cancel'
}

export type PutFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdCancelResponse =
  PutFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdCancelResponses[keyof PutFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdCancelResponses]

export type PostFalAiWanV22A14bImageToVideoTurboData = {
  body: SchemaWanV22A14bImageToVideoTurboInput
  path?: never
  query?: never
  url: '/fal-ai/wan/v2.2-a14b/image-to-video/turbo'
}

export type PostFalAiWanV22A14bImageToVideoTurboResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiWanV22A14bImageToVideoTurboResponse =
  PostFalAiWanV22A14bImageToVideoTurboResponses[keyof PostFalAiWanV22A14bImageToVideoTurboResponses]

export type GetFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan/v2.2-a14b/image-to-video/turbo/requests/{request_id}'
}

export type GetFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaWanV22A14bImageToVideoTurboOutput
}

export type GetFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdResponse =
  GetFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdResponses[keyof GetFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdResponses]

export type GetFalAiWanV225bImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/wan/v2.2-5b/image-to-video/requests/{request_id}/status'
}

export type GetFalAiWanV225bImageToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiWanV225bImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiWanV225bImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiWanV225bImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiWanV225bImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan/v2.2-5b/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiWanV225bImageToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiWanV225bImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiWanV225bImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiWanV225bImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiWanV225bImageToVideoData = {
  body: SchemaWanV225bImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/wan/v2.2-5b/image-to-video'
}

export type PostFalAiWanV225bImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiWanV225bImageToVideoResponse =
  PostFalAiWanV225bImageToVideoResponses[keyof PostFalAiWanV225bImageToVideoResponses]

export type GetFalAiWanV225bImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan/v2.2-5b/image-to-video/requests/{request_id}'
}

export type GetFalAiWanV225bImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaWanV225bImageToVideoOutput
}

export type GetFalAiWanV225bImageToVideoRequestsByRequestIdResponse =
  GetFalAiWanV225bImageToVideoRequestsByRequestIdResponses[keyof GetFalAiWanV225bImageToVideoRequestsByRequestIdResponses]

export type GetFalAiWanV22A14bImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/wan/v2.2-a14b/image-to-video/requests/{request_id}/status'
}

export type GetFalAiWanV22A14bImageToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiWanV22A14bImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiWanV22A14bImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiWanV22A14bImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiWanV22A14bImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan/v2.2-a14b/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiWanV22A14bImageToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiWanV22A14bImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiWanV22A14bImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiWanV22A14bImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiWanV22A14bImageToVideoData = {
  body: SchemaWanV22A14bImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/wan/v2.2-a14b/image-to-video'
}

export type PostFalAiWanV22A14bImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiWanV22A14bImageToVideoResponse =
  PostFalAiWanV22A14bImageToVideoResponses[keyof PostFalAiWanV22A14bImageToVideoResponses]

export type GetFalAiWanV22A14bImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan/v2.2-a14b/image-to-video/requests/{request_id}'
}

export type GetFalAiWanV22A14bImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaWanV22A14bImageToVideoOutput
}

export type GetFalAiWanV22A14bImageToVideoRequestsByRequestIdResponse =
  GetFalAiWanV22A14bImageToVideoRequestsByRequestIdResponses[keyof GetFalAiWanV22A14bImageToVideoRequestsByRequestIdResponses]

export type GetFalAiBytedanceOmnihumanRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/bytedance/omnihuman/requests/{request_id}/status'
}

export type GetFalAiBytedanceOmnihumanRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiBytedanceOmnihumanRequestsByRequestIdStatusResponse =
  GetFalAiBytedanceOmnihumanRequestsByRequestIdStatusResponses[keyof GetFalAiBytedanceOmnihumanRequestsByRequestIdStatusResponses]

export type PutFalAiBytedanceOmnihumanRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/bytedance/omnihuman/requests/{request_id}/cancel'
}

export type PutFalAiBytedanceOmnihumanRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiBytedanceOmnihumanRequestsByRequestIdCancelResponse =
  PutFalAiBytedanceOmnihumanRequestsByRequestIdCancelResponses[keyof PutFalAiBytedanceOmnihumanRequestsByRequestIdCancelResponses]

export type PostFalAiBytedanceOmnihumanData = {
  body: SchemaBytedanceOmnihumanInput
  path?: never
  query?: never
  url: '/fal-ai/bytedance/omnihuman'
}

export type PostFalAiBytedanceOmnihumanResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiBytedanceOmnihumanResponse =
  PostFalAiBytedanceOmnihumanResponses[keyof PostFalAiBytedanceOmnihumanResponses]

export type GetFalAiBytedanceOmnihumanRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/bytedance/omnihuman/requests/{request_id}'
}

export type GetFalAiBytedanceOmnihumanRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaBytedanceOmnihumanOutput
}

export type GetFalAiBytedanceOmnihumanRequestsByRequestIdResponse =
  GetFalAiBytedanceOmnihumanRequestsByRequestIdResponses[keyof GetFalAiBytedanceOmnihumanRequestsByRequestIdResponses]

export type GetFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/ltxv-13b-098-distilled/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/ltxv-13b-098-distilled/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiLtxv13B098DistilledImageToVideoData = {
  body: SchemaLtxv13B098DistilledImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/ltxv-13b-098-distilled/image-to-video'
}

export type PostFalAiLtxv13B098DistilledImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLtxv13B098DistilledImageToVideoResponse =
  PostFalAiLtxv13B098DistilledImageToVideoResponses[keyof PostFalAiLtxv13B098DistilledImageToVideoResponses]

export type GetFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltxv-13b-098-distilled/image-to-video/requests/{request_id}'
}

export type GetFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaLtxv13B098DistilledImageToVideoOutput
  }

export type GetFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdResponse =
  GetFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdResponses[keyof GetFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdResponses]

export type GetFalAiVeo3FastImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/veo3/fast/image-to-video/requests/{request_id}/status'
}

export type GetFalAiVeo3FastImageToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiVeo3FastImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiVeo3FastImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiVeo3FastImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiVeo3FastImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/veo3/fast/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiVeo3FastImageToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiVeo3FastImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiVeo3FastImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiVeo3FastImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiVeo3FastImageToVideoData = {
  body: SchemaVeo3FastImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/veo3/fast/image-to-video'
}

export type PostFalAiVeo3FastImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiVeo3FastImageToVideoResponse =
  PostFalAiVeo3FastImageToVideoResponses[keyof PostFalAiVeo3FastImageToVideoResponses]

export type GetFalAiVeo3FastImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/veo3/fast/image-to-video/requests/{request_id}'
}

export type GetFalAiVeo3FastImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaVeo3FastImageToVideoOutput
}

export type GetFalAiVeo3FastImageToVideoRequestsByRequestIdResponse =
  GetFalAiVeo3FastImageToVideoRequestsByRequestIdResponses[keyof GetFalAiVeo3FastImageToVideoRequestsByRequestIdResponses]

export type GetFalAiViduQ1ReferenceToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/vidu/q1/reference-to-video/requests/{request_id}/status'
}

export type GetFalAiViduQ1ReferenceToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiViduQ1ReferenceToVideoRequestsByRequestIdStatusResponse =
  GetFalAiViduQ1ReferenceToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiViduQ1ReferenceToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiViduQ1ReferenceToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/vidu/q1/reference-to-video/requests/{request_id}/cancel'
}

export type PutFalAiViduQ1ReferenceToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiViduQ1ReferenceToVideoRequestsByRequestIdCancelResponse =
  PutFalAiViduQ1ReferenceToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiViduQ1ReferenceToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiViduQ1ReferenceToVideoData = {
  body: SchemaViduQ1ReferenceToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/vidu/q1/reference-to-video'
}

export type PostFalAiViduQ1ReferenceToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiViduQ1ReferenceToVideoResponse =
  PostFalAiViduQ1ReferenceToVideoResponses[keyof PostFalAiViduQ1ReferenceToVideoResponses]

export type GetFalAiViduQ1ReferenceToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/vidu/q1/reference-to-video/requests/{request_id}'
}

export type GetFalAiViduQ1ReferenceToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaViduQ1ReferenceToVideoOutput
}

export type GetFalAiViduQ1ReferenceToVideoRequestsByRequestIdResponse =
  GetFalAiViduQ1ReferenceToVideoRequestsByRequestIdResponses[keyof GetFalAiViduQ1ReferenceToVideoRequestsByRequestIdResponses]

export type GetFalAiAiAvatarSingleTextRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ai-avatar/single-text/requests/{request_id}/status'
}

export type GetFalAiAiAvatarSingleTextRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiAiAvatarSingleTextRequestsByRequestIdStatusResponse =
  GetFalAiAiAvatarSingleTextRequestsByRequestIdStatusResponses[keyof GetFalAiAiAvatarSingleTextRequestsByRequestIdStatusResponses]

export type PutFalAiAiAvatarSingleTextRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ai-avatar/single-text/requests/{request_id}/cancel'
}

export type PutFalAiAiAvatarSingleTextRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiAiAvatarSingleTextRequestsByRequestIdCancelResponse =
  PutFalAiAiAvatarSingleTextRequestsByRequestIdCancelResponses[keyof PutFalAiAiAvatarSingleTextRequestsByRequestIdCancelResponses]

export type PostFalAiAiAvatarSingleTextData = {
  body: SchemaAiAvatarSingleTextInput
  path?: never
  query?: never
  url: '/fal-ai/ai-avatar/single-text'
}

export type PostFalAiAiAvatarSingleTextResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiAiAvatarSingleTextResponse =
  PostFalAiAiAvatarSingleTextResponses[keyof PostFalAiAiAvatarSingleTextResponses]

export type GetFalAiAiAvatarSingleTextRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ai-avatar/single-text/requests/{request_id}'
}

export type GetFalAiAiAvatarSingleTextRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaAiAvatarSingleTextOutput
}

export type GetFalAiAiAvatarSingleTextRequestsByRequestIdResponse =
  GetFalAiAiAvatarSingleTextRequestsByRequestIdResponses[keyof GetFalAiAiAvatarSingleTextRequestsByRequestIdResponses]

export type GetFalAiAiAvatarRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ai-avatar/requests/{request_id}/status'
}

export type GetFalAiAiAvatarRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiAiAvatarRequestsByRequestIdStatusResponse =
  GetFalAiAiAvatarRequestsByRequestIdStatusResponses[keyof GetFalAiAiAvatarRequestsByRequestIdStatusResponses]

export type PutFalAiAiAvatarRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ai-avatar/requests/{request_id}/cancel'
}

export type PutFalAiAiAvatarRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiAiAvatarRequestsByRequestIdCancelResponse =
  PutFalAiAiAvatarRequestsByRequestIdCancelResponses[keyof PutFalAiAiAvatarRequestsByRequestIdCancelResponses]

export type PostFalAiAiAvatarData = {
  body: SchemaAiAvatarInput
  path?: never
  query?: never
  url: '/fal-ai/ai-avatar'
}

export type PostFalAiAiAvatarResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiAiAvatarResponse =
  PostFalAiAiAvatarResponses[keyof PostFalAiAiAvatarResponses]

export type GetFalAiAiAvatarRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ai-avatar/requests/{request_id}'
}

export type GetFalAiAiAvatarRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaAiAvatarOutput
}

export type GetFalAiAiAvatarRequestsByRequestIdResponse =
  GetFalAiAiAvatarRequestsByRequestIdResponses[keyof GetFalAiAiAvatarRequestsByRequestIdResponses]

export type GetFalAiAiAvatarMultiTextRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ai-avatar/multi-text/requests/{request_id}/status'
}

export type GetFalAiAiAvatarMultiTextRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiAiAvatarMultiTextRequestsByRequestIdStatusResponse =
  GetFalAiAiAvatarMultiTextRequestsByRequestIdStatusResponses[keyof GetFalAiAiAvatarMultiTextRequestsByRequestIdStatusResponses]

export type PutFalAiAiAvatarMultiTextRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ai-avatar/multi-text/requests/{request_id}/cancel'
}

export type PutFalAiAiAvatarMultiTextRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiAiAvatarMultiTextRequestsByRequestIdCancelResponse =
  PutFalAiAiAvatarMultiTextRequestsByRequestIdCancelResponses[keyof PutFalAiAiAvatarMultiTextRequestsByRequestIdCancelResponses]

export type PostFalAiAiAvatarMultiTextData = {
  body: SchemaAiAvatarMultiTextInput
  path?: never
  query?: never
  url: '/fal-ai/ai-avatar/multi-text'
}

export type PostFalAiAiAvatarMultiTextResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiAiAvatarMultiTextResponse =
  PostFalAiAiAvatarMultiTextResponses[keyof PostFalAiAiAvatarMultiTextResponses]

export type GetFalAiAiAvatarMultiTextRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ai-avatar/multi-text/requests/{request_id}'
}

export type GetFalAiAiAvatarMultiTextRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaAiAvatarMultiTextOutput
}

export type GetFalAiAiAvatarMultiTextRequestsByRequestIdResponse =
  GetFalAiAiAvatarMultiTextRequestsByRequestIdResponses[keyof GetFalAiAiAvatarMultiTextRequestsByRequestIdResponses]

export type GetFalAiAiAvatarMultiRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ai-avatar/multi/requests/{request_id}/status'
}

export type GetFalAiAiAvatarMultiRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiAiAvatarMultiRequestsByRequestIdStatusResponse =
  GetFalAiAiAvatarMultiRequestsByRequestIdStatusResponses[keyof GetFalAiAiAvatarMultiRequestsByRequestIdStatusResponses]

export type PutFalAiAiAvatarMultiRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ai-avatar/multi/requests/{request_id}/cancel'
}

export type PutFalAiAiAvatarMultiRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiAiAvatarMultiRequestsByRequestIdCancelResponse =
  PutFalAiAiAvatarMultiRequestsByRequestIdCancelResponses[keyof PutFalAiAiAvatarMultiRequestsByRequestIdCancelResponses]

export type PostFalAiAiAvatarMultiData = {
  body: SchemaAiAvatarMultiInput
  path?: never
  query?: never
  url: '/fal-ai/ai-avatar/multi'
}

export type PostFalAiAiAvatarMultiResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiAiAvatarMultiResponse =
  PostFalAiAiAvatarMultiResponses[keyof PostFalAiAiAvatarMultiResponses]

export type GetFalAiAiAvatarMultiRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ai-avatar/multi/requests/{request_id}'
}

export type GetFalAiAiAvatarMultiRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaAiAvatarMultiOutput
}

export type GetFalAiAiAvatarMultiRequestsByRequestIdResponse =
  GetFalAiAiAvatarMultiRequestsByRequestIdResponses[keyof GetFalAiAiAvatarMultiRequestsByRequestIdResponses]

export type GetFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/minimax/hailuo-02/pro/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/minimax/hailuo-02/pro/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiMinimaxHailuo02ProImageToVideoData = {
  body: SchemaMinimaxHailuo02ProImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/minimax/hailuo-02/pro/image-to-video'
}

export type PostFalAiMinimaxHailuo02ProImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMinimaxHailuo02ProImageToVideoResponse =
  PostFalAiMinimaxHailuo02ProImageToVideoResponses[keyof PostFalAiMinimaxHailuo02ProImageToVideoResponses]

export type GetFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax/hailuo-02/pro/image-to-video/requests/{request_id}'
}

export type GetFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaMinimaxHailuo02ProImageToVideoOutput
  }

export type GetFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdResponse =
  GetFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdResponses[keyof GetFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdResponses]

export type GetFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/bytedance/seedance/v1/lite/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/bytedance/seedance/v1/lite/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiBytedanceSeedanceV1LiteImageToVideoData = {
  body: SchemaBytedanceSeedanceV1LiteImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/bytedance/seedance/v1/lite/image-to-video'
}

export type PostFalAiBytedanceSeedanceV1LiteImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiBytedanceSeedanceV1LiteImageToVideoResponse =
  PostFalAiBytedanceSeedanceV1LiteImageToVideoResponses[keyof PostFalAiBytedanceSeedanceV1LiteImageToVideoResponses]

export type GetFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/bytedance/seedance/v1/lite/image-to-video/requests/{request_id}'
  }

export type GetFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaBytedanceSeedanceV1LiteImageToVideoOutput
  }

export type GetFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdResponse =
  GetFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdResponses[keyof GetFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdResponses]

export type GetFalAiHunyuanAvatarRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/hunyuan-avatar/requests/{request_id}/status'
}

export type GetFalAiHunyuanAvatarRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiHunyuanAvatarRequestsByRequestIdStatusResponse =
  GetFalAiHunyuanAvatarRequestsByRequestIdStatusResponses[keyof GetFalAiHunyuanAvatarRequestsByRequestIdStatusResponses]

export type PutFalAiHunyuanAvatarRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/hunyuan-avatar/requests/{request_id}/cancel'
}

export type PutFalAiHunyuanAvatarRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiHunyuanAvatarRequestsByRequestIdCancelResponse =
  PutFalAiHunyuanAvatarRequestsByRequestIdCancelResponses[keyof PutFalAiHunyuanAvatarRequestsByRequestIdCancelResponses]

export type PostFalAiHunyuanAvatarData = {
  body: SchemaHunyuanAvatarInput
  path?: never
  query?: never
  url: '/fal-ai/hunyuan-avatar'
}

export type PostFalAiHunyuanAvatarResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiHunyuanAvatarResponse =
  PostFalAiHunyuanAvatarResponses[keyof PostFalAiHunyuanAvatarResponses]

export type GetFalAiHunyuanAvatarRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/hunyuan-avatar/requests/{request_id}'
}

export type GetFalAiHunyuanAvatarRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaHunyuanAvatarOutput
}

export type GetFalAiHunyuanAvatarRequestsByRequestIdResponse =
  GetFalAiHunyuanAvatarRequestsByRequestIdResponses[keyof GetFalAiHunyuanAvatarRequestsByRequestIdResponses]

export type GetFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/kling-video/v2.1/pro/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/v2.1/pro/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV21ProImageToVideoData = {
  body: SchemaKlingVideoV21ProImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v2.1/pro/image-to-video'
}

export type PostFalAiKlingVideoV21ProImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV21ProImageToVideoResponse =
  PostFalAiKlingVideoV21ProImageToVideoResponses[keyof PostFalAiKlingVideoV21ProImageToVideoResponses]

export type GetFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v2.1/pro/image-to-video/requests/{request_id}'
}

export type GetFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKlingVideoV21ProImageToVideoOutput
}

export type GetFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdResponse =
  GetFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdResponses]

export type GetFalAiHunyuanPortraitRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/hunyuan-portrait/requests/{request_id}/status'
}

export type GetFalAiHunyuanPortraitRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiHunyuanPortraitRequestsByRequestIdStatusResponse =
  GetFalAiHunyuanPortraitRequestsByRequestIdStatusResponses[keyof GetFalAiHunyuanPortraitRequestsByRequestIdStatusResponses]

export type PutFalAiHunyuanPortraitRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/hunyuan-portrait/requests/{request_id}/cancel'
}

export type PutFalAiHunyuanPortraitRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiHunyuanPortraitRequestsByRequestIdCancelResponse =
  PutFalAiHunyuanPortraitRequestsByRequestIdCancelResponses[keyof PutFalAiHunyuanPortraitRequestsByRequestIdCancelResponses]

export type PostFalAiHunyuanPortraitData = {
  body: SchemaHunyuanPortraitInput
  path?: never
  query?: never
  url: '/fal-ai/hunyuan-portrait'
}

export type PostFalAiHunyuanPortraitResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiHunyuanPortraitResponse =
  PostFalAiHunyuanPortraitResponses[keyof PostFalAiHunyuanPortraitResponses]

export type GetFalAiHunyuanPortraitRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/hunyuan-portrait/requests/{request_id}'
}

export type GetFalAiHunyuanPortraitRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaHunyuanPortraitOutput
}

export type GetFalAiHunyuanPortraitRequestsByRequestIdResponse =
  GetFalAiHunyuanPortraitRequestsByRequestIdResponses[keyof GetFalAiHunyuanPortraitRequestsByRequestIdResponses]

export type GetFalAiKlingVideoV16StandardElementsRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/kling-video/v1.6/standard/elements/requests/{request_id}/status'
  }

export type GetFalAiKlingVideoV16StandardElementsRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV16StandardElementsRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV16StandardElementsRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV16StandardElementsRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV16StandardElementsRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/v1.6/standard/elements/requests/{request_id}/cancel'
  }

export type PutFalAiKlingVideoV16StandardElementsRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV16StandardElementsRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV16StandardElementsRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV16StandardElementsRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV16StandardElementsData = {
  body: SchemaKlingVideoV16StandardElementsInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v1.6/standard/elements'
}

export type PostFalAiKlingVideoV16StandardElementsResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV16StandardElementsResponse =
  PostFalAiKlingVideoV16StandardElementsResponses[keyof PostFalAiKlingVideoV16StandardElementsResponses]

export type GetFalAiKlingVideoV16StandardElementsRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v1.6/standard/elements/requests/{request_id}'
}

export type GetFalAiKlingVideoV16StandardElementsRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaKlingVideoV16StandardElementsOutput
  }

export type GetFalAiKlingVideoV16StandardElementsRequestsByRequestIdResponse =
  GetFalAiKlingVideoV16StandardElementsRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV16StandardElementsRequestsByRequestIdResponses]

export type GetFalAiKlingVideoV16ProElementsRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kling-video/v1.6/pro/elements/requests/{request_id}/status'
}

export type GetFalAiKlingVideoV16ProElementsRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV16ProElementsRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV16ProElementsRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV16ProElementsRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV16ProElementsRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v1.6/pro/elements/requests/{request_id}/cancel'
}

export type PutFalAiKlingVideoV16ProElementsRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV16ProElementsRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV16ProElementsRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV16ProElementsRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV16ProElementsData = {
  body: SchemaKlingVideoV16ProElementsInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v1.6/pro/elements'
}

export type PostFalAiKlingVideoV16ProElementsResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV16ProElementsResponse =
  PostFalAiKlingVideoV16ProElementsResponses[keyof PostFalAiKlingVideoV16ProElementsResponses]

export type GetFalAiKlingVideoV16ProElementsRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v1.6/pro/elements/requests/{request_id}'
}

export type GetFalAiKlingVideoV16ProElementsRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKlingVideoV16ProElementsOutput
}

export type GetFalAiKlingVideoV16ProElementsRequestsByRequestIdResponse =
  GetFalAiKlingVideoV16ProElementsRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV16ProElementsRequestsByRequestIdResponses]

export type GetFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/ltx-video-13b-distilled/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/ltx-video-13b-distilled/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiLtxVideo13bDistilledImageToVideoData = {
  body: SchemaLtxVideo13bDistilledImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/ltx-video-13b-distilled/image-to-video'
}

export type PostFalAiLtxVideo13bDistilledImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLtxVideo13bDistilledImageToVideoResponse =
  PostFalAiLtxVideo13bDistilledImageToVideoResponses[keyof PostFalAiLtxVideo13bDistilledImageToVideoResponses]

export type GetFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-video-13b-distilled/image-to-video/requests/{request_id}'
}

export type GetFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaLtxVideo13bDistilledImageToVideoOutput
  }

export type GetFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdResponse =
  GetFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdResponses[keyof GetFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdResponses]

export type GetFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ltx-video-13b-dev/image-to-video/requests/{request_id}/status'
}

export type GetFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-video-13b-dev/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiLtxVideo13bDevImageToVideoData = {
  body: SchemaLtxVideo13bDevImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/ltx-video-13b-dev/image-to-video'
}

export type PostFalAiLtxVideo13bDevImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLtxVideo13bDevImageToVideoResponse =
  PostFalAiLtxVideo13bDevImageToVideoResponses[keyof PostFalAiLtxVideo13bDevImageToVideoResponses]

export type GetFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-video-13b-dev/image-to-video/requests/{request_id}'
}

export type GetFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLtxVideo13bDevImageToVideoOutput
}

export type GetFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdResponse =
  GetFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdResponses[keyof GetFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdResponses]

export type GetFalAiLtxVideoLoraImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ltx-video-lora/image-to-video/requests/{request_id}/status'
}

export type GetFalAiLtxVideoLoraImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiLtxVideoLoraImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiLtxVideoLoraImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiLtxVideoLoraImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiLtxVideoLoraImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-video-lora/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiLtxVideoLoraImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiLtxVideoLoraImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiLtxVideoLoraImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiLtxVideoLoraImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiLtxVideoLoraImageToVideoData = {
  body: SchemaLtxVideoLoraImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/ltx-video-lora/image-to-video'
}

export type PostFalAiLtxVideoLoraImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLtxVideoLoraImageToVideoResponse =
  PostFalAiLtxVideoLoraImageToVideoResponses[keyof PostFalAiLtxVideoLoraImageToVideoResponses]

export type GetFalAiLtxVideoLoraImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-video-lora/image-to-video/requests/{request_id}'
}

export type GetFalAiLtxVideoLoraImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLtxVideoLoraImageToVideoOutput
}

export type GetFalAiLtxVideoLoraImageToVideoRequestsByRequestIdResponse =
  GetFalAiLtxVideoLoraImageToVideoRequestsByRequestIdResponses[keyof GetFalAiLtxVideoLoraImageToVideoRequestsByRequestIdResponses]

export type GetFalAiPixverseV45TransitionRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v4.5/transition/requests/{request_id}/status'
}

export type GetFalAiPixverseV45TransitionRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPixverseV45TransitionRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV45TransitionRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV45TransitionRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV45TransitionRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v4.5/transition/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV45TransitionRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPixverseV45TransitionRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV45TransitionRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV45TransitionRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV45TransitionData = {
  body: SchemaPixverseV45TransitionInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v4.5/transition'
}

export type PostFalAiPixverseV45TransitionResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV45TransitionResponse =
  PostFalAiPixverseV45TransitionResponses[keyof PostFalAiPixverseV45TransitionResponses]

export type GetFalAiPixverseV45TransitionRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v4.5/transition/requests/{request_id}'
}

export type GetFalAiPixverseV45TransitionRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV45TransitionOutput
}

export type GetFalAiPixverseV45TransitionRequestsByRequestIdResponse =
  GetFalAiPixverseV45TransitionRequestsByRequestIdResponses[keyof GetFalAiPixverseV45TransitionRequestsByRequestIdResponses]

export type GetFalAiPixverseV45ImageToVideoFastRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v4.5/image-to-video/fast/requests/{request_id}/status'
}

export type GetFalAiPixverseV45ImageToVideoFastRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiPixverseV45ImageToVideoFastRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV45ImageToVideoFastRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV45ImageToVideoFastRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV45ImageToVideoFastRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v4.5/image-to-video/fast/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV45ImageToVideoFastRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiPixverseV45ImageToVideoFastRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV45ImageToVideoFastRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV45ImageToVideoFastRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV45ImageToVideoFastData = {
  body: SchemaPixverseV45ImageToVideoFastInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v4.5/image-to-video/fast'
}

export type PostFalAiPixverseV45ImageToVideoFastResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV45ImageToVideoFastResponse =
  PostFalAiPixverseV45ImageToVideoFastResponses[keyof PostFalAiPixverseV45ImageToVideoFastResponses]

export type GetFalAiPixverseV45ImageToVideoFastRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v4.5/image-to-video/fast/requests/{request_id}'
}

export type GetFalAiPixverseV45ImageToVideoFastRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV45ImageToVideoFastOutput
}

export type GetFalAiPixverseV45ImageToVideoFastRequestsByRequestIdResponse =
  GetFalAiPixverseV45ImageToVideoFastRequestsByRequestIdResponses[keyof GetFalAiPixverseV45ImageToVideoFastRequestsByRequestIdResponses]

export type GetFalAiPixverseV45EffectsRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v4.5/effects/requests/{request_id}/status'
}

export type GetFalAiPixverseV45EffectsRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPixverseV45EffectsRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV45EffectsRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV45EffectsRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV45EffectsRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v4.5/effects/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV45EffectsRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPixverseV45EffectsRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV45EffectsRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV45EffectsRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV45EffectsData = {
  body: SchemaPixverseV45EffectsInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v4.5/effects'
}

export type PostFalAiPixverseV45EffectsResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV45EffectsResponse =
  PostFalAiPixverseV45EffectsResponses[keyof PostFalAiPixverseV45EffectsResponses]

export type GetFalAiPixverseV45EffectsRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v4.5/effects/requests/{request_id}'
}

export type GetFalAiPixverseV45EffectsRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV45EffectsOutput
}

export type GetFalAiPixverseV45EffectsRequestsByRequestIdResponse =
  GetFalAiPixverseV45EffectsRequestsByRequestIdResponses[keyof GetFalAiPixverseV45EffectsRequestsByRequestIdResponses]

export type GetFalAiHunyuanCustomRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/hunyuan-custom/requests/{request_id}/status'
}

export type GetFalAiHunyuanCustomRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiHunyuanCustomRequestsByRequestIdStatusResponse =
  GetFalAiHunyuanCustomRequestsByRequestIdStatusResponses[keyof GetFalAiHunyuanCustomRequestsByRequestIdStatusResponses]

export type PutFalAiHunyuanCustomRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/hunyuan-custom/requests/{request_id}/cancel'
}

export type PutFalAiHunyuanCustomRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiHunyuanCustomRequestsByRequestIdCancelResponse =
  PutFalAiHunyuanCustomRequestsByRequestIdCancelResponses[keyof PutFalAiHunyuanCustomRequestsByRequestIdCancelResponses]

export type PostFalAiHunyuanCustomData = {
  body: SchemaHunyuanCustomInput
  path?: never
  query?: never
  url: '/fal-ai/hunyuan-custom'
}

export type PostFalAiHunyuanCustomResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiHunyuanCustomResponse =
  PostFalAiHunyuanCustomResponses[keyof PostFalAiHunyuanCustomResponses]

export type GetFalAiHunyuanCustomRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/hunyuan-custom/requests/{request_id}'
}

export type GetFalAiHunyuanCustomRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaHunyuanCustomOutput
}

export type GetFalAiHunyuanCustomRequestsByRequestIdResponse =
  GetFalAiHunyuanCustomRequestsByRequestIdResponses[keyof GetFalAiHunyuanCustomRequestsByRequestIdResponses]

export type GetFalAiFramepackF1RequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/framepack/f1/requests/{request_id}/status'
}

export type GetFalAiFramepackF1RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiFramepackF1RequestsByRequestIdStatusResponse =
  GetFalAiFramepackF1RequestsByRequestIdStatusResponses[keyof GetFalAiFramepackF1RequestsByRequestIdStatusResponses]

export type PutFalAiFramepackF1RequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/framepack/f1/requests/{request_id}/cancel'
}

export type PutFalAiFramepackF1RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiFramepackF1RequestsByRequestIdCancelResponse =
  PutFalAiFramepackF1RequestsByRequestIdCancelResponses[keyof PutFalAiFramepackF1RequestsByRequestIdCancelResponses]

export type PostFalAiFramepackF1Data = {
  body: SchemaFramepackF1Input
  path?: never
  query?: never
  url: '/fal-ai/framepack/f1'
}

export type PostFalAiFramepackF1Responses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiFramepackF1Response =
  PostFalAiFramepackF1Responses[keyof PostFalAiFramepackF1Responses]

export type GetFalAiFramepackF1RequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/framepack/f1/requests/{request_id}'
}

export type GetFalAiFramepackF1RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaFramepackF1Output
}

export type GetFalAiFramepackF1RequestsByRequestIdResponse =
  GetFalAiFramepackF1RequestsByRequestIdResponses[keyof GetFalAiFramepackF1RequestsByRequestIdResponses]

export type GetFalAiViduQ1StartEndToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/vidu/q1/start-end-to-video/requests/{request_id}/status'
}

export type GetFalAiViduQ1StartEndToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiViduQ1StartEndToVideoRequestsByRequestIdStatusResponse =
  GetFalAiViduQ1StartEndToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiViduQ1StartEndToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiViduQ1StartEndToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/vidu/q1/start-end-to-video/requests/{request_id}/cancel'
}

export type PutFalAiViduQ1StartEndToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiViduQ1StartEndToVideoRequestsByRequestIdCancelResponse =
  PutFalAiViduQ1StartEndToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiViduQ1StartEndToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiViduQ1StartEndToVideoData = {
  body: SchemaViduQ1StartEndToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/vidu/q1/start-end-to-video'
}

export type PostFalAiViduQ1StartEndToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiViduQ1StartEndToVideoResponse =
  PostFalAiViduQ1StartEndToVideoResponses[keyof PostFalAiViduQ1StartEndToVideoResponses]

export type GetFalAiViduQ1StartEndToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/vidu/q1/start-end-to-video/requests/{request_id}'
}

export type GetFalAiViduQ1StartEndToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaViduQ1StartEndToVideoOutput
}

export type GetFalAiViduQ1StartEndToVideoRequestsByRequestIdResponse =
  GetFalAiViduQ1StartEndToVideoRequestsByRequestIdResponses[keyof GetFalAiViduQ1StartEndToVideoRequestsByRequestIdResponses]

export type GetFalAiViduQ1ImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/vidu/q1/image-to-video/requests/{request_id}/status'
}

export type GetFalAiViduQ1ImageToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiViduQ1ImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiViduQ1ImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiViduQ1ImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiViduQ1ImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/vidu/q1/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiViduQ1ImageToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiViduQ1ImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiViduQ1ImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiViduQ1ImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiViduQ1ImageToVideoData = {
  body: SchemaViduQ1ImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/vidu/q1/image-to-video'
}

export type PostFalAiViduQ1ImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiViduQ1ImageToVideoResponse =
  PostFalAiViduQ1ImageToVideoResponses[keyof PostFalAiViduQ1ImageToVideoResponses]

export type GetFalAiViduQ1ImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/vidu/q1/image-to-video/requests/{request_id}'
}

export type GetFalAiViduQ1ImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaViduQ1ImageToVideoOutput
}

export type GetFalAiViduQ1ImageToVideoRequestsByRequestIdResponse =
  GetFalAiViduQ1ImageToVideoRequestsByRequestIdResponses[keyof GetFalAiViduQ1ImageToVideoRequestsByRequestIdResponses]

export type GetFalAiMagiImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/magi/image-to-video/requests/{request_id}/status'
}

export type GetFalAiMagiImageToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiMagiImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiMagiImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiMagiImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiMagiImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/magi/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiMagiImageToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiMagiImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiMagiImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiMagiImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiMagiImageToVideoData = {
  body: SchemaMagiImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/magi/image-to-video'
}

export type PostFalAiMagiImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMagiImageToVideoResponse =
  PostFalAiMagiImageToVideoResponses[keyof PostFalAiMagiImageToVideoResponses]

export type GetFalAiMagiImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/magi/image-to-video/requests/{request_id}'
}

export type GetFalAiMagiImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaMagiImageToVideoOutput
}

export type GetFalAiMagiImageToVideoRequestsByRequestIdResponse =
  GetFalAiMagiImageToVideoRequestsByRequestIdResponses[keyof GetFalAiMagiImageToVideoRequestsByRequestIdResponses]

export type GetFalAiPixverseV4EffectsRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v4/effects/requests/{request_id}/status'
}

export type GetFalAiPixverseV4EffectsRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPixverseV4EffectsRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV4EffectsRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV4EffectsRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV4EffectsRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v4/effects/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV4EffectsRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPixverseV4EffectsRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV4EffectsRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV4EffectsRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV4EffectsData = {
  body: SchemaPixverseV4EffectsInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v4/effects'
}

export type PostFalAiPixverseV4EffectsResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV4EffectsResponse =
  PostFalAiPixverseV4EffectsResponses[keyof PostFalAiPixverseV4EffectsResponses]

export type GetFalAiPixverseV4EffectsRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v4/effects/requests/{request_id}'
}

export type GetFalAiPixverseV4EffectsRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV4EffectsOutput
}

export type GetFalAiPixverseV4EffectsRequestsByRequestIdResponse =
  GetFalAiPixverseV4EffectsRequestsByRequestIdResponses[keyof GetFalAiPixverseV4EffectsRequestsByRequestIdResponses]

export type GetFalAiMagiDistilledImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/magi-distilled/image-to-video/requests/{request_id}/status'
}

export type GetFalAiMagiDistilledImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiMagiDistilledImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiMagiDistilledImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiMagiDistilledImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiMagiDistilledImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/magi-distilled/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiMagiDistilledImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiMagiDistilledImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiMagiDistilledImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiMagiDistilledImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiMagiDistilledImageToVideoData = {
  body: SchemaMagiDistilledImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/magi-distilled/image-to-video'
}

export type PostFalAiMagiDistilledImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMagiDistilledImageToVideoResponse =
  PostFalAiMagiDistilledImageToVideoResponses[keyof PostFalAiMagiDistilledImageToVideoResponses]

export type GetFalAiMagiDistilledImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/magi-distilled/image-to-video/requests/{request_id}'
}

export type GetFalAiMagiDistilledImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaMagiDistilledImageToVideoOutput
}

export type GetFalAiMagiDistilledImageToVideoRequestsByRequestIdResponse =
  GetFalAiMagiDistilledImageToVideoRequestsByRequestIdResponses[keyof GetFalAiMagiDistilledImageToVideoRequestsByRequestIdResponses]

export type GetFalAiFramepackFlf2vRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/framepack/flf2v/requests/{request_id}/status'
}

export type GetFalAiFramepackFlf2vRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiFramepackFlf2vRequestsByRequestIdStatusResponse =
  GetFalAiFramepackFlf2vRequestsByRequestIdStatusResponses[keyof GetFalAiFramepackFlf2vRequestsByRequestIdStatusResponses]

export type PutFalAiFramepackFlf2vRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/framepack/flf2v/requests/{request_id}/cancel'
}

export type PutFalAiFramepackFlf2vRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiFramepackFlf2vRequestsByRequestIdCancelResponse =
  PutFalAiFramepackFlf2vRequestsByRequestIdCancelResponses[keyof PutFalAiFramepackFlf2vRequestsByRequestIdCancelResponses]

export type PostFalAiFramepackFlf2vData = {
  body: SchemaFramepackFlf2vInput
  path?: never
  query?: never
  url: '/fal-ai/framepack/flf2v'
}

export type PostFalAiFramepackFlf2vResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiFramepackFlf2vResponse =
  PostFalAiFramepackFlf2vResponses[keyof PostFalAiFramepackFlf2vResponses]

export type GetFalAiFramepackFlf2vRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/framepack/flf2v/requests/{request_id}'
}

export type GetFalAiFramepackFlf2vRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaFramepackFlf2vOutput
}

export type GetFalAiFramepackFlf2vRequestsByRequestIdResponse =
  GetFalAiFramepackFlf2vRequestsByRequestIdResponses[keyof GetFalAiFramepackFlf2vRequestsByRequestIdResponses]

export type GetFalAiWanFlf2vRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/wan-flf2v/requests/{request_id}/status'
}

export type GetFalAiWanFlf2vRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiWanFlf2vRequestsByRequestIdStatusResponse =
  GetFalAiWanFlf2vRequestsByRequestIdStatusResponses[keyof GetFalAiWanFlf2vRequestsByRequestIdStatusResponses]

export type PutFalAiWanFlf2vRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan-flf2v/requests/{request_id}/cancel'
}

export type PutFalAiWanFlf2vRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiWanFlf2vRequestsByRequestIdCancelResponse =
  PutFalAiWanFlf2vRequestsByRequestIdCancelResponses[keyof PutFalAiWanFlf2vRequestsByRequestIdCancelResponses]

export type PostFalAiWanFlf2vData = {
  body: SchemaWanFlf2vInput
  path?: never
  query?: never
  url: '/fal-ai/wan-flf2v'
}

export type PostFalAiWanFlf2vResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiWanFlf2vResponse =
  PostFalAiWanFlf2vResponses[keyof PostFalAiWanFlf2vResponses]

export type GetFalAiWanFlf2vRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan-flf2v/requests/{request_id}'
}

export type GetFalAiWanFlf2vRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaWanFlf2vOutput
}

export type GetFalAiWanFlf2vRequestsByRequestIdResponse =
  GetFalAiWanFlf2vRequestsByRequestIdResponses[keyof GetFalAiWanFlf2vRequestsByRequestIdResponses]

export type GetFalAiFramepackRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/framepack/requests/{request_id}/status'
}

export type GetFalAiFramepackRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiFramepackRequestsByRequestIdStatusResponse =
  GetFalAiFramepackRequestsByRequestIdStatusResponses[keyof GetFalAiFramepackRequestsByRequestIdStatusResponses]

export type PutFalAiFramepackRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/framepack/requests/{request_id}/cancel'
}

export type PutFalAiFramepackRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiFramepackRequestsByRequestIdCancelResponse =
  PutFalAiFramepackRequestsByRequestIdCancelResponses[keyof PutFalAiFramepackRequestsByRequestIdCancelResponses]

export type PostFalAiFramepackData = {
  body: SchemaFramepackInput
  path?: never
  query?: never
  url: '/fal-ai/framepack'
}

export type PostFalAiFramepackResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiFramepackResponse =
  PostFalAiFramepackResponses[keyof PostFalAiFramepackResponses]

export type GetFalAiFramepackRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/framepack/requests/{request_id}'
}

export type GetFalAiFramepackRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaFramepackOutput
}

export type GetFalAiFramepackRequestsByRequestIdResponse =
  GetFalAiFramepackRequestsByRequestIdResponses[keyof GetFalAiFramepackRequestsByRequestIdResponses]

export type GetFalAiPixverseV4ImageToVideoFastRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v4/image-to-video/fast/requests/{request_id}/status'
}

export type GetFalAiPixverseV4ImageToVideoFastRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiPixverseV4ImageToVideoFastRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV4ImageToVideoFastRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV4ImageToVideoFastRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV4ImageToVideoFastRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v4/image-to-video/fast/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV4ImageToVideoFastRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiPixverseV4ImageToVideoFastRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV4ImageToVideoFastRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV4ImageToVideoFastRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV4ImageToVideoFastData = {
  body: SchemaPixverseV4ImageToVideoFastInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v4/image-to-video/fast'
}

export type PostFalAiPixverseV4ImageToVideoFastResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV4ImageToVideoFastResponse =
  PostFalAiPixverseV4ImageToVideoFastResponses[keyof PostFalAiPixverseV4ImageToVideoFastResponses]

export type GetFalAiPixverseV4ImageToVideoFastRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v4/image-to-video/fast/requests/{request_id}'
}

export type GetFalAiPixverseV4ImageToVideoFastRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV4ImageToVideoFastOutput
}

export type GetFalAiPixverseV4ImageToVideoFastRequestsByRequestIdResponse =
  GetFalAiPixverseV4ImageToVideoFastRequestsByRequestIdResponses[keyof GetFalAiPixverseV4ImageToVideoFastRequestsByRequestIdResponses]

export type GetFalAiPixverseV4ImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v4/image-to-video/requests/{request_id}/status'
}

export type GetFalAiPixverseV4ImageToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPixverseV4ImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV4ImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV4ImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV4ImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v4/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV4ImageToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPixverseV4ImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV4ImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV4ImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV4ImageToVideoData = {
  body: SchemaPixverseV4ImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v4/image-to-video'
}

export type PostFalAiPixverseV4ImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV4ImageToVideoResponse =
  PostFalAiPixverseV4ImageToVideoResponses[keyof PostFalAiPixverseV4ImageToVideoResponses]

export type GetFalAiPixverseV4ImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v4/image-to-video/requests/{request_id}'
}

export type GetFalAiPixverseV4ImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV4ImageToVideoOutput
}

export type GetFalAiPixverseV4ImageToVideoRequestsByRequestIdResponse =
  GetFalAiPixverseV4ImageToVideoRequestsByRequestIdResponses[keyof GetFalAiPixverseV4ImageToVideoRequestsByRequestIdResponses]

export type GetFalAiPixverseV35EffectsRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v3.5/effects/requests/{request_id}/status'
}

export type GetFalAiPixverseV35EffectsRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPixverseV35EffectsRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV35EffectsRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV35EffectsRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV35EffectsRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v3.5/effects/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV35EffectsRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPixverseV35EffectsRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV35EffectsRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV35EffectsRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV35EffectsData = {
  body: SchemaPixverseV35EffectsInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v3.5/effects'
}

export type PostFalAiPixverseV35EffectsResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV35EffectsResponse =
  PostFalAiPixverseV35EffectsResponses[keyof PostFalAiPixverseV35EffectsResponses]

export type GetFalAiPixverseV35EffectsRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v3.5/effects/requests/{request_id}'
}

export type GetFalAiPixverseV35EffectsRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV35EffectsOutput
}

export type GetFalAiPixverseV35EffectsRequestsByRequestIdResponse =
  GetFalAiPixverseV35EffectsRequestsByRequestIdResponses[keyof GetFalAiPixverseV35EffectsRequestsByRequestIdResponses]

export type GetFalAiPixverseV35TransitionRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v3.5/transition/requests/{request_id}/status'
}

export type GetFalAiPixverseV35TransitionRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPixverseV35TransitionRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV35TransitionRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV35TransitionRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV35TransitionRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v3.5/transition/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV35TransitionRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPixverseV35TransitionRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV35TransitionRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV35TransitionRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV35TransitionData = {
  body: SchemaPixverseV35TransitionInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v3.5/transition'
}

export type PostFalAiPixverseV35TransitionResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV35TransitionResponse =
  PostFalAiPixverseV35TransitionResponses[keyof PostFalAiPixverseV35TransitionResponses]

export type GetFalAiPixverseV35TransitionRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v3.5/transition/requests/{request_id}'
}

export type GetFalAiPixverseV35TransitionRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV35TransitionOutput
}

export type GetFalAiPixverseV35TransitionRequestsByRequestIdResponse =
  GetFalAiPixverseV35TransitionRequestsByRequestIdResponses[keyof GetFalAiPixverseV35TransitionRequestsByRequestIdResponses]

export type GetFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/luma-dream-machine/ray-2-flash/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/luma-dream-machine/ray-2-flash/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiLumaDreamMachineRay2FlashImageToVideoData = {
  body: SchemaLumaDreamMachineRay2FlashImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/luma-dream-machine/ray-2-flash/image-to-video'
}

export type PostFalAiLumaDreamMachineRay2FlashImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLumaDreamMachineRay2FlashImageToVideoResponse =
  PostFalAiLumaDreamMachineRay2FlashImageToVideoResponses[keyof PostFalAiLumaDreamMachineRay2FlashImageToVideoResponses]

export type GetFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/luma-dream-machine/ray-2-flash/image-to-video/requests/{request_id}'
  }

export type GetFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaLumaDreamMachineRay2FlashImageToVideoOutput
  }

export type GetFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdResponse =
  GetFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdResponses[keyof GetFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdResponses]

export type GetFalAiPikaV15PikaffectsRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pika/v1.5/pikaffects/requests/{request_id}/status'
}

export type GetFalAiPikaV15PikaffectsRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPikaV15PikaffectsRequestsByRequestIdStatusResponse =
  GetFalAiPikaV15PikaffectsRequestsByRequestIdStatusResponses[keyof GetFalAiPikaV15PikaffectsRequestsByRequestIdStatusResponses]

export type PutFalAiPikaV15PikaffectsRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pika/v1.5/pikaffects/requests/{request_id}/cancel'
}

export type PutFalAiPikaV15PikaffectsRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPikaV15PikaffectsRequestsByRequestIdCancelResponse =
  PutFalAiPikaV15PikaffectsRequestsByRequestIdCancelResponses[keyof PutFalAiPikaV15PikaffectsRequestsByRequestIdCancelResponses]

export type PostFalAiPikaV15PikaffectsData = {
  body: SchemaPikaV15PikaffectsInput
  path?: never
  query?: never
  url: '/fal-ai/pika/v1.5/pikaffects'
}

export type PostFalAiPikaV15PikaffectsResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPikaV15PikaffectsResponse =
  PostFalAiPikaV15PikaffectsResponses[keyof PostFalAiPikaV15PikaffectsResponses]

export type GetFalAiPikaV15PikaffectsRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pika/v1.5/pikaffects/requests/{request_id}'
}

export type GetFalAiPikaV15PikaffectsRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPikaV15PikaffectsOutput
}

export type GetFalAiPikaV15PikaffectsRequestsByRequestIdResponse =
  GetFalAiPikaV15PikaffectsRequestsByRequestIdResponses[keyof GetFalAiPikaV15PikaffectsRequestsByRequestIdResponses]

export type GetFalAiPikaV2TurboImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pika/v2/turbo/image-to-video/requests/{request_id}/status'
}

export type GetFalAiPikaV2TurboImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiPikaV2TurboImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiPikaV2TurboImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiPikaV2TurboImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiPikaV2TurboImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pika/v2/turbo/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiPikaV2TurboImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiPikaV2TurboImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiPikaV2TurboImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiPikaV2TurboImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiPikaV2TurboImageToVideoData = {
  body: SchemaPikaV2TurboImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/pika/v2/turbo/image-to-video'
}

export type PostFalAiPikaV2TurboImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPikaV2TurboImageToVideoResponse =
  PostFalAiPikaV2TurboImageToVideoResponses[keyof PostFalAiPikaV2TurboImageToVideoResponses]

export type GetFalAiPikaV2TurboImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pika/v2/turbo/image-to-video/requests/{request_id}'
}

export type GetFalAiPikaV2TurboImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPikaV2TurboImageToVideoOutput
}

export type GetFalAiPikaV2TurboImageToVideoRequestsByRequestIdResponse =
  GetFalAiPikaV2TurboImageToVideoRequestsByRequestIdResponses[keyof GetFalAiPikaV2TurboImageToVideoRequestsByRequestIdResponses]

export type GetFalAiPikaV22PikascenesRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pika/v2.2/pikascenes/requests/{request_id}/status'
}

export type GetFalAiPikaV22PikascenesRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPikaV22PikascenesRequestsByRequestIdStatusResponse =
  GetFalAiPikaV22PikascenesRequestsByRequestIdStatusResponses[keyof GetFalAiPikaV22PikascenesRequestsByRequestIdStatusResponses]

export type PutFalAiPikaV22PikascenesRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pika/v2.2/pikascenes/requests/{request_id}/cancel'
}

export type PutFalAiPikaV22PikascenesRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPikaV22PikascenesRequestsByRequestIdCancelResponse =
  PutFalAiPikaV22PikascenesRequestsByRequestIdCancelResponses[keyof PutFalAiPikaV22PikascenesRequestsByRequestIdCancelResponses]

export type PostFalAiPikaV22PikascenesData = {
  body: SchemaPikaV22PikascenesInput
  path?: never
  query?: never
  url: '/fal-ai/pika/v2.2/pikascenes'
}

export type PostFalAiPikaV22PikascenesResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPikaV22PikascenesResponse =
  PostFalAiPikaV22PikascenesResponses[keyof PostFalAiPikaV22PikascenesResponses]

export type GetFalAiPikaV22PikascenesRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pika/v2.2/pikascenes/requests/{request_id}'
}

export type GetFalAiPikaV22PikascenesRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPikaV22PikascenesOutput
}

export type GetFalAiPikaV22PikascenesRequestsByRequestIdResponse =
  GetFalAiPikaV22PikascenesRequestsByRequestIdResponses[keyof GetFalAiPikaV22PikascenesRequestsByRequestIdResponses]

export type GetFalAiPikaV22ImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pika/v2.2/image-to-video/requests/{request_id}/status'
}

export type GetFalAiPikaV22ImageToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPikaV22ImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiPikaV22ImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiPikaV22ImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiPikaV22ImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pika/v2.2/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiPikaV22ImageToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPikaV22ImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiPikaV22ImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiPikaV22ImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiPikaV22ImageToVideoData = {
  body: SchemaPikaV22ImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/pika/v2.2/image-to-video'
}

export type PostFalAiPikaV22ImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPikaV22ImageToVideoResponse =
  PostFalAiPikaV22ImageToVideoResponses[keyof PostFalAiPikaV22ImageToVideoResponses]

export type GetFalAiPikaV22ImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pika/v2.2/image-to-video/requests/{request_id}'
}

export type GetFalAiPikaV22ImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPikaV22ImageToVideoOutput
}

export type GetFalAiPikaV22ImageToVideoRequestsByRequestIdResponse =
  GetFalAiPikaV22ImageToVideoRequestsByRequestIdResponses[keyof GetFalAiPikaV22ImageToVideoRequestsByRequestIdResponses]

export type GetFalAiPikaV21ImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pika/v2.1/image-to-video/requests/{request_id}/status'
}

export type GetFalAiPikaV21ImageToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPikaV21ImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiPikaV21ImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiPikaV21ImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiPikaV21ImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pika/v2.1/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiPikaV21ImageToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPikaV21ImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiPikaV21ImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiPikaV21ImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiPikaV21ImageToVideoData = {
  body: SchemaPikaV21ImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/pika/v2.1/image-to-video'
}

export type PostFalAiPikaV21ImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPikaV21ImageToVideoResponse =
  PostFalAiPikaV21ImageToVideoResponses[keyof PostFalAiPikaV21ImageToVideoResponses]

export type GetFalAiPikaV21ImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pika/v2.1/image-to-video/requests/{request_id}'
}

export type GetFalAiPikaV21ImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPikaV21ImageToVideoOutput
}

export type GetFalAiPikaV21ImageToVideoRequestsByRequestIdResponse =
  GetFalAiPikaV21ImageToVideoRequestsByRequestIdResponses[keyof GetFalAiPikaV21ImageToVideoRequestsByRequestIdResponses]

export type GetFalAiViduImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/vidu/image-to-video/requests/{request_id}/status'
}

export type GetFalAiViduImageToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiViduImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiViduImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiViduImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiViduImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/vidu/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiViduImageToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiViduImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiViduImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiViduImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiViduImageToVideoData = {
  body: SchemaViduImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/vidu/image-to-video'
}

export type PostFalAiViduImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiViduImageToVideoResponse =
  PostFalAiViduImageToVideoResponses[keyof PostFalAiViduImageToVideoResponses]

export type GetFalAiViduImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/vidu/image-to-video/requests/{request_id}'
}

export type GetFalAiViduImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaViduImageToVideoOutput
}

export type GetFalAiViduImageToVideoRequestsByRequestIdResponse =
  GetFalAiViduImageToVideoRequestsByRequestIdResponses[keyof GetFalAiViduImageToVideoRequestsByRequestIdResponses]

export type GetFalAiViduStartEndToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/vidu/start-end-to-video/requests/{request_id}/status'
}

export type GetFalAiViduStartEndToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiViduStartEndToVideoRequestsByRequestIdStatusResponse =
  GetFalAiViduStartEndToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiViduStartEndToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiViduStartEndToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/vidu/start-end-to-video/requests/{request_id}/cancel'
}

export type PutFalAiViduStartEndToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiViduStartEndToVideoRequestsByRequestIdCancelResponse =
  PutFalAiViduStartEndToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiViduStartEndToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiViduStartEndToVideoData = {
  body: SchemaViduStartEndToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/vidu/start-end-to-video'
}

export type PostFalAiViduStartEndToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiViduStartEndToVideoResponse =
  PostFalAiViduStartEndToVideoResponses[keyof PostFalAiViduStartEndToVideoResponses]

export type GetFalAiViduStartEndToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/vidu/start-end-to-video/requests/{request_id}'
}

export type GetFalAiViduStartEndToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaViduStartEndToVideoOutput
}

export type GetFalAiViduStartEndToVideoRequestsByRequestIdResponse =
  GetFalAiViduStartEndToVideoRequestsByRequestIdResponses[keyof GetFalAiViduStartEndToVideoRequestsByRequestIdResponses]

export type GetFalAiViduReferenceToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/vidu/reference-to-video/requests/{request_id}/status'
}

export type GetFalAiViduReferenceToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiViduReferenceToVideoRequestsByRequestIdStatusResponse =
  GetFalAiViduReferenceToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiViduReferenceToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiViduReferenceToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/vidu/reference-to-video/requests/{request_id}/cancel'
}

export type PutFalAiViduReferenceToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiViduReferenceToVideoRequestsByRequestIdCancelResponse =
  PutFalAiViduReferenceToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiViduReferenceToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiViduReferenceToVideoData = {
  body: SchemaViduReferenceToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/vidu/reference-to-video'
}

export type PostFalAiViduReferenceToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiViduReferenceToVideoResponse =
  PostFalAiViduReferenceToVideoResponses[keyof PostFalAiViduReferenceToVideoResponses]

export type GetFalAiViduReferenceToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/vidu/reference-to-video/requests/{request_id}'
}

export type GetFalAiViduReferenceToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaViduReferenceToVideoOutput
}

export type GetFalAiViduReferenceToVideoRequestsByRequestIdResponse =
  GetFalAiViduReferenceToVideoRequestsByRequestIdResponses[keyof GetFalAiViduReferenceToVideoRequestsByRequestIdResponses]

export type GetFalAiViduTemplateToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/vidu/template-to-video/requests/{request_id}/status'
}

export type GetFalAiViduTemplateToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiViduTemplateToVideoRequestsByRequestIdStatusResponse =
  GetFalAiViduTemplateToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiViduTemplateToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiViduTemplateToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/vidu/template-to-video/requests/{request_id}/cancel'
}

export type PutFalAiViduTemplateToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiViduTemplateToVideoRequestsByRequestIdCancelResponse =
  PutFalAiViduTemplateToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiViduTemplateToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiViduTemplateToVideoData = {
  body: SchemaViduTemplateToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/vidu/template-to-video'
}

export type PostFalAiViduTemplateToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiViduTemplateToVideoResponse =
  PostFalAiViduTemplateToVideoResponses[keyof PostFalAiViduTemplateToVideoResponses]

export type GetFalAiViduTemplateToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/vidu/template-to-video/requests/{request_id}'
}

export type GetFalAiViduTemplateToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaViduTemplateToVideoOutput
}

export type GetFalAiViduTemplateToVideoRequestsByRequestIdResponse =
  GetFalAiViduTemplateToVideoRequestsByRequestIdResponses[keyof GetFalAiViduTemplateToVideoRequestsByRequestIdResponses]

export type GetFalAiWanI2vLoraRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/wan-i2v-lora/requests/{request_id}/status'
}

export type GetFalAiWanI2vLoraRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiWanI2vLoraRequestsByRequestIdStatusResponse =
  GetFalAiWanI2vLoraRequestsByRequestIdStatusResponses[keyof GetFalAiWanI2vLoraRequestsByRequestIdStatusResponses]

export type PutFalAiWanI2vLoraRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan-i2v-lora/requests/{request_id}/cancel'
}

export type PutFalAiWanI2vLoraRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiWanI2vLoraRequestsByRequestIdCancelResponse =
  PutFalAiWanI2vLoraRequestsByRequestIdCancelResponses[keyof PutFalAiWanI2vLoraRequestsByRequestIdCancelResponses]

export type PostFalAiWanI2vLoraData = {
  body: SchemaWanI2vLoraInput
  path?: never
  query?: never
  url: '/fal-ai/wan-i2v-lora'
}

export type PostFalAiWanI2vLoraResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiWanI2vLoraResponse =
  PostFalAiWanI2vLoraResponses[keyof PostFalAiWanI2vLoraResponses]

export type GetFalAiWanI2vLoraRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan-i2v-lora/requests/{request_id}'
}

export type GetFalAiWanI2vLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaWanI2vLoraOutput
}

export type GetFalAiWanI2vLoraRequestsByRequestIdResponse =
  GetFalAiWanI2vLoraRequestsByRequestIdResponses[keyof GetFalAiWanI2vLoraRequestsByRequestIdResponses]

export type GetFalAiHunyuanVideoImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/hunyuan-video-image-to-video/requests/{request_id}/status'
}

export type GetFalAiHunyuanVideoImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiHunyuanVideoImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiHunyuanVideoImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiHunyuanVideoImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiHunyuanVideoImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/hunyuan-video-image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiHunyuanVideoImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiHunyuanVideoImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiHunyuanVideoImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiHunyuanVideoImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiHunyuanVideoImageToVideoData = {
  body: SchemaHunyuanVideoImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/hunyuan-video-image-to-video'
}

export type PostFalAiHunyuanVideoImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiHunyuanVideoImageToVideoResponse =
  PostFalAiHunyuanVideoImageToVideoResponses[keyof PostFalAiHunyuanVideoImageToVideoResponses]

export type GetFalAiHunyuanVideoImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/hunyuan-video-image-to-video/requests/{request_id}'
}

export type GetFalAiHunyuanVideoImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaHunyuanVideoImageToVideoOutput
}

export type GetFalAiHunyuanVideoImageToVideoRequestsByRequestIdResponse =
  GetFalAiHunyuanVideoImageToVideoRequestsByRequestIdResponses[keyof GetFalAiHunyuanVideoImageToVideoRequestsByRequestIdResponses]

export type GetFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/minimax/video-01-director/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/minimax/video-01-director/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiMinimaxVideo01DirectorImageToVideoData = {
  body: SchemaMinimaxVideo01DirectorImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/minimax/video-01-director/image-to-video'
}

export type PostFalAiMinimaxVideo01DirectorImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMinimaxVideo01DirectorImageToVideoResponse =
  PostFalAiMinimaxVideo01DirectorImageToVideoResponses[keyof PostFalAiMinimaxVideo01DirectorImageToVideoResponses]

export type GetFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/minimax/video-01-director/image-to-video/requests/{request_id}'
  }

export type GetFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaMinimaxVideo01DirectorImageToVideoOutput
  }

export type GetFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdResponse =
  GetFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdResponses[keyof GetFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdResponses]

export type GetFalAiSkyreelsI2vRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/skyreels-i2v/requests/{request_id}/status'
}

export type GetFalAiSkyreelsI2vRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiSkyreelsI2vRequestsByRequestIdStatusResponse =
  GetFalAiSkyreelsI2vRequestsByRequestIdStatusResponses[keyof GetFalAiSkyreelsI2vRequestsByRequestIdStatusResponses]

export type PutFalAiSkyreelsI2vRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/skyreels-i2v/requests/{request_id}/cancel'
}

export type PutFalAiSkyreelsI2vRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiSkyreelsI2vRequestsByRequestIdCancelResponse =
  PutFalAiSkyreelsI2vRequestsByRequestIdCancelResponses[keyof PutFalAiSkyreelsI2vRequestsByRequestIdCancelResponses]

export type PostFalAiSkyreelsI2vData = {
  body: SchemaSkyreelsI2vInput
  path?: never
  query?: never
  url: '/fal-ai/skyreels-i2v'
}

export type PostFalAiSkyreelsI2vResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiSkyreelsI2vResponse =
  PostFalAiSkyreelsI2vResponses[keyof PostFalAiSkyreelsI2vResponses]

export type GetFalAiSkyreelsI2vRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/skyreels-i2v/requests/{request_id}'
}

export type GetFalAiSkyreelsI2vRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaSkyreelsI2vOutput
}

export type GetFalAiSkyreelsI2vRequestsByRequestIdResponse =
  GetFalAiSkyreelsI2vRequestsByRequestIdResponses[keyof GetFalAiSkyreelsI2vRequestsByRequestIdResponses]

export type GetFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/luma-dream-machine/ray-2/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/luma-dream-machine/ray-2/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiLumaDreamMachineRay2ImageToVideoData = {
  body: SchemaLumaDreamMachineRay2ImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/luma-dream-machine/ray-2/image-to-video'
}

export type PostFalAiLumaDreamMachineRay2ImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLumaDreamMachineRay2ImageToVideoResponse =
  PostFalAiLumaDreamMachineRay2ImageToVideoResponses[keyof PostFalAiLumaDreamMachineRay2ImageToVideoResponses]

export type GetFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/luma-dream-machine/ray-2/image-to-video/requests/{request_id}'
}

export type GetFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaLumaDreamMachineRay2ImageToVideoOutput
  }

export type GetFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdResponse =
  GetFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdResponses[keyof GetFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdResponses]

export type GetFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/hunyuan-video-img2vid-lora/requests/{request_id}/status'
}

export type GetFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdStatusResponse =
  GetFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdStatusResponses[keyof GetFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdStatusResponses]

export type PutFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/hunyuan-video-img2vid-lora/requests/{request_id}/cancel'
}

export type PutFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdCancelResponse =
  PutFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdCancelResponses[keyof PutFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdCancelResponses]

export type PostFalAiHunyuanVideoImg2VidLoraData = {
  body: SchemaHunyuanVideoImg2VidLoraInput
  path?: never
  query?: never
  url: '/fal-ai/hunyuan-video-img2vid-lora'
}

export type PostFalAiHunyuanVideoImg2VidLoraResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiHunyuanVideoImg2VidLoraResponse =
  PostFalAiHunyuanVideoImg2VidLoraResponses[keyof PostFalAiHunyuanVideoImg2VidLoraResponses]

export type GetFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/hunyuan-video-img2vid-lora/requests/{request_id}'
}

export type GetFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaHunyuanVideoImg2VidLoraOutput
}

export type GetFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdResponse =
  GetFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdResponses[keyof GetFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdResponses]

export type GetFalAiPixverseV35ImageToVideoFastRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v3.5/image-to-video/fast/requests/{request_id}/status'
}

export type GetFalAiPixverseV35ImageToVideoFastRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiPixverseV35ImageToVideoFastRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV35ImageToVideoFastRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV35ImageToVideoFastRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV35ImageToVideoFastRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v3.5/image-to-video/fast/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV35ImageToVideoFastRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiPixverseV35ImageToVideoFastRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV35ImageToVideoFastRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV35ImageToVideoFastRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV35ImageToVideoFastData = {
  body: SchemaPixverseV35ImageToVideoFastInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v3.5/image-to-video/fast'
}

export type PostFalAiPixverseV35ImageToVideoFastResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV35ImageToVideoFastResponse =
  PostFalAiPixverseV35ImageToVideoFastResponses[keyof PostFalAiPixverseV35ImageToVideoFastResponses]

export type GetFalAiPixverseV35ImageToVideoFastRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v3.5/image-to-video/fast/requests/{request_id}'
}

export type GetFalAiPixverseV35ImageToVideoFastRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV35ImageToVideoFastOutput
}

export type GetFalAiPixverseV35ImageToVideoFastRequestsByRequestIdResponse =
  GetFalAiPixverseV35ImageToVideoFastRequestsByRequestIdResponses[keyof GetFalAiPixverseV35ImageToVideoFastRequestsByRequestIdResponses]

export type GetFalAiPixverseV35ImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v3.5/image-to-video/requests/{request_id}/status'
}

export type GetFalAiPixverseV35ImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiPixverseV35ImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV35ImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV35ImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV35ImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v3.5/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV35ImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiPixverseV35ImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV35ImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV35ImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV35ImageToVideoData = {
  body: SchemaPixverseV35ImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v3.5/image-to-video'
}

export type PostFalAiPixverseV35ImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV35ImageToVideoResponse =
  PostFalAiPixverseV35ImageToVideoResponses[keyof PostFalAiPixverseV35ImageToVideoResponses]

export type GetFalAiPixverseV35ImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v3.5/image-to-video/requests/{request_id}'
}

export type GetFalAiPixverseV35ImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV35ImageToVideoOutput
}

export type GetFalAiPixverseV35ImageToVideoRequestsByRequestIdResponse =
  GetFalAiPixverseV35ImageToVideoRequestsByRequestIdResponses[keyof GetFalAiPixverseV35ImageToVideoRequestsByRequestIdResponses]

export type GetFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/minimax/video-01-subject-reference/requests/{request_id}/status'
  }

export type GetFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdStatusResponses]

export type PutFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/minimax/video-01-subject-reference/requests/{request_id}/cancel'
  }

export type PutFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdCancelResponses]

export type PostFalAiMinimaxVideo01SubjectReferenceData = {
  body: SchemaMinimaxVideo01SubjectReferenceInput
  path?: never
  query?: never
  url: '/fal-ai/minimax/video-01-subject-reference'
}

export type PostFalAiMinimaxVideo01SubjectReferenceResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMinimaxVideo01SubjectReferenceResponse =
  PostFalAiMinimaxVideo01SubjectReferenceResponses[keyof PostFalAiMinimaxVideo01SubjectReferenceResponses]

export type GetFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax/video-01-subject-reference/requests/{request_id}'
}

export type GetFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaMinimaxVideo01SubjectReferenceOutput
  }

export type GetFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdResponse =
  GetFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdResponses[keyof GetFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdResponses]

export type GetFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/kling-video/v1.6/standard/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/v1.6/standard/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV16StandardImageToVideoData = {
  body: SchemaKlingVideoV16StandardImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v1.6/standard/image-to-video'
}

export type PostFalAiKlingVideoV16StandardImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV16StandardImageToVideoResponse =
  PostFalAiKlingVideoV16StandardImageToVideoResponses[keyof PostFalAiKlingVideoV16StandardImageToVideoResponses]

export type GetFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v1.6/standard/image-to-video/requests/{request_id}'
}

export type GetFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaKlingVideoV16StandardImageToVideoOutput
  }

export type GetFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdResponse =
  GetFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdResponses]

export type GetFalAiSadtalkerReferenceRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/sadtalker/reference/requests/{request_id}/status'
}

export type GetFalAiSadtalkerReferenceRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiSadtalkerReferenceRequestsByRequestIdStatusResponse =
  GetFalAiSadtalkerReferenceRequestsByRequestIdStatusResponses[keyof GetFalAiSadtalkerReferenceRequestsByRequestIdStatusResponses]

export type PutFalAiSadtalkerReferenceRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/sadtalker/reference/requests/{request_id}/cancel'
}

export type PutFalAiSadtalkerReferenceRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiSadtalkerReferenceRequestsByRequestIdCancelResponse =
  PutFalAiSadtalkerReferenceRequestsByRequestIdCancelResponses[keyof PutFalAiSadtalkerReferenceRequestsByRequestIdCancelResponses]

export type PostFalAiSadtalkerReferenceData = {
  body: SchemaSadtalkerReferenceInput
  path?: never
  query?: never
  url: '/fal-ai/sadtalker/reference'
}

export type PostFalAiSadtalkerReferenceResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiSadtalkerReferenceResponse =
  PostFalAiSadtalkerReferenceResponses[keyof PostFalAiSadtalkerReferenceResponses]

export type GetFalAiSadtalkerReferenceRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/sadtalker/reference/requests/{request_id}'
}

export type GetFalAiSadtalkerReferenceRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaSadtalkerReferenceOutput
}

export type GetFalAiSadtalkerReferenceRequestsByRequestIdResponse =
  GetFalAiSadtalkerReferenceRequestsByRequestIdResponses[keyof GetFalAiSadtalkerReferenceRequestsByRequestIdResponses]

export type GetFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/minimax/video-01-live/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/minimax/video-01-live/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiMinimaxVideo01LiveImageToVideoData = {
  body: SchemaMinimaxVideo01LiveImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/minimax/video-01-live/image-to-video'
}

export type PostFalAiMinimaxVideo01LiveImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMinimaxVideo01LiveImageToVideoResponse =
  PostFalAiMinimaxVideo01LiveImageToVideoResponses[keyof PostFalAiMinimaxVideo01LiveImageToVideoResponses]

export type GetFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax/video-01-live/image-to-video/requests/{request_id}'
}

export type GetFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaMinimaxVideo01LiveImageToVideoOutput
  }

export type GetFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdResponse =
  GetFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdResponses[keyof GetFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdResponses]

export type GetFalAiLtxVideoImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ltx-video/image-to-video/requests/{request_id}/status'
}

export type GetFalAiLtxVideoImageToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiLtxVideoImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiLtxVideoImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiLtxVideoImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiLtxVideoImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-video/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiLtxVideoImageToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiLtxVideoImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiLtxVideoImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiLtxVideoImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiLtxVideoImageToVideoData = {
  body: SchemaLtxVideoImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/ltx-video/image-to-video'
}

export type PostFalAiLtxVideoImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLtxVideoImageToVideoResponse =
  PostFalAiLtxVideoImageToVideoResponses[keyof PostFalAiLtxVideoImageToVideoResponses]

export type GetFalAiLtxVideoImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-video/image-to-video/requests/{request_id}'
}

export type GetFalAiLtxVideoImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLtxVideoImageToVideoOutput
}

export type GetFalAiLtxVideoImageToVideoRequestsByRequestIdResponse =
  GetFalAiLtxVideoImageToVideoRequestsByRequestIdResponses[keyof GetFalAiLtxVideoImageToVideoRequestsByRequestIdResponses]

export type GetFalAiCogvideox5bImageToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/cogvideox-5b/image-to-video/requests/{request_id}/status'
}

export type GetFalAiCogvideox5bImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiCogvideox5bImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiCogvideox5bImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiCogvideox5bImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiCogvideox5bImageToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/cogvideox-5b/image-to-video/requests/{request_id}/cancel'
}

export type PutFalAiCogvideox5bImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiCogvideox5bImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiCogvideox5bImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiCogvideox5bImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiCogvideox5bImageToVideoData = {
  body: SchemaCogvideox5bImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/cogvideox-5b/image-to-video'
}

export type PostFalAiCogvideox5bImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiCogvideox5bImageToVideoResponse =
  PostFalAiCogvideox5bImageToVideoResponses[keyof PostFalAiCogvideox5bImageToVideoResponses]

export type GetFalAiCogvideox5bImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/cogvideox-5b/image-to-video/requests/{request_id}'
}

export type GetFalAiCogvideox5bImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaCogvideox5bImageToVideoOutput
}

export type GetFalAiCogvideox5bImageToVideoRequestsByRequestIdResponse =
  GetFalAiCogvideox5bImageToVideoRequestsByRequestIdResponses[keyof GetFalAiCogvideox5bImageToVideoRequestsByRequestIdResponses]

export type GetFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/kling-video/v1.5/pro/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/v1.5/pro/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV15ProImageToVideoData = {
  body: SchemaKlingVideoV15ProImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v1.5/pro/image-to-video'
}

export type PostFalAiKlingVideoV15ProImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV15ProImageToVideoResponse =
  PostFalAiKlingVideoV15ProImageToVideoResponses[keyof PostFalAiKlingVideoV15ProImageToVideoResponses]

export type GetFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v1.5/pro/image-to-video/requests/{request_id}'
}

export type GetFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKlingVideoV15ProImageToVideoOutput
}

export type GetFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdResponse =
  GetFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdResponses]

export type GetFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/kling-video/v1/standard/image-to-video/requests/{request_id}/status'
  }

export type GetFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/v1/standard/image-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV1StandardImageToVideoData = {
  body: SchemaKlingVideoV1StandardImageToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v1/standard/image-to-video'
}

export type PostFalAiKlingVideoV1StandardImageToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV1StandardImageToVideoResponse =
  PostFalAiKlingVideoV1StandardImageToVideoResponses[keyof PostFalAiKlingVideoV1StandardImageToVideoResponses]

export type GetFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v1/standard/image-to-video/requests/{request_id}'
}

export type GetFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaKlingVideoV1StandardImageToVideoOutput
  }

export type GetFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdResponse =
  GetFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdResponses]

export type GetFalAiStableVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/stable-video/requests/{request_id}/status'
}

export type GetFalAiStableVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiStableVideoRequestsByRequestIdStatusResponse =
  GetFalAiStableVideoRequestsByRequestIdStatusResponses[keyof GetFalAiStableVideoRequestsByRequestIdStatusResponses]

export type PutFalAiStableVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/stable-video/requests/{request_id}/cancel'
}

export type PutFalAiStableVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiStableVideoRequestsByRequestIdCancelResponse =
  PutFalAiStableVideoRequestsByRequestIdCancelResponses[keyof PutFalAiStableVideoRequestsByRequestIdCancelResponses]

export type PostFalAiStableVideoData = {
  body: SchemaStableVideoInput
  path?: never
  query?: never
  url: '/fal-ai/stable-video'
}

export type PostFalAiStableVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiStableVideoResponse =
  PostFalAiStableVideoResponses[keyof PostFalAiStableVideoResponses]

export type GetFalAiStableVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/stable-video/requests/{request_id}'
}

export type GetFalAiStableVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaStableVideoOutput
}

export type GetFalAiStableVideoRequestsByRequestIdResponse =
  GetFalAiStableVideoRequestsByRequestIdResponses[keyof GetFalAiStableVideoRequestsByRequestIdResponses]

export type GetFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/amt-interpolation/frame-interpolation/requests/{request_id}/status'
  }

export type GetFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdStatusResponse =
  GetFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdStatusResponses[keyof GetFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdStatusResponses]

export type PutFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/amt-interpolation/frame-interpolation/requests/{request_id}/cancel'
  }

export type PutFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdCancelResponse =
  PutFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdCancelResponses[keyof PutFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdCancelResponses]

export type PostFalAiAmtInterpolationFrameInterpolationData = {
  body: SchemaAmtInterpolationFrameInterpolationInput
  path?: never
  query?: never
  url: '/fal-ai/amt-interpolation/frame-interpolation'
}

export type PostFalAiAmtInterpolationFrameInterpolationResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiAmtInterpolationFrameInterpolationResponse =
  PostFalAiAmtInterpolationFrameInterpolationResponses[keyof PostFalAiAmtInterpolationFrameInterpolationResponses]

export type GetFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/amt-interpolation/frame-interpolation/requests/{request_id}'
  }

export type GetFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaAmtInterpolationFrameInterpolationOutput
  }

export type GetFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdResponse =
  GetFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdResponses[keyof GetFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdResponses]

export type GetFalAiLivePortraitRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/live-portrait/requests/{request_id}/status'
}

export type GetFalAiLivePortraitRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiLivePortraitRequestsByRequestIdStatusResponse =
  GetFalAiLivePortraitRequestsByRequestIdStatusResponses[keyof GetFalAiLivePortraitRequestsByRequestIdStatusResponses]

export type PutFalAiLivePortraitRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/live-portrait/requests/{request_id}/cancel'
}

export type PutFalAiLivePortraitRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiLivePortraitRequestsByRequestIdCancelResponse =
  PutFalAiLivePortraitRequestsByRequestIdCancelResponses[keyof PutFalAiLivePortraitRequestsByRequestIdCancelResponses]

export type PostFalAiLivePortraitData = {
  body: SchemaLivePortraitInput
  path?: never
  query?: never
  url: '/fal-ai/live-portrait'
}

export type PostFalAiLivePortraitResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLivePortraitResponse =
  PostFalAiLivePortraitResponses[keyof PostFalAiLivePortraitResponses]

export type GetFalAiLivePortraitRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/live-portrait/requests/{request_id}'
}

export type GetFalAiLivePortraitRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLivePortraitOutput
}

export type GetFalAiLivePortraitRequestsByRequestIdResponse =
  GetFalAiLivePortraitRequestsByRequestIdResponses[keyof GetFalAiLivePortraitRequestsByRequestIdResponses]

export type GetFalAiMusetalkRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/musetalk/requests/{request_id}/status'
}

export type GetFalAiMusetalkRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiMusetalkRequestsByRequestIdStatusResponse =
  GetFalAiMusetalkRequestsByRequestIdStatusResponses[keyof GetFalAiMusetalkRequestsByRequestIdStatusResponses]

export type PutFalAiMusetalkRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/musetalk/requests/{request_id}/cancel'
}

export type PutFalAiMusetalkRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiMusetalkRequestsByRequestIdCancelResponse =
  PutFalAiMusetalkRequestsByRequestIdCancelResponses[keyof PutFalAiMusetalkRequestsByRequestIdCancelResponses]

export type PostFalAiMusetalkData = {
  body: SchemaMusetalkInput
  path?: never
  query?: never
  url: '/fal-ai/musetalk'
}

export type PostFalAiMusetalkResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMusetalkResponse =
  PostFalAiMusetalkResponses[keyof PostFalAiMusetalkResponses]

export type GetFalAiMusetalkRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/musetalk/requests/{request_id}'
}

export type GetFalAiMusetalkRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaMusetalkOutput
}

export type GetFalAiMusetalkRequestsByRequestIdResponse =
  GetFalAiMusetalkRequestsByRequestIdResponses[keyof GetFalAiMusetalkRequestsByRequestIdResponses]

export type GetFalAiSadtalkerRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/sadtalker/requests/{request_id}/status'
}

export type GetFalAiSadtalkerRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiSadtalkerRequestsByRequestIdStatusResponse =
  GetFalAiSadtalkerRequestsByRequestIdStatusResponses[keyof GetFalAiSadtalkerRequestsByRequestIdStatusResponses]

export type PutFalAiSadtalkerRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/sadtalker/requests/{request_id}/cancel'
}

export type PutFalAiSadtalkerRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiSadtalkerRequestsByRequestIdCancelResponse =
  PutFalAiSadtalkerRequestsByRequestIdCancelResponses[keyof PutFalAiSadtalkerRequestsByRequestIdCancelResponses]

export type PostFalAiSadtalkerData = {
  body: SchemaSadtalkerInput
  path?: never
  query?: never
  url: '/fal-ai/sadtalker'
}

export type PostFalAiSadtalkerResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiSadtalkerResponse =
  PostFalAiSadtalkerResponses[keyof PostFalAiSadtalkerResponses]

export type GetFalAiSadtalkerRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/sadtalker/requests/{request_id}'
}

export type GetFalAiSadtalkerRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaSadtalkerOutput
}

export type GetFalAiSadtalkerRequestsByRequestIdResponse =
  GetFalAiSadtalkerRequestsByRequestIdResponses[keyof GetFalAiSadtalkerRequestsByRequestIdResponses]

export type GetFalAiFastSvdLcmRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/fast-svd-lcm/requests/{request_id}/status'
}

export type GetFalAiFastSvdLcmRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiFastSvdLcmRequestsByRequestIdStatusResponse =
  GetFalAiFastSvdLcmRequestsByRequestIdStatusResponses[keyof GetFalAiFastSvdLcmRequestsByRequestIdStatusResponses]

export type PutFalAiFastSvdLcmRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/fast-svd-lcm/requests/{request_id}/cancel'
}

export type PutFalAiFastSvdLcmRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiFastSvdLcmRequestsByRequestIdCancelResponse =
  PutFalAiFastSvdLcmRequestsByRequestIdCancelResponses[keyof PutFalAiFastSvdLcmRequestsByRequestIdCancelResponses]

export type PostFalAiFastSvdLcmData = {
  body: SchemaFastSvdLcmInput
  path?: never
  query?: never
  url: '/fal-ai/fast-svd-lcm'
}

export type PostFalAiFastSvdLcmResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiFastSvdLcmResponse =
  PostFalAiFastSvdLcmResponses[keyof PostFalAiFastSvdLcmResponses]

export type GetFalAiFastSvdLcmRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/fast-svd-lcm/requests/{request_id}'
}

export type GetFalAiFastSvdLcmRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaFastSvdLcmOutput
}

export type GetFalAiFastSvdLcmRequestsByRequestIdResponse =
  GetFalAiFastSvdLcmRequestsByRequestIdResponses[keyof GetFalAiFastSvdLcmRequestsByRequestIdResponses]
