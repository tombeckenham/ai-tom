// This file is auto-generated by @hey-api/openapi-ts

export type ClientOptions = {
  baseUrl: 'https://queue.fal.run' | (string & {})
}

/**
 * AnimatediffLCMOutput
 */
export type SchemaAnimatediffSparsectrlLcmOutput = {
  /**
   * Seed
   *
   * The seed used to generate the video.
   */
  seed: number
  /**
   * Video
   *
   * Generated video file.
   */
  video: SchemaFile
}

/**
 * File
 */
export type SchemaFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * AnimatediffLCMInput
 */
export type SchemaAnimatediffSparsectrlLcmInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable
   * Diffusion will output the same image every time.
   *
   */
  seed?: number
  /**
   * Controlnet Type
   *
   * The type of controlnet to use for generating the video. The controlnet determines how the video will be animated.
   */
  controlnet_type?: 'scribble' | 'rgb'
  /**
   * Keyframe 2 Index
   *
   * The frame index of the third keyframe to use for the generation.
   */
  keyframe_2_index?: number
  /**
   * Keyframe 0 Index
   *
   * The frame index of the first keyframe to use for the generation.
   */
  keyframe_0_index?: number
  /**
   * Keyframe 1 Image Url
   *
   * The URL of the second keyframe to use for the generation.
   */
  keyframe_1_image_url?: string | null
  /**
   * Keyframe 1 Index
   *
   * The frame index of the second keyframe to use for the generation.
   */
  keyframe_1_index?: number
  /**
   * Classifier-Free Guidance scale (CFG)
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Number of inference steps
   *
   * Increasing the amount of steps tells Stable Diffusion that it should take more steps to generate your final result which can increase the amount of detail in your image.
   */
  num_inference_steps?: number
  /**
   * Keyframe 2 Image Url
   *
   * The URL of the third keyframe to use for the generation.
   */
  keyframe_2_image_url?: string | null
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to specify what you don't want.
   *
   */
  negative_prompt?: string
  /**
   * Keyframe 0 Image Url
   *
   * The URL of the first keyframe to use for the generation.
   */
  keyframe_0_image_url?: string | null
}

/**
 * VideoOutput
 */
export type SchemaMinimaxVideo01Output = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * TextToVideoRequest
 */
export type SchemaMinimaxVideo01Input = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Prompt
   */
  prompt: string
}

/**
 * AnimateDiffT2VOutput
 */
export type SchemaFastAnimatediffTurboTextToVideoOutput = {
  /**
   * Seed
   *
   * Seed used for generating the video.
   */
  seed: number
  /**
   * Video
   *
   * Generated video file.
   */
  video: SchemaFile
}

/**
 * AnimateDiffT2VTurboInput
 */
export type SchemaFastAnimatediffTurboTextToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the video. Be as descriptive as possible for best results.
   */
  prompt: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Fps
   *
   * Number of frames per second to extract from the video.
   */
  fps?: number
  /**
   * Video Size
   *
   * The size of the video to generate.
   */
  video_size?:
    | SchemaImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Num Frames
   *
   * The number of frames to generate for the video.
   */
  num_frames?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform. 4-12 is recommended for turbo mode.
   */
  num_inference_steps?: number
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
  /**
   * Motions
   *
   * The motions to apply to the video.
   */
  motions?: Array<
    'zoom-out' | 'zoom-in' | 'pan-left' | 'pan-right' | 'tilt-up' | 'tilt-down'
  >
}

/**
 * ImageSize
 */
export type SchemaImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * AnimateDiffT2VOutput
 */
export type SchemaFastAnimatediffTextToVideoOutput = {
  /**
   * Seed
   *
   * Seed used for generating the video.
   */
  seed: number
  /**
   * Video
   *
   * Generated video file.
   */
  video: SchemaFile
}

/**
 * AnimateDiffT2VInput
 */
export type SchemaFastAnimatediffTextToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the video. Be as descriptive as possible for best results.
   */
  prompt: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Fps
   *
   * Number of frames per second to extract from the video.
   */
  fps?: number
  /**
   * Video Size
   *
   * The size of the video to generate.
   */
  video_size?:
    | SchemaImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Frames
   *
   * The number of frames to generate for the video.
   */
  num_frames?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
  /**
   * Motions
   *
   * The motions to apply to the video.
   */
  motions?: Array<
    'zoom-out' | 'zoom-in' | 'pan-left' | 'pan-right' | 'tilt-up' | 'tilt-down'
  >
}

/**
 * Output
 */
export type SchemaT2vTurboOutput = {
  video: SchemaFile
}

/**
 * Input
 */
export type SchemaT2vTurboInput = {
  /**
   * Prompt
   *
   * The prompt to generate images from
   */
  prompt: string
  /**
   * Guidance Scale
   *
   * The guidance scale
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * The seed to use for the random number generator
   */
  seed?: number | unknown
  /**
   * Export Fps
   *
   * The FPS of the exported video
   */
  export_fps?: number
  /**
   * Num Frames
   *
   * The number of frames to generate
   */
  num_frames?: number
  /**
   * Num Inference Steps
   *
   * The number of steps to sample
   */
  num_inference_steps?: number
}

/**
 * FastSVDOutput
 */
export type SchemaFastSvdLcmTextToVideoOutput = {
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   *
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * FastSVDTextInput
 */
export type SchemaFastSvdLcmTextToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to use as a starting point for the generation.
   */
  prompt: string
  /**
   * Cond Aug
   *
   *
   * The conditoning augmentation determines the amount of noise that will be
   * added to the conditioning frame. The higher the number, the more noise
   * there will be, and the less the video will look like the initial image.
   * Increase it for more motion.
   *
   */
  cond_aug?: number
  /**
   * Fps
   *
   *
   * The FPS of the generated video. The higher the number, the faster the video will
   * play. Total video length is 25 frames.
   *
   */
  fps?: number
  /**
   * Motion Bucket Id
   *
   *
   * The motion bucket id determines the motion of the generated video. The
   * higher the number, the more motion there will be.
   *
   */
  motion_bucket_id?: number
  /**
   * Video Size
   *
   * The size of the generated video.
   */
  video_size?:
    | SchemaImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Steps
   *
   *
   * The number of steps to run the model for. The higher the number the better
   * the quality and longer it will take to generate.
   *
   */
  steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
}

/**
 * FastSVDOutput
 */
export type SchemaFastSvdTextToVideoOutput = {
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   *
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * FastSVDTextInput
 */
export type SchemaFastSvdTextToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to use as a starting point for the generation.
   */
  prompt: string
  /**
   * Cond Aug
   *
   *
   * The conditoning augmentation determines the amount of noise that will be
   * added to the conditioning frame. The higher the number, the more noise
   * there will be, and the less the video will look like the initial image.
   * Increase it for more motion.
   *
   */
  cond_aug?: number
  /**
   * Deep Cache
   *
   *
   * Enabling [DeepCache](https://github.com/horseee/DeepCache) will make the execution
   * faster, but might sometimes degrade overall quality. The higher the setting, the
   * faster the execution will be, but the more quality might be lost.
   *
   */
  deep_cache?: 'none' | 'minimum' | 'medium' | 'high'
  /**
   * Fps
   *
   *
   * The FPS of the generated video. The higher the number, the faster the video will
   * play. Total video length is 25 frames.
   *
   */
  fps?: number
  /**
   * Motion Bucket Id
   *
   *
   * The motion bucket id determines the motion of the generated video. The
   * higher the number, the more motion there will be.
   *
   */
  motion_bucket_id?: number
  /**
   * Video Size
   *
   * The size of the generated video.
   */
  video_size?:
    | SchemaImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Steps
   *
   *
   * The number of steps to run the model for. The higher the number the better
   * the quality and longer it will take to generate.
   *
   */
  steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to use as a starting point for the generation.
   */
  negative_prompt?: string
}

/**
 * Output
 */
export type SchemaLtxVideoOutput = {
  /**
   * Seed
   *
   * The seed used for random number generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video.
   */
  video: SchemaFile
}

/**
 * TextToVideoInput
 */
export type SchemaLtxVideoInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Guidance Scale
   *
   * The guidance scale to use.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * The seed to use for random number generation.
   */
  seed?: number
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to take.
   */
  num_inference_steps?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to generate the video from.
   */
  negative_prompt?: string
}

/**
 * HunyuanT2VResponse
 */
export type SchemaHunyuanVideoOutput = {
  /**
   * Seed
   *
   * The seed used for generating the video.
   */
  seed: number
  /**
   * Video
   */
  video: SchemaFile
}

/**
 * HunyuanVideoRequest
 */
export type SchemaHunyuanVideoInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Aspect Ratio (W:H)
   *
   * The aspect ratio of the video to generate.
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the video to generate.
   */
  resolution?: '480p' | '580p' | '720p'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Inference Steps
   *
   * The number of inference steps to run. Lower gets faster results, higher gets better results.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The seed to use for generating the video.
   */
  seed?: number
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: '129' | '85'
  /**
   * Pro Mode
   *
   * By default, generations are done with 35 steps. Pro mode does 55 steps which results in higher quality videos but will take more time and cost 2x more billing units.
   */
  pro_mode?: boolean
}

/**
 * MochiT2VOutput
 */
export type SchemaMochiV1Output = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * MochiT2VInput
 */
export type SchemaMochiV1Input = {
  /**
   * Prompt
   *
   * The prompt to generate a video from.
   */
  prompt: string
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * The seed to use for generating the video.
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * The negative prompt for the video.
   */
  negative_prompt?: string
}

/**
 * T2VOutput
 */
export type SchemaKlingVideoV15ProTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * TextToVideoRequest
 */
export type SchemaKlingVideoV15ProTextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video frame
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * CameraControl
 */
export type SchemaCameraControl = {
  /**
   * Movement Type
   *
   * The type of camera movement
   */
  movement_type: 'horizontal' | 'vertical' | 'pan' | 'tilt' | 'roll' | 'zoom'
  /**
   * Movement Value
   *
   * The value of the camera movement
   */
  movement_value: number
}

/**
 * T2VOutput
 */
export type SchemaKlingVideoV1StandardTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * V1TextToVideoRequest
 */
export type SchemaKlingVideoV1StandardTextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video frame
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Advanced Camera Control
   *
   * Advanced Camera control parameters
   */
  advanced_camera_control?: SchemaCameraControl
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Camera Control
   *
   * Camera control parameters
   */
  camera_control?:
    | 'down_back'
    | 'forward_up'
    | 'right_turn_forward'
    | 'left_turn_forward'
}

/**
 * T2VLiveOutput
 */
export type SchemaMinimaxVideo01LiveOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * TextToVideoLiveRequest
 */
export type SchemaMinimaxVideo01LiveInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Prompt
   */
  prompt: string
}

/**
 * T2VOutput
 */
export type SchemaKlingVideoV16StandardTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * TextToVideoRequest
 */
export type SchemaKlingVideoV16StandardTextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video frame
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * Output
 */
export type SchemaCogvideox5bOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the video.
   */
  prompt: string
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Seed
   *
   *
   * Seed of the generated video. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
  /**
   * Video
   *
   * The URL to the generated video
   */
  video: SchemaFile
}

/**
 * BaseInput
 */
export type SchemaCogvideox5bInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Use Rife
   *
   * Use RIFE for video interpolation
   */
  use_rife?: boolean
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. We currently support one lora.
   *
   */
  loras?: Array<SchemaLoraWeight>
  /**
   * Video Size
   *
   * The size of the generated video.
   */
  video_size?:
    | SchemaImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related video to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Export Fps
   *
   * The target FPS of the video
   */
  export_fps?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to generate video from
   */
  negative_prompt?: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
}

/**
 * LoraWeight
 */
export type SchemaLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
}

/**
 * Output
 */
export type SchemaTranspixarOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the video.
   */
  prompt: string
  /**
   * Videos
   *
   * The URL to the generated video
   */
  videos: Array<SchemaFile>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Seed
   *
   *
   * Seed of the generated video. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * BaseInput
 */
export type SchemaTranspixarInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related video to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Export Fps
   *
   * The target FPS of the video
   */
  export_fps?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to generate video from
   */
  negative_prompt?: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number | unknown
}

/**
 * HunyuanT2VResponse
 */
export type SchemaHunyuanVideoLoraOutput = {
  /**
   * Seed
   *
   * The seed used for generating the video.
   */
  seed: number
  /**
   * Video
   */
  video: SchemaFile
}

/**
 * HunyuanT2VRequest
 */
export type SchemaHunyuanVideoLoraInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Aspect Ratio (W:H)
   *
   * The aspect ratio of the video to generate.
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the video to generate.
   */
  resolution?: '480p' | '580p' | '720p'
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<SchemaLoraWeight>
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * The seed to use for generating the video.
   */
  seed?: number
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: '129' | '85'
  /**
   * Pro Mode
   *
   * By default, generations are done with 35 steps. Pro mode does 55 steps which results in higher quality videos but will take more time and cost 2x more billing units.
   */
  pro_mode?: boolean
}

/**
 * Ray2T2VOutput
 */
export type SchemaLumaDreamMachineRay2Output = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * Ray2TextToVideoRequest
 */
export type SchemaLumaDreamMachineRay2Input = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '9:16' | '4:3' | '3:4' | '21:9' | '9:21'
  /**
   * Resolution
   *
   * The resolution of the generated video (720p costs 2x more, 1080p costs 4x more)
   */
  resolution?: '540p' | '720p' | '1080p'
  /**
   * Loop
   *
   * Whether the video should loop (end of video is blended with the beginning)
   */
  loop?: boolean
  /**
   * Duration
   *
   * The duration of the generated video (9s costs 2x more)
   */
  duration?: '5s' | '9s'
}

/**
 * VideoOutput
 */
export type SchemaPixverseV35TextToVideoFastOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * FastTextToVideoRequest
 */
export type SchemaPixverseV35TextToVideoFastInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * VideoOutput
 */
export type SchemaPixverseV35TextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * TextToVideoRequest
 */
export type SchemaPixverseV35TextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Duration
   *
   * The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds
   */
  duration?: '5' | '8'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * T2VDirectorOutput
 */
export type SchemaMinimaxVideo01DirectorOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * TextToVideoDirectorRequest
 */
export type SchemaMinimaxVideo01DirectorInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Prompt
   *
   * Text prompt for video generation. Camera movement instructions can be added using square brackets (e.g. [Pan left] or [Zoom in]). You can use up to 3 combined movements per prompt. Supported movements: Truck left/right, Pan left/right, Push in/Pull out, Pedestal up/down, Tilt up/down, Zoom in/out, Shake, Tracking shot, Static shot. For example: [Truck left, Pan right, Zoom in]. For a more detailed guide, refer https://sixth-switch-2ac.notion.site/T2V-01-Director-Model-Tutorial-with-camera-movement-1886c20a98eb80f395b8e05291ad8645
   */
  prompt: string
}

/**
 * TextToVideoOutput
 */
export type SchemaVeo2Output = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * TextToVideoInput
 */
export type SchemaVeo2Input = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5s' | '6s' | '7s' | '8s'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Seed
   *
   * A seed to use for the video generation
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the video generation
   */
  negative_prompt?: string
  /**
   * Enhance Prompt
   *
   * Whether to enhance the video generation
   */
  enhance_prompt?: boolean
}

/**
 * WanT2VResponse
 */
export type SchemaWanT2vOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * WanT2VRequest
 */
export type SchemaWanT2vInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video (16:9 or 9:16).
   */
  aspect_ratio?: '9:16' | '16:9'
  /**
   * Resolution
   *
   * Resolution of the generated video (480p, 580p, or 720p).
   */
  resolution?: '480p' | '580p' | '720p'
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Turbo Mode
   *
   * If true, the video will be generated faster with no noticeable degradation in the visual quality.
   */
  turbo_mode?: boolean
  /**
   * Frames Per Second
   *
   * Frames per second of the generated video. Must be between 5 to 24.
   */
  frames_per_second?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Frames
   *
   * Number of frames to generate. Must be between 81 to 100 (inclusive).
   */
  num_frames?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
}

/**
 * T2VOutput
 */
export type SchemaKlingVideoV16ProTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * TextToVideoRequest
 */
export type SchemaKlingVideoV16ProTextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video frame
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * TextToVideoOutput
 */
export type SchemaLtxVideoV095Output = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * TextToVideoInput
 */
export type SchemaLtxVideoV095Input = {
  /**
   * Prompt
   *
   * Text prompt to guide generation
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p or 720p).
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video (16:9 or 9:16).
   */
  aspect_ratio?: '9:16' | '16:9'
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt using the model's own capabilities.
   */
  expand_prompt?: boolean
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps
   */
  num_inference_steps?: number
  /**
   * Negative Prompt
   *
   * Negative prompt for generation
   */
  negative_prompt?: string
}

/**
 * VideoEffectsOutput
 */
export type SchemaKlingVideoV16StandardEffectsOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * VideoEffectsRequest
 */
export type SchemaKlingVideoV16StandardEffectsInput = {
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Input Image Urls
   *
   * URL of images to be used for hug, kiss or heart_gesture video.
   */
  input_image_urls?: Array<string>
  /**
   * Effect Scene
   *
   * The effect scene to use for the video generation
   */
  effect_scene:
    | 'hug'
    | 'kiss'
    | 'heart_gesture'
    | 'squish'
    | 'expansion'
    | 'fuzzyfuzzy'
    | 'bloombloom'
    | 'dizzydizzy'
    | 'jelly_press'
    | 'jelly_slice'
    | 'jelly_squish'
    | 'jelly_jiggle'
    | 'pixelpixel'
    | 'yearbook'
    | 'instant_film'
    | 'anime_figure'
    | 'rocketrocket'
    | 'fly_fly'
    | 'disappear'
    | 'lightning_power'
    | 'bullet_time'
    | 'bullet_time_360'
    | 'media_interview'
    | 'day_to_night'
    | "let's_ride"
    | 'jumpdrop'
    | 'swish_swish'
    | 'running_man'
    | 'jazz_jazz'
    | 'swing_swing'
    | 'skateskate'
    | 'building_sweater'
    | 'pure_white_wings'
    | 'black_wings'
    | 'golden_wing'
    | 'pink_pink_wings'
    | 'rampage_ape'
    | 'a_list_look'
    | 'countdown_teleport'
    | 'firework_2026'
    | 'instant_christmas'
    | 'birthday_star'
    | 'firework'
    | 'celebration'
    | 'tiger_hug_pro'
    | 'pet_lion_pro'
    | 'guardian_spirit'
    | 'squeeze_scream'
    | 'inner_voice'
    | 'memory_alive'
    | 'guess_what'
    | 'eagle_snatch'
    | 'hug_from_past'
    | 'instant_kid'
    | 'dollar_rain'
    | 'cry_cry'
    | 'building_collapse'
    | 'mushroom'
    | 'jesus_hug'
    | 'shark_alert'
    | 'lie_flat'
    | 'polar_bear_hug'
    | 'brown_bear_hug'
    | 'office_escape_plow'
    | 'watermelon_bomb'
    | 'boss_coming'
    | 'wig_out'
    | 'car_explosion'
    | 'tiger_hug'
    | 'siblings'
    | 'construction_worker'
    | 'snatched'
    | 'felt_felt'
    | 'plushcut'
    | 'drunk_dance'
    | 'drunk_dance_pet'
    | 'daoma_dance'
    | 'bouncy_dance'
    | 'smooth_sailing_dance'
    | 'new_year_greeting'
    | 'lion_dance'
    | 'prosperity'
    | 'great_success'
    | 'golden_horse_fortune'
    | 'red_packet_box'
    | 'lucky_horse_year'
    | 'lucky_red_packet'
    | 'lucky_money_come'
    | 'lion_dance_pet'
    | 'dumpling_making_pet'
    | 'fish_making_pet'
    | 'pet_red_packet'
    | 'lantern_glow'
    | 'expression_challenge'
    | 'overdrive'
    | 'heart_gesture_dance'
    | 'poping'
    | 'martial_arts'
    | 'running'
    | 'nezha'
    | 'motorcycle_dance'
    | 'subject_3_dance'
    | 'ghost_step_dance'
    | 'phantom_jewel'
    | 'zoom_out'
    | 'cheers_2026'
    | 'kiss_pro'
    | 'fight_pro'
    | 'hug_pro'
    | 'heart_gesture_pro'
    | 'dollar_rain_pro'
    | 'pet_bee_pro'
    | 'santa_random_surprise'
    | 'magic_match_tree'
    | 'happy_birthday'
    | 'thumbs_up_pro'
    | 'surprise_bouquet'
    | 'bouquet_drop'
    | '3d_cartoon_1_pro'
    | 'glamour_photo_shoot'
    | 'box_of_joy'
    | 'first_toast_of_the_year'
    | 'my_santa_pic'
    | 'santa_gift'
    | 'steampunk_christmas'
    | 'snowglobe'
    | 'christmas_photo_shoot'
    | 'ornament_crash'
    | 'santa_express'
    | 'particle_santa_surround'
    | 'coronation_of_frost'
    | 'spark_in_the_snow'
    | 'scarlet_and_snow'
    | 'cozy_toon_wrap'
    | 'bullet_time_lite'
    | 'magic_cloak'
    | 'balloon_parade'
    | 'jumping_ginger_joy'
    | 'c4d_cartoon_pro'
    | 'venomous_spider'
    | 'throne_of_king'
    | 'luminous_elf'
    | 'woodland_elf'
    | 'japanese_anime_1'
    | 'american_comics'
    | 'snowboarding'
    | 'witch_transform'
    | 'vampire_transform'
    | 'pumpkin_head_transform'
    | 'demon_transform'
    | 'mummy_transform'
    | 'zombie_transform'
    | 'cute_pumpkin_transform'
    | 'cute_ghost_transform'
    | 'knock_knock_halloween'
    | 'halloween_escape'
    | 'baseball'
    | 'trampoline'
    | 'trampoline_night'
    | 'pucker_up'
    | 'feed_mooncake'
    | 'flyer'
    | 'dishwasher'
    | 'pet_chinese_opera'
    | 'magic_fireball'
    | 'gallery_ring'
    | 'pet_moto_rider'
    | 'muscle_pet'
    | 'pet_delivery'
    | 'mythic_style'
    | 'steampunk'
    | '3d_cartoon_2'
    | 'pet_chef'
    | 'santa_gifts'
    | 'santa_hug'
    | 'girlfriend'
    | 'boyfriend'
    | 'heart_gesture_1'
    | 'pet_wizard'
    | 'smoke_smoke'
    | 'gun_shot'
    | 'double_gun'
    | 'pet_warrior'
    | 'long_hair'
    | 'pet_dance'
    | 'wool_curly'
    | 'pet_bee'
    | 'marry_me'
    | 'piggy_morph'
    | 'ski_ski'
    | 'magic_broom'
    | 'splashsplash'
    | 'surfsurf'
    | 'fairy_wing'
    | 'angel_wing'
    | 'dark_wing'
    | 'emoji'
}

/**
 * VideoEffectsOutput
 */
export type SchemaKlingVideoV1StandardEffectsOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * VideoEffectsRequest
 */
export type SchemaKlingVideoV1StandardEffectsInput = {
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Input Image Urls
   *
   * URL of images to be used for hug, kiss or heart_gesture video.
   */
  input_image_urls?: Array<string>
  /**
   * Effect Scene
   *
   * The effect scene to use for the video generation
   */
  effect_scene:
    | 'hug'
    | 'kiss'
    | 'heart_gesture'
    | 'squish'
    | 'expansion'
    | 'fuzzyfuzzy'
    | 'bloombloom'
    | 'dizzydizzy'
    | 'jelly_press'
    | 'jelly_slice'
    | 'jelly_squish'
    | 'jelly_jiggle'
    | 'pixelpixel'
    | 'yearbook'
    | 'instant_film'
    | 'anime_figure'
    | 'rocketrocket'
    | 'fly_fly'
    | 'disappear'
    | 'lightning_power'
    | 'bullet_time'
    | 'bullet_time_360'
    | 'media_interview'
    | 'day_to_night'
    | "let's_ride"
    | 'jumpdrop'
    | 'swish_swish'
    | 'running_man'
    | 'jazz_jazz'
    | 'swing_swing'
    | 'skateskate'
    | 'building_sweater'
    | 'pure_white_wings'
    | 'black_wings'
    | 'golden_wing'
    | 'pink_pink_wings'
    | 'rampage_ape'
    | 'a_list_look'
    | 'countdown_teleport'
    | 'firework_2026'
    | 'instant_christmas'
    | 'birthday_star'
    | 'firework'
    | 'celebration'
    | 'tiger_hug_pro'
    | 'pet_lion_pro'
    | 'guardian_spirit'
    | 'squeeze_scream'
    | 'inner_voice'
    | 'memory_alive'
    | 'guess_what'
    | 'eagle_snatch'
    | 'hug_from_past'
    | 'instant_kid'
    | 'dollar_rain'
    | 'cry_cry'
    | 'building_collapse'
    | 'mushroom'
    | 'jesus_hug'
    | 'shark_alert'
    | 'lie_flat'
    | 'polar_bear_hug'
    | 'brown_bear_hug'
    | 'office_escape_plow'
    | 'watermelon_bomb'
    | 'boss_coming'
    | 'wig_out'
    | 'car_explosion'
    | 'tiger_hug'
    | 'siblings'
    | 'construction_worker'
    | 'snatched'
    | 'felt_felt'
    | 'plushcut'
    | 'drunk_dance'
    | 'drunk_dance_pet'
    | 'daoma_dance'
    | 'bouncy_dance'
    | 'smooth_sailing_dance'
    | 'new_year_greeting'
    | 'lion_dance'
    | 'prosperity'
    | 'great_success'
    | 'golden_horse_fortune'
    | 'red_packet_box'
    | 'lucky_horse_year'
    | 'lucky_red_packet'
    | 'lucky_money_come'
    | 'lion_dance_pet'
    | 'dumpling_making_pet'
    | 'fish_making_pet'
    | 'pet_red_packet'
    | 'lantern_glow'
    | 'expression_challenge'
    | 'overdrive'
    | 'heart_gesture_dance'
    | 'poping'
    | 'martial_arts'
    | 'running'
    | 'nezha'
    | 'motorcycle_dance'
    | 'subject_3_dance'
    | 'ghost_step_dance'
    | 'phantom_jewel'
    | 'zoom_out'
    | 'cheers_2026'
    | 'kiss_pro'
    | 'fight_pro'
    | 'hug_pro'
    | 'heart_gesture_pro'
    | 'dollar_rain_pro'
    | 'pet_bee_pro'
    | 'santa_random_surprise'
    | 'magic_match_tree'
    | 'happy_birthday'
    | 'thumbs_up_pro'
    | 'surprise_bouquet'
    | 'bouquet_drop'
    | '3d_cartoon_1_pro'
    | 'glamour_photo_shoot'
    | 'box_of_joy'
    | 'first_toast_of_the_year'
    | 'my_santa_pic'
    | 'santa_gift'
    | 'steampunk_christmas'
    | 'snowglobe'
    | 'christmas_photo_shoot'
    | 'ornament_crash'
    | 'santa_express'
    | 'particle_santa_surround'
    | 'coronation_of_frost'
    | 'spark_in_the_snow'
    | 'scarlet_and_snow'
    | 'cozy_toon_wrap'
    | 'bullet_time_lite'
    | 'magic_cloak'
    | 'balloon_parade'
    | 'jumping_ginger_joy'
    | 'c4d_cartoon_pro'
    | 'venomous_spider'
    | 'throne_of_king'
    | 'luminous_elf'
    | 'woodland_elf'
    | 'japanese_anime_1'
    | 'american_comics'
    | 'snowboarding'
    | 'witch_transform'
    | 'vampire_transform'
    | 'pumpkin_head_transform'
    | 'demon_transform'
    | 'mummy_transform'
    | 'zombie_transform'
    | 'cute_pumpkin_transform'
    | 'cute_ghost_transform'
    | 'knock_knock_halloween'
    | 'halloween_escape'
    | 'baseball'
    | 'trampoline'
    | 'trampoline_night'
    | 'pucker_up'
    | 'feed_mooncake'
    | 'flyer'
    | 'dishwasher'
    | 'pet_chinese_opera'
    | 'magic_fireball'
    | 'gallery_ring'
    | 'pet_moto_rider'
    | 'muscle_pet'
    | 'pet_delivery'
    | 'mythic_style'
    | 'steampunk'
    | '3d_cartoon_2'
    | 'pet_chef'
    | 'santa_gifts'
    | 'santa_hug'
    | 'girlfriend'
    | 'boyfriend'
    | 'heart_gesture_1'
    | 'pet_wizard'
    | 'smoke_smoke'
    | 'gun_shot'
    | 'double_gun'
    | 'pet_warrior'
    | 'long_hair'
    | 'pet_dance'
    | 'wool_curly'
    | 'pet_bee'
    | 'marry_me'
    | 'piggy_morph'
    | 'ski_ski'
    | 'magic_broom'
    | 'splashsplash'
    | 'surfsurf'
    | 'fairy_wing'
    | 'angel_wing'
    | 'dark_wing'
    | 'emoji'
}

/**
 * VideoEffectsOutput
 */
export type SchemaKlingVideoV16ProEffectsOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * VideoEffectsRequest
 */
export type SchemaKlingVideoV16ProEffectsInput = {
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Input Image Urls
   *
   * URL of images to be used for hug, kiss or heart_gesture video.
   */
  input_image_urls?: Array<string>
  /**
   * Effect Scene
   *
   * The effect scene to use for the video generation
   */
  effect_scene:
    | 'hug'
    | 'kiss'
    | 'heart_gesture'
    | 'squish'
    | 'expansion'
    | 'fuzzyfuzzy'
    | 'bloombloom'
    | 'dizzydizzy'
    | 'jelly_press'
    | 'jelly_slice'
    | 'jelly_squish'
    | 'jelly_jiggle'
    | 'pixelpixel'
    | 'yearbook'
    | 'instant_film'
    | 'anime_figure'
    | 'rocketrocket'
    | 'fly_fly'
    | 'disappear'
    | 'lightning_power'
    | 'bullet_time'
    | 'bullet_time_360'
    | 'media_interview'
    | 'day_to_night'
    | "let's_ride"
    | 'jumpdrop'
    | 'swish_swish'
    | 'running_man'
    | 'jazz_jazz'
    | 'swing_swing'
    | 'skateskate'
    | 'building_sweater'
    | 'pure_white_wings'
    | 'black_wings'
    | 'golden_wing'
    | 'pink_pink_wings'
    | 'rampage_ape'
    | 'a_list_look'
    | 'countdown_teleport'
    | 'firework_2026'
    | 'instant_christmas'
    | 'birthday_star'
    | 'firework'
    | 'celebration'
    | 'tiger_hug_pro'
    | 'pet_lion_pro'
    | 'guardian_spirit'
    | 'squeeze_scream'
    | 'inner_voice'
    | 'memory_alive'
    | 'guess_what'
    | 'eagle_snatch'
    | 'hug_from_past'
    | 'instant_kid'
    | 'dollar_rain'
    | 'cry_cry'
    | 'building_collapse'
    | 'mushroom'
    | 'jesus_hug'
    | 'shark_alert'
    | 'lie_flat'
    | 'polar_bear_hug'
    | 'brown_bear_hug'
    | 'office_escape_plow'
    | 'watermelon_bomb'
    | 'boss_coming'
    | 'wig_out'
    | 'car_explosion'
    | 'tiger_hug'
    | 'siblings'
    | 'construction_worker'
    | 'snatched'
    | 'felt_felt'
    | 'plushcut'
    | 'drunk_dance'
    | 'drunk_dance_pet'
    | 'daoma_dance'
    | 'bouncy_dance'
    | 'smooth_sailing_dance'
    | 'new_year_greeting'
    | 'lion_dance'
    | 'prosperity'
    | 'great_success'
    | 'golden_horse_fortune'
    | 'red_packet_box'
    | 'lucky_horse_year'
    | 'lucky_red_packet'
    | 'lucky_money_come'
    | 'lion_dance_pet'
    | 'dumpling_making_pet'
    | 'fish_making_pet'
    | 'pet_red_packet'
    | 'lantern_glow'
    | 'expression_challenge'
    | 'overdrive'
    | 'heart_gesture_dance'
    | 'poping'
    | 'martial_arts'
    | 'running'
    | 'nezha'
    | 'motorcycle_dance'
    | 'subject_3_dance'
    | 'ghost_step_dance'
    | 'phantom_jewel'
    | 'zoom_out'
    | 'cheers_2026'
    | 'kiss_pro'
    | 'fight_pro'
    | 'hug_pro'
    | 'heart_gesture_pro'
    | 'dollar_rain_pro'
    | 'pet_bee_pro'
    | 'santa_random_surprise'
    | 'magic_match_tree'
    | 'happy_birthday'
    | 'thumbs_up_pro'
    | 'surprise_bouquet'
    | 'bouquet_drop'
    | '3d_cartoon_1_pro'
    | 'glamour_photo_shoot'
    | 'box_of_joy'
    | 'first_toast_of_the_year'
    | 'my_santa_pic'
    | 'santa_gift'
    | 'steampunk_christmas'
    | 'snowglobe'
    | 'christmas_photo_shoot'
    | 'ornament_crash'
    | 'santa_express'
    | 'particle_santa_surround'
    | 'coronation_of_frost'
    | 'spark_in_the_snow'
    | 'scarlet_and_snow'
    | 'cozy_toon_wrap'
    | 'bullet_time_lite'
    | 'magic_cloak'
    | 'balloon_parade'
    | 'jumping_ginger_joy'
    | 'c4d_cartoon_pro'
    | 'venomous_spider'
    | 'throne_of_king'
    | 'luminous_elf'
    | 'woodland_elf'
    | 'japanese_anime_1'
    | 'american_comics'
    | 'snowboarding'
    | 'witch_transform'
    | 'vampire_transform'
    | 'pumpkin_head_transform'
    | 'demon_transform'
    | 'mummy_transform'
    | 'zombie_transform'
    | 'cute_pumpkin_transform'
    | 'cute_ghost_transform'
    | 'knock_knock_halloween'
    | 'halloween_escape'
    | 'baseball'
    | 'trampoline'
    | 'trampoline_night'
    | 'pucker_up'
    | 'feed_mooncake'
    | 'flyer'
    | 'dishwasher'
    | 'pet_chinese_opera'
    | 'magic_fireball'
    | 'gallery_ring'
    | 'pet_moto_rider'
    | 'muscle_pet'
    | 'pet_delivery'
    | 'mythic_style'
    | 'steampunk'
    | '3d_cartoon_2'
    | 'pet_chef'
    | 'santa_gifts'
    | 'santa_hug'
    | 'girlfriend'
    | 'boyfriend'
    | 'heart_gesture_1'
    | 'pet_wizard'
    | 'smoke_smoke'
    | 'gun_shot'
    | 'double_gun'
    | 'pet_warrior'
    | 'long_hair'
    | 'pet_dance'
    | 'wool_curly'
    | 'pet_bee'
    | 'marry_me'
    | 'piggy_morph'
    | 'ski_ski'
    | 'magic_broom'
    | 'splashsplash'
    | 'surfsurf'
    | 'fairy_wing'
    | 'angel_wing'
    | 'dark_wing'
    | 'emoji'
}

/**
 * VideoEffectsOutput
 */
export type SchemaKlingVideoV15ProEffectsOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * VideoEffectsRequest
 */
export type SchemaKlingVideoV15ProEffectsInput = {
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Input Image Urls
   *
   * URL of images to be used for hug, kiss or heart_gesture video.
   */
  input_image_urls?: Array<string>
  /**
   * Effect Scene
   *
   * The effect scene to use for the video generation
   */
  effect_scene:
    | 'hug'
    | 'kiss'
    | 'heart_gesture'
    | 'squish'
    | 'expansion'
    | 'fuzzyfuzzy'
    | 'bloombloom'
    | 'dizzydizzy'
    | 'jelly_press'
    | 'jelly_slice'
    | 'jelly_squish'
    | 'jelly_jiggle'
    | 'pixelpixel'
    | 'yearbook'
    | 'instant_film'
    | 'anime_figure'
    | 'rocketrocket'
    | 'fly_fly'
    | 'disappear'
    | 'lightning_power'
    | 'bullet_time'
    | 'bullet_time_360'
    | 'media_interview'
    | 'day_to_night'
    | "let's_ride"
    | 'jumpdrop'
    | 'swish_swish'
    | 'running_man'
    | 'jazz_jazz'
    | 'swing_swing'
    | 'skateskate'
    | 'building_sweater'
    | 'pure_white_wings'
    | 'black_wings'
    | 'golden_wing'
    | 'pink_pink_wings'
    | 'rampage_ape'
    | 'a_list_look'
    | 'countdown_teleport'
    | 'firework_2026'
    | 'instant_christmas'
    | 'birthday_star'
    | 'firework'
    | 'celebration'
    | 'tiger_hug_pro'
    | 'pet_lion_pro'
    | 'guardian_spirit'
    | 'squeeze_scream'
    | 'inner_voice'
    | 'memory_alive'
    | 'guess_what'
    | 'eagle_snatch'
    | 'hug_from_past'
    | 'instant_kid'
    | 'dollar_rain'
    | 'cry_cry'
    | 'building_collapse'
    | 'mushroom'
    | 'jesus_hug'
    | 'shark_alert'
    | 'lie_flat'
    | 'polar_bear_hug'
    | 'brown_bear_hug'
    | 'office_escape_plow'
    | 'watermelon_bomb'
    | 'boss_coming'
    | 'wig_out'
    | 'car_explosion'
    | 'tiger_hug'
    | 'siblings'
    | 'construction_worker'
    | 'snatched'
    | 'felt_felt'
    | 'plushcut'
    | 'drunk_dance'
    | 'drunk_dance_pet'
    | 'daoma_dance'
    | 'bouncy_dance'
    | 'smooth_sailing_dance'
    | 'new_year_greeting'
    | 'lion_dance'
    | 'prosperity'
    | 'great_success'
    | 'golden_horse_fortune'
    | 'red_packet_box'
    | 'lucky_horse_year'
    | 'lucky_red_packet'
    | 'lucky_money_come'
    | 'lion_dance_pet'
    | 'dumpling_making_pet'
    | 'fish_making_pet'
    | 'pet_red_packet'
    | 'lantern_glow'
    | 'expression_challenge'
    | 'overdrive'
    | 'heart_gesture_dance'
    | 'poping'
    | 'martial_arts'
    | 'running'
    | 'nezha'
    | 'motorcycle_dance'
    | 'subject_3_dance'
    | 'ghost_step_dance'
    | 'phantom_jewel'
    | 'zoom_out'
    | 'cheers_2026'
    | 'kiss_pro'
    | 'fight_pro'
    | 'hug_pro'
    | 'heart_gesture_pro'
    | 'dollar_rain_pro'
    | 'pet_bee_pro'
    | 'santa_random_surprise'
    | 'magic_match_tree'
    | 'happy_birthday'
    | 'thumbs_up_pro'
    | 'surprise_bouquet'
    | 'bouquet_drop'
    | '3d_cartoon_1_pro'
    | 'glamour_photo_shoot'
    | 'box_of_joy'
    | 'first_toast_of_the_year'
    | 'my_santa_pic'
    | 'santa_gift'
    | 'steampunk_christmas'
    | 'snowglobe'
    | 'christmas_photo_shoot'
    | 'ornament_crash'
    | 'santa_express'
    | 'particle_santa_surround'
    | 'coronation_of_frost'
    | 'spark_in_the_snow'
    | 'scarlet_and_snow'
    | 'cozy_toon_wrap'
    | 'bullet_time_lite'
    | 'magic_cloak'
    | 'balloon_parade'
    | 'jumping_ginger_joy'
    | 'c4d_cartoon_pro'
    | 'venomous_spider'
    | 'throne_of_king'
    | 'luminous_elf'
    | 'woodland_elf'
    | 'japanese_anime_1'
    | 'american_comics'
    | 'snowboarding'
    | 'witch_transform'
    | 'vampire_transform'
    | 'pumpkin_head_transform'
    | 'demon_transform'
    | 'mummy_transform'
    | 'zombie_transform'
    | 'cute_pumpkin_transform'
    | 'cute_ghost_transform'
    | 'knock_knock_halloween'
    | 'halloween_escape'
    | 'baseball'
    | 'trampoline'
    | 'trampoline_night'
    | 'pucker_up'
    | 'feed_mooncake'
    | 'flyer'
    | 'dishwasher'
    | 'pet_chinese_opera'
    | 'magic_fireball'
    | 'gallery_ring'
    | 'pet_moto_rider'
    | 'muscle_pet'
    | 'pet_delivery'
    | 'mythic_style'
    | 'steampunk'
    | '3d_cartoon_2'
    | 'pet_chef'
    | 'santa_gifts'
    | 'santa_hug'
    | 'girlfriend'
    | 'boyfriend'
    | 'heart_gesture_1'
    | 'pet_wizard'
    | 'smoke_smoke'
    | 'gun_shot'
    | 'double_gun'
    | 'pet_warrior'
    | 'long_hair'
    | 'pet_dance'
    | 'wool_curly'
    | 'pet_bee'
    | 'marry_me'
    | 'piggy_morph'
    | 'ski_ski'
    | 'magic_broom'
    | 'splashsplash'
    | 'surfsurf'
    | 'fairy_wing'
    | 'angel_wing'
    | 'dark_wing'
    | 'emoji'
}

/**
 * WanProT2VResponse
 */
export type SchemaWanProTextToVideoOutput = {
  video: SchemaFile
}

/**
 * WanProT2VRequest
 */
export type SchemaWanProTextToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video
   */
  prompt: string
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number | unknown
}

/**
 * Pika22TextToVideoOutput
 *
 * Output model for Pika 2.2 text-to-video generation
 */
export type SchemaPikaV22TextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * Pika22TextToVideoRequest
 *
 * Request model for Pika 2.2 text-to-video generation
 */
export type SchemaPikaV22TextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '1080p' | '720p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1' | '4:5' | '5:4' | '3:2' | '2:3'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: 5 | 10
  /**
   * Seed
   *
   * The seed for the random number generator
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the model
   */
  negative_prompt?: string
}

/**
 * TextToVideoV21Output
 *
 * Output from text-to-video generation
 */
export type SchemaPikaV21TextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * TextToVideov21Input
 *
 * Base request for text-to-video generation
 */
export type SchemaPikaV21TextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1' | '4:5' | '5:4' | '3:2' | '2:3'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: number
  /**
   * Seed
   *
   * The seed for the random number generator
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the model
   */
  negative_prompt?: string
}

/**
 * TurboTextToVideoOutput
 *
 * Output from text-to-video generation
 */
export type SchemaPikaV2TurboTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * TextToVideoTurboInput
 *
 * Base request for text-to-video generation
 */
export type SchemaPikaV2TurboTextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1' | '4:5' | '5:4' | '3:2' | '2:3'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: number
  /**
   * Seed
   *
   * The seed for the random number generator
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the model
   */
  negative_prompt?: string
}

/**
 * Ray2T2VOutput
 */
export type SchemaLumaDreamMachineRay2FlashOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * Ray2TextToVideoRequest
 */
export type SchemaLumaDreamMachineRay2FlashInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '9:16' | '4:3' | '3:4' | '21:9' | '9:21'
  /**
   * Resolution
   *
   * The resolution of the generated video (720p costs 2x more, 1080p costs 4x more)
   */
  resolution?: '540p' | '720p' | '1080p'
  /**
   * Loop
   *
   * Whether the video should loop (end of video is blended with the beginning)
   */
  loop?: boolean
  /**
   * Duration
   *
   * The duration of the generated video (9s costs 2x more)
   */
  duration?: '5s' | '9s'
}

/**
 * WanT2VResponse
 */
export type SchemaWanT2vLoraOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * WanLoRARequest
 */
export type SchemaWanT2vLoraInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p,580p, or 720p).
   */
  resolution?: '480p' | '580p' | '720p'
  /**
   * Reverse Video
   *
   * If true, the video will be reversed.
   */
  reverse_video?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video (16:9 or 9:16).
   */
  aspect_ratio?: '9:16' | '16:9'
  /**
   * Loras
   *
   * LoRA weights to be used in the inference.
   */
  loras?: Array<SchemaLoraWeight>
  /**
   * Frames Per Second
   *
   * Frames per second of the generated video. Must be between 5 to 24.
   */
  frames_per_second?: number
  /**
   * Turbo Mode
   *
   * If true, the video will be generated faster with no noticeable degradation in the visual quality.
   */
  turbo_mode?: boolean
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Num Frames
   *
   * Number of frames to generate. Must be between 81 to 100 (inclusive).
   */
  num_frames?: number
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
}

/**
 * LipsyncOutput
 */
export type SchemaKlingVideoLipsyncTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * LipsyncT2VRequest
 */
export type SchemaKlingVideoLipsyncTextToVideoInput = {
  /**
   * Text
   *
   * Text content for lip-sync video generation. Max 120 characters.
   */
  text: string
  /**
   * Video Url
   *
   * The URL of the video to generate the lip sync for. Supports .mp4/.mov, 100MB, 2-60s, 720p/1080p only, width/height 7201920px. If validation fails, an error is returned.
   */
  video_url: string
  /**
   * Voice Id
   *
   * Voice ID to use for speech synthesis
   */
  voice_id:
    | 'genshin_vindi2'
    | 'zhinen_xuesheng'
    | 'AOT'
    | 'ai_shatang'
    | 'genshin_klee2'
    | 'genshin_kirara'
    | 'ai_kaiya'
    | 'oversea_male1'
    | 'ai_chenjiahao_712'
    | 'girlfriend_4_speech02'
    | 'chat1_female_new-3'
    | 'chat_0407_5-1'
    | 'cartoon-boy-07'
    | 'uk_boy1'
    | 'cartoon-girl-01'
    | 'PeppaPig_platform'
    | 'ai_huangzhong_712'
    | 'ai_huangyaoshi_712'
    | 'ai_laoguowang_712'
    | 'chengshu_jiejie'
    | 'you_pingjing'
    | 'calm_story1'
    | 'uk_man2'
    | 'laopopo_speech02'
    | 'heainainai_speech02'
    | 'reader_en_m-v1'
    | 'commercial_lady_en_f-v1'
    | 'tiyuxi_xuedi'
    | 'tiexin_nanyou'
    | 'girlfriend_1_speech02'
    | 'girlfriend_2_speech02'
    | 'zhuxi_speech02'
    | 'uk_oldman3'
    | 'dongbeilaotie_speech02'
    | 'chongqingxiaohuo_speech02'
    | 'chuanmeizi_speech02'
    | 'chaoshandashu_speech02'
    | 'ai_taiwan_man2_speech02'
    | 'xianzhanggui_speech02'
    | 'tianjinjiejie_speech02'
    | 'diyinnansang_DB_CN_M_04-v2'
    | 'yizhipiannan-v1'
    | 'guanxiaofang-v2'
    | 'tianmeixuemei-v1'
    | 'daopianyansang-v1'
    | 'mengwa-v1'
  /**
   * Voice Language
   *
   * The voice language corresponding to the Voice ID
   */
  voice_language?: 'zh' | 'en'
  /**
   * Voice Speed
   *
   * Speech rate for Text to Video generation
   */
  voice_speed?: number
}

/**
 * LipsyncA2VOutput
 */
export type SchemaKlingVideoLipsyncAudioToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * LipsyncA2VRequest
 */
export type SchemaKlingVideoLipsyncAudioToVideoInput = {
  /**
   * Video Url
   *
   * The URL of the video to generate the lip sync for. Supports .mp4/.mov, 100MB, 210s, 720p/1080p only, width/height 7201920px.
   */
  video_url: string
  /**
   * Audio Url
   *
   * The URL of the audio to generate the lip sync for. Minimum duration is 2s and maximum duration is 60s. Maximum file size is 5MB.
   */
  audio_url: string
}

/**
 * VideoOutputV4
 */
export type SchemaPixverseV4TextToVideoFastOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * FastTextToVideoRequest
 */
export type SchemaPixverseV4TextToVideoFastInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * VideoOutputV4
 */
export type SchemaPixverseV4TextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * TextToVideoRequest
 */
export type SchemaPixverseV4TextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Duration
   *
   * The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds
   */
  duration?: '5' | '8'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * MagiResponse
 */
export type SchemaMagiDistilledOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * MagiTextToVideoRequest
 */
export type SchemaMagiDistilledInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16' | '1:1'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: 4 | 8 | 16 | 32
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Num Frames
   *
   * Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.
   */
  num_frames?: number
}

/**
 * MagiResponse
 */
export type SchemaMagiOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * MagiTextToVideoRequest
 */
export type SchemaMagiInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16' | '1:1'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: 4 | 8 | 16 | 32 | 64
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Num Frames
   *
   * Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.
   */
  num_frames?: number
}

/**
 * Q1TextToVideoOutput
 */
export type SchemaViduQ1TextToVideoOutput = {
  /**
   * Video
   *
   * The generated video using the Q1 model
   */
  video: SchemaFile
}

/**
 * Q1TextToVideoRequest
 */
export type SchemaViduQ1TextToVideoInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 1500 characters
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the output video
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Style
   *
   * The style of output video
   */
  style?: 'general' | 'anime'
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number
  /**
   * Movement Amplitude
   *
   * The movement amplitude of objects in the frame
   */
  movement_amplitude?: 'auto' | 'small' | 'medium' | 'large'
}

/**
 * VideoOutputV4
 */
export type SchemaPixverseV45TextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * TextToVideoRequest
 */
export type SchemaPixverseV45TextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Duration
   *
   * The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds
   */
  duration?: '5' | '8'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * VideoOutputV4
 */
export type SchemaPixverseV45TextToVideoFastOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * FastTextToVideoRequest
 */
export type SchemaPixverseV45TextToVideoFastInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * TextToVideoOutput
 */
export type SchemaLtxVideo13bDistilledOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * DistilledTextToVideoInput
 *
 * Distilled model input
 */
export type SchemaLtxVideo13bDistilledInput = {
  /**
   * Second Pass Skip Initial Steps
   *
   * The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.
   */
  second_pass_skip_initial_steps?: number
  /**
   * First Pass Num Inference Steps
   *
   * Number of inference steps during the first pass.
   */
  first_pass_num_inference_steps?: number
  /**
   * Frame Rate
   *
   * The frame rate of the video.
   */
  frame_rate?: number
  /**
   * Reverse Video
   *
   * Whether to reverse the video.
   */
  reverse_video?: boolean
  /**
   * Prompt
   *
   * Text prompt to guide generation
   */
  prompt: string
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt using a language model.
   */
  expand_prompt?: boolean
  /**
   * Loras
   *
   * LoRA weights to use for generation
   */
  loras?: Array<SchemaLoRaWeight>
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Num Frames
   *
   * The number of frames in the video.
   */
  num_frames?: number
  /**
   * Second Pass Num Inference Steps
   *
   * Number of inference steps during the second pass.
   */
  second_pass_num_inference_steps?: number
  /**
   * Negative Prompt
   *
   * Negative prompt for generation
   */
  negative_prompt?: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p or 720p).
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video (16:9, 1:1 or 9:16).
   */
  aspect_ratio?: '9:16' | '1:1' | '16:9'
  /**
   * First Pass Skip Final Steps
   *
   * Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.
   */
  first_pass_skip_final_steps?: number
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number
}

/**
 * LoRAWeight
 */
export type SchemaLoRaWeight = {
  /**
   * Path
   *
   * URL or path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   * Scale of the LoRA weight. This is a multiplier applied to the LoRA weight when loading it.
   */
  scale?: number
  /**
   * Weight Name
   *
   * Name of the LoRA weight. Only used if `path` is a HuggingFace repository, and is only required when the repository contains multiple LoRA weights.
   */
  weight_name?: string
}

/**
 * TextToVideoOutput
 */
export type SchemaLtxVideo13bDevOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * TextToVideoInput
 */
export type SchemaLtxVideo13bDevInput = {
  /**
   * Second Pass Skip Initial Steps
   *
   * The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.
   */
  second_pass_skip_initial_steps?: number
  /**
   * First Pass Num Inference Steps
   *
   * Number of inference steps during the first pass.
   */
  first_pass_num_inference_steps?: number
  /**
   * Frame Rate
   *
   * The frame rate of the video.
   */
  frame_rate?: number
  /**
   * Prompt
   *
   * Text prompt to guide generation
   */
  prompt: string
  /**
   * Reverse Video
   *
   * Whether to reverse the video.
   */
  reverse_video?: boolean
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt using a language model.
   */
  expand_prompt?: boolean
  /**
   * Loras
   *
   * LoRA weights to use for generation
   */
  loras?: Array<SchemaLoRaWeight>
  /**
   * Second Pass Num Inference Steps
   *
   * Number of inference steps during the second pass.
   */
  second_pass_num_inference_steps?: number
  /**
   * Num Frames
   *
   * The number of frames in the video.
   */
  num_frames?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * Negative prompt for generation
   */
  negative_prompt?: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p or 720p).
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video (16:9, 1:1 or 9:16).
   */
  aspect_ratio?: '9:16' | '1:1' | '16:9'
  /**
   * First Pass Skip Final Steps
   *
   * Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.
   */
  first_pass_skip_final_steps?: number
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number
}

/**
 * TextToVideoV21MasterOutput
 */
export type SchemaKlingVideoV21MasterTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * TextToVideoV21MasterRequest
 */
export type SchemaKlingVideoV21MasterTextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video frame
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * SeedanceVideoOutput
 */
export type SchemaBytedanceSeedanceV1LiteTextToVideoOutput = {
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * Generated video file
   */
  video: SchemaFile
}

/**
 * SeedanceTextToVideoInput
 */
export type SchemaBytedanceSeedanceV1LiteTextToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt used to generate the video
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution - 480p for faster generation, 720p for higher quality
   */
  resolution?: '480p' | '720p' | '1080p'
  /**
   * Duration
   *
   * Duration of the video in seconds
   */
  duration?: '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9' | '10' | '11' | '12'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '21:9' | '16:9' | '4:3' | '1:1' | '3:4' | '9:16' | '9:21'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * Random seed to control video generation. Use -1 for random.
   */
  seed?: number
  /**
   * Camera Fixed
   *
   * Whether to fix the camera position
   */
  camera_fixed?: boolean
}

/**
 * SeedanceProT2VVideoOutput
 */
export type SchemaBytedanceSeedanceV1ProTextToVideoOutput = {
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * Generated video file
   */
  video: SchemaFile
}

/**
 * SeedanceProTextToVideoInput
 */
export type SchemaBytedanceSeedanceV1ProTextToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt used to generate the video
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality
   */
  resolution?: '480p' | '720p' | '1080p'
  /**
   * Duration
   *
   * Duration of the video in seconds
   */
  duration?: '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9' | '10' | '11' | '12'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '21:9' | '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * Random seed to control video generation. Use -1 for random.
   */
  seed?: number
  /**
   * Camera Fixed
   *
   * Whether to fix the camera position
   */
  camera_fixed?: boolean
}

/**
 * TextToVideoHailuo02Output
 */
export type SchemaMinimaxHailuo02ProTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * ProTextToVideoHailuo02Input
 */
export type SchemaMinimaxHailuo02ProTextToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Prompt
   */
  prompt: string
}

/**
 * TextToVideoOutput
 */
export type SchemaLtxv13B098DistilledOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * DistilledTextToVideoInput
 *
 * Distilled model input
 */
export type SchemaLtxv13B098DistilledInput = {
  /**
   * Second Pass Skip Initial Steps
   *
   * The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.
   */
  second_pass_skip_initial_steps?: number
  /**
   * Number of Inference Steps
   *
   * Number of inference steps during the first pass.
   */
  first_pass_num_inference_steps?: number
  /**
   * Frame Rate
   *
   * The frame rate of the video.
   */
  frame_rate?: number
  /**
   * Reverse Video
   *
   * Whether to reverse the video.
   */
  reverse_video?: boolean
  /**
   * Prompt
   *
   * Text prompt to guide generation
   */
  prompt: string
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt using a language model.
   */
  expand_prompt?: boolean
  /**
   * Temporal AdaIN Factor
   *
   * The factor for adaptive instance normalization (AdaIN) applied to generated video chunks after the first. This can help deal with a gradual increase in saturation/contrast in the generated video by normalizing the color distribution across the video. A high value will ensure the color distribution is more consistent across the video, while a low value will allow for more variation in color distribution.
   */
  temporal_adain_factor?: number
  /**
   * Loras
   *
   * LoRA weights to use for generation
   */
  loras?: Array<SchemaLoRaWeight>
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Frames
   *
   * The number of frames in the video.
   */
  num_frames?: number
  /**
   * Second Pass Number of Inference Steps
   *
   * Number of inference steps during the second pass.
   */
  second_pass_num_inference_steps?: number
  /**
   * Negative Prompt
   *
   * Negative prompt for generation
   */
  negative_prompt?: string
  /**
   * Enable Detail Pass
   *
   * Whether to use a detail pass. If True, the model will perform a second pass to refine the video and enhance details. This incurs a 2.0x cost multiplier on the base price.
   */
  enable_detail_pass?: boolean
  /**
   * Resolution
   *
   * Resolution of the generated video.
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video.
   */
  aspect_ratio?: '9:16' | '1:1' | '16:9'
  /**
   * Tone Map Compression Ratio
   *
   * The compression ratio for tone mapping. This is used to compress the dynamic range of the video to improve visual quality. A value of 0.0 means no compression, while a value of 1.0 means maximum compression.
   */
  tone_map_compression_ratio?: number
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number
}

/**
 * WanT2VResponse
 */
export type SchemaWanV22A14bTextToVideoOutput = {
  /**
   * Prompt
   *
   * The text prompt used for video generation.
   */
  prompt?: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * WanT2VRequest
 */
export type SchemaWanV22A14bTextToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Shift
   *
   * Shift value for the video. Must be between 1.0 and 10.0.
   */
  shift?: number
  /**
   * Acceleration
   *
   * Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Number of Interpolated Frames
   *
   * Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.
   */
  num_interpolated_frames?: number
  /**
   * Frames per Second
   *
   * Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.
   */
  frames_per_second?: number
  /**
   * Guidance Scale (1st Stage)
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guidance_scale?: number
  /**
   * Number of Frames
   *
   * Number of frames to generate. Must be between 17 to 161 (inclusive).
   */
  num_frames?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, input data will be checked for safety before processing.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Video Write Mode
   *
   * The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Resolution
   *
   * Resolution of the generated video (480p, 580p, or 720p).
   */
  resolution?: '480p' | '580p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video (16:9 or 9:16).
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Enable Output Safety Checker
   *
   * If set to true, output video will be checked for safety after generation.
   */
  enable_output_safety_checker?: boolean
  /**
   * Guidance Scale (2nd Stage)
   *
   * Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.
   */
  guidance_scale_2?: number
  /**
   * Video Quality
   *
   * The quality of the output video. Higher quality means better visual quality but larger file size.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean
  /**
   * Number of Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Interpolator Model
   *
   * The model to use for frame interpolation. If None, no interpolation is applied.
   */
  interpolator_model?: 'none' | 'film' | 'rife'
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Adjust FPS for Interpolation
   *
   * If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.
   */
  adjust_fps_for_interpolation?: boolean
}

/**
 * WanSmallT2VResponse
 */
export type SchemaWanV225bTextToVideoOutput = {
  /**
   * Prompt
   *
   * The text prompt used for video generation.
   */
  prompt?: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * WanSmallT2VRequest
 */
export type SchemaWanV225bTextToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Shift
   *
   * Shift value for the video. Must be between 1.0 and 10.0.
   */
  shift?: number
  /**
   * Number of Interpolated Frames
   *
   * Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.
   */
  num_interpolated_frames?: number
  /**
   * Frames per Second
   *
   * Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.
   */
  frames_per_second?: number
  /**
   * Guidance Scale
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guidance_scale?: number
  /**
   * Number of Frames
   *
   * Number of frames to generate. Must be between 17 to 161 (inclusive).
   */
  num_frames?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, input data will be checked for safety before processing.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Video Write Mode
   *
   * The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Resolution
   *
   * Resolution of the generated video (580p or 720p).
   */
  resolution?: '580p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video (16:9 or 9:16).
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Enable Output Safety Checker
   *
   * If set to true, output video will be checked for safety after generation.
   */
  enable_output_safety_checker?: boolean
  /**
   * Video Quality
   *
   * The quality of the output video. Higher quality means better visual quality but larger file size.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean
  /**
   * Number of Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Interpolator Model
   *
   * The model to use for frame interpolation. If None, no interpolation is applied.
   */
  interpolator_model?: 'none' | 'film' | 'rife'
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Adjust FPS for Interpolation
   *
   * If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.
   */
  adjust_fps_for_interpolation?: boolean
}

/**
 * WanTurboT2VResponse
 */
export type SchemaWanV22A14bTextToVideoTurboOutput = {
  /**
   * Prompt
   *
   * The text prompt used for video generation.
   */
  prompt?: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * WanTurboT2VRequest
 */
export type SchemaWanV22A14bTextToVideoTurboInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p, 580p, or 720p).
   */
  resolution?: '480p' | '580p' | '720p'
  /**
   * Acceleration
   *
   * Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video (16:9 or 9:16).
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Video Write Mode
   *
   * The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Enable Output Safety Checker
   *
   * If set to true, output video will be checked for safety after generation.
   */
  enable_output_safety_checker?: boolean
  /**
   * Video Quality
   *
   * The quality of the output video. Higher quality means better visual quality but larger file size.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Safety Checker
   *
   * If set to true, input data will be checked for safety before processing.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean
}

/**
 * WanSmallFastVideoT2VResponse
 */
export type SchemaWanV225bTextToVideoFastWanOutput = {
  /**
   * Prompt
   *
   * The text prompt used for video generation.
   */
  prompt?: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * WanSmallFastVideoT2VRequest
 */
export type SchemaWanV225bTextToVideoFastWanInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Number of Interpolated Frames
   *
   * Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.
   */
  num_interpolated_frames?: number
  /**
   * Frames per Second
   *
   * Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.
   */
  frames_per_second?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, input data will be checked for safety before processing.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Frames
   *
   * Number of frames to generate. Must be between 17 to 161 (inclusive).
   */
  num_frames?: number
  /**
   * Guidance Scale
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guidance_scale?: number
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Video Write Mode
   *
   * The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Resolution
   *
   * Resolution of the generated video (580p or 720p).
   */
  resolution?: '480p' | '580p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video (16:9 or 9:16).
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Enable Output Safety Checker
   *
   * If set to true, output video will be checked for safety after generation.
   */
  enable_output_safety_checker?: boolean
  /**
   * Video Quality
   *
   * The quality of the output video. Higher quality means better visual quality but larger file size.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Interpolator Model
   *
   * The model to use for frame interpolation. If None, no interpolation is applied.
   */
  interpolator_model?: 'none' | 'film' | 'rife'
  /**
   * Adjust FPS for Interpolation
   *
   * If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.
   */
  adjust_fps_for_interpolation?: boolean
}

/**
 * WanSmallT2VResponse
 */
export type SchemaWanV225bTextToVideoDistillOutput = {
  /**
   * Prompt
   *
   * The text prompt used for video generation.
   */
  prompt?: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * WanDistillT2VRequest
 */
export type SchemaWanV225bTextToVideoDistillInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Shift
   *
   * Shift value for the video. Must be between 1.0 and 10.0.
   */
  shift?: number
  /**
   * Number of Interpolated Frames
   *
   * Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.
   */
  num_interpolated_frames?: number
  /**
   * Frames per Second
   *
   * Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.
   */
  frames_per_second?: number
  /**
   * Guidance Scale (1st Stage)
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guidance_scale?: number
  /**
   * Number of Frames
   *
   * Number of frames to generate. Must be between 17 to 161 (inclusive).
   */
  num_frames?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, input data will be checked for safety before processing.
   */
  enable_safety_checker?: boolean
  /**
   * Video Write Mode
   *
   * The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Resolution
   *
   * Resolution of the generated video (580p or 720p).
   */
  resolution?: '580p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video (16:9 or 9:16).
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Enable Output Safety Checker
   *
   * If set to true, output video will be checked for safety after generation.
   */
  enable_output_safety_checker?: boolean
  /**
   * Video Quality
   *
   * The quality of the output video. Higher quality means better visual quality but larger file size.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean
  /**
   * Number of Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Interpolator Model
   *
   * The model to use for frame interpolation. If None, no interpolation is applied.
   */
  interpolator_model?: 'none' | 'film' | 'rife'
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Adjust FPS for Interpolation
   *
   * If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.
   */
  adjust_fps_for_interpolation?: boolean
}

/**
 * WanT2VResponse
 */
export type SchemaWanV22A14bTextToVideoLoraOutput = {
  /**
   * Prompt
   *
   * The text prompt used for video generation.
   */
  prompt?: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * WanLoRAT2VRequest
 */
export type SchemaWanV22A14bTextToVideoLoraInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Shift
   *
   * Shift value for the video. Must be between 1.0 and 10.0.
   */
  shift?: number
  /**
   * Acceleration
   *
   * Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Number of Interpolated Frames
   *
   * Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.
   */
  num_interpolated_frames?: number
  /**
   * Reverse Video
   *
   * If true, the video will be reversed.
   */
  reverse_video?: boolean
  /**
   * Loras
   *
   * LoRA weights to be used in the inference.
   */
  loras?: Array<SchemaLoRaWeight>
  /**
   * Frames per Second
   *
   * Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.
   */
  frames_per_second?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, input data will be checked for safety before processing.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Frames
   *
   * Number of frames to generate. Must be between 17 to 161 (inclusive).
   */
  num_frames?: number
  /**
   * Guidance Scale (1st Stage)
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guidance_scale?: number
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Video Write Mode
   *
   * The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Resolution
   *
   * Resolution of the generated video (480p, 580p, or 720p).
   */
  resolution?: '480p' | '580p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video (16:9 or 9:16).
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Enable Output Safety Checker
   *
   * If set to true, output video will be checked for safety after generation.
   */
  enable_output_safety_checker?: boolean
  /**
   * Guidance Scale (2nd Stage)
   *
   * Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.
   */
  guidance_scale_2?: number
  /**
   * Video Quality
   *
   * The quality of the output video. Higher quality means better visual quality but larger file size.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean
  /**
   * Number of Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Interpolator Model
   *
   * The model to use for frame interpolation. If None, no interpolation is applied.
   */
  interpolator_model?: 'none' | 'film' | 'rife'
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Adjust FPS for Interpolation
   *
   * If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.
   */
  adjust_fps_for_interpolation?: boolean
}

/**
 * MareyOutput
 */
export type SchemaMareyT2vOutput = {
  video: SchemaFile
}

/**
 * MareyInputT2V
 */
export type SchemaMareyT2vInput = {
  /**
   * Prompt
   *
   * The prompt to generate a video from
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video.
   */
  duration?: '5s' | '10s'
  /**
   * Dimensions
   *
   * The dimensions of the generated video in width x height format.
   */
  dimensions?: '1920x1080' | '1152x1152' | '1536x1152' | '1152x1536'
  /**
   * Guidance Scale
   *
   * Controls how strongly the generation is guided by the prompt (0-20). Higher values follow the prompt more closely.
   */
  guidance_scale?: number | unknown
  /**
   * Seed
   *
   * Seed for random number generation. Use -1 for random seed each run.
   */
  seed?: number | unknown
  /**
   * Negative Prompt
   *
   * Negative prompt used to guide the model away from undesirable features.
   */
  negative_prompt?: string | unknown
}

/**
 * AvatarSingleTextResponse
 */
export type SchemaInfinitalkSingleTextOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * InfiniTalkSingleTextRequest
 */
export type SchemaInfinitalkSingleTextInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the video to generate. Must be either 480p or 720p.
   */
  resolution?: '480p' | '720p'
  /**
   * Acceleration
   *
   * The acceleration level to use for generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Text Input
   *
   * The text input to guide video generation.
   */
  text_input: string
  /**
   * Image URL
   *
   * URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Voice
   *
   * The voice to use for speech generation
   */
  voice:
    | 'Aria'
    | 'Roger'
    | 'Sarah'
    | 'Laura'
    | 'Charlie'
    | 'George'
    | 'Callum'
    | 'River'
    | 'Liam'
    | 'Charlotte'
    | 'Alice'
    | 'Matilda'
    | 'Will'
    | 'Jessica'
    | 'Eric'
    | 'Chris'
    | 'Brian'
    | 'Daniel'
    | 'Lily'
    | 'Bill'
  /**
   * Number of Frames
   *
   * Number of frames to generate. Must be between 41 to 721.
   */
  num_frames?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
}

/**
 * VideoOutputV5
 */
export type SchemaPixverseV5TextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * TextToVideoRequest
 */
export type SchemaPixverseV5TextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Duration
   *
   * The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds
   */
  duration?: '5' | '8'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * AvatarsAppOutput
 */
export type SchemaAvatarsTextToVideoOutput = {
  video: SchemaFile
}

/**
 * Text2VideoInput
 */
export type SchemaAvatarsTextToVideoInput = {
  /**
   * Text
   */
  text: string
  /**
   * Avatar Id
   *
   * The avatar to use for the video
   */
  avatar_id:
    | 'emily_vertical_primary'
    | 'emily_vertical_secondary'
    | 'marcus_vertical_primary'
    | 'marcus_vertical_secondary'
    | 'mira_vertical_primary'
    | 'mira_vertical_secondary'
    | 'jasmine_vertical_primary'
    | 'jasmine_vertical_secondary'
    | 'jasmine_vertical_walking'
    | 'aisha_vertical_walking'
    | 'elena_vertical_primary'
    | 'elena_vertical_secondary'
    | 'any_male_vertical_primary'
    | 'any_female_vertical_primary'
    | 'any_male_vertical_secondary'
    | 'any_female_vertical_secondary'
    | 'any_female_vertical_walking'
    | 'emily_primary'
    | 'emily_side'
    | 'marcus_primary'
    | 'marcus_side'
    | 'aisha_walking'
    | 'elena_primary'
    | 'elena_side'
    | 'any_male_primary'
    | 'any_female_primary'
    | 'any_male_side'
    | 'any_female_side'
}

/**
 * VideoOutput
 *
 * Base output for video generation
 */
export type SchemaWan25PreviewTextToVideoOutput = {
  /**
   * Actual Prompt
   *
   * The actual prompt used if prompt rewriting was enabled
   */
  actual_prompt?: string
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * The generated video file
   */
  video: SchemaVideoFile
}

/**
 * VideoFile
 */
export type SchemaVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number
  /**
   * Height
   *
   * The height of the video
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number
  /**
   * Width
   *
   * The width of the video
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TextToVideoInput
 *
 * Input for text-to-video generation
 */
export type SchemaWan25PreviewTextToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt for video generation. Supports Chinese and English, max 800 characters.
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution tier
   */
  resolution?: '480p' | '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Duration
   *
   * Duration of the generated video in seconds. Choose between 5 or 10 seconds.
   */
  duration?: '5' | '10'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Audio Url
   *
   *
   * URL of the audio to use as the background music. Must be publicly accessible.
   * Limit handling: If the audio duration exceeds the duration value (5 or 10 seconds),
   * the audio is truncated to the first 5 or 10 seconds, and the rest is discarded. If
   * the audio is shorter than the video, the remaining part of the video will be silent.
   * For example, if the audio is 3 seconds long and the video duration is 5 seconds, the
   * first 3 seconds of the output video will have sound, and the last 2 seconds will be silent.
   * - Format: WAV, MP3.
   * - Duration: 3 to 30 s.
   * - File size: Up to 15 MB.
   *
   */
  audio_url?: string
  /**
   * Negative Prompt
   *
   * Negative prompt to describe content to avoid. Max 500 characters.
   */
  negative_prompt?: string
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt rewriting using LLM. Improves results for short prompts but increases processing time.
   */
  enable_prompt_expansion?: boolean
}

/**
 * OviT2VResponse
 */
export type SchemaOviOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * The generated video file.
   */
  video?: SchemaFile | unknown
}

/**
 * OviT2VRequest
 */
export type SchemaOviInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the generated video in W:H format. One of (512x992, 992x512, 960x512, 512x960, 720x720, or 448x1120).
   */
  resolution?:
    | '512x992'
    | '992x512'
    | '960x512'
    | '512x960'
    | '720x720'
    | '448x1120'
    | '1120x448'
  /**
   * Num Inference Steps
   *
   * The number of inference steps.
   */
  num_inference_steps?: number
  /**
   * Audio Negative Prompt
   *
   * Negative prompt for audio generation.
   */
  audio_negative_prompt?: string
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number | unknown
}

/**
 * TextToVideoOutput
 */
export type SchemaSora2TextToVideoOutput = {
  /**
   * Spritesheet
   *
   * Spritesheet image for the video
   */
  spritesheet?: SchemaImageFile
  /**
   * Thumbnail
   *
   * Thumbnail image for the video
   */
  thumbnail?: SchemaImageFile
  /**
   * Video ID
   *
   * The ID of the generated video
   */
  video_id: string
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaVideoFile
}

/**
 * ImageFile
 */
export type SchemaImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TextToVideoInput
 */
export type SchemaSora2TextToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * Duration of the generated video in seconds
   */
  duration?: 4 | 8 | 12
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '720p'
  /**
   * Model
   *
   * The model to use for the generation. When the default model is selected, the latest snapshot of the model will be used - otherwise, select a specific snapshot of the model.
   */
  model?: 'sora-2' | 'sora-2-2025-12-08' | 'sora-2-2025-10-06'
  /**
   * Delete Video
   *
   * Whether to delete the video after generation for privacy reasons. If True, the video cannot be used for remixing and will be permanently deleted.
   */
  delete_video?: boolean
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '9:16' | '16:9'
}

/**
 * ProTextToVideoOutput
 */
export type SchemaSora2TextToVideoProOutput = {
  /**
   * Spritesheet
   *
   * Spritesheet image for the video
   */
  spritesheet?: SchemaImageFile
  /**
   * Thumbnail
   *
   * Thumbnail image for the video
   */
  thumbnail?: SchemaImageFile
  /**
   * Video ID
   *
   * The ID of the generated video
   */
  video_id: string
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaVideoFile
}

/**
 * ProTextToVideoInput
 */
export type SchemaSora2TextToVideoProInput = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * Duration of the generated video in seconds
   */
  duration?: 4 | 8 | 12
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '9:16' | '16:9'
  /**
   * Delete Video
   *
   * Whether to delete the video after generation for privacy reasons. If True, the video cannot be used for remixing and will be permanently deleted.
   */
  delete_video?: boolean
}

/**
 * Veo31TextToVideoOutput
 */
export type SchemaVeo31Output = {
  /**
   * Video
   *
   * The generated video.
   */
  video: SchemaFile
}

/**
 * Veo31TextToVideoInput
 */
export type SchemaVeo31Input = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video.
   */
  duration?: '4s' | '6s' | '8s'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * Auto Fix
   *
   * Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.
   */
  auto_fix?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '720p' | '1080p' | '4k'
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the video generation.
   */
  negative_prompt?: string
}

/**
 * Veo31TextToVideoOutput
 */
export type SchemaVeo31FastOutput = {
  /**
   * Video
   *
   * The generated video.
   */
  video: SchemaFile
}

/**
 * Veo31TextToVideoInput
 */
export type SchemaVeo31FastInput = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video.
   */
  duration?: '4s' | '6s' | '8s'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * Auto Fix
   *
   * Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.
   */
  auto_fix?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '720p' | '1080p' | '4k'
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the video generation.
   */
  negative_prompt?: string
}

/**
 * KandinskyT2VResponse
 */
export type SchemaKandinsky5TextToVideoOutput = {
  /**
   * Video
   *
   * The generated video file.
   */
  video?: SchemaFile
}

/**
 * KandinskyT2VRequest
 */
export type SchemaKandinsky5TextToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the generated video in W:H format. Will be calculated based on the aspect ratio(768x512, 512x512, 512x768).
   */
  resolution?: '768x512'
  /**
   * Duration
   *
   * The length of the video to generate (5s or 10s)
   */
  duration?: '5s' | '10s'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video. One of (3:2, 1:1, 2:3).
   */
  aspect_ratio?: '3:2' | '1:1' | '2:3'
  /**
   * Num Inference Steps
   *
   * The number of inference steps.
   */
  num_inference_steps?: number
}

/**
 * KandinskyT2VResponse
 */
export type SchemaKandinsky5TextToVideoDistillOutput = {
  /**
   * Video
   *
   * The generated video file.
   */
  video?: SchemaFile
}

/**
 * KandinskyT2VDistillRequest
 */
export type SchemaKandinsky5TextToVideoDistillInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Duration
   *
   * The length of the video to generate (5s or 10s)
   */
  duration?: '5s' | '10s'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video. One of (3:2, 1:1, 2:3).
   */
  aspect_ratio?: '3:2' | '1:1' | '2:3'
  /**
   * Resolution
   *
   * Resolution of the generated video in W:H format. Will be calculated based on the aspect ratio(768x512, 512x512, 512x768).
   */
  resolution?: '768x512'
}

/**
 * WanAlphaResponse
 */
export type SchemaWanAlphaOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Image
   *
   * The generated image file.
   */
  image?: SchemaVideoFile
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Mask
   *
   * The generated mask file.
   */
  mask?: SchemaVideoFile
  /**
   * Video
   *
   * The generated video file.
   */
  video?: SchemaVideoFile
}

/**
 * WanAlphaRequest
 */
export type SchemaWanAlphaInput = {
  /**
   * Prompt
   *
   * The prompt to guide the video generation.
   */
  prompt: string
  /**
   * Shift
   *
   * The shift of the generated video.
   */
  shift?: number
  /**
   * Mask Clamp Upper
   *
   * The upper bound of the mask clamping.
   */
  mask_clamp_upper?: number
  /**
   * FPS
   *
   * The frame rate of the generated video.
   */
  fps?: number
  /**
   * Mask Clamp Lower
   *
   * The lower bound of the mask clamping.
   */
  mask_clamp_lower?: number
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Mask Binarization Threshold
   *
   * The threshold for mask binarization. When binarize_mask is True, this threshold will be used to binarize the mask. This will also be used for transparency when the output type is `.webm`.
   */
  mask_binarization_threshold?: number
  /**
   * Sampler
   *
   * The sampler to use.
   */
  sampler?: 'unipc' | 'dpm++' | 'euler'
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '240p' | '360p' | '480p' | '580p' | '720p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video.
   */
  aspect_ratio?: '16:9' | '1:1' | '9:16'
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * Binarize Mask
   *
   * Whether to binarize the mask.
   */
  binarize_mask?: boolean
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
}

/**
 * VideoToVideoOutput
 */
export type SchemaKreaWan14bTextToVideoOutput = {
  video: SchemaFile
}

/**
 * TextToVideoInput
 */
export type SchemaKreaWan14bTextToVideoInput = {
  /**
   * Prompt
   *
   * Prompt for the video-to-video generation.
   */
  prompt: string
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean
  /**
   * Num Frames
   *
   * Number of frames to generate. Must be a multiple of 12 plus 6, for example 6, 18, 30, 42, etc.
   */
  num_frames?: number
  /**
   * Seed
   *
   * Seed for the video-to-video generation.
   */
  seed?: number | unknown
}

/**
 * Q2TextToVideoOutput
 */
export type SchemaViduQ2TextToVideoOutput = {
  /**
   * Video
   *
   * The generated video from text using the Q2 model
   */
  video: SchemaFile
}

/**
 * Q2TextToVideoRequest
 */
export type SchemaViduQ2TextToVideoInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 3000 characters
   */
  prompt: string
  /**
   * Resolution
   *
   * Output video resolution
   */
  resolution?: '360p' | '520p' | '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the output video
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Duration
   *
   * Duration of the video in seconds
   */
  duration?: 2 | 3 | 4 | 5 | 6 | 7 | 8
  /**
   * Bgm
   *
   * Whether to add background music to the video (only for 4-second videos)
   */
  bgm?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Movement Amplitude
   *
   * The movement amplitude of objects in the frame
   */
  movement_amplitude?: 'auto' | 'small' | 'medium' | 'large'
}

/**
 * SeedanceFastT2VVideoOutput
 */
export type SchemaBytedanceSeedanceV1ProFastTextToVideoOutput = {
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * Generated video file
   */
  video: SchemaFile
}

/**
 * SeedanceProFastTextToVideoInput
 */
export type SchemaBytedanceSeedanceV1ProFastTextToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt used to generate the video
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality
   */
  resolution?: '480p' | '720p' | '1080p'
  /**
   * Duration
   *
   * Duration of the video in seconds
   */
  duration?: '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9' | '10' | '11' | '12'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '21:9' | '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * Random seed to control video generation. Use -1 for random.
   */
  seed?: number
  /**
   * Camera Fixed
   *
   * Whether to fix the camera position
   */
  camera_fixed?: boolean
}

/**
 * ProTextToVideoHailuo23Output
 */
export type SchemaMinimaxHailuo23ProTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * ProTextToVideoHailuo23Input
 */
export type SchemaMinimaxHailuo23ProTextToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Prompt
   *
   * Text prompt for video generation
   */
  prompt: string
}

/**
 * StandardTextToVideoHailuo23Output
 */
export type SchemaMinimaxHailuo23StandardTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * StandardTextToVideoHailuo23Input
 */
export type SchemaMinimaxHailuo23StandardTextToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Duration
   *
   * The duration of the video in seconds.
   */
  duration?: '6' | '10'
  /**
   * Prompt
   */
  prompt: string
}

/**
 * LongCatVideoResponse
 */
export type SchemaLongcatVideoDistilledTextToVideo480pOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * LongCatVideoRequest
 */
export type SchemaLongcatVideoDistilledTextToVideo480pInput = {
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video.
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Prompt
   *
   * The prompt to guide the video generation.
   */
  prompt: string
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * FPS
   *
   * The frame rate of the generated video.
   */
  fps?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Safety Checker
   *
   * Whether to enable safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
}

/**
 * LongCatVideoResponse
 */
export type SchemaLongcatVideoDistilledTextToVideo720pOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * LongCat720PVideoRequest
 */
export type SchemaLongcatVideoDistilledTextToVideo720pInput = {
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video.
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Prompt
   *
   * The prompt to guide the video generation.
   */
  prompt: string
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * FPS
   *
   * The frame rate of the generated video.
   */
  fps?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Number of Refinement Inference Steps
   *
   * The number of inference steps to use for refinement.
   */
  num_refine_inference_steps?: number
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Safety Checker
   *
   * Whether to enable safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
}

/**
 * LongCatVideoResponse
 */
export type SchemaLongcatVideoTextToVideo480pOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * LongCatCFGVideoRequest
 */
export type SchemaLongcatVideoTextToVideo480pInput = {
  /**
   * Prompt
   *
   * The prompt to guide the video generation.
   */
  prompt: string
  /**
   * Acceleration
   *
   * The acceleration level to use for the video generation.
   */
  acceleration?: 'none' | 'regular'
  /**
   * FPS
   *
   * The frame rate of the generated video.
   */
  fps?: number
  /**
   * Guidance Scale
   *
   * The guidance scale to use for the video generation.
   */
  guidance_scale?: number
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * The negative prompt to use for the video generation.
   */
  negative_prompt?: string
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video.
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use for the video generation.
   */
  num_inference_steps?: number
}

/**
 * LongCatVideoResponse
 */
export type SchemaLongcatVideoTextToVideo720pOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * LongCat720PCFGVideoRequest
 */
export type SchemaLongcatVideoTextToVideo720pInput = {
  /**
   * Prompt
   *
   * The prompt to guide the video generation.
   */
  prompt: string
  /**
   * Acceleration
   *
   * The acceleration level to use for the video generation.
   */
  acceleration?: 'none' | 'regular'
  /**
   * FPS
   *
   * The frame rate of the generated video.
   */
  fps?: number
  /**
   * Number of Refinement Inference Steps
   *
   * The number of inference steps to use for refinement.
   */
  num_refine_inference_steps?: number
  /**
   * Guidance Scale
   *
   * The guidance scale to use for the video generation.
   */
  guidance_scale?: number
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * The negative prompt to use for the video generation.
   */
  negative_prompt?: string
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video.
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use for the video generation.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
}

/**
 * SanaVideoOutput
 */
export type SchemaSanaVideoOutput = {
  /**
   * Seed
   *
   * The random seed used for the generation process
   */
  seed: number
  /**
   * Video
   *
   * Generated video file
   */
  video: SchemaFile
}

/**
 * SanaVideoInput
 */
export type SchemaSanaVideoInput = {
  /**
   * Prompt
   *
   * The text prompt describing the video to generate
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the output video
   */
  resolution?: '480p'
  /**
   * Fps
   *
   * Frames per second for the output video
   */
  fps?: number
  /**
   * Motion Score
   *
   * Motion intensity score (higher = more motion)
   */
  motion_score?: number
  /**
   * Guidance Scale
   *
   * Guidance scale for generation (higher = more prompt adherence)
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of denoising steps
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * Random seed for reproducible generation. If not provided, a random seed will be used.
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * The negative prompt describing what to avoid in the generation
   */
  negative_prompt?: string
  /**
   * Num Frames
   *
   * Number of frames to generate
   */
  num_frames?: number
}

/**
 * GenerationOutput
 *
 * Output model for text-to-video generation
 */
export type SchemaInfinityStarTextToVideoOutput = {
  /**
   * Video
   *
   * Generated video file
   */
  video: SchemaFile
}

/**
 * GenerationInput
 *
 * Input model for text-to-video generation
 */
export type SchemaInfinityStarTextToVideoInput = {
  /**
   * Prompt
   *
   * Text prompt for generating the video
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated output
   */
  aspect_ratio?: '16:9' | '1:1' | '9:16'
  /**
   * Enhance Prompt
   *
   * Whether to use an LLM to enhance the prompt.
   */
  enhance_prompt?: boolean
  /**
   * Use Apg
   *
   * Whether to use APG
   */
  use_apg?: boolean
  /**
   * Guidance Scale
   *
   * Guidance scale for generation
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. Leave empty for random generation.
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to guide what to avoid in generation
   */
  negative_prompt?: string
  /**
   * Tau Video
   *
   * Tau value for video scale
   */
  tau_video?: number
}

/**
 * HunyuanVideo15Response
 */
export type SchemaHunyuanVideoV15TextToVideoOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: SchemaFile
}

/**
 * HunyuanVideo15T2VRequest
 */
export type SchemaHunyuanVideoV15TextToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video.
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the video.
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the video.
   */
  resolution?: '480p'
  /**
   * Enable Prompt Expansion
   *
   * Enable prompt expansion to enhance the input prompt.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility.
   */
  seed?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps.
   */
  num_inference_steps?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to guide what not to generate.
   */
  negative_prompt?: string
  /**
   * Num Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
}

/**
 * LTXVTextToVideoResponse
 */
export type SchemaLtx2TextToVideoOutput = {
  /**
   * Video
   *
   * The generated video file
   */
  video: SchemaVideoFile
}

/**
 * LTXVTextToVideoRequest
 */
export type SchemaLtx2TextToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: 6 | 8 | 10
  /**
   * Generate Audio
   *
   * Whether to generate audio for the generated video
   */
  generate_audio?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '1080p' | '1440p' | '2160p'
  /**
   * Frames per Second
   *
   * The frames per second of the generated video
   */
  fps?: 25 | 50
}

/**
 * LTXVTextToVideoResponse
 */
export type SchemaLtx2TextToVideoFastOutput = {
  /**
   * Video
   *
   * The generated video file
   */
  video: SchemaVideoFile
}

/**
 * LTXVTextToVideoFastRequest
 */
export type SchemaLtx2TextToVideoFastInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9'
  /**
   * Duration
   *
   * The duration of the generated video in seconds. The fast model supports 6-20 seconds. Note: Durations longer than 10 seconds (12, 14, 16, 18, 20) are only supported with 25 FPS and 1080p resolution.
   */
  duration?: 6 | 8 | 10 | 12 | 14 | 16 | 18 | 20
  /**
   * Generate Audio
   *
   * Whether to generate audio for the generated video
   */
  generate_audio?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '1080p' | '1440p' | '2160p'
  /**
   * Frames per Second
   *
   * The frames per second of the generated video
   */
  fps?: 25 | 50
}

/**
 * VideoOutputV5_5
 */
export type SchemaPixverseV55TextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * TextToVideoRequestV5_5
 */
export type SchemaPixverseV55TextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Thinking Type
   *
   * Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision
   */
  thinking_type?: 'enabled' | 'disabled' | 'auto'
  /**
   * Generate Multi Clip Switch
   *
   * Enable multi-clip generation with dynamic camera changes
   */
  generate_multi_clip_switch?: boolean
  /**
   * Duration
   *
   * The duration of the generated video in seconds. Longer durations cost more. 1080p videos are limited to 5 or 8 seconds
   */
  duration?: '5' | '8' | '10'
  /**
   * Generate Audio Switch
   *
   * Enable audio generation (BGM, SFX, dialogue)
   */
  generate_audio_switch?: boolean
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * TextToVideoV26ProOutput
 */
export type SchemaKlingVideoV26ProTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * TextToVideoV26ProRequest
 */
export type SchemaKlingVideoV26ProTextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video frame
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Generate Audio
   *
   * Whether to generate native audio for the video. Supports Chinese and English voice output. Other languages are automatically translated to English. For English speech, use lowercase letters; for acronyms or proper nouns, use uppercase.
   */
  generate_audio?: boolean
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * FabricOneTextOutput
 */
export type SchemaFabric10TextOutput = {
  video: SchemaFile
}

/**
 * FabricOneTextInput
 */
export type SchemaFabric10TextInput = {
  /**
   * Text
   */
  text: string
  /**
   * Resolution
   *
   * Resolution
   */
  resolution: '720p' | '480p'
  /**
   * Voice Description
   *
   * Optional additional voice description. The primary voice description is auto-generated from the image. You can use simple descriptors like 'British accent' or 'Confident' or provide a detailed description like 'Confident male voice, mid-20s, with notes of...'
   */
  voice_description?: string | unknown
  /**
   * Image Url
   */
  image_url: string
}

/**
 * TextToVideoOutput
 *
 * Output for text-to-video generation
 */
export type SchemaV26TextToVideoOutput = {
  /**
   * Actual Prompt
   *
   * The actual prompt used if prompt rewriting was enabled
   */
  actual_prompt?: string
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * The generated video file
   */
  video: SchemaVideoFile
}

/**
 * TextToVideoInput
 *
 * Input for Wan 2.6 text-to-video generation
 */
export type SchemaV26TextToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt for video generation. Supports Chinese and English, max 800 characters. For multi-shot videos, use format: 'Overall description. First shot [0-3s] content. Second shot [3-5s] content.'
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video. Wan 2.6 supports additional ratios.
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1' | '4:3' | '3:4'
  /**
   * Resolution
   *
   * Video resolution tier. Wan 2.6 T2V only supports 720p and 1080p (no 480p).
   */
  resolution?: '720p' | '1080p'
  /**
   * Duration
   *
   * Duration of the generated video in seconds. Choose between 5, 10, or 15 seconds.
   */
  duration?: '5' | '10' | '15'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Audio Url
   *
   *
   * URL of the audio to use as the background music. Must be publicly accessible.
   * Limit handling: If the audio duration exceeds the duration value (5, 10, or 15 seconds),
   * the audio is truncated to the first N seconds, and the rest is discarded. If
   * the audio is shorter than the video, the remaining part of the video will be silent.
   * For example, if the audio is 3 seconds long and the video duration is 5 seconds, the
   * first 3 seconds of the output video will have sound, and the last 2 seconds will be silent.
   * - Format: WAV, MP3.
   * - Duration: 3 to 30 s.
   * - File size: Up to 15 MB.
   *
   */
  audio_url?: string
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Multi Shots
   *
   * When true, enables intelligent multi-shot segmentation for coherent narrative videos. Only active when enable_prompt_expansion is True. Set to false for single-shot generation.
   */
  multi_shots?: boolean
  /**
   * Negative Prompt
   *
   * Negative prompt to describe content to avoid. Max 500 characters.
   */
  negative_prompt?: string
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt rewriting using LLM. Improves results for short prompts but increases processing time.
   */
  enable_prompt_expansion?: boolean
}

/**
 * SeedanceProv15T2VVideoOutput
 */
export type SchemaBytedanceSeedanceV15ProTextToVideoOutput = {
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * Generated video file
   */
  video: SchemaFile
}

/**
 * SeedanceProv15TextToVideoInput
 */
export type SchemaBytedanceSeedanceV15ProTextToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt used to generate the video
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality
   */
  resolution?: '480p' | '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '21:9' | '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video
   */
  generate_audio?: boolean
  /**
   * Duration
   *
   * Duration of the video in seconds
   */
  duration?: '4' | '5' | '6' | '7' | '8' | '9' | '10' | '11' | '12'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Camera Fixed
   *
   * Whether to fix the camera position
   */
  camera_fixed?: boolean
  /**
   * Seed
   *
   * Random seed to control video generation. Use -1 for random.
   */
  seed?: number
}

/**
 * KandinskyT2VResponse
 */
export type SchemaKandinsky5ProTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video file.
   */
  video?: SchemaFile
}

/**
 * KandinskyT2VRequest
 */
export type SchemaKandinsky5ProTextToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution: 512p or 1024p.
   */
  resolution?: '512P' | '1024P'
  /**
   * Acceleration
   *
   * Acceleration level for faster generation.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video. One of (3:2, 1:1, 2:3).
   */
  aspect_ratio?: '3:2' | '1:1' | '2:3'
  /**
   * Num Inference Steps
   *
   * The number of inference steps.
   */
  num_inference_steps?: number
  /**
   * Duration
   *
   * The length of the video to generate (5s or 10s)
   */
  duration?: '5s'
}

/**
 * LTX2TextToVideoOutput
 */
export type SchemaLtx219bTextToVideoOutput = {
  /**
   * Prompt
   *
   * The prompt used for the generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for the random number generator.
   */
  seed: number
  video: SchemaVideoFile
}

/**
 * LTX2TextToVideoInput
 */
export type SchemaLtx219bTextToVideoInput = {
  /**
   * Use Multi-Scale
   *
   * Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.
   */
  use_multiscale?: boolean
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: 'none' | 'regular' | 'high' | 'full'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * FPS
   *
   * The frames per second of the generated video.
   */
  fps?: number
  /**
   * Camera LoRA
   *
   * The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.
   */
  camera_lora?:
    | 'dolly_in'
    | 'dolly_out'
    | 'dolly_left'
    | 'dolly_right'
    | 'jib_up'
    | 'jib_down'
    | 'static'
    | 'none'
  /**
   * Video Size
   *
   * The size of the generated video.
   */
  video_size?:
    | SchemaImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Guidance Scale
   *
   * The guidance scale to use.
   */
  guidance_scale?: number
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Camera LoRA Scale
   *
   * The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.
   */
  camera_lora_scale?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to generate the video from.
   */
  negative_prompt?: string
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number | unknown
}

/**
 * LTX2TextToVideoOutput
 */
export type SchemaLtx219bTextToVideoLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for the generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for the random number generator.
   */
  seed: number
  video: SchemaVideoFile
}

/**
 * LTX2LoRATextToVideoInput
 */
export type SchemaLtx219bTextToVideoLoraInput = {
  /**
   * Use Multi-Scale
   *
   * Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.
   */
  use_multiscale?: boolean
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: 'none' | 'regular' | 'high' | 'full'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * FPS
   *
   * The frames per second of the generated video.
   */
  fps?: number
  /**
   * LoRAs
   *
   * The LoRAs to use for the generation.
   */
  loras: Array<SchemaLoRaInput>
  /**
   * Camera LoRA
   *
   * The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.
   */
  camera_lora?:
    | 'dolly_in'
    | 'dolly_out'
    | 'dolly_left'
    | 'dolly_right'
    | 'jib_up'
    | 'jib_down'
    | 'static'
    | 'none'
  /**
   * Video Size
   *
   * The size of the generated video.
   */
  video_size?:
    | SchemaImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Guidance Scale
   *
   * The guidance scale to use.
   */
  guidance_scale?: number
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Camera LoRA Scale
   *
   * The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.
   */
  camera_lora_scale?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to generate the video from.
   */
  negative_prompt?: string
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number | unknown
}

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export type SchemaLoRaInput = {
  /**
   * Path
   *
   * URL, HuggingFace repo ID (owner/repo) to lora weights.
   */
  path: string
  /**
   * Scale
   *
   * Scale factor for LoRA application (0.0 to 4.0).
   */
  scale?: number
  /**
   * Weight Name
   *
   * Name of the LoRA weight. Only used if `path` is a HuggingFace repository, and is only required when the repository contains multiple LoRA weights.
   */
  weight_name?: string | unknown
}

/**
 * LTX2TextToVideoOutput
 */
export type SchemaLtx219bDistilledTextToVideoOutput = {
  /**
   * Prompt
   *
   * The prompt used for the generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for the random number generator.
   */
  seed: number
  video: SchemaVideoFile
}

/**
 * LTX2DistilledTextToVideoInput
 */
export type SchemaLtx219bDistilledTextToVideoInput = {
  /**
   * Use Multi-Scale
   *
   * Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.
   */
  use_multiscale?: boolean
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: 'none' | 'regular' | 'high' | 'full'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * FPS
   *
   * The frames per second of the generated video.
   */
  fps?: number
  /**
   * Camera LoRA
   *
   * The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.
   */
  camera_lora?:
    | 'dolly_in'
    | 'dolly_out'
    | 'dolly_left'
    | 'dolly_right'
    | 'jib_up'
    | 'jib_down'
    | 'static'
    | 'none'
  /**
   * Video Size
   *
   * The size of the generated video.
   */
  video_size?:
    | SchemaImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Camera LoRA Scale
   *
   * The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.
   */
  camera_lora_scale?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to generate the video from.
   */
  negative_prompt?: string
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number | unknown
}

/**
 * LTX2TextToVideoOutput
 */
export type SchemaLtx219bDistilledTextToVideoLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for the generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for the random number generator.
   */
  seed: number
  video: SchemaVideoFile
}

/**
 * LTX2LoRADistilledTextToVideoInput
 */
export type SchemaLtx219bDistilledTextToVideoLoraInput = {
  /**
   * Use Multi-Scale
   *
   * Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.
   */
  use_multiscale?: boolean
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: 'none' | 'regular' | 'high' | 'full'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * FPS
   *
   * The frames per second of the generated video.
   */
  fps?: number
  /**
   * LoRAs
   *
   * The LoRAs to use for the generation.
   */
  loras: Array<SchemaLoRaInput>
  /**
   * Camera LoRA
   *
   * The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.
   */
  camera_lora?:
    | 'dolly_in'
    | 'dolly_out'
    | 'dolly_left'
    | 'dolly_right'
    | 'jib_up'
    | 'jib_down'
    | 'static'
    | 'none'
  /**
   * Video Size
   *
   * The size of the generated video.
   */
  video_size?:
    | SchemaImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Camera LoRA Scale
   *
   * The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.
   */
  camera_lora_scale?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to generate the video from.
   */
  negative_prompt?: string
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number | unknown
}

/**
 * VideoOutputV5_5
 */
export type SchemaPixverseV56TextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * TextToVideoRequestV5_6
 */
export type SchemaPixverseV56TextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Thinking Type
   *
   * Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision
   */
  thinking_type?: 'enabled' | 'disabled' | 'auto'
  /**
   * Duration
   *
   * The duration of the generated video in seconds. 1080p videos are limited to 5 or 8 seconds
   */
  duration?: '5' | '8' | '10'
  /**
   * Generate Audio Switch
   *
   * Enable audio generation (BGM, SFX, dialogue)
   */
  generate_audio_switch?: boolean
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * TextToVideoV2MasterOutput
 */
export type SchemaKlingVideoV2MasterTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * TextToVideoV2MasterRequest
 */
export type SchemaKlingVideoV2MasterTextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video frame
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * Veo3TextToVideoOutput
 */
export type SchemaVeo3Output = {
  /**
   * Video
   *
   * The generated video.
   */
  video: SchemaFile
}

/**
 * Veo3TextToVideoInput
 */
export type SchemaVeo3Input = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video.
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Duration
   *
   * The duration of the generated video.
   */
  duration?: '4s' | '6s' | '8s'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * Auto Fix
   *
   * Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.
   */
  auto_fix?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '720p' | '1080p'
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the video generation.
   */
  negative_prompt?: string
}

/**
 * TextToVideoHailuo02Output
 */
export type SchemaMinimaxHailuo02StandardTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * StandardTextToVideoHailuo02Input
 */
export type SchemaMinimaxHailuo02StandardTextToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Duration
   *
   * The duration of the video in seconds. 10 seconds videos are not supported for 1080p resolution.
   */
  duration?: '6' | '10'
  /**
   * Prompt
   */
  prompt: string
}

/**
 * Veo3TextToVideoOutput
 */
export type SchemaVeo3FastOutput = {
  /**
   * Video
   *
   * The generated video.
   */
  video: SchemaFile
}

/**
 * Veo3TextToVideoInput
 */
export type SchemaVeo3FastInput = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video.
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Duration
   *
   * The duration of the generated video.
   */
  duration?: '4s' | '6s' | '8s'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * Auto Fix
   *
   * Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.
   */
  auto_fix?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '720p' | '1080p'
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the video generation.
   */
  negative_prompt?: string
}

/**
 * TextToVideoV25ProOutput
 */
export type SchemaKlingVideoV25TurboProTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: SchemaFile
}

/**
 * TextToVideoV25ProRequest
 */
export type SchemaKlingVideoV25TurboProTextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video frame
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

export type SchemaQueueStatus = {
  status: 'IN_QUEUE' | 'IN_PROGRESS' | 'COMPLETED'
  /**
   * The request id.
   */
  request_id: string
  /**
   * The response url.
   */
  response_url?: string
  /**
   * The status url.
   */
  status_url?: string
  /**
   * The cancel url.
   */
  cancel_url?: string
  /**
   * The logs.
   */
  logs?: {
    [key: string]: unknown
  }
  /**
   * The metrics.
   */
  metrics?: {
    [key: string]: unknown
  }
  /**
   * The queue position.
   */
  queue_position?: number
}

export type GetFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/kling-video/v2.5-turbo/pro/text-to-video/requests/{request_id}/status'
  }

export type GetFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/v2.5-turbo/pro/text-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV25TurboProTextToVideoData = {
  body: SchemaKlingVideoV25TurboProTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v2.5-turbo/pro/text-to-video'
}

export type PostFalAiKlingVideoV25TurboProTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV25TurboProTextToVideoResponse =
  PostFalAiKlingVideoV25TurboProTextToVideoResponses[keyof PostFalAiKlingVideoV25TurboProTextToVideoResponses]

export type GetFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v2.5-turbo/pro/text-to-video/requests/{request_id}'
}

export type GetFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaKlingVideoV25TurboProTextToVideoOutput
  }

export type GetFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdResponse =
  GetFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdResponses]

export type GetFalAiVeo3FastRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/veo3/fast/requests/{request_id}/status'
}

export type GetFalAiVeo3FastRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiVeo3FastRequestsByRequestIdStatusResponse =
  GetFalAiVeo3FastRequestsByRequestIdStatusResponses[keyof GetFalAiVeo3FastRequestsByRequestIdStatusResponses]

export type PutFalAiVeo3FastRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/veo3/fast/requests/{request_id}/cancel'
}

export type PutFalAiVeo3FastRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiVeo3FastRequestsByRequestIdCancelResponse =
  PutFalAiVeo3FastRequestsByRequestIdCancelResponses[keyof PutFalAiVeo3FastRequestsByRequestIdCancelResponses]

export type PostFalAiVeo3FastData = {
  body: SchemaVeo3FastInput
  path?: never
  query?: never
  url: '/fal-ai/veo3/fast'
}

export type PostFalAiVeo3FastResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiVeo3FastResponse =
  PostFalAiVeo3FastResponses[keyof PostFalAiVeo3FastResponses]

export type GetFalAiVeo3FastRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/veo3/fast/requests/{request_id}'
}

export type GetFalAiVeo3FastRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaVeo3FastOutput
}

export type GetFalAiVeo3FastRequestsByRequestIdResponse =
  GetFalAiVeo3FastRequestsByRequestIdResponses[keyof GetFalAiVeo3FastRequestsByRequestIdResponses]

export type GetFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/minimax/hailuo-02/standard/text-to-video/requests/{request_id}/status'
  }

export type GetFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/minimax/hailuo-02/standard/text-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiMinimaxHailuo02StandardTextToVideoData = {
  body: SchemaMinimaxHailuo02StandardTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/minimax/hailuo-02/standard/text-to-video'
}

export type PostFalAiMinimaxHailuo02StandardTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMinimaxHailuo02StandardTextToVideoResponse =
  PostFalAiMinimaxHailuo02StandardTextToVideoResponses[keyof PostFalAiMinimaxHailuo02StandardTextToVideoResponses]

export type GetFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/minimax/hailuo-02/standard/text-to-video/requests/{request_id}'
  }

export type GetFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaMinimaxHailuo02StandardTextToVideoOutput
  }

export type GetFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdResponse =
  GetFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdResponses[keyof GetFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdResponses]

export type GetFalAiVeo3RequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/veo3/requests/{request_id}/status'
}

export type GetFalAiVeo3RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiVeo3RequestsByRequestIdStatusResponse =
  GetFalAiVeo3RequestsByRequestIdStatusResponses[keyof GetFalAiVeo3RequestsByRequestIdStatusResponses]

export type PutFalAiVeo3RequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/veo3/requests/{request_id}/cancel'
}

export type PutFalAiVeo3RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiVeo3RequestsByRequestIdCancelResponse =
  PutFalAiVeo3RequestsByRequestIdCancelResponses[keyof PutFalAiVeo3RequestsByRequestIdCancelResponses]

export type PostFalAiVeo3Data = {
  body: SchemaVeo3Input
  path?: never
  query?: never
  url: '/fal-ai/veo3'
}

export type PostFalAiVeo3Responses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiVeo3Response =
  PostFalAiVeo3Responses[keyof PostFalAiVeo3Responses]

export type GetFalAiVeo3RequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/veo3/requests/{request_id}'
}

export type GetFalAiVeo3RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaVeo3Output
}

export type GetFalAiVeo3RequestsByRequestIdResponse =
  GetFalAiVeo3RequestsByRequestIdResponses[keyof GetFalAiVeo3RequestsByRequestIdResponses]

export type GetFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/kling-video/v2/master/text-to-video/requests/{request_id}/status'
  }

export type GetFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/v2/master/text-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV2MasterTextToVideoData = {
  body: SchemaKlingVideoV2MasterTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v2/master/text-to-video'
}

export type PostFalAiKlingVideoV2MasterTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV2MasterTextToVideoResponse =
  PostFalAiKlingVideoV2MasterTextToVideoResponses[keyof PostFalAiKlingVideoV2MasterTextToVideoResponses]

export type GetFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v2/master/text-to-video/requests/{request_id}'
}

export type GetFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaKlingVideoV2MasterTextToVideoOutput
  }

export type GetFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdResponse =
  GetFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdResponses]

export type GetFalAiPixverseV56TextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v5.6/text-to-video/requests/{request_id}/status'
}

export type GetFalAiPixverseV56TextToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPixverseV56TextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV56TextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV56TextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV56TextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v5.6/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV56TextToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPixverseV56TextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV56TextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV56TextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV56TextToVideoData = {
  body: SchemaPixverseV56TextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v5.6/text-to-video'
}

export type PostFalAiPixverseV56TextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV56TextToVideoResponse =
  PostFalAiPixverseV56TextToVideoResponses[keyof PostFalAiPixverseV56TextToVideoResponses]

export type GetFalAiPixverseV56TextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v5.6/text-to-video/requests/{request_id}'
}

export type GetFalAiPixverseV56TextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV56TextToVideoOutput
}

export type GetFalAiPixverseV56TextToVideoRequestsByRequestIdResponse =
  GetFalAiPixverseV56TextToVideoRequestsByRequestIdResponses[keyof GetFalAiPixverseV56TextToVideoRequestsByRequestIdResponses]

export type GetFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/ltx-2-19b/distilled/text-to-video/lora/requests/{request_id}/status'
  }

export type GetFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdStatusResponse =
  GetFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdStatusResponses[keyof GetFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdStatusResponses]

export type PutFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/ltx-2-19b/distilled/text-to-video/lora/requests/{request_id}/cancel'
  }

export type PutFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdCancelResponse =
  PutFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdCancelResponses[keyof PutFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdCancelResponses]

export type PostFalAiLtx219bDistilledTextToVideoLoraData = {
  body: SchemaLtx219bDistilledTextToVideoLoraInput
  path?: never
  query?: never
  url: '/fal-ai/ltx-2-19b/distilled/text-to-video/lora'
}

export type PostFalAiLtx219bDistilledTextToVideoLoraResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLtx219bDistilledTextToVideoLoraResponse =
  PostFalAiLtx219bDistilledTextToVideoLoraResponses[keyof PostFalAiLtx219bDistilledTextToVideoLoraResponses]

export type GetFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-2-19b/distilled/text-to-video/lora/requests/{request_id}'
}

export type GetFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaLtx219bDistilledTextToVideoLoraOutput
  }

export type GetFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdResponse =
  GetFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdResponses[keyof GetFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdResponses]

export type GetFalAiLtx219bDistilledTextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ltx-2-19b/distilled/text-to-video/requests/{request_id}/status'
}

export type GetFalAiLtx219bDistilledTextToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiLtx219bDistilledTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiLtx219bDistilledTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiLtx219bDistilledTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiLtx219bDistilledTextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-2-19b/distilled/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiLtx219bDistilledTextToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiLtx219bDistilledTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiLtx219bDistilledTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiLtx219bDistilledTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiLtx219bDistilledTextToVideoData = {
  body: SchemaLtx219bDistilledTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/ltx-2-19b/distilled/text-to-video'
}

export type PostFalAiLtx219bDistilledTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLtx219bDistilledTextToVideoResponse =
  PostFalAiLtx219bDistilledTextToVideoResponses[keyof PostFalAiLtx219bDistilledTextToVideoResponses]

export type GetFalAiLtx219bDistilledTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-2-19b/distilled/text-to-video/requests/{request_id}'
}

export type GetFalAiLtx219bDistilledTextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLtx219bDistilledTextToVideoOutput
}

export type GetFalAiLtx219bDistilledTextToVideoRequestsByRequestIdResponse =
  GetFalAiLtx219bDistilledTextToVideoRequestsByRequestIdResponses[keyof GetFalAiLtx219bDistilledTextToVideoRequestsByRequestIdResponses]

export type GetFalAiLtx219bTextToVideoLoraRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ltx-2-19b/text-to-video/lora/requests/{request_id}/status'
}

export type GetFalAiLtx219bTextToVideoLoraRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiLtx219bTextToVideoLoraRequestsByRequestIdStatusResponse =
  GetFalAiLtx219bTextToVideoLoraRequestsByRequestIdStatusResponses[keyof GetFalAiLtx219bTextToVideoLoraRequestsByRequestIdStatusResponses]

export type PutFalAiLtx219bTextToVideoLoraRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-2-19b/text-to-video/lora/requests/{request_id}/cancel'
}

export type PutFalAiLtx219bTextToVideoLoraRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiLtx219bTextToVideoLoraRequestsByRequestIdCancelResponse =
  PutFalAiLtx219bTextToVideoLoraRequestsByRequestIdCancelResponses[keyof PutFalAiLtx219bTextToVideoLoraRequestsByRequestIdCancelResponses]

export type PostFalAiLtx219bTextToVideoLoraData = {
  body: SchemaLtx219bTextToVideoLoraInput
  path?: never
  query?: never
  url: '/fal-ai/ltx-2-19b/text-to-video/lora'
}

export type PostFalAiLtx219bTextToVideoLoraResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLtx219bTextToVideoLoraResponse =
  PostFalAiLtx219bTextToVideoLoraResponses[keyof PostFalAiLtx219bTextToVideoLoraResponses]

export type GetFalAiLtx219bTextToVideoLoraRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-2-19b/text-to-video/lora/requests/{request_id}'
}

export type GetFalAiLtx219bTextToVideoLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLtx219bTextToVideoLoraOutput
}

export type GetFalAiLtx219bTextToVideoLoraRequestsByRequestIdResponse =
  GetFalAiLtx219bTextToVideoLoraRequestsByRequestIdResponses[keyof GetFalAiLtx219bTextToVideoLoraRequestsByRequestIdResponses]

export type GetFalAiLtx219bTextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ltx-2-19b/text-to-video/requests/{request_id}/status'
}

export type GetFalAiLtx219bTextToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiLtx219bTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiLtx219bTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiLtx219bTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiLtx219bTextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-2-19b/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiLtx219bTextToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiLtx219bTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiLtx219bTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiLtx219bTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiLtx219bTextToVideoData = {
  body: SchemaLtx219bTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/ltx-2-19b/text-to-video'
}

export type PostFalAiLtx219bTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLtx219bTextToVideoResponse =
  PostFalAiLtx219bTextToVideoResponses[keyof PostFalAiLtx219bTextToVideoResponses]

export type GetFalAiLtx219bTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-2-19b/text-to-video/requests/{request_id}'
}

export type GetFalAiLtx219bTextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLtx219bTextToVideoOutput
}

export type GetFalAiLtx219bTextToVideoRequestsByRequestIdResponse =
  GetFalAiLtx219bTextToVideoRequestsByRequestIdResponses[keyof GetFalAiLtx219bTextToVideoRequestsByRequestIdResponses]

export type GetFalAiKandinsky5ProTextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kandinsky5-pro/text-to-video/requests/{request_id}/status'
}

export type GetFalAiKandinsky5ProTextToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKandinsky5ProTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKandinsky5ProTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKandinsky5ProTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKandinsky5ProTextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kandinsky5-pro/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiKandinsky5ProTextToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKandinsky5ProTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKandinsky5ProTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKandinsky5ProTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKandinsky5ProTextToVideoData = {
  body: SchemaKandinsky5ProTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kandinsky5-pro/text-to-video'
}

export type PostFalAiKandinsky5ProTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKandinsky5ProTextToVideoResponse =
  PostFalAiKandinsky5ProTextToVideoResponses[keyof PostFalAiKandinsky5ProTextToVideoResponses]

export type GetFalAiKandinsky5ProTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kandinsky5-pro/text-to-video/requests/{request_id}'
}

export type GetFalAiKandinsky5ProTextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKandinsky5ProTextToVideoOutput
}

export type GetFalAiKandinsky5ProTextToVideoRequestsByRequestIdResponse =
  GetFalAiKandinsky5ProTextToVideoRequestsByRequestIdResponses[keyof GetFalAiKandinsky5ProTextToVideoRequestsByRequestIdResponses]

export type GetFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/bytedance/seedance/v1.5/pro/text-to-video/requests/{request_id}/status'
  }

export type GetFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/bytedance/seedance/v1.5/pro/text-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiBytedanceSeedanceV15ProTextToVideoData = {
  body: SchemaBytedanceSeedanceV15ProTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/bytedance/seedance/v1.5/pro/text-to-video'
}

export type PostFalAiBytedanceSeedanceV15ProTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiBytedanceSeedanceV15ProTextToVideoResponse =
  PostFalAiBytedanceSeedanceV15ProTextToVideoResponses[keyof PostFalAiBytedanceSeedanceV15ProTextToVideoResponses]

export type GetFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/bytedance/seedance/v1.5/pro/text-to-video/requests/{request_id}'
  }

export type GetFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaBytedanceSeedanceV15ProTextToVideoOutput
  }

export type GetFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdResponse =
  GetFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdResponses[keyof GetFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdResponses]

export type GetWanV26TextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/wan/v2.6/text-to-video/requests/{request_id}/status'
}

export type GetWanV26TextToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetWanV26TextToVideoRequestsByRequestIdStatusResponse =
  GetWanV26TextToVideoRequestsByRequestIdStatusResponses[keyof GetWanV26TextToVideoRequestsByRequestIdStatusResponses]

export type PutWanV26TextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/wan/v2.6/text-to-video/requests/{request_id}/cancel'
}

export type PutWanV26TextToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutWanV26TextToVideoRequestsByRequestIdCancelResponse =
  PutWanV26TextToVideoRequestsByRequestIdCancelResponses[keyof PutWanV26TextToVideoRequestsByRequestIdCancelResponses]

export type PostWanV26TextToVideoData = {
  body: SchemaV26TextToVideoInput
  path?: never
  query?: never
  url: '/wan/v2.6/text-to-video'
}

export type PostWanV26TextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostWanV26TextToVideoResponse =
  PostWanV26TextToVideoResponses[keyof PostWanV26TextToVideoResponses]

export type GetWanV26TextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/wan/v2.6/text-to-video/requests/{request_id}'
}

export type GetWanV26TextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaV26TextToVideoOutput
}

export type GetWanV26TextToVideoRequestsByRequestIdResponse =
  GetWanV26TextToVideoRequestsByRequestIdResponses[keyof GetWanV26TextToVideoRequestsByRequestIdResponses]

export type GetVeedFabric10TextRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/veed/fabric-1.0/text/requests/{request_id}/status'
}

export type GetVeedFabric10TextRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetVeedFabric10TextRequestsByRequestIdStatusResponse =
  GetVeedFabric10TextRequestsByRequestIdStatusResponses[keyof GetVeedFabric10TextRequestsByRequestIdStatusResponses]

export type PutVeedFabric10TextRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/veed/fabric-1.0/text/requests/{request_id}/cancel'
}

export type PutVeedFabric10TextRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutVeedFabric10TextRequestsByRequestIdCancelResponse =
  PutVeedFabric10TextRequestsByRequestIdCancelResponses[keyof PutVeedFabric10TextRequestsByRequestIdCancelResponses]

export type PostVeedFabric10TextData = {
  body: SchemaFabric10TextInput
  path?: never
  query?: never
  url: '/veed/fabric-1.0/text'
}

export type PostVeedFabric10TextResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostVeedFabric10TextResponse =
  PostVeedFabric10TextResponses[keyof PostVeedFabric10TextResponses]

export type GetVeedFabric10TextRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/veed/fabric-1.0/text/requests/{request_id}'
}

export type GetVeedFabric10TextRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaFabric10TextOutput
}

export type GetVeedFabric10TextRequestsByRequestIdResponse =
  GetVeedFabric10TextRequestsByRequestIdResponses[keyof GetVeedFabric10TextRequestsByRequestIdResponses]

export type GetFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kling-video/v2.6/pro/text-to-video/requests/{request_id}/status'
}

export type GetFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v2.6/pro/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV26ProTextToVideoData = {
  body: SchemaKlingVideoV26ProTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v2.6/pro/text-to-video'
}

export type PostFalAiKlingVideoV26ProTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV26ProTextToVideoResponse =
  PostFalAiKlingVideoV26ProTextToVideoResponses[keyof PostFalAiKlingVideoV26ProTextToVideoResponses]

export type GetFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v2.6/pro/text-to-video/requests/{request_id}'
}

export type GetFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKlingVideoV26ProTextToVideoOutput
}

export type GetFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdResponse =
  GetFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdResponses]

export type GetFalAiPixverseV55TextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v5.5/text-to-video/requests/{request_id}/status'
}

export type GetFalAiPixverseV55TextToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPixverseV55TextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV55TextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV55TextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV55TextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v5.5/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV55TextToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPixverseV55TextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV55TextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV55TextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV55TextToVideoData = {
  body: SchemaPixverseV55TextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v5.5/text-to-video'
}

export type PostFalAiPixverseV55TextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV55TextToVideoResponse =
  PostFalAiPixverseV55TextToVideoResponses[keyof PostFalAiPixverseV55TextToVideoResponses]

export type GetFalAiPixverseV55TextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v5.5/text-to-video/requests/{request_id}'
}

export type GetFalAiPixverseV55TextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV55TextToVideoOutput
}

export type GetFalAiPixverseV55TextToVideoRequestsByRequestIdResponse =
  GetFalAiPixverseV55TextToVideoRequestsByRequestIdResponses[keyof GetFalAiPixverseV55TextToVideoRequestsByRequestIdResponses]

export type GetFalAiLtx2TextToVideoFastRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ltx-2/text-to-video/fast/requests/{request_id}/status'
}

export type GetFalAiLtx2TextToVideoFastRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiLtx2TextToVideoFastRequestsByRequestIdStatusResponse =
  GetFalAiLtx2TextToVideoFastRequestsByRequestIdStatusResponses[keyof GetFalAiLtx2TextToVideoFastRequestsByRequestIdStatusResponses]

export type PutFalAiLtx2TextToVideoFastRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-2/text-to-video/fast/requests/{request_id}/cancel'
}

export type PutFalAiLtx2TextToVideoFastRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiLtx2TextToVideoFastRequestsByRequestIdCancelResponse =
  PutFalAiLtx2TextToVideoFastRequestsByRequestIdCancelResponses[keyof PutFalAiLtx2TextToVideoFastRequestsByRequestIdCancelResponses]

export type PostFalAiLtx2TextToVideoFastData = {
  body: SchemaLtx2TextToVideoFastInput
  path?: never
  query?: never
  url: '/fal-ai/ltx-2/text-to-video/fast'
}

export type PostFalAiLtx2TextToVideoFastResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLtx2TextToVideoFastResponse =
  PostFalAiLtx2TextToVideoFastResponses[keyof PostFalAiLtx2TextToVideoFastResponses]

export type GetFalAiLtx2TextToVideoFastRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-2/text-to-video/fast/requests/{request_id}'
}

export type GetFalAiLtx2TextToVideoFastRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLtx2TextToVideoFastOutput
}

export type GetFalAiLtx2TextToVideoFastRequestsByRequestIdResponse =
  GetFalAiLtx2TextToVideoFastRequestsByRequestIdResponses[keyof GetFalAiLtx2TextToVideoFastRequestsByRequestIdResponses]

export type GetFalAiLtx2TextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ltx-2/text-to-video/requests/{request_id}/status'
}

export type GetFalAiLtx2TextToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiLtx2TextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiLtx2TextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiLtx2TextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiLtx2TextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-2/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiLtx2TextToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiLtx2TextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiLtx2TextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiLtx2TextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiLtx2TextToVideoData = {
  body: SchemaLtx2TextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/ltx-2/text-to-video'
}

export type PostFalAiLtx2TextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLtx2TextToVideoResponse =
  PostFalAiLtx2TextToVideoResponses[keyof PostFalAiLtx2TextToVideoResponses]

export type GetFalAiLtx2TextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-2/text-to-video/requests/{request_id}'
}

export type GetFalAiLtx2TextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLtx2TextToVideoOutput
}

export type GetFalAiLtx2TextToVideoRequestsByRequestIdResponse =
  GetFalAiLtx2TextToVideoRequestsByRequestIdResponses[keyof GetFalAiLtx2TextToVideoRequestsByRequestIdResponses]

export type GetFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/hunyuan-video-v1.5/text-to-video/requests/{request_id}/status'
}

export type GetFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/hunyuan-video-v1.5/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiHunyuanVideoV15TextToVideoData = {
  body: SchemaHunyuanVideoV15TextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/hunyuan-video-v1.5/text-to-video'
}

export type PostFalAiHunyuanVideoV15TextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiHunyuanVideoV15TextToVideoResponse =
  PostFalAiHunyuanVideoV15TextToVideoResponses[keyof PostFalAiHunyuanVideoV15TextToVideoResponses]

export type GetFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/hunyuan-video-v1.5/text-to-video/requests/{request_id}'
}

export type GetFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaHunyuanVideoV15TextToVideoOutput
}

export type GetFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdResponse =
  GetFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdResponses[keyof GetFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdResponses]

export type GetFalAiInfinityStarTextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/infinity-star/text-to-video/requests/{request_id}/status'
}

export type GetFalAiInfinityStarTextToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiInfinityStarTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiInfinityStarTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiInfinityStarTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiInfinityStarTextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/infinity-star/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiInfinityStarTextToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiInfinityStarTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiInfinityStarTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiInfinityStarTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiInfinityStarTextToVideoData = {
  body: SchemaInfinityStarTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/infinity-star/text-to-video'
}

export type PostFalAiInfinityStarTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiInfinityStarTextToVideoResponse =
  PostFalAiInfinityStarTextToVideoResponses[keyof PostFalAiInfinityStarTextToVideoResponses]

export type GetFalAiInfinityStarTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/infinity-star/text-to-video/requests/{request_id}'
}

export type GetFalAiInfinityStarTextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaInfinityStarTextToVideoOutput
}

export type GetFalAiInfinityStarTextToVideoRequestsByRequestIdResponse =
  GetFalAiInfinityStarTextToVideoRequestsByRequestIdResponses[keyof GetFalAiInfinityStarTextToVideoRequestsByRequestIdResponses]

export type GetFalAiSanaVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/sana-video/requests/{request_id}/status'
}

export type GetFalAiSanaVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiSanaVideoRequestsByRequestIdStatusResponse =
  GetFalAiSanaVideoRequestsByRequestIdStatusResponses[keyof GetFalAiSanaVideoRequestsByRequestIdStatusResponses]

export type PutFalAiSanaVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/sana-video/requests/{request_id}/cancel'
}

export type PutFalAiSanaVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiSanaVideoRequestsByRequestIdCancelResponse =
  PutFalAiSanaVideoRequestsByRequestIdCancelResponses[keyof PutFalAiSanaVideoRequestsByRequestIdCancelResponses]

export type PostFalAiSanaVideoData = {
  body: SchemaSanaVideoInput
  path?: never
  query?: never
  url: '/fal-ai/sana-video'
}

export type PostFalAiSanaVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiSanaVideoResponse =
  PostFalAiSanaVideoResponses[keyof PostFalAiSanaVideoResponses]

export type GetFalAiSanaVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/sana-video/requests/{request_id}'
}

export type GetFalAiSanaVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaSanaVideoOutput
}

export type GetFalAiSanaVideoRequestsByRequestIdResponse =
  GetFalAiSanaVideoRequestsByRequestIdResponses[keyof GetFalAiSanaVideoRequestsByRequestIdResponses]

export type GetFalAiLongcatVideoTextToVideo720pRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/longcat-video/text-to-video/720p/requests/{request_id}/status'
}

export type GetFalAiLongcatVideoTextToVideo720pRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiLongcatVideoTextToVideo720pRequestsByRequestIdStatusResponse =
  GetFalAiLongcatVideoTextToVideo720pRequestsByRequestIdStatusResponses[keyof GetFalAiLongcatVideoTextToVideo720pRequestsByRequestIdStatusResponses]

export type PutFalAiLongcatVideoTextToVideo720pRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/longcat-video/text-to-video/720p/requests/{request_id}/cancel'
}

export type PutFalAiLongcatVideoTextToVideo720pRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiLongcatVideoTextToVideo720pRequestsByRequestIdCancelResponse =
  PutFalAiLongcatVideoTextToVideo720pRequestsByRequestIdCancelResponses[keyof PutFalAiLongcatVideoTextToVideo720pRequestsByRequestIdCancelResponses]

export type PostFalAiLongcatVideoTextToVideo720pData = {
  body: SchemaLongcatVideoTextToVideo720pInput
  path?: never
  query?: never
  url: '/fal-ai/longcat-video/text-to-video/720p'
}

export type PostFalAiLongcatVideoTextToVideo720pResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLongcatVideoTextToVideo720pResponse =
  PostFalAiLongcatVideoTextToVideo720pResponses[keyof PostFalAiLongcatVideoTextToVideo720pResponses]

export type GetFalAiLongcatVideoTextToVideo720pRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/longcat-video/text-to-video/720p/requests/{request_id}'
}

export type GetFalAiLongcatVideoTextToVideo720pRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLongcatVideoTextToVideo720pOutput
}

export type GetFalAiLongcatVideoTextToVideo720pRequestsByRequestIdResponse =
  GetFalAiLongcatVideoTextToVideo720pRequestsByRequestIdResponses[keyof GetFalAiLongcatVideoTextToVideo720pRequestsByRequestIdResponses]

export type GetFalAiLongcatVideoTextToVideo480pRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/longcat-video/text-to-video/480p/requests/{request_id}/status'
}

export type GetFalAiLongcatVideoTextToVideo480pRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiLongcatVideoTextToVideo480pRequestsByRequestIdStatusResponse =
  GetFalAiLongcatVideoTextToVideo480pRequestsByRequestIdStatusResponses[keyof GetFalAiLongcatVideoTextToVideo480pRequestsByRequestIdStatusResponses]

export type PutFalAiLongcatVideoTextToVideo480pRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/longcat-video/text-to-video/480p/requests/{request_id}/cancel'
}

export type PutFalAiLongcatVideoTextToVideo480pRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiLongcatVideoTextToVideo480pRequestsByRequestIdCancelResponse =
  PutFalAiLongcatVideoTextToVideo480pRequestsByRequestIdCancelResponses[keyof PutFalAiLongcatVideoTextToVideo480pRequestsByRequestIdCancelResponses]

export type PostFalAiLongcatVideoTextToVideo480pData = {
  body: SchemaLongcatVideoTextToVideo480pInput
  path?: never
  query?: never
  url: '/fal-ai/longcat-video/text-to-video/480p'
}

export type PostFalAiLongcatVideoTextToVideo480pResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLongcatVideoTextToVideo480pResponse =
  PostFalAiLongcatVideoTextToVideo480pResponses[keyof PostFalAiLongcatVideoTextToVideo480pResponses]

export type GetFalAiLongcatVideoTextToVideo480pRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/longcat-video/text-to-video/480p/requests/{request_id}'
}

export type GetFalAiLongcatVideoTextToVideo480pRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLongcatVideoTextToVideo480pOutput
}

export type GetFalAiLongcatVideoTextToVideo480pRequestsByRequestIdResponse =
  GetFalAiLongcatVideoTextToVideo480pRequestsByRequestIdResponses[keyof GetFalAiLongcatVideoTextToVideo480pRequestsByRequestIdResponses]

export type GetFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/longcat-video/distilled/text-to-video/720p/requests/{request_id}/status'
  }

export type GetFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdStatusResponse =
  GetFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdStatusResponses[keyof GetFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdStatusResponses]

export type PutFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/longcat-video/distilled/text-to-video/720p/requests/{request_id}/cancel'
  }

export type PutFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdCancelResponse =
  PutFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdCancelResponses[keyof PutFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdCancelResponses]

export type PostFalAiLongcatVideoDistilledTextToVideo720pData = {
  body: SchemaLongcatVideoDistilledTextToVideo720pInput
  path?: never
  query?: never
  url: '/fal-ai/longcat-video/distilled/text-to-video/720p'
}

export type PostFalAiLongcatVideoDistilledTextToVideo720pResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLongcatVideoDistilledTextToVideo720pResponse =
  PostFalAiLongcatVideoDistilledTextToVideo720pResponses[keyof PostFalAiLongcatVideoDistilledTextToVideo720pResponses]

export type GetFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/longcat-video/distilled/text-to-video/720p/requests/{request_id}'
  }

export type GetFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaLongcatVideoDistilledTextToVideo720pOutput
  }

export type GetFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdResponse =
  GetFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdResponses[keyof GetFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdResponses]

export type GetFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/longcat-video/distilled/text-to-video/480p/requests/{request_id}/status'
  }

export type GetFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdStatusResponse =
  GetFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdStatusResponses[keyof GetFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdStatusResponses]

export type PutFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/longcat-video/distilled/text-to-video/480p/requests/{request_id}/cancel'
  }

export type PutFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdCancelResponse =
  PutFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdCancelResponses[keyof PutFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdCancelResponses]

export type PostFalAiLongcatVideoDistilledTextToVideo480pData = {
  body: SchemaLongcatVideoDistilledTextToVideo480pInput
  path?: never
  query?: never
  url: '/fal-ai/longcat-video/distilled/text-to-video/480p'
}

export type PostFalAiLongcatVideoDistilledTextToVideo480pResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLongcatVideoDistilledTextToVideo480pResponse =
  PostFalAiLongcatVideoDistilledTextToVideo480pResponses[keyof PostFalAiLongcatVideoDistilledTextToVideo480pResponses]

export type GetFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/longcat-video/distilled/text-to-video/480p/requests/{request_id}'
  }

export type GetFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaLongcatVideoDistilledTextToVideo480pOutput
  }

export type GetFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdResponse =
  GetFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdResponses[keyof GetFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdResponses]

export type GetFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/minimax/hailuo-2.3/standard/text-to-video/requests/{request_id}/status'
  }

export type GetFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/minimax/hailuo-2.3/standard/text-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiMinimaxHailuo23StandardTextToVideoData = {
  body: SchemaMinimaxHailuo23StandardTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/minimax/hailuo-2.3/standard/text-to-video'
}

export type PostFalAiMinimaxHailuo23StandardTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMinimaxHailuo23StandardTextToVideoResponse =
  PostFalAiMinimaxHailuo23StandardTextToVideoResponses[keyof PostFalAiMinimaxHailuo23StandardTextToVideoResponses]

export type GetFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/minimax/hailuo-2.3/standard/text-to-video/requests/{request_id}'
  }

export type GetFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaMinimaxHailuo23StandardTextToVideoOutput
  }

export type GetFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdResponse =
  GetFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdResponses[keyof GetFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdResponses]

export type GetFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/minimax/hailuo-2.3/pro/text-to-video/requests/{request_id}/status'
  }

export type GetFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/minimax/hailuo-2.3/pro/text-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiMinimaxHailuo23ProTextToVideoData = {
  body: SchemaMinimaxHailuo23ProTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/minimax/hailuo-2.3/pro/text-to-video'
}

export type PostFalAiMinimaxHailuo23ProTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMinimaxHailuo23ProTextToVideoResponse =
  PostFalAiMinimaxHailuo23ProTextToVideoResponses[keyof PostFalAiMinimaxHailuo23ProTextToVideoResponses]

export type GetFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax/hailuo-2.3/pro/text-to-video/requests/{request_id}'
}

export type GetFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaMinimaxHailuo23ProTextToVideoOutput
  }

export type GetFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdResponse =
  GetFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdResponses[keyof GetFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdResponses]

export type GetFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/bytedance/seedance/v1/pro/fast/text-to-video/requests/{request_id}/status'
  }

export type GetFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/bytedance/seedance/v1/pro/fast/text-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiBytedanceSeedanceV1ProFastTextToVideoData = {
  body: SchemaBytedanceSeedanceV1ProFastTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/bytedance/seedance/v1/pro/fast/text-to-video'
}

export type PostFalAiBytedanceSeedanceV1ProFastTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiBytedanceSeedanceV1ProFastTextToVideoResponse =
  PostFalAiBytedanceSeedanceV1ProFastTextToVideoResponses[keyof PostFalAiBytedanceSeedanceV1ProFastTextToVideoResponses]

export type GetFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/bytedance/seedance/v1/pro/fast/text-to-video/requests/{request_id}'
  }

export type GetFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaBytedanceSeedanceV1ProFastTextToVideoOutput
  }

export type GetFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdResponse =
  GetFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdResponses[keyof GetFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdResponses]

export type GetFalAiViduQ2TextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/vidu/q2/text-to-video/requests/{request_id}/status'
}

export type GetFalAiViduQ2TextToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiViduQ2TextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiViduQ2TextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiViduQ2TextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiViduQ2TextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/vidu/q2/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiViduQ2TextToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiViduQ2TextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiViduQ2TextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiViduQ2TextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiViduQ2TextToVideoData = {
  body: SchemaViduQ2TextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/vidu/q2/text-to-video'
}

export type PostFalAiViduQ2TextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiViduQ2TextToVideoResponse =
  PostFalAiViduQ2TextToVideoResponses[keyof PostFalAiViduQ2TextToVideoResponses]

export type GetFalAiViduQ2TextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/vidu/q2/text-to-video/requests/{request_id}'
}

export type GetFalAiViduQ2TextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaViduQ2TextToVideoOutput
}

export type GetFalAiViduQ2TextToVideoRequestsByRequestIdResponse =
  GetFalAiViduQ2TextToVideoRequestsByRequestIdResponses[keyof GetFalAiViduQ2TextToVideoRequestsByRequestIdResponses]

export type GetFalAiKreaWan14bTextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/krea-wan-14b/text-to-video/requests/{request_id}/status'
}

export type GetFalAiKreaWan14bTextToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiKreaWan14bTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKreaWan14bTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKreaWan14bTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKreaWan14bTextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/krea-wan-14b/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiKreaWan14bTextToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiKreaWan14bTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKreaWan14bTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKreaWan14bTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKreaWan14bTextToVideoData = {
  body: SchemaKreaWan14bTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/krea-wan-14b/text-to-video'
}

export type PostFalAiKreaWan14bTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKreaWan14bTextToVideoResponse =
  PostFalAiKreaWan14bTextToVideoResponses[keyof PostFalAiKreaWan14bTextToVideoResponses]

export type GetFalAiKreaWan14bTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/krea-wan-14b/text-to-video/requests/{request_id}'
}

export type GetFalAiKreaWan14bTextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKreaWan14bTextToVideoOutput
}

export type GetFalAiKreaWan14bTextToVideoRequestsByRequestIdResponse =
  GetFalAiKreaWan14bTextToVideoRequestsByRequestIdResponses[keyof GetFalAiKreaWan14bTextToVideoRequestsByRequestIdResponses]

export type GetFalAiWanAlphaRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/wan-alpha/requests/{request_id}/status'
}

export type GetFalAiWanAlphaRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiWanAlphaRequestsByRequestIdStatusResponse =
  GetFalAiWanAlphaRequestsByRequestIdStatusResponses[keyof GetFalAiWanAlphaRequestsByRequestIdStatusResponses]

export type PutFalAiWanAlphaRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan-alpha/requests/{request_id}/cancel'
}

export type PutFalAiWanAlphaRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiWanAlphaRequestsByRequestIdCancelResponse =
  PutFalAiWanAlphaRequestsByRequestIdCancelResponses[keyof PutFalAiWanAlphaRequestsByRequestIdCancelResponses]

export type PostFalAiWanAlphaData = {
  body: SchemaWanAlphaInput
  path?: never
  query?: never
  url: '/fal-ai/wan-alpha'
}

export type PostFalAiWanAlphaResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiWanAlphaResponse =
  PostFalAiWanAlphaResponses[keyof PostFalAiWanAlphaResponses]

export type GetFalAiWanAlphaRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan-alpha/requests/{request_id}'
}

export type GetFalAiWanAlphaRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaWanAlphaOutput
}

export type GetFalAiWanAlphaRequestsByRequestIdResponse =
  GetFalAiWanAlphaRequestsByRequestIdResponses[keyof GetFalAiWanAlphaRequestsByRequestIdResponses]

export type GetFalAiKandinsky5TextToVideoDistillRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/kandinsky5/text-to-video/distill/requests/{request_id}/status'
  }

export type GetFalAiKandinsky5TextToVideoDistillRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKandinsky5TextToVideoDistillRequestsByRequestIdStatusResponse =
  GetFalAiKandinsky5TextToVideoDistillRequestsByRequestIdStatusResponses[keyof GetFalAiKandinsky5TextToVideoDistillRequestsByRequestIdStatusResponses]

export type PutFalAiKandinsky5TextToVideoDistillRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kandinsky5/text-to-video/distill/requests/{request_id}/cancel'
  }

export type PutFalAiKandinsky5TextToVideoDistillRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKandinsky5TextToVideoDistillRequestsByRequestIdCancelResponse =
  PutFalAiKandinsky5TextToVideoDistillRequestsByRequestIdCancelResponses[keyof PutFalAiKandinsky5TextToVideoDistillRequestsByRequestIdCancelResponses]

export type PostFalAiKandinsky5TextToVideoDistillData = {
  body: SchemaKandinsky5TextToVideoDistillInput
  path?: never
  query?: never
  url: '/fal-ai/kandinsky5/text-to-video/distill'
}

export type PostFalAiKandinsky5TextToVideoDistillResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKandinsky5TextToVideoDistillResponse =
  PostFalAiKandinsky5TextToVideoDistillResponses[keyof PostFalAiKandinsky5TextToVideoDistillResponses]

export type GetFalAiKandinsky5TextToVideoDistillRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kandinsky5/text-to-video/distill/requests/{request_id}'
}

export type GetFalAiKandinsky5TextToVideoDistillRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKandinsky5TextToVideoDistillOutput
}

export type GetFalAiKandinsky5TextToVideoDistillRequestsByRequestIdResponse =
  GetFalAiKandinsky5TextToVideoDistillRequestsByRequestIdResponses[keyof GetFalAiKandinsky5TextToVideoDistillRequestsByRequestIdResponses]

export type GetFalAiKandinsky5TextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kandinsky5/text-to-video/requests/{request_id}/status'
}

export type GetFalAiKandinsky5TextToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiKandinsky5TextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKandinsky5TextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKandinsky5TextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKandinsky5TextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kandinsky5/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiKandinsky5TextToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiKandinsky5TextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKandinsky5TextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKandinsky5TextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKandinsky5TextToVideoData = {
  body: SchemaKandinsky5TextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kandinsky5/text-to-video'
}

export type PostFalAiKandinsky5TextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKandinsky5TextToVideoResponse =
  PostFalAiKandinsky5TextToVideoResponses[keyof PostFalAiKandinsky5TextToVideoResponses]

export type GetFalAiKandinsky5TextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kandinsky5/text-to-video/requests/{request_id}'
}

export type GetFalAiKandinsky5TextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKandinsky5TextToVideoOutput
}

export type GetFalAiKandinsky5TextToVideoRequestsByRequestIdResponse =
  GetFalAiKandinsky5TextToVideoRequestsByRequestIdResponses[keyof GetFalAiKandinsky5TextToVideoRequestsByRequestIdResponses]

export type GetFalAiVeo31FastRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/veo3.1/fast/requests/{request_id}/status'
}

export type GetFalAiVeo31FastRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiVeo31FastRequestsByRequestIdStatusResponse =
  GetFalAiVeo31FastRequestsByRequestIdStatusResponses[keyof GetFalAiVeo31FastRequestsByRequestIdStatusResponses]

export type PutFalAiVeo31FastRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/veo3.1/fast/requests/{request_id}/cancel'
}

export type PutFalAiVeo31FastRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiVeo31FastRequestsByRequestIdCancelResponse =
  PutFalAiVeo31FastRequestsByRequestIdCancelResponses[keyof PutFalAiVeo31FastRequestsByRequestIdCancelResponses]

export type PostFalAiVeo31FastData = {
  body: SchemaVeo31FastInput
  path?: never
  query?: never
  url: '/fal-ai/veo3.1/fast'
}

export type PostFalAiVeo31FastResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiVeo31FastResponse =
  PostFalAiVeo31FastResponses[keyof PostFalAiVeo31FastResponses]

export type GetFalAiVeo31FastRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/veo3.1/fast/requests/{request_id}'
}

export type GetFalAiVeo31FastRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaVeo31FastOutput
}

export type GetFalAiVeo31FastRequestsByRequestIdResponse =
  GetFalAiVeo31FastRequestsByRequestIdResponses[keyof GetFalAiVeo31FastRequestsByRequestIdResponses]

export type GetFalAiVeo31RequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/veo3.1/requests/{request_id}/status'
}

export type GetFalAiVeo31RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiVeo31RequestsByRequestIdStatusResponse =
  GetFalAiVeo31RequestsByRequestIdStatusResponses[keyof GetFalAiVeo31RequestsByRequestIdStatusResponses]

export type PutFalAiVeo31RequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/veo3.1/requests/{request_id}/cancel'
}

export type PutFalAiVeo31RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiVeo31RequestsByRequestIdCancelResponse =
  PutFalAiVeo31RequestsByRequestIdCancelResponses[keyof PutFalAiVeo31RequestsByRequestIdCancelResponses]

export type PostFalAiVeo31Data = {
  body: SchemaVeo31Input
  path?: never
  query?: never
  url: '/fal-ai/veo3.1'
}

export type PostFalAiVeo31Responses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiVeo31Response =
  PostFalAiVeo31Responses[keyof PostFalAiVeo31Responses]

export type GetFalAiVeo31RequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/veo3.1/requests/{request_id}'
}

export type GetFalAiVeo31RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaVeo31Output
}

export type GetFalAiVeo31RequestsByRequestIdResponse =
  GetFalAiVeo31RequestsByRequestIdResponses[keyof GetFalAiVeo31RequestsByRequestIdResponses]

export type GetFalAiSora2TextToVideoProRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/sora-2/text-to-video/pro/requests/{request_id}/status'
}

export type GetFalAiSora2TextToVideoProRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiSora2TextToVideoProRequestsByRequestIdStatusResponse =
  GetFalAiSora2TextToVideoProRequestsByRequestIdStatusResponses[keyof GetFalAiSora2TextToVideoProRequestsByRequestIdStatusResponses]

export type PutFalAiSora2TextToVideoProRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/sora-2/text-to-video/pro/requests/{request_id}/cancel'
}

export type PutFalAiSora2TextToVideoProRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiSora2TextToVideoProRequestsByRequestIdCancelResponse =
  PutFalAiSora2TextToVideoProRequestsByRequestIdCancelResponses[keyof PutFalAiSora2TextToVideoProRequestsByRequestIdCancelResponses]

export type PostFalAiSora2TextToVideoProData = {
  body: SchemaSora2TextToVideoProInput
  path?: never
  query?: never
  url: '/fal-ai/sora-2/text-to-video/pro'
}

export type PostFalAiSora2TextToVideoProResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiSora2TextToVideoProResponse =
  PostFalAiSora2TextToVideoProResponses[keyof PostFalAiSora2TextToVideoProResponses]

export type GetFalAiSora2TextToVideoProRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/sora-2/text-to-video/pro/requests/{request_id}'
}

export type GetFalAiSora2TextToVideoProRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaSora2TextToVideoProOutput
}

export type GetFalAiSora2TextToVideoProRequestsByRequestIdResponse =
  GetFalAiSora2TextToVideoProRequestsByRequestIdResponses[keyof GetFalAiSora2TextToVideoProRequestsByRequestIdResponses]

export type GetFalAiSora2TextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/sora-2/text-to-video/requests/{request_id}/status'
}

export type GetFalAiSora2TextToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiSora2TextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiSora2TextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiSora2TextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiSora2TextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/sora-2/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiSora2TextToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiSora2TextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiSora2TextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiSora2TextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiSora2TextToVideoData = {
  body: SchemaSora2TextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/sora-2/text-to-video'
}

export type PostFalAiSora2TextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiSora2TextToVideoResponse =
  PostFalAiSora2TextToVideoResponses[keyof PostFalAiSora2TextToVideoResponses]

export type GetFalAiSora2TextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/sora-2/text-to-video/requests/{request_id}'
}

export type GetFalAiSora2TextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaSora2TextToVideoOutput
}

export type GetFalAiSora2TextToVideoRequestsByRequestIdResponse =
  GetFalAiSora2TextToVideoRequestsByRequestIdResponses[keyof GetFalAiSora2TextToVideoRequestsByRequestIdResponses]

export type GetFalAiOviRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ovi/requests/{request_id}/status'
}

export type GetFalAiOviRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiOviRequestsByRequestIdStatusResponse =
  GetFalAiOviRequestsByRequestIdStatusResponses[keyof GetFalAiOviRequestsByRequestIdStatusResponses]

export type PutFalAiOviRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ovi/requests/{request_id}/cancel'
}

export type PutFalAiOviRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiOviRequestsByRequestIdCancelResponse =
  PutFalAiOviRequestsByRequestIdCancelResponses[keyof PutFalAiOviRequestsByRequestIdCancelResponses]

export type PostFalAiOviData = {
  body: SchemaOviInput
  path?: never
  query?: never
  url: '/fal-ai/ovi'
}

export type PostFalAiOviResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiOviResponse =
  PostFalAiOviResponses[keyof PostFalAiOviResponses]

export type GetFalAiOviRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ovi/requests/{request_id}'
}

export type GetFalAiOviRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaOviOutput
}

export type GetFalAiOviRequestsByRequestIdResponse =
  GetFalAiOviRequestsByRequestIdResponses[keyof GetFalAiOviRequestsByRequestIdResponses]

export type GetFalAiWan25PreviewTextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/wan-25-preview/text-to-video/requests/{request_id}/status'
}

export type GetFalAiWan25PreviewTextToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiWan25PreviewTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiWan25PreviewTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiWan25PreviewTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiWan25PreviewTextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan-25-preview/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiWan25PreviewTextToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiWan25PreviewTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiWan25PreviewTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiWan25PreviewTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiWan25PreviewTextToVideoData = {
  body: SchemaWan25PreviewTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/wan-25-preview/text-to-video'
}

export type PostFalAiWan25PreviewTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiWan25PreviewTextToVideoResponse =
  PostFalAiWan25PreviewTextToVideoResponses[keyof PostFalAiWan25PreviewTextToVideoResponses]

export type GetFalAiWan25PreviewTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan-25-preview/text-to-video/requests/{request_id}'
}

export type GetFalAiWan25PreviewTextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaWan25PreviewTextToVideoOutput
}

export type GetFalAiWan25PreviewTextToVideoRequestsByRequestIdResponse =
  GetFalAiWan25PreviewTextToVideoRequestsByRequestIdResponses[keyof GetFalAiWan25PreviewTextToVideoRequestsByRequestIdResponses]

export type GetArgilAvatarsTextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/argil/avatars/text-to-video/requests/{request_id}/status'
}

export type GetArgilAvatarsTextToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetArgilAvatarsTextToVideoRequestsByRequestIdStatusResponse =
  GetArgilAvatarsTextToVideoRequestsByRequestIdStatusResponses[keyof GetArgilAvatarsTextToVideoRequestsByRequestIdStatusResponses]

export type PutArgilAvatarsTextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/argil/avatars/text-to-video/requests/{request_id}/cancel'
}

export type PutArgilAvatarsTextToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutArgilAvatarsTextToVideoRequestsByRequestIdCancelResponse =
  PutArgilAvatarsTextToVideoRequestsByRequestIdCancelResponses[keyof PutArgilAvatarsTextToVideoRequestsByRequestIdCancelResponses]

export type PostArgilAvatarsTextToVideoData = {
  body: SchemaAvatarsTextToVideoInput
  path?: never
  query?: never
  url: '/argil/avatars/text-to-video'
}

export type PostArgilAvatarsTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostArgilAvatarsTextToVideoResponse =
  PostArgilAvatarsTextToVideoResponses[keyof PostArgilAvatarsTextToVideoResponses]

export type GetArgilAvatarsTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/argil/avatars/text-to-video/requests/{request_id}'
}

export type GetArgilAvatarsTextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaAvatarsTextToVideoOutput
}

export type GetArgilAvatarsTextToVideoRequestsByRequestIdResponse =
  GetArgilAvatarsTextToVideoRequestsByRequestIdResponses[keyof GetArgilAvatarsTextToVideoRequestsByRequestIdResponses]

export type GetFalAiPixverseV5TextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v5/text-to-video/requests/{request_id}/status'
}

export type GetFalAiPixverseV5TextToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPixverseV5TextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV5TextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV5TextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV5TextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v5/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV5TextToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPixverseV5TextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV5TextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV5TextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV5TextToVideoData = {
  body: SchemaPixverseV5TextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v5/text-to-video'
}

export type PostFalAiPixverseV5TextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV5TextToVideoResponse =
  PostFalAiPixverseV5TextToVideoResponses[keyof PostFalAiPixverseV5TextToVideoResponses]

export type GetFalAiPixverseV5TextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v5/text-to-video/requests/{request_id}'
}

export type GetFalAiPixverseV5TextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV5TextToVideoOutput
}

export type GetFalAiPixverseV5TextToVideoRequestsByRequestIdResponse =
  GetFalAiPixverseV5TextToVideoRequestsByRequestIdResponses[keyof GetFalAiPixverseV5TextToVideoRequestsByRequestIdResponses]

export type GetFalAiInfinitalkSingleTextRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/infinitalk/single-text/requests/{request_id}/status'
}

export type GetFalAiInfinitalkSingleTextRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiInfinitalkSingleTextRequestsByRequestIdStatusResponse =
  GetFalAiInfinitalkSingleTextRequestsByRequestIdStatusResponses[keyof GetFalAiInfinitalkSingleTextRequestsByRequestIdStatusResponses]

export type PutFalAiInfinitalkSingleTextRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/infinitalk/single-text/requests/{request_id}/cancel'
}

export type PutFalAiInfinitalkSingleTextRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiInfinitalkSingleTextRequestsByRequestIdCancelResponse =
  PutFalAiInfinitalkSingleTextRequestsByRequestIdCancelResponses[keyof PutFalAiInfinitalkSingleTextRequestsByRequestIdCancelResponses]

export type PostFalAiInfinitalkSingleTextData = {
  body: SchemaInfinitalkSingleTextInput
  path?: never
  query?: never
  url: '/fal-ai/infinitalk/single-text'
}

export type PostFalAiInfinitalkSingleTextResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiInfinitalkSingleTextResponse =
  PostFalAiInfinitalkSingleTextResponses[keyof PostFalAiInfinitalkSingleTextResponses]

export type GetFalAiInfinitalkSingleTextRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/infinitalk/single-text/requests/{request_id}'
}

export type GetFalAiInfinitalkSingleTextRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaInfinitalkSingleTextOutput
}

export type GetFalAiInfinitalkSingleTextRequestsByRequestIdResponse =
  GetFalAiInfinitalkSingleTextRequestsByRequestIdResponses[keyof GetFalAiInfinitalkSingleTextRequestsByRequestIdResponses]

export type GetMoonvalleyMareyT2vRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/moonvalley/marey/t2v/requests/{request_id}/status'
}

export type GetMoonvalleyMareyT2vRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetMoonvalleyMareyT2vRequestsByRequestIdStatusResponse =
  GetMoonvalleyMareyT2vRequestsByRequestIdStatusResponses[keyof GetMoonvalleyMareyT2vRequestsByRequestIdStatusResponses]

export type PutMoonvalleyMareyT2vRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/moonvalley/marey/t2v/requests/{request_id}/cancel'
}

export type PutMoonvalleyMareyT2vRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutMoonvalleyMareyT2vRequestsByRequestIdCancelResponse =
  PutMoonvalleyMareyT2vRequestsByRequestIdCancelResponses[keyof PutMoonvalleyMareyT2vRequestsByRequestIdCancelResponses]

export type PostMoonvalleyMareyT2vData = {
  body: SchemaMareyT2vInput
  path?: never
  query?: never
  url: '/moonvalley/marey/t2v'
}

export type PostMoonvalleyMareyT2vResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostMoonvalleyMareyT2vResponse =
  PostMoonvalleyMareyT2vResponses[keyof PostMoonvalleyMareyT2vResponses]

export type GetMoonvalleyMareyT2vRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/moonvalley/marey/t2v/requests/{request_id}'
}

export type GetMoonvalleyMareyT2vRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaMareyT2vOutput
}

export type GetMoonvalleyMareyT2vRequestsByRequestIdResponse =
  GetMoonvalleyMareyT2vRequestsByRequestIdResponses[keyof GetMoonvalleyMareyT2vRequestsByRequestIdResponses]

export type GetFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/wan/v2.2-a14b/text-to-video/lora/requests/{request_id}/status'
}

export type GetFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdStatusResponse =
  GetFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdStatusResponses[keyof GetFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdStatusResponses]

export type PutFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan/v2.2-a14b/text-to-video/lora/requests/{request_id}/cancel'
}

export type PutFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdCancelResponse =
  PutFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdCancelResponses[keyof PutFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdCancelResponses]

export type PostFalAiWanV22A14bTextToVideoLoraData = {
  body: SchemaWanV22A14bTextToVideoLoraInput
  path?: never
  query?: never
  url: '/fal-ai/wan/v2.2-a14b/text-to-video/lora'
}

export type PostFalAiWanV22A14bTextToVideoLoraResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiWanV22A14bTextToVideoLoraResponse =
  PostFalAiWanV22A14bTextToVideoLoraResponses[keyof PostFalAiWanV22A14bTextToVideoLoraResponses]

export type GetFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan/v2.2-a14b/text-to-video/lora/requests/{request_id}'
}

export type GetFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaWanV22A14bTextToVideoLoraOutput
}

export type GetFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdResponse =
  GetFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdResponses[keyof GetFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdResponses]

export type GetFalAiWanV225bTextToVideoDistillRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/wan/v2.2-5b/text-to-video/distill/requests/{request_id}/status'
}

export type GetFalAiWanV225bTextToVideoDistillRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiWanV225bTextToVideoDistillRequestsByRequestIdStatusResponse =
  GetFalAiWanV225bTextToVideoDistillRequestsByRequestIdStatusResponses[keyof GetFalAiWanV225bTextToVideoDistillRequestsByRequestIdStatusResponses]

export type PutFalAiWanV225bTextToVideoDistillRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan/v2.2-5b/text-to-video/distill/requests/{request_id}/cancel'
}

export type PutFalAiWanV225bTextToVideoDistillRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiWanV225bTextToVideoDistillRequestsByRequestIdCancelResponse =
  PutFalAiWanV225bTextToVideoDistillRequestsByRequestIdCancelResponses[keyof PutFalAiWanV225bTextToVideoDistillRequestsByRequestIdCancelResponses]

export type PostFalAiWanV225bTextToVideoDistillData = {
  body: SchemaWanV225bTextToVideoDistillInput
  path?: never
  query?: never
  url: '/fal-ai/wan/v2.2-5b/text-to-video/distill'
}

export type PostFalAiWanV225bTextToVideoDistillResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiWanV225bTextToVideoDistillResponse =
  PostFalAiWanV225bTextToVideoDistillResponses[keyof PostFalAiWanV225bTextToVideoDistillResponses]

export type GetFalAiWanV225bTextToVideoDistillRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan/v2.2-5b/text-to-video/distill/requests/{request_id}'
}

export type GetFalAiWanV225bTextToVideoDistillRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaWanV225bTextToVideoDistillOutput
}

export type GetFalAiWanV225bTextToVideoDistillRequestsByRequestIdResponse =
  GetFalAiWanV225bTextToVideoDistillRequestsByRequestIdResponses[keyof GetFalAiWanV225bTextToVideoDistillRequestsByRequestIdResponses]

export type GetFalAiWanV225bTextToVideoFastWanRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/wan/v2.2-5b/text-to-video/fast-wan/requests/{request_id}/status'
}

export type GetFalAiWanV225bTextToVideoFastWanRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiWanV225bTextToVideoFastWanRequestsByRequestIdStatusResponse =
  GetFalAiWanV225bTextToVideoFastWanRequestsByRequestIdStatusResponses[keyof GetFalAiWanV225bTextToVideoFastWanRequestsByRequestIdStatusResponses]

export type PutFalAiWanV225bTextToVideoFastWanRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan/v2.2-5b/text-to-video/fast-wan/requests/{request_id}/cancel'
}

export type PutFalAiWanV225bTextToVideoFastWanRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiWanV225bTextToVideoFastWanRequestsByRequestIdCancelResponse =
  PutFalAiWanV225bTextToVideoFastWanRequestsByRequestIdCancelResponses[keyof PutFalAiWanV225bTextToVideoFastWanRequestsByRequestIdCancelResponses]

export type PostFalAiWanV225bTextToVideoFastWanData = {
  body: SchemaWanV225bTextToVideoFastWanInput
  path?: never
  query?: never
  url: '/fal-ai/wan/v2.2-5b/text-to-video/fast-wan'
}

export type PostFalAiWanV225bTextToVideoFastWanResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiWanV225bTextToVideoFastWanResponse =
  PostFalAiWanV225bTextToVideoFastWanResponses[keyof PostFalAiWanV225bTextToVideoFastWanResponses]

export type GetFalAiWanV225bTextToVideoFastWanRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan/v2.2-5b/text-to-video/fast-wan/requests/{request_id}'
}

export type GetFalAiWanV225bTextToVideoFastWanRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaWanV225bTextToVideoFastWanOutput
}

export type GetFalAiWanV225bTextToVideoFastWanRequestsByRequestIdResponse =
  GetFalAiWanV225bTextToVideoFastWanRequestsByRequestIdResponses[keyof GetFalAiWanV225bTextToVideoFastWanRequestsByRequestIdResponses]

export type GetFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/wan/v2.2-a14b/text-to-video/turbo/requests/{request_id}/status'
}

export type GetFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdStatusResponse =
  GetFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdStatusResponses[keyof GetFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdStatusResponses]

export type PutFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan/v2.2-a14b/text-to-video/turbo/requests/{request_id}/cancel'
}

export type PutFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdCancelResponse =
  PutFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdCancelResponses[keyof PutFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdCancelResponses]

export type PostFalAiWanV22A14bTextToVideoTurboData = {
  body: SchemaWanV22A14bTextToVideoTurboInput
  path?: never
  query?: never
  url: '/fal-ai/wan/v2.2-a14b/text-to-video/turbo'
}

export type PostFalAiWanV22A14bTextToVideoTurboResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiWanV22A14bTextToVideoTurboResponse =
  PostFalAiWanV22A14bTextToVideoTurboResponses[keyof PostFalAiWanV22A14bTextToVideoTurboResponses]

export type GetFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan/v2.2-a14b/text-to-video/turbo/requests/{request_id}'
}

export type GetFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaWanV22A14bTextToVideoTurboOutput
}

export type GetFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdResponse =
  GetFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdResponses[keyof GetFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdResponses]

export type GetFalAiWanV225bTextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/wan/v2.2-5b/text-to-video/requests/{request_id}/status'
}

export type GetFalAiWanV225bTextToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiWanV225bTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiWanV225bTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiWanV225bTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiWanV225bTextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan/v2.2-5b/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiWanV225bTextToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiWanV225bTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiWanV225bTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiWanV225bTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiWanV225bTextToVideoData = {
  body: SchemaWanV225bTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/wan/v2.2-5b/text-to-video'
}

export type PostFalAiWanV225bTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiWanV225bTextToVideoResponse =
  PostFalAiWanV225bTextToVideoResponses[keyof PostFalAiWanV225bTextToVideoResponses]

export type GetFalAiWanV225bTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan/v2.2-5b/text-to-video/requests/{request_id}'
}

export type GetFalAiWanV225bTextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaWanV225bTextToVideoOutput
}

export type GetFalAiWanV225bTextToVideoRequestsByRequestIdResponse =
  GetFalAiWanV225bTextToVideoRequestsByRequestIdResponses[keyof GetFalAiWanV225bTextToVideoRequestsByRequestIdResponses]

export type GetFalAiWanV22A14bTextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/wan/v2.2-a14b/text-to-video/requests/{request_id}/status'
}

export type GetFalAiWanV22A14bTextToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiWanV22A14bTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiWanV22A14bTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiWanV22A14bTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiWanV22A14bTextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan/v2.2-a14b/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiWanV22A14bTextToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiWanV22A14bTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiWanV22A14bTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiWanV22A14bTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiWanV22A14bTextToVideoData = {
  body: SchemaWanV22A14bTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/wan/v2.2-a14b/text-to-video'
}

export type PostFalAiWanV22A14bTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiWanV22A14bTextToVideoResponse =
  PostFalAiWanV22A14bTextToVideoResponses[keyof PostFalAiWanV22A14bTextToVideoResponses]

export type GetFalAiWanV22A14bTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan/v2.2-a14b/text-to-video/requests/{request_id}'
}

export type GetFalAiWanV22A14bTextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaWanV22A14bTextToVideoOutput
}

export type GetFalAiWanV22A14bTextToVideoRequestsByRequestIdResponse =
  GetFalAiWanV22A14bTextToVideoRequestsByRequestIdResponses[keyof GetFalAiWanV22A14bTextToVideoRequestsByRequestIdResponses]

export type GetFalAiLtxv13B098DistilledRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ltxv-13b-098-distilled/requests/{request_id}/status'
}

export type GetFalAiLtxv13B098DistilledRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiLtxv13B098DistilledRequestsByRequestIdStatusResponse =
  GetFalAiLtxv13B098DistilledRequestsByRequestIdStatusResponses[keyof GetFalAiLtxv13B098DistilledRequestsByRequestIdStatusResponses]

export type PutFalAiLtxv13B098DistilledRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltxv-13b-098-distilled/requests/{request_id}/cancel'
}

export type PutFalAiLtxv13B098DistilledRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiLtxv13B098DistilledRequestsByRequestIdCancelResponse =
  PutFalAiLtxv13B098DistilledRequestsByRequestIdCancelResponses[keyof PutFalAiLtxv13B098DistilledRequestsByRequestIdCancelResponses]

export type PostFalAiLtxv13B098DistilledData = {
  body: SchemaLtxv13B098DistilledInput
  path?: never
  query?: never
  url: '/fal-ai/ltxv-13b-098-distilled'
}

export type PostFalAiLtxv13B098DistilledResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLtxv13B098DistilledResponse =
  PostFalAiLtxv13B098DistilledResponses[keyof PostFalAiLtxv13B098DistilledResponses]

export type GetFalAiLtxv13B098DistilledRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltxv-13b-098-distilled/requests/{request_id}'
}

export type GetFalAiLtxv13B098DistilledRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLtxv13B098DistilledOutput
}

export type GetFalAiLtxv13B098DistilledRequestsByRequestIdResponse =
  GetFalAiLtxv13B098DistilledRequestsByRequestIdResponses[keyof GetFalAiLtxv13B098DistilledRequestsByRequestIdResponses]

export type GetFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/minimax/hailuo-02/pro/text-to-video/requests/{request_id}/status'
  }

export type GetFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/minimax/hailuo-02/pro/text-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiMinimaxHailuo02ProTextToVideoData = {
  body: SchemaMinimaxHailuo02ProTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/minimax/hailuo-02/pro/text-to-video'
}

export type PostFalAiMinimaxHailuo02ProTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMinimaxHailuo02ProTextToVideoResponse =
  PostFalAiMinimaxHailuo02ProTextToVideoResponses[keyof PostFalAiMinimaxHailuo02ProTextToVideoResponses]

export type GetFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax/hailuo-02/pro/text-to-video/requests/{request_id}'
}

export type GetFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaMinimaxHailuo02ProTextToVideoOutput
  }

export type GetFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdResponse =
  GetFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdResponses[keyof GetFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdResponses]

export type GetFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/bytedance/seedance/v1/pro/text-to-video/requests/{request_id}/status'
  }

export type GetFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/bytedance/seedance/v1/pro/text-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiBytedanceSeedanceV1ProTextToVideoData = {
  body: SchemaBytedanceSeedanceV1ProTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/bytedance/seedance/v1/pro/text-to-video'
}

export type PostFalAiBytedanceSeedanceV1ProTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiBytedanceSeedanceV1ProTextToVideoResponse =
  PostFalAiBytedanceSeedanceV1ProTextToVideoResponses[keyof PostFalAiBytedanceSeedanceV1ProTextToVideoResponses]

export type GetFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/bytedance/seedance/v1/pro/text-to-video/requests/{request_id}'
}

export type GetFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaBytedanceSeedanceV1ProTextToVideoOutput
  }

export type GetFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdResponse =
  GetFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdResponses[keyof GetFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdResponses]

export type GetFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/bytedance/seedance/v1/lite/text-to-video/requests/{request_id}/status'
  }

export type GetFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/bytedance/seedance/v1/lite/text-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiBytedanceSeedanceV1LiteTextToVideoData = {
  body: SchemaBytedanceSeedanceV1LiteTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/bytedance/seedance/v1/lite/text-to-video'
}

export type PostFalAiBytedanceSeedanceV1LiteTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiBytedanceSeedanceV1LiteTextToVideoResponse =
  PostFalAiBytedanceSeedanceV1LiteTextToVideoResponses[keyof PostFalAiBytedanceSeedanceV1LiteTextToVideoResponses]

export type GetFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/bytedance/seedance/v1/lite/text-to-video/requests/{request_id}'
  }

export type GetFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaBytedanceSeedanceV1LiteTextToVideoOutput
  }

export type GetFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdResponse =
  GetFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdResponses[keyof GetFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdResponses]

export type GetFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/kling-video/v2.1/master/text-to-video/requests/{request_id}/status'
  }

export type GetFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/v2.1/master/text-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV21MasterTextToVideoData = {
  body: SchemaKlingVideoV21MasterTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v2.1/master/text-to-video'
}

export type PostFalAiKlingVideoV21MasterTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV21MasterTextToVideoResponse =
  PostFalAiKlingVideoV21MasterTextToVideoResponses[keyof PostFalAiKlingVideoV21MasterTextToVideoResponses]

export type GetFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v2.1/master/text-to-video/requests/{request_id}'
}

export type GetFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaKlingVideoV21MasterTextToVideoOutput
  }

export type GetFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdResponse =
  GetFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdResponses]

export type GetVeedAvatarsTextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/veed/avatars/text-to-video/requests/{request_id}/status'
}

export type GetVeedAvatarsTextToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetVeedAvatarsTextToVideoRequestsByRequestIdStatusResponse =
  GetVeedAvatarsTextToVideoRequestsByRequestIdStatusResponses[keyof GetVeedAvatarsTextToVideoRequestsByRequestIdStatusResponses]

export type PutVeedAvatarsTextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/veed/avatars/text-to-video/requests/{request_id}/cancel'
}

export type PutVeedAvatarsTextToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutVeedAvatarsTextToVideoRequestsByRequestIdCancelResponse =
  PutVeedAvatarsTextToVideoRequestsByRequestIdCancelResponses[keyof PutVeedAvatarsTextToVideoRequestsByRequestIdCancelResponses]

export type PostVeedAvatarsTextToVideoData = {
  body: SchemaAvatarsTextToVideoInput
  path?: never
  query?: never
  url: '/veed/avatars/text-to-video'
}

export type PostVeedAvatarsTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostVeedAvatarsTextToVideoResponse =
  PostVeedAvatarsTextToVideoResponses[keyof PostVeedAvatarsTextToVideoResponses]

export type GetVeedAvatarsTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/veed/avatars/text-to-video/requests/{request_id}'
}

export type GetVeedAvatarsTextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaAvatarsTextToVideoOutput
}

export type GetVeedAvatarsTextToVideoRequestsByRequestIdResponse =
  GetVeedAvatarsTextToVideoRequestsByRequestIdResponses[keyof GetVeedAvatarsTextToVideoRequestsByRequestIdResponses]

export type GetFalAiLtxVideo13bDevRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ltx-video-13b-dev/requests/{request_id}/status'
}

export type GetFalAiLtxVideo13bDevRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiLtxVideo13bDevRequestsByRequestIdStatusResponse =
  GetFalAiLtxVideo13bDevRequestsByRequestIdStatusResponses[keyof GetFalAiLtxVideo13bDevRequestsByRequestIdStatusResponses]

export type PutFalAiLtxVideo13bDevRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-video-13b-dev/requests/{request_id}/cancel'
}

export type PutFalAiLtxVideo13bDevRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiLtxVideo13bDevRequestsByRequestIdCancelResponse =
  PutFalAiLtxVideo13bDevRequestsByRequestIdCancelResponses[keyof PutFalAiLtxVideo13bDevRequestsByRequestIdCancelResponses]

export type PostFalAiLtxVideo13bDevData = {
  body: SchemaLtxVideo13bDevInput
  path?: never
  query?: never
  url: '/fal-ai/ltx-video-13b-dev'
}

export type PostFalAiLtxVideo13bDevResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLtxVideo13bDevResponse =
  PostFalAiLtxVideo13bDevResponses[keyof PostFalAiLtxVideo13bDevResponses]

export type GetFalAiLtxVideo13bDevRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-video-13b-dev/requests/{request_id}'
}

export type GetFalAiLtxVideo13bDevRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLtxVideo13bDevOutput
}

export type GetFalAiLtxVideo13bDevRequestsByRequestIdResponse =
  GetFalAiLtxVideo13bDevRequestsByRequestIdResponses[keyof GetFalAiLtxVideo13bDevRequestsByRequestIdResponses]

export type GetFalAiLtxVideo13bDistilledRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ltx-video-13b-distilled/requests/{request_id}/status'
}

export type GetFalAiLtxVideo13bDistilledRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiLtxVideo13bDistilledRequestsByRequestIdStatusResponse =
  GetFalAiLtxVideo13bDistilledRequestsByRequestIdStatusResponses[keyof GetFalAiLtxVideo13bDistilledRequestsByRequestIdStatusResponses]

export type PutFalAiLtxVideo13bDistilledRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-video-13b-distilled/requests/{request_id}/cancel'
}

export type PutFalAiLtxVideo13bDistilledRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiLtxVideo13bDistilledRequestsByRequestIdCancelResponse =
  PutFalAiLtxVideo13bDistilledRequestsByRequestIdCancelResponses[keyof PutFalAiLtxVideo13bDistilledRequestsByRequestIdCancelResponses]

export type PostFalAiLtxVideo13bDistilledData = {
  body: SchemaLtxVideo13bDistilledInput
  path?: never
  query?: never
  url: '/fal-ai/ltx-video-13b-distilled'
}

export type PostFalAiLtxVideo13bDistilledResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLtxVideo13bDistilledResponse =
  PostFalAiLtxVideo13bDistilledResponses[keyof PostFalAiLtxVideo13bDistilledResponses]

export type GetFalAiLtxVideo13bDistilledRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-video-13b-distilled/requests/{request_id}'
}

export type GetFalAiLtxVideo13bDistilledRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLtxVideo13bDistilledOutput
}

export type GetFalAiLtxVideo13bDistilledRequestsByRequestIdResponse =
  GetFalAiLtxVideo13bDistilledRequestsByRequestIdResponses[keyof GetFalAiLtxVideo13bDistilledRequestsByRequestIdResponses]

export type GetFalAiPixverseV45TextToVideoFastRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v4.5/text-to-video/fast/requests/{request_id}/status'
}

export type GetFalAiPixverseV45TextToVideoFastRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiPixverseV45TextToVideoFastRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV45TextToVideoFastRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV45TextToVideoFastRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV45TextToVideoFastRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v4.5/text-to-video/fast/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV45TextToVideoFastRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiPixverseV45TextToVideoFastRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV45TextToVideoFastRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV45TextToVideoFastRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV45TextToVideoFastData = {
  body: SchemaPixverseV45TextToVideoFastInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v4.5/text-to-video/fast'
}

export type PostFalAiPixverseV45TextToVideoFastResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV45TextToVideoFastResponse =
  PostFalAiPixverseV45TextToVideoFastResponses[keyof PostFalAiPixverseV45TextToVideoFastResponses]

export type GetFalAiPixverseV45TextToVideoFastRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v4.5/text-to-video/fast/requests/{request_id}'
}

export type GetFalAiPixverseV45TextToVideoFastRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV45TextToVideoFastOutput
}

export type GetFalAiPixverseV45TextToVideoFastRequestsByRequestIdResponse =
  GetFalAiPixverseV45TextToVideoFastRequestsByRequestIdResponses[keyof GetFalAiPixverseV45TextToVideoFastRequestsByRequestIdResponses]

export type GetFalAiPixverseV45TextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v4.5/text-to-video/requests/{request_id}/status'
}

export type GetFalAiPixverseV45TextToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPixverseV45TextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV45TextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV45TextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV45TextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v4.5/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV45TextToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPixverseV45TextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV45TextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV45TextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV45TextToVideoData = {
  body: SchemaPixverseV45TextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v4.5/text-to-video'
}

export type PostFalAiPixverseV45TextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV45TextToVideoResponse =
  PostFalAiPixverseV45TextToVideoResponses[keyof PostFalAiPixverseV45TextToVideoResponses]

export type GetFalAiPixverseV45TextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v4.5/text-to-video/requests/{request_id}'
}

export type GetFalAiPixverseV45TextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV45TextToVideoOutput
}

export type GetFalAiPixverseV45TextToVideoRequestsByRequestIdResponse =
  GetFalAiPixverseV45TextToVideoRequestsByRequestIdResponses[keyof GetFalAiPixverseV45TextToVideoRequestsByRequestIdResponses]

export type GetFalAiViduQ1TextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/vidu/q1/text-to-video/requests/{request_id}/status'
}

export type GetFalAiViduQ1TextToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiViduQ1TextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiViduQ1TextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiViduQ1TextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiViduQ1TextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/vidu/q1/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiViduQ1TextToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiViduQ1TextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiViduQ1TextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiViduQ1TextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiViduQ1TextToVideoData = {
  body: SchemaViduQ1TextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/vidu/q1/text-to-video'
}

export type PostFalAiViduQ1TextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiViduQ1TextToVideoResponse =
  PostFalAiViduQ1TextToVideoResponses[keyof PostFalAiViduQ1TextToVideoResponses]

export type GetFalAiViduQ1TextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/vidu/q1/text-to-video/requests/{request_id}'
}

export type GetFalAiViduQ1TextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaViduQ1TextToVideoOutput
}

export type GetFalAiViduQ1TextToVideoRequestsByRequestIdResponse =
  GetFalAiViduQ1TextToVideoRequestsByRequestIdResponses[keyof GetFalAiViduQ1TextToVideoRequestsByRequestIdResponses]

export type GetFalAiMagiRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/magi/requests/{request_id}/status'
}

export type GetFalAiMagiRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiMagiRequestsByRequestIdStatusResponse =
  GetFalAiMagiRequestsByRequestIdStatusResponses[keyof GetFalAiMagiRequestsByRequestIdStatusResponses]

export type PutFalAiMagiRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/magi/requests/{request_id}/cancel'
}

export type PutFalAiMagiRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiMagiRequestsByRequestIdCancelResponse =
  PutFalAiMagiRequestsByRequestIdCancelResponses[keyof PutFalAiMagiRequestsByRequestIdCancelResponses]

export type PostFalAiMagiData = {
  body: SchemaMagiInput
  path?: never
  query?: never
  url: '/fal-ai/magi'
}

export type PostFalAiMagiResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMagiResponse =
  PostFalAiMagiResponses[keyof PostFalAiMagiResponses]

export type GetFalAiMagiRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/magi/requests/{request_id}'
}

export type GetFalAiMagiRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaMagiOutput
}

export type GetFalAiMagiRequestsByRequestIdResponse =
  GetFalAiMagiRequestsByRequestIdResponses[keyof GetFalAiMagiRequestsByRequestIdResponses]

export type GetFalAiMagiDistilledRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/magi-distilled/requests/{request_id}/status'
}

export type GetFalAiMagiDistilledRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiMagiDistilledRequestsByRequestIdStatusResponse =
  GetFalAiMagiDistilledRequestsByRequestIdStatusResponses[keyof GetFalAiMagiDistilledRequestsByRequestIdStatusResponses]

export type PutFalAiMagiDistilledRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/magi-distilled/requests/{request_id}/cancel'
}

export type PutFalAiMagiDistilledRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiMagiDistilledRequestsByRequestIdCancelResponse =
  PutFalAiMagiDistilledRequestsByRequestIdCancelResponses[keyof PutFalAiMagiDistilledRequestsByRequestIdCancelResponses]

export type PostFalAiMagiDistilledData = {
  body: SchemaMagiDistilledInput
  path?: never
  query?: never
  url: '/fal-ai/magi-distilled'
}

export type PostFalAiMagiDistilledResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMagiDistilledResponse =
  PostFalAiMagiDistilledResponses[keyof PostFalAiMagiDistilledResponses]

export type GetFalAiMagiDistilledRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/magi-distilled/requests/{request_id}'
}

export type GetFalAiMagiDistilledRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaMagiDistilledOutput
}

export type GetFalAiMagiDistilledRequestsByRequestIdResponse =
  GetFalAiMagiDistilledRequestsByRequestIdResponses[keyof GetFalAiMagiDistilledRequestsByRequestIdResponses]

export type GetFalAiPixverseV4TextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v4/text-to-video/requests/{request_id}/status'
}

export type GetFalAiPixverseV4TextToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPixverseV4TextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV4TextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV4TextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV4TextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v4/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV4TextToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPixverseV4TextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV4TextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV4TextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV4TextToVideoData = {
  body: SchemaPixverseV4TextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v4/text-to-video'
}

export type PostFalAiPixverseV4TextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV4TextToVideoResponse =
  PostFalAiPixverseV4TextToVideoResponses[keyof PostFalAiPixverseV4TextToVideoResponses]

export type GetFalAiPixverseV4TextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v4/text-to-video/requests/{request_id}'
}

export type GetFalAiPixverseV4TextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV4TextToVideoOutput
}

export type GetFalAiPixverseV4TextToVideoRequestsByRequestIdResponse =
  GetFalAiPixverseV4TextToVideoRequestsByRequestIdResponses[keyof GetFalAiPixverseV4TextToVideoRequestsByRequestIdResponses]

export type GetFalAiPixverseV4TextToVideoFastRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v4/text-to-video/fast/requests/{request_id}/status'
}

export type GetFalAiPixverseV4TextToVideoFastRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiPixverseV4TextToVideoFastRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV4TextToVideoFastRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV4TextToVideoFastRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV4TextToVideoFastRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v4/text-to-video/fast/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV4TextToVideoFastRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiPixverseV4TextToVideoFastRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV4TextToVideoFastRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV4TextToVideoFastRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV4TextToVideoFastData = {
  body: SchemaPixverseV4TextToVideoFastInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v4/text-to-video/fast'
}

export type PostFalAiPixverseV4TextToVideoFastResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV4TextToVideoFastResponse =
  PostFalAiPixverseV4TextToVideoFastResponses[keyof PostFalAiPixverseV4TextToVideoFastResponses]

export type GetFalAiPixverseV4TextToVideoFastRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v4/text-to-video/fast/requests/{request_id}'
}

export type GetFalAiPixverseV4TextToVideoFastRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV4TextToVideoFastOutput
}

export type GetFalAiPixverseV4TextToVideoFastRequestsByRequestIdResponse =
  GetFalAiPixverseV4TextToVideoFastRequestsByRequestIdResponses[keyof GetFalAiPixverseV4TextToVideoFastRequestsByRequestIdResponses]

export type GetFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/kling-video/lipsync/audio-to-video/requests/{request_id}/status'
  }

export type GetFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/lipsync/audio-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoLipsyncAudioToVideoData = {
  body: SchemaKlingVideoLipsyncAudioToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/lipsync/audio-to-video'
}

export type PostFalAiKlingVideoLipsyncAudioToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoLipsyncAudioToVideoResponse =
  PostFalAiKlingVideoLipsyncAudioToVideoResponses[keyof PostFalAiKlingVideoLipsyncAudioToVideoResponses]

export type GetFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/lipsync/audio-to-video/requests/{request_id}'
}

export type GetFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaKlingVideoLipsyncAudioToVideoOutput
  }

export type GetFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdResponse =
  GetFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdResponses[keyof GetFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdResponses]

export type GetFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/kling-video/lipsync/text-to-video/requests/{request_id}/status'
  }

export type GetFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/lipsync/text-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoLipsyncTextToVideoData = {
  body: SchemaKlingVideoLipsyncTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/lipsync/text-to-video'
}

export type PostFalAiKlingVideoLipsyncTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoLipsyncTextToVideoResponse =
  PostFalAiKlingVideoLipsyncTextToVideoResponses[keyof PostFalAiKlingVideoLipsyncTextToVideoResponses]

export type GetFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/lipsync/text-to-video/requests/{request_id}'
}

export type GetFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKlingVideoLipsyncTextToVideoOutput
}

export type GetFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdResponse =
  GetFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdResponses[keyof GetFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdResponses]

export type GetFalAiWanT2vLoraRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/wan-t2v-lora/requests/{request_id}/status'
}

export type GetFalAiWanT2vLoraRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiWanT2vLoraRequestsByRequestIdStatusResponse =
  GetFalAiWanT2vLoraRequestsByRequestIdStatusResponses[keyof GetFalAiWanT2vLoraRequestsByRequestIdStatusResponses]

export type PutFalAiWanT2vLoraRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan-t2v-lora/requests/{request_id}/cancel'
}

export type PutFalAiWanT2vLoraRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiWanT2vLoraRequestsByRequestIdCancelResponse =
  PutFalAiWanT2vLoraRequestsByRequestIdCancelResponses[keyof PutFalAiWanT2vLoraRequestsByRequestIdCancelResponses]

export type PostFalAiWanT2vLoraData = {
  body: SchemaWanT2vLoraInput
  path?: never
  query?: never
  url: '/fal-ai/wan-t2v-lora'
}

export type PostFalAiWanT2vLoraResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiWanT2vLoraResponse =
  PostFalAiWanT2vLoraResponses[keyof PostFalAiWanT2vLoraResponses]

export type GetFalAiWanT2vLoraRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan-t2v-lora/requests/{request_id}'
}

export type GetFalAiWanT2vLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaWanT2vLoraOutput
}

export type GetFalAiWanT2vLoraRequestsByRequestIdResponse =
  GetFalAiWanT2vLoraRequestsByRequestIdResponses[keyof GetFalAiWanT2vLoraRequestsByRequestIdResponses]

export type GetFalAiLumaDreamMachineRay2FlashRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/luma-dream-machine/ray-2-flash/requests/{request_id}/status'
}

export type GetFalAiLumaDreamMachineRay2FlashRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiLumaDreamMachineRay2FlashRequestsByRequestIdStatusResponse =
  GetFalAiLumaDreamMachineRay2FlashRequestsByRequestIdStatusResponses[keyof GetFalAiLumaDreamMachineRay2FlashRequestsByRequestIdStatusResponses]

export type PutFalAiLumaDreamMachineRay2FlashRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/luma-dream-machine/ray-2-flash/requests/{request_id}/cancel'
}

export type PutFalAiLumaDreamMachineRay2FlashRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiLumaDreamMachineRay2FlashRequestsByRequestIdCancelResponse =
  PutFalAiLumaDreamMachineRay2FlashRequestsByRequestIdCancelResponses[keyof PutFalAiLumaDreamMachineRay2FlashRequestsByRequestIdCancelResponses]

export type PostFalAiLumaDreamMachineRay2FlashData = {
  body: SchemaLumaDreamMachineRay2FlashInput
  path?: never
  query?: never
  url: '/fal-ai/luma-dream-machine/ray-2-flash'
}

export type PostFalAiLumaDreamMachineRay2FlashResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLumaDreamMachineRay2FlashResponse =
  PostFalAiLumaDreamMachineRay2FlashResponses[keyof PostFalAiLumaDreamMachineRay2FlashResponses]

export type GetFalAiLumaDreamMachineRay2FlashRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/luma-dream-machine/ray-2-flash/requests/{request_id}'
}

export type GetFalAiLumaDreamMachineRay2FlashRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLumaDreamMachineRay2FlashOutput
}

export type GetFalAiLumaDreamMachineRay2FlashRequestsByRequestIdResponse =
  GetFalAiLumaDreamMachineRay2FlashRequestsByRequestIdResponses[keyof GetFalAiLumaDreamMachineRay2FlashRequestsByRequestIdResponses]

export type GetFalAiPikaV2TurboTextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pika/v2/turbo/text-to-video/requests/{request_id}/status'
}

export type GetFalAiPikaV2TurboTextToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPikaV2TurboTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiPikaV2TurboTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiPikaV2TurboTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiPikaV2TurboTextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pika/v2/turbo/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiPikaV2TurboTextToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPikaV2TurboTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiPikaV2TurboTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiPikaV2TurboTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiPikaV2TurboTextToVideoData = {
  body: SchemaPikaV2TurboTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/pika/v2/turbo/text-to-video'
}

export type PostFalAiPikaV2TurboTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPikaV2TurboTextToVideoResponse =
  PostFalAiPikaV2TurboTextToVideoResponses[keyof PostFalAiPikaV2TurboTextToVideoResponses]

export type GetFalAiPikaV2TurboTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pika/v2/turbo/text-to-video/requests/{request_id}'
}

export type GetFalAiPikaV2TurboTextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPikaV2TurboTextToVideoOutput
}

export type GetFalAiPikaV2TurboTextToVideoRequestsByRequestIdResponse =
  GetFalAiPikaV2TurboTextToVideoRequestsByRequestIdResponses[keyof GetFalAiPikaV2TurboTextToVideoRequestsByRequestIdResponses]

export type GetFalAiPikaV21TextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pika/v2.1/text-to-video/requests/{request_id}/status'
}

export type GetFalAiPikaV21TextToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPikaV21TextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiPikaV21TextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiPikaV21TextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiPikaV21TextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pika/v2.1/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiPikaV21TextToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPikaV21TextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiPikaV21TextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiPikaV21TextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiPikaV21TextToVideoData = {
  body: SchemaPikaV21TextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/pika/v2.1/text-to-video'
}

export type PostFalAiPikaV21TextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPikaV21TextToVideoResponse =
  PostFalAiPikaV21TextToVideoResponses[keyof PostFalAiPikaV21TextToVideoResponses]

export type GetFalAiPikaV21TextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pika/v2.1/text-to-video/requests/{request_id}'
}

export type GetFalAiPikaV21TextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPikaV21TextToVideoOutput
}

export type GetFalAiPikaV21TextToVideoRequestsByRequestIdResponse =
  GetFalAiPikaV21TextToVideoRequestsByRequestIdResponses[keyof GetFalAiPikaV21TextToVideoRequestsByRequestIdResponses]

export type GetFalAiPikaV22TextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pika/v2.2/text-to-video/requests/{request_id}/status'
}

export type GetFalAiPikaV22TextToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPikaV22TextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiPikaV22TextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiPikaV22TextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiPikaV22TextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pika/v2.2/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiPikaV22TextToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPikaV22TextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiPikaV22TextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiPikaV22TextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiPikaV22TextToVideoData = {
  body: SchemaPikaV22TextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/pika/v2.2/text-to-video'
}

export type PostFalAiPikaV22TextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPikaV22TextToVideoResponse =
  PostFalAiPikaV22TextToVideoResponses[keyof PostFalAiPikaV22TextToVideoResponses]

export type GetFalAiPikaV22TextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pika/v2.2/text-to-video/requests/{request_id}'
}

export type GetFalAiPikaV22TextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPikaV22TextToVideoOutput
}

export type GetFalAiPikaV22TextToVideoRequestsByRequestIdResponse =
  GetFalAiPikaV22TextToVideoRequestsByRequestIdResponses[keyof GetFalAiPikaV22TextToVideoRequestsByRequestIdResponses]

export type GetFalAiWanProTextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/wan-pro/text-to-video/requests/{request_id}/status'
}

export type GetFalAiWanProTextToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiWanProTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiWanProTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiWanProTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiWanProTextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan-pro/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiWanProTextToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiWanProTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiWanProTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiWanProTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiWanProTextToVideoData = {
  body: SchemaWanProTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/wan-pro/text-to-video'
}

export type PostFalAiWanProTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiWanProTextToVideoResponse =
  PostFalAiWanProTextToVideoResponses[keyof PostFalAiWanProTextToVideoResponses]

export type GetFalAiWanProTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan-pro/text-to-video/requests/{request_id}'
}

export type GetFalAiWanProTextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaWanProTextToVideoOutput
}

export type GetFalAiWanProTextToVideoRequestsByRequestIdResponse =
  GetFalAiWanProTextToVideoRequestsByRequestIdResponses[keyof GetFalAiWanProTextToVideoRequestsByRequestIdResponses]

export type GetFalAiKlingVideoV15ProEffectsRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kling-video/v1.5/pro/effects/requests/{request_id}/status'
}

export type GetFalAiKlingVideoV15ProEffectsRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV15ProEffectsRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV15ProEffectsRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV15ProEffectsRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV15ProEffectsRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v1.5/pro/effects/requests/{request_id}/cancel'
}

export type PutFalAiKlingVideoV15ProEffectsRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV15ProEffectsRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV15ProEffectsRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV15ProEffectsRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV15ProEffectsData = {
  body: SchemaKlingVideoV15ProEffectsInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v1.5/pro/effects'
}

export type PostFalAiKlingVideoV15ProEffectsResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV15ProEffectsResponse =
  PostFalAiKlingVideoV15ProEffectsResponses[keyof PostFalAiKlingVideoV15ProEffectsResponses]

export type GetFalAiKlingVideoV15ProEffectsRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v1.5/pro/effects/requests/{request_id}'
}

export type GetFalAiKlingVideoV15ProEffectsRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKlingVideoV15ProEffectsOutput
}

export type GetFalAiKlingVideoV15ProEffectsRequestsByRequestIdResponse =
  GetFalAiKlingVideoV15ProEffectsRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV15ProEffectsRequestsByRequestIdResponses]

export type GetFalAiKlingVideoV16ProEffectsRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kling-video/v1.6/pro/effects/requests/{request_id}/status'
}

export type GetFalAiKlingVideoV16ProEffectsRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV16ProEffectsRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV16ProEffectsRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV16ProEffectsRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV16ProEffectsRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v1.6/pro/effects/requests/{request_id}/cancel'
}

export type PutFalAiKlingVideoV16ProEffectsRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV16ProEffectsRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV16ProEffectsRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV16ProEffectsRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV16ProEffectsData = {
  body: SchemaKlingVideoV16ProEffectsInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v1.6/pro/effects'
}

export type PostFalAiKlingVideoV16ProEffectsResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV16ProEffectsResponse =
  PostFalAiKlingVideoV16ProEffectsResponses[keyof PostFalAiKlingVideoV16ProEffectsResponses]

export type GetFalAiKlingVideoV16ProEffectsRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v1.6/pro/effects/requests/{request_id}'
}

export type GetFalAiKlingVideoV16ProEffectsRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKlingVideoV16ProEffectsOutput
}

export type GetFalAiKlingVideoV16ProEffectsRequestsByRequestIdResponse =
  GetFalAiKlingVideoV16ProEffectsRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV16ProEffectsRequestsByRequestIdResponses]

export type GetFalAiKlingVideoV1StandardEffectsRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kling-video/v1/standard/effects/requests/{request_id}/status'
}

export type GetFalAiKlingVideoV1StandardEffectsRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV1StandardEffectsRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV1StandardEffectsRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV1StandardEffectsRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV1StandardEffectsRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v1/standard/effects/requests/{request_id}/cancel'
}

export type PutFalAiKlingVideoV1StandardEffectsRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV1StandardEffectsRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV1StandardEffectsRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV1StandardEffectsRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV1StandardEffectsData = {
  body: SchemaKlingVideoV1StandardEffectsInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v1/standard/effects'
}

export type PostFalAiKlingVideoV1StandardEffectsResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV1StandardEffectsResponse =
  PostFalAiKlingVideoV1StandardEffectsResponses[keyof PostFalAiKlingVideoV1StandardEffectsResponses]

export type GetFalAiKlingVideoV1StandardEffectsRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v1/standard/effects/requests/{request_id}'
}

export type GetFalAiKlingVideoV1StandardEffectsRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKlingVideoV1StandardEffectsOutput
}

export type GetFalAiKlingVideoV1StandardEffectsRequestsByRequestIdResponse =
  GetFalAiKlingVideoV1StandardEffectsRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV1StandardEffectsRequestsByRequestIdResponses]

export type GetFalAiKlingVideoV16StandardEffectsRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/kling-video/v1.6/standard/effects/requests/{request_id}/status'
  }

export type GetFalAiKlingVideoV16StandardEffectsRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV16StandardEffectsRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV16StandardEffectsRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV16StandardEffectsRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV16StandardEffectsRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/v1.6/standard/effects/requests/{request_id}/cancel'
  }

export type PutFalAiKlingVideoV16StandardEffectsRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV16StandardEffectsRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV16StandardEffectsRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV16StandardEffectsRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV16StandardEffectsData = {
  body: SchemaKlingVideoV16StandardEffectsInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v1.6/standard/effects'
}

export type PostFalAiKlingVideoV16StandardEffectsResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV16StandardEffectsResponse =
  PostFalAiKlingVideoV16StandardEffectsResponses[keyof PostFalAiKlingVideoV16StandardEffectsResponses]

export type GetFalAiKlingVideoV16StandardEffectsRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v1.6/standard/effects/requests/{request_id}'
}

export type GetFalAiKlingVideoV16StandardEffectsRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKlingVideoV16StandardEffectsOutput
}

export type GetFalAiKlingVideoV16StandardEffectsRequestsByRequestIdResponse =
  GetFalAiKlingVideoV16StandardEffectsRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV16StandardEffectsRequestsByRequestIdResponses]

export type GetFalAiLtxVideoV095RequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ltx-video-v095/requests/{request_id}/status'
}

export type GetFalAiLtxVideoV095RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiLtxVideoV095RequestsByRequestIdStatusResponse =
  GetFalAiLtxVideoV095RequestsByRequestIdStatusResponses[keyof GetFalAiLtxVideoV095RequestsByRequestIdStatusResponses]

export type PutFalAiLtxVideoV095RequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-video-v095/requests/{request_id}/cancel'
}

export type PutFalAiLtxVideoV095RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiLtxVideoV095RequestsByRequestIdCancelResponse =
  PutFalAiLtxVideoV095RequestsByRequestIdCancelResponses[keyof PutFalAiLtxVideoV095RequestsByRequestIdCancelResponses]

export type PostFalAiLtxVideoV095Data = {
  body: SchemaLtxVideoV095Input
  path?: never
  query?: never
  url: '/fal-ai/ltx-video-v095'
}

export type PostFalAiLtxVideoV095Responses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLtxVideoV095Response =
  PostFalAiLtxVideoV095Responses[keyof PostFalAiLtxVideoV095Responses]

export type GetFalAiLtxVideoV095RequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-video-v095/requests/{request_id}'
}

export type GetFalAiLtxVideoV095RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLtxVideoV095Output
}

export type GetFalAiLtxVideoV095RequestsByRequestIdResponse =
  GetFalAiLtxVideoV095RequestsByRequestIdResponses[keyof GetFalAiLtxVideoV095RequestsByRequestIdResponses]

export type GetFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kling-video/v1.6/pro/text-to-video/requests/{request_id}/status'
}

export type GetFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v1.6/pro/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV16ProTextToVideoData = {
  body: SchemaKlingVideoV16ProTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v1.6/pro/text-to-video'
}

export type PostFalAiKlingVideoV16ProTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV16ProTextToVideoResponse =
  PostFalAiKlingVideoV16ProTextToVideoResponses[keyof PostFalAiKlingVideoV16ProTextToVideoResponses]

export type GetFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v1.6/pro/text-to-video/requests/{request_id}'
}

export type GetFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKlingVideoV16ProTextToVideoOutput
}

export type GetFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdResponse =
  GetFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdResponses]

export type GetFalAiWanT2vRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/wan-t2v/requests/{request_id}/status'
}

export type GetFalAiWanT2vRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiWanT2vRequestsByRequestIdStatusResponse =
  GetFalAiWanT2vRequestsByRequestIdStatusResponses[keyof GetFalAiWanT2vRequestsByRequestIdStatusResponses]

export type PutFalAiWanT2vRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan-t2v/requests/{request_id}/cancel'
}

export type PutFalAiWanT2vRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiWanT2vRequestsByRequestIdCancelResponse =
  PutFalAiWanT2vRequestsByRequestIdCancelResponses[keyof PutFalAiWanT2vRequestsByRequestIdCancelResponses]

export type PostFalAiWanT2vData = {
  body: SchemaWanT2vInput
  path?: never
  query?: never
  url: '/fal-ai/wan-t2v'
}

export type PostFalAiWanT2vResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiWanT2vResponse =
  PostFalAiWanT2vResponses[keyof PostFalAiWanT2vResponses]

export type GetFalAiWanT2vRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/wan-t2v/requests/{request_id}'
}

export type GetFalAiWanT2vRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaWanT2vOutput
}

export type GetFalAiWanT2vRequestsByRequestIdResponse =
  GetFalAiWanT2vRequestsByRequestIdResponses[keyof GetFalAiWanT2vRequestsByRequestIdResponses]

export type GetFalAiVeo2RequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/veo2/requests/{request_id}/status'
}

export type GetFalAiVeo2RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiVeo2RequestsByRequestIdStatusResponse =
  GetFalAiVeo2RequestsByRequestIdStatusResponses[keyof GetFalAiVeo2RequestsByRequestIdStatusResponses]

export type PutFalAiVeo2RequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/veo2/requests/{request_id}/cancel'
}

export type PutFalAiVeo2RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiVeo2RequestsByRequestIdCancelResponse =
  PutFalAiVeo2RequestsByRequestIdCancelResponses[keyof PutFalAiVeo2RequestsByRequestIdCancelResponses]

export type PostFalAiVeo2Data = {
  body: SchemaVeo2Input
  path?: never
  query?: never
  url: '/fal-ai/veo2'
}

export type PostFalAiVeo2Responses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiVeo2Response =
  PostFalAiVeo2Responses[keyof PostFalAiVeo2Responses]

export type GetFalAiVeo2RequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/veo2/requests/{request_id}'
}

export type GetFalAiVeo2RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaVeo2Output
}

export type GetFalAiVeo2RequestsByRequestIdResponse =
  GetFalAiVeo2RequestsByRequestIdResponses[keyof GetFalAiVeo2RequestsByRequestIdResponses]

export type GetFalAiMinimaxVideo01DirectorRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/minimax/video-01-director/requests/{request_id}/status'
}

export type GetFalAiMinimaxVideo01DirectorRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiMinimaxVideo01DirectorRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxVideo01DirectorRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxVideo01DirectorRequestsByRequestIdStatusResponses]

export type PutFalAiMinimaxVideo01DirectorRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax/video-01-director/requests/{request_id}/cancel'
}

export type PutFalAiMinimaxVideo01DirectorRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiMinimaxVideo01DirectorRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxVideo01DirectorRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxVideo01DirectorRequestsByRequestIdCancelResponses]

export type PostFalAiMinimaxVideo01DirectorData = {
  body: SchemaMinimaxVideo01DirectorInput
  path?: never
  query?: never
  url: '/fal-ai/minimax/video-01-director'
}

export type PostFalAiMinimaxVideo01DirectorResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMinimaxVideo01DirectorResponse =
  PostFalAiMinimaxVideo01DirectorResponses[keyof PostFalAiMinimaxVideo01DirectorResponses]

export type GetFalAiMinimaxVideo01DirectorRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax/video-01-director/requests/{request_id}'
}

export type GetFalAiMinimaxVideo01DirectorRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaMinimaxVideo01DirectorOutput
}

export type GetFalAiMinimaxVideo01DirectorRequestsByRequestIdResponse =
  GetFalAiMinimaxVideo01DirectorRequestsByRequestIdResponses[keyof GetFalAiMinimaxVideo01DirectorRequestsByRequestIdResponses]

export type GetFalAiPixverseV35TextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v3.5/text-to-video/requests/{request_id}/status'
}

export type GetFalAiPixverseV35TextToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiPixverseV35TextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV35TextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV35TextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV35TextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v3.5/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV35TextToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiPixverseV35TextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV35TextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV35TextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV35TextToVideoData = {
  body: SchemaPixverseV35TextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v3.5/text-to-video'
}

export type PostFalAiPixverseV35TextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV35TextToVideoResponse =
  PostFalAiPixverseV35TextToVideoResponses[keyof PostFalAiPixverseV35TextToVideoResponses]

export type GetFalAiPixverseV35TextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v3.5/text-to-video/requests/{request_id}'
}

export type GetFalAiPixverseV35TextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV35TextToVideoOutput
}

export type GetFalAiPixverseV35TextToVideoRequestsByRequestIdResponse =
  GetFalAiPixverseV35TextToVideoRequestsByRequestIdResponses[keyof GetFalAiPixverseV35TextToVideoRequestsByRequestIdResponses]

export type GetFalAiPixverseV35TextToVideoFastRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/pixverse/v3.5/text-to-video/fast/requests/{request_id}/status'
}

export type GetFalAiPixverseV35TextToVideoFastRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiPixverseV35TextToVideoFastRequestsByRequestIdStatusResponse =
  GetFalAiPixverseV35TextToVideoFastRequestsByRequestIdStatusResponses[keyof GetFalAiPixverseV35TextToVideoFastRequestsByRequestIdStatusResponses]

export type PutFalAiPixverseV35TextToVideoFastRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v3.5/text-to-video/fast/requests/{request_id}/cancel'
}

export type PutFalAiPixverseV35TextToVideoFastRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiPixverseV35TextToVideoFastRequestsByRequestIdCancelResponse =
  PutFalAiPixverseV35TextToVideoFastRequestsByRequestIdCancelResponses[keyof PutFalAiPixverseV35TextToVideoFastRequestsByRequestIdCancelResponses]

export type PostFalAiPixverseV35TextToVideoFastData = {
  body: SchemaPixverseV35TextToVideoFastInput
  path?: never
  query?: never
  url: '/fal-ai/pixverse/v3.5/text-to-video/fast'
}

export type PostFalAiPixverseV35TextToVideoFastResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiPixverseV35TextToVideoFastResponse =
  PostFalAiPixverseV35TextToVideoFastResponses[keyof PostFalAiPixverseV35TextToVideoFastResponses]

export type GetFalAiPixverseV35TextToVideoFastRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/pixverse/v3.5/text-to-video/fast/requests/{request_id}'
}

export type GetFalAiPixverseV35TextToVideoFastRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaPixverseV35TextToVideoFastOutput
}

export type GetFalAiPixverseV35TextToVideoFastRequestsByRequestIdResponse =
  GetFalAiPixverseV35TextToVideoFastRequestsByRequestIdResponses[keyof GetFalAiPixverseV35TextToVideoFastRequestsByRequestIdResponses]

export type GetFalAiLumaDreamMachineRay2RequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/luma-dream-machine/ray-2/requests/{request_id}/status'
}

export type GetFalAiLumaDreamMachineRay2RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiLumaDreamMachineRay2RequestsByRequestIdStatusResponse =
  GetFalAiLumaDreamMachineRay2RequestsByRequestIdStatusResponses[keyof GetFalAiLumaDreamMachineRay2RequestsByRequestIdStatusResponses]

export type PutFalAiLumaDreamMachineRay2RequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/luma-dream-machine/ray-2/requests/{request_id}/cancel'
}

export type PutFalAiLumaDreamMachineRay2RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiLumaDreamMachineRay2RequestsByRequestIdCancelResponse =
  PutFalAiLumaDreamMachineRay2RequestsByRequestIdCancelResponses[keyof PutFalAiLumaDreamMachineRay2RequestsByRequestIdCancelResponses]

export type PostFalAiLumaDreamMachineRay2Data = {
  body: SchemaLumaDreamMachineRay2Input
  path?: never
  query?: never
  url: '/fal-ai/luma-dream-machine/ray-2'
}

export type PostFalAiLumaDreamMachineRay2Responses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLumaDreamMachineRay2Response =
  PostFalAiLumaDreamMachineRay2Responses[keyof PostFalAiLumaDreamMachineRay2Responses]

export type GetFalAiLumaDreamMachineRay2RequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/luma-dream-machine/ray-2/requests/{request_id}'
}

export type GetFalAiLumaDreamMachineRay2RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLumaDreamMachineRay2Output
}

export type GetFalAiLumaDreamMachineRay2RequestsByRequestIdResponse =
  GetFalAiLumaDreamMachineRay2RequestsByRequestIdResponses[keyof GetFalAiLumaDreamMachineRay2RequestsByRequestIdResponses]

export type GetFalAiHunyuanVideoLoraRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/hunyuan-video-lora/requests/{request_id}/status'
}

export type GetFalAiHunyuanVideoLoraRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiHunyuanVideoLoraRequestsByRequestIdStatusResponse =
  GetFalAiHunyuanVideoLoraRequestsByRequestIdStatusResponses[keyof GetFalAiHunyuanVideoLoraRequestsByRequestIdStatusResponses]

export type PutFalAiHunyuanVideoLoraRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/hunyuan-video-lora/requests/{request_id}/cancel'
}

export type PutFalAiHunyuanVideoLoraRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiHunyuanVideoLoraRequestsByRequestIdCancelResponse =
  PutFalAiHunyuanVideoLoraRequestsByRequestIdCancelResponses[keyof PutFalAiHunyuanVideoLoraRequestsByRequestIdCancelResponses]

export type PostFalAiHunyuanVideoLoraData = {
  body: SchemaHunyuanVideoLoraInput
  path?: never
  query?: never
  url: '/fal-ai/hunyuan-video-lora'
}

export type PostFalAiHunyuanVideoLoraResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiHunyuanVideoLoraResponse =
  PostFalAiHunyuanVideoLoraResponses[keyof PostFalAiHunyuanVideoLoraResponses]

export type GetFalAiHunyuanVideoLoraRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/hunyuan-video-lora/requests/{request_id}'
}

export type GetFalAiHunyuanVideoLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaHunyuanVideoLoraOutput
}

export type GetFalAiHunyuanVideoLoraRequestsByRequestIdResponse =
  GetFalAiHunyuanVideoLoraRequestsByRequestIdResponses[keyof GetFalAiHunyuanVideoLoraRequestsByRequestIdResponses]

export type GetFalAiTranspixarRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/transpixar/requests/{request_id}/status'
}

export type GetFalAiTranspixarRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiTranspixarRequestsByRequestIdStatusResponse =
  GetFalAiTranspixarRequestsByRequestIdStatusResponses[keyof GetFalAiTranspixarRequestsByRequestIdStatusResponses]

export type PutFalAiTranspixarRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/transpixar/requests/{request_id}/cancel'
}

export type PutFalAiTranspixarRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiTranspixarRequestsByRequestIdCancelResponse =
  PutFalAiTranspixarRequestsByRequestIdCancelResponses[keyof PutFalAiTranspixarRequestsByRequestIdCancelResponses]

export type PostFalAiTranspixarData = {
  body: SchemaTranspixarInput
  path?: never
  query?: never
  url: '/fal-ai/transpixar'
}

export type PostFalAiTranspixarResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiTranspixarResponse =
  PostFalAiTranspixarResponses[keyof PostFalAiTranspixarResponses]

export type GetFalAiTranspixarRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/transpixar/requests/{request_id}'
}

export type GetFalAiTranspixarRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaTranspixarOutput
}

export type GetFalAiTranspixarRequestsByRequestIdResponse =
  GetFalAiTranspixarRequestsByRequestIdResponses[keyof GetFalAiTranspixarRequestsByRequestIdResponses]

export type GetFalAiCogvideox5bRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/cogvideox-5b/requests/{request_id}/status'
}

export type GetFalAiCogvideox5bRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiCogvideox5bRequestsByRequestIdStatusResponse =
  GetFalAiCogvideox5bRequestsByRequestIdStatusResponses[keyof GetFalAiCogvideox5bRequestsByRequestIdStatusResponses]

export type PutFalAiCogvideox5bRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/cogvideox-5b/requests/{request_id}/cancel'
}

export type PutFalAiCogvideox5bRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiCogvideox5bRequestsByRequestIdCancelResponse =
  PutFalAiCogvideox5bRequestsByRequestIdCancelResponses[keyof PutFalAiCogvideox5bRequestsByRequestIdCancelResponses]

export type PostFalAiCogvideox5bData = {
  body: SchemaCogvideox5bInput
  path?: never
  query?: never
  url: '/fal-ai/cogvideox-5b'
}

export type PostFalAiCogvideox5bResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiCogvideox5bResponse =
  PostFalAiCogvideox5bResponses[keyof PostFalAiCogvideox5bResponses]

export type GetFalAiCogvideox5bRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/cogvideox-5b/requests/{request_id}'
}

export type GetFalAiCogvideox5bRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaCogvideox5bOutput
}

export type GetFalAiCogvideox5bRequestsByRequestIdResponse =
  GetFalAiCogvideox5bRequestsByRequestIdResponses[keyof GetFalAiCogvideox5bRequestsByRequestIdResponses]

export type GetFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/kling-video/v1.6/standard/text-to-video/requests/{request_id}/status'
  }

export type GetFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/v1.6/standard/text-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV16StandardTextToVideoData = {
  body: SchemaKlingVideoV16StandardTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v1.6/standard/text-to-video'
}

export type PostFalAiKlingVideoV16StandardTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV16StandardTextToVideoResponse =
  PostFalAiKlingVideoV16StandardTextToVideoResponses[keyof PostFalAiKlingVideoV16StandardTextToVideoResponses]

export type GetFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v1.6/standard/text-to-video/requests/{request_id}'
}

export type GetFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaKlingVideoV16StandardTextToVideoOutput
  }

export type GetFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdResponse =
  GetFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdResponses]

export type GetFalAiMinimaxVideo01LiveRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/minimax/video-01-live/requests/{request_id}/status'
}

export type GetFalAiMinimaxVideo01LiveRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiMinimaxVideo01LiveRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxVideo01LiveRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxVideo01LiveRequestsByRequestIdStatusResponses]

export type PutFalAiMinimaxVideo01LiveRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax/video-01-live/requests/{request_id}/cancel'
}

export type PutFalAiMinimaxVideo01LiveRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiMinimaxVideo01LiveRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxVideo01LiveRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxVideo01LiveRequestsByRequestIdCancelResponses]

export type PostFalAiMinimaxVideo01LiveData = {
  body: SchemaMinimaxVideo01LiveInput
  path?: never
  query?: never
  url: '/fal-ai/minimax/video-01-live'
}

export type PostFalAiMinimaxVideo01LiveResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMinimaxVideo01LiveResponse =
  PostFalAiMinimaxVideo01LiveResponses[keyof PostFalAiMinimaxVideo01LiveResponses]

export type GetFalAiMinimaxVideo01LiveRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax/video-01-live/requests/{request_id}'
}

export type GetFalAiMinimaxVideo01LiveRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaMinimaxVideo01LiveOutput
}

export type GetFalAiMinimaxVideo01LiveRequestsByRequestIdResponse =
  GetFalAiMinimaxVideo01LiveRequestsByRequestIdResponses[keyof GetFalAiMinimaxVideo01LiveRequestsByRequestIdResponses]

export type GetFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/kling-video/v1/standard/text-to-video/requests/{request_id}/status'
  }

export type GetFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/kling-video/v1/standard/text-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV1StandardTextToVideoData = {
  body: SchemaKlingVideoV1StandardTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v1/standard/text-to-video'
}

export type PostFalAiKlingVideoV1StandardTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV1StandardTextToVideoResponse =
  PostFalAiKlingVideoV1StandardTextToVideoResponses[keyof PostFalAiKlingVideoV1StandardTextToVideoResponses]

export type GetFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v1/standard/text-to-video/requests/{request_id}'
}

export type GetFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaKlingVideoV1StandardTextToVideoOutput
  }

export type GetFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdResponse =
  GetFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdResponses]

export type GetFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/kling-video/v1.5/pro/text-to-video/requests/{request_id}/status'
}

export type GetFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v1.5/pro/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiKlingVideoV15ProTextToVideoData = {
  body: SchemaKlingVideoV15ProTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/kling-video/v1.5/pro/text-to-video'
}

export type PostFalAiKlingVideoV15ProTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiKlingVideoV15ProTextToVideoResponse =
  PostFalAiKlingVideoV15ProTextToVideoResponses[keyof PostFalAiKlingVideoV15ProTextToVideoResponses]

export type GetFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/kling-video/v1.5/pro/text-to-video/requests/{request_id}'
}

export type GetFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaKlingVideoV15ProTextToVideoOutput
}

export type GetFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdResponse =
  GetFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdResponses]

export type GetFalAiMochiV1RequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/mochi-v1/requests/{request_id}/status'
}

export type GetFalAiMochiV1RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiMochiV1RequestsByRequestIdStatusResponse =
  GetFalAiMochiV1RequestsByRequestIdStatusResponses[keyof GetFalAiMochiV1RequestsByRequestIdStatusResponses]

export type PutFalAiMochiV1RequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/mochi-v1/requests/{request_id}/cancel'
}

export type PutFalAiMochiV1RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiMochiV1RequestsByRequestIdCancelResponse =
  PutFalAiMochiV1RequestsByRequestIdCancelResponses[keyof PutFalAiMochiV1RequestsByRequestIdCancelResponses]

export type PostFalAiMochiV1Data = {
  body: SchemaMochiV1Input
  path?: never
  query?: never
  url: '/fal-ai/mochi-v1'
}

export type PostFalAiMochiV1Responses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMochiV1Response =
  PostFalAiMochiV1Responses[keyof PostFalAiMochiV1Responses]

export type GetFalAiMochiV1RequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/mochi-v1/requests/{request_id}'
}

export type GetFalAiMochiV1RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaMochiV1Output
}

export type GetFalAiMochiV1RequestsByRequestIdResponse =
  GetFalAiMochiV1RequestsByRequestIdResponses[keyof GetFalAiMochiV1RequestsByRequestIdResponses]

export type GetFalAiHunyuanVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/hunyuan-video/requests/{request_id}/status'
}

export type GetFalAiHunyuanVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiHunyuanVideoRequestsByRequestIdStatusResponse =
  GetFalAiHunyuanVideoRequestsByRequestIdStatusResponses[keyof GetFalAiHunyuanVideoRequestsByRequestIdStatusResponses]

export type PutFalAiHunyuanVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/hunyuan-video/requests/{request_id}/cancel'
}

export type PutFalAiHunyuanVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiHunyuanVideoRequestsByRequestIdCancelResponse =
  PutFalAiHunyuanVideoRequestsByRequestIdCancelResponses[keyof PutFalAiHunyuanVideoRequestsByRequestIdCancelResponses]

export type PostFalAiHunyuanVideoData = {
  body: SchemaHunyuanVideoInput
  path?: never
  query?: never
  url: '/fal-ai/hunyuan-video'
}

export type PostFalAiHunyuanVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiHunyuanVideoResponse =
  PostFalAiHunyuanVideoResponses[keyof PostFalAiHunyuanVideoResponses]

export type GetFalAiHunyuanVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/hunyuan-video/requests/{request_id}'
}

export type GetFalAiHunyuanVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaHunyuanVideoOutput
}

export type GetFalAiHunyuanVideoRequestsByRequestIdResponse =
  GetFalAiHunyuanVideoRequestsByRequestIdResponses[keyof GetFalAiHunyuanVideoRequestsByRequestIdResponses]

export type GetFalAiLtxVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/ltx-video/requests/{request_id}/status'
}

export type GetFalAiLtxVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiLtxVideoRequestsByRequestIdStatusResponse =
  GetFalAiLtxVideoRequestsByRequestIdStatusResponses[keyof GetFalAiLtxVideoRequestsByRequestIdStatusResponses]

export type PutFalAiLtxVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-video/requests/{request_id}/cancel'
}

export type PutFalAiLtxVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiLtxVideoRequestsByRequestIdCancelResponse =
  PutFalAiLtxVideoRequestsByRequestIdCancelResponses[keyof PutFalAiLtxVideoRequestsByRequestIdCancelResponses]

export type PostFalAiLtxVideoData = {
  body: SchemaLtxVideoInput
  path?: never
  query?: never
  url: '/fal-ai/ltx-video'
}

export type PostFalAiLtxVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiLtxVideoResponse =
  PostFalAiLtxVideoResponses[keyof PostFalAiLtxVideoResponses]

export type GetFalAiLtxVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/ltx-video/requests/{request_id}'
}

export type GetFalAiLtxVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaLtxVideoOutput
}

export type GetFalAiLtxVideoRequestsByRequestIdResponse =
  GetFalAiLtxVideoRequestsByRequestIdResponses[keyof GetFalAiLtxVideoRequestsByRequestIdResponses]

export type GetFalAiFastSvdTextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/fast-svd/text-to-video/requests/{request_id}/status'
}

export type GetFalAiFastSvdTextToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiFastSvdTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiFastSvdTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiFastSvdTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiFastSvdTextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/fast-svd/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiFastSvdTextToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiFastSvdTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiFastSvdTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiFastSvdTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiFastSvdTextToVideoData = {
  body: SchemaFastSvdTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/fast-svd/text-to-video'
}

export type PostFalAiFastSvdTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiFastSvdTextToVideoResponse =
  PostFalAiFastSvdTextToVideoResponses[keyof PostFalAiFastSvdTextToVideoResponses]

export type GetFalAiFastSvdTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/fast-svd/text-to-video/requests/{request_id}'
}

export type GetFalAiFastSvdTextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaFastSvdTextToVideoOutput
}

export type GetFalAiFastSvdTextToVideoRequestsByRequestIdResponse =
  GetFalAiFastSvdTextToVideoRequestsByRequestIdResponses[keyof GetFalAiFastSvdTextToVideoRequestsByRequestIdResponses]

export type GetFalAiFastSvdLcmTextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/fast-svd-lcm/text-to-video/requests/{request_id}/status'
}

export type GetFalAiFastSvdLcmTextToVideoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiFastSvdLcmTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiFastSvdLcmTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiFastSvdLcmTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiFastSvdLcmTextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/fast-svd-lcm/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiFastSvdLcmTextToVideoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiFastSvdLcmTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiFastSvdLcmTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiFastSvdLcmTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiFastSvdLcmTextToVideoData = {
  body: SchemaFastSvdLcmTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/fast-svd-lcm/text-to-video'
}

export type PostFalAiFastSvdLcmTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiFastSvdLcmTextToVideoResponse =
  PostFalAiFastSvdLcmTextToVideoResponses[keyof PostFalAiFastSvdLcmTextToVideoResponses]

export type GetFalAiFastSvdLcmTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/fast-svd-lcm/text-to-video/requests/{request_id}'
}

export type GetFalAiFastSvdLcmTextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaFastSvdLcmTextToVideoOutput
}

export type GetFalAiFastSvdLcmTextToVideoRequestsByRequestIdResponse =
  GetFalAiFastSvdLcmTextToVideoRequestsByRequestIdResponses[keyof GetFalAiFastSvdLcmTextToVideoRequestsByRequestIdResponses]

export type GetFalAiT2vTurboRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/t2v-turbo/requests/{request_id}/status'
}

export type GetFalAiT2vTurboRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiT2vTurboRequestsByRequestIdStatusResponse =
  GetFalAiT2vTurboRequestsByRequestIdStatusResponses[keyof GetFalAiT2vTurboRequestsByRequestIdStatusResponses]

export type PutFalAiT2vTurboRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/t2v-turbo/requests/{request_id}/cancel'
}

export type PutFalAiT2vTurboRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiT2vTurboRequestsByRequestIdCancelResponse =
  PutFalAiT2vTurboRequestsByRequestIdCancelResponses[keyof PutFalAiT2vTurboRequestsByRequestIdCancelResponses]

export type PostFalAiT2vTurboData = {
  body: SchemaT2vTurboInput
  path?: never
  query?: never
  url: '/fal-ai/t2v-turbo'
}

export type PostFalAiT2vTurboResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiT2vTurboResponse =
  PostFalAiT2vTurboResponses[keyof PostFalAiT2vTurboResponses]

export type GetFalAiT2vTurboRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/t2v-turbo/requests/{request_id}'
}

export type GetFalAiT2vTurboRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaT2vTurboOutput
}

export type GetFalAiT2vTurboRequestsByRequestIdResponse =
  GetFalAiT2vTurboRequestsByRequestIdResponses[keyof GetFalAiT2vTurboRequestsByRequestIdResponses]

export type GetFalAiFastAnimatediffTextToVideoRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/fast-animatediff/text-to-video/requests/{request_id}/status'
}

export type GetFalAiFastAnimatediffTextToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiFastAnimatediffTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiFastAnimatediffTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiFastAnimatediffTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiFastAnimatediffTextToVideoRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/fast-animatediff/text-to-video/requests/{request_id}/cancel'
}

export type PutFalAiFastAnimatediffTextToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiFastAnimatediffTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiFastAnimatediffTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiFastAnimatediffTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiFastAnimatediffTextToVideoData = {
  body: SchemaFastAnimatediffTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/fast-animatediff/text-to-video'
}

export type PostFalAiFastAnimatediffTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiFastAnimatediffTextToVideoResponse =
  PostFalAiFastAnimatediffTextToVideoResponses[keyof PostFalAiFastAnimatediffTextToVideoResponses]

export type GetFalAiFastAnimatediffTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/fast-animatediff/text-to-video/requests/{request_id}'
}

export type GetFalAiFastAnimatediffTextToVideoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaFastAnimatediffTextToVideoOutput
}

export type GetFalAiFastAnimatediffTextToVideoRequestsByRequestIdResponse =
  GetFalAiFastAnimatediffTextToVideoRequestsByRequestIdResponses[keyof GetFalAiFastAnimatediffTextToVideoRequestsByRequestIdResponses]

export type GetFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdStatusData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number
    }
    url: '/fal-ai/fast-animatediff/turbo/text-to-video/requests/{request_id}/status'
  }

export type GetFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdStatusResponse =
  GetFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdStatusResponses[keyof GetFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdStatusResponses]

export type PutFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdCancelData =
  {
    body?: never
    path: {
      /**
       * Request ID
       */
      request_id: string
    }
    query?: never
    url: '/fal-ai/fast-animatediff/turbo/text-to-video/requests/{request_id}/cancel'
  }

export type PutFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdCancelResponse =
  PutFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdCancelResponses[keyof PutFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdCancelResponses]

export type PostFalAiFastAnimatediffTurboTextToVideoData = {
  body: SchemaFastAnimatediffTurboTextToVideoInput
  path?: never
  query?: never
  url: '/fal-ai/fast-animatediff/turbo/text-to-video'
}

export type PostFalAiFastAnimatediffTurboTextToVideoResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiFastAnimatediffTurboTextToVideoResponse =
  PostFalAiFastAnimatediffTurboTextToVideoResponses[keyof PostFalAiFastAnimatediffTurboTextToVideoResponses]

export type GetFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/fast-animatediff/turbo/text-to-video/requests/{request_id}'
}

export type GetFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SchemaFastAnimatediffTurboTextToVideoOutput
  }

export type GetFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdResponse =
  GetFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdResponses[keyof GetFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdResponses]

export type GetFalAiMinimaxVideo01RequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/minimax/video-01/requests/{request_id}/status'
}

export type GetFalAiMinimaxVideo01RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type GetFalAiMinimaxVideo01RequestsByRequestIdStatusResponse =
  GetFalAiMinimaxVideo01RequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxVideo01RequestsByRequestIdStatusResponses]

export type PutFalAiMinimaxVideo01RequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax/video-01/requests/{request_id}/cancel'
}

export type PutFalAiMinimaxVideo01RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean
  }
}

export type PutFalAiMinimaxVideo01RequestsByRequestIdCancelResponse =
  PutFalAiMinimaxVideo01RequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxVideo01RequestsByRequestIdCancelResponses]

export type PostFalAiMinimaxVideo01Data = {
  body: SchemaMinimaxVideo01Input
  path?: never
  query?: never
  url: '/fal-ai/minimax/video-01'
}

export type PostFalAiMinimaxVideo01Responses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiMinimaxVideo01Response =
  PostFalAiMinimaxVideo01Responses[keyof PostFalAiMinimaxVideo01Responses]

export type GetFalAiMinimaxVideo01RequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/minimax/video-01/requests/{request_id}'
}

export type GetFalAiMinimaxVideo01RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaMinimaxVideo01Output
}

export type GetFalAiMinimaxVideo01RequestsByRequestIdResponse =
  GetFalAiMinimaxVideo01RequestsByRequestIdResponses[keyof GetFalAiMinimaxVideo01RequestsByRequestIdResponses]

export type GetFalAiAnimatediffSparsectrlLcmRequestsByRequestIdStatusData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number
  }
  url: '/fal-ai/animatediff-sparsectrl-lcm/requests/{request_id}/status'
}

export type GetFalAiAnimatediffSparsectrlLcmRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: SchemaQueueStatus
  }

export type GetFalAiAnimatediffSparsectrlLcmRequestsByRequestIdStatusResponse =
  GetFalAiAnimatediffSparsectrlLcmRequestsByRequestIdStatusResponses[keyof GetFalAiAnimatediffSparsectrlLcmRequestsByRequestIdStatusResponses]

export type PutFalAiAnimatediffSparsectrlLcmRequestsByRequestIdCancelData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/animatediff-sparsectrl-lcm/requests/{request_id}/cancel'
}

export type PutFalAiAnimatediffSparsectrlLcmRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean
    }
  }

export type PutFalAiAnimatediffSparsectrlLcmRequestsByRequestIdCancelResponse =
  PutFalAiAnimatediffSparsectrlLcmRequestsByRequestIdCancelResponses[keyof PutFalAiAnimatediffSparsectrlLcmRequestsByRequestIdCancelResponses]

export type PostFalAiAnimatediffSparsectrlLcmData = {
  body: SchemaAnimatediffSparsectrlLcmInput
  path?: never
  query?: never
  url: '/fal-ai/animatediff-sparsectrl-lcm'
}

export type PostFalAiAnimatediffSparsectrlLcmResponses = {
  /**
   * The request status.
   */
  200: SchemaQueueStatus
}

export type PostFalAiAnimatediffSparsectrlLcmResponse =
  PostFalAiAnimatediffSparsectrlLcmResponses[keyof PostFalAiAnimatediffSparsectrlLcmResponses]

export type GetFalAiAnimatediffSparsectrlLcmRequestsByRequestIdData = {
  body?: never
  path: {
    /**
     * Request ID
     */
    request_id: string
  }
  query?: never
  url: '/fal-ai/animatediff-sparsectrl-lcm/requests/{request_id}'
}

export type GetFalAiAnimatediffSparsectrlLcmRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SchemaAnimatediffSparsectrlLcmOutput
}

export type GetFalAiAnimatediffSparsectrlLcmRequestsByRequestIdResponse =
  GetFalAiAnimatediffSparsectrlLcmRequestsByRequestIdResponses[keyof GetFalAiAnimatediffSparsectrlLcmRequestsByRequestIdResponses]
