// This file is auto-generated by @hey-api/openapi-ts

export type ClientOptions = {
  baseUrl: `${string}://${string}` | (string & {})
}

export type File = {
  url: string
  content_type?: string
  file_name?: string
  file_size?: number
}

export type QueueStatus = {
  status: 'IN_PROGRESS' | 'COMPLETED' | 'FAILED'
  response_url?: string
}

/**
 * TextToVideoV25ProRequest
 */
export type KlingVideoV25TurboProTextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video frame
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * TextToVideoV25ProOutput
 */
export type KlingVideoV25TurboProTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV25TurboProTextToVideoFile
}

/**
 * File
 */
export type FalAiKlingVideoV25TurboProTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Veo3TextToVideoInput
 */
export type Veo3FastInput = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video.
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Duration
   *
   * The duration of the generated video.
   */
  duration?: '4s' | '6s' | '8s'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * Auto Fix
   *
   * Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.
   */
  auto_fix?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '720p' | '1080p'
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the video generation.
   */
  negative_prompt?: string
}

/**
 * Veo3TextToVideoOutput
 */
export type Veo3FastOutput = {
  /**
   * Video
   *
   * The generated video.
   */
  video: FalAiVeo3FastFile
}

/**
 * File
 */
export type FalAiVeo3FastFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * StandardTextToVideoHailuo02Input
 */
export type MinimaxHailuo02StandardTextToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Duration
   *
   * The duration of the video in seconds. 10 seconds videos are not supported for 1080p resolution.
   */
  duration?: '6' | '10'
  /**
   * Prompt
   */
  prompt: string
}

/**
 * TextToVideoHailuo02Output
 */
export type MinimaxHailuo02StandardTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiMinimaxHailuo02StandardTextToVideoFile
}

/**
 * File
 */
export type FalAiMinimaxHailuo02StandardTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Veo3TextToVideoInput
 */
export type Veo3Input = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video.
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Duration
   *
   * The duration of the generated video.
   */
  duration?: '4s' | '6s' | '8s'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * Auto Fix
   *
   * Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.
   */
  auto_fix?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '720p' | '1080p'
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the video generation.
   */
  negative_prompt?: string
}

/**
 * Veo3TextToVideoOutput
 */
export type Veo3Output = {
  /**
   * Video
   *
   * The generated video.
   */
  video: FalAiVeo3File
}

/**
 * File
 */
export type FalAiVeo3File = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TextToVideoV2MasterRequest
 */
export type KlingVideoV2MasterTextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video frame
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * TextToVideoV2MasterOutput
 */
export type KlingVideoV2MasterTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV2MasterTextToVideoFile
}

/**
 * File
 */
export type FalAiKlingVideoV2MasterTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export type LoRaInput = {
  /**
   * Path
   *
   * URL, HuggingFace repo ID (owner/repo) to lora weights.
   */
  path: string
  /**
   * Scale
   *
   * Scale factor for LoRA application (0.0 to 4.0).
   */
  scale?: number
  /**
   * Weight Name
   *
   * Name of the LoRA weight. Only used if `path` is a HuggingFace repository, and is only required when the repository contains multiple LoRA weights.
   */
  weight_name?: string | unknown
}

/**
 * LTX2TextToVideoOutput
 */
export type Ltx219bDistilledTextToVideoLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for the generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for the random number generator.
   */
  seed: number
  video: VideoFile
}

/**
 * VideoFile
 */
export type VideoFile = {
  /**
   * Height
   *
   * The height of the video
   */
  height?: number | unknown
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number | unknown
  /**
   * Width
   *
   * The width of the video
   */
  width?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
}

/**
 * LTX2DistilledTextToVideoInput
 */
export type Ltx219bDistilledTextToVideoInput = {
  /**
   * Use Multi-Scale
   *
   * Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.
   */
  use_multiscale?: boolean
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: 'none' | 'regular' | 'high' | 'full'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * FPS
   *
   * The frames per second of the generated video.
   */
  fps?: number
  /**
   * Camera LoRA
   *
   * The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.
   */
  camera_lora?:
    | 'dolly_in'
    | 'dolly_out'
    | 'dolly_left'
    | 'dolly_right'
    | 'jib_up'
    | 'jib_down'
    | 'static'
    | 'none'
  /**
   * Video Size
   *
   * The size of the generated video.
   */
  video_size?:
    | ImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Camera LoRA Scale
   *
   * The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.
   */
  camera_lora_scale?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to generate the video from.
   */
  negative_prompt?: string
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number | unknown
}

/**
 * ImageSize
 */
export type ImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * LTX2TextToVideoOutput
 */
export type Ltx219bDistilledTextToVideoOutput = {
  /**
   * Prompt
   *
   * The prompt used for the generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for the random number generator.
   */
  seed: number
  video: FalAiLtx219bDistilledTextToVideoVideoFile
}

/**
 * VideoFile
 */
export type FalAiLtx219bDistilledTextToVideoVideoFile = {
  /**
   * Height
   *
   * The height of the video
   */
  height?: number | unknown
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number | unknown
  /**
   * Width
   *
   * The width of the video
   */
  width?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
}

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export type FalAiLtx219bTextToVideoLoraLoRaInput = {
  /**
   * Path
   *
   * URL, HuggingFace repo ID (owner/repo) to lora weights.
   */
  path: string
  /**
   * Scale
   *
   * Scale factor for LoRA application (0.0 to 4.0).
   */
  scale?: number
  /**
   * Weight Name
   *
   * Name of the LoRA weight. Only used if `path` is a HuggingFace repository, and is only required when the repository contains multiple LoRA weights.
   */
  weight_name?: string | unknown
}

/**
 * LTX2TextToVideoOutput
 */
export type Ltx219bTextToVideoLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for the generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for the random number generator.
   */
  seed: number
  video: FalAiLtx219bTextToVideoLoraVideoFile
}

/**
 * VideoFile
 */
export type FalAiLtx219bTextToVideoLoraVideoFile = {
  /**
   * Height
   *
   * The height of the video
   */
  height?: number | unknown
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number | unknown
  /**
   * Width
   *
   * The width of the video
   */
  width?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
}

/**
 * LTX2TextToVideoInput
 */
export type Ltx219bTextToVideoInput = {
  /**
   * Use Multi-Scale
   *
   * Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.
   */
  use_multiscale?: boolean
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: 'none' | 'regular' | 'high' | 'full'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * FPS
   *
   * The frames per second of the generated video.
   */
  fps?: number
  /**
   * Camera LoRA
   *
   * The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.
   */
  camera_lora?:
    | 'dolly_in'
    | 'dolly_out'
    | 'dolly_left'
    | 'dolly_right'
    | 'jib_up'
    | 'jib_down'
    | 'static'
    | 'none'
  /**
   * Video Size
   *
   * The size of the generated video.
   */
  video_size?:
    | FalAiLtx219bTextToVideoImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Guidance Scale
   *
   * The guidance scale to use.
   */
  guidance_scale?: number
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Camera LoRA Scale
   *
   * The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.
   */
  camera_lora_scale?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to generate the video from.
   */
  negative_prompt?: string
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number | unknown
}

/**
 * ImageSize
 */
export type FalAiLtx219bTextToVideoImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * LTX2TextToVideoOutput
 */
export type Ltx219bTextToVideoOutput = {
  /**
   * Prompt
   *
   * The prompt used for the generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for the random number generator.
   */
  seed: number
  video: FalAiLtx219bTextToVideoVideoFile
}

/**
 * VideoFile
 */
export type FalAiLtx219bTextToVideoVideoFile = {
  /**
   * Height
   *
   * The height of the video
   */
  height?: number | unknown
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number | unknown
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number | unknown
  /**
   * Width
   *
   * The width of the video
   */
  width?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
}

/**
 * KandinskyT2VRequest
 */
export type Kandinsky5ProTextToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution: 512p or 1024p.
   */
  resolution?: '512P' | '1024P'
  /**
   * Acceleration
   *
   * Acceleration level for faster generation.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video. One of (3:2, 1:1, 2:3).
   */
  aspect_ratio?: '3:2' | '1:1' | '2:3'
  /**
   * Num Inference Steps
   *
   * The number of inference steps.
   */
  num_inference_steps?: number
  /**
   * Duration
   *
   * The length of the video to generate (5s or 10s)
   */
  duration?: '5s'
}

/**
 * KandinskyT2VResponse
 */
export type Kandinsky5ProTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video file.
   */
  video?: FalAiKandinsky5ProTextToVideoFile
}

/**
 * File
 */
export type FalAiKandinsky5ProTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * SeedanceProv15TextToVideoInput
 */
export type BytedanceSeedanceV15ProTextToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt used to generate the video
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality
   */
  resolution?: '480p' | '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '21:9' | '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video
   */
  generate_audio?: boolean
  /**
   * Duration
   *
   * Duration of the video in seconds
   */
  duration?: '4' | '5' | '6' | '7' | '8' | '9' | '10' | '11' | '12'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Camera Fixed
   *
   * Whether to fix the camera position
   */
  camera_fixed?: boolean
  /**
   * Seed
   *
   * Random seed to control video generation. Use -1 for random.
   */
  seed?: number
}

/**
 * SeedanceProv15T2VVideoOutput
 */
export type BytedanceSeedanceV15ProTextToVideoOutput = {
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * Generated video file
   */
  video: FalAiBytedanceSeedanceV15ProTextToVideoFile
}

/**
 * File
 */
export type FalAiBytedanceSeedanceV15ProTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TextToVideoInput
 *
 * Input for Wan 2.6 text-to-video generation
 */
export type V26TextToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt for video generation. Supports Chinese and English, max 800 characters. For multi-shot videos, use format: 'Overall description. First shot [0-3s] content. Second shot [3-5s] content.'
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video. Wan 2.6 supports additional ratios.
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1' | '4:3' | '3:4'
  /**
   * Resolution
   *
   * Video resolution tier. Wan 2.6 T2V only supports 720p and 1080p (no 480p).
   */
  resolution?: '720p' | '1080p'
  /**
   * Duration
   *
   * Duration of the generated video in seconds. Choose between 5, 10, or 15 seconds.
   */
  duration?: '5' | '10' | '15'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Audio Url
   *
   *
   * URL of the audio to use as the background music. Must be publicly accessible.
   * Limit handling: If the audio duration exceeds the duration value (5, 10, or 15 seconds),
   * the audio is truncated to the first N seconds, and the rest is discarded. If
   * the audio is shorter than the video, the remaining part of the video will be silent.
   * For example, if the audio is 3 seconds long and the video duration is 5 seconds, the
   * first 3 seconds of the output video will have sound, and the last 2 seconds will be silent.
   * - Format: WAV, MP3.
   * - Duration: 3 to 30 s.
   * - File size: Up to 15 MB.
   *
   */
  audio_url?: string
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Multi Shots
   *
   * When true, enables intelligent multi-shot segmentation for coherent narrative videos. Only active when enable_prompt_expansion is True. Set to false for single-shot generation.
   */
  multi_shots?: boolean
  /**
   * Negative Prompt
   *
   * Negative prompt to describe content to avoid. Max 500 characters.
   */
  negative_prompt?: string
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt rewriting using LLM. Improves results for short prompts but increases processing time.
   */
  enable_prompt_expansion?: boolean
}

/**
 * TextToVideoOutput
 *
 * Output for text-to-video generation
 */
export type V26TextToVideoOutput = {
  /**
   * Actual Prompt
   *
   * The actual prompt used if prompt rewriting was enabled
   */
  actual_prompt?: string
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * The generated video file
   */
  video: WanV26TextToVideoVideoFile
}

/**
 * VideoFile
 */
export type WanV26TextToVideoVideoFile = {
  /**
   * Height
   *
   * The height of the video
   */
  height?: number
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number
  /**
   * Width
   *
   * The width of the video
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * FabricOneTextInput
 */
export type Fabric10TextInput = {
  /**
   * Text
   */
  text: string
  /**
   * Resolution
   *
   * Resolution
   */
  resolution: '720p' | '480p'
  /**
   * Voice Description
   *
   * Optional additional voice description. The primary voice description is auto-generated from the image. You can use simple descriptors like 'British accent' or 'Confident' or provide a detailed description like 'Confident male voice, mid-20s, with notes of...'
   */
  voice_description?: string | unknown
  /**
   * Image Url
   */
  image_url: string
}

/**
 * FabricOneTextOutput
 */
export type Fabric10TextOutput = {
  video: VeedFabric10TextFile
}

/**
 * File
 */
export type VeedFabric10TextFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * TextToVideoV26ProRequest
 */
export type KlingVideoV26ProTextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video frame
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Generate Audio
   *
   * Whether to generate native audio for the video. Supports Chinese and English voice output. Other languages are automatically translated to English. For English speech, use lowercase letters; for acronyms or proper nouns, use uppercase.
   */
  generate_audio?: boolean
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * TextToVideoV26ProOutput
 */
export type KlingVideoV26ProTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV26ProTextToVideoFile
}

/**
 * File
 */
export type FalAiKlingVideoV26ProTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TextToVideoRequestV5_5
 */
export type PixverseV55TextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Duration
   *
   * The duration of the generated video in seconds. Longer durations cost more. 1080p videos are limited to 5 or 8 seconds
   */
  duration?: '5' | '8' | '10'
  /**
   * Generate Multi Clip Switch
   *
   * Enable multi-clip generation with dynamic camera changes
   */
  generate_multi_clip_switch?: boolean
  /**
   * Thinking Type
   *
   * Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision
   */
  thinking_type?: 'enabled' | 'disabled' | 'auto'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Generate Audio Switch
   *
   * Enable audio generation (BGM, SFX, dialogue)
   */
  generate_audio_switch?: boolean
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * VideoOutputV5_5
 */
export type PixverseV55TextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPixverseV55TextToVideoFile
}

/**
 * File
 */
export type FalAiPixverseV55TextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * LTXVTextToVideoFastRequest
 */
export type Ltx2TextToVideoFastInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9'
  /**
   * Duration
   *
   * The duration of the generated video in seconds. The fast model supports 6-20 seconds. Note: Durations longer than 10 seconds (12, 14, 16, 18, 20) are only supported with 25 FPS and 1080p resolution.
   */
  duration?: 6 | 8 | 10 | 12 | 14 | 16 | 18 | 20
  /**
   * Generate Audio
   *
   * Whether to generate audio for the generated video
   */
  generate_audio?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '1080p' | '1440p' | '2160p'
  /**
   * Frames per Second
   *
   * The frames per second of the generated video
   */
  fps?: 25 | 50
}

/**
 * LTXVTextToVideoResponse
 */
export type Ltx2TextToVideoFastOutput = {
  /**
   * Video
   *
   * The generated video file
   */
  video: FalAiLtx2TextToVideoFastVideoFile
}

/**
 * VideoFile
 */
export type FalAiLtx2TextToVideoFastVideoFile = {
  /**
   * Height
   *
   * The height of the video
   */
  height?: number
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number
  /**
   * Width
   *
   * The width of the video
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * LTXVTextToVideoRequest
 */
export type Ltx2TextToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: 6 | 8 | 10
  /**
   * Generate Audio
   *
   * Whether to generate audio for the generated video
   */
  generate_audio?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '1080p' | '1440p' | '2160p'
  /**
   * Frames per Second
   *
   * The frames per second of the generated video
   */
  fps?: 25 | 50
}

/**
 * LTXVTextToVideoResponse
 */
export type Ltx2TextToVideoOutput = {
  /**
   * Video
   *
   * The generated video file
   */
  video: FalAiLtx2TextToVideoVideoFile
}

/**
 * VideoFile
 */
export type FalAiLtx2TextToVideoVideoFile = {
  /**
   * Height
   *
   * The height of the video
   */
  height?: number
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number
  /**
   * Width
   *
   * The width of the video
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * HunyuanVideo15T2VRequest
 */
export type HunyuanVideoV15TextToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video.
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the video.
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the video.
   */
  resolution?: '480p'
  /**
   * Enable Prompt Expansion
   *
   * Enable prompt expansion to enhance the input prompt.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility.
   */
  seed?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps.
   */
  num_inference_steps?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to guide what not to generate.
   */
  negative_prompt?: string
  /**
   * Num Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
}

/**
 * HunyuanVideo15Response
 */
export type HunyuanVideoV15TextToVideoOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiHunyuanVideoV15TextToVideoFile
}

/**
 * File
 */
export type FalAiHunyuanVideoV15TextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * GenerationInput
 *
 * Input model for text-to-video generation
 */
export type InfinityStarTextToVideoInput = {
  /**
   * Prompt
   *
   * Text prompt for generating the video
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated output
   */
  aspect_ratio?: '16:9' | '1:1' | '9:16'
  /**
   * Enhance Prompt
   *
   * Whether to use an LLM to enhance the prompt.
   */
  enhance_prompt?: boolean
  /**
   * Use Apg
   *
   * Whether to use APG
   */
  use_apg?: boolean
  /**
   * Guidance Scale
   *
   * Guidance scale for generation
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. Leave empty for random generation.
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to guide what to avoid in generation
   */
  negative_prompt?: string
  /**
   * Tau Video
   *
   * Tau value for video scale
   */
  tau_video?: number
}

/**
 * GenerationOutput
 *
 * Output model for text-to-video generation
 */
export type InfinityStarTextToVideoOutput = {
  /**
   * Video
   *
   * Generated video file
   */
  video: FalAiInfinityStarTextToVideoFile
}

/**
 * File
 */
export type FalAiInfinityStarTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * SanaVideoInput
 */
export type SanaVideoInput = {
  /**
   * Prompt
   *
   * The text prompt describing the video to generate
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the output video
   */
  resolution?: '480p'
  /**
   * Fps
   *
   * Frames per second for the output video
   */
  fps?: number
  /**
   * Motion Score
   *
   * Motion intensity score (higher = more motion)
   */
  motion_score?: number
  /**
   * Guidance Scale
   *
   * Guidance scale for generation (higher = more prompt adherence)
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * Number of denoising steps
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * Random seed for reproducible generation. If not provided, a random seed will be used.
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * The negative prompt describing what to avoid in the generation
   */
  negative_prompt?: string
  /**
   * Num Frames
   *
   * Number of frames to generate
   */
  num_frames?: number
}

/**
 * SanaVideoOutput
 */
export type SanaVideoOutput = {
  /**
   * Seed
   *
   * The random seed used for the generation process
   */
  seed: number
  /**
   * Video
   *
   * Generated video file
   */
  video: FalAiSanaVideoFile
}

/**
 * File
 */
export type FalAiSanaVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * LongCat720PCFGVideoRequest
 */
export type LongcatVideoTextToVideo720pInput = {
  /**
   * Prompt
   *
   * The prompt to guide the video generation.
   */
  prompt: string
  /**
   * Acceleration
   *
   * The acceleration level to use for the video generation.
   */
  acceleration?: 'none' | 'regular'
  /**
   * FPS
   *
   * The frame rate of the generated video.
   */
  fps?: number
  /**
   * Number of Refinement Inference Steps
   *
   * The number of inference steps to use for refinement.
   */
  num_refine_inference_steps?: number
  /**
   * Guidance Scale
   *
   * The guidance scale to use for the video generation.
   */
  guidance_scale?: number
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * The negative prompt to use for the video generation.
   */
  negative_prompt?: string
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video.
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use for the video generation.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
}

/**
 * LongCatVideoResponse
 */
export type LongcatVideoTextToVideo720pOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiLongcatVideoTextToVideo720pFile
}

/**
 * File
 */
export type FalAiLongcatVideoTextToVideo720pFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * LongCatCFGVideoRequest
 */
export type LongcatVideoTextToVideo480pInput = {
  /**
   * Prompt
   *
   * The prompt to guide the video generation.
   */
  prompt: string
  /**
   * Acceleration
   *
   * The acceleration level to use for the video generation.
   */
  acceleration?: 'none' | 'regular'
  /**
   * FPS
   *
   * The frame rate of the generated video.
   */
  fps?: number
  /**
   * Guidance Scale
   *
   * The guidance scale to use for the video generation.
   */
  guidance_scale?: number
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * The negative prompt to use for the video generation.
   */
  negative_prompt?: string
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video.
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use for the video generation.
   */
  num_inference_steps?: number
}

/**
 * LongCatVideoResponse
 */
export type LongcatVideoTextToVideo480pOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiLongcatVideoTextToVideo480pFile
}

/**
 * File
 */
export type FalAiLongcatVideoTextToVideo480pFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * LongCat720PVideoRequest
 */
export type LongcatVideoDistilledTextToVideo720pInput = {
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video.
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Prompt
   *
   * The prompt to guide the video generation.
   */
  prompt: string
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * FPS
   *
   * The frame rate of the generated video.
   */
  fps?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Number of Refinement Inference Steps
   *
   * The number of inference steps to use for refinement.
   */
  num_refine_inference_steps?: number
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Safety Checker
   *
   * Whether to enable safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
}

/**
 * LongCatVideoResponse
 */
export type LongcatVideoDistilledTextToVideo720pOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiLongcatVideoDistilledTextToVideo720pFile
}

/**
 * File
 */
export type FalAiLongcatVideoDistilledTextToVideo720pFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * LongCatVideoRequest
 */
export type LongcatVideoDistilledTextToVideo480pInput = {
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video.
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Prompt
   *
   * The prompt to guide the video generation.
   */
  prompt: string
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * FPS
   *
   * The frame rate of the generated video.
   */
  fps?: number
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Safety Checker
   *
   * Whether to enable safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
}

/**
 * LongCatVideoResponse
 */
export type LongcatVideoDistilledTextToVideo480pOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiLongcatVideoDistilledTextToVideo480pFile
}

/**
 * File
 */
export type FalAiLongcatVideoDistilledTextToVideo480pFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * StandardTextToVideoHailuo23Input
 */
export type MinimaxHailuo23StandardTextToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Duration
   *
   * The duration of the video in seconds.
   */
  duration?: '6' | '10'
  /**
   * Prompt
   */
  prompt: string
}

/**
 * StandardTextToVideoHailuo23Output
 */
export type MinimaxHailuo23StandardTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiMinimaxHailuo23StandardTextToVideoFile
}

/**
 * File
 */
export type FalAiMinimaxHailuo23StandardTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ProTextToVideoHailuo23Input
 */
export type MinimaxHailuo23ProTextToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Prompt
   *
   * Text prompt for video generation
   */
  prompt: string
}

/**
 * ProTextToVideoHailuo23Output
 */
export type MinimaxHailuo23ProTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiMinimaxHailuo23ProTextToVideoFile
}

/**
 * File
 */
export type FalAiMinimaxHailuo23ProTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * SeedanceProFastTextToVideoInput
 */
export type BytedanceSeedanceV1ProFastTextToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt used to generate the video
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality
   */
  resolution?: '480p' | '720p' | '1080p'
  /**
   * Duration
   *
   * Duration of the video in seconds
   */
  duration?: '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9' | '10' | '11' | '12'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '21:9' | '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * Random seed to control video generation. Use -1 for random.
   */
  seed?: number
  /**
   * Camera Fixed
   *
   * Whether to fix the camera position
   */
  camera_fixed?: boolean
}

/**
 * SeedanceFastT2VVideoOutput
 */
export type BytedanceSeedanceV1ProFastTextToVideoOutput = {
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * Generated video file
   */
  video: FalAiBytedanceSeedanceV1ProFastTextToVideoFile
}

/**
 * File
 */
export type FalAiBytedanceSeedanceV1ProFastTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Q2TextToVideoRequest
 */
export type ViduQ2TextToVideoInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 3000 characters
   */
  prompt: string
  /**
   * Resolution
   *
   * Output video resolution
   */
  resolution?: '360p' | '520p' | '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the output video
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Duration
   *
   * Duration of the video in seconds
   */
  duration?: 2 | 3 | 4 | 5 | 6 | 7 | 8
  /**
   * Bgm
   *
   * Whether to add background music to the video (only for 4-second videos)
   */
  bgm?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Movement Amplitude
   *
   * The movement amplitude of objects in the frame
   */
  movement_amplitude?: 'auto' | 'small' | 'medium' | 'large'
}

/**
 * Q2TextToVideoOutput
 */
export type ViduQ2TextToVideoOutput = {
  /**
   * Video
   *
   * The generated video from text using the Q2 model
   */
  video: FalAiViduQ2TextToVideoFile
}

/**
 * File
 */
export type FalAiViduQ2TextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TextToVideoInput
 */
export type KreaWan14bTextToVideoInput = {
  /**
   * Prompt
   *
   * Prompt for the video-to-video generation.
   */
  prompt: string
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean
  /**
   * Num Frames
   *
   * Number of frames to generate. Must be a multiple of 12 plus 6, for example 6, 18, 30, 42, etc.
   */
  num_frames?: number
  /**
   * Seed
   *
   * Seed for the video-to-video generation.
   */
  seed?: number | unknown
}

/**
 * VideoToVideoOutput
 */
export type KreaWan14bTextToVideoOutput = {
  video: FalAiKreaWan14bTextToVideoFile
}

/**
 * File
 */
export type FalAiKreaWan14bTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * WanAlphaRequest
 */
export type WanAlphaInput = {
  /**
   * Prompt
   *
   * The prompt to guide the video generation.
   */
  prompt: string
  /**
   * Shift
   *
   * The shift of the generated video.
   */
  shift?: number
  /**
   * Mask Clamp Upper
   *
   * The upper bound of the mask clamping.
   */
  mask_clamp_upper?: number
  /**
   * FPS
   *
   * The frame rate of the generated video.
   */
  fps?: number
  /**
   * Mask Clamp Lower
   *
   * The lower bound of the mask clamping.
   */
  mask_clamp_lower?: number
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Mask Binarization Threshold
   *
   * The threshold for mask binarization. When binarize_mask is True, this threshold will be used to binarize the mask. This will also be used for transparency when the output type is `.webm`.
   */
  mask_binarization_threshold?: number
  /**
   * Sampler
   *
   * The sampler to use.
   */
  sampler?: 'unipc' | 'dpm++' | 'euler'
  /**
   * Video Write Mode
   *
   * The write mode of the generated video.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '240p' | '360p' | '480p' | '580p' | '720p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video.
   */
  aspect_ratio?: '16:9' | '1:1' | '9:16'
  /**
   * Video Output Type
   *
   * The output type of the generated video.
   */
  video_output_type?:
    | 'X264 (.mp4)'
    | 'VP9 (.webm)'
    | 'PRORES4444 (.mov)'
    | 'GIF (.gif)'
  /**
   * Binarize Mask
   *
   * Whether to binarize the mask.
   */
  binarize_mask?: boolean
  /**
   * Video Quality
   *
   * The quality of the generated video.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
}

/**
 * WanAlphaResponse
 */
export type WanAlphaOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Image
   *
   * The generated image file.
   */
  image?: FalAiWanAlphaVideoFile
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Mask
   *
   * The generated mask file.
   */
  mask?: FalAiWanAlphaVideoFile
  /**
   * Video
   *
   * The generated video file.
   */
  video?: FalAiWanAlphaVideoFile
}

/**
 * VideoFile
 */
export type FalAiWanAlphaVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number
  /**
   * Height
   *
   * The height of the video
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the video
   */
  width?: number
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * KandinskyT2VDistillRequest
 */
export type Kandinsky5TextToVideoDistillInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Duration
   *
   * The length of the video to generate (5s or 10s)
   */
  duration?: '5s' | '10s'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video. One of (3:2, 1:1, 2:3).
   */
  aspect_ratio?: '3:2' | '1:1' | '2:3'
  /**
   * Resolution
   *
   * Resolution of the generated video in W:H format. Will be calculated based on the aspect ratio(768x512, 512x512, 512x768).
   */
  resolution?: '768x512'
}

/**
 * KandinskyT2VResponse
 */
export type Kandinsky5TextToVideoDistillOutput = {
  /**
   * Video
   *
   * The generated video file.
   */
  video?: FalAiKandinsky5TextToVideoDistillFile
}

/**
 * File
 */
export type FalAiKandinsky5TextToVideoDistillFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * KandinskyT2VRequest
 */
export type Kandinsky5TextToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the generated video in W:H format. Will be calculated based on the aspect ratio(768x512, 512x512, 512x768).
   */
  resolution?: '768x512'
  /**
   * Duration
   *
   * The length of the video to generate (5s or 10s)
   */
  duration?: '5s' | '10s'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video. One of (3:2, 1:1, 2:3).
   */
  aspect_ratio?: '3:2' | '1:1' | '2:3'
  /**
   * Num Inference Steps
   *
   * The number of inference steps.
   */
  num_inference_steps?: number
}

/**
 * KandinskyT2VResponse
 */
export type Kandinsky5TextToVideoOutput = {
  /**
   * Video
   *
   * The generated video file.
   */
  video?: FalAiKandinsky5TextToVideoFile
}

/**
 * File
 */
export type FalAiKandinsky5TextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Veo31TextToVideoInput
 */
export type Veo31FastInput = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video.
   */
  duration?: '4s' | '6s' | '8s'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * Auto Fix
   *
   * Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.
   */
  auto_fix?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '720p' | '1080p' | '4k'
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the video generation.
   */
  negative_prompt?: string
}

/**
 * Veo31TextToVideoOutput
 */
export type Veo31FastOutput = {
  /**
   * Video
   *
   * The generated video.
   */
  video: FalAiVeo31FastFile
}

/**
 * File
 */
export type FalAiVeo31FastFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Veo31TextToVideoInput
 */
export type Veo31Input = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video.
   */
  duration?: '4s' | '6s' | '8s'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Generate Audio
   *
   * Whether to generate audio for the video.
   */
  generate_audio?: boolean
  /**
   * Auto Fix
   *
   * Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.
   */
  auto_fix?: boolean
  /**
   * Resolution
   *
   * The resolution of the generated video.
   */
  resolution?: '720p' | '1080p' | '4k'
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the video generation.
   */
  negative_prompt?: string
}

/**
 * Veo31TextToVideoOutput
 */
export type Veo31Output = {
  /**
   * Video
   *
   * The generated video.
   */
  video: FalAiVeo31File
}

/**
 * File
 */
export type FalAiVeo31File = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ProTextToVideoInput
 */
export type Sora2TextToVideoProInput = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * Duration of the generated video in seconds
   */
  duration?: 4 | 8 | 12
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '9:16' | '16:9'
  /**
   * Delete Video
   *
   * Whether to delete the video after generation for privacy reasons. If True, the video cannot be used for remixing and will be permanently deleted.
   */
  delete_video?: boolean
}

/**
 * ProTextToVideoOutput
 */
export type Sora2TextToVideoProOutput = {
  /**
   * Spritesheet
   *
   * Spritesheet image for the video
   */
  spritesheet?: ImageFile
  /**
   * Thumbnail
   *
   * Thumbnail image for the video
   */
  thumbnail?: ImageFile
  /**
   * Video ID
   *
   * The ID of the generated video
   */
  video_id: string
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiSora2TextToVideoProVideoFile
}

/**
 * ImageFile
 */
export type ImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * VideoFile
 */
export type FalAiSora2TextToVideoProVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number
  /**
   * Height
   *
   * The height of the video
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number
  /**
   * Width
   *
   * The width of the video
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TextToVideoInput
 */
export type Sora2TextToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * Duration of the generated video in seconds
   */
  duration?: 4 | 8 | 12
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '720p'
  /**
   * Model
   *
   * The model to use for the generation. When the default model is selected, the latest snapshot of the model will be used - otherwise, select a specific snapshot of the model.
   */
  model?: 'sora-2' | 'sora-2-2025-12-08' | 'sora-2-2025-10-06'
  /**
   * Delete Video
   *
   * Whether to delete the video after generation for privacy reasons. If True, the video cannot be used for remixing and will be permanently deleted.
   */
  delete_video?: boolean
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '9:16' | '16:9'
}

/**
 * TextToVideoOutput
 */
export type Sora2TextToVideoOutput = {
  /**
   * Spritesheet
   *
   * Spritesheet image for the video
   */
  spritesheet?: FalAiSora2TextToVideoImageFile
  /**
   * Thumbnail
   *
   * Thumbnail image for the video
   */
  thumbnail?: FalAiSora2TextToVideoImageFile
  /**
   * Video ID
   *
   * The ID of the generated video
   */
  video_id: string
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiSora2TextToVideoVideoFile
}

/**
 * ImageFile
 */
export type FalAiSora2TextToVideoImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Height
   *
   * The height of the image
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Width
   *
   * The width of the image
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * VideoFile
 */
export type FalAiSora2TextToVideoVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number
  /**
   * Height
   *
   * The height of the video
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number
  /**
   * Width
   *
   * The width of the video
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * OviT2VRequest
 */
export type OviInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the generated video in W:H format. One of (512x992, 992x512, 960x512, 512x960, 720x720, or 448x1120).
   */
  resolution?:
    | '512x992'
    | '992x512'
    | '960x512'
    | '512x960'
    | '720x720'
    | '448x1120'
    | '1120x448'
  /**
   * Num Inference Steps
   *
   * The number of inference steps.
   */
  num_inference_steps?: number
  /**
   * Audio Negative Prompt
   *
   * Negative prompt for audio generation.
   */
  audio_negative_prompt?: string
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number | unknown
}

/**
 * OviT2VResponse
 */
export type OviOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * The generated video file.
   */
  video?: FalAiOviFile | unknown
}

/**
 * File
 */
export type FalAiOviFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * TextToVideoInput
 *
 * Input for text-to-video generation
 */
export type Wan25PreviewTextToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt for video generation. Supports Chinese and English, max 800 characters.
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution tier
   */
  resolution?: '480p' | '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Duration
   *
   * Duration of the generated video in seconds. Choose between 5 or 10 seconds.
   */
  duration?: '5' | '10'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Audio Url
   *
   *
   * URL of the audio to use as the background music. Must be publicly accessible.
   * Limit handling: If the audio duration exceeds the duration value (5 or 10 seconds),
   * the audio is truncated to the first 5 or 10 seconds, and the rest is discarded. If
   * the audio is shorter than the video, the remaining part of the video will be silent.
   * For example, if the audio is 3 seconds long and the video duration is 5 seconds, the
   * first 3 seconds of the output video will have sound, and the last 2 seconds will be silent.
   * - Format: WAV, MP3.
   * - Duration: 3 to 30 s.
   * - File size: Up to 15 MB.
   *
   */
  audio_url?: string
  /**
   * Negative Prompt
   *
   * Negative prompt to describe content to avoid. Max 500 characters.
   */
  negative_prompt?: string
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt rewriting using LLM. Improves results for short prompts but increases processing time.
   */
  enable_prompt_expansion?: boolean
}

/**
 * VideoOutput
 *
 * Base output for video generation
 */
export type Wan25PreviewTextToVideoOutput = {
  /**
   * Actual Prompt
   *
   * The actual prompt used if prompt rewriting was enabled
   */
  actual_prompt?: string
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * The generated video file
   */
  video: FalAiWan25PreviewTextToVideoVideoFile
}

/**
 * VideoFile
 */
export type FalAiWan25PreviewTextToVideoVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number
  /**
   * Height
   *
   * The height of the video
   */
  height?: number
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number
  /**
   * Width
   *
   * The width of the video
   */
  width?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TextToVideoRequest
 */
export type AvatarsTextToVideoInput = {
  /**
   * Text
   */
  text: string
  /**
   * Voice
   */
  voice:
    | 'Rachel'
    | 'Clyde'
    | 'Roger'
    | 'Sarah'
    | 'Laura'
    | 'Thomas'
    | 'Charlie'
    | 'George'
    | 'Callum'
    | 'River'
    | 'Harry'
    | 'Liam'
    | 'Alice'
    | 'Matilda'
    | 'Will'
    | 'Jessica'
    | 'Lilly'
    | 'Bill'
    | 'Oxley'
    | 'Luna'
  /**
   * Remove Background
   *
   * Enabling the remove background feature will result in a 50% increase in the price.
   */
  remove_background?: boolean
  /**
   * Avatar
   */
  avatar:
    | 'Mia outdoor (UGC)'
    | 'Lara (Masterclass)'
    | 'Ines (UGC)'
    | 'Maria (Masterclass)'
    | 'Emma (UGC)'
    | 'Sienna (Masterclass)'
    | 'Elena (UGC)'
    | 'Jasmine (Masterclass)'
    | 'Amara (Masterclass)'
    | 'Ryan podcast (UGC)'
    | 'Tyler (Masterclass)'
    | 'Jayse (Masterclass)'
    | 'Paul (Masterclass)'
    | 'Matteo (UGC)'
    | 'Daniel car (UGC)'
    | 'Dario (Masterclass)'
    | 'Viva (Masterclass)'
    | 'Chen (Masterclass)'
    | 'Alex (Masterclass)'
    | 'Vanessa (UGC)'
    | 'Laurent (UGC)'
    | 'Noemie car (UGC)'
    | 'Brandon (UGC)'
    | 'Byron (Masterclass)'
    | 'Calista (Masterclass)'
    | 'Milo (Masterclass)'
    | 'Fabien (Masterclass)'
    | 'Rose (UGC)'
}

/**
 * InferenceResult
 */
export type AvatarsTextToVideoOutput = {
  /**
   * Moderation Transcription
   */
  moderation_transcription?: string | unknown
  /**
   * Moderation Error
   */
  moderation_error?: string | unknown
  /**
   * Moderation Flagged
   */
  moderation_flagged?: boolean
  video?: Video | unknown
}

/**
 * Video
 */
export type Video = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * TextToVideoRequest
 */
export type PixverseV5TextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Duration
   *
   * The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds
   */
  duration?: '5' | '8'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * VideoOutputV5
 */
export type PixverseV5TextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPixverseV5TextToVideoFile
}

/**
 * File
 */
export type FalAiPixverseV5TextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * InfiniTalkSingleTextRequest
 */
export type InfinitalkSingleTextInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the video to generate. Must be either 480p or 720p.
   */
  resolution?: '480p' | '720p'
  /**
   * Acceleration
   *
   * The acceleration level to use for generation.
   */
  acceleration?: 'none' | 'regular' | 'high'
  /**
   * Text Input
   *
   * The text input to guide video generation.
   */
  text_input: string
  /**
   * Image URL
   *
   * URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.
   */
  image_url: string
  /**
   * Voice
   *
   * The voice to use for speech generation
   */
  voice:
    | 'Aria'
    | 'Roger'
    | 'Sarah'
    | 'Laura'
    | 'Charlie'
    | 'George'
    | 'Callum'
    | 'River'
    | 'Liam'
    | 'Charlotte'
    | 'Alice'
    | 'Matilda'
    | 'Will'
    | 'Jessica'
    | 'Eric'
    | 'Chris'
    | 'Brian'
    | 'Daniel'
    | 'Lily'
    | 'Bill'
  /**
   * Number of Frames
   *
   * Number of frames to generate. Must be between 41 to 721.
   */
  num_frames?: number
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
}

/**
 * AvatarSingleTextResponse
 */
export type InfinitalkSingleTextOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiInfinitalkSingleTextFile
}

/**
 * File
 */
export type FalAiInfinitalkSingleTextFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * MareyInputT2V
 */
export type MareyT2vInput = {
  /**
   * Prompt
   *
   * The prompt to generate a video from
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video.
   */
  duration?: '5s' | '10s'
  /**
   * Dimensions
   *
   * The dimensions of the generated video in width x height format.
   */
  dimensions?: '1920x1080' | '1152x1152' | '1536x1152' | '1152x1536'
  /**
   * Guidance Scale
   *
   * Controls how strongly the generation is guided by the prompt (0-20). Higher values follow the prompt more closely.
   */
  guidance_scale?: number | unknown
  /**
   * Seed
   *
   * Seed for random number generation. Use -1 for random seed each run.
   */
  seed?: number | unknown
  /**
   * Negative Prompt
   *
   * Negative prompt used to guide the model away from undesirable features.
   */
  negative_prompt?: string | unknown
}

/**
 * MareyOutput
 */
export type MareyT2vOutput = {
  video: MoonvalleyMareyT2vFile
}

/**
 * File
 */
export type MoonvalleyMareyT2vFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * WanLoRAT2VRequest
 */
export type WanV22A14bTextToVideoLoraInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Shift
   *
   * Shift value for the video. Must be between 1.0 and 10.0.
   */
  shift?: number
  /**
   * Acceleration
   *
   * Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Number of Interpolated Frames
   *
   * Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.
   */
  num_interpolated_frames?: number
  /**
   * Reverse Video
   *
   * If true, the video will be reversed.
   */
  reverse_video?: boolean
  /**
   * Loras
   *
   * LoRA weights to be used in the inference.
   */
  loras?: Array<LoRaWeight>
  /**
   * Frames per Second
   *
   * Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.
   */
  frames_per_second?: number | unknown
  /**
   * Guidance Scale (1st Stage)
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guidance_scale?: number
  /**
   * Number of Frames
   *
   * Number of frames to generate. Must be between 17 to 161 (inclusive).
   */
  num_frames?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, input data will be checked for safety before processing.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Video Write Mode
   *
   * The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Resolution
   *
   * Resolution of the generated video (480p, 580p, or 720p).
   */
  resolution?: '480p' | '580p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video (16:9 or 9:16).
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Enable Output Safety Checker
   *
   * If set to true, output video will be checked for safety after generation.
   */
  enable_output_safety_checker?: boolean
  /**
   * Guidance Scale (2nd Stage)
   *
   * Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.
   */
  guidance_scale_2?: number
  /**
   * Video Quality
   *
   * The quality of the output video. Higher quality means better visual quality but larger file size.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number | unknown
  /**
   * Interpolator Model
   *
   * The model to use for frame interpolation. If None, no interpolation is applied.
   */
  interpolator_model?: 'none' | 'film' | 'rife'
  /**
   * Number of Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Adjust FPS for Interpolation
   *
   * If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.
   */
  adjust_fps_for_interpolation?: boolean
}

/**
 * LoRAWeight
 */
export type LoRaWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
  /**
   * Transformer
   *
   * Specifies the transformer to load the lora weight into. 'high' loads into the high-noise transformer, 'low' loads it into the low-noise transformer, while 'both' loads the LoRA into both transformers.
   */
  transformer?: 'high' | 'low' | 'both'
  /**
   * Weight Name
   *
   * Name of the LoRA weight. Used only if `path` is a Hugging Face repository, and required only if you have more than 1 safetensors file in the repo.
   */
  weight_name?: string | unknown
}

/**
 * WanT2VResponse
 */
export type WanV22A14bTextToVideoLoraOutput = {
  /**
   * Prompt
   *
   * The text prompt used for video generation.
   */
  prompt?: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  video: FalAiWanV22A14bTextToVideoLoraFile
}

/**
 * File
 */
export type FalAiWanV22A14bTextToVideoLoraFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * WanDistillT2VRequest
 */
export type WanV225bTextToVideoDistillInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Shift
   *
   * Shift value for the video. Must be between 1.0 and 10.0.
   */
  shift?: number
  /**
   * Number of Interpolated Frames
   *
   * Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.
   */
  num_interpolated_frames?: number
  /**
   * Frames per Second
   *
   * Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.
   */
  frames_per_second?: number | unknown
  /**
   * Guidance Scale (1st Stage)
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guidance_scale?: number
  /**
   * Number of Frames
   *
   * Number of frames to generate. Must be between 17 to 161 (inclusive).
   */
  num_frames?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, input data will be checked for safety before processing.
   */
  enable_safety_checker?: boolean
  /**
   * Video Write Mode
   *
   * The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Resolution
   *
   * Resolution of the generated video (580p or 720p).
   */
  resolution?: '580p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video (16:9 or 9:16).
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Enable Output Safety Checker
   *
   * If set to true, output video will be checked for safety after generation.
   */
  enable_output_safety_checker?: boolean
  /**
   * Video Quality
   *
   * The quality of the output video. Higher quality means better visual quality but larger file size.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number | unknown
  /**
   * Interpolator Model
   *
   * The model to use for frame interpolation. If None, no interpolation is applied.
   */
  interpolator_model?: 'none' | 'film' | 'rife'
  /**
   * Number of Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Adjust FPS for Interpolation
   *
   * If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.
   */
  adjust_fps_for_interpolation?: boolean
}

/**
 * WanSmallT2VResponse
 */
export type WanV225bTextToVideoDistillOutput = {
  /**
   * Prompt
   *
   * The text prompt used for video generation.
   */
  prompt?: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  video: FalAiWanV225bTextToVideoDistillFile
}

/**
 * File
 */
export type FalAiWanV225bTextToVideoDistillFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * WanSmallFastVideoT2VRequest
 */
export type WanV225bTextToVideoFastWanInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Number of Interpolated Frames
   *
   * Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.
   */
  num_interpolated_frames?: number
  /**
   * Frames per Second
   *
   * Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.
   */
  frames_per_second?: number | unknown
  /**
   * Guidance Scale
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guidance_scale?: number
  /**
   * Number of Frames
   *
   * Number of frames to generate. Must be between 17 to 161 (inclusive).
   */
  num_frames?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, input data will be checked for safety before processing.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Video Write Mode
   *
   * The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Resolution
   *
   * Resolution of the generated video (580p or 720p).
   */
  resolution?: '480p' | '580p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video (16:9 or 9:16).
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Enable Output Safety Checker
   *
   * If set to true, output video will be checked for safety after generation.
   */
  enable_output_safety_checker?: boolean
  /**
   * Video Quality
   *
   * The quality of the output video. Higher quality means better visual quality but larger file size.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number | unknown
  /**
   * Interpolator Model
   *
   * The model to use for frame interpolation. If None, no interpolation is applied.
   */
  interpolator_model?: 'none' | 'film' | 'rife'
  /**
   * Adjust FPS for Interpolation
   *
   * If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.
   */
  adjust_fps_for_interpolation?: boolean
}

/**
 * WanSmallFastVideoT2VResponse
 */
export type WanV225bTextToVideoFastWanOutput = {
  /**
   * Prompt
   *
   * The text prompt used for video generation.
   */
  prompt?: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  video: FalAiWanV225bTextToVideoFastWanFile
}

/**
 * File
 */
export type FalAiWanV225bTextToVideoFastWanFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * WanTurboT2VRequest
 */
export type WanV22A14bTextToVideoTurboInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p, 580p, or 720p).
   */
  resolution?: '480p' | '580p' | '720p'
  /**
   * Acceleration
   *
   * Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video (16:9 or 9:16).
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Video Write Mode
   *
   * The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Enable Output Safety Checker
   *
   * If set to true, output video will be checked for safety after generation.
   */
  enable_output_safety_checker?: boolean
  /**
   * Video Quality
   *
   * The quality of the output video. Higher quality means better visual quality but larger file size.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Safety Checker
   *
   * If set to true, input data will be checked for safety before processing.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number | unknown
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean
}

/**
 * WanTurboT2VResponse
 */
export type WanV22A14bTextToVideoTurboOutput = {
  /**
   * Prompt
   *
   * The text prompt used for video generation.
   */
  prompt?: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  video: FalAiWanV22A14bTextToVideoTurboFile
}

/**
 * File
 */
export type FalAiWanV22A14bTextToVideoTurboFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * WanSmallT2VRequest
 */
export type WanV225bTextToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Shift
   *
   * Shift value for the video. Must be between 1.0 and 10.0.
   */
  shift?: number
  /**
   * Number of Interpolated Frames
   *
   * Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.
   */
  num_interpolated_frames?: number
  /**
   * Frames per Second
   *
   * Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.
   */
  frames_per_second?: number | unknown
  /**
   * Guidance Scale
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guidance_scale?: number
  /**
   * Number of Frames
   *
   * Number of frames to generate. Must be between 17 to 161 (inclusive).
   */
  num_frames?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, input data will be checked for safety before processing.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Video Write Mode
   *
   * The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Resolution
   *
   * Resolution of the generated video (580p or 720p).
   */
  resolution?: '580p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video (16:9 or 9:16).
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Enable Output Safety Checker
   *
   * If set to true, output video will be checked for safety after generation.
   */
  enable_output_safety_checker?: boolean
  /**
   * Video Quality
   *
   * The quality of the output video. Higher quality means better visual quality but larger file size.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number | unknown
  /**
   * Interpolator Model
   *
   * The model to use for frame interpolation. If None, no interpolation is applied.
   */
  interpolator_model?: 'none' | 'film' | 'rife'
  /**
   * Number of Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Adjust FPS for Interpolation
   *
   * If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.
   */
  adjust_fps_for_interpolation?: boolean
}

/**
 * WanSmallT2VResponse
 */
export type WanV225bTextToVideoOutput = {
  /**
   * Prompt
   *
   * The text prompt used for video generation.
   */
  prompt?: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  video: FalAiWanV225bTextToVideoFile
}

/**
 * File
 */
export type FalAiWanV225bTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * WanT2VRequest
 */
export type WanV22A14bTextToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Shift
   *
   * Shift value for the video. Must be between 1.0 and 10.0.
   */
  shift?: number
  /**
   * Acceleration
   *
   * Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.
   */
  acceleration?: 'none' | 'regular'
  /**
   * Number of Interpolated Frames
   *
   * Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.
   */
  num_interpolated_frames?: number
  /**
   * Frames per Second
   *
   * Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.
   */
  frames_per_second?: number | unknown
  /**
   * Guidance Scale (1st Stage)
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guidance_scale?: number
  /**
   * Number of Frames
   *
   * Number of frames to generate. Must be between 17 to 161 (inclusive).
   */
  num_frames?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, input data will be checked for safety before processing.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Video Write Mode
   *
   * The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.
   */
  video_write_mode?: 'fast' | 'balanced' | 'small'
  /**
   * Resolution
   *
   * Resolution of the generated video (480p, 580p, or 720p).
   */
  resolution?: '480p' | '580p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video (16:9 or 9:16).
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Enable Output Safety Checker
   *
   * If set to true, output video will be checked for safety after generation.
   */
  enable_output_safety_checker?: boolean
  /**
   * Guidance Scale (2nd Stage)
   *
   * Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.
   */
  guidance_scale_2?: number
  /**
   * Video Quality
   *
   * The quality of the output video. Higher quality means better visual quality but larger file size.
   */
  video_quality?: 'low' | 'medium' | 'high' | 'maximum'
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number | unknown
  /**
   * Interpolator Model
   *
   * The model to use for frame interpolation. If None, no interpolation is applied.
   */
  interpolator_model?: 'none' | 'film' | 'rife'
  /**
   * Number of Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Adjust FPS for Interpolation
   *
   * If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.
   */
  adjust_fps_for_interpolation?: boolean
}

/**
 * WanT2VResponse
 */
export type WanV22A14bTextToVideoOutput = {
  /**
   * Prompt
   *
   * The text prompt used for video generation.
   */
  prompt?: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  video: FalAiWanV22A14bTextToVideoFile
}

/**
 * File
 */
export type FalAiWanV22A14bTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * DistilledTextToVideoInput
 *
 * Distilled model input
 */
export type Ltxv13B098DistilledInput = {
  /**
   * Second Pass Skip Initial Steps
   *
   * The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.
   */
  second_pass_skip_initial_steps?: number
  /**
   * Number of Inference Steps
   *
   * Number of inference steps during the first pass.
   */
  first_pass_num_inference_steps?: number
  /**
   * Frame Rate
   *
   * The frame rate of the video.
   */
  frame_rate?: number
  /**
   * Reverse Video
   *
   * Whether to reverse the video.
   */
  reverse_video?: boolean
  /**
   * Prompt
   *
   * Text prompt to guide generation
   */
  prompt: string
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt using a language model.
   */
  expand_prompt?: boolean
  /**
   * Temporal AdaIN Factor
   *
   * The factor for adaptive instance normalization (AdaIN) applied to generated video chunks after the first. This can help deal with a gradual increase in saturation/contrast in the generated video by normalizing the color distribution across the video. A high value will ensure the color distribution is more consistent across the video, while a low value will allow for more variation in color distribution.
   */
  temporal_adain_factor?: number
  /**
   * Loras
   *
   * LoRA weights to use for generation
   */
  loras?: Array<FalAiLtxv13B098DistilledLoRaWeight>
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Number of Frames
   *
   * The number of frames in the video.
   */
  num_frames?: number
  /**
   * Second Pass Number of Inference Steps
   *
   * Number of inference steps during the second pass.
   */
  second_pass_num_inference_steps?: number
  /**
   * Negative Prompt
   *
   * Negative prompt for generation
   */
  negative_prompt?: string
  /**
   * Enable Detail Pass
   *
   * Whether to use a detail pass. If True, the model will perform a second pass to refine the video and enhance details. This incurs a 2.0x cost multiplier on the base price.
   */
  enable_detail_pass?: boolean
  /**
   * Resolution
   *
   * Resolution of the generated video.
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video.
   */
  aspect_ratio?: '9:16' | '1:1' | '16:9'
  /**
   * Tone Map Compression Ratio
   *
   * The compression ratio for tone mapping. This is used to compress the dynamic range of the video to improve visual quality. A value of 0.0 means no compression, while a value of 1.0 means maximum compression.
   */
  tone_map_compression_ratio?: number
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number
}

/**
 * LoRAWeight
 */
export type FalAiLtxv13B098DistilledLoRaWeight = {
  /**
   * Path
   *
   * URL or path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   * Scale of the LoRA weight. This is a multiplier applied to the LoRA weight when loading it.
   */
  scale?: number
  /**
   * Weight Name
   *
   * Name of the LoRA weight. Only used if `path` is a HuggingFace repository, and is only required when the repository contains multiple LoRA weights.
   */
  weight_name?: string
}

/**
 * TextToVideoOutput
 */
export type Ltxv13B098DistilledOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiLtxv13B098DistilledFile
}

/**
 * File
 */
export type FalAiLtxv13B098DistilledFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * ProTextToVideoHailuo02Input
 */
export type MinimaxHailuo02ProTextToVideoInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Prompt
   */
  prompt: string
}

/**
 * TextToVideoHailuo02Output
 */
export type MinimaxHailuo02ProTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiMinimaxHailuo02ProTextToVideoFile
}

/**
 * File
 */
export type FalAiMinimaxHailuo02ProTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * SeedanceProTextToVideoInput
 */
export type BytedanceSeedanceV1ProTextToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt used to generate the video
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality
   */
  resolution?: '480p' | '720p' | '1080p'
  /**
   * Duration
   *
   * Duration of the video in seconds
   */
  duration?: '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9' | '10' | '11' | '12'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '21:9' | '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * Random seed to control video generation. Use -1 for random.
   */
  seed?: number
  /**
   * Camera Fixed
   *
   * Whether to fix the camera position
   */
  camera_fixed?: boolean
}

/**
 * SeedanceProT2VVideoOutput
 */
export type BytedanceSeedanceV1ProTextToVideoOutput = {
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * Generated video file
   */
  video: FalAiBytedanceSeedanceV1ProTextToVideoFile
}

/**
 * File
 */
export type FalAiBytedanceSeedanceV1ProTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * SeedanceTextToVideoInput
 */
export type BytedanceSeedanceV1LiteTextToVideoInput = {
  /**
   * Prompt
   *
   * The text prompt used to generate the video
   */
  prompt: string
  /**
   * Resolution
   *
   * Video resolution - 480p for faster generation, 720p for higher quality
   */
  resolution?: '480p' | '720p' | '1080p'
  /**
   * Duration
   *
   * Duration of the video in seconds
   */
  duration?: '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9' | '10' | '11' | '12'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '21:9' | '16:9' | '4:3' | '1:1' | '3:4' | '9:16' | '9:21'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * Random seed to control video generation. Use -1 for random.
   */
  seed?: number
  /**
   * Camera Fixed
   *
   * Whether to fix the camera position
   */
  camera_fixed?: boolean
}

/**
 * SeedanceVideoOutput
 */
export type BytedanceSeedanceV1LiteTextToVideoOutput = {
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number
  /**
   * Video
   *
   * Generated video file
   */
  video: FalAiBytedanceSeedanceV1LiteTextToVideoFile
}

/**
 * File
 */
export type FalAiBytedanceSeedanceV1LiteTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TextToVideoV21MasterRequest
 */
export type KlingVideoV21MasterTextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video frame
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * TextToVideoV21MasterOutput
 */
export type KlingVideoV21MasterTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV21MasterTextToVideoFile
}

/**
 * File
 */
export type FalAiKlingVideoV21MasterTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Text2VideoInput
 */
export type VeedAvatarsTextToVideoAvatarsTextToVideoInput = {
  /**
   * Text
   */
  text: string
  /**
   * Avatar Id
   *
   * The avatar to use for the video
   */
  avatar_id:
    | 'emily_vertical_primary'
    | 'emily_vertical_secondary'
    | 'marcus_vertical_primary'
    | 'marcus_vertical_secondary'
    | 'mira_vertical_primary'
    | 'mira_vertical_secondary'
    | 'jasmine_vertical_primary'
    | 'jasmine_vertical_secondary'
    | 'jasmine_vertical_walking'
    | 'aisha_vertical_walking'
    | 'elena_vertical_primary'
    | 'elena_vertical_secondary'
    | 'any_male_vertical_primary'
    | 'any_female_vertical_primary'
    | 'any_male_vertical_secondary'
    | 'any_female_vertical_secondary'
    | 'any_female_vertical_walking'
    | 'emily_primary'
    | 'emily_side'
    | 'marcus_primary'
    | 'marcus_side'
    | 'aisha_walking'
    | 'elena_primary'
    | 'elena_side'
    | 'any_male_primary'
    | 'any_female_primary'
    | 'any_male_side'
    | 'any_female_side'
}

/**
 * AvatarsAppOutput
 */
export type VeedAvatarsTextToVideoAvatarsTextToVideoOutput = {
  video: VeedAvatarsTextToVideoFile
}

/**
 * File
 */
export type VeedAvatarsTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * TextToVideoInput
 */
export type LtxVideo13bDevInput = {
  /**
   * Second Pass Skip Initial Steps
   *
   * The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.
   */
  second_pass_skip_initial_steps?: number
  /**
   * First Pass Num Inference Steps
   *
   * Number of inference steps during the first pass.
   */
  first_pass_num_inference_steps?: number
  /**
   * Frame Rate
   *
   * The frame rate of the video.
   */
  frame_rate?: number
  /**
   * Prompt
   *
   * Text prompt to guide generation
   */
  prompt: string
  /**
   * Reverse Video
   *
   * Whether to reverse the video.
   */
  reverse_video?: boolean
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt using a language model.
   */
  expand_prompt?: boolean
  /**
   * Loras
   *
   * LoRA weights to use for generation
   */
  loras?: Array<FalAiLtxVideo13bDevLoRaWeight>
  /**
   * Second Pass Num Inference Steps
   *
   * Number of inference steps during the second pass.
   */
  second_pass_num_inference_steps?: number
  /**
   * Num Frames
   *
   * The number of frames in the video.
   */
  num_frames?: number
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Negative Prompt
   *
   * Negative prompt for generation
   */
  negative_prompt?: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p or 720p).
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video (16:9, 1:1 or 9:16).
   */
  aspect_ratio?: '9:16' | '1:1' | '16:9'
  /**
   * First Pass Skip Final Steps
   *
   * Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.
   */
  first_pass_skip_final_steps?: number
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number
}

/**
 * LoRAWeight
 */
export type FalAiLtxVideo13bDevLoRaWeight = {
  /**
   * Path
   *
   * URL or path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   * Scale of the LoRA weight. This is a multiplier applied to the LoRA weight when loading it.
   */
  scale?: number
  /**
   * Weight Name
   *
   * Name of the LoRA weight. Only used if `path` is a HuggingFace repository, and is only required when the repository contains multiple LoRA weights.
   */
  weight_name?: string
}

/**
 * TextToVideoOutput
 */
export type LtxVideo13bDevOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiLtxVideo13bDevFile
}

/**
 * File
 */
export type FalAiLtxVideo13bDevFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * DistilledTextToVideoInput
 *
 * Distilled model input
 */
export type LtxVideo13bDistilledInput = {
  /**
   * Second Pass Skip Initial Steps
   *
   * The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.
   */
  second_pass_skip_initial_steps?: number
  /**
   * First Pass Num Inference Steps
   *
   * Number of inference steps during the first pass.
   */
  first_pass_num_inference_steps?: number
  /**
   * Frame Rate
   *
   * The frame rate of the video.
   */
  frame_rate?: number
  /**
   * Reverse Video
   *
   * Whether to reverse the video.
   */
  reverse_video?: boolean
  /**
   * Prompt
   *
   * Text prompt to guide generation
   */
  prompt: string
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt using a language model.
   */
  expand_prompt?: boolean
  /**
   * Loras
   *
   * LoRA weights to use for generation
   */
  loras?: Array<FalAiLtxVideo13bDistilledLoRaWeight>
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean
  /**
   * Num Frames
   *
   * The number of frames in the video.
   */
  num_frames?: number
  /**
   * Second Pass Num Inference Steps
   *
   * Number of inference steps during the second pass.
   */
  second_pass_num_inference_steps?: number
  /**
   * Negative Prompt
   *
   * Negative prompt for generation
   */
  negative_prompt?: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p or 720p).
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video (16:9, 1:1 or 9:16).
   */
  aspect_ratio?: '9:16' | '1:1' | '16:9'
  /**
   * First Pass Skip Final Steps
   *
   * Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.
   */
  first_pass_skip_final_steps?: number
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number
}

/**
 * LoRAWeight
 */
export type FalAiLtxVideo13bDistilledLoRaWeight = {
  /**
   * Path
   *
   * URL or path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   * Scale of the LoRA weight. This is a multiplier applied to the LoRA weight when loading it.
   */
  scale?: number
  /**
   * Weight Name
   *
   * Name of the LoRA weight. Only used if `path` is a HuggingFace repository, and is only required when the repository contains multiple LoRA weights.
   */
  weight_name?: string
}

/**
 * TextToVideoOutput
 */
export type LtxVideo13bDistilledOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation.
   */
  prompt: string
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiLtxVideo13bDistilledFile
}

/**
 * File
 */
export type FalAiLtxVideo13bDistilledFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * FastTextToVideoRequest
 */
export type PixverseV45TextToVideoFastInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * VideoOutputV4
 */
export type PixverseV45TextToVideoFastOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPixverseV45TextToVideoFastFile
}

/**
 * File
 */
export type FalAiPixverseV45TextToVideoFastFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TextToVideoRequest
 */
export type PixverseV45TextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Duration
   *
   * The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds
   */
  duration?: '5' | '8'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * VideoOutputV4
 */
export type PixverseV45TextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPixverseV45TextToVideoFile
}

/**
 * File
 */
export type FalAiPixverseV45TextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Q1TextToVideoRequest
 */
export type ViduQ1TextToVideoInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 1500 characters
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the output video
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Style
   *
   * The style of output video
   */
  style?: 'general' | 'anime'
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number
  /**
   * Movement Amplitude
   *
   * The movement amplitude of objects in the frame
   */
  movement_amplitude?: 'auto' | 'small' | 'medium' | 'large'
}

/**
 * Q1TextToVideoOutput
 */
export type ViduQ1TextToVideoOutput = {
  /**
   * Video
   *
   * The generated video using the Q1 model
   */
  video: FalAiViduQ1TextToVideoFile
}

/**
 * File
 */
export type FalAiViduQ1TextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * MagiTextToVideoRequest
 */
export type MagiInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16' | '1:1'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: 4 | 8 | 16 | 32 | 64
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Num Frames
   *
   * Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.
   */
  num_frames?: number
}

/**
 * MagiResponse
 */
export type MagiOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiMagiFile
}

/**
 * File
 */
export type FalAiMagiFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * MagiTextToVideoRequest
 */
export type MagiDistilledInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.
   */
  aspect_ratio?: 'auto' | '16:9' | '9:16' | '1:1'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: 4 | 8 | 16 | 32
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Num Frames
   *
   * Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.
   */
  num_frames?: number
}

/**
 * MagiResponse
 */
export type MagiDistilledOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiMagiDistilledFile
}

/**
 * File
 */
export type FalAiMagiDistilledFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TextToVideoRequest
 */
export type PixverseV4TextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Duration
   *
   * The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds
   */
  duration?: '5' | '8'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * VideoOutputV4
 */
export type PixverseV4TextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPixverseV4TextToVideoFile
}

/**
 * File
 */
export type FalAiPixverseV4TextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * FastTextToVideoRequest
 */
export type PixverseV4TextToVideoFastInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * VideoOutputV4
 */
export type PixverseV4TextToVideoFastOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPixverseV4TextToVideoFastFile
}

/**
 * File
 */
export type FalAiPixverseV4TextToVideoFastFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * LipsyncA2VRequest
 */
export type KlingVideoLipsyncAudioToVideoInput = {
  /**
   * Video Url
   *
   * The URL of the video to generate the lip sync for. Supports .mp4/.mov, 100MB, 210s, 720p/1080p only, width/height 7201920px.
   */
  video_url: string
  /**
   * Audio Url
   *
   * The URL of the audio to generate the lip sync for. Minimum duration is 2s and maximum duration is 60s. Maximum file size is 5MB.
   */
  audio_url: string
}

/**
 * LipsyncA2VOutput
 */
export type KlingVideoLipsyncAudioToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoLipsyncAudioToVideoFile
}

/**
 * File
 */
export type FalAiKlingVideoLipsyncAudioToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * LipsyncT2VRequest
 */
export type KlingVideoLipsyncTextToVideoInput = {
  /**
   * Text
   *
   * Text content for lip-sync video generation. Max 120 characters.
   */
  text: string
  /**
   * Video Url
   *
   * The URL of the video to generate the lip sync for. Supports .mp4/.mov, 100MB, 2-60s, 720p/1080p only, width/height 7201920px. If validation fails, an error is returned.
   */
  video_url: string
  /**
   * Voice Id
   *
   * Voice ID to use for speech synthesis
   */
  voice_id:
    | 'genshin_vindi2'
    | 'zhinen_xuesheng'
    | 'AOT'
    | 'ai_shatang'
    | 'genshin_klee2'
    | 'genshin_kirara'
    | 'ai_kaiya'
    | 'oversea_male1'
    | 'ai_chenjiahao_712'
    | 'girlfriend_4_speech02'
    | 'chat1_female_new-3'
    | 'chat_0407_5-1'
    | 'cartoon-boy-07'
    | 'uk_boy1'
    | 'cartoon-girl-01'
    | 'PeppaPig_platform'
    | 'ai_huangzhong_712'
    | 'ai_huangyaoshi_712'
    | 'ai_laoguowang_712'
    | 'chengshu_jiejie'
    | 'you_pingjing'
    | 'calm_story1'
    | 'uk_man2'
    | 'laopopo_speech02'
    | 'heainainai_speech02'
    | 'reader_en_m-v1'
    | 'commercial_lady_en_f-v1'
    | 'tiyuxi_xuedi'
    | 'tiexin_nanyou'
    | 'girlfriend_1_speech02'
    | 'girlfriend_2_speech02'
    | 'zhuxi_speech02'
    | 'uk_oldman3'
    | 'dongbeilaotie_speech02'
    | 'chongqingxiaohuo_speech02'
    | 'chuanmeizi_speech02'
    | 'chaoshandashu_speech02'
    | 'ai_taiwan_man2_speech02'
    | 'xianzhanggui_speech02'
    | 'tianjinjiejie_speech02'
    | 'diyinnansang_DB_CN_M_04-v2'
    | 'yizhipiannan-v1'
    | 'guanxiaofang-v2'
    | 'tianmeixuemei-v1'
    | 'daopianyansang-v1'
    | 'mengwa-v1'
  /**
   * Voice Speed
   *
   * Speech rate for Text to Video generation
   */
  voice_speed?: number
  /**
   * Voice Language
   *
   * The voice language corresponding to the Voice ID
   */
  voice_language?: 'zh' | 'en'
}

/**
 * LipsyncOutput
 */
export type KlingVideoLipsyncTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoLipsyncTextToVideoFile
}

/**
 * File
 */
export type FalAiKlingVideoLipsyncTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * WanLoRARequest
 */
export type WanT2vLoraInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p,580p, or 720p).
   */
  resolution?: '480p' | '580p' | '720p'
  /**
   * Reverse Video
   *
   * If true, the video will be reversed.
   */
  reverse_video?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video (16:9 or 9:16).
   */
  aspect_ratio?: '9:16' | '16:9'
  /**
   * Loras
   *
   * LoRA weights to be used in the inference.
   */
  loras?: Array<LoraWeight>
  /**
   * Frames Per Second
   *
   * Frames per second of the generated video. Must be between 5 to 24.
   */
  frames_per_second?: number
  /**
   * Turbo Mode
   *
   * If true, the video will be generated faster with no noticeable degradation in the visual quality.
   */
  turbo_mode?: boolean
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Num Frames
   *
   * Number of frames to generate. Must be between 81 to 100 (inclusive).
   */
  num_frames?: number
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
}

/**
 * LoraWeight
 */
export type LoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
  /**
   * Weight Name
   *
   * Name of the LoRA weight. Used only if `path` is a Hugging Face repository, and required only if you have more than 1 safetensors file in the repo.
   */
  weight_name?: string
}

/**
 * WanT2VResponse
 */
export type WanT2vLoraOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiWanT2vLoraFile
}

/**
 * File
 */
export type FalAiWanT2vLoraFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Ray2TextToVideoRequest
 */
export type LumaDreamMachineRay2FlashInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '9:16' | '4:3' | '3:4' | '21:9' | '9:21'
  /**
   * Resolution
   *
   * The resolution of the generated video (720p costs 2x more, 1080p costs 4x more)
   */
  resolution?: '540p' | '720p' | '1080p'
  /**
   * Loop
   *
   * Whether the video should loop (end of video is blended with the beginning)
   */
  loop?: boolean
  /**
   * Duration
   *
   * The duration of the generated video (9s costs 2x more)
   */
  duration?: '5s' | '9s'
}

/**
 * Ray2T2VOutput
 */
export type LumaDreamMachineRay2FlashOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiLumaDreamMachineRay2FlashFile
}

/**
 * File
 */
export type FalAiLumaDreamMachineRay2FlashFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TextToVideoTurboInput
 *
 * Base request for text-to-video generation
 */
export type PikaV2TurboTextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1' | '4:5' | '5:4' | '3:2' | '2:3'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: number
  /**
   * Seed
   *
   * The seed for the random number generator
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the model
   */
  negative_prompt?: string
}

/**
 * TurboTextToVideoOutput
 *
 * Output from text-to-video generation
 */
export type PikaV2TurboTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPikaV2TurboTextToVideoFile
}

/**
 * File
 */
export type FalAiPikaV2TurboTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Pika22TextToVideoRequest
 *
 * Request model for Pika 2.2 text-to-video generation
 */
export type PikaV22TextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '1080p' | '720p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1' | '4:5' | '5:4' | '3:2' | '2:3'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: 5 | 10
  /**
   * Seed
   *
   * The seed for the random number generator
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the model
   */
  negative_prompt?: string
}

/**
 * Pika22TextToVideoOutput
 *
 * Output model for Pika 2.2 text-to-video generation
 */
export type PikaV22TextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPikaV22TextToVideoFile
}

/**
 * File
 */
export type FalAiPikaV22TextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TextToVideov21Input
 *
 * Base request for text-to-video generation
 */
export type PikaV21TextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '720p' | '1080p'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1' | '4:5' | '5:4' | '3:2' | '2:3'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: number
  /**
   * Seed
   *
   * The seed for the random number generator
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the model
   */
  negative_prompt?: string
}

/**
 * TextToVideoV21Output
 *
 * Output from text-to-video generation
 */
export type PikaV21TextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPikaV21TextToVideoFile
}

/**
 * File
 */
export type FalAiPikaV21TextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * WanProT2VRequest
 */
export type WanProTextToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video
   */
  prompt: string
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number | unknown
}

/**
 * WanProT2VResponse
 */
export type WanProTextToVideoOutput = {
  video: FalAiWanProTextToVideoFile
}

/**
 * File
 */
export type FalAiWanProTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * VideoEffectsRequest
 */
export type KlingVideoV15ProEffectsInput = {
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Input Image Urls
   *
   * URL of images to be used for hug, kiss or heart_gesture video.
   */
  input_image_urls?: Array<string>
  /**
   * Effect Scene
   *
   * The effect scene to use for the video generation
   */
  effect_scene:
    | 'hug'
    | 'kiss'
    | 'heart_gesture'
    | 'squish'
    | 'expansion'
    | 'fuzzyfuzzy'
    | 'bloombloom'
    | 'dizzydizzy'
    | 'jelly_press'
    | 'jelly_slice'
    | 'jelly_squish'
    | 'jelly_jiggle'
    | 'pixelpixel'
    | 'yearbook'
    | 'instant_film'
    | 'anime_figure'
    | 'rocketrocket'
    | 'fly_fly'
    | 'disappear'
    | 'lightning_power'
    | 'bullet_time'
    | 'bullet_time_360'
    | 'media_interview'
    | 'day_to_night'
    | "let's_ride"
    | 'jumpdrop'
    | 'swish_swish'
    | 'running_man'
    | 'jazz_jazz'
    | 'swing_swing'
    | 'skateskate'
    | 'building_sweater'
    | 'pure_white_wings'
    | 'black_wings'
    | 'golden_wing'
    | 'pink_pink_wings'
    | 'rampage_ape'
    | 'a_list_look'
    | 'countdown_teleport'
    | 'firework_2026'
    | 'instant_christmas'
    | 'birthday_star'
    | 'firework'
    | 'celebration'
    | 'tiger_hug_pro'
    | 'pet_lion_pro'
    | 'guardian_spirit'
    | 'squeeze_scream'
    | 'inner_voice'
    | 'memory_alive'
    | 'guess_what'
    | 'eagle_snatch'
    | 'hug_from_past'
    | 'instant_kid'
    | 'dollar_rain'
    | 'cry_cry'
    | 'building_collapse'
    | 'mushroom'
    | 'jesus_hug'
    | 'shark_alert'
    | 'lie_flat'
    | 'polar_bear_hug'
    | 'brown_bear_hug'
    | 'office_escape_plow'
    | 'watermelon_bomb'
    | 'boss_coming'
    | 'wig_out'
    | 'car_explosion'
    | 'tiger_hug'
    | 'siblings'
    | 'construction_worker'
    | 'snatched'
    | 'felt_felt'
    | 'plushcut'
}

/**
 * VideoEffectsOutput
 */
export type KlingVideoV15ProEffectsOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV15ProEffectsFile
}

/**
 * File
 */
export type FalAiKlingVideoV15ProEffectsFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * VideoEffectsRequest
 */
export type KlingVideoV16ProEffectsInput = {
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Input Image Urls
   *
   * URL of images to be used for hug, kiss or heart_gesture video.
   */
  input_image_urls?: Array<string>
  /**
   * Effect Scene
   *
   * The effect scene to use for the video generation
   */
  effect_scene:
    | 'hug'
    | 'kiss'
    | 'heart_gesture'
    | 'squish'
    | 'expansion'
    | 'fuzzyfuzzy'
    | 'bloombloom'
    | 'dizzydizzy'
    | 'jelly_press'
    | 'jelly_slice'
    | 'jelly_squish'
    | 'jelly_jiggle'
    | 'pixelpixel'
    | 'yearbook'
    | 'instant_film'
    | 'anime_figure'
    | 'rocketrocket'
    | 'fly_fly'
    | 'disappear'
    | 'lightning_power'
    | 'bullet_time'
    | 'bullet_time_360'
    | 'media_interview'
    | 'day_to_night'
    | "let's_ride"
    | 'jumpdrop'
    | 'swish_swish'
    | 'running_man'
    | 'jazz_jazz'
    | 'swing_swing'
    | 'skateskate'
    | 'building_sweater'
    | 'pure_white_wings'
    | 'black_wings'
    | 'golden_wing'
    | 'pink_pink_wings'
    | 'rampage_ape'
    | 'a_list_look'
    | 'countdown_teleport'
    | 'firework_2026'
    | 'instant_christmas'
    | 'birthday_star'
    | 'firework'
    | 'celebration'
    | 'tiger_hug_pro'
    | 'pet_lion_pro'
    | 'guardian_spirit'
    | 'squeeze_scream'
    | 'inner_voice'
    | 'memory_alive'
    | 'guess_what'
    | 'eagle_snatch'
    | 'hug_from_past'
    | 'instant_kid'
    | 'dollar_rain'
    | 'cry_cry'
    | 'building_collapse'
    | 'mushroom'
    | 'jesus_hug'
    | 'shark_alert'
    | 'lie_flat'
    | 'polar_bear_hug'
    | 'brown_bear_hug'
    | 'office_escape_plow'
    | 'watermelon_bomb'
    | 'boss_coming'
    | 'wig_out'
    | 'car_explosion'
    | 'tiger_hug'
    | 'siblings'
    | 'construction_worker'
    | 'snatched'
    | 'felt_felt'
    | 'plushcut'
}

/**
 * VideoEffectsOutput
 */
export type KlingVideoV16ProEffectsOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV16ProEffectsFile
}

/**
 * File
 */
export type FalAiKlingVideoV16ProEffectsFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * VideoEffectsRequest
 */
export type KlingVideoV1StandardEffectsInput = {
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Input Image Urls
   *
   * URL of images to be used for hug, kiss or heart_gesture video.
   */
  input_image_urls?: Array<string>
  /**
   * Effect Scene
   *
   * The effect scene to use for the video generation
   */
  effect_scene:
    | 'hug'
    | 'kiss'
    | 'heart_gesture'
    | 'squish'
    | 'expansion'
    | 'fuzzyfuzzy'
    | 'bloombloom'
    | 'dizzydizzy'
    | 'jelly_press'
    | 'jelly_slice'
    | 'jelly_squish'
    | 'jelly_jiggle'
    | 'pixelpixel'
    | 'yearbook'
    | 'instant_film'
    | 'anime_figure'
    | 'rocketrocket'
    | 'fly_fly'
    | 'disappear'
    | 'lightning_power'
    | 'bullet_time'
    | 'bullet_time_360'
    | 'media_interview'
    | 'day_to_night'
    | "let's_ride"
    | 'jumpdrop'
    | 'swish_swish'
    | 'running_man'
    | 'jazz_jazz'
    | 'swing_swing'
    | 'skateskate'
    | 'building_sweater'
    | 'pure_white_wings'
    | 'black_wings'
    | 'golden_wing'
    | 'pink_pink_wings'
    | 'rampage_ape'
    | 'a_list_look'
    | 'countdown_teleport'
    | 'firework_2026'
    | 'instant_christmas'
    | 'birthday_star'
    | 'firework'
    | 'celebration'
    | 'tiger_hug_pro'
    | 'pet_lion_pro'
    | 'guardian_spirit'
    | 'squeeze_scream'
    | 'inner_voice'
    | 'memory_alive'
    | 'guess_what'
    | 'eagle_snatch'
    | 'hug_from_past'
    | 'instant_kid'
    | 'dollar_rain'
    | 'cry_cry'
    | 'building_collapse'
    | 'mushroom'
    | 'jesus_hug'
    | 'shark_alert'
    | 'lie_flat'
    | 'polar_bear_hug'
    | 'brown_bear_hug'
    | 'office_escape_plow'
    | 'watermelon_bomb'
    | 'boss_coming'
    | 'wig_out'
    | 'car_explosion'
    | 'tiger_hug'
    | 'siblings'
    | 'construction_worker'
    | 'snatched'
    | 'felt_felt'
    | 'plushcut'
}

/**
 * VideoEffectsOutput
 */
export type KlingVideoV1StandardEffectsOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV1StandardEffectsFile
}

/**
 * File
 */
export type FalAiKlingVideoV1StandardEffectsFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * VideoEffectsRequest
 */
export type KlingVideoV16StandardEffectsInput = {
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Input Image Urls
   *
   * URL of images to be used for hug, kiss or heart_gesture video.
   */
  input_image_urls?: Array<string>
  /**
   * Effect Scene
   *
   * The effect scene to use for the video generation
   */
  effect_scene:
    | 'hug'
    | 'kiss'
    | 'heart_gesture'
    | 'squish'
    | 'expansion'
    | 'fuzzyfuzzy'
    | 'bloombloom'
    | 'dizzydizzy'
    | 'jelly_press'
    | 'jelly_slice'
    | 'jelly_squish'
    | 'jelly_jiggle'
    | 'pixelpixel'
    | 'yearbook'
    | 'instant_film'
    | 'anime_figure'
    | 'rocketrocket'
    | 'fly_fly'
    | 'disappear'
    | 'lightning_power'
    | 'bullet_time'
    | 'bullet_time_360'
    | 'media_interview'
    | 'day_to_night'
    | "let's_ride"
    | 'jumpdrop'
    | 'swish_swish'
    | 'running_man'
    | 'jazz_jazz'
    | 'swing_swing'
    | 'skateskate'
    | 'building_sweater'
    | 'pure_white_wings'
    | 'black_wings'
    | 'golden_wing'
    | 'pink_pink_wings'
    | 'rampage_ape'
    | 'a_list_look'
    | 'countdown_teleport'
    | 'firework_2026'
    | 'instant_christmas'
    | 'birthday_star'
    | 'firework'
    | 'celebration'
    | 'tiger_hug_pro'
    | 'pet_lion_pro'
    | 'guardian_spirit'
    | 'squeeze_scream'
    | 'inner_voice'
    | 'memory_alive'
    | 'guess_what'
    | 'eagle_snatch'
    | 'hug_from_past'
    | 'instant_kid'
    | 'dollar_rain'
    | 'cry_cry'
    | 'building_collapse'
    | 'mushroom'
    | 'jesus_hug'
    | 'shark_alert'
    | 'lie_flat'
    | 'polar_bear_hug'
    | 'brown_bear_hug'
    | 'office_escape_plow'
    | 'watermelon_bomb'
    | 'boss_coming'
    | 'wig_out'
    | 'car_explosion'
    | 'tiger_hug'
    | 'siblings'
    | 'construction_worker'
    | 'snatched'
    | 'felt_felt'
    | 'plushcut'
}

/**
 * VideoEffectsOutput
 */
export type KlingVideoV16StandardEffectsOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV16StandardEffectsFile
}

/**
 * File
 */
export type FalAiKlingVideoV16StandardEffectsFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TextToVideoInput
 */
export type LtxVideoV095Input = {
  /**
   * Prompt
   *
   * Text prompt to guide generation
   */
  prompt: string
  /**
   * Resolution
   *
   * Resolution of the generated video (480p or 720p).
   */
  resolution?: '480p' | '720p'
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video (16:9 or 9:16).
   */
  aspect_ratio?: '9:16' | '16:9'
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt using the model's own capabilities.
   */
  expand_prompt?: boolean
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps
   */
  num_inference_steps?: number
  /**
   * Negative Prompt
   *
   * Negative prompt for generation
   */
  negative_prompt?: string
}

/**
 * TextToVideoOutput
 */
export type LtxVideoV095Output = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiLtxVideoV095File
}

/**
 * File
 */
export type FalAiLtxVideoV095File = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TextToVideoRequest
 */
export type KlingVideoV16ProTextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video frame
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * T2VOutput
 */
export type KlingVideoV16ProTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV16ProTextToVideoFile
}

/**
 * File
 */
export type FalAiKlingVideoV16ProTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * WanT2VRequest
 */
export type WanT2vInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated video (16:9 or 9:16).
   */
  aspect_ratio?: '9:16' | '16:9'
  /**
   * Resolution
   *
   * Resolution of the generated video (480p, 580p, or 720p).
   */
  resolution?: '480p' | '580p' | '720p'
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number
  /**
   * Turbo Mode
   *
   * If true, the video will be generated faster with no noticeable degradation in the visual quality.
   */
  turbo_mode?: boolean
  /**
   * Frames Per Second
   *
   * Frames per second of the generated video. Must be between 5 to 24.
   */
  frames_per_second?: number
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Frames
   *
   * Number of frames to generate. Must be between 81 to 100 (inclusive).
   */
  num_frames?: number
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
}

/**
 * WanT2VResponse
 */
export type WanT2vOutput = {
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiWanT2vFile
}

/**
 * File
 */
export type FalAiWanT2vFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TextToVideoInput
 */
export type Veo2Input = {
  /**
   * Prompt
   *
   * The text prompt describing the video you want to generate
   */
  prompt: string
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5s' | '6s' | '7s' | '8s'
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Seed
   *
   * A seed to use for the video generation
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * A negative prompt to guide the video generation
   */
  negative_prompt?: string
  /**
   * Enhance Prompt
   *
   * Whether to enhance the video generation
   */
  enhance_prompt?: boolean
}

/**
 * TextToVideoOutput
 */
export type Veo2Output = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiVeo2File
}

/**
 * File
 */
export type FalAiVeo2File = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TextToVideoDirectorRequest
 */
export type MinimaxVideo01DirectorInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Prompt
   *
   * Text prompt for video generation. Camera movement instructions can be added using square brackets (e.g. [Pan left] or [Zoom in]). You can use up to 3 combined movements per prompt. Supported movements: Truck left/right, Pan left/right, Push in/Pull out, Pedestal up/down, Tilt up/down, Zoom in/out, Shake, Tracking shot, Static shot. For example: [Truck left, Pan right, Zoom in]. For a more detailed guide, refer https://sixth-switch-2ac.notion.site/T2V-01-Director-Model-Tutorial-with-camera-movement-1886c20a98eb80f395b8e05291ad8645
   */
  prompt: string
}

/**
 * T2VDirectorOutput
 */
export type MinimaxVideo01DirectorOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiMinimaxVideo01DirectorFile
}

/**
 * File
 */
export type FalAiMinimaxVideo01DirectorFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TextToVideoRequest
 */
export type PixverseV35TextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Duration
   *
   * The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds
   */
  duration?: '5' | '8'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p' | '1080p'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * VideoOutput
 */
export type PixverseV35TextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPixverseV35TextToVideoFile
}

/**
 * File
 */
export type FalAiPixverseV35TextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * FastTextToVideoRequest
 */
export type PixverseV35TextToVideoFastInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '4:3' | '1:1' | '3:4' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the generated video
   */
  resolution?: '360p' | '540p' | '720p'
  /**
   * Style
   *
   * The style of the generated video
   */
  style?: 'anime' | '3d_animation' | 'clay' | 'comic' | 'cyberpunk'
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * Negative prompt to be used for the generation
   */
  negative_prompt?: string
}

/**
 * VideoOutput
 */
export type PixverseV35TextToVideoFastOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiPixverseV35TextToVideoFastFile
}

/**
 * File
 */
export type FalAiPixverseV35TextToVideoFastFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Ray2TextToVideoRequest
 */
export type LumaDreamMachineRay2Input = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: '16:9' | '9:16' | '4:3' | '3:4' | '21:9' | '9:21'
  /**
   * Resolution
   *
   * The resolution of the generated video (720p costs 2x more, 1080p costs 4x more)
   */
  resolution?: '540p' | '720p' | '1080p'
  /**
   * Loop
   *
   * Whether the video should loop (end of video is blended with the beginning)
   */
  loop?: boolean
  /**
   * Duration
   *
   * The duration of the generated video (9s costs 2x more)
   */
  duration?: '5s' | '9s'
}

/**
 * Ray2T2VOutput
 */
export type LumaDreamMachineRay2Output = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiLumaDreamMachineRay2File
}

/**
 * File
 */
export type FalAiLumaDreamMachineRay2File = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * HunyuanT2VRequest
 */
export type HunyuanVideoLoraInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Aspect Ratio (W:H)
   *
   * The aspect ratio of the video to generate.
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the video to generate.
   */
  resolution?: '480p' | '580p' | '720p'
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<FalAiHunyuanVideoLoraLoraWeight>
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Seed
   *
   * The seed to use for generating the video.
   */
  seed?: number
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: '129' | '85'
  /**
   * Pro Mode
   *
   * By default, generations are done with 35 steps. Pro mode does 55 steps which results in higher quality videos but will take more time and cost 2x more billing units.
   */
  pro_mode?: boolean
}

/**
 * LoraWeight
 */
export type FalAiHunyuanVideoLoraLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
}

/**
 * HunyuanT2VResponse
 */
export type HunyuanVideoLoraOutput = {
  /**
   * Seed
   *
   * The seed used for generating the video.
   */
  seed: number
  /**
   * Video
   */
  video: FalAiHunyuanVideoLoraFile
}

/**
 * File
 */
export type FalAiHunyuanVideoLoraFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * BaseInput
 */
export type TranspixarInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related video to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Export Fps
   *
   * The target FPS of the video
   */
  export_fps?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to generate video from
   */
  negative_prompt?: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number | unknown
}

/**
 * Output
 */
export type TranspixarOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the video.
   */
  prompt: string
  /**
   * Videos
   *
   * The URL to the generated video
   */
  videos: Array<FalAiTranspixarFile>
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Seed
   *
   *
   * Seed of the generated video. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
}

/**
 * File
 */
export type FalAiTranspixarFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * BaseInput
 */
export type Cogvideox5bInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Use Rife
   *
   * Use RIFE for video interpolation
   */
  use_rife?: boolean
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. We currently support one lora.
   *
   */
  loras?: Array<FalAiCogvideox5bLoraWeight>
  /**
   * Video Size
   *
   * The size of the generated video.
   */
  video_size?:
    | FalAiCogvideox5bImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related video to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Export Fps
   *
   * The target FPS of the video
   */
  export_fps?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to generate video from
   */
  negative_prompt?: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same video every time.
   *
   */
  seed?: number
}

/**
 * LoraWeight
 */
export type FalAiCogvideox5bLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number
}

/**
 * ImageSize
 */
export type FalAiCogvideox5bImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * Output
 */
export type Cogvideox5bOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the video.
   */
  prompt: string
  /**
   * Timings
   */
  timings: {
    [key: string]: number
  }
  /**
   * Seed
   *
   *
   * Seed of the generated video. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number
  /**
   * Video
   *
   * The URL to the generated video
   */
  video: FalAiCogvideox5bFile
}

/**
 * File
 */
export type FalAiCogvideox5bFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TextToVideoRequest
 */
export type KlingVideoV16StandardTextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video frame
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * T2VOutput
 */
export type KlingVideoV16StandardTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV16StandardTextToVideoFile
}

/**
 * File
 */
export type FalAiKlingVideoV16StandardTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TextToVideoLiveRequest
 */
export type MinimaxVideo01LiveInput = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Prompt
   */
  prompt: string
}

/**
 * T2VLiveOutput
 */
export type MinimaxVideo01LiveOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiMinimaxVideo01LiveFile
}

/**
 * File
 */
export type FalAiMinimaxVideo01LiveFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * V1TextToVideoRequest
 */
export type KlingVideoV1StandardTextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video frame
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Advanced Camera Control
   *
   * Advanced Camera control parameters
   */
  advanced_camera_control?: CameraControl
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Camera Control
   *
   * Camera control parameters
   */
  camera_control?:
    | 'down_back'
    | 'forward_up'
    | 'right_turn_forward'
    | 'left_turn_forward'
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * CameraControl
 */
export type CameraControl = {
  /**
   * Movement Type
   *
   * The type of camera movement
   */
  movement_type: 'horizontal' | 'vertical' | 'pan' | 'tilt' | 'roll' | 'zoom'
  /**
   * Movement Value
   *
   * The value of the camera movement
   */
  movement_value: number
}

/**
 * T2VOutput
 */
export type KlingVideoV1StandardTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV1StandardTextToVideoFile
}

/**
 * File
 */
export type FalAiKlingVideoV1StandardTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TextToVideoRequest
 */
export type KlingVideoV15ProTextToVideoInput = {
  /**
   * Prompt
   */
  prompt: string
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video frame
   */
  aspect_ratio?: '16:9' | '9:16' | '1:1'
  /**
   * Duration
   *
   * The duration of the generated video in seconds
   */
  duration?: '5' | '10'
  /**
   * Negative Prompt
   */
  negative_prompt?: string
  /**
   * Cfg Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt.
   *
   */
  cfg_scale?: number
}

/**
 * T2VOutput
 */
export type KlingVideoV15ProTextToVideoOutput = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiKlingVideoV15ProTextToVideoFile
}

/**
 * File
 */
export type FalAiKlingVideoV15ProTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * MochiT2VInput
 */
export type MochiV1Input = {
  /**
   * Prompt
   *
   * The prompt to generate a video from.
   */
  prompt: string
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean
  /**
   * Seed
   *
   * The seed to use for generating the video.
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * The negative prompt for the video.
   */
  negative_prompt?: string
}

/**
 * MochiT2VOutput
 */
export type MochiV1Output = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiMochiV1File
}

/**
 * File
 */
export type FalAiMochiV1File = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * HunyuanVideoRequest
 */
export type HunyuanVideoInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Aspect Ratio (W:H)
   *
   * The aspect ratio of the video to generate.
   */
  aspect_ratio?: '16:9' | '9:16'
  /**
   * Resolution
   *
   * The resolution of the video to generate.
   */
  resolution?: '480p' | '580p' | '720p'
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean
  /**
   * Num Inference Steps
   *
   * The number of inference steps to run. Lower gets faster results, higher gets better results.
   */
  num_inference_steps?: number
  /**
   * Seed
   *
   * The seed to use for generating the video.
   */
  seed?: number
  /**
   * Number of Frames
   *
   * The number of frames to generate.
   */
  num_frames?: '129' | '85'
  /**
   * Pro Mode
   *
   * By default, generations are done with 35 steps. Pro mode does 55 steps which results in higher quality videos but will take more time and cost 2x more billing units.
   */
  pro_mode?: boolean
}

/**
 * HunyuanT2VResponse
 */
export type HunyuanVideoOutput = {
  /**
   * Seed
   *
   * The seed used for generating the video.
   */
  seed: number
  /**
   * Video
   */
  video: FalAiHunyuanVideoFile
}

/**
 * File
 */
export type FalAiHunyuanVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * TextToVideoInput
 */
export type LtxVideoInput = {
  /**
   * Prompt
   *
   * The prompt to generate the video from.
   */
  prompt: string
  /**
   * Guidance Scale
   *
   * The guidance scale to use.
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * The seed to use for random number generation.
   */
  seed?: number
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to take.
   */
  num_inference_steps?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to generate the video from.
   */
  negative_prompt?: string
}

/**
 * Output
 */
export type LtxVideoOutput = {
  /**
   * Seed
   *
   * The seed used for random number generation.
   */
  seed: number
  /**
   * Video
   *
   * The generated video.
   */
  video: FalAiLtxVideoFile
}

/**
 * File
 */
export type FalAiLtxVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * FastSVDTextInput
 */
export type FastSvdTextToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to use as a starting point for the generation.
   */
  prompt: string
  /**
   * Cond Aug
   *
   *
   * The conditoning augmentation determines the amount of noise that will be
   * added to the conditioning frame. The higher the number, the more noise
   * there will be, and the less the video will look like the initial image.
   * Increase it for more motion.
   *
   */
  cond_aug?: number
  /**
   * Deep Cache
   *
   *
   * Enabling [DeepCache](https://github.com/horseee/DeepCache) will make the execution
   * faster, but might sometimes degrade overall quality. The higher the setting, the
   * faster the execution will be, but the more quality might be lost.
   *
   */
  deep_cache?: 'none' | 'minimum' | 'medium' | 'high'
  /**
   * Fps
   *
   *
   * The FPS of the generated video. The higher the number, the faster the video will
   * play. Total video length is 25 frames.
   *
   */
  fps?: number
  /**
   * Motion Bucket Id
   *
   *
   * The motion bucket id determines the motion of the generated video. The
   * higher the number, the more motion there will be.
   *
   */
  motion_bucket_id?: number
  /**
   * Video Size
   *
   * The size of the generated video.
   */
  video_size?:
    | FalAiFastSvdTextToVideoImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Steps
   *
   *
   * The number of steps to run the model for. The higher the number the better
   * the quality and longer it will take to generate.
   *
   */
  steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Negative Prompt
   *
   * The negative prompt to use as a starting point for the generation.
   */
  negative_prompt?: string
}

/**
 * ImageSize
 */
export type FalAiFastSvdTextToVideoImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * FastSVDOutput
 */
export type FastSvdTextToVideoOutput = {
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   *
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiFastSvdTextToVideoFile
}

/**
 * File
 */
export type FalAiFastSvdTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * FastSVDTextInput
 */
export type FastSvdLcmTextToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to use as a starting point for the generation.
   */
  prompt: string
  /**
   * Cond Aug
   *
   *
   * The conditoning augmentation determines the amount of noise that will be
   * added to the conditioning frame. The higher the number, the more noise
   * there will be, and the less the video will look like the initial image.
   * Increase it for more motion.
   *
   */
  cond_aug?: number
  /**
   * Fps
   *
   *
   * The FPS of the generated video. The higher the number, the faster the video will
   * play. Total video length is 25 frames.
   *
   */
  fps?: number
  /**
   * Motion Bucket Id
   *
   *
   * The motion bucket id determines the motion of the generated video. The
   * higher the number, the more motion there will be.
   *
   */
  motion_bucket_id?: number
  /**
   * Video Size
   *
   * The size of the generated video.
   */
  video_size?:
    | FalAiFastSvdLcmTextToVideoImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Steps
   *
   *
   * The number of steps to run the model for. The higher the number the better
   * the quality and longer it will take to generate.
   *
   */
  steps?: number
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
}

/**
 * ImageSize
 */
export type FalAiFastSvdLcmTextToVideoImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * FastSVDOutput
 */
export type FastSvdLcmTextToVideoOutput = {
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   *
   */
  seed: number
  /**
   * Video
   *
   * The generated video file.
   */
  video: FalAiFastSvdLcmTextToVideoFile
}

/**
 * File
 */
export type FalAiFastSvdLcmTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * Input
 */
export type T2vTurboInput = {
  /**
   * Prompt
   *
   * The prompt to generate images from
   */
  prompt: string
  /**
   * Guidance Scale
   *
   * The guidance scale
   */
  guidance_scale?: number
  /**
   * Seed
   *
   * The seed to use for the random number generator
   */
  seed?: number | unknown
  /**
   * Export Fps
   *
   * The FPS of the exported video
   */
  export_fps?: number
  /**
   * Num Frames
   *
   * The number of frames to generate
   */
  num_frames?: number
  /**
   * Num Inference Steps
   *
   * The number of steps to sample
   */
  num_inference_steps?: number
}

/**
 * Output
 */
export type T2vTurboOutput = {
  video: FalAiT2vTurboFile
}

/**
 * File
 */
export type FalAiT2vTurboFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * AnimateDiffT2VInput
 */
export type FastAnimatediffTextToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the video. Be as descriptive as possible for best results.
   */
  prompt: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Fps
   *
   * Number of frames per second to extract from the video.
   */
  fps?: number
  /**
   * Video Size
   *
   * The size of the video to generate.
   */
  video_size?:
    | FalAiFastAnimatediffTextToVideoImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number
  /**
   * Num Frames
   *
   * The number of frames to generate for the video.
   */
  num_frames?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
  /**
   * Motions
   *
   * The motions to apply to the video.
   */
  motions?: Array<
    'zoom-out' | 'zoom-in' | 'pan-left' | 'pan-right' | 'tilt-up' | 'tilt-down'
  >
}

/**
 * ImageSize
 */
export type FalAiFastAnimatediffTextToVideoImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * AnimateDiffT2VOutput
 */
export type FastAnimatediffTextToVideoOutput = {
  /**
   * Seed
   *
   * Seed used for generating the video.
   */
  seed: number
  /**
   * Video
   *
   * Generated video file.
   */
  video: FalAiFastAnimatediffTextToVideoFile
}

/**
 * File
 */
export type FalAiFastAnimatediffTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * AnimateDiffT2VTurboInput
 */
export type FastAnimatediffTurboTextToVideoInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the video. Be as descriptive as possible for best results.
   */
  prompt: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number
  /**
   * Fps
   *
   * Number of frames per second to extract from the video.
   */
  fps?: number
  /**
   * Video Size
   *
   * The size of the video to generate.
   */
  video_size?:
    | FalAiFastAnimatediffTurboTextToVideoImageSize
    | 'square_hd'
    | 'square'
    | 'portrait_4_3'
    | 'portrait_16_9'
    | 'landscape_4_3'
    | 'landscape_16_9'
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Num Frames
   *
   * The number of frames to generate for the video.
   */
  num_frames?: number
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform. 4-12 is recommended for turbo mode.
   */
  num_inference_steps?: number
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string
  /**
   * Motions
   *
   * The motions to apply to the video.
   */
  motions?: Array<
    'zoom-out' | 'zoom-in' | 'pan-left' | 'pan-right' | 'tilt-up' | 'tilt-down'
  >
}

/**
 * ImageSize
 */
export type FalAiFastAnimatediffTurboTextToVideoImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number
}

/**
 * AnimateDiffT2VOutput
 */
export type FastAnimatediffTurboTextToVideoOutput = {
  /**
   * Seed
   *
   * Seed used for generating the video.
   */
  seed: number
  /**
   * Video
   *
   * Generated video file.
   */
  video: FalAiFastAnimatediffTurboTextToVideoFile
}

/**
 * File
 */
export type FalAiFastAnimatediffTurboTextToVideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}

/**
 * TextToVideoRequest
 */
export type MinimaxVideo01Input = {
  /**
   * Prompt Optimizer
   *
   * Whether to use the model's prompt optimizer
   */
  prompt_optimizer?: boolean
  /**
   * Prompt
   */
  prompt: string
}

/**
 * VideoOutput
 */
export type MinimaxVideo01Output = {
  /**
   * Video
   *
   * The generated video
   */
  video: FalAiMinimaxVideo01File
}

/**
 * File
 */
export type FalAiMinimaxVideo01File = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File
}

/**
 * AnimatediffLCMInput
 */
export type AnimatediffSparsectrlLcmInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable
   * Diffusion will output the same image every time.
   *
   */
  seed?: number
  /**
   * Controlnet Type
   *
   * The type of controlnet to use for generating the video. The controlnet determines how the video will be animated.
   */
  controlnet_type?: 'scribble' | 'rgb'
  /**
   * Keyframe 2 Index
   *
   * The frame index of the third keyframe to use for the generation.
   */
  keyframe_2_index?: number
  /**
   * Keyframe 0 Index
   *
   * The frame index of the first keyframe to use for the generation.
   */
  keyframe_0_index?: number
  /**
   * Keyframe 1 Image Url
   *
   * The URL of the second keyframe to use for the generation.
   */
  keyframe_1_image_url?: string | null
  /**
   * Keyframe 1 Index
   *
   * The frame index of the second keyframe to use for the generation.
   */
  keyframe_1_index?: number
  /**
   * Classifier-Free Guidance scale (CFG)
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number
  /**
   * Number of inference steps
   *
   * Increasing the amount of steps tells Stable Diffusion that it should take more steps to generate your final result which can increase the amount of detail in your image.
   */
  num_inference_steps?: number
  /**
   * Keyframe 2 Image Url
   *
   * The URL of the third keyframe to use for the generation.
   */
  keyframe_2_image_url?: string | null
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to specify what you don't want.
   *
   */
  negative_prompt?: string
  /**
   * Keyframe 0 Image Url
   *
   * The URL of the first keyframe to use for the generation.
   */
  keyframe_0_image_url?: string | null
}

/**
 * AnimatediffLCMOutput
 */
export type AnimatediffSparsectrlLcmOutput = {
  /**
   * Seed
   *
   * The seed used to generate the video.
   */
  seed: number
  /**
   * Video
   *
   * Generated video file.
   */
  video: FalAiAnimatediffSparsectrlLcmFile
}

/**
 * File
 */
export type FalAiAnimatediffSparsectrlLcmFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size: number
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name: string
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type: string
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string
}
