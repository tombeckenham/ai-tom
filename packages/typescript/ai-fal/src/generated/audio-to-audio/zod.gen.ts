// This file is auto-generated by @hey-api/openapi-ts

import { z } from 'zod'

export const zFile = z.object({
  url: z.url(),
  content_type: z.optional(z.string()),
  file_name: z.optional(z.string()),
  file_size: z.optional(z.int()),
})

export const zQueueStatus = z.object({
  status: z.enum(['IN_PROGRESS', 'COMPLETED', 'FAILED']),
  response_url: z.optional(z.url()),
})

/**
 * VoiceChangerRequest
 */
export const zElevenlabsVoiceChangerInput = z.object({
  voice: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The voice to use for speech generation',
      }),
    )
    .default('Rachel'),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'The input audio file',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for reproducibility.',
    }),
  ),
  output_format: z.optional(
    z
      .enum([
        'mp3_22050_32',
        'mp3_44100_32',
        'mp3_44100_64',
        'mp3_44100_96',
        'mp3_44100_128',
        'mp3_44100_192',
        'pcm_8000',
        'pcm_16000',
        'pcm_22050',
        'pcm_24000',
        'pcm_44100',
        'pcm_48000',
        'ulaw_8000',
        'alaw_8000',
        'opus_48000_32',
        'opus_48000_64',
        'opus_48000_96',
        'opus_48000_128',
        'opus_48000_192',
      ])
      .register(z.globalRegistry, {
        description:
          'Output format of the generated audio. Formatted as codec_sample_rate_bitrate.',
      }),
  ),
  remove_background_noise: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set, will remove the background noise from your audio input using our audio isolation model.',
      }),
    )
    .default(false),
})

/**
 * File
 */
export const zFalAiElevenlabsVoiceChangerFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * VoiceChangerOutput
 */
export const zElevenlabsVoiceChangerOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'Random seed for reproducibility.',
  }),
  audio: zFalAiElevenlabsVoiceChangerFile,
})

/**
 * NovaSRInput
 */
export const zNovaSrInput = z.object({
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  bitrate: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The bitrate of the output audio.',
      }),
    )
    .default('192k'),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the audio file to enhance.',
  }),
  audio_format: z.optional(
    z
      .enum(['mp3', 'aac', 'm4a', 'ogg', 'opus', 'flac', 'wav'])
      .register(z.globalRegistry, {
        description: 'The format for the output audio.',
      }),
  ),
})

/**
 * NovaSRTimings
 */
export const zNovaSrTimings = z.object({
  postprocess: z.number().register(z.globalRegistry, {
    description: 'Time taken to postprocess the audio in seconds.',
  }),
  inference: z.number().register(z.globalRegistry, {
    description: 'Time taken to run the inference in seconds.',
  }),
  preprocess: z.number().register(z.globalRegistry, {
    description: 'Time taken to preprocess the audio in seconds.',
  }),
})

/**
 * AudioFile
 */
export const zAudioFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  duration: z.optional(
    z.number().register(z.globalRegistry, {
      description: 'The duration of the audio',
    }),
  ),
  bitrate: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The bitrate of the audio',
    }),
  ),
  channels: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The number of channels in the audio',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  sample_rate: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The sample rate of the audio',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * NovaSROutput
 */
export const zNovaSrOutput = z.object({
  timings: zNovaSrTimings,
  audio: zAudioFile,
})

/**
 * DeepFilterNet3Input
 */
export const zDeepfilternet3Input = z.object({
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  audio_format: z.optional(
    z
      .enum(['mp3', 'aac', 'm4a', 'ogg', 'opus', 'flac', 'wav'])
      .register(z.globalRegistry, {
        description: 'The format for the output audio.',
      }),
  ),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the audio to enhance.',
  }),
  bitrate: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The bitrate of the output audio.',
      }),
    )
    .default('192k'),
})

/**
 * DeepFilterNetTimings
 */
export const zDeepFilterNetTimings = z.object({
  postprocess: z.number().register(z.globalRegistry, {
    description: 'Postprocessing time.',
  }),
  inference: z.number().register(z.globalRegistry, {
    description: 'Inference time.',
  }),
  preprocess: z.number().register(z.globalRegistry, {
    description: 'Preprocessing time.',
  }),
})

/**
 * AudioFile
 */
export const zFalAiDeepfilternet3AudioFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  duration: z.optional(
    z.number().register(z.globalRegistry, {
      description: 'The duration of the audio',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
  bitrate: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The bitrate of the audio',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  sample_rate: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The sample rate of the audio',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  channels: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The number of channels in the audio',
    }),
  ),
})

/**
 * DeepFilterNet3Output
 */
export const zDeepfilternet3Output = z.object({
  timings: zDeepFilterNetTimings,
  audio_file: zFalAiDeepfilternet3AudioFile,
})

/**
 * SAMAudioInput
 *
 * Input for text-based audio separation.
 */
export const zSamAudioSeparateInput = z
  .object({
    prompt: z.string().register(z.globalRegistry, {
      description: 'Text prompt describing the sound to isolate.',
    }),
    acceleration: z.optional(
      z.enum(['fast', 'balanced', 'quality']).register(z.globalRegistry, {
        description: 'The acceleration level to use.',
      }),
    ),
    audio_url: z.string().register(z.globalRegistry, {
      description:
        'URL of the audio file to process (WAV, MP3, FLAC supported)',
    }),
    predict_spans: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Automatically predict temporal spans where the target sound occurs.',
        }),
      )
      .default(false),
    output_format: z.optional(
      z.enum(['wav', 'mp3']).register(z.globalRegistry, {
        description: 'Output audio format.',
      }),
    ),
    reranking_candidates: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description:
            'Number of candidates to generate and rank. Higher improves quality but increases latency and cost.',
        }),
      )
      .default(1),
  })
  .register(z.globalRegistry, {
    description: 'Input for text-based audio separation.',
  })

/**
 * File
 */
export const zFalAiSamAudioSeparateFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * SAMAudioSeparateOutput
 *
 * Output for text-based audio separation.
 */
export const zSamAudioSeparateOutput = z
  .object({
    target: zFalAiSamAudioSeparateFile,
    duration: z.number().register(z.globalRegistry, {
      description: 'Duration of the output audio in seconds.',
    }),
    sample_rate: z
      .optional(
        z.int().register(z.globalRegistry, {
          description: 'Sample rate of the output audio in Hz.',
        }),
      )
      .default(48000),
    residual: zFalAiSamAudioSeparateFile,
  })
  .register(z.globalRegistry, {
    description: 'Output for text-based audio separation.',
  })

/**
 * AudioTimeSpan
 *
 * A time span indicating where the target sound occurs.
 */
export const zAudioTimeSpan = z
  .object({
    end: z.number().gte(0).register(z.globalRegistry, {
      description: 'End time of the span in seconds',
    }),
    start: z.number().gte(0).register(z.globalRegistry, {
      description: 'Start time of the span in seconds',
    }),
    include: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to include (True) or exclude (False) sounds in this span',
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description: 'A time span indicating where the target sound occurs.',
  })

/**
 * SAMAudioSpanInput
 *
 * Input for temporal span-based audio separation.
 */
export const zSamAudioSpanSeparateInput = z
  .object({
    prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'Text prompt describing the sound to isolate. Optional but recommended - helps the model identify what type of sound to extract from the span.',
      }),
    ),
    acceleration: z.optional(
      z.enum(['fast', 'balanced', 'quality']).register(z.globalRegistry, {
        description: 'The acceleration level to use.',
      }),
    ),
    spans: z.array(zAudioTimeSpan).register(z.globalRegistry, {
      description:
        'Time spans where the target sound occurs which should be isolated.',
    }),
    output_format: z.optional(
      z.enum(['wav', 'mp3']).register(z.globalRegistry, {
        description: 'Output audio format.',
      }),
    ),
    trim_to_span: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Trim output audio to only include the specified span time range. If False, returns the full audio length with the target sound isolated throughout.',
        }),
      )
      .default(false),
    audio_url: z.string().register(z.globalRegistry, {
      description: 'URL of the audio file to process.',
    }),
    reranking_candidates: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description:
            'Number of candidates to generate and rank. Higher improves quality but increases latency and cost. Requires text prompt; ignored for span-only separation.',
        }),
      )
      .default(1),
  })
  .register(z.globalRegistry, {
    description: 'Input for temporal span-based audio separation.',
  })

/**
 * File
 */
export const zFalAiSamAudioSpanSeparateFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * SAMAudioSpanSeparateOutput
 *
 * Output for span-based audio separation.
 */
export const zSamAudioSpanSeparateOutput = z
  .object({
    target: zFalAiSamAudioSpanSeparateFile,
    duration: z.number().register(z.globalRegistry, {
      description: 'Duration of the output audio in seconds.',
    }),
    sample_rate: z
      .optional(
        z.int().register(z.globalRegistry, {
          description: 'Sample rate of the output audio in Hz.',
        }),
      )
      .default(48000),
    residual: zFalAiSamAudioSpanSeparateFile,
  })
  .register(z.globalRegistry, {
    description: 'Output for span-based audio separation.',
  })

/**
 * MergeAudiosInput
 */
export const zFfmpegApiMergeAudiosInput = z.object({
  audio_urls: z.array(z.string()).min(2).max(5).register(z.globalRegistry, {
    description:
      'List of audio URLs to merge in order. The 0th stream of the audio will be considered as the merge candidate.',
  }),
  output_format: z.optional(
    z.union([
      z.enum([
        'mp3_22050_32',
        'mp3_44100_32',
        'mp3_44100_64',
        'mp3_44100_96',
        'mp3_44100_128',
        'mp3_44100_192',
        'pcm_8000',
        'pcm_16000',
        'pcm_22050',
        'pcm_24000',
        'pcm_44100',
        'pcm_48000',
        'ulaw_8000',
        'alaw_8000',
        'opus_48000_32',
        'opus_48000_64',
        'opus_48000_96',
        'opus_48000_128',
        'opus_48000_192',
      ]),
      z.unknown(),
    ]),
  ),
})

/**
 * File
 */
export const zFalAiFfmpegApiMergeAudiosFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * MergeAudiosOutput
 */
export const zFfmpegApiMergeAudiosOutput = z.object({
  audio: zFalAiFfmpegApiMergeAudiosFile,
})

/**
 * CreateVoiceInput
 *
 * Request model for creating a custom voice.
 */
export const zKlingVideoCreateVoiceInput = z
  .object({
    voice_url: z.string().register(z.globalRegistry, {
      description:
        'URL of the voice audio file. Supports .mp3/.wav audio or .mp4/.mov video. Duration must be 5-30 seconds with clean, single-voice audio.',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Request model for creating a custom voice.',
  })

/**
 * CreateVoiceOutput
 *
 * Response model for creating a custom voice.
 */
export const zKlingVideoCreateVoiceOutput = z
  .object({
    voice_id: z.string().register(z.globalRegistry, {
      description: 'Unique identifier for the created voice',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Response model for creating a custom voice.',
  })

/**
 * DemucsInput
 */
export const zDemucsInput = z.object({
  segment_length: z.optional(z.union([z.int(), z.unknown()])),
  output_format: z.optional(
    z.enum(['wav', 'mp3']).register(z.globalRegistry, {
      description: 'Output audio format for the separated stems',
    }),
  ),
  stems: z.optional(
    z.union([
      z.array(z.enum(['vocals', 'drums', 'bass', 'other', 'guitar', 'piano'])),
      z.unknown(),
    ]),
  ),
  overlap: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Overlap between segments (0.0 to 1.0). Higher values may improve quality but increase processing time.',
      }),
    )
    .default(0.25),
  model: z.optional(
    z
      .enum([
        'htdemucs',
        'htdemucs_ft',
        'htdemucs_6s',
        'hdemucs_mmi',
        'mdx',
        'mdx_extra',
        'mdx_q',
        'mdx_extra_q',
      ])
      .register(z.globalRegistry, {
        description: 'Demucs model to use for separation',
      }),
  ),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'URL of the audio file to separate into stems',
  }),
  shifts: z
    .optional(
      z.int().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Number of random shifts for equivariant stabilization. Higher values improve quality but increase processing time.',
      }),
    )
    .default(1),
})

/**
 * File
 */
export const zFalAiDemucsFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * DemucsOutput
 */
export const zDemucsOutput = z.object({
  vocals: z.optional(z.union([zFalAiDemucsFile, z.unknown()])),
  guitar: z.optional(z.union([zFalAiDemucsFile, z.unknown()])),
  bass: z.optional(z.union([zFalAiDemucsFile, z.unknown()])),
  piano: z.optional(z.union([zFalAiDemucsFile, z.unknown()])),
  other: z.optional(z.union([zFalAiDemucsFile, z.unknown()])),
  drums: z.optional(z.union([zFalAiDemucsFile, z.unknown()])),
})

/**
 * AudioUnderstandingInput
 */
export const zAudioUnderstandingInput = z.object({
  prompt: z.string().min(1).max(10000).register(z.globalRegistry, {
    description: 'The question or prompt about the audio content.',
  }),
  detailed_analysis: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to request a more detailed analysis of the audio',
      }),
    )
    .default(false),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'URL of the audio file to analyze',
  }),
})

/**
 * AudioUnderstandingOutput
 */
export const zAudioUnderstandingOutput = z.object({
  output: z.string().register(z.globalRegistry, {
    description: 'The analysis of the audio content based on the prompt',
  }),
})

/**
 * AudioToAudioInput
 */
export const zStableAudio25AudioToAudioInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to guide the audio generation',
  }),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'Sometimes referred to as denoising, this parameter controls how much influence the `audio_url` parameter has on the generated audio. A value of 0 would yield audio that is identical to the input. A value of 1 would be as if you passed in no audio at all.',
      }),
    )
    .default(0.8),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'The audio clip to transform',
  }),
  num_inference_steps: z
    .optional(
      z.int().gte(4).lte(8).register(z.globalRegistry, {
        description: 'The number of steps to denoise the audio for',
      }),
    )
    .default(8),
  guidance_scale: z
    .optional(
      z.int().gte(1).lte(25).register(z.globalRegistry, {
        description:
          'How strictly the diffusion process adheres to the prompt text (higher values make your audio closer to your prompt). ',
      }),
    )
    .default(1),
  seed: z.optional(z.int()),
  total_seconds: z.optional(
    z.int().gte(1).lte(190).register(z.globalRegistry, {
      description:
        'The duration of the audio clip to generate. If not provided, it will be set to the duration of the input audio.',
    }),
  ),
})

/**
 * File
 */
export const zFalAiStableAudio25AudioToAudioFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * AudioToAudioOutput
 */
export const zStableAudio25AudioToAudioOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The random seed used for generation',
  }),
  audio: zFalAiStableAudio25AudioToAudioFile,
})

/**
 * InpaintInput
 */
export const zStableAudio25InpaintInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to guide the audio generation',
  }),
  guidance_scale: z
    .optional(
      z.int().gte(1).lte(25).register(z.globalRegistry, {
        description:
          'How strictly the diffusion process adheres to the prompt text (higher values make your audio closer to your prompt). ',
      }),
    )
    .default(1),
  mask_end: z
    .optional(
      z.int().gte(0).lte(190).register(z.globalRegistry, {
        description: 'The end point of the audio mask',
      }),
    )
    .default(190),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'The audio clip to inpaint',
  }),
  seed: z.optional(z.int()),
  seconds_total: z
    .optional(
      z.int().gte(1).lte(190).register(z.globalRegistry, {
        description:
          'The duration of the audio clip to generate. If not provided, it will be set to the duration of the input audio.',
      }),
    )
    .default(190),
  num_inference_steps: z
    .optional(
      z.int().gte(4).lte(8).register(z.globalRegistry, {
        description: 'The number of steps to denoise the audio for',
      }),
    )
    .default(8),
  mask_start: z
    .optional(
      z.int().gte(0).lte(190).register(z.globalRegistry, {
        description: 'The start point of the audio mask',
      }),
    )
    .default(30),
})

/**
 * File
 */
export const zFalAiStableAudio25InpaintFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * InpaintOutput
 */
export const zStableAudio25InpaintOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The random seed used for generation',
  }),
  audio: zFalAiStableAudio25InpaintFile,
})

/**
 * ExtendInput
 */
export const zV2ExtendInput = z.object({
  prompt: z.optional(z.union([z.string(), z.unknown()])),
  lyrics_prompt: z.optional(z.union([z.string(), z.unknown()])),
  tags: z.optional(z.union([z.array(z.string()), z.unknown()])),
  prompt_strength: z
    .optional(
      z.number().gte(1.4).lte(3.1).register(z.globalRegistry, {
        description:
          'Controls how strongly your prompt influences the output. Greater values adhere more to the prompt but sound less natural. (This is CFG.)',
      }),
    )
    .default(1.8),
  output_bit_rate: z.optional(
    z.union([
      z.union([z.literal(128), z.literal(192), z.literal(256), z.literal(320)]),
      z.unknown(),
    ]),
  ),
  num_songs: z
    .optional(
      z.int().gte(1).lte(2).register(z.globalRegistry, {
        description:
          'Generating 2 songs costs 1.5x the price of generating 1 song. Also, note that using the same seed may not result in identical songs if the number of songs generated is changed.',
      }),
    )
    .default(1),
  output_format: z.optional(z.enum(['flac', 'mp3', 'wav', 'ogg', 'm4a'])),
  side: z.enum(['left', 'right']).register(z.globalRegistry, {
    description: 'Add more to the beginning (left) or end (right) of the song',
  }),
  balance_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Greater means more natural vocals. Lower means sharper instrumentals. We recommend 0.7.',
      }),
    )
    .default(0.7),
  crop_duration: z
    .optional(
      z.number().register(z.globalRegistry, {
        description:
          'Duration in seconds to crop from the selected side before extending from that side.',
      }),
    )
    .default(0),
  audio_url: z.url().min(1).max(2083).register(z.globalRegistry, {
    description:
      'The URL of the audio file to alter. Must be a valid publicly accessible URL.',
  }),
  seed: z.optional(
    z.union([
      z.int().gte(-9223372036854776000).lte(9223372036854776000),
      z.unknown(),
    ]),
  ),
  extend_duration: z.optional(z.union([z.number().lte(85), z.unknown()])),
})

/**
 * File
 */
export const zSonautoV2ExtendFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * ExtendOutput
 */
export const zV2ExtendOutput = z.object({
  tags: z.optional(z.union([z.array(z.string()), z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description:
      'The seed used for generation. This can be used to generate an identical song by passing the same parameters with this seed in a future request.',
  }),
  extend_duration: z.number().register(z.globalRegistry, {
    description: 'The duration in seconds that the song was extended by.',
  }),
  audio: z.array(zSonautoV2ExtendFile).register(z.globalRegistry, {
    description: 'The generated audio files.',
  }),
  lyrics: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * ACEStepAudioOutpaintRequest
 */
export const zAceStepAudioOutpaintInput = z.object({
  number_of_steps: z
    .optional(
      z.int().gte(3).lte(60).register(z.globalRegistry, {
        description: 'Number of steps to generate the audio.',
      }),
    )
    .default(27),
  tags: z.string().register(z.globalRegistry, {
    description:
      'Comma-separated list of genre tags to control the style of the generated audio.',
  }),
  minimum_guidance_scale: z
    .optional(
      z.number().gte(0).lte(200).register(z.globalRegistry, {
        description:
          'Minimum guidance scale for the generation after the decay.',
      }),
    )
    .default(3),
  extend_after_duration: z
    .optional(
      z.number().gte(0).lte(240).register(z.globalRegistry, {
        description: 'Duration in seconds to extend the audio from the end.',
      }),
    )
    .default(30),
  lyrics: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Lyrics to be sung in the audio. If not provided or if [inst] or [instrumental] is the content of this field, no lyrics will be sung. Use control structures like [verse], [chorus] and [bridge] to control the structure of the song.',
      }),
    )
    .default(''),
  tag_guidance_scale: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description: 'Tag guidance scale for the generation.',
      }),
    )
    .default(5),
  scheduler: z.optional(
    z.enum(['euler', 'heun']).register(z.globalRegistry, {
      description: 'Scheduler to use for the generation process.',
    }),
  ),
  extend_before_duration: z
    .optional(
      z.number().gte(0).lte(240).register(z.globalRegistry, {
        description: 'Duration in seconds to extend the audio from the start.',
      }),
    )
    .default(0),
  guidance_type: z.optional(
    z.enum(['cfg', 'apg', 'cfg_star']).register(z.globalRegistry, {
      description: 'Type of CFG to use for the generation process.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(200).register(z.globalRegistry, {
        description: 'Guidance scale for the generation.',
      }),
    )
    .default(15),
  lyric_guidance_scale: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description: 'Lyric guidance scale for the generation.',
      }),
    )
    .default(1.5),
  guidance_interval: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Guidance interval for the generation. 0.5 means only apply guidance in the middle steps (0.25 * infer_steps to 0.75 * infer_steps)',
      }),
    )
    .default(0.5),
  guidance_interval_decay: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Guidance interval decay for the generation. Guidance scale will decay from guidance_scale to min_guidance_scale in the interval. 0.0 means no decay.',
      }),
    )
    .default(0),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'URL of the audio file to be outpainted.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If not provided, a random seed will be used.',
    }),
  ),
  granularity_scale: z
    .optional(
      z.int().gte(-100).lte(100).register(z.globalRegistry, {
        description:
          'Granularity scale for the generation process. Higher values can reduce artifacts.',
      }),
    )
    .default(10),
})

/**
 * File
 */
export const zFalAiAceStepAudioOutpaintFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ACEStepResponse
 */
export const zAceStepAudioOutpaintOutput = z.object({
  tags: z.string().register(z.globalRegistry, {
    description: 'The genre tags used in the generation process.',
  }),
  lyrics: z.string().register(z.globalRegistry, {
    description: 'The lyrics used in the generation process.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The random seed used for the generation process.',
  }),
  audio: zFalAiAceStepAudioOutpaintFile,
})

/**
 * ACEStepAudioInpaintRequest
 */
export const zAceStepAudioInpaintInput = z.object({
  number_of_steps: z
    .optional(
      z.int().gte(3).lte(60).register(z.globalRegistry, {
        description: 'Number of steps to generate the audio.',
      }),
    )
    .default(27),
  start_time: z
    .optional(
      z.number().gte(0).lte(240).register(z.globalRegistry, {
        description: 'start time in seconds for the inpainting process.',
      }),
    )
    .default(0),
  tags: z.string().register(z.globalRegistry, {
    description:
      'Comma-separated list of genre tags to control the style of the generated audio.',
  }),
  minimum_guidance_scale: z
    .optional(
      z.number().gte(0).lte(200).register(z.globalRegistry, {
        description:
          'Minimum guidance scale for the generation after the decay.',
      }),
    )
    .default(3),
  lyrics: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Lyrics to be sung in the audio. If not provided or if [inst] or [instrumental] is the content of this field, no lyrics will be sung. Use control structures like [verse], [chorus] and [bridge] to control the structure of the song.',
      }),
    )
    .default(''),
  end_time_relative_to: z.optional(
    z.enum(['start', 'end']).register(z.globalRegistry, {
      description:
        'Whether the end time is relative to the start or end of the audio.',
    }),
  ),
  tag_guidance_scale: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description: 'Tag guidance scale for the generation.',
      }),
    )
    .default(5),
  scheduler: z.optional(
    z.enum(['euler', 'heun']).register(z.globalRegistry, {
      description: 'Scheduler to use for the generation process.',
    }),
  ),
  end_time: z
    .optional(
      z.number().gte(0).lte(240).register(z.globalRegistry, {
        description: 'end time in seconds for the inpainting process.',
      }),
    )
    .default(30),
  guidance_type: z.optional(
    z.enum(['cfg', 'apg', 'cfg_star']).register(z.globalRegistry, {
      description: 'Type of CFG to use for the generation process.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(200).register(z.globalRegistry, {
        description: 'Guidance scale for the generation.',
      }),
    )
    .default(15),
  lyric_guidance_scale: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description: 'Lyric guidance scale for the generation.',
      }),
    )
    .default(1.5),
  guidance_interval: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Guidance interval for the generation. 0.5 means only apply guidance in the middle steps (0.25 * infer_steps to 0.75 * infer_steps)',
      }),
    )
    .default(0.5),
  variance: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Variance for the inpainting process. Higher values can lead to more diverse results.',
      }),
    )
    .default(0.5),
  guidance_interval_decay: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Guidance interval decay for the generation. Guidance scale will decay from guidance_scale to min_guidance_scale in the interval. 0.0 means no decay.',
      }),
    )
    .default(0),
  start_time_relative_to: z.optional(
    z.enum(['start', 'end']).register(z.globalRegistry, {
      description:
        'Whether the start time is relative to the start or end of the audio.',
    }),
  ),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'URL of the audio file to be inpainted.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If not provided, a random seed will be used.',
    }),
  ),
  granularity_scale: z
    .optional(
      z.int().gte(-100).lte(100).register(z.globalRegistry, {
        description:
          'Granularity scale for the generation process. Higher values can reduce artifacts.',
      }),
    )
    .default(10),
})

/**
 * File
 */
export const zFalAiAceStepAudioInpaintFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ACEStepAudioInpaintResponse
 */
export const zAceStepAudioInpaintOutput = z.object({
  tags: z.string().register(z.globalRegistry, {
    description: 'The genre tags used in the generation process.',
  }),
  lyrics: z.string().register(z.globalRegistry, {
    description: 'The lyrics used in the generation process.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The random seed used for the generation process.',
  }),
  audio: zFalAiAceStepAudioInpaintFile,
})

/**
 * ACEStepAudioToAudioRequest
 */
export const zAceStepAudioToAudioInput = z.object({
  number_of_steps: z
    .optional(
      z.int().gte(3).lte(60).register(z.globalRegistry, {
        description: 'Number of steps to generate the audio.',
      }),
    )
    .default(27),
  tags: z.string().register(z.globalRegistry, {
    description:
      'Comma-separated list of genre tags to control the style of the generated audio.',
  }),
  minimum_guidance_scale: z
    .optional(
      z.number().gte(0).lte(200).register(z.globalRegistry, {
        description:
          'Minimum guidance scale for the generation after the decay.',
      }),
    )
    .default(3),
  lyrics: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Lyrics to be sung in the audio. If not provided or if [inst] or [instrumental] is the content of this field, no lyrics will be sung. Use control structures like [verse], [chorus] and [bridge] to control the structure of the song.',
      }),
    )
    .default(''),
  tag_guidance_scale: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description: 'Tag guidance scale for the generation.',
      }),
    )
    .default(5),
  original_lyrics: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Original lyrics of the audio file.',
      }),
    )
    .default(''),
  scheduler: z.optional(
    z.enum(['euler', 'heun']).register(z.globalRegistry, {
      description: 'Scheduler to use for the generation process.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(200).register(z.globalRegistry, {
        description: 'Guidance scale for the generation.',
      }),
    )
    .default(15),
  guidance_type: z.optional(
    z.enum(['cfg', 'apg', 'cfg_star']).register(z.globalRegistry, {
      description: 'Type of CFG to use for the generation process.',
    }),
  ),
  lyric_guidance_scale: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description: 'Lyric guidance scale for the generation.',
      }),
    )
    .default(1.5),
  guidance_interval: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Guidance interval for the generation. 0.5 means only apply guidance in the middle steps (0.25 * infer_steps to 0.75 * infer_steps)',
      }),
    )
    .default(0.5),
  edit_mode: z.optional(
    z.enum(['lyrics', 'remix']).register(z.globalRegistry, {
      description: 'Whether to edit the lyrics only or remix the audio.',
    }),
  ),
  guidance_interval_decay: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Guidance interval decay for the generation. Guidance scale will decay from guidance_scale to min_guidance_scale in the interval. 0.0 means no decay.',
      }),
    )
    .default(0),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'URL of the audio file to be outpainted.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If not provided, a random seed will be used.',
    }),
  ),
  granularity_scale: z
    .optional(
      z.int().gte(-100).lte(100).register(z.globalRegistry, {
        description:
          'Granularity scale for the generation process. Higher values can reduce artifacts.',
      }),
    )
    .default(10),
  original_tags: z.string().register(z.globalRegistry, {
    description: 'Original tags of the audio file.',
  }),
  original_seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Original seed of the audio file.',
    }),
  ),
})

/**
 * File
 */
export const zFalAiAceStepAudioToAudioFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ACEStepAudioToAudioResponse
 */
export const zAceStepAudioToAudioOutput = z.object({
  tags: z.string().register(z.globalRegistry, {
    description: 'The genre tags used in the generation process.',
  }),
  lyrics: z.string().register(z.globalRegistry, {
    description: 'The lyrics used in the generation process.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The random seed used for the generation process.',
  }),
  audio: zFalAiAceStepAudioToAudioFile,
})

/**
 * CloneRequest
 */
export const zDiaTtsVoiceCloneInput = z.object({
  text: z.string().register(z.globalRegistry, {
    description: 'The text to be converted to speech.',
  }),
  ref_text: z.string().register(z.globalRegistry, {
    description: 'The reference text to be used for TTS.',
  }),
  ref_audio_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the reference audio file.',
  }),
})

/**
 * File
 */
export const zFalAiDiaTtsVoiceCloneFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * DiaCloneOutput
 */
export const zDiaTtsVoiceCloneOutput = z.object({
  audio: zFalAiDiaTtsVoiceCloneFile,
})

/**
 * AudioIsolationRequest
 */
export const zElevenlabsAudioIsolationInput = z.object({
  video_url: z.optional(z.union([z.string(), z.unknown()])),
  audio_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * File
 */
export const zFalAiElevenlabsAudioIsolationFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * TTSOutput
 */
export const zElevenlabsAudioIsolationOutput = z.object({
  audio: zFalAiElevenlabsAudioIsolationFile,
  timestamps: z.optional(z.union([z.array(z.unknown()), z.unknown()])),
})
