// This file is auto-generated by @hey-api/openapi-ts

import { z } from 'zod'

export const zFile = z.object({
  url: z.url(),
  content_type: z.optional(z.string()),
  file_name: z.optional(z.string()),
  file_size: z.optional(z.int()),
})

export const zQueueStatus = z.object({
  status: z.enum(['IN_PROGRESS', 'COMPLETED', 'FAILED']),
  response_url: z.optional(z.url()),
})

/**
 * SpeechInput
 */
export const zNemotronAsrStreamInput = z.object({
  acceleration: z.optional(
    z.enum(['none', 'low', 'medium', 'high']).register(z.globalRegistry, {
      description:
        "Controls the speed/accuracy trade-off. 'none' = best accuracy (1.12s chunks, ~7.16% WER), 'low' = balanced (0.56s chunks, ~7.22% WER), 'medium' = faster (0.16s chunks, ~7.84% WER), 'high' = fastest (0.08s chunks, ~8.53% WER).",
    }),
  ),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'URL of the audio file.',
  }),
})

export const zNemotronAsrStreamOutput = z.unknown()

/**
 * SpeechInput
 */
export const zNemotronAsrInput = z.object({
  acceleration: z.optional(
    z.enum(['none', 'low', 'medium', 'high']).register(z.globalRegistry, {
      description:
        "Controls the speed/accuracy trade-off. 'none' = best accuracy (1.12s chunks, ~7.16% WER), 'low' = balanced (0.56s chunks, ~7.22% WER), 'medium' = faster (0.16s chunks, ~7.84% WER), 'high' = fastest (0.08s chunks, ~8.53% WER).",
    }),
  ),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'URL of the audio file.',
  }),
})

/**
 * SpeechOutput
 */
export const zNemotronAsrOutput = z.object({
  partial: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'True if this is an intermediate result during streaming.',
      }),
    )
    .default(false),
  output: z.string().register(z.globalRegistry, {
    description: 'The transcribed text from the audio.',
  }),
})

/**
 * SileroVADInput
 */
export const zSileroVadInput = z.object({
  audio_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the audio to get speech timestamps from.',
  }),
})

/**
 * SpeechTimestamp
 */
export const zSpeechTimestamp = z.object({
  end: z.number().register(z.globalRegistry, {
    description: 'The end time of the speech in seconds.',
  }),
  start: z.number().register(z.globalRegistry, {
    description: 'The start time of the speech in seconds.',
  }),
})

/**
 * SileroVADOutput
 */
export const zSileroVadOutput = z.object({
  has_speech: z.boolean().register(z.globalRegistry, {
    description: 'Whether the audio has speech.',
  }),
  timestamps: z.array(zSpeechTimestamp).register(z.globalRegistry, {
    description: 'The speech timestamps.',
  }),
})
