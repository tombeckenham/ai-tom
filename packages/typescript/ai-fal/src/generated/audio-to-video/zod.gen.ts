// This file is auto-generated by @hey-api/openapi-ts

import { z } from 'zod'

export const zFile = z.object({
  url: z.url(),
  content_type: z.optional(z.string()),
  file_name: z.optional(z.string()),
  file_size: z.optional(z.int()),
})

export const zQueueStatus = z.object({
  status: z.enum(['IN_PROGRESS', 'COMPLETED', 'FAILED']),
  response_url: z.optional(z.url()),
})

/**
 * DubbingRequest
 */
export const zElevenlabsDubbingInput = z.object({
  video_url: z.optional(z.union([z.string(), z.unknown()])),
  audio_url: z.optional(z.union([z.string(), z.unknown()])),
  highest_resolution: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to use the highest resolution for dubbing.',
      }),
    )
    .default(true),
  target_lang: z.string().register(z.globalRegistry, {
    description: 'Target language code for dubbing (ISO 639-1)',
  }),
  source_lang: z.optional(z.union([z.string(), z.unknown()])),
  num_speakers: z.optional(z.union([z.int().gte(1).lte(50), z.unknown()])),
})

/**
 * File
 */
export const zFalAiElevenlabsDubbingFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * DubbingVideoOutput
 */
export const zElevenlabsDubbingOutput = z.object({
  target_lang: z.string().register(z.globalRegistry, {
    description: 'The target language of the dubbed content',
  }),
  video: zFalAiElevenlabsDubbingFile,
})

/**
 * BoundingBox
 */
export const zBoundingBox = z.object({
  y: z.number().register(z.globalRegistry, {
    description: 'Y-coordinate of the top-left corner',
  }),
  x: z.number().register(z.globalRegistry, {
    description: 'X-coordinate of the top-left corner',
  }),
  h: z.number().register(z.globalRegistry, {
    description: 'Height of the bounding box',
  }),
  w: z.number().register(z.globalRegistry, {
    description: 'Width of the bounding box',
  }),
  label: z.string().register(z.globalRegistry, {
    description: 'Label of the bounding box',
  }),
})

/**
 * MultiSpeakerImageAudioToVideoRequest
 *
 * Request model for multi-speaker image+audio to video generation.
 */
export const zLongcatMultiAvatarImageAudioToVideoInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The prompt to guide the video generation.',
        }),
      )
      .default(
        'Two people are having a conversation with natural expressions and movements.',
      ),
    num_inference_steps: z
      .optional(
        z.int().gte(10).lte(100).register(z.globalRegistry, {
          description: 'The number of inference steps to use.',
        }),
      )
      .default(30),
    audio_url_person2: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The URL of the audio file for person 2 (right side).',
        }),
      )
      .default(
        'https://raw.githubusercontent.com/meituan-longcat/LongCat-Video/refs/heads/main/assets/avatar/multi/sing_woman.WAV',
      ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable safety checker.',
        }),
      )
      .default(true),
    bbox_person1: z.optional(zBoundingBox),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt to avoid in the video generation.',
        }),
      )
      .default(
        'Close-up, Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards',
      ),
    text_guidance_scale: z
      .optional(
        z.number().gte(1).lte(10).register(z.globalRegistry, {
          description: 'The text guidance scale for classifier-free guidance.',
        }),
      )
      .default(4),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description:
          'Resolution of the generated video (480p or 720p). Billing is per video-second (16 frames): 480p is 1 unit per second and 720p is 4 units per second.',
      }),
    ),
    audio_type: z.optional(
      z.enum(['para', 'add']).register(z.globalRegistry, {
        description:
          "How to combine the two audio tracks. 'para' (parallel) plays both simultaneously, 'add' (sequential) plays person 1 first then person 2.",
      }),
    ),
    image_url: z.string().register(z.globalRegistry, {
      description: 'The URL of the image containing two speakers.',
    }),
    audio_url_person1: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The URL of the audio file for person 1 (left side).',
        }),
      )
      .default(
        'https://raw.githubusercontent.com/meituan-longcat/LongCat-Video/refs/heads/main/assets/avatar/multi/sing_man.WAV',
      ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the random number generator.',
      }),
    ),
    audio_guidance_scale: z
      .optional(
        z.number().gte(1).lte(10).register(z.globalRegistry, {
          description:
            'The audio guidance scale. Higher values may lead to exaggerated mouth movements.',
        }),
      )
      .default(4),
    bbox_person2: z.optional(zBoundingBox),
    num_segments: z
      .optional(
        z.int().gte(1).lte(10).register(z.globalRegistry, {
          description:
            'Number of video segments to generate. Each segment adds ~5 seconds of video. First segment is ~5.8s, additional segments are 5s each.',
        }),
      )
      .default(1),
  })
  .register(z.globalRegistry, {
    description:
      'Request model for multi-speaker image+audio to video generation.',
  })

/**
 * File
 */
export const zFalAiLongcatMultiAvatarImageAudioToVideoFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * MultiSpeakerImageAudioToVideoResponse
 *
 * Response model for multi-speaker image+audio to video generation.
 */
export const zLongcatMultiAvatarImageAudioToVideoOutput = z
  .object({
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed used for generation.',
    }),
    video: zFalAiLongcatMultiAvatarImageAudioToVideoFile,
  })
  .register(z.globalRegistry, {
    description:
      'Response model for multi-speaker image+audio to video generation.',
  })

/**
 * ImageAudioToVideoRequest
 *
 * Request model for image+audio to video generation.
 */
export const zLongcatSingleAvatarImageAudioToVideoInput = z
  .object({
    prompt: z.string().register(z.globalRegistry, {
      description: 'The prompt to guide the video generation.',
    }),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description:
          'Resolution of the generated video (480p or 720p). Billing is per video-second (16 frames): 480p is 1 unit per second and 720p is 4 units per second.',
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable safety checker.',
        }),
      )
      .default(true),
    audio_guidance_scale: z
      .optional(
        z.number().gte(1).lte(10).register(z.globalRegistry, {
          description:
            'The audio guidance scale. Higher values may lead to exaggerated mouth movements.',
        }),
      )
      .default(4),
    num_segments: z
      .optional(
        z.int().gte(1).lte(10).register(z.globalRegistry, {
          description:
            'Number of video segments to generate. Each segment adds ~5 seconds of video. First segment is ~5.8s, additional segments are 5s each.',
        }),
      )
      .default(1),
    image_url: z.string().register(z.globalRegistry, {
      description: 'The URL of the image to animate.',
    }),
    audio_url: z.string().register(z.globalRegistry, {
      description: 'The URL of the audio file to drive the avatar.',
    }),
    num_inference_steps: z
      .optional(
        z.int().gte(10).lte(100).register(z.globalRegistry, {
          description: 'The number of inference steps to use.',
        }),
      )
      .default(30),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the random number generator.',
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt to avoid in the video generation.',
        }),
      )
      .default(
        'Close-up, Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards',
      ),
    text_guidance_scale: z
      .optional(
        z.number().gte(1).lte(10).register(z.globalRegistry, {
          description: 'The text guidance scale for classifier-free guidance.',
        }),
      )
      .default(4),
  })
  .register(z.globalRegistry, {
    description: 'Request model for image+audio to video generation.',
  })

/**
 * File
 */
export const zFalAiLongcatSingleAvatarImageAudioToVideoFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ImageAudioToVideoResponse
 *
 * Response model for image+audio to video generation.
 */
export const zLongcatSingleAvatarImageAudioToVideoOutput = z
  .object({
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed used for generation.',
    }),
    video: zFalAiLongcatSingleAvatarImageAudioToVideoFile,
  })
  .register(z.globalRegistry, {
    description: 'Response model for image+audio to video generation.',
  })

/**
 * AudioToVideoRequest
 *
 * Request model for audio-to-video generation.
 */
export const zLongcatSingleAvatarAudioToVideoInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The prompt to guide the video generation.',
        }),
      )
      .default(
        'A person is talking naturally with natural expressions and movements.',
      ),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description:
          'Resolution of the generated video (480p or 720p). Billing is per video-second (16 frames): 480p is 1 unit per second and 720p is 4 units per second.',
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable safety checker.',
        }),
      )
      .default(true),
    audio_guidance_scale: z
      .optional(
        z.number().gte(1).lte(10).register(z.globalRegistry, {
          description:
            'The audio guidance scale. Higher values may lead to exaggerated mouth movements.',
        }),
      )
      .default(4),
    num_segments: z
      .optional(
        z.int().gte(1).lte(10).register(z.globalRegistry, {
          description:
            'Number of video segments to generate. Each segment adds ~5 seconds of video. First segment is ~5.8s, additional segments are 5s each.',
        }),
      )
      .default(1),
    audio_url: z.string().register(z.globalRegistry, {
      description: 'The URL of the audio file to drive the avatar.',
    }),
    num_inference_steps: z
      .optional(
        z.int().gte(10).lte(100).register(z.globalRegistry, {
          description: 'The number of inference steps to use.',
        }),
      )
      .default(30),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the random number generator.',
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt to avoid in the video generation.',
        }),
      )
      .default(
        'Close-up, Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards',
      ),
    text_guidance_scale: z
      .optional(
        z.number().gte(1).lte(10).register(z.globalRegistry, {
          description: 'The text guidance scale for classifier-free guidance.',
        }),
      )
      .default(4),
  })
  .register(z.globalRegistry, {
    description: 'Request model for audio-to-video generation.',
  })

/**
 * File
 */
export const zFalAiLongcatSingleAvatarAudioToVideoFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * AudioToVideoResponse
 *
 * Response model for audio-to-video generation (no reference image).
 */
export const zLongcatSingleAvatarAudioToVideoOutput = z
  .object({
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed used for generation.',
    }),
    video: zFalAiLongcatSingleAvatarAudioToVideoFile,
  })
  .register(z.globalRegistry, {
    description:
      'Response model for audio-to-video generation (no reference image).',
  })

/**
 * InferenceRequest
 */
export const zAvatarsAudioToVideoInput = z.object({
  avatar: z.enum([
    'Mia outdoor (UGC)',
    'Lara (Masterclass)',
    'Ines (UGC)',
    'Maria (Masterclass)',
    'Emma (UGC)',
    'Sienna (Masterclass)',
    'Elena (UGC)',
    'Jasmine (Masterclass)',
    'Amara (Masterclass)',
    'Ryan podcast (UGC)',
    'Tyler (Masterclass)',
    'Jayse (Masterclass)',
    'Paul (Masterclass)',
    'Matteo (UGC)',
    'Daniel car (UGC)',
    'Dario (Masterclass)',
    'Viva (Masterclass)',
    'Chen (Masterclass)',
    'Alex (Masterclass)',
    'Vanessa (UGC)',
    'Laurent (UGC)',
    'Noemie car (UGC)',
    'Brandon (UGC)',
    'Byron (Masterclass)',
    'Calista (Masterclass)',
    'Milo (Masterclass)',
    'Fabien (Masterclass)',
    'Rose (UGC)',
  ]),
  remove_background: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Enabling the remove background feature will result in a 50% increase in the price.',
      }),
    )
    .default(false),
  audio_url: z.string(),
})

/**
 * Video
 */
export const zVideo = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * InferenceResult
 */
export const zAvatarsAudioToVideoOutput = z.object({
  moderation_transcription: z.optional(z.union([z.string(), z.unknown()])),
  moderation_error: z.optional(z.union([z.string(), z.unknown()])),
  moderation_flagged: z.optional(z.boolean()).default(false),
  video: z.optional(z.union([zVideo, z.unknown()])),
})

/**
 * WanS2VRequest
 */
export const zWanV2214bSpeechToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt used for video generation.',
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift value for the video. Must be between 1.0 and 10.0.',
      }),
    )
    .default(5),
  frames_per_second: z.optional(z.union([z.int().gte(4).lte(60), z.unknown()])),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(3.5),
  num_frames: z
    .optional(
      z.int().gte(40).lte(120).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 40 to 120, (must be multiple of 4).',
      }),
    )
    .default(80),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, input data will be checked for safety before processing.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(''),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description:
        'The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p, 580p, or 720p).',
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, output video will be checked for safety after generation.',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.',
  }),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description:
        'The quality of the output video. Higher quality means better visual quality but larger file size.',
    }),
  ),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the audio file.',
  }),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(27),
})

/**
 * File
 */
export const zFalAiWanV2214bSpeechToVideoFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * WanS2VResponse
 */
export const zWanV2214bSpeechToVideoOutput = z.object({
  video: zFalAiWanV2214bSpeechToVideoFile,
})

/**
 * StableAvatarRequest
 */
export const zStableAvatarInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to use for the video generation.',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '1:1', '9:16', 'auto']).register(z.globalRegistry, {
      description:
        "The aspect ratio of the video to generate. If 'auto', the aspect ratio will be determined by the reference image.",
    }),
  ),
  perturbation: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The amount of perturbation to use for the video generation. 0.0 means no perturbation, 1.0 means full perturbation.',
      }),
    )
    .default(0.1),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the image to use as a reference for the video generation.',
  }),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use for the video generation.',
      }),
    )
    .default(5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for the video generation.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(10).lte(50).register(z.globalRegistry, {
        description:
          'The number of inference steps to use for the video generation.',
      }),
    )
    .default(50),
  audio_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the audio to use as a reference for the video generation.',
  }),
  audio_guidance_scale: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description:
          'The audio guidance scale to use for the video generation.',
      }),
    )
    .default(4),
})

/**
 * File
 */
export const zFalAiStableAvatarFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * StableAvatarResponse
 */
export const zStableAvatarOutput = z.object({
  video: zFalAiStableAvatarFile,
})

/**
 * EchoMimicRequest
 */
export const zEchomimicV3Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to use for the video generation.',
  }),
  audio_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the audio to use as a reference for the video generation.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the image to use as a reference for the video generation.',
  }),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use for the video generation.',
      }),
    )
    .default(4.5),
  audio_guidance_scale: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description:
          'The audio guidance scale to use for the video generation.',
      }),
    )
    .default(2.5),
  num_frames_per_generation: z
    .optional(
      z.int().gte(49).lte(161).register(z.globalRegistry, {
        description: 'The number of frames to generate at once.',
      }),
    )
    .default(121),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to use for the video generation.',
      }),
    )
    .default(''),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for the video generation.',
    }),
  ),
})

/**
 * File
 */
export const zFalAiEchomimicV3File = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * EchoMimicResponse
 */
export const zEchomimicV3Output = z.object({
  video: zFalAiEchomimicV3File,
})

/**
 * Audio2VideoInput
 */
export const zVeedAvatarsAudioToVideoAvatarsAudioToVideoInput = z.object({
  audio_url: z.url().min(1).max(2083),
  avatar_id: z
    .enum([
      'emily_vertical_primary',
      'emily_vertical_secondary',
      'marcus_vertical_primary',
      'marcus_vertical_secondary',
      'mira_vertical_primary',
      'mira_vertical_secondary',
      'jasmine_vertical_primary',
      'jasmine_vertical_secondary',
      'jasmine_vertical_walking',
      'aisha_vertical_walking',
      'elena_vertical_primary',
      'elena_vertical_secondary',
      'any_male_vertical_primary',
      'any_female_vertical_primary',
      'any_male_vertical_secondary',
      'any_female_vertical_secondary',
      'any_female_vertical_walking',
      'emily_primary',
      'emily_side',
      'marcus_primary',
      'marcus_side',
      'aisha_walking',
      'elena_primary',
      'elena_side',
      'any_male_primary',
      'any_female_primary',
      'any_male_side',
      'any_female_side',
    ])
    .register(z.globalRegistry, {
      description: 'The avatar to use for the video',
    }),
})

/**
 * File
 */
export const zVeedAvatarsAudioToVideoFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * AvatarsAppOutput
 */
export const zVeedAvatarsAudioToVideoAvatarsAudioToVideoOutput = z.object({
  video: zVeedAvatarsAudioToVideoFile,
})
