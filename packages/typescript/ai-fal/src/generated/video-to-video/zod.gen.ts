// This file is auto-generated by @hey-api/openapi-ts

import { z } from 'zod'

/**
 * File
 */
export const zSchemaFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * AnimateDiffV2VOutput
 */
export const zSchemaFastAnimatediffVideoToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generating the video.',
  }),
  video: zSchemaFile,
})

/**
 * AnimateDiffV2VInput
 */
export const zSchemaFastAnimatediffVideoToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the video.',
  }),
  first_n_seconds: z
    .optional(
      z.int().gte(2).lte(4).register(z.globalRegistry, {
        description: 'The first N number of seconds of video to animate.',
      }),
    )
    .default(3),
  fps: z
    .optional(
      z.int().gte(1).lte(16).register(z.globalRegistry, {
        description: 'Number of frames per second to extract from the video.',
      }),
    )
    .default(8),
  strength: z
    .optional(
      z.number().gte(0.1).lte(1).register(z.globalRegistry, {
        description: 'The strength of the input video in the final output.',
      }),
    )
    .default(0.7),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(7.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(25),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default('(bad quality, worst quality:1.2), ugly faces, bad anime'),
  motions: z.optional(
    z
      .array(
        z.enum([
          'zoom-out',
          'zoom-in',
          'pan-left',
          'pan-right',
          'tilt-up',
          'tilt-down',
        ]),
      )
      .register(z.globalRegistry, {
        description: 'The motions to apply to the video.',
      }),
  ),
})

/**
 * AnimateDiffV2VOutput
 */
export const zSchemaFastAnimatediffTurboVideoToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generating the video.',
  }),
  video: zSchemaFile,
})

/**
 * AnimateDiffV2VTurboInput
 */
export const zSchemaFastAnimatediffTurboVideoToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the video.',
  }),
  first_n_seconds: z
    .optional(
      z.int().gte(2).lte(12).register(z.globalRegistry, {
        description: 'The first N number of seconds of video to animate.',
      }),
    )
    .default(3),
  fps: z
    .optional(
      z.int().gte(1).lte(16).register(z.globalRegistry, {
        description: 'Number of frames per second to extract from the video.',
      }),
    )
    .default(8),
  strength: z
    .optional(
      z.number().gte(0.1).lte(1).register(z.globalRegistry, {
        description: 'The strength of the input video in the final output.',
      }),
    )
    .default(0.7),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(1),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(32).register(z.globalRegistry, {
        description:
          'The number of inference steps to perform. 4-12 is recommended for turbo mode.',
      }),
    )
    .default(8),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default('(bad quality, worst quality:1.2), ugly faces, bad anime'),
  motions: z.optional(
    z
      .array(
        z.enum([
          'zoom-out',
          'zoom-in',
          'pan-left',
          'pan-right',
          'tilt-up',
          'tilt-down',
        ]),
      )
      .register(z.globalRegistry, {
        description: 'The motions to apply to the video.',
      }),
  ),
})

/**
 * AMTInterpolationOutput
 */
export const zSchemaAmtInterpolationOutput = z.object({
  video: zSchemaFile,
})

/**
 * AMTInterpolationInput
 */
export const zSchemaAmtInterpolationInput = z.object({
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the video to be processed',
  }),
  recursive_interpolation_passes: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Number of recursive interpolation passes',
      }),
    )
    .default(2),
  output_fps: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Output frames per second',
      }),
    )
    .default(24),
})

/**
 * SAM2VideoOutput
 */
export const zSchemaSam2VideoOutput = z.object({
  boundingbox_frames_zip: z.optional(zSchemaFile),
  video: zSchemaFile,
})

/**
 * BoxPrompt
 */
export const zSchemaBoxPrompt = z.object({
  y_min: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Y Min Coordinate of the box',
      }),
    )
    .default(0),
  frame_index: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'The frame index to interact with.',
      }),
    )
    .default(0),
  x_max: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'X Max Coordinate of the prompt',
      }),
    )
    .default(0),
  x_min: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'X Min Coordinate of the box',
      }),
    )
    .default(0),
  y_max: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Y Max Coordinate of the prompt',
      }),
    )
    .default(0),
})

/**
 * PointPrompt
 */
export const zSchemaPointPrompt = z.object({
  y: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Y Coordinate of the prompt',
      }),
    )
    .default(350),
  label: z.optional(
    z.union([z.literal(0), z.literal(1)]).register(z.globalRegistry, {
      description: 'Label of the prompt. 1 for foreground, 0 for background',
    }),
  ),
  frame_index: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'The frame index to interact with.',
      }),
    )
    .default(0),
  x: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'X Coordinate of the prompt',
      }),
    )
    .default(305),
})

/**
 * SAM2VideoRLEInput
 */
export const zSchemaSam2VideoInput = z.object({
  video_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the video to be segmented.',
  }),
  prompts: z
    .optional(
      z.array(zSchemaPointPrompt).register(z.globalRegistry, {
        description: 'List of prompts to segment the video',
      }),
    )
    .default([]),
  boundingbox_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Return per-frame bounding box overlays as a zip archive.',
      }),
    )
    .default(false),
  mask_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The URL of the mask to be applied initially.',
    }),
  ),
  apply_mask: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Apply the mask on the video.',
      }),
    )
    .default(false),
  box_prompts: z
    .optional(
      z.array(zSchemaBoxPrompt).register(z.globalRegistry, {
        description: 'Coordinates for boxes',
      }),
    )
    .default([]),
})

/**
 * ControlNeXtOutput
 */
export const zSchemaControlnextOutput = z.object({
  video: zSchemaFile,
})

/**
 * ControlNeXtInput
 */
export const zSchemaControlnextInput = z.object({
  controlnext_cond_scale: z
    .optional(
      z.number().gte(0.1).lte(10).register(z.globalRegistry, {
        description: 'Condition scale for ControlNeXt.',
      }),
    )
    .default(1),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input video.',
  }),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: 'Frames per second for the output video.',
      }),
    )
    .default(7),
  max_frame_num: z
    .optional(
      z.int().gte(1).lte(1000).register(z.globalRegistry, {
        description: 'Maximum number of frames to process.',
      }),
    )
    .default(240),
  width: z
    .optional(
      z.int().gte(64).lte(1024).register(z.globalRegistry, {
        description: 'Width of the output video.',
      }),
    )
    .default(576),
  overlap: z
    .optional(
      z.int().gte(0).lte(20).register(z.globalRegistry, {
        description: 'Number of overlapping frames between batches.',
      }),
    )
    .default(6),
  guidance_scale: z
    .optional(
      z.number().gte(0.1).lte(10).register(z.globalRegistry, {
        description: 'Guidance scale for the diffusion process.',
      }),
    )
    .default(3),
  batch_frames: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'Number of frames to process in each batch.',
      }),
    )
    .default(24),
  height: z
    .optional(
      z.int().gte(64).lte(1024).register(z.globalRegistry, {
        description: 'Height of the output video.',
      }),
    )
    .default(1024),
  sample_stride: z
    .optional(
      z.int().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Stride for sampling frames from the input video.',
      }),
    )
    .default(2),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the reference image.',
  }),
  decode_chunk_size: z
    .optional(
      z.int().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Chunk size for decoding frames.',
      }),
    )
    .default(2),
  motion_bucket_id: z
    .optional(
      z.number().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Motion bucket ID for the pipeline.',
      }),
    )
    .default(127),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(100).register(z.globalRegistry, {
        description: 'Number of inference steps.',
      }),
    )
    .default(25),
})

/**
 * Output
 */
export const zSchemaCogvideox5bVideoToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the video.',
  }),
  timings: z.record(z.string(), z.number()),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated video. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  video: zSchemaFile,
})

/**
 * ImageSize
 */
export const zSchemaImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zSchemaLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * VideoToVideoInput
 */
export const zSchemaCogvideox5bVideoToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  video_url: z.string().register(z.globalRegistry, {
    description: 'The video to generate the video from.',
  }),
  use_rife: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Use RIFE for video interpolation',
      }),
    )
    .default(true),
  loras: z
    .optional(
      z.array(zSchemaLoraWeight).register(z.globalRegistry, {
        description:
          '\n            The LoRAs to use for the image generation. We currently support one lora.\n        ',
      }),
    )
    .default([]),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  strength: z
    .optional(
      z.number().gte(0.05).lte(1).register(z.globalRegistry, {
        description:
          'The strength to use for Video to Video.  1.0 completely remakes the video while 0.0 preserves the original.',
      }),
    )
    .default(0.8),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related video to show you.\n        ',
      }),
    )
    .default(7),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(50),
  export_fps: z
    .optional(
      z.int().gte(4).lte(32).register(z.globalRegistry, {
        description: 'The target FPS of the video',
      }),
    )
    .default(16),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate video from',
      }),
    )
    .default(''),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ',
    }),
  ),
})

/**
 * Output
 */
export const zSchemaVideoUpscalerOutput = z.object({
  video: zSchemaFile,
})

/**
 * Input
 */
export const zSchemaVideoUpscalerInput = z.object({
  video_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the video to upscale',
  }),
  scale: z
    .optional(
      z.number().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The scale factor',
      }),
    )
    .default(2),
})

/**
 * OutputModel
 */
export const zSchemaDubbingOutput = z.object({
  video: zSchemaFile,
})

/**
 * InputModel
 */
export const zSchemaDubbingInput = z.object({
  do_lipsync: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to lip sync the audio to the video',
      }),
    )
    .default(true),
  video_url: z.string().register(z.globalRegistry, {
    description: 'Input video URL to be dubbed.',
  }),
  target_language: z.optional(
    z.enum(['hindi', 'turkish', 'english']).register(z.globalRegistry, {
      description: 'Target language to dub the video to',
    }),
  ),
})

/**
 * Output
 */
export const zSchemaAutoCaptionOutput = z.object({
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL to the caption .mp4 video.',
  }),
})

/**
 * CaptionInput
 */
export const zSchemaAutoCaptionInput = z.object({
  txt_font: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "Font for generated captions. Choose one in 'Arial','Standard','Garamond', 'Times New Roman','Georgia', or pass a url to a .ttf file",
      }),
    )
    .default('Standard'),
  video_url: z.string().register(z.globalRegistry, {
    description:
      'URL to the .mp4 video with audio. Only videos of size <100MB are allowed.',
  }),
  top_align: z.optional(z.union([z.string(), z.number()])),
  txt_color: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Colour of the text. Can be a RGB tuple, a color name, or an hexadecimal notation.',
      }),
    )
    .default('white'),
  stroke_width: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Width of the text strokes in pixels',
      }),
    )
    .default(1),
  refresh_interval: z
    .optional(
      z.number().gte(0.5).lte(3).register(z.globalRegistry, {
        description:
          'Number of seconds the captions should stay on screen. A higher number will also result in more text being displayed at once.',
      }),
    )
    .default(1.5),
  font_size: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Size of text in generated captions.',
      }),
    )
    .default(24),
  left_align: z.optional(z.union([z.string(), z.number()])),
})

/**
 * LipSyncOutput
 */
export const zSchemaSyncLipsyncOutput = z.object({
  video: zSchemaFile,
})

/**
 * LipSyncInput
 */
export const zSchemaSyncLipsyncInput = z.object({
  model: z.optional(
    z
      .enum(['lipsync-1.8.0', 'lipsync-1.7.1', 'lipsync-1.9.0-beta'])
      .register(z.globalRegistry, {
        description: 'The model to use for lipsyncing',
      }),
  ),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input video',
  }),
  sync_mode: z.optional(
    z
      .enum(['cut_off', 'loop', 'bounce', 'silence', 'remap'])
      .register(z.globalRegistry, {
        description:
          'Lipsync mode when audio and video durations are out of sync.',
      }),
  ),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input audio',
  }),
})

/**
 * Keyframe
 */
export const zSchemaKeyframe = z.object({
  duration: z.number().register(z.globalRegistry, {
    description: 'The duration in milliseconds of this keyframe',
  }),
  timestamp: z.number().register(z.globalRegistry, {
    description: 'The timestamp in milliseconds where this keyframe starts',
  }),
  url: z.string().register(z.globalRegistry, {
    description: "The URL where this keyframe's media file can be accessed",
  }),
})

/**
 * Track
 */
export const zSchemaTrack = z.object({
  type: z.string().register(z.globalRegistry, {
    description: "Type of track ('video' or 'audio')",
  }),
  id: z.string().register(z.globalRegistry, {
    description: 'Unique identifier for the track',
  }),
  keyframes: z.array(zSchemaKeyframe).register(z.globalRegistry, {
    description: 'List of keyframes that make up this track',
  }),
})

/**
 * ComposeOutput
 */
export const zSchemaFfmpegApiComposeOutput = z.object({
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the processed video file',
  }),
  thumbnail_url: z.string().register(z.globalRegistry, {
    description: "URL of the video's thumbnail image",
  }),
})

/**
 * Input
 */
export const zSchemaFfmpegApiComposeInput = z.object({
  tracks: z.array(zSchemaTrack).register(z.globalRegistry, {
    description: 'List of tracks to be combined into the final media',
  }),
})

/**
 * HunyuanV2VResponse
 */
export const zSchemaHunyuanVideoLoraVideoToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generating the video.',
  }),
  video: zSchemaFile,
})

/**
 * HunyuanV2VRequest
 */
export const zSchemaHunyuanVideoLoraVideoToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the video to generate.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'The resolution of the video to generate.',
    }),
  ),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the video',
  }),
  loras: z
    .optional(
      z.array(zSchemaLoraWeight).register(z.globalRegistry, {
        description:
          '\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ',
      }),
    )
    .default([]),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description: 'Strength of video-to-video',
      }),
    )
    .default(0.75),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for generating the video.',
    }),
  ),
  num_frames: z.optional(
    z.enum(['129', '85']).register(z.globalRegistry, {
      description: 'The number of frames to generate.',
    }),
  ),
  pro_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'By default, generations are done with 35 steps. Pro mode does 55 steps which results in higher quality videos but will take more time and cost 2x more billing units.',
      }),
    )
    .default(false),
})

/**
 * HunyuanT2VResponse
 */
export const zSchemaHunyuanVideoVideoToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generating the video.',
  }),
  video: zSchemaFile,
})

/**
 * HunyuanV2VRequest
 */
export const zSchemaHunyuanVideoVideoToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'The aspect ratio of the video to generate.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'The resolution of the video to generate.',
    }),
  ),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the video input.',
  }),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description: 'Strength for Video-to-Video',
      }),
    )
    .default(0.85),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(30).register(z.globalRegistry, {
        description:
          'The number of inference steps to run. Lower gets faster results, higher gets better results.',
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for generating the video.',
    }),
  ),
  num_frames: z.optional(
    z.enum(['129', '85']).register(z.globalRegistry, {
      description: 'The number of frames to generate.',
    }),
  ),
  pro_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'By default, generations are done with 35 steps. Pro mode does 55 steps which results in higher quality videos but will take more time and cost 2x more billing units.',
      }),
    )
    .default(false),
})

/**
 * Ben2OutputVideo
 */
export const zSchemaBenV2VideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  video: zSchemaFile,
})

/**
 * Ben2InputVideo
 */
export const zSchemaBenV2VideoInput = z.object({
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of video to be used for background removal.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for reproducible generation.',
    }),
  ),
  background_color: z.optional(
    z
      .tuple([z.unknown(), z.unknown(), z.unknown()])
      .register(z.globalRegistry, {
        description:
          'Optional RGB values (0-255) for the background color. If not provided, the background will be transparent. For ex: [0, 0, 0]',
      }),
  ),
})

/**
 * VideoUpscaleOutput
 */
export const zSchemaTopazUpscaleVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * VideoUpscaleRequest
 */
export const zSchemaTopazUpscaleVideoInput = z.object({
  H264_output: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use H264 codec for output video. Default is H265.',
      }),
    )
    .default(false),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the video to upscale',
  }),
  upscale_factor: z
    .optional(
      z.number().gte(1).lte(4).register(z.globalRegistry, {
        description:
          'Factor to upscale the video by (e.g. 2.0 doubles width and height)',
      }),
    )
    .default(2),
  target_fps: z.optional(
    z.int().gte(16).lte(60).register(z.globalRegistry, {
      description:
        'Target FPS for frame interpolation. If set, frame interpolation will be enabled.',
    }),
  ),
})

/**
 * ExtendVideoOutput
 */
export const zSchemaLtxVideoV095ExtendOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * VideoConditioningInput
 */
export const zSchemaVideoConditioningInput = z.object({
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of video to be extended',
  }),
  start_frame_num: z.int().gte(0).lte(120).register(z.globalRegistry, {
    description:
      'Frame number of the video from which the conditioning starts. Must be a multiple of 8.',
  }),
})

/**
 * ExtendVideoInput
 */
export const zSchemaLtxVideoV095ExtendInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt to guide generation',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['9:16', '16:9']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video (16:9 or 9:16).',
    }),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to expand the prompt using the model's own capabilities.",
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps',
      }),
    )
    .default(40),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for generation',
      }),
    )
    .default('worst quality, inconsistent motion, blurry, jittery, distorted'),
  video: zSchemaVideoConditioningInput,
})

/**
 * MulticonditioningVideoOutput
 */
export const zSchemaLtxVideoV095MulticonditioningOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * ImageConditioningInput
 */
export const zSchemaImageConditioningInput = z.object({
  start_frame_num: z.int().gte(0).lte(120).register(z.globalRegistry, {
    description:
      'Frame number of the image from which the conditioning starts. Must be a multiple of 8.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to use as conditioning',
  }),
})

/**
 * MultiConditioningVideoInput
 */
export const zSchemaLtxVideoV095MulticonditioningInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt to guide generation',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['9:16', '16:9']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video (16:9 or 9:16).',
    }),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to expand the prompt using the model's own capabilities.",
      }),
    )
    .default(true),
  images: z
    .optional(
      z.array(zSchemaImageConditioningInput).register(z.globalRegistry, {
        description: 'URL of images to use as conditioning',
      }),
    )
    .default([]),
  videos: z
    .optional(
      z.array(zSchemaVideoConditioningInput).register(z.globalRegistry, {
        description: 'Videos to use as conditioning',
      }),
    )
    .default([]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps',
      }),
    )
    .default(40),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for generation',
      }),
    )
    .default('worst quality, inconsistent motion, blurry, jittery, distorted'),
})

/**
 * PikadditionsOutput
 *
 * Output from Pikadditions generation
 */
export const zSchemaPikaV2PikadditionsOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output from Pikadditions generation',
  })

/**
 * PikadditionsRequest
 *
 * Request model for Pikadditions endpoint
 */
export const zSchemaPikaV2PikadditionsInput = z
  .object({
    prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'Text prompt describing what to add',
      }),
    ),
    video_url: z.string().register(z.globalRegistry, {
      description: 'URL of the input video',
    }),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the random number generator',
      }),
    ),
    negative_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to guide the model',
      }),
    ),
    image_url: z.string().register(z.globalRegistry, {
      description: 'URL of the image to add',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Request model for Pikadditions endpoint',
  })

/**
 * Output
 */
export const zSchemaLatentsyncOutput = z.object({
  video: zSchemaFile,
})

/**
 * Input
 */
export const zSchemaLatentsyncInput = z.object({
  video_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the video to generate the lip sync for.',
  }),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(2).register(z.globalRegistry, {
        description: 'Guidance scale for the model inference',
      }),
    )
    .default(1),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for generation. If None, a random seed will be used.',
    }),
  ),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the audio to generate the lip sync for.',
  }),
  loop_mode: z.optional(
    z.enum(['pingpong', 'loop']).register(z.globalRegistry, {
      description:
        'Video loop mode when audio is longer than video. Options: pingpong, loop',
    }),
  ),
})

/**
 * LipSyncV2Output
 */
export const zSchemaSyncLipsyncV2Output = z.object({
  video: zSchemaFile,
})

/**
 * LipSyncV2Input
 */
export const zSchemaSyncLipsyncV2Input = z.object({
  model: z.optional(
    z.enum(['lipsync-2', 'lipsync-2-pro']).register(z.globalRegistry, {
      description:
        'The model to use for lipsyncing. `lipsync-2-pro` will cost roughly 1.67 times as much as `lipsync-2` for the same duration.',
    }),
  ),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input video',
  }),
  sync_mode: z.optional(
    z
      .enum(['cut_off', 'loop', 'bounce', 'silence', 'remap'])
      .register(z.globalRegistry, {
        description:
          'Lipsync mode when audio and video durations are out of sync.',
      }),
  ),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input audio',
  }),
})

/**
 * VideoOutput
 *
 * Pydantic model for returning the re-sounded video back to the client.
 */
export const zSchemaVideoSoundEffectsGeneratorOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description:
      'Pydantic model for returning the re-sounded video back to the client.',
  })

/**
 * Video
 *
 * Represents a video file.
 */
export const zSchemaVideo = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    file_data: z.optional(z.union([z.string(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents a video file.',
  })

/**
 * VideoInput
 *
 * Pydantic model for receiving a video file to analyze and re-sound.
 */
export const zSchemaVideoSoundEffectsGeneratorInput = z
  .object({
    video_url: zSchemaVideo,
  })
  .register(z.globalRegistry, {
    description:
      'Pydantic model for receiving a video file to analyze and re-sound.',
  })

/**
 * WanT2VResponse
 */
export const zSchemaWanVaceOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanT2VRequest
 */
export const zSchemaWanVaceInput = z.object({
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  video_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'URL to the source video file. If provided, the model will use this video as a reference.',
    }),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'Urls to source reference image. If provided, the model will use this image as reference.',
    }),
  ),
  task: z.optional(
    z.enum(['depth', 'inpainting']).register(z.globalRegistry, {
      description: 'Task type for the model.',
    }),
  ),
  frames_per_second: z
    .optional(
      z.int().gte(5).lte(24).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 5 to 24.',
      }),
    )
    .default(16),
  mask_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'URL to the guiding mask file. If provided, the model will use this mask as a reference to create masked video. If provided mask video url will be ignored.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(81).lte(240).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 100 (inclusive). Works only with only reference images as input if source video or mask video is provided output len would be same as source up to 241 frames',
      }),
    )
    .default(81),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  aspect_ratio: z.optional(
    z.enum(['auto', '9:16', '16:9']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video (16:9 or 9:16).',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p,580p, or 720p).',
    }),
  ),
  mask_video_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'URL to the source mask file. If provided, the model will use this mask as a reference.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the input video.',
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
})

/**
 * MagiVideoExtensionResponse
 */
export const zSchemaMagiDistilledExtendVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * MagiVideoExtensionRequest
 */
export const zSchemaMagiDistilledExtendVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  video_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the input video to represent the beginning of the video. If the input video does not match the chosen aspect ratio, it is resized and center cropped.',
  }),
  start_frame: z.optional(
    z.int().gte(0).register(z.globalRegistry, {
      description:
        'The frame to begin the generation from, with the remaining frames will be treated as the prefix video. The final video will contain the frames up until this number unchanged, followed by the generated frames. The default start frame is 32 frames before the end of the video, which gives optimal results.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z.optional(
    z
      .union([z.literal(4), z.literal(8), z.literal(16), z.literal(32)])
      .register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(96).lte(192).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.',
      }),
    )
    .default(96),
})

/**
 * MagiVideoExtensionResponse
 */
export const zSchemaMagiExtendVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * MagiVideoExtensionRequest
 */
export const zSchemaMagiExtendVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  video_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the input video to represent the beginning of the video. If the input video does not match the chosen aspect ratio, it is resized and center cropped.',
  }),
  start_frame: z.optional(
    z.int().gte(0).register(z.globalRegistry, {
      description:
        'The frame to begin the generation from, with the remaining frames will be treated as the prefix video. The final video will contain the frames up until this number unchanged, followed by the generated frames. The default start frame is 32 frames before the end of the video, which gives optimal results.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z.optional(
    z
      .union([
        z.literal(4),
        z.literal(8),
        z.literal(16),
        z.literal(32),
        z.literal(64),
      ])
      .register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(96).lte(192).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.',
      }),
    )
    .default(96),
})

/**
 * VideoCondition
 *
 * Video condition to use for generation.
 */
export const zSchemaVideoCondition = z
  .object({
    strength: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description: 'The strength of the condition.',
        }),
      )
      .default(1),
    start_frame_number: z
      .optional(
        z.int().gte(0).lte(160).register(z.globalRegistry, {
          description: 'The frame number to start the condition on.',
        }),
      )
      .default(0),
    video_url: z.string().register(z.globalRegistry, {
      description: 'The URL of the video to use as input.',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Video condition to use for generation.',
  })

/**
 * ImageCondition
 *
 * Image condition to use for generation.
 */
export const zSchemaImageCondition = z
  .object({
    strength: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description: 'The strength of the condition.',
        }),
      )
      .default(1),
    start_frame_number: z
      .optional(
        z.int().gte(0).lte(160).register(z.globalRegistry, {
          description: 'The frame number to start the condition on.',
        }),
      )
      .default(0),
    image_url: z.string().register(z.globalRegistry, {
      description: 'The URL of the image to use as input.',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Image condition to use for generation.',
  })

/**
 * MulticonditioningVideoOutput
 */
export const zSchemaLtxVideoLoraMulticonditioningOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * LoRAWeight
 *
 * LoRA weight to use for generation.
 */
export const zSchemaLoRaWeight = z
  .object({
    path: z.string().register(z.globalRegistry, {
      description: 'URL or path to the LoRA weights.',
    }),
    scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'Scale of the LoRA weight. This is a multiplier applied to the LoRA weight when loading it.',
        }),
      )
      .default(1),
    weight_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'Name of the LoRA weight. Only used if `path` is a HuggingFace repository, and is only required when the repository contains multiple LoRA weights.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'LoRA weight to use for generation.',
  })

/**
 * MulticonditioningVideoInput
 *
 * Request model for text-to-video generation with multiple conditions.
 */
export const zSchemaLtxVideoLoraMulticonditioningInput = z
  .object({
    number_of_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to use.',
        }),
      )
      .default(30),
    prompt: z.string().register(z.globalRegistry, {
      description: 'The prompt to generate the video from.',
    }),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to reverse the video.',
        }),
      )
      .default(false),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: 'The frame rate of the video.',
        }),
      )
      .default(25),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to expand the prompt using the LLM.',
        }),
      )
      .default(false),
    number_of_frames: z
      .optional(
        z.int().gte(9).lte(161).register(z.globalRegistry, {
          description: 'The number of frames in the video.',
        }),
      )
      .default(89),
    loras: z
      .optional(
        z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
          description: 'The LoRA weights to use for generation.',
        }),
      )
      .default([]),
    images: z
      .optional(
        z.array(zSchemaImageCondition).register(z.globalRegistry, {
          description: 'The image conditions to use for generation.',
        }),
      )
      .default([]),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable the safety checker.',
        }),
      )
      .default(true),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt to use.',
        }),
      )
      .default(
        'blurry, low quality, low resolution, inconsistent motion, jittery, distorted',
      ),
    aspect_ratio: z.optional(
      z.enum(['16:9', '1:1', '9:16', 'auto']).register(z.globalRegistry, {
        description: 'The aspect ratio of the video.',
      }),
    ),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description: 'The resolution of the video.',
      }),
    ),
    videos: z
      .optional(
        z.array(zSchemaVideoCondition).register(z.globalRegistry, {
          description: 'The video conditions to use for generation.',
        }),
      )
      .default([]),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed to use for generation.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description:
      'Request model for text-to-video generation with multiple conditions.',
  })

/**
 * ExtendVideoOutput
 */
export const zSchemaLtxVideo13bDevExtendOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * ExtendVideoInput
 */
export const zSchemaLtxVideo13bDevExtendInput = z.object({
  second_pass_skip_initial_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description:
          'The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.',
      }),
    )
    .default(17),
  first_pass_num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps during the first pass.',
      }),
    )
    .default(30),
  frame_rate: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frame rate of the video.',
      }),
    )
    .default(30),
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt to guide generation',
  }),
  reverse_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to reverse the video.',
      }),
    )
    .default(false),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to expand the prompt using a language model.',
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
        description: 'LoRA weights to use for generation',
      }),
    )
    .default([]),
  second_pass_num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps during the second pass.',
      }),
    )
    .default(30),
  num_frames: z
    .optional(
      z.int().gte(9).lte(161).register(z.globalRegistry, {
        description: 'The number of frames in the video.',
      }),
    )
    .default(121),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  video: zSchemaVideoConditioningInput,
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for generation',
      }),
    )
    .default('worst quality, inconsistent motion, blurry, jittery, distorted'),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['9:16', '1:1', '16:9', 'auto']).register(z.globalRegistry, {
      description: 'The aspect ratio of the video.',
    }),
  ),
  constant_rate_factor: z
    .optional(
      z.int().gte(20).lte(60).register(z.globalRegistry, {
        description:
          "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
      }),
    )
    .default(35),
  first_pass_skip_final_steps: z
    .optional(
      z.int().gte(0).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.',
      }),
    )
    .default(3),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
})

/**
 * MultiConditioningVideoOutput
 */
export const zSchemaLtxVideo13bDevMulticonditioningOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * MultiConditioningVideoInput
 */
export const zSchemaLtxVideo13bDevMulticonditioningInput = z.object({
  second_pass_skip_initial_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description:
          'The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.',
      }),
    )
    .default(17),
  first_pass_num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps during the first pass.',
      }),
    )
    .default(30),
  frame_rate: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frame rate of the video.',
      }),
    )
    .default(30),
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt to guide generation',
  }),
  reverse_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to reverse the video.',
      }),
    )
    .default(false),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to expand the prompt using a language model.',
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
        description: 'LoRA weights to use for generation',
      }),
    )
    .default([]),
  images: z
    .optional(
      z.array(zSchemaImageConditioningInput).register(z.globalRegistry, {
        description: 'URL of images to use as conditioning',
      }),
    )
    .default([]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(9).lte(161).register(z.globalRegistry, {
        description: 'The number of frames in the video.',
      }),
    )
    .default(121),
  second_pass_num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps during the second pass.',
      }),
    )
    .default(30),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for generation',
      }),
    )
    .default('worst quality, inconsistent motion, blurry, jittery, distorted'),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['9:16', '1:1', '16:9', 'auto']).register(z.globalRegistry, {
      description: 'The aspect ratio of the video.',
    }),
  ),
  videos: z
    .optional(
      z.array(zSchemaVideoConditioningInput).register(z.globalRegistry, {
        description: 'Videos to use as conditioning',
      }),
    )
    .default([]),
  constant_rate_factor: z
    .optional(
      z.int().gte(20).lte(60).register(z.globalRegistry, {
        description:
          "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
      }),
    )
    .default(35),
  first_pass_skip_final_steps: z
    .optional(
      z.int().gte(0).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.',
      }),
    )
    .default(3),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
})

/**
 * MultiConditioningVideoOutput
 */
export const zSchemaLtxVideo13bDistilledMulticonditioningOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * DistilledMultiConditioningVideoInput
 *
 * Distilled model input
 */
export const zSchemaLtxVideo13bDistilledMulticonditioningInput = z
  .object({
    second_pass_skip_initial_steps: z
      .optional(
        z.int().gte(1).lte(20).register(z.globalRegistry, {
          description:
            'The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.',
        }),
      )
      .default(5),
    first_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(20).register(z.globalRegistry, {
          description: 'Number of inference steps during the first pass.',
        }),
      )
      .default(8),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: 'The frame rate of the video.',
        }),
      )
      .default(30),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to reverse the video.',
        }),
      )
      .default(false),
    prompt: z.string().register(z.globalRegistry, {
      description: 'Text prompt to guide generation',
    }),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to expand the prompt using a language model.',
        }),
      )
      .default(false),
    loras: z
      .optional(
        z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
          description: 'LoRA weights to use for generation',
        }),
      )
      .default([]),
    images: z
      .optional(
        z.array(zSchemaImageConditioningInput).register(z.globalRegistry, {
          description: 'URL of images to use as conditioning',
        }),
      )
      .default([]),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable the safety checker.',
        }),
      )
      .default(true),
    num_frames: z
      .optional(
        z.int().gte(9).lte(161).register(z.globalRegistry, {
          description: 'The number of frames in the video.',
        }),
      )
      .default(121),
    second_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(20).register(z.globalRegistry, {
          description: 'Number of inference steps during the second pass.',
        }),
      )
      .default(8),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'Negative prompt for generation',
        }),
      )
      .default(
        'worst quality, inconsistent motion, blurry, jittery, distorted',
      ),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description: 'Resolution of the generated video (480p or 720p).',
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(['9:16', '1:1', '16:9', 'auto']).register(z.globalRegistry, {
        description: 'The aspect ratio of the video.',
      }),
    ),
    constant_rate_factor: z
      .optional(
        z.int().gte(20).lte(60).register(z.globalRegistry, {
          description:
            "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        }),
      )
      .default(35),
    videos: z
      .optional(
        z.array(zSchemaVideoConditioningInput).register(z.globalRegistry, {
          description: 'Videos to use as conditioning',
        }),
      )
      .default([]),
    first_pass_skip_final_steps: z
      .optional(
        z.int().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.',
        }),
      )
      .default(1),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'Random seed for generation',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Distilled model input',
  })

/**
 * ExtendVideoOutput
 */
export const zSchemaLtxVideo13bDistilledExtendOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * DistilledExtendVideoInput
 *
 * Distilled model input
 */
export const zSchemaLtxVideo13bDistilledExtendInput = z
  .object({
    second_pass_skip_initial_steps: z
      .optional(
        z.int().gte(1).lte(20).register(z.globalRegistry, {
          description:
            'The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.',
        }),
      )
      .default(5),
    first_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(20).register(z.globalRegistry, {
          description: 'Number of inference steps during the first pass.',
        }),
      )
      .default(8),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: 'The frame rate of the video.',
        }),
      )
      .default(30),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to reverse the video.',
        }),
      )
      .default(false),
    prompt: z.string().register(z.globalRegistry, {
      description: 'Text prompt to guide generation',
    }),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to expand the prompt using a language model.',
        }),
      )
      .default(false),
    loras: z
      .optional(
        z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
          description: 'LoRA weights to use for generation',
        }),
      )
      .default([]),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable the safety checker.',
        }),
      )
      .default(true),
    num_frames: z
      .optional(
        z.int().gte(9).lte(161).register(z.globalRegistry, {
          description: 'The number of frames in the video.',
        }),
      )
      .default(121),
    second_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(20).register(z.globalRegistry, {
          description: 'Number of inference steps during the second pass.',
        }),
      )
      .default(8),
    video: zSchemaVideoConditioningInput,
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'Negative prompt for generation',
        }),
      )
      .default(
        'worst quality, inconsistent motion, blurry, jittery, distorted',
      ),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description: 'Resolution of the generated video (480p or 720p).',
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(['9:16', '1:1', '16:9', 'auto']).register(z.globalRegistry, {
        description: 'The aspect ratio of the video.',
      }),
    ),
    constant_rate_factor: z
      .optional(
        z.int().gte(20).lte(60).register(z.globalRegistry, {
          description:
            "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        }),
      )
      .default(35),
    first_pass_skip_final_steps: z
      .optional(
        z.int().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.',
        }),
      )
      .default(1),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'Random seed for generation',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Distilled model input',
  })

/**
 * VideoFile
 */
export const zSchemaVideoFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  duration: z.optional(z.union([z.number(), z.unknown()])),
  height: z.optional(z.union([z.int(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(z.union([z.int(), z.unknown()])),
  fps: z.optional(z.union([z.number(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  num_frames: z.optional(z.union([z.int(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * WanVACEResponse
 */
export const zSchemaWanVace14bOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  frames_zip: z.optional(z.union([zSchemaFile, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * WanVACERequest
 */
export const zSchemaWanVace14bInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  video_url: z.optional(z.union([z.string(), z.unknown()])),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between the original frames. A value of 0 means no interpolation.',
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.',
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'URLs to source reference image. If provided, the model will use this image as reference.',
    }),
  ),
  transparency_mode: z.optional(
    z.enum(['content_aware', 'white', 'black']).register(z.globalRegistry, {
      description:
        'The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 241 (inclusive).',
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.',
      }),
    )
    .default(15),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.',
      }),
    )
    .default(5),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'Sampler to use for video generation.',
    }),
  ),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  mask_video_url: z.optional(z.union([z.string(), z.unknown()])),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(['rife', 'film']).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.',
      }),
    )
    .default(false),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the input video.',
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  acceleration: z.optional(
    z.union([z.enum(['none', 'low', 'regular']), z.unknown()]),
  ),
  mask_image_url: z.optional(z.union([z.string(), z.unknown()])),
  task: z.optional(
    z
      .enum(['depth', 'pose', 'inpainting', 'outpainting', 'reframe'])
      .register(z.globalRegistry, {
        description: 'Task type for the model.',
      }),
  ),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.',
      }),
    )
    .default(false),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP file containing all generated frames.',
      }),
    )
    .default(false),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * LipsyncAppOutput
 */
export const zSchemaLipsyncOutput = z.object({
  video: zSchemaFile,
})

/**
 * LipsyncInput
 */
export const zSchemaLipsyncInput = z.object({
  video_url: z.url().min(1).max(2083),
  audio_url: z.url().min(1).max(2083),
})

/**
 * ReframeOutput
 */
export const zSchemaLumaDreamMachineRay2ReframeOutput = z.object({
  video: zSchemaFile,
})

/**
 * ReframeVideoRequest
 */
export const zSchemaLumaDreamMachineRay2ReframeInput = z.object({
  prompt: z.optional(
    z.string().min(1).max(5000).register(z.globalRegistry, {
      description: 'Optional prompt for reframing',
    }),
  ),
  aspect_ratio: z
    .enum(['1:1', '16:9', '9:16', '4:3', '3:4', '21:9', '9:21'])
    .register(z.globalRegistry, {
      description: 'The aspect ratio of the reframed video',
    }),
  y_start: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Start Y coordinate for reframing',
    }),
  ),
  x_end: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'End X coordinate for reframing',
    }),
  ),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input video to reframe',
  }),
  y_end: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'End Y coordinate for reframing',
    }),
  ),
  x_start: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Start X coordinate for reframing',
    }),
  ),
  grid_position_y: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Y position of the grid for reframing',
    }),
  ),
  grid_position_x: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'X position of the grid for reframing',
    }),
  ),
  image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'Optional URL of the first frame image for reframing',
    }),
  ),
})

/**
 * ReframeOutput
 */
export const zSchemaLumaDreamMachineRay2FlashReframeOutput = z.object({
  video: zSchemaFile,
})

/**
 * ReframeVideoRequest
 */
export const zSchemaLumaDreamMachineRay2FlashReframeInput = z.object({
  prompt: z.optional(
    z.string().min(1).max(5000).register(z.globalRegistry, {
      description: 'Optional prompt for reframing',
    }),
  ),
  aspect_ratio: z
    .enum(['1:1', '16:9', '9:16', '4:3', '3:4', '21:9', '9:21'])
    .register(z.globalRegistry, {
      description: 'The aspect ratio of the reframed video',
    }),
  y_start: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Start Y coordinate for reframing',
    }),
  ),
  x_end: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'End X coordinate for reframing',
    }),
  ),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input video to reframe',
  }),
  y_end: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'End Y coordinate for reframing',
    }),
  ),
  x_start: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Start X coordinate for reframing',
    }),
  ),
  grid_position_y: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Y position of the grid for reframing',
    }),
  ),
  grid_position_x: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'X position of the grid for reframing',
    }),
  ),
  image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'Optional URL of the first frame image for reframing',
    }),
  ),
})

/**
 * WanT2VResponse
 */
export const zSchemaWanVace13bOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanT2VRequest
 */
export const zSchemaWanVace13bInput = z.object({
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  video_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'URL to the source video file. If provided, the model will use this video as a reference.',
    }),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  mask_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'URL to the guiding mask file. If provided, the model will use this mask as a reference to create masked video. If provided mask video url will be ignored.',
    }),
  ),
  task: z.optional(
    z.enum(['depth', 'inpainting', 'pose']).register(z.globalRegistry, {
      description: 'Task type for the model.',
    }),
  ),
  frames_per_second: z
    .optional(
      z.int().gte(5).lte(24).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 5 to 24.',
      }),
    )
    .default(16),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'Urls to source reference image. If provided, the model will use this image as reference.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(81).lte(240).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 100 (inclusive). Works only with only reference images as input if source video or mask video is provided output len would be same as source up to 241 frames',
      }),
    )
    .default(81),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p,580p, or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '9:16', '16:9']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video (16:9 or 9:16).',
    }),
  ),
  mask_video_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'URL to the source mask file. If provided, the model will use this mask as a reference.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the input video.',
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
})

/**
 * CombineOutput
 */
export const zSchemaFfmpegApiMergeAudioVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * CombineInput
 */
export const zSchemaFfmpegApiMergeAudioVideoInput = z.object({
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the video file to use as the video track',
  }),
  start_offset: z
    .optional(
      z.number().gte(0).register(z.globalRegistry, {
        description:
          'Offset in seconds for when the audio should start relative to the video',
      }),
    )
    .default(0),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'URL of the audio file to use as the audio track',
  }),
})

/**
 * DWPoseVideoOutput
 */
export const zSchemaDwposeVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * DWPoseVideoInput
 */
export const zSchemaDwposeVideoInput = z.object({
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of video to be used for pose estimation',
  }),
  draw_mode: z.optional(
    z
      .enum([
        'full-pose',
        'body-pose',
        'face-pose',
        'hand-pose',
        'face-hand-mask',
        'face-mask',
        'hand-mask',
      ])
      .register(z.globalRegistry, {
        description:
          "Mode of drawing the pose on the video. Options are: 'full-pose', 'body-pose', 'face-pose', 'hand-pose', 'face-hand-mask', 'face-mask', 'hand-mask'.",
      }),
  ),
})

/**
 * WanVACEDepthResponse
 */
export const zSchemaWanVace14bDepthOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  frames_zip: z.optional(z.union([zSchemaFile, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * WanVACEDepthRequest
 */
export const zSchemaWanVace14bDepthInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL to the source video file. Required for depth task.',
  }),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between the original frames. A value of 0 means no interpolation.',
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.',
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'URLs to source reference image. If provided, the model will use this image as reference.',
    }),
  ),
  transparency_mode: z.optional(
    z.enum(['content_aware', 'white', 'black']).register(z.globalRegistry, {
      description:
        'The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 241 (inclusive).',
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.',
      }),
    )
    .default(15),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.',
      }),
    )
    .default(5),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'Sampler to use for video generation.',
    }),
  ),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(['rife', 'film']).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.',
      }),
    )
    .default(false),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the input video.',
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.union([z.enum(['none', 'low', 'regular']), z.unknown()]),
  ),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.',
      }),
    )
    .default(false),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP file containing all generated frames.',
      }),
    )
    .default(false),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * WanVACEPoseResponse
 */
export const zSchemaWanVace14bPoseOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  frames_zip: z.optional(z.union([zSchemaFile, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * WanVACEPoseRequest
 */
export const zSchemaWanVace14bPoseInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The text prompt to guide video generation. For pose task, the prompt should describe the desired pose and action of the subject in the video.',
  }),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL to the source video file. Required for pose task.',
  }),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between the original frames. A value of 0 means no interpolation.',
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.',
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'URLs to source reference image. If provided, the model will use this image as reference.',
    }),
  ),
  transparency_mode: z.optional(
    z.enum(['content_aware', 'white', 'black']).register(z.globalRegistry, {
      description:
        'The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 241 (inclusive).',
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.',
      }),
    )
    .default(15),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.',
      }),
    )
    .default(5),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'Sampler to use for video generation.',
    }),
  ),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(['rife', 'film']).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.',
      }),
    )
    .default(false),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the input video.',
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.union([z.enum(['none', 'low', 'regular']), z.unknown()]),
  ),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.',
      }),
    )
    .default(false),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP file containing all generated frames.',
      }),
    )
    .default(false),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * WanVACEInpaintingResponse
 */
export const zSchemaWanVace14bInpaintingOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  frames_zip: z.optional(z.union([zSchemaFile, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * WanVACEInpaintingRequest
 */
export const zSchemaWanVace14bInpaintingInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL to the source video file. Required for inpainting.',
  }),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between the original frames. A value of 0 means no interpolation.',
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.',
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'Urls to source reference image. If provided, the model will use this image as reference.',
    }),
  ),
  transparency_mode: z.optional(
    z.enum(['content_aware', 'white', 'black']).register(z.globalRegistry, {
      description:
        'The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 241 (inclusive).',
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.',
      }),
    )
    .default(15),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.',
      }),
    )
    .default(5),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'Sampler to use for video generation.',
    }),
  ),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  mask_video_url: z.union([z.string(), z.unknown()]),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(['rife', 'film']).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.',
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the input video.',
      }),
    )
    .default(false),
  acceleration: z.optional(
    z.union([z.enum(['none', 'low', 'regular']), z.unknown()]),
  ),
  mask_image_url: z.optional(z.union([z.string(), z.unknown()])),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.',
      }),
    )
    .default(false),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP file containing all generated frames.',
      }),
    )
    .default(false),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * WanVACEOutpaintingResponse
 */
export const zSchemaWanVace14bOutpaintingOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  frames_zip: z.optional(z.union([zSchemaFile, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * WanVACEOutpaintingRequest
 */
export const zSchemaWanVace14bOutpaintingInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL to the source video file. Required for outpainting.',
  }),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between the original frames. A value of 0 means no interpolation.',
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.',
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'URLs to source reference image. If provided, the model will use this image as reference.',
    }),
  ),
  expand_ratio: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Amount of expansion. This is a float value between 0 and 1, where 0.25 adds 25% to the original video size on the specified sides.',
      }),
    )
    .default(0.25),
  transparency_mode: z.optional(
    z.enum(['content_aware', 'white', 'black']).register(z.globalRegistry, {
      description:
        'The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 241 (inclusive).',
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.',
      }),
    )
    .default(15),
  expand_bottom: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to expand the video to the bottom.',
      }),
    )
    .default(false),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'Sampler to use for video generation.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.',
      }),
    )
    .default(5),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(['rife', 'film']).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.',
      }),
    )
    .default(false),
  expand_top: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to expand the video to the top.',
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  expand_left: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to expand the video to the left.',
      }),
    )
    .default(false),
  acceleration: z.optional(
    z.union([z.enum(['none', 'low', 'regular']), z.unknown()]),
  ),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.',
      }),
    )
    .default(false),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP file containing all generated frames.',
      }),
    )
    .default(false),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
  ),
  expand_right: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to expand the video to the right.',
      }),
    )
    .default(false),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * WanVACEReframeResponse
 */
export const zSchemaWanVace14bReframeOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  frames_zip: z.optional(z.union([zSchemaFile, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * WanVACEReframeRequest
 */
export const zSchemaWanVace14bReframeInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'The text prompt to guide video generation. Optional for reframing.',
      }),
    )
    .default(''),
  video_url: z.string().register(z.globalRegistry, {
    description:
      'URL to the source video file. This video will be used as a reference for the reframe task.',
  }),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between the original frames. A value of 0 means no interpolation.',
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.',
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  transparency_mode: z.optional(
    z.enum(['content_aware', 'white', 'black']).register(z.globalRegistry, {
      description:
        'The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 241 (inclusive).',
      }),
    )
    .default(81),
  trim_borders: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to trim borders from the video.',
      }),
    )
    .default(true),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.',
      }),
    )
    .default(15),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'Sampler to use for video generation.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.',
      }),
    )
    .default(5),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(['rife', 'film']).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.',
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.union([z.enum(['none', 'low', 'regular']), z.unknown()]),
  ),
  zoom_factor: z
    .optional(
      z.number().gte(0).lte(0.9).register(z.globalRegistry, {
        description:
          'Zoom factor for the video. When this value is greater than 0, the video will be zoomed in by this factor (in relation to the canvas size,) cutting off the edges of the video. A value of 0 means no zoom.',
      }),
    )
    .default(0),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.',
      }),
    )
    .default(true),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP file containing all generated frames.',
      }),
    )
    .default(false),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * ModifyOutput
 */
export const zSchemaLumaDreamMachineRay2ModifyOutput = z.object({
  video: zSchemaFile,
})

/**
 * ModifyVideoRequest
 */
export const zSchemaLumaDreamMachineRay2ModifyInput = z.object({
  prompt: z.optional(
    z.string().min(3).max(5000).register(z.globalRegistry, {
      description: 'Instruction for modifying the video',
    }),
  ),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input video to modify',
  }),
  mode: z.optional(
    z
      .enum([
        'adhere_1',
        'adhere_2',
        'adhere_3',
        'flex_1',
        'flex_2',
        'flex_3',
        'reimagine_1',
        'reimagine_2',
        'reimagine_3',
      ])
      .register(z.globalRegistry, {
        description:
          'Amount of modification to apply to the video, adhere_1 is the least amount of modification, reimagine_3 is the most',
      }),
  ),
  image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'Optional URL of the first frame image for modification',
    }),
  ),
})

/**
 * LipsyncOutput
 */
export const zSchemaPixverseLipsyncOutput = z.object({
  video: zSchemaFile,
})

/**
 * LipsyncRequest
 */
export const zSchemaPixverseLipsyncInput = z.object({
  text: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'Text content for TTS when audio_url is not provided',
    }),
  ),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input video',
  }),
  audio_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'URL of the input audio. If not provided, TTS will be used.',
    }),
  ),
  voice_id: z.optional(
    z
      .enum([
        'Emily',
        'James',
        'Isabella',
        'Liam',
        'Chloe',
        'Adrian',
        'Harper',
        'Ava',
        'Sophia',
        'Julia',
        'Mason',
        'Jack',
        'Oliver',
        'Ethan',
        'Auto',
      ])
      .register(z.globalRegistry, {
        description: 'Voice to use for TTS when audio_url is not provided',
      }),
  ),
})

/**
 * ExtendOutput
 */
export const zSchemaPixverseExtendOutput = z.object({
  video: zSchemaFile,
})

/**
 * ExtendRequest
 */
export const zSchemaPixverseExtendInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Prompt describing how to extend the video',
  }),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p', '1080p']).register(z.globalRegistry, {
      description: 'The resolution of the generated video',
    }),
  ),
  duration: z.optional(
    z.enum(['5', '8']).register(z.globalRegistry, {
      description:
        'The duration of the generated video in seconds. 1080p videos are limited to 5 seconds',
    }),
  ),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the extended video',
      }),
  ),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input video to extend',
  }),
  model: z.optional(
    z
      .enum(['v3.5', 'v4', 'v4.5', 'v5', 'v5.5', 'v5.6'])
      .register(z.globalRegistry, {
        description: 'The model version to use for generation',
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * ExtendOutput
 */
export const zSchemaPixverseExtendFastOutput = z.object({
  video: zSchemaFile,
})

/**
 * FastExtendRequest
 */
export const zSchemaPixverseExtendFastInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Prompt describing how to extend the video',
  }),
  resolution: z.optional(
    z.enum(['360p', '540p', '720p']).register(z.globalRegistry, {
      description:
        "The resolution of the generated video. Fast mode doesn't support 1080p",
    }),
  ),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input video to extend',
  }),
  style: z.optional(
    z
      .enum(['anime', '3d_animation', 'clay', 'comic', 'cyberpunk'])
      .register(z.globalRegistry, {
        description: 'The style of the extended video',
      }),
  ),
  model: z.optional(
    z
      .enum(['v3.5', 'v4', 'v4.5', 'v5', 'v5.5', 'v5.6'])
      .register(z.globalRegistry, {
        description: 'The model version to use for generation',
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to be used for the generation',
      }),
    )
    .default(''),
})

/**
 * Output
 */
export const zSchemaThinksoundOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used to generate the audio.',
  }),
  video: zSchemaFile,
})

/**
 * Input
 */
export const zSchemaThinksoundInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'A prompt to guide the audio generation. If not provided, it will be extracted from the video.',
      }),
    )
    .default(''),
  video_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the video to generate the audio for.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(100).register(z.globalRegistry, {
        description: 'The number of inference steps for audio generation.',
      }),
    )
    .default(24),
  cfg_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description: 'The classifier-free guidance scale for audio generation.',
      }),
    )
    .default(5),
})

/**
 * AudioOutput
 */
export const zSchemaThinksoundAudioOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used to generate the audio.',
  }),
  audio: zSchemaFile,
})

/**
 * Input
 */
export const zSchemaThinksoundAudioInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'A prompt to guide the audio generation. If not provided, it will be extracted from the video.',
      }),
    )
    .default(''),
  video_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the video to generate the audio for.',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(100).register(z.globalRegistry, {
        description: 'The number of inference steps for audio generation.',
      }),
    )
    .default(24),
  cfg_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description: 'The classifier-free guidance scale for audio generation.',
      }),
    )
    .default(5),
})

/**
 * SoundEffectOutput
 */
export const zSchemaPixverseSoundEffectsOutput = z.object({
  video: zSchemaFile,
})

/**
 * SoundEffectRequest
 */
export const zSchemaPixverseSoundEffectsInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Description of the sound effect to generate. If empty, a random sound effect will be generated',
      }),
    )
    .default(''),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input video to add sound effects to',
  }),
  original_sound_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to keep the original audio from the video',
      }),
    )
    .default(false),
})

/**
 * MultiConditioningVideoOutput
 */
export const zSchemaLtxv13B098DistilledMulticonditioningOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * DistilledMultiConditioningVideoInput
 *
 * Distilled model input
 */
export const zSchemaLtxv13B098DistilledMulticonditioningInput = z
  .object({
    second_pass_skip_initial_steps: z
      .optional(
        z.int().gte(1).lte(11).register(z.globalRegistry, {
          description:
            'The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.',
        }),
      )
      .default(5),
    first_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(12).register(z.globalRegistry, {
          description: 'Number of inference steps during the first pass.',
        }),
      )
      .default(8),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: 'The frame rate of the video.',
        }),
      )
      .default(24),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to reverse the video.',
        }),
      )
      .default(false),
    prompt: z.string().register(z.globalRegistry, {
      description: 'Text prompt to guide generation',
    }),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to expand the prompt using a language model.',
        }),
      )
      .default(false),
    temporal_adain_factor: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            'The factor for adaptive instance normalization (AdaIN) applied to generated video chunks after the first. This can help deal with a gradual increase in saturation/contrast in the generated video by normalizing the color distribution across the video. A high value will ensure the color distribution is more consistent across the video, while a low value will allow for more variation in color distribution.',
        }),
      )
      .default(0.5),
    loras: z
      .optional(
        z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
          description: 'LoRA weights to use for generation',
        }),
      )
      .default([]),
    images: z
      .optional(
        z.array(zSchemaImageConditioningInput).register(z.globalRegistry, {
          description: 'URL of images to use as conditioning',
        }),
      )
      .default([]),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable the safety checker.',
        }),
      )
      .default(true),
    num_frames: z
      .optional(
        z.int().gte(9).lte(1441).register(z.globalRegistry, {
          description: 'The number of frames in the video.',
        }),
      )
      .default(121),
    second_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(12).register(z.globalRegistry, {
          description: 'Number of inference steps during the second pass.',
        }),
      )
      .default(8),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'Negative prompt for generation',
        }),
      )
      .default(
        'worst quality, inconsistent motion, blurry, jittery, distorted',
      ),
    enable_detail_pass: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to use a detail pass. If True, the model will perform a second pass to refine the video and enhance details. This incurs a 2.0x cost multiplier on the base price.',
        }),
      )
      .default(false),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(['9:16', '1:1', '16:9', 'auto']).register(z.globalRegistry, {
        description: 'The aspect ratio of the video.',
      }),
    ),
    tone_map_compression_ratio: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            'The compression ratio for tone mapping. This is used to compress the dynamic range of the video to improve visual quality. A value of 0.0 means no compression, while a value of 1.0 means maximum compression.',
        }),
      )
      .default(0),
    videos: z
      .optional(
        z.array(zSchemaVideoConditioningInput).register(z.globalRegistry, {
          description: 'Videos to use as conditioning',
        }),
      )
      .default([]),
    constant_rate_factor: z
      .optional(
        z.int().gte(0).lte(51).register(z.globalRegistry, {
          description:
            "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        }),
      )
      .default(29),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'Random seed for generation',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Distilled model input',
  })

/**
 * ModifyOutput
 */
export const zSchemaLumaDreamMachineRay2FlashModifyOutput = z.object({
  video: zSchemaFile,
})

/**
 * ModifyVideoRequest
 */
export const zSchemaLumaDreamMachineRay2FlashModifyInput = z.object({
  prompt: z.optional(
    z.string().min(3).max(5000).register(z.globalRegistry, {
      description: 'Instruction for modifying the video',
    }),
  ),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input video to modify',
  }),
  mode: z.optional(
    z
      .enum([
        'adhere_1',
        'adhere_2',
        'adhere_3',
        'flex_1',
        'flex_2',
        'flex_3',
        'reimagine_1',
        'reimagine_2',
        'reimagine_3',
      ])
      .register(z.globalRegistry, {
        description:
          'Amount of modification to apply to the video, adhere_1 is the least amount of modification, reimagine_3 is the most',
      }),
  ),
  image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'Optional URL of the first frame image for modification',
    }),
  ),
})

/**
 * FILMVideoOutput
 */
export const zSchemaFilmVideoOutput = z.object({
  video: zSchemaVideoFile,
})

/**
 * FILMVideoInput
 */
export const zSchemaFilmVideoInput = z.object({
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description:
        "The write mode of the output video. Only applicable if output_type is 'video'.",
    }),
  ),
  video_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the video to use for interpolation.',
  }),
  use_calculated_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If True, the function will use the calculated FPS of the input video multiplied by the number of frames to determine the output FPS. If False, the passed FPS will be used.',
      }),
    )
    .default(true),
  loop: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If True, the final frame will be looped back to the first frame to create a seamless loop. If False, the final frame will not loop back.',
      }),
    )
    .default(false),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'Frames per second for the output video. Only applicable if use_calculated_fps is False.',
      }),
    )
    .default(8),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description:
        "The quality of the output video. Only applicable if output_type is 'video'.",
    }),
  ),
  use_scene_detection: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If True, the input video will be split into scenes before interpolation. This removes smear frames between scenes, but can result in false positives if the scene detection is not accurate. If False, the entire video will be treated as a single scene.',
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description:
          'The number of frames to generate between the input video frames.',
      }),
    )
    .default(1),
})

/**
 * RIFEVideoOutput
 */
export const zSchemaRifeVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * RIFEVideoInput
 */
export const zSchemaRifeVideoInput = z.object({
  video_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the video to use for interpolation.',
  }),
  use_scene_detection: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If True, the input video will be split into scenes before interpolation. This removes smear frames between scenes, but can result in false positives if the scene detection is not accurate. If False, the entire video will be treated as a single scene.',
      }),
    )
    .default(false),
  loop: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If True, the final frame will be looped back to the first frame to create a seamless loop. If False, the final frame will not loop back.',
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description:
          'The number of frames to generate between the input video frames.',
      }),
    )
    .default(1),
  use_calculated_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If True, the function will use the calculated FPS of the input video multiplied by the number of frames to determine the output FPS. If False, the passed FPS will be used.',
      }),
    )
    .default(true),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'Frames per second for the output video. Only applicable if use_calculated_fps is False.',
      }),
    )
    .default(8),
})

/**
 * ExtendVideoConditioningInput
 */
export const zSchemaExtendVideoConditioningInput = z.object({
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of video to use as conditioning',
  }),
  start_frame_num: z
    .optional(
      z.int().gte(0).lte(1440).register(z.globalRegistry, {
        description:
          'Frame number of the video from which the conditioning starts. Must be a multiple of 8.',
      }),
    )
    .default(0),
  reverse_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to reverse the video. This is useful for tasks where the video conditioning should be applied in reverse order.',
      }),
    )
    .default(false),
  limit_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to limit the number of frames used from the video. If True, the `max_num_frames` parameter will be used to limit the number of frames.',
      }),
    )
    .default(false),
  resample_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to resample the video to a specific FPS. If True, the `target_fps` parameter will be used to resample the video.',
      }),
    )
    .default(false),
  strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Strength of the conditioning. 0.0 means no conditioning, 1.0 means full conditioning.',
      }),
    )
    .default(1),
  target_fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'Target FPS to resample the video to. Only relevant if `resample_fps` is True.',
      }),
    )
    .default(24),
  max_num_frames: z
    .optional(
      z.int().gte(1).lte(1441).register(z.globalRegistry, {
        description:
          'Maximum number of frames to use from the video. If None, all frames will be used.',
      }),
    )
    .default(1441),
})

/**
 * ExtendVideoOutput
 */
export const zSchemaLtxv13B098DistilledExtendOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * DistilledExtendVideoInput
 *
 * Distilled model input
 */
export const zSchemaLtxv13B098DistilledExtendInput = z
  .object({
    second_pass_skip_initial_steps: z
      .optional(
        z.int().gte(1).lte(11).register(z.globalRegistry, {
          description:
            'The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.',
        }),
      )
      .default(5),
    first_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(12).register(z.globalRegistry, {
          description: 'Number of inference steps during the first pass.',
        }),
      )
      .default(8),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: 'The frame rate of the video.',
        }),
      )
      .default(24),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to reverse the video.',
        }),
      )
      .default(false),
    prompt: z.string().register(z.globalRegistry, {
      description: 'Text prompt to guide generation',
    }),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to expand the prompt using a language model.',
        }),
      )
      .default(false),
    temporal_adain_factor: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            'The factor for adaptive instance normalization (AdaIN) applied to generated video chunks after the first. This can help deal with a gradual increase in saturation/contrast in the generated video by normalizing the color distribution across the video. A high value will ensure the color distribution is more consistent across the video, while a low value will allow for more variation in color distribution.',
        }),
      )
      .default(0.5),
    loras: z
      .optional(
        z.array(zSchemaLoRaWeight).register(z.globalRegistry, {
          description: 'LoRA weights to use for generation',
        }),
      )
      .default([]),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable the safety checker.',
        }),
      )
      .default(true),
    num_frames: z
      .optional(
        z.int().gte(9).lte(1441).register(z.globalRegistry, {
          description: 'The number of frames in the video.',
        }),
      )
      .default(121),
    second_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(12).register(z.globalRegistry, {
          description: 'Number of inference steps during the second pass.',
        }),
      )
      .default(8),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'Negative prompt for generation',
        }),
      )
      .default(
        'worst quality, inconsistent motion, blurry, jittery, distorted',
      ),
    video: zSchemaExtendVideoConditioningInput,
    enable_detail_pass: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to use a detail pass. If True, the model will perform a second pass to refine the video and enhance details. This incurs a 2.0x cost multiplier on the base price.',
        }),
      )
      .default(false),
    resolution: z.optional(
      z.enum(['480p', '720p']).register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(['9:16', '1:1', '16:9', 'auto']).register(z.globalRegistry, {
        description: 'The aspect ratio of the video.',
      }),
    ),
    tone_map_compression_ratio: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            'The compression ratio for tone mapping. This is used to compress the dynamic range of the video to improve visual quality. A value of 0.0 means no compression, while a value of 1.0 means maximum compression.',
        }),
      )
      .default(0),
    constant_rate_factor: z
      .optional(
        z.int().gte(0).lte(51).register(z.globalRegistry, {
          description:
            "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        }),
      )
      .default(29),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'Random seed for generation',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Distilled model input',
  })

/**
 * WanV2VResponse
 */
export const zSchemaWanV22A14bVideoToVideoOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The text prompt used for video generation.',
      }),
    )
    .default(''),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * WanV2VRequest
 */
export const zSchemaWanV22A14bVideoToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input video.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(4).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.',
      }),
    )
    .default(1),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift value for the video. Must be between 1.0 and 10.0.',
      }),
    )
    .default(5),
  resample_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the video will be resampled to the passed frames per second. If false, the video will not be resampled.',
      }),
    )
    .default(false),
  frames_per_second: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.',
      }),
    )
    .default(16),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, input data will be checked for safety before processing.',
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(17).lte(161).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 17 to 161 (inclusive).',
      }),
    )
    .default(81),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(3.5),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(''),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description:
        'The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p, 580p, or 720p).',
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input video.",
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, output video will be checked for safety after generation.',
      }),
    )
    .default(false),
  guidance_scale_2: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.',
      }),
    )
    .default(4),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description:
        'The quality of the output video. Higher quality means better visual quality but larger file size.',
    }),
  ),
  strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Strength of the video transformation. A value of 1.0 means the output will be completely based on the prompt, while a value of 0.0 means the output will be identical to the input video.',
      }),
    )
    .default(0.9),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(27),
  interpolator_model: z.optional(
    z.enum(['none', 'film', 'rife']).register(z.globalRegistry, {
      description:
        'The model to use for frame interpolation. If None, no interpolation is applied.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  adjust_fps_for_interpolation: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.',
      }),
    )
    .default(true),
})

/**
 * MergeVideosOutput
 */
export const zSchemaFfmpegApiMergeVideosOutput = z.object({
  metadata: z.record(z.string(), z.unknown()).register(z.globalRegistry, {
    description:
      'Metadata about the merged video including original video info',
  }),
  video: zSchemaFile,
})

/**
 * MergeVideosInput
 */
export const zSchemaFfmpegApiMergeVideosInput = z.object({
  target_fps: z.optional(z.union([z.number().gte(1).lte(60), z.unknown()])),
  video_urls: z.array(z.string()).min(2).register(z.globalRegistry, {
    description: 'List of video URLs to merge in order',
  }),
  resolution: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
      z.unknown(),
    ]),
  ),
})

/**
 * MareyOutput
 */
export const zSchemaMareyMotionTransferOutput = z.object({
  video: zSchemaFile,
})

/**
 * MareyInputMotionTransfer
 */
export const zSchemaMareyMotionTransferInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate a video from',
  }),
  video_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the video to use as the control video.',
  }),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  reference_image_url: z.optional(z.union([z.string(), z.unknown()])),
  negative_prompt: z.optional(z.union([z.string(), z.unknown()])),
  first_frame_image_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * MareyOutput
 */
export const zSchemaMareyPoseTransferOutput = z.object({
  video: zSchemaFile,
})

/**
 * MareyInputPoseTransfer
 */
export const zSchemaMareyPoseTransferInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate a video from',
  }),
  video_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the video to use as the control video.',
  }),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  reference_image_url: z.optional(z.union([z.string(), z.unknown()])),
  negative_prompt: z.optional(z.union([z.string(), z.unknown()])),
  first_frame_image_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * VideoOutput
 */
export const zSchemaSfxV1VideoToVideoOutput = z.object({
  video: z.array(zSchemaVideo).register(z.globalRegistry, {
    description: 'The processed video with sound effects',
  }),
})

/**
 * Input
 */
export const zSchemaSfxV1VideoToVideoInput = z.object({
  num_samples: z.optional(z.union([z.int().gte(2).lte(8), z.unknown()])),
  video_url: z.url().min(1).max(2083).register(z.globalRegistry, {
    description:
      'A video url that can accessed from the API to process and add sound effects',
  }),
  duration: z.optional(z.union([z.number().gte(1).lte(10), z.unknown()])),
  seed: z.optional(z.union([z.int().gte(1), z.unknown()])),
  text_prompt: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * AvatarSingleAudioResponse
 */
export const zSchemaInfinitalkOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * InfiniTalkSingleAudioRequest
 */
export const zSchemaInfinitalkInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the video to generate. Must be either 480p or 720p.',
    }),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use for generation.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.',
  }),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the audio file.',
  }),
  num_frames: z
    .optional(
      z.int().gte(41).lte(721).register(z.globalRegistry, {
        description: 'Number of frames to generate. Must be between 41 to 721.',
      }),
    )
    .default(145),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    )
    .default(42),
})

/**
 * OutputIncreaseResolutionModel
 */
export const zSchemaVideoIncreaseResolutionOutput = z.object({
  video: z.union([zSchemaVideo, zSchemaFile]),
})

/**
 * InputIncreaseResolutionModel
 */
export const zSchemaVideoIncreaseResolutionInput = z.object({
  video_url: z.string().register(z.globalRegistry, {
    description:
      'Input video to increase resolution. Size should be less than 14142x14142 and duration less than 30s.',
  }),
  output_container_and_codec: z.optional(
    z
      .enum([
        'mp4_h265',
        'mp4_h264',
        'webm_vp9',
        'mov_h265',
        'mov_proresks',
        'mkv_h265',
        'mkv_h264',
        'mkv_vp9',
        'gif',
      ])
      .register(z.globalRegistry, {
        description:
          'Output container and codec. Options: mp4_h265, mp4_h264, webm_vp9, mov_h265, mov_proresks, mkv_h265, mkv_h264, mkv_vp9, gif.',
      }),
  ),
  desired_increase: z.optional(
    z.enum(['2', '4']).register(z.globalRegistry, {
      description: 'desired_increase factor. Options: 2x, 4x.',
    }),
  ),
})

/**
 * WanFunControlResponse
 */
export const zSchemaWanFunControlOutput = z.object({
  video: zSchemaFile,
})

/**
 * WanFunControlRequest
 */
export const zSchemaWanFunControlInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video.',
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The shift for the scheduler.',
      }),
    )
    .default(5),
  preprocess_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to preprocess the video. If True, the video will be preprocessed to depth or pose.',
      }),
    )
    .default(false),
  reference_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The URL of the reference image to use as a reference for the video generation.',
    }),
  ),
  fps: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          'The fps to generate. Only used when match_input_fps is False.',
      }),
    )
    .default(16),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to match the number of frames in the input video.',
      }),
    )
    .default(true),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale.',
      }),
    )
    .default(6),
  preprocess_type: z.optional(
    z.enum(['depth', 'pose']).register(z.globalRegistry, {
      description:
        'The type of preprocess to apply to the video. Only used when preprocess_video is True.',
    }),
  ),
  control_video_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the control video to use as a reference for the video generation.',
  }),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video.',
      }),
    )
    .default(''),
  num_frames: z
    .optional(
      z.int().gte(49).lte(121).register(z.globalRegistry, {
        description:
          'The number of frames to generate. Only used when match_input_num_frames is False.',
      }),
    )
    .default(81),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(4).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps.',
      }),
    )
    .default(27),
  match_input_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to match the fps in the input video.',
      }),
    )
    .default(true),
})

/**
 * LipSyncV2ProOutput
 */
export const zSchemaSyncLipsyncV2ProOutput = z.object({
  video: zSchemaFile,
})

/**
 * LipSyncV2ProInput
 */
export const zSchemaSyncLipsyncV2ProInput = z.object({
  sync_mode: z.optional(
    z
      .enum(['cut_off', 'loop', 'bounce', 'silence', 'remap'])
      .register(z.globalRegistry, {
        description:
          'Lipsync mode when audio and video durations are out of sync.',
      }),
  ),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input video',
  }),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input audio',
  }),
})

/**
 * HunyuanFoleyResponse
 */
export const zSchemaHunyuanVideoFoleyOutput = z.object({
  video: zSchemaFile,
})

/**
 * HunyuanFoleyRequest
 */
export const zSchemaHunyuanVideoFoleyInput = z.object({
  video_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the video to generate audio for.',
  }),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Guidance scale for audio generation.',
      }),
    )
    .default(4.5),
  num_inference_steps: z
    .optional(
      z.int().gte(10).lte(100).register(z.globalRegistry, {
        description: 'Number of inference steps for generation.',
      }),
    )
    .default(50),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for reproducible generation.',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt to avoid certain audio characteristics.',
      }),
    )
    .default('noisy, harsh'),
  text_prompt: z.string().register(z.globalRegistry, {
    description: 'Text description of the desired audio (optional).',
  }),
})

/**
 * WanVACEPoseResponse
 */
export const zSchemaWan22VaceFunA14bPoseOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  frames_zip: z.optional(z.union([zSchemaFile, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * WanVACEPoseRequest
 */
export const zSchemaWan22VaceFunA14bPoseInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The text prompt to guide video generation. For pose task, the prompt should describe the desired pose and action of the subject in the video.',
  }),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL to the source video file. Required for pose task.',
  }),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between the original frames. A value of 0 means no interpolation.',
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.',
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'URLs to source reference image. If provided, the model will use this image as reference.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.',
      }),
    )
    .default(5),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 241 (inclusive).',
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.',
      }),
    )
    .default(15),
  transparency_mode: z.optional(
    z.enum(['content_aware', 'white', 'black']).register(z.globalRegistry, {
      description:
        'The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.',
    }),
  ),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'Sampler to use for video generation.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(['rife', 'film']).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.',
      }),
    )
    .default(false),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the input video.',
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.union([z.enum(['none', 'low', 'regular']), z.unknown()]),
  ),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP file containing all generated frames.',
      }),
    )
    .default(false),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * WanVACEDepthResponse
 */
export const zSchemaWan22VaceFunA14bDepthOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  frames_zip: z.optional(z.union([zSchemaFile, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * WanVACEDepthRequest
 */
export const zSchemaWan22VaceFunA14bDepthInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL to the source video file. Required for depth task.',
  }),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between the original frames. A value of 0 means no interpolation.',
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.',
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'URLs to source reference image. If provided, the model will use this image as reference.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.',
      }),
    )
    .default(5),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 241 (inclusive).',
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.',
      }),
    )
    .default(15),
  transparency_mode: z.optional(
    z.enum(['content_aware', 'white', 'black']).register(z.globalRegistry, {
      description:
        'The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.',
    }),
  ),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'Sampler to use for video generation.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(['rife', 'film']).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.',
      }),
    )
    .default(false),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the input video.',
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.union([z.enum(['none', 'low', 'regular']), z.unknown()]),
  ),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP file containing all generated frames.',
      }),
    )
    .default(false),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * WanVACEInpaintingResponse
 */
export const zSchemaWan22VaceFunA14bInpaintingOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  frames_zip: z.optional(z.union([zSchemaFile, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * WanVACEInpaintingRequest
 */
export const zSchemaWan22VaceFunA14bInpaintingInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL to the source video file. Required for inpainting.',
  }),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between the original frames. A value of 0 means no interpolation.',
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.',
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'Urls to source reference image. If provided, the model will use this image as reference.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.',
      }),
    )
    .default(5),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 241 (inclusive).',
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.',
      }),
    )
    .default(15),
  transparency_mode: z.optional(
    z.enum(['content_aware', 'white', 'black']).register(z.globalRegistry, {
      description:
        'The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.',
    }),
  ),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'Sampler to use for video generation.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  mask_video_url: z.union([z.string(), z.unknown()]),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(['rife', 'film']).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.',
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the input video.',
      }),
    )
    .default(false),
  acceleration: z.optional(
    z.union([z.enum(['none', 'low', 'regular']), z.unknown()]),
  ),
  mask_image_url: z.optional(z.union([z.string(), z.unknown()])),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP file containing all generated frames.',
      }),
    )
    .default(false),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * WanVACEOutpaintingResponse
 */
export const zSchemaWan22VaceFunA14bOutpaintingOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  frames_zip: z.optional(z.union([zSchemaFile, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * WanVACEOutpaintingRequest
 */
export const zSchemaWan22VaceFunA14bOutpaintingInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL to the source video file. Required for outpainting.',
  }),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between the original frames. A value of 0 means no interpolation.',
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.',
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'URLs to source reference image. If provided, the model will use this image as reference.',
    }),
  ),
  expand_ratio: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Amount of expansion. This is a float value between 0 and 1, where 0.25 adds 25% to the original video size on the specified sides.',
      }),
    )
    .default(0.25),
  transparency_mode: z.optional(
    z.enum(['content_aware', 'white', 'black']).register(z.globalRegistry, {
      description:
        'The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 241 (inclusive).',
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.',
      }),
    )
    .default(15),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.',
      }),
    )
    .default(5),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'Sampler to use for video generation.',
    }),
  ),
  expand_bottom: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to expand the video to the bottom.',
      }),
    )
    .default(false),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  expand_left: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to expand the video to the left.',
      }),
    )
    .default(false),
  interpolator_model: z.optional(
    z.enum(['rife', 'film']).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.',
      }),
    )
    .default(false),
  expand_top: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to expand the video to the top.',
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  acceleration: z.optional(
    z.union([z.enum(['none', 'low', 'regular']), z.unknown()]),
  ),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  expand_right: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to expand the video to the right.',
      }),
    )
    .default(false),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP file containing all generated frames.',
      }),
    )
    .default(false),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * WanVACEReframeResponse
 */
export const zSchemaWan22VaceFunA14bReframeOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  frames_zip: z.optional(z.union([zSchemaFile, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * WanVACEReframeRequest
 */
export const zSchemaWan22VaceFunA14bReframeInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'The text prompt to guide video generation. Optional for reframing.',
      }),
    )
    .default(''),
  video_url: z.string().register(z.globalRegistry, {
    description:
      'URL to the source video file. This video will be used as a reference for the reframe task.',
  }),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between the original frames. A value of 0 means no interpolation.',
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.',
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.',
      }),
    )
    .default(5),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 241 (inclusive).',
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.',
      }),
    )
    .default(15),
  trim_borders: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to trim borders from the video.',
      }),
    )
    .default(true),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'Sampler to use for video generation.',
    }),
  ),
  transparency_mode: z.optional(
    z.enum(['content_aware', 'white', 'black']).register(z.globalRegistry, {
      description:
        'The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(['rife', 'film']).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.',
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.union([z.enum(['none', 'low', 'regular']), z.unknown()]),
  ),
  zoom_factor: z
    .optional(
      z.number().gte(0).lte(0.9).register(z.globalRegistry, {
        description:
          'Zoom factor for the video. When this value is greater than 0, the video will be zoomed in by this factor (in relation to the canvas size,) cutting off the edges of the video. A value of 0 means no zoom.',
      }),
    )
    .default(0),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.',
      }),
    )
    .default(true),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP file containing all generated frames.',
      }),
    )
    .default(false),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * LucyEditDevOutput
 */
export const zSchemaLucyEditDevOutput = z.object({
  video: zSchemaFile,
})

/**
 * LucyEditDevInput
 */
export const zSchemaLucyEditDevInput = z.object({
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the video to be generated\n            and uploaded before returning the response. This will increase the\n            latency of the function but it allows you to get the video directly\n            in the response without going through the CDN.\n        ',
      }),
    )
    .default(true),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the video to edit',
  }),
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text description of the desired video content',
  }),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enhance the prompt for better results.',
      }),
    )
    .default(true),
})

/**
 * LucyEditProOutput
 */
export const zSchemaLucyEditProOutput = z.object({
  video: zSchemaFile,
})

/**
 * LucyEditProInput
 */
export const zSchemaLucyEditProInput = z.object({
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the video to be generated\n            and uploaded before returning the response. This will increase the\n            latency of the function but it allows you to get the video directly\n            in the response without going through the CDN.\n        ',
      }),
    )
    .default(true),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the video to edit',
  }),
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text description of the desired video content',
  }),
  resolution: z.optional(
    z.enum(['720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video',
    }),
  ),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enhance the prompt for better results.',
      }),
    )
    .default(true),
})

/**
 * WanAnimateMoveResponse
 */
export const zSchemaWanV2214bAnimateMoveOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation (auto-generated by the model)',
  }),
  frames_zip: z.optional(zSchemaFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
  video: zSchemaFile,
})

/**
 * WanAnimateMoveRequest
 */
export const zSchemaWanV2214bAnimateMoveInput = z.object({
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description:
        'The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.',
    }),
  ),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input video.',
  }),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p, 580p, or 720p).',
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP archive containing per-frame images generated on GPU (lossless).',
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift value for the video. Must be between 1.0 and 10.0.',
      }),
    )
    .default(5),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, output video will be checked for safety after generation.',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.',
  }),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description:
        'The quality of the output video. Higher quality means better visual quality but larger file size.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, input data will be checked for safety before processing.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(20),
  use_turbo: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, applies quality enhancement for faster generation with improved quality. When enabled, parameters are automatically optimized for best results.',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(1),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
})

/**
 * WanAnimateReplaceResponse
 */
export const zSchemaWanV2214bAnimateReplaceOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation (auto-generated by the model)',
  }),
  frames_zip: z.optional(zSchemaFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
  video: zSchemaFile,
})

/**
 * WanAnimateMoveRequest
 */
export const zSchemaWanV2214bAnimateReplaceInput = z.object({
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description:
        'The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.',
    }),
  ),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input video.',
  }),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video (480p, 580p, or 720p).',
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP archive containing per-frame images generated on GPU (lossless).',
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift value for the video. Must be between 1.0 and 10.0.',
      }),
    )
    .default(5),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, output video will be checked for safety after generation.',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.',
  }),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description:
        'The quality of the output video. Higher quality means better visual quality but larger file size.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, input data will be checked for safety before processing.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(20),
  use_turbo: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, applies quality enhancement for faster generation with improved quality. When enabled, parameters are automatically optimized for best results.',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(1),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
})

/**
 * WanVACEVideoEditResponse
 */
export const zSchemaWanVaceAppsVideoEditOutput = z.object({
  frames_zip: z.optional(zSchemaFile),
  video: zSchemaVideoFile,
})

/**
 * WanVACEVideoEditRequest
 */
export const zSchemaWanVaceAppsVideoEditInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Prompt to edit the video.',
  }),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input video.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'low', 'regular']).register(z.globalRegistry, {
      description:
        "Acceleration to use for inference. Options are 'none' or 'regular'. Accelerated inference will very slightly affect output, but will be significantly faster.",
    }),
  ),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the edited video.',
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'Aspect ratio of the edited video.',
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to include a ZIP archive containing all generated frames.',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  video_type: z.optional(
    z.enum(['auto', 'general', 'human']).register(z.globalRegistry, {
      description:
        "The type of video you're editing. Use 'general' for most videos, and 'human' for videos emphasizing human subjects and motions. The default value 'auto' means the model will guess based on the first frame of the video.",
    }),
  ),
  image_urls: z
    .optional(
      z.array(z.string()).register(z.globalRegistry, {
        description:
          'URLs of the input images to use as a reference for the generation.',
      }),
    )
    .default([]),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable automatic downsampling. If your video has a high frame rate or is long, enabling longer sequences to be generated. The video will be interpolated back to the original frame rate after generation.',
      }),
    )
    .default(true),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          'The minimum frames per second to downsample the video to.',
      }),
    )
    .default(15),
})

/**
 * SeedVRVideoOutput
 */
export const zSchemaSeedvrUpscaleVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The random seed used for the generation process.',
  }),
  video: zSchemaFile,
})

/**
 * SeedVRVideoInput
 */
export const zSchemaSeedvrUpscaleVideoInput = z.object({
  upscale_mode: z.optional(
    z.enum(['target', 'factor']).register(z.globalRegistry, {
      description:
        "The mode to use for the upscale. If 'target', the upscale factor will be calculated based on the target resolution. If 'factor', the upscale factor will be used directly.",
    }),
  ),
  video_url: z.string().register(z.globalRegistry, {
    description: 'The input video to be processed',
  }),
  noise_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The noise scale to use for the generation process.',
      }),
    )
    .default(0.1),
  output_format: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The format of the output video.',
      }),
  ),
  output_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the output video.',
    }),
  ),
  target_resolution: z.optional(
    z.enum(['720p', '1080p', '1440p', '2160p']).register(z.globalRegistry, {
      description:
        'The target resolution to upscale to when `upscale_mode` is `target`.',
    }),
  ),
  output_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the output video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  upscale_factor: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Upscaling factor to be used. Will multiply the dimensions with this factor when `upscale_mode` is `factor`.',
      }),
    )
    .default(2),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * InfinitalkVid2VidResponse
 */
export const zSchemaInfinitalkVideoToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaFile,
})

/**
 * InfiniTalkVid2VidAudioRequest
 */
export const zSchemaInfinitalkVideoToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description:
        'Resolution of the video to generate. Must be either 480p or 720p.',
    }),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use for generation.',
    }),
  ),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the input video.',
  }),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the audio file.',
  }),
  num_frames: z
    .optional(
      z.int().gte(41).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.',
      }),
    )
    .default(145),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    )
    .default(42),
})

/**
 * LongWanVACEReframeResponse
 */
export const zSchemaWanVaceAppsLongReframeOutput = z.object({
  video: zSchemaVideoFile,
})

/**
 * LongWanVACEReframeRequest
 */
export const zSchemaWanVaceAppsLongReframeInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'The text prompt to guide video generation. Optional for reframing.',
      }),
    )
    .default(''),
  video_url: z.string().register(z.globalRegistry, {
    description:
      'URL to the source video file. This video will be used as a reference for the reframe task.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'low', 'regular']).register(z.globalRegistry, {
      description:
        "Acceleration to use for inference. Options are 'none' or 'regular'. Accelerated inference will very slightly affect output, but will be significantly faster.",
    }),
  ),
  paste_back: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to paste back the reframed scene to the original video.',
      }),
    )
    .default(true),
  zoom_factor: z
    .optional(
      z.number().gte(0).lte(0.9).register(z.globalRegistry, {
        description:
          'Zoom factor for the video. When this value is greater than 0, the video will be zoomed in by this factor (in relation to the canvas size,) cutting off the edges of the video. A value of 0 means no zoom.',
      }),
    )
    .default(0),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  scene_threshold: z
    .optional(
      z.number().gte(0).lte(100).register(z.globalRegistry, {
        description:
          'Threshold for scene detection sensitivity (0-100). Lower values detect more scenes.',
      }),
    )
    .default(30),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.',
      }),
    )
    .default(5),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'Minimum FPS for auto downsample.',
      }),
    )
    .default(6),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'Sampler to use for video generation.',
    }),
  ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP file containing all generated frames.',
      }),
    )
    .default(false),
  trim_borders: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to trim borders from the video.',
      }),
    )
    .default(true),
  transparency_mode: z.optional(
    z.enum(['content_aware', 'white', 'black']).register(z.globalRegistry, {
      description:
        'The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.',
    }),
  ),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  interpolator_model: z.optional(
    z.enum(['rife', 'film']).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable auto downsample.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
})

/**
 * ImageFile
 */
export const zSchemaImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * RemixOutput
 */
export const zSchemaSora2VideoToVideoRemixOutput = z.object({
  spritesheet: z.optional(zSchemaImageFile),
  thumbnail: z.optional(zSchemaImageFile),
  video_id: z.string().register(z.globalRegistry, {
    description: 'The ID of the generated video',
  }),
  video: zSchemaVideoFile,
})

/**
 * RemixInput
 */
export const zSchemaSora2VideoToVideoRemixInput = z.object({
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: 'Updated text prompt that directs the remix generation',
  }),
  video_id: z.string().register(z.globalRegistry, {
    description:
      'The video_id from a previous Sora 2 generation. Note: You can only remix videos that were generated by Sora (via text-to-video or image-to-video endpoints), not arbitrary uploaded videos.',
  }),
  delete_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to delete the video after generation for privacy reasons. If True, the video cannot be used for remixing and will be permanently deleted.',
      }),
    )
    .default(true),
})

/**
 * VideoToVideoOutput
 */
export const zSchemaKreaWan14bVideoToVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * VideoToVideoInput
 */
export const zSchemaKreaWan14bVideoToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Prompt for the video-to-video generation.',
  }),
  video_url: z.string().register(z.globalRegistry, {
    description:
      'URL of the input video. Currently, only outputs of 16:9 aspect ratio and 480p resolution are supported. Video duration should be less than 1000 frames at 16fps, and output frames will be 6 plus a multiple of 12, for example 18, 30, 42, etc.',
  }),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'Denoising strength for the video-to-video generation. 0.0 preserves the original, 1.0 completely remakes the video.',
      }),
    )
    .default(0.85),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
})

/**
 * Video
 */
export const zSchemaVideoOutput = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * VideoOutput
 */
export const zSchemaSfxV15VideoToVideoOutput = z.object({
  video: z.array(zSchemaVideoOutput).register(z.globalRegistry, {
    description: 'The processed video with sound effects',
  }),
})

/**
 * Input
 */
export const zSchemaSfxV15VideoToVideoInput = z.object({
  num_samples: z.optional(z.union([z.int().gte(2).lte(8), z.unknown()])),
  duration: z.optional(z.union([z.number().gte(1).lte(10), z.unknown()])),
  start_offset: z.optional(z.union([z.number().gte(0), z.unknown()])),
  video_url: z.url().min(1).max(2083).register(z.globalRegistry, {
    description:
      'A video url that can accessed from the API to process and add sound effects',
  }),
  seed: z.optional(z.union([z.int().gte(1), z.unknown()])),
  text_prompt: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * Q2VideoExtensionOutput
 */
export const zSchemaViduQ2VideoExtensionProOutput = z.object({
  video: zSchemaFile,
})

/**
 * Q2VideoExtensionRequest
 */
export const zSchemaViduQ2VideoExtensionProInput = z.object({
  prompt: z.optional(
    z.string().max(3000).register(z.globalRegistry, {
      description: 'text prompt to guide the video extension',
    }),
  ),
  duration: z.optional(
    z
      .union([
        z.literal(2),
        z.literal(3),
        z.literal(4),
        z.literal(5),
        z.literal(6),
        z.literal(7),
      ])
      .register(z.globalRegistry, {
        description: 'Duration of the extension in seconds',
      }),
  ),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the video to extend',
  }),
  resolution: z.optional(
    z.enum(['720p', '1080p']).register(z.globalRegistry, {
      description: 'Output video resolution',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
})

/**
 * VideoOutput
 */
export const zSchemaBirefnetV2VideoOutput = z.object({
  video: zSchemaVideoFile,
  mask_video: z.optional(zSchemaVideoFile),
})

/**
 * VideoInputV2
 */
export const zSchemaBirefnetV2VideoInput = z.object({
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  operating_resolution: z.optional(
    z.enum(['1024x1024', '2048x2048', '2304x2304']).register(z.globalRegistry, {
      description:
        "The resolution to operate on. The higher the resolution, the more accurate the output will be for high res input images. The '2304x2304' option is only available for the 'General Use (Dynamic)' model.",
    }),
  ),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the video to remove background from',
  }),
  model: z.optional(
    z
      .enum([
        'General Use (Light)',
        'General Use (Light 2K)',
        'General Use (Heavy)',
        'Matting',
        'Portrait',
        'General Use (Dynamic)',
      ])
      .register(z.globalRegistry, {
        description:
          "\n            Model to use for background removal.\n            The 'General Use (Light)' model is the original model used in the BiRefNet repository.\n            The 'General Use (Light 2K)' model is the original model used in the BiRefNet repository but trained with 2K images.\n            The 'General Use (Heavy)' model is a slower but more accurate model.\n            The 'Matting' model is a model trained specifically for matting images.\n            The 'Portrait' model is a model trained specifically for portrait images.\n            The 'General Use (Dynamic)' model supports dynamic resolutions from 256x256 to 2304x2304.\n            The 'General Use (Light)' model is recommended for most use cases.\n\n            The corresponding models are as follows:\n            - 'General Use (Light)': BiRefNet\n            - 'General Use (Light 2K)': BiRefNet_lite-2K\n            - 'General Use (Heavy)': BiRefNet_lite\n            - 'Matting': BiRefNet-matting\n            - 'Portrait': BiRefNet-portrait\n            - 'General Use (Dynamic)': BiRefNet_dynamic\n        ",
      }),
  ),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  output_mask: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to output the mask used to remove the background',
      }),
    )
    .default(false),
  refine_foreground: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to refine the foreground using the estimated mask',
      }),
    )
    .default(true),
})

/**
 * VideoEffectOutput
 */
export const zSchemaVideoAsPromptOutput = z.object({
  video: zSchemaFile,
})

/**
 * VideoEffectInputWan
 */
export const zSchemaVideoAsPromptInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video.',
    }),
  ),
  video_url: z.string().register(z.globalRegistry, {
    description: 'reference video to generate effect video from.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Input image to generate the effect video for.',
  }),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description:
          "Frames per second for the output video. Only applicable if output_type is 'video'.",
      }),
    )
    .default(16),
  video_description: z.string().register(z.globalRegistry, {
    description: 'A brief description of the input video content.',
  }),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description: 'Guidance scale for generation.',
      }),
    )
    .default(5),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(1).lte(100).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(49),
})

/**
 * UpscaleOutput
 */
export const zSchemaBytedanceUpscalerUpscaleVideoOutput = z.object({
  duration: z.number().register(z.globalRegistry, {
    description: 'Duration of audio input/video output as used for billing.',
  }),
  video: zSchemaFile,
})

/**
 * UpscaleInput
 */
export const zSchemaBytedanceUpscalerUpscaleVideoInput = z.object({
  target_fps: z.optional(
    z.enum(['30fps', '60fps']).register(z.globalRegistry, {
      description: 'The target FPS of the video to upscale.',
    }),
  ),
  video_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the video to upscale.',
  }),
  target_resolution: z.optional(
    z.enum(['1080p', '2k', '4k']).register(z.globalRegistry, {
      description: 'The target resolution of the video to upscale.',
    }),
  ),
})

/**
 * AutoSubtitleOutput
 *
 * Output model for video with automatic subtitles
 */
export const zSchemaWorkflowUtilitiesAutoSubtitleOutput = z
  .object({
    transcription: z.string().register(z.globalRegistry, {
      description: 'Full transcription text',
    }),
    subtitle_count: z.int().register(z.globalRegistry, {
      description: 'Number of subtitle segments generated',
    }),
    transcription_metadata: z.optional(
      z.record(z.string(), z.unknown()).register(z.globalRegistry, {
        description:
          'Additional transcription metadata from ElevenLabs (language, segments, etc.)',
      }),
    ),
    words: z.optional(
      z.array(z.record(z.string(), z.unknown())).register(z.globalRegistry, {
        description: 'Word-level timing information from transcription service',
      }),
    ),
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output model for video with automatic subtitles',
  })

/**
 * AutoSubtitleInput
 *
 * Input model for automatic subtitle generation and styling
 */
export const zSchemaWorkflowUtilitiesAutoSubtitleInput = z
  .object({
    font_weight: z.optional(
      z.enum(['normal', 'bold', 'black']).register(z.globalRegistry, {
        description: 'Font weight (TikTok style typically uses bold or black)',
      }),
    ),
    video_url: z.string().register(z.globalRegistry, {
      description:
        'URL of the video file to add automatic subtitles to\n\nMax file size: 95.4MB, Timeout: 30.0s',
    }),
    stroke_width: z
      .optional(
        z.int().gte(0).lte(10).register(z.globalRegistry, {
          description: 'Text stroke/outline width in pixels (0 for no stroke)',
        }),
      )
      .default(3),
    font_color: z.optional(
      z
        .enum([
          'white',
          'black',
          'red',
          'green',
          'blue',
          'yellow',
          'orange',
          'purple',
          'pink',
          'brown',
          'gray',
          'cyan',
          'magenta',
        ])
        .register(z.globalRegistry, {
          description: 'Subtitle text color for non-active words',
        }),
    ),
    font_size: z
      .optional(
        z.int().gte(20).lte(150).register(z.globalRegistry, {
          description:
            'Font size for subtitles (TikTok style uses larger text)',
        }),
      )
      .default(100),
    language: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            "Language code for transcription (e.g., 'en', 'es', 'fr', 'de', 'it', 'pt', 'nl', 'ja', 'zh', 'ko') or 3-letter ISO code (e.g., 'eng', 'spa', 'fra')",
        }),
      )
      .default('en'),
    y_offset: z
      .optional(
        z.int().gte(-200).lte(200).register(z.globalRegistry, {
          description:
            'Vertical offset in pixels (positive = move down, negative = move up)',
        }),
      )
      .default(75),
    background_opacity: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            'Background opacity (0.0 = fully transparent, 1.0 = fully opaque)',
        }),
      )
      .default(0),
    stroke_color: z.optional(
      z
        .enum([
          'black',
          'white',
          'red',
          'green',
          'blue',
          'yellow',
          'orange',
          'purple',
          'pink',
          'brown',
          'gray',
          'cyan',
          'magenta',
        ])
        .register(z.globalRegistry, {
          description: 'Text stroke/outline color',
        }),
    ),
    highlight_color: z.optional(
      z
        .enum([
          'white',
          'black',
          'red',
          'green',
          'blue',
          'yellow',
          'orange',
          'purple',
          'pink',
          'brown',
          'gray',
          'cyan',
          'magenta',
        ])
        .register(z.globalRegistry, {
          description:
            'Color for the currently speaking word (karaoke-style highlight)',
        }),
    ),
    enable_animation: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Enable animation effects for subtitles (bounce style entrance)',
        }),
      )
      .default(true),
    font_name: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            "Any Google Font name from fonts.google.com (e.g., 'Montserrat', 'Poppins', 'BBH Sans Hegarty')",
        }),
      )
      .default('Montserrat'),
    position: z.optional(
      z.enum(['top', 'center', 'bottom']).register(z.globalRegistry, {
        description: 'Vertical position of subtitles',
      }),
    ),
    words_per_subtitle: z
      .optional(
        z.int().gte(1).lte(12).register(z.globalRegistry, {
          description:
            'Maximum number of words per subtitle segment. Use 1 for single-word display, 2-3 for short phrases, or 8-12 for full sentences.',
        }),
      )
      .default(3),
    background_color: z.optional(
      z
        .enum([
          'black',
          'white',
          'red',
          'green',
          'blue',
          'yellow',
          'orange',
          'purple',
          'pink',
          'brown',
          'gray',
          'cyan',
          'magenta',
          'none',
          'transparent',
        ])
        .register(z.globalRegistry, {
          description:
            "Background color behind text ('none' or 'transparent' for no background)",
        }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Input model for automatic subtitle generation and styling',
  })

/**
 * FlashVSRPlusVideoOutput
 */
export const zSchemaFlashvsrUpscaleVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: 'The random seed used for the generation process.',
  }),
  video: zSchemaFile,
})

/**
 * FlashVSRPlusVideoInput
 *
 * Input fields common to FlashVSR+ image/video endpoints.
 */
export const zSchemaFlashvsrUpscaleVideoInput = z
  .object({
    video_url: z.string().register(z.globalRegistry, {
      description: 'The input video to be upscaled',
    }),
    acceleration: z.optional(
      z.enum(['regular', 'high', 'full']).register(z.globalRegistry, {
        description:
          'Acceleration mode for VAE decoding. Options: regular (best quality), high (balanced), full (fastest). More accerleation means longer duration videos can be processed too.',
      }),
    ),
    quality: z
      .optional(
        z.int().gte(0).lte(100).register(z.globalRegistry, {
          description:
            'Quality level for tile blending (0-100). Controls overlap between tiles to prevent grid artifacts. Higher values provide better quality with more overlap. Recommended: 70-85 for high-res videos, 50-70 for faster processing.',
        }),
      )
      .default(70),
    output_format: z.optional(
      z
        .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
        .register(z.globalRegistry, {
          description: 'The format of the output video.',
        }),
    ),
    color_fix: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Color correction enabled.',
        }),
      )
      .default(true),
    output_write_mode: z.optional(
      z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
        description: 'The write mode of the output video.',
      }),
    ),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'If `True`, the media will be returned inline and not stored in history.',
        }),
      )
      .default(false),
    output_quality: z.optional(
      z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
        description: 'The quality of the output video.',
      }),
    ),
    upscale_factor: z
      .optional(
        z.number().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Upscaling factor to be used.',
        }),
      )
      .default(2),
    preserve_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Copy the original audio tracks into the upscaled video using FFmpeg when possible.',
        }),
      )
      .default(false),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The random seed used for the generation process.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Input fields common to FlashVSR+ image/video endpoints.',
  })

/**
 * EdittoOutput
 */
export const zSchemaEdittoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation.',
  }),
  frames_zip: z.optional(z.union([zSchemaFile, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  video: zSchemaVideoFile,
})

/**
 * EdittoInput
 */
export const zSchemaEdittoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL to the source video file. Required for inpainting.',
  }),
  acceleration: z.optional(
    z.union([z.enum(['none', 'low', 'regular']), z.unknown()]),
  ),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Number of frames to interpolate between the original frames. A value of 0 means no interpolation.',
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          'Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.',
      }),
    )
    .default(0),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: 'Shift parameter for video generation.',
      }),
    )
    .default(5),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.',
      }),
    )
    .default(5),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. Must be between 81 to 241 (inclusive).',
      }),
    )
    .default(81),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  sampler: z.optional(
    z.enum(['unipc', 'dpm++', 'euler']).register(z.globalRegistry, {
      description: 'Sampler to use for video generation.',
    }),
  ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  resolution: z.optional(
    z
      .enum(['auto', '240p', '360p', '480p', '580p', '720p'])
      .register(z.globalRegistry, {
        description: 'Resolution of the generated video.',
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(['auto', '16:9', '1:1', '9:16']).register(z.globalRegistry, {
      description: 'Aspect ratio of the generated video.',
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, also return a ZIP file containing all generated frames.',
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.',
      }),
    )
    .default(false),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.',
      }),
    )
    .default(false),
})

/**
 * PointPromptBase
 */
export const zSchemaPointPromptBase = z.object({
  y: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Y Coordinate of the prompt',
    }),
  ),
  x: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'X Coordinate of the prompt',
    }),
  ),
  object_id: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Optional object identifier. Prompts sharing an object id refine the same object.',
    }),
  ),
  label: z.optional(
    z.union([z.literal(0), z.literal(1)]).register(z.globalRegistry, {
      description: '1 for foreground, 0 for background',
    }),
  ),
})

/**
 * BoxPromptBase
 */
export const zSchemaBoxPromptBase = z.object({
  y_min: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Y Min Coordinate of the box',
    }),
  ),
  object_id: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Optional object identifier. Boxes sharing an object id refine the same object.',
    }),
  ),
  x_max: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'X Max Coordinate of the box',
    }),
  ),
  x_min: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'X Min Coordinate of the box',
    }),
  ),
  y_max: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Y Max Coordinate of the box',
    }),
  ),
})

/**
 * SAM3VideoOutput
 */
export const zSchemaSam3VideoOutput = z.object({
  boundingbox_frames_zip: z.optional(zSchemaFile),
  video: zSchemaFile,
})

/**
 * SAM3VideoInput
 */
export const zSchemaSam3VideoInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "Text prompt for segmentation. Use commas to track multiple objects (e.g., 'person, cloth').",
      }),
    )
    .default(''),
  video_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the video to be segmented.',
  }),
  detection_threshold: z
    .optional(
      z.number().gte(0.1).lte(1).register(z.globalRegistry, {
        description:
          'Detection confidence threshold (0.0-1.0). Lower = more detections but less precise. ',
      }),
    )
    .default(0.5),
  box_prompts: z
    .optional(
      z.array(zSchemaBoxPromptBase).register(z.globalRegistry, {
        description:
          'List of box prompt coordinates (x_min, y_min, x_max, y_max).',
      }),
    )
    .default([]),
  point_prompts: z
    .optional(
      z.array(zSchemaPointPromptBase).register(z.globalRegistry, {
        description: 'List of point prompts',
      }),
    )
    .default([]),
  apply_mask: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Apply the mask on the video.',
      }),
    )
    .default(true),
  text_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        "[DEPRECATED] Use 'prompt' instead. Kept for backward compatibility.",
    }),
  ),
})

/**
 * SAM3VideoOutput
 */
export const zSchemaSam3VideoRleOutput = z.object({
  boundingbox_frames_zip: z.optional(zSchemaFile),
  video: zSchemaFile,
})

/**
 * SAM3VideoRLEInput
 */
export const zSchemaSam3VideoRleInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "Text prompt for segmentation. Use commas to track multiple objects (e.g., 'person, cloth').",
      }),
    )
    .default(''),
  video_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the video to be segmented.',
  }),
  detection_threshold: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'Detection confidence threshold (0.0-1.0). Lower = more detections but less precise. Defaults: 0.5 for existing, 0.7 for new objects. Try 0.2-0.3 if text prompts fail.',
      }),
    )
    .default(0.5),
  box_prompts: z
    .optional(
      z.array(zSchemaBoxPrompt).register(z.globalRegistry, {
        description: 'List of box prompts with optional frame_index.',
      }),
    )
    .default([]),
  boundingbox_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Return per-frame bounding box overlays as a zip archive.',
      }),
    )
    .default(false),
  point_prompts: z
    .optional(
      z.array(zSchemaPointPrompt).register(z.globalRegistry, {
        description: 'List of point prompts with frame indices.',
      }),
    )
    .default([]),
  frame_index: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          'Frame index used for initial interaction when mask_url is provided.',
      }),
    )
    .default(0),
  mask_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The URL of the mask to be applied initially.',
    }),
  ),
  apply_mask: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Apply the mask on the video.',
      }),
    )
    .default(false),
})

/**
 * LucyEditFastOutput
 */
export const zSchemaLucyEditFastOutput = z.object({
  video: zSchemaFile,
})

/**
 * LucyEditFastInput
 */
export const zSchemaLucyEditFastInput = z.object({
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the video to be generated\n            and uploaded before returning the response. This will increase the\n            latency of the function but it allows you to get the video directly\n            in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the video to edit',
  }),
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text description of the desired video content',
  }),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enhance the prompt for better results.',
      }),
    )
    .default(true),
})

/**
 * LTXRetakeVideoResponse
 */
export const zSchemaLtx2RetakeVideoOutput = z.object({
  video: zSchemaVideoFile,
})

/**
 * LTXRetakeVideoRequest
 */
export const zSchemaLtx2RetakeVideoInput = z.object({
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: 'The prompt to retake the video with',
  }),
  duration: z
    .optional(
      z.number().gte(2).lte(20).register(z.globalRegistry, {
        description: 'The duration of the video to retake in seconds',
      }),
    )
    .default(5),
  video_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the video to retake',
  }),
  start_time: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description: 'The start time of the video to retake in seconds',
      }),
    )
    .default(0),
  retake_mode: z.optional(
    z
      .enum(['replace_audio', 'replace_video', 'replace_audio_and_video'])
      .register(z.globalRegistry, {
        description: 'The retake mode to use for the retake',
      }),
  ),
})

/**
 * GreenScreenRembgOutput
 */
export const zSchemaVideoBackgroundRemovalGreenScreenOutput = z.object({
  video: z.array(zSchemaFile),
})

/**
 * GreenScreenRembgInput
 */
export const zSchemaVideoBackgroundRemovalGreenScreenInput = z.object({
  video_url: z.url().min(1).max(2083),
  output_codec: z.optional(
    z.enum(['vp9', 'h264']).register(z.globalRegistry, {
      description:
        'Single VP9 video with alpha channel or two videos (rgb and alpha) in H264 format. H264 is recommended for better RGB quality.',
    }),
  ),
  spill_suppression_strength: z.optional(
    z.union([z.number().gte(0).lte(1), z.unknown()]),
  ),
})

/**
 * OmniV2VReferenceOutput
 */
export const zSchemaKlingVideoO1VideoToVideoReferenceOutput = z.object({
  video: zSchemaFile,
})

/**
 * OmniVideoElementInput
 */
export const zSchemaOmniVideoElementInput = z.object({
  reference_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        'Additional reference images from different angles. 1-4 images supported. At least one image is required.',
    }),
  ),
  frontal_image_url: z.string().register(z.globalRegistry, {
    description:
      'The frontal image of the element (main view).\n\nMax file size: 10.0MB, Min width: 300px, Min height: 300px, Min aspect ratio: 0.40, Max aspect ratio: 2.50, Timeout: 20.0s',
  }),
})

/**
 * OmniV2VReferenceInput
 *
 * Input for video editing or video-as-reference generation.
 */
export const zSchemaKlingVideoO1VideoToVideoReferenceInput = z
  .object({
    prompt: z.string().max(2500).register(z.globalRegistry, {
      description:
        'Use @Element1, @Element2 to reference elements and @Image1, @Image2 to reference images in order.',
    }),
    aspect_ratio: z.optional(
      z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
        description:
          "The aspect ratio of the generated video frame. If 'auto', the aspect ratio will be determined automatically based on the input video, and the closest aspect ratio to the input video will be used.",
      }),
    ),
    duration: z.optional(
      z
        .enum(['3', '4', '5', '6', '7', '8', '9', '10'])
        .register(z.globalRegistry, {
          description: 'Video duration in seconds.',
        }),
    ),
    video_url: z.string().register(z.globalRegistry, {
      description:
        'Reference video URL. Only .mp4/.mov formats supported, 3-10 seconds duration, 720-2160px resolution, max 200MB.\n\nMax file size: 200.0MB, Min width: 720px, Min height: 720px, Max width: 2160px, Max height: 2160px, Min duration: 3.0s, Max duration: 10.05s, Min FPS: 24.0, Max FPS: 60.0, Timeout: 30.0s',
    }),
    keep_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to keep the original audio from the video.',
        }),
      )
      .default(false),
    elements: z.optional(
      z.array(zSchemaOmniVideoElementInput).register(z.globalRegistry, {
        description:
          'Elements (characters/objects) to include. Reference in prompt as @Element1, @Element2, etc. Maximum 4 total (elements + reference images) when using video.',
      }),
    ),
    image_urls: z.optional(
      z.array(z.string()).register(z.globalRegistry, {
        description:
          'Reference images for style/appearance. Reference in prompt as @Image1, @Image2, etc. Maximum 4 total (elements + reference images) when using video.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Input for video editing or video-as-reference generation.',
  })

/**
 * OmniV2VEditOutput
 */
export const zSchemaKlingVideoO1VideoToVideoEditOutput = z.object({
  video: zSchemaFile,
})

/**
 * OmniV2VEditInput
 *
 * Input for video editing or video-as-reference generation.
 */
export const zSchemaKlingVideoO1VideoToVideoEditInput = z
  .object({
    prompt: z.string().max(2500).register(z.globalRegistry, {
      description:
        'Use @Element1, @Element2 to reference elements and @Image1, @Image2 to reference images in order.',
    }),
    video_url: z.string().register(z.globalRegistry, {
      description:
        'Reference video URL. Only .mp4/.mov formats supported, 3-10 seconds duration, 720-2160px resolution, max 200MB.\n\nMax file size: 200.0MB, Min width: 720px, Min height: 720px, Max width: 2160px, Max height: 2160px, Min duration: 3.0s, Max duration: 10.05s, Min FPS: 24.0, Max FPS: 60.0, Timeout: 30.0s',
    }),
    elements: z.optional(
      z.array(zSchemaOmniVideoElementInput).register(z.globalRegistry, {
        description:
          'Elements (characters/objects) to include. Reference in prompt as @Element1, @Element2, etc. Maximum 4 total (elements + reference images) when using video.',
      }),
    ),
    image_urls: z.optional(
      z.array(z.string()).register(z.globalRegistry, {
        description:
          'Reference images for style/appearance. Reference in prompt as @Image1, @Image2, etc. Maximum 4 total (elements + reference images) when using video.',
      }),
    ),
    keep_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to keep the original audio from the video.',
        }),
      )
      .default(false),
  })
  .register(z.globalRegistry, {
    description: 'Input for video editing or video-as-reference generation.',
  })

/**
 * FastGeneralRembgOutput
 */
export const zSchemaVideoBackgroundRemovalFastOutput = z.object({
  video: z.array(zSchemaFile),
})

/**
 * FastGeneralRembgInput
 */
export const zSchemaVideoBackgroundRemovalFastInput = z.object({
  video_url: z.url().min(1).max(2083),
  subject_is_person: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Set to False if the subject is not a person.',
      }),
    )
    .default(true),
  output_codec: z.optional(
    z.enum(['vp9', 'h264']).register(z.globalRegistry, {
      description:
        'Single VP9 video with alpha channel or two videos (rgb and alpha) in H264 format. H264 is recommended for better RGB quality.',
    }),
  ),
  refine_foreground_edges: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Improves the quality of the extracted object's edges.",
      }),
    )
    .default(true),
})

/**
 * React1Output
 */
export const zSchemaSyncLipsyncReact1Output = z.object({
  video: zSchemaVideoFile,
})

/**
 * React1Input
 */
export const zSchemaSyncLipsyncReact1Input = z.object({
  emotion: z
    .enum(['happy', 'angry', 'sad', 'neutral', 'disgusted', 'surprised'])
    .register(z.globalRegistry, {
      description:
        'Emotion prompt for the generation. Currently supports single-word emotions only.',
    }),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL to the input video. Must be **15 seconds or shorter**.',
  }),
  lipsync_mode: z.optional(
    z
      .enum(['cut_off', 'loop', 'bounce', 'silence', 'remap'])
      .register(z.globalRegistry, {
        description:
          'Lipsync mode when audio and video durations are out of sync.',
      }),
  ),
  audio_url: z.string().register(z.globalRegistry, {
    description: 'URL to the input audio. Must be **15 seconds or shorter**.',
  }),
  temperature: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Controls the expresiveness of the lipsync.',
      }),
    )
    .default(0.5),
  model_mode: z.optional(
    z.enum(['lips', 'face', 'head']).register(z.globalRegistry, {
      description:
        'Controls the edit region and movement scope for the model. Available options:\n- `lips`: Only lipsync using react-1 (minimal facial changes).\n- `face`: Lipsync + facial expressions without head movements.\n- `head`: Lipsync + facial expressions + natural talking head movements.',
    }),
  ),
})

/**
 * Output
 *
 * Output from Wan Vision Enhancer
 */
export const zSchemaWanVisionEnhancerOutput = z
  .object({
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed used for generation.',
    }),
    timings: z.record(z.string(), z.number()).register(z.globalRegistry, {
      description: 'The timings of the different steps in the workflow.',
    }),
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output from Wan Vision Enhancer',
  })

/**
 * Input
 *
 * Input parameters for Wan Vision Enhancer (Video-to-Video)
 */
export const zSchemaWanVisionEnhancerInput = z
  .object({
    prompt: z.optional(z.union([z.string(), z.unknown()])),
    video_url: z.string().register(z.globalRegistry, {
      description:
        'The URL of the video to enhance with Wan Video. Maximum 200MB file size. Videos longer than 500 frames will have only the first 500 frames processed (~8-21 seconds depending on fps).',
    }),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    target_resolution: z.optional(
      z.enum(['720p', '1080p']).register(z.globalRegistry, {
        description:
          'Target output resolution for the enhanced video. 720p (native, fast) or 1080p (upscaled, slower). Processing is always done at 720p, then upscaled if 1080p selected.',
      }),
    ),
    negative_prompt: z.optional(z.union([z.string(), z.unknown()])),
    creativity: z
      .optional(
        z.int().gte(0).lte(4).register(z.globalRegistry, {
          description:
            'Controls how much the model enhances/changes the video. 0 = Minimal change (preserves original), 1 = Subtle enhancement (default), 2 = Medium enhancement, 3 = Strong enhancement, 4 = Maximum enhancement.',
        }),
      )
      .default(1),
  })
  .register(z.globalRegistry, {
    description: 'Input parameters for Wan Vision Enhancer (Video-to-Video)',
  })

/**
 * OneToALLAnimationResponse
 */
export const zSchemaOneToAllAnimation14bOutput = z.object({
  video: zSchemaFile,
})

/**
 * OneToALLAnimationRequest
 */
export const zSchemaOneToAllAnimation14bInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'The resolution of the video to generate.',
    }),
  ),
  image_guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'The image guidance scale to use for the video generation.',
      }),
    )
    .default(2),
  pose_guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The pose guidance scale to use for the video generation.',
      }),
    )
    .default(1.5),
  video_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the video to use as a reference for the video generation.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the image to use as a reference for the video generation.',
  }),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(30).register(z.globalRegistry, {
        description:
          'The number of inference steps to use for the video generation.',
      }),
    )
    .default(30),
  negative_prompt: z.string().register(z.globalRegistry, {
    description: 'The negative prompt to generate the video from.',
  }),
})

/**
 * OneToALLAnimationResponse
 */
export const zSchemaOneToAllAnimation13bOutput = z.object({
  video: zSchemaFile,
})

/**
 * OneToALLAnimationRequest
 */
export const zSchemaOneToAllAnimation13bInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  resolution: z.optional(
    z.enum(['480p', '580p', '720p']).register(z.globalRegistry, {
      description: 'The resolution of the video to generate.',
    }),
  ),
  image_guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'The image guidance scale to use for the video generation.',
      }),
    )
    .default(2),
  pose_guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The pose guidance scale to use for the video generation.',
      }),
    )
    .default(1.5),
  video_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the video to use as a reference for the video generation.',
  }),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the image to use as a reference for the video generation.',
  }),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(30).register(z.globalRegistry, {
        description:
          'The number of inference steps to use for the video generation.',
      }),
    )
    .default(30),
  negative_prompt: z.string().register(z.globalRegistry, {
    description: 'The negative prompt to generate the video from.',
  }),
})

/**
 * SteadyDancerResponse
 *
 * Response model for SteadyDancer.
 */
export const zSchemaSteadyDancerOutput = z
  .object({
    num_frames: z.int().register(z.globalRegistry, {
      description:
        'The actual number of frames generated (aligned to 4k+1 pattern).',
    }),
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed used for generation.',
    }),
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Response model for SteadyDancer.',
  })

/**
 * SteadyDancerRequest
 *
 * Request model for SteadyDancer human animation.
 */
export const zSchemaSteadyDancerInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'Text prompt describing the desired animation.',
        }),
      )
      .default('A person dancing with smooth and natural movements.'),
    video_url: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            'URL of the driving pose video. The motion from this video will be transferred to the reference image.',
        }),
      )
      .default(
        'https://v3b.fal.media/files/b/0a84de68/jXDWywjhagRfR-GuZjoRs_video.mp4',
      ),
    acceleration: z.optional(
      z.enum(['light', 'moderate', 'aggressive']).register(z.globalRegistry, {
        description: 'Acceleration levels.',
      }),
    ),
    pose_guidance_scale: z
      .optional(
        z.number().gte(0.5).lte(3).register(z.globalRegistry, {
          description: 'Pose guidance scale for pose control strength.',
        }),
      )
      .default(1),
    shift: z
      .optional(
        z.number().gte(1).lte(10).register(z.globalRegistry, {
          description: 'Shift parameter for video generation.',
        }),
      )
      .default(5),
    pose_guidance_end: z
      .optional(
        z.number().gte(0.2).lte(1).register(z.globalRegistry, {
          description:
            'End ratio for pose guidance. Controls when pose guidance ends.',
        }),
      )
      .default(0.4),
    frames_per_second: z.optional(
      z.int().gte(5).lte(24).register(z.globalRegistry, {
        description:
          'Frames per second of the generated video. Must be between 5 to 24. If not specified, uses the FPS from the input video.',
      }),
    ),
    guidance_scale: z
      .optional(
        z.number().gte(1).lte(6).register(z.globalRegistry, {
          description: 'Classifier-free guidance scale for prompt adherence.',
        }),
      )
      .default(1),
    num_frames: z.optional(
      z.int().gte(5).lte(241).register(z.globalRegistry, {
        description:
          'Number of frames to generate. If not specified, uses the frame count from the input video (capped at 241). Will be adjusted to nearest valid value (must satisfy 4k+1 pattern).',
      }),
    ),
    use_turbo: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'If true, applies quality enhancement for faster generation with improved quality. When enabled, parameters are automatically optimized (num_inference_steps=6, guidance_scale=1.0) and uses the LightX2V distillation LoRA.',
        }),
      )
      .default(false),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'Negative prompt for video generation.',
        }),
      )
      .default(
        'blurred, distorted face, bad anatomy, extra limbs, poorly drawn hands, poorly drawn feet, disfigured, out of frame, duplicate, watermark, signature, text',
      ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'If set to true, the safety checker will be enabled.',
        }),
      )
      .default(false),
    aspect_ratio: z.optional(
      z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
        description:
          "Aspect ratio of the generated video. If 'auto', will be determined from the reference image.",
      }),
    ),
    pose_guidance_start: z
      .optional(
        z.number().gte(0).lte(0.5).register(z.globalRegistry, {
          description:
            'Start ratio for pose guidance. Controls when pose guidance begins.',
        }),
      )
      .default(0.1),
    resolution: z.optional(
      z.enum(['480p', '576p', '720p']).register(z.globalRegistry, {
        description:
          'Resolution of the generated video. 576p is default, 720p for higher quality. 480p is lower quality.',
      }),
    ),
    image_url: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            'URL of the reference image to animate. This is the person/character whose appearance will be preserved.',
        }),
      )
      .default(
        'https://v3b.fal.media/files/b/0a85edaa/GDUCMPrdvOMcI5JpEcU7f.png',
      ),
    preserve_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'If enabled, copies audio from the input driving video to the output video.',
        }),
      )
      .default(true),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    ),
    num_inference_steps: z
      .optional(
        z.int().gte(4).lte(50).register(z.globalRegistry, {
          description:
            'Number of inference steps for sampling. Higher values give better quality but take longer.',
        }),
      )
      .default(6),
  })
  .register(z.globalRegistry, {
    description: 'Request model for SteadyDancer human animation.',
  })

/**
 * OmniV2VEditOutput
 */
export const zSchemaKlingVideoO1StandardVideoToVideoEditOutput = z.object({
  video: zSchemaFile,
})

/**
 * OmniV2VEditInput
 *
 * Input for video editing or video-as-reference generation.
 */
export const zSchemaKlingVideoO1StandardVideoToVideoEditInput = z
  .object({
    prompt: z.string().max(2500).register(z.globalRegistry, {
      description:
        'Use @Element1, @Element2 to reference elements and @Image1, @Image2 to reference images in order.',
    }),
    video_url: z.string().register(z.globalRegistry, {
      description:
        'Reference video URL. Only .mp4/.mov formats supported, 3-10 seconds duration, 720-2160px resolution, max 200MB.\n\nMax file size: 200.0MB, Min width: 720px, Min height: 720px, Max width: 2160px, Max height: 2160px, Min duration: 3.0s, Max duration: 10.05s, Min FPS: 24.0, Max FPS: 60.0, Timeout: 30.0s',
    }),
    elements: z.optional(
      z.array(zSchemaOmniVideoElementInput).register(z.globalRegistry, {
        description:
          'Elements (characters/objects) to include. Reference in prompt as @Element1, @Element2, etc. Maximum 4 total (elements + reference images) when using video.',
      }),
    ),
    image_urls: z.optional(
      z.array(z.string()).register(z.globalRegistry, {
        description:
          'Reference images for style/appearance. Reference in prompt as @Image1, @Image2, etc. Maximum 4 total (elements + reference images) when using video.',
      }),
    ),
    keep_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to keep the original audio from the video.',
        }),
      )
      .default(false),
  })
  .register(z.globalRegistry, {
    description: 'Input for video editing or video-as-reference generation.',
  })

/**
 * OmniV2VReferenceOutput
 */
export const zSchemaKlingVideoO1StandardVideoToVideoReferenceOutput = z.object({
  video: zSchemaFile,
})

/**
 * OmniV2VReferenceInput
 *
 * Input for video editing or video-as-reference generation.
 */
export const zSchemaKlingVideoO1StandardVideoToVideoReferenceInput = z
  .object({
    prompt: z.string().max(2500).register(z.globalRegistry, {
      description:
        'Use @Element1, @Element2 to reference elements and @Image1, @Image2 to reference images in order.',
    }),
    aspect_ratio: z.optional(
      z.enum(['auto', '16:9', '9:16', '1:1']).register(z.globalRegistry, {
        description:
          "The aspect ratio of the generated video frame. If 'auto', the aspect ratio will be determined automatically based on the input video, and the closest aspect ratio to the input video will be used.",
      }),
    ),
    duration: z.optional(
      z
        .enum(['3', '4', '5', '6', '7', '8', '9', '10'])
        .register(z.globalRegistry, {
          description: 'Video duration in seconds.',
        }),
    ),
    video_url: z.string().register(z.globalRegistry, {
      description:
        'Reference video URL. Only .mp4/.mov formats supported, 3-10 seconds duration, 720-2160px resolution, max 200MB.\n\nMax file size: 200.0MB, Min width: 720px, Min height: 720px, Max width: 2160px, Max height: 2160px, Min duration: 3.0s, Max duration: 10.05s, Min FPS: 24.0, Max FPS: 60.0, Timeout: 30.0s',
    }),
    keep_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to keep the original audio from the video.',
        }),
      )
      .default(false),
    elements: z.optional(
      z.array(zSchemaOmniVideoElementInput).register(z.globalRegistry, {
        description:
          'Elements (characters/objects) to include. Reference in prompt as @Element1, @Element2, etc. Maximum 4 total (elements + reference images) when using video.',
      }),
    ),
    image_urls: z.optional(
      z.array(z.string()).register(z.globalRegistry, {
        description:
          'Reference images for style/appearance. Reference in prompt as @Image1, @Image2, etc. Maximum 4 total (elements + reference images) when using video.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Input for video editing or video-as-reference generation.',
  })

/**
 * Veo31VideoToVideoOutput
 */
export const zSchemaVeo31ExtendVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Veo31VideoToVideoInput
 *
 * Input for video extension/video-to-video generation.
 */
export const zSchemaVeo31ExtendVideoInput = z
  .object({
    prompt: z.string().max(20000).register(z.globalRegistry, {
      description:
        'The text prompt describing how the video should be extended',
    }),
    duration: z.optional(
      z.enum(['7s']).register(z.globalRegistry, {
        description: 'The duration of the generated video.',
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(['auto', '16:9', '9:16']).register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video.',
      }),
    ),
    generate_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to generate audio for the video.',
        }),
      )
      .default(true),
    auto_fix: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.',
        }),
      )
      .default(false),
    video_url: z.string().register(z.globalRegistry, {
      description:
        'URL of the video to extend. The video should be 720p or 1080p resolution in 16:9 or 9:16 aspect ratio.',
    }),
    resolution: z.optional(
      z.enum(['720p']).register(z.globalRegistry, {
        description: 'The resolution of the generated video.',
      }),
    ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the random number generator.',
      }),
    ),
    negative_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'A negative prompt to guide the video generation.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Input for video extension/video-to-video generation.',
  })

/**
 * Veo31VideoToVideoOutput
 */
export const zSchemaVeo31FastExtendVideoOutput = z.object({
  video: zSchemaFile,
})

/**
 * Veo31VideoToVideoInput
 *
 * Input for video extension/video-to-video generation.
 */
export const zSchemaVeo31FastExtendVideoInput = z
  .object({
    prompt: z.string().max(20000).register(z.globalRegistry, {
      description:
        'The text prompt describing how the video should be extended',
    }),
    duration: z.optional(
      z.enum(['7s']).register(z.globalRegistry, {
        description: 'The duration of the generated video.',
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(['auto', '16:9', '9:16']).register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video.',
      }),
    ),
    generate_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to generate audio for the video.',
        }),
      )
      .default(true),
    auto_fix: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.',
        }),
      )
      .default(false),
    video_url: z.string().register(z.globalRegistry, {
      description:
        'URL of the video to extend. The video should be 720p or 1080p resolution in 16:9 or 9:16 aspect ratio.',
    }),
    resolution: z.optional(
      z.enum(['720p']).register(z.globalRegistry, {
        description: 'The resolution of the generated video.',
      }),
    ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The seed for the random number generator.',
      }),
    ),
    negative_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'A negative prompt to guide the video generation.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Input for video extension/video-to-video generation.',
  })

/**
 * ReferenceToVideoOutput
 *
 * Output for reference-to-video generation
 */
export const zSchemaV26ReferenceToVideoOutput = z
  .object({
    actual_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The actual prompt used if prompt rewriting was enabled',
      }),
    ),
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed used for generation',
    }),
    video: zSchemaVideoFile,
  })
  .register(z.globalRegistry, {
    description: 'Output for reference-to-video generation',
  })

/**
 * ReferenceToVideoInput
 *
 * Input for Wan 2.6 reference-to-video generation (R2V)
 */
export const zSchemaV26ReferenceToVideoInput = z
  .object({
    prompt: z.string().min(1).register(z.globalRegistry, {
      description:
        "Use @Video1, @Video2, @Video3 to reference subjects from your videos. Works for people, animals, or objects. For multi-shot prompts: '[0-3s] Shot 1. [3-6s] Shot 2.' Max 800 characters.",
    }),
    resolution: z.optional(
      z.enum(['720p', '1080p']).register(z.globalRegistry, {
        description:
          'Video resolution tier. R2V only supports 720p and 1080p (no 480p).',
      }),
    ),
    video_urls: z.array(z.string()).register(z.globalRegistry, {
      description:
        "Reference videos for subject consistency (1-3 videos). Videos' FPS must be at least 16 FPS.Reference in prompt as @Video1, @Video2, @Video3. Works for people, animals, or objects.",
    }),
    aspect_ratio: z.optional(
      z.enum(['16:9', '9:16', '1:1', '4:3', '3:4']).register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video.',
      }),
    ),
    duration: z.optional(
      z.enum(['5', '10']).register(z.globalRegistry, {
        description:
          'Duration of the generated video in seconds. R2V supports only 5 or 10 seconds (no 15s).',
      }),
    ),
    enable_prompt_expansion: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable prompt rewriting using LLM.',
        }),
      )
      .default(true),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    ),
    multi_shots: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'When true (default), enables intelligent multi-shot segmentation for coherent narrative videos with multiple shots. When false, generates single continuous shot. Only active when enable_prompt_expansion is True.',
        }),
      )
      .default(true),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            'Negative prompt to describe content to avoid. Max 500 characters.',
        }),
      )
      .default(''),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'If set to true, the safety checker will be enabled.',
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description: 'Input for Wan 2.6 reference-to-video generation (R2V)',
  })

/**
 * VideoOutput
 */
export const zSchemaBriaVideoEraserErasePromptOutput = z.object({
  video: z.union([zSchemaVideo, zSchemaFile]),
})

/**
 * EraseByPromptInputModel
 */
export const zSchemaBriaVideoEraserErasePromptInput = z.object({
  preserve_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If true, audio will be preserved in the output video.',
      }),
    )
    .default(true),
  video_url: z.string().register(z.globalRegistry, {
    description:
      'Input video to erase object from. duration must be less than 5s.',
  }),
  prompt: z.string().register(z.globalRegistry, {
    description: 'Input prompt to detect object to erase',
  }),
  output_container_and_codec: z.optional(
    z
      .enum([
        'mp4_h265',
        'mp4_h264',
        'webm_vp9',
        'gif',
        'mov_h264',
        'mov_h265',
        'mov_proresks',
        'mkv_h264',
        'mkv_h265',
        'mkv_vp9',
        'mkv_mpeg4',
      ])
      .register(z.globalRegistry, {
        description:
          'Output container and codec. Options: mp4_h265, mp4_h264, webm_vp9, gif, mov_h264, mov_h265, mov_proresks, mkv_h264, mkv_h265, mkv_vp9, mkv_mpeg4.',
      }),
  ),
  auto_trim: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'auto trim the video, to working duration ( 5s )',
      }),
    )
    .default(true),
})

/**
 * VideoOutput
 */
export const zSchemaBriaVideoEraserEraseKeypointsOutput = z.object({
  video: z.union([zSchemaVideo, zSchemaFile]),
})

/**
 * EraseByKeyPointsInputModel
 */
export const zSchemaBriaVideoEraserEraseKeypointsInput = z.object({
  preserve_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If true, audio will be preserved in the output video.',
      }),
    )
    .default(true),
  video_url: z.string().register(z.globalRegistry, {
    description:
      'Input video to erase object from. duration must be less than 5s.',
  }),
  output_container_and_codec: z.optional(
    z
      .enum([
        'mp4_h265',
        'mp4_h264',
        'webm_vp9',
        'gif',
        'mov_h264',
        'mov_h265',
        'mov_proresks',
        'mkv_h264',
        'mkv_h265',
        'mkv_vp9',
        'mkv_mpeg4',
      ])
      .register(z.globalRegistry, {
        description:
          'Output container and codec. Options: mp4_h265, mp4_h264, webm_vp9, gif, mov_h264, mov_h265, mov_proresks, mkv_h264, mkv_h265, mkv_vp9, mkv_mpeg4.',
      }),
  ),
  keypoints: z.array(z.string()).register(z.globalRegistry, {
    description:
      "Input keypoints [x,y] to erase or keep from the video. Format like so: {'x':100, 'y':100, 'type':'positive/negative'}",
  }),
  auto_trim: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'auto trim the video, to working duration ( 5s )',
      }),
    )
    .default(true),
})

/**
 * VideoOutput
 */
export const zSchemaBriaVideoEraserEraseMaskOutput = z.object({
  video: z.union([zSchemaVideo, zSchemaFile]),
})

/**
 * EraseInputModel
 */
export const zSchemaBriaVideoEraserEraseMaskInput = z.object({
  preserve_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If true, audio will be preserved in the output video.',
      }),
    )
    .default(true),
  video_url: z.string().register(z.globalRegistry, {
    description:
      'Input video to erase object from. duration must be less than 5s.',
  }),
  output_container_and_codec: z.optional(
    z
      .enum([
        'mp4_h265',
        'mp4_h264',
        'webm_vp9',
        'gif',
        'mov_h264',
        'mov_h265',
        'mov_proresks',
        'mkv_h264',
        'mkv_h265',
        'mkv_vp9',
        'mkv_mpeg4',
      ])
      .register(z.globalRegistry, {
        description:
          'Output container and codec. Options: mp4_h265, mp4_h264, webm_vp9, gif, mov_h264, mov_h265, mov_proresks, mkv_h264, mkv_h265, mkv_vp9, mkv_mpeg4.',
      }),
  ),
  mask_video_url: z.string().register(z.globalRegistry, {
    description:
      'Input video to mask erase object from. duration must be less than 5s.',
  }),
  auto_trim: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'auto trim the video, to working duration ( 5s )',
      }),
    )
    .default(true),
})

/**
 * CrystalVideoUpscaleOutput
 */
export const zSchemaCrystalVideoUpscalerOutput = z.object({
  video: zSchemaVideoFile,
})

/**
 * CrystalVideoUpscaleInput
 */
export const zSchemaCrystalVideoUpscalerInput = z.object({
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL to the input video.',
  }),
  scale_factor: z
    .optional(
      z.number().gte(1).lte(200).register(z.globalRegistry, {
        description:
          'Scale factor. The scale factor must be chosen such that the upscaled video does not exceed 5K resolution.',
      }),
    )
    .default(2),
})

/**
 * ScailResponse
 */
export const zSchemaScailOutput = z.object({
  video: zSchemaFile,
})

/**
 * ScailRequest
 */
export const zSchemaScailInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to guide video generation.',
  }),
  video_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the video to use as a reference for the video generation.',
  }),
  resolution: z.optional(
    z.enum(['512p']).register(z.globalRegistry, {
      description:
        'Output resolution. Outputs 896x512 (landscape) or 512x896 (portrait) based on the input image aspect ratio.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(30).register(z.globalRegistry, {
        description:
          'The number of inference steps to use for the video generation.',
      }),
    )
    .default(28),
  multi_character: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Enable multi-character mode. Use when driving video has multiple people.',
      }),
    )
    .default(false),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the image to use as a reference for the video generation.',
  }),
})

/**
 * LucyRestyleOutput
 */
export const zSchemaLucyRestyleOutput = z.object({
  video: zSchemaFile,
})

/**
 * LucyRestyleInput
 */
export const zSchemaLucyRestyleInput = z.object({
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the video to be generated\n            and uploaded before returning the response. This will increase the\n            latency of the function but it allows you to get the video directly\n            in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  video_url: z.string().register(z.globalRegistry, {
    description: 'URL of the video to edit',
  }),
  resolution: z.optional(
    z.enum(['720p']).register(z.globalRegistry, {
      description: 'Resolution of the generated video',
    }),
  ),
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text description of the desired video content',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Seed for video generation',
    }),
  ),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enhance the prompt for better results.',
      }),
    )
    .default(true),
})

/**
 * MotionControlOutput
 *
 * Output model for motion control video generation.
 */
export const zSchemaKlingVideoV26ProMotionControlOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output model for motion control video generation.',
  })

/**
 * MotionControlRequest
 *
 * Request model for motion control video generation.
 */
export const zSchemaKlingVideoV26ProMotionControlInput = z
  .object({
    prompt: z.optional(z.string().max(2500)),
    video_url: z.string().register(z.globalRegistry, {
      description:
        "Reference video URL. The character actions in the generated video will be consistent with this reference video. Should contain a realistic style character with entire body or upper body visible, including head, without obstruction. Duration limit depends on character_orientation: 10s max for 'image', 30s max for 'video'.",
    }),
    character_orientation: z
      .enum(['image', 'video'])
      .register(z.globalRegistry, {
        description:
          "Controls whether the output character's orientation matches the reference image or video. 'video': orientation matches reference video - better for complex motions (max 30s). 'image': orientation matches reference image - better for following camera movements (max 10s).",
      }),
    keep_original_sound: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to keep the original sound from the reference video.',
        }),
      )
      .default(true),
    image_url: z.string().register(z.globalRegistry, {
      description:
        'Reference image URL. The characters, backgrounds, and other elements in the generated video are based on this reference image. Characters should have clear body proportions, avoid occlusion, and occupy more than 5% of the image area.',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Request model for motion control video generation.',
  })

/**
 * MotionControlOutput
 *
 * Output model for motion control video generation.
 */
export const zSchemaKlingVideoV26StandardMotionControlOutput = z
  .object({
    video: zSchemaFile,
  })
  .register(z.globalRegistry, {
    description: 'Output model for motion control video generation.',
  })

/**
 * MotionControlRequest
 *
 * Request model for motion control video generation.
 */
export const zSchemaKlingVideoV26StandardMotionControlInput = z
  .object({
    prompt: z.optional(z.string().max(2500)),
    video_url: z.string().register(z.globalRegistry, {
      description:
        "Reference video URL. The character actions in the generated video will be consistent with this reference video. Should contain a realistic style character with entire body or upper body visible, including head, without obstruction. Duration limit depends on character_orientation: 10s max for 'image', 30s max for 'video'.",
    }),
    character_orientation: z
      .enum(['image', 'video'])
      .register(z.globalRegistry, {
        description:
          "Controls whether the output character's orientation matches the reference image or video. 'video': orientation matches reference video - better for complex motions (max 30s). 'image': orientation matches reference image - better for following camera movements (max 10s).",
      }),
    keep_original_sound: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to keep the original sound from the reference video.',
        }),
      )
      .default(true),
    image_url: z.string().register(z.globalRegistry, {
      description:
        'Reference image URL. The characters, backgrounds, and other elements in the generated video are based on this reference image. Characters should have clear body proportions, avoid occlusion, and occupy more than 5% of the image area.',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Request model for motion control video generation.',
  })

/**
 * TrajectoryParameters
 *
 * Camera trajectory parameters for re-camera operations.
 *
 * Each list represents interpolation values across frames:
 * - theta: Horizontal rotation angles (degrees)
 * - phi: Vertical rotation angles (degrees)
 * - radius: Camera distance scaling factors
 */
export const zSchemaTrajectoryParameters = z
  .object({
    theta: z.array(z.number()).register(z.globalRegistry, {
      description: 'Horizontal rotation angles (degrees) for each keyframe.',
    }),
    radius: z.array(z.number()).register(z.globalRegistry, {
      description: 'Camera distance scaling factors for each keyframe.',
    }),
    phi: z.array(z.number()).register(z.globalRegistry, {
      description: 'Vertical rotation angles (degrees) for each keyframe.',
    }),
  })
  .register(z.globalRegistry, {
    description:
      'Camera trajectory parameters for re-camera operations.\n\nEach list represents interpolation values across frames:\n- theta: Horizontal rotation angles (degrees)\n- phi: Vertical rotation angles (degrees)\n- radius: Camera distance scaling factors',
  })

/**
 * LightXOutput
 */
export const zSchemaLightxRecameraOutput = z.object({
  viz_video: z.optional(zSchemaFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  input_video: z.optional(zSchemaFile),
  video: zSchemaFile,
})

/**
 * LightXRecameraRequest
 *
 * Re-camera-only request (minimal schema).
 */
export const zSchemaLightxRecameraInput = z
  .object({
    prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'Optional text prompt. If omitted, Light-X will auto-caption the video.',
      }),
    ),
    trajectory: z.optional(zSchemaTrajectoryParameters),
    video_url: z.string().register(z.globalRegistry, {
      description: 'URL of the input video.',
    }),
    camera: z.optional(
      z.enum(['traj', 'target']).register(z.globalRegistry, {
        description: 'Camera control mode.',
      }),
    ),
    target_pose: z.optional(
      z.array(z.number()).register(z.globalRegistry, {
        description:
          "Target camera pose [theta, phi, radius, x, y] (required when camera='target').",
      }),
    ),
    mode: z.optional(
      z
        .enum(['gradual', 'bullet', 'direct', 'dolly-zoom'])
        .register(z.globalRegistry, {
          description: 'Camera motion mode.',
        }),
    ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Re-camera-only request (minimal schema).',
  })

/**
 * RelightParameters
 *
 * Relighting parameters for video relighting operations.
 *
 * Used with relight_condition_type 'ic' (intrinsic conditioning).
 */
export const zSchemaRelightParameters = z
  .object({
    relight_prompt: z.string().register(z.globalRegistry, {
      description: 'Text prompt describing the desired lighting condition.',
    }),
    bg_source: z.optional(
      z.enum(['Left', 'Right', 'Top', 'Bottom']).register(z.globalRegistry, {
        description: 'Direction of the light source (used for IC-light).',
      }),
    ),
    use_sky_mask: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to use sky masking for outdoor scenes.',
        }),
      )
      .default(false),
    cfg: z
      .optional(
        z.number().gte(1).lte(10).register(z.globalRegistry, {
          description: 'Classifier-free guidance scale for relighting.',
        }),
      )
      .default(2),
  })
  .register(z.globalRegistry, {
    description:
      "Relighting parameters for video relighting operations.\n\nUsed with relight_condition_type 'ic' (intrinsic conditioning).",
  })

/**
 * LightXOutput
 */
export const zSchemaLightxRelightOutput = z.object({
  viz_video: z.optional(zSchemaFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
  input_video: z.optional(zSchemaFile),
  video: zSchemaFile,
})

/**
 * LightXRelightRequest
 *
 * Relighting-only request (minimal schema).
 */
export const zSchemaLightxRelightInput = z
  .object({
    prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'Optional text prompt. If omitted, Light-X will auto-caption the video.',
      }),
    ),
    video_url: z.string().register(z.globalRegistry, {
      description: 'URL of the input video.',
    }),
    relight_parameters: z.optional(zSchemaRelightParameters),
    ref_id: z
      .optional(
        z.int().gte(0).register(z.globalRegistry, {
          description:
            'Frame index to use as referencen to relight the video with reference.',
        }),
      )
      .default(0),
    relit_cond_img_url: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          "URL of conditioning image. Required for relight_condition_type='ref'/'hdr'. Also required for relight_condition_type='bg' (background image).",
      }),
    ),
    relit_cond_type: z.optional(
      z.enum(['ic', 'ref', 'hdr', 'bg']).register(z.globalRegistry, {
        description: 'Relight condition type.',
      }),
    ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Relighting-only request (minimal schema).',
  })

/**
 * VideoOutput
 */
export const zSchemaVideoEraseMaskOutput = z.object({
  video: z.union([zSchemaVideo, zSchemaFile]),
})

/**
 * EraseInputModel
 */
export const zSchemaVideoEraseMaskInput = z.object({
  preserve_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If true, audio will be preserved in the output video.',
      }),
    )
    .default(true),
  video_url: z.string().register(z.globalRegistry, {
    description:
      'Input video to erase object from. duration must be less than 5s.',
  }),
  output_container_and_codec: z.optional(
    z
      .enum([
        'mp4_h265',
        'mp4_h264',
        'webm_vp9',
        'gif',
        'mov_h264',
        'mov_h265',
        'mov_proresks',
        'mkv_h264',
        'mkv_h265',
        'mkv_vp9',
        'mkv_mpeg4',
      ])
      .register(z.globalRegistry, {
        description:
          'Output container and codec. Options: mp4_h265, mp4_h264, webm_vp9, gif, mov_h264, mov_h265, mov_proresks, mkv_h264, mkv_h265, mkv_vp9, mkv_mpeg4.',
      }),
  ),
  mask_video_url: z.string().register(z.globalRegistry, {
    description:
      'Input video to mask erase object from. duration must be less than 5s.',
  }),
  auto_trim: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'auto trim the video, to working duration ( 5s )',
      }),
    )
    .default(true),
})

/**
 * VideoOutput
 */
export const zSchemaVideoErasePromptOutput = z.object({
  video: z.union([zSchemaVideo, zSchemaFile]),
})

/**
 * EraseByPromptInputModel
 */
export const zSchemaVideoErasePromptInput = z.object({
  preserve_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If true, audio will be preserved in the output video.',
      }),
    )
    .default(true),
  video_url: z.string().register(z.globalRegistry, {
    description:
      'Input video to erase object from. duration must be less than 5s.',
  }),
  prompt: z.string().register(z.globalRegistry, {
    description: 'Input prompt to detect object to erase',
  }),
  output_container_and_codec: z.optional(
    z
      .enum([
        'mp4_h265',
        'mp4_h264',
        'webm_vp9',
        'gif',
        'mov_h264',
        'mov_h265',
        'mov_proresks',
        'mkv_h264',
        'mkv_h265',
        'mkv_vp9',
        'mkv_mpeg4',
      ])
      .register(z.globalRegistry, {
        description:
          'Output container and codec. Options: mp4_h265, mp4_h264, webm_vp9, gif, mov_h264, mov_h265, mov_proresks, mkv_h264, mkv_h265, mkv_vp9, mkv_mpeg4.',
      }),
  ),
  auto_trim: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'auto trim the video, to working duration ( 5s )',
      }),
    )
    .default(true),
})

/**
 * VideoOutput
 */
export const zSchemaVideoEraseKeypointsOutput = z.object({
  video: z.union([zSchemaVideo, zSchemaFile]),
})

/**
 * EraseByKeyPointsInputModel
 */
export const zSchemaVideoEraseKeypointsInput = z.object({
  preserve_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If true, audio will be preserved in the output video.',
      }),
    )
    .default(true),
  video_url: z.string().register(z.globalRegistry, {
    description:
      'Input video to erase object from. duration must be less than 5s.',
  }),
  output_container_and_codec: z.optional(
    z
      .enum([
        'mp4_h265',
        'mp4_h264',
        'webm_vp9',
        'gif',
        'mov_h264',
        'mov_h265',
        'mov_proresks',
        'mkv_h264',
        'mkv_h265',
        'mkv_vp9',
        'mkv_mpeg4',
      ])
      .register(z.globalRegistry, {
        description:
          'Output container and codec. Options: mp4_h265, mp4_h264, webm_vp9, gif, mov_h264, mov_h265, mov_proresks, mkv_h264, mkv_h265, mkv_vp9, mkv_mpeg4.',
      }),
  ),
  keypoints: z.array(z.string()).register(z.globalRegistry, {
    description:
      "Input keypoints [x,y] to erase or keep from the video. Format like so: {'x':100, 'y':100, 'type':'positive/negative'}",
  }),
  auto_trim: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'auto trim the video, to working duration ( 5s )',
      }),
    )
    .default(true),
})

/**
 * LTX2ExtendVideoOutput
 */
export const zSchemaLtx219bExtendVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2ExtendVideoInput
 *
 * extend_direction: ExtendDirection = Field(
 * description="Direction to extend the video. 'forward' extends from the end of the video, 'backward' extends from the beginning.",
 * default="forward",
 * ui={"important": True},
 * title="Extend Direction",
 * )
 */
export const zSchemaLtx219bExtendVideoInput = z
  .object({
    use_multiscale: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
        }),
      )
      .default(true),
    video_url: z.string().register(z.globalRegistry, {
      description: 'The URL of the video to extend.',
    }),
    acceleration: z.optional(
      z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
        description: 'The acceleration level to use.',
      }),
    ),
    generate_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to generate audio for the video.',
        }),
      )
      .default(true),
    prompt: z.string().register(z.globalRegistry, {
      description: 'The prompt to generate the video from.',
    }),
    fps: z
      .optional(
        z.number().gte(1).lte(60).register(z.globalRegistry, {
          description: 'The frames per second of the generated video.',
        }),
      )
      .default(25),
    camera_lora: z.optional(
      z
        .enum([
          'dolly_in',
          'dolly_out',
          'dolly_left',
          'dolly_right',
          'jib_up',
          'jib_down',
          'static',
          'none',
        ])
        .register(z.globalRegistry, {
          description:
            'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
        }),
    ),
    video_size: z.optional(
      z.union([
        zSchemaImageSize,
        z.enum([
          'auto',
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
      ]),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable the safety checker.',
        }),
      )
      .default(true),
    camera_lora_scale: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
        }),
      )
      .default(1),
    guidance_scale: z
      .optional(
        z.number().gte(1).lte(10).register(z.globalRegistry, {
          description: 'The guidance scale to use.',
        }),
      )
      .default(3),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: 'The negative prompt to generate the video from.',
        }),
      )
      .default(
        'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
      ),
    num_frames: z
      .optional(
        z.int().gte(9).lte(481).register(z.globalRegistry, {
          description: 'The number of frames to generate.',
        }),
      )
      .default(121),
    video_strength: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            'Video conditioning strength. Lower values represent more freedom given to the model to change the video content.',
        }),
      )
      .default(1),
    video_output_type: z.optional(
      z
        .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
        .register(z.globalRegistry, {
          description: 'The output type of the generated video.',
        }),
    ),
    video_write_mode: z.optional(
      z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
        description: 'The write mode of the generated video.',
      }),
    ),
    num_context_frames: z
      .optional(
        z.int().gte(0).lte(121).register(z.globalRegistry, {
          description:
            'The number of frames to use as context for the extension.',
        }),
      )
      .default(25),
    video_quality: z.optional(
      z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
        description: 'The quality of the generated video.',
      }),
    ),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        }),
      )
      .default(false),
    enable_prompt_expansion: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether to enable prompt expansion.',
        }),
      )
      .default(false),
    num_inference_steps: z
      .optional(
        z.int().gte(8).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to use.',
        }),
      )
      .default(40),
    audio_strength: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            'Audio conditioning strength. Lower values represent more freedom given to the model to change the audio content.',
        }),
      )
      .default(1),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    match_input_fps: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "When true, match the output FPS to the input video's FPS instead of using the default target FPS.",
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description:
      'extend_direction: ExtendDirection = Field(\n    description="Direction to extend the video. \'forward\' extends from the end of the video, \'backward\' extends from the beginning.",\n    default="forward",\n    ui={"important": True},\n    title="Extend Direction",\n)',
  })

/**
 * LTX2ExtendVideoOutput
 */
export const zSchemaLtx219bExtendVideoLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export const zSchemaLoRaInput = z
  .object({
    path: z.string().register(z.globalRegistry, {
      description: 'URL, HuggingFace repo ID (owner/repo) to lora weights.',
    }),
    scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description: 'Scale factor for LoRA application (0.0 to 4.0).',
        }),
      )
      .default(1),
    weight_name: z.optional(z.union([z.string(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'LoRA weight configuration.',
  })

/**
 * LTX2LoRAExtendVideoInput
 */
export const zSchemaLtx219bExtendVideoLoraInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  video_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the video to extend.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  loras: z.array(zSchemaLoRaInput).register(z.globalRegistry, {
    description: 'The LoRAs to use for the generation.',
  }),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use.',
      }),
    )
    .default(3),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  video_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Video conditioning strength. Lower values represent more freedom given to the model to change the video content.',
      }),
    )
    .default(1),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  num_context_frames: z
    .optional(
      z.int().gte(0).lte(121).register(z.globalRegistry, {
        description:
          'The number of frames to use as context for the extension.',
      }),
    )
    .default(25),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to use.',
      }),
    )
    .default(40),
  audio_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Audio conditioning strength. Lower values represent more freedom given to the model to change the audio content.',
      }),
    )
    .default(1),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  match_input_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When true, match the output FPS to the input video's FPS instead of using the default target FPS.",
      }),
    )
    .default(true),
})

/**
 * LTX2ExtendVideoOutput
 */
export const zSchemaLtx219bDistilledExtendVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2DistilledExtendVideoInput
 */
export const zSchemaLtx219bDistilledExtendVideoInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  video_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the video to extend.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  video_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Video conditioning strength. Lower values represent more freedom given to the model to change the video content.',
      }),
    )
    .default(1),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  num_context_frames: z
    .optional(
      z.int().gte(0).lte(121).register(z.globalRegistry, {
        description:
          'The number of frames to use as context for the extension.',
      }),
    )
    .default(25),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  audio_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Audio conditioning strength. Lower values represent more freedom given to the model to change the audio content.',
      }),
    )
    .default(1),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  match_input_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When true, match the output FPS to the input video's FPS instead of using the default target FPS.",
      }),
    )
    .default(true),
})

/**
 * LTX2ExtendVideoOutput
 */
export const zSchemaLtx219bDistilledExtendVideoLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2LoRADistilledExtendVideoInput
 */
export const zSchemaLtx219bDistilledExtendVideoLoraInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  video_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the video to extend.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  loras: z.array(zSchemaLoRaInput).register(z.globalRegistry, {
    description: 'The LoRAs to use for the generation.',
  }),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  video_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Video conditioning strength. Lower values represent more freedom given to the model to change the video content.',
      }),
    )
    .default(1),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  num_context_frames: z
    .optional(
      z.int().gte(0).lte(121).register(z.globalRegistry, {
        description:
          'The number of frames to use as context for the extension.',
      }),
    )
    .default(25),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  audio_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Audio conditioning strength. Lower values represent more freedom given to the model to change the audio content.',
      }),
    )
    .default(1),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  match_input_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When true, match the output FPS to the input video's FPS instead of using the default target FPS.",
      }),
    )
    .default(true),
})

/**
 * LTX2VideoToVideoOutput
 */
export const zSchemaLtx219bVideoToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2VideoToVideoInput
 */
export const zSchemaLtx219bVideoToVideoInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  video_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the video to generate the video from.',
  }),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  ic_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the IC-LoRA to use. This allows you to control the strength of the IC-LoRA.',
      }),
    )
    .default(1),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use.',
      }),
    )
    .default(3),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  video_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Video conditioning strength. Lower values represent more freedom given to the model to change the video content.',
      }),
    )
    .default(1),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  image_url: z.optional(z.union([z.string(), z.unknown()])),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  match_video_length: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'When enabled, the number of frames will be calculated based on the video duration and FPS. When disabled, use the specified num_frames.',
      }),
    )
    .default(true),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the image to use for the video generation.',
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  preprocessor: z.optional(
    z.enum(['depth', 'canny', 'pose', 'none']).register(z.globalRegistry, {
      description:
        'The preprocessor to use for the video. When a preprocessor is used and `ic_lora_type` is set to `match_preprocessor`, the IC-LoRA will be loaded based on the preprocessor type.',
    }),
  ),
  ic_lora: z.optional(
    z
      .enum([
        'match_preprocessor',
        'canny',
        'depth',
        'pose',
        'detailer',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The type of IC-LoRA to load. In-Context LoRA weights are used to condition the video based on edge, depth, or pose videos. Only change this from `match_preprocessor` if your videos are already preprocessed (or you are using the detailer.)',
      }),
  ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to use.',
      }),
    )
    .default(40),
  match_input_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When true, match the output FPS to the input video's FPS instead of using the default target FPS.",
      }),
    )
    .default(true),
})

/**
 * LTX2VideoToVideoOutput
 */
export const zSchemaLtx219bVideoToVideoLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2LoRAVideoToVideoInput
 */
export const zSchemaLtx219bVideoToVideoLoraInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  video_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the video to generate the video from.',
  }),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  ic_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the IC-LoRA to use. This allows you to control the strength of the IC-LoRA.',
      }),
    )
    .default(1),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  loras: z.array(zSchemaLoRaInput).register(z.globalRegistry, {
    description: 'The LoRAs to use for the generation.',
  }),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use.',
      }),
    )
    .default(3),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  video_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Video conditioning strength. Lower values represent more freedom given to the model to change the video content.',
      }),
    )
    .default(1),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  image_url: z.optional(z.union([z.string(), z.unknown()])),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  match_video_length: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'When enabled, the number of frames will be calculated based on the video duration and FPS. When disabled, use the specified num_frames.',
      }),
    )
    .default(true),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the image to use for the video generation.',
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  preprocessor: z.optional(
    z.enum(['depth', 'canny', 'pose', 'none']).register(z.globalRegistry, {
      description:
        'The preprocessor to use for the video. When a preprocessor is used and `ic_lora_type` is set to `match_preprocessor`, the IC-LoRA will be loaded based on the preprocessor type.',
    }),
  ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  ic_lora: z.optional(
    z
      .enum([
        'match_preprocessor',
        'canny',
        'depth',
        'pose',
        'detailer',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The type of IC-LoRA to load. In-Context LoRA weights are used to condition the video based on edge, depth, or pose videos. Only change this from `match_preprocessor` if your videos are already preprocessed (or you are using the detailer.)',
      }),
  ),
  match_input_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When true, match the output FPS to the input video's FPS instead of using the default target FPS.",
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to use.',
      }),
    )
    .default(40),
})

/**
 * LTX2VideoToVideoOutput
 */
export const zSchemaLtx219bDistilledVideoToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2DistilledVideoToVideoInput
 */
export const zSchemaLtx219bDistilledVideoToVideoInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  video_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the video to generate the video from.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  ic_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the IC-LoRA to use. This allows you to control the strength of the IC-LoRA.',
      }),
    )
    .default(1),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the image to use for the video generation.',
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  preprocessor: z.optional(
    z.enum(['depth', 'canny', 'pose', 'none']).register(z.globalRegistry, {
      description:
        'The preprocessor to use for the video. When a preprocessor is used and `ic_lora_type` is set to `match_preprocessor`, the IC-LoRA will be loaded based on the preprocessor type.',
    }),
  ),
  video_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Video conditioning strength. Lower values represent more freedom given to the model to change the video content.',
      }),
    )
    .default(1),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  ic_lora: z.optional(
    z
      .enum([
        'match_preprocessor',
        'canny',
        'depth',
        'pose',
        'detailer',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The type of IC-LoRA to load. In-Context LoRA weights are used to condition the video based on edge, depth, or pose videos. Only change this from `match_preprocessor` if your videos are already preprocessed (or you are using the detailer.)',
      }),
  ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  image_url: z.optional(z.union([z.string(), z.unknown()])),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  match_input_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When true, match the output FPS to the input video's FPS instead of using the default target FPS.",
      }),
    )
    .default(true),
  match_video_length: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'When enabled, the number of frames will be calculated based on the video duration and FPS. When disabled, use the specified num_frames.',
      }),
    )
    .default(true),
})

/**
 * LTX2VideoToVideoOutput
 */
export const zSchemaLtx219bDistilledVideoToVideoLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for the generation.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the random number generator.',
  }),
  video: zSchemaVideoFile,
})

/**
 * LTX2LoRADistilledVideoToVideoInput
 */
export const zSchemaLtx219bDistilledVideoToVideoLoraInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.',
      }),
    )
    .default(true),
  video_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the video to generate the video from.',
  }),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high', 'full']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to generate audio for the video.',
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the video from.',
  }),
  ic_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the IC-LoRA to use. This allows you to control the strength of the IC-LoRA.',
      }),
    )
    .default(1),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: 'The frames per second of the generated video.',
      }),
    )
    .default(25),
  loras: z.array(zSchemaLoRaInput).register(z.globalRegistry, {
    description: 'The LoRAs to use for the generation.',
  }),
  camera_lora: z.optional(
    z
      .enum([
        'dolly_in',
        'dolly_out',
        'dolly_left',
        'dolly_right',
        'jib_up',
        'jib_down',
        'static',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
  ),
  video_size: z.optional(
    z.union([
      zSchemaImageSize,
      z.enum([
        'auto',
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.',
      }),
    )
    .default(1),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The strength of the image to use for the video generation.',
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the video from.',
      }),
    )
    .default(
      'blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.',
    ),
  preprocessor: z.optional(
    z.enum(['depth', 'canny', 'pose', 'none']).register(z.globalRegistry, {
      description:
        'The preprocessor to use for the video. When a preprocessor is used and `ic_lora_type` is set to `match_preprocessor`, the IC-LoRA will be loaded based on the preprocessor type.',
    }),
  ),
  video_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'Video conditioning strength. Lower values represent more freedom given to the model to change the video content.',
      }),
    )
    .default(1),
  video_output_type: z.optional(
    z
      .enum(['X264 (.mp4)', 'VP9 (.webm)', 'PRORES4444 (.mov)', 'GIF (.gif)'])
      .register(z.globalRegistry, {
        description: 'The output type of the generated video.',
      }),
  ),
  ic_lora: z.optional(
    z
      .enum([
        'match_preprocessor',
        'canny',
        'depth',
        'pose',
        'detailer',
        'none',
      ])
      .register(z.globalRegistry, {
        description:
          'The type of IC-LoRA to load. In-Context LoRA weights are used to condition the video based on edge, depth, or pose videos. Only change this from `match_preprocessor` if your videos are already preprocessed (or you are using the detailer.)',
      }),
  ),
  video_write_mode: z.optional(
    z.enum(['fast', 'balanced', 'small']).register(z.globalRegistry, {
      description: 'The write mode of the generated video.',
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: 'The number of frames to generate.',
      }),
    )
    .default(121),
  image_url: z.optional(z.union([z.string(), z.unknown()])),
  video_quality: z.optional(
    z.enum(['low', 'medium', 'high', 'maximum']).register(z.globalRegistry, {
      description: 'The quality of the generated video.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  match_input_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When true, match the output FPS to the input video's FPS instead of using the default target FPS.",
      }),
    )
    .default(true),
  match_video_length: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'When enabled, the number of frames will be calculated based on the video duration and FPS. When disabled, use the specified num_frames.',
      }),
    )
    .default(true),
})

/**
 * FaceFusionVideoOutput
 *
 * FaceFusion output payload when video content is generated
 */
export const zSchemaAiFaceSwapFaceswapvideoOutput = z
  .object({
    processing_time_ms: z.optional(z.union([z.int(), z.unknown()])),
    video: zSchemaVideo,
  })
  .register(z.globalRegistry, {
    description: 'FaceFusion output payload when video content is generated',
  })

/**
 * FaceSwapInputVideo
 *
 * Input schema for image  video face swap
 */
export const zSchemaAiFaceSwapFaceswapvideoInput = z
  .object({
    source_face_url: z.string().register(z.globalRegistry, {
      description: 'Source face image',
    }),
    target_video_url: z.string().register(z.globalRegistry, {
      description: 'Target video URL',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Input schema for image  video face swap',
  })

/**
 * Output
 */
export const zSchemaMmaudioV2Output = z.object({
  video: zSchemaFile,
})

/**
 * BaseInput
 */
export const zSchemaMmaudioV2Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the audio for.',
  }),
  video_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the video to generate the audio for.',
  }),
  num_steps: z
    .optional(
      z.int().gte(4).lte(50).register(z.globalRegistry, {
        description: 'The number of steps to generate the audio for.',
      }),
    )
    .default(25),
  duration: z
    .optional(
      z.number().gte(1).lte(30).register(z.globalRegistry, {
        description: 'The duration of the audio to generate.',
      }),
    )
    .default(8),
  cfg_strength: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description: 'The strength of Classifier Free Guidance.',
      }),
    )
    .default(4.5),
  seed: z.optional(
    z.int().gte(0).lte(65535).register(z.globalRegistry, {
      description: 'The seed for the random number generator',
    }),
  ),
  mask_away_clip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to mask away the clip.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate the audio for.',
      }),
    )
    .default(''),
})

/**
 * GeneralRembgOutput
 */
export const zSchemaVideoBackgroundRemovalOutput = z.object({
  video: z.array(zSchemaFile),
})

/**
 * GeneralRembgInput
 */
export const zSchemaVideoBackgroundRemovalInput = z.object({
  video_url: z.url().min(1).max(2083),
  subject_is_person: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Set to False if the subject is not a person.',
      }),
    )
    .default(true),
  output_codec: z.optional(
    z.enum(['vp9', 'h264']).register(z.globalRegistry, {
      description:
        'Single VP9 video with alpha channel or two videos (rgb and alpha) in H264 format. H264 is recommended for better RGB quality.',
    }),
  ),
  refine_foreground_edges: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Improves the quality of the extracted object's edges.",
      }),
    )
    .default(true),
})

export const zSchemaQueueStatus = z.object({
  status: z.enum(['IN_QUEUE', 'IN_PROGRESS', 'COMPLETED']),
  request_id: z.string().register(z.globalRegistry, {
    description: 'The request id.',
  }),
  response_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The response url.',
    }),
  ),
  status_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The status url.',
    }),
  ),
  cancel_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The cancel url.',
    }),
  ),
  logs: z.optional(
    z.record(z.string(), z.unknown()).register(z.globalRegistry, {
      description: 'The logs.',
    }),
  ),
  metrics: z.optional(
    z.record(z.string(), z.unknown()).register(z.globalRegistry, {
      description: 'The metrics.',
    }),
  ),
  queue_position: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The queue position.',
    }),
  ),
})

export const zGetBriaVideoBackgroundRemovalRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetBriaVideoBackgroundRemovalRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutBriaVideoBackgroundRemovalRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutBriaVideoBackgroundRemovalRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostBriaVideoBackgroundRemovalData = z.object({
  body: zSchemaVideoBackgroundRemovalInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostBriaVideoBackgroundRemovalResponse = zSchemaQueueStatus

export const zGetBriaVideoBackgroundRemovalRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetBriaVideoBackgroundRemovalRequestsByRequestIdResponse =
  zSchemaVideoBackgroundRemovalOutput

export const zGetFalAiMmaudioV2RequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiMmaudioV2RequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMmaudioV2RequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiMmaudioV2RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiMmaudioV2Data = z.object({
  body: zSchemaMmaudioV2Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMmaudioV2Response = zSchemaQueueStatus

export const zGetFalAiMmaudioV2RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiMmaudioV2RequestsByRequestIdResponse =
  zSchemaMmaudioV2Output

export const zGetHalfMoonAiAiFaceSwapFaceswapvideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetHalfMoonAiAiFaceSwapFaceswapvideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutHalfMoonAiAiFaceSwapFaceswapvideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutHalfMoonAiAiFaceSwapFaceswapvideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostHalfMoonAiAiFaceSwapFaceswapvideoData = z.object({
  body: zSchemaAiFaceSwapFaceswapvideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostHalfMoonAiAiFaceSwapFaceswapvideoResponse = zSchemaQueueStatus

export const zGetHalfMoonAiAiFaceSwapFaceswapvideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetHalfMoonAiAiFaceSwapFaceswapvideoRequestsByRequestIdResponse =
  zSchemaAiFaceSwapFaceswapvideoOutput

export const zGetFalAiLtx219bDistilledVideoToVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bDistilledVideoToVideoLoraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bDistilledVideoToVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bDistilledVideoToVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtx219bDistilledVideoToVideoLoraData = z.object({
  body: zSchemaLtx219bDistilledVideoToVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bDistilledVideoToVideoLoraResponse =
  zSchemaQueueStatus

export const zGetFalAiLtx219bDistilledVideoToVideoLoraRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bDistilledVideoToVideoLoraRequestsByRequestIdResponse =
  zSchemaLtx219bDistilledVideoToVideoLoraOutput

export const zGetFalAiLtx219bDistilledVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bDistilledVideoToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bDistilledVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bDistilledVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtx219bDistilledVideoToVideoData = z.object({
  body: zSchemaLtx219bDistilledVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bDistilledVideoToVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtx219bDistilledVideoToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bDistilledVideoToVideoRequestsByRequestIdResponse =
  zSchemaLtx219bDistilledVideoToVideoOutput

export const zGetFalAiLtx219bVideoToVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bVideoToVideoLoraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bVideoToVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bVideoToVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtx219bVideoToVideoLoraData = z.object({
  body: zSchemaLtx219bVideoToVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bVideoToVideoLoraResponse = zSchemaQueueStatus

export const zGetFalAiLtx219bVideoToVideoLoraRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bVideoToVideoLoraRequestsByRequestIdResponse =
  zSchemaLtx219bVideoToVideoLoraOutput

export const zGetFalAiLtx219bVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bVideoToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bVideoToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtx219bVideoToVideoData = z.object({
  body: zSchemaLtx219bVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bVideoToVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtx219bVideoToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bVideoToVideoRequestsByRequestIdResponse =
  zSchemaLtx219bVideoToVideoOutput

export const zGetFalAiLtx219bDistilledExtendVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bDistilledExtendVideoLoraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bDistilledExtendVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bDistilledExtendVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtx219bDistilledExtendVideoLoraData = z.object({
  body: zSchemaLtx219bDistilledExtendVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bDistilledExtendVideoLoraResponse =
  zSchemaQueueStatus

export const zGetFalAiLtx219bDistilledExtendVideoLoraRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bDistilledExtendVideoLoraRequestsByRequestIdResponse =
  zSchemaLtx219bDistilledExtendVideoLoraOutput

export const zGetFalAiLtx219bDistilledExtendVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bDistilledExtendVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bDistilledExtendVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bDistilledExtendVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtx219bDistilledExtendVideoData = z.object({
  body: zSchemaLtx219bDistilledExtendVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bDistilledExtendVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtx219bDistilledExtendVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bDistilledExtendVideoRequestsByRequestIdResponse =
  zSchemaLtx219bDistilledExtendVideoOutput

export const zGetFalAiLtx219bExtendVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bExtendVideoLoraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bExtendVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bExtendVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtx219bExtendVideoLoraData = z.object({
  body: zSchemaLtx219bExtendVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bExtendVideoLoraResponse = zSchemaQueueStatus

export const zGetFalAiLtx219bExtendVideoLoraRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bExtendVideoLoraRequestsByRequestIdResponse =
  zSchemaLtx219bExtendVideoLoraOutput

export const zGetFalAiLtx219bExtendVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtx219bExtendVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx219bExtendVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bExtendVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtx219bExtendVideoData = z.object({
  body: zSchemaLtx219bExtendVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx219bExtendVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtx219bExtendVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bExtendVideoRequestsByRequestIdResponse =
  zSchemaLtx219bExtendVideoOutput

export const zGetBriaVideoEraseKeypointsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetBriaVideoEraseKeypointsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutBriaVideoEraseKeypointsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutBriaVideoEraseKeypointsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostBriaVideoEraseKeypointsData = z.object({
  body: zSchemaVideoEraseKeypointsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostBriaVideoEraseKeypointsResponse = zSchemaQueueStatus

export const zGetBriaVideoEraseKeypointsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetBriaVideoEraseKeypointsRequestsByRequestIdResponse =
  zSchemaVideoEraseKeypointsOutput

export const zGetBriaVideoErasePromptRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetBriaVideoErasePromptRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutBriaVideoErasePromptRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutBriaVideoErasePromptRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostBriaVideoErasePromptData = z.object({
  body: zSchemaVideoErasePromptInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostBriaVideoErasePromptResponse = zSchemaQueueStatus

export const zGetBriaVideoErasePromptRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetBriaVideoErasePromptRequestsByRequestIdResponse =
  zSchemaVideoErasePromptOutput

export const zGetBriaVideoEraseMaskRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetBriaVideoEraseMaskRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutBriaVideoEraseMaskRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutBriaVideoEraseMaskRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostBriaVideoEraseMaskData = z.object({
  body: zSchemaVideoEraseMaskInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostBriaVideoEraseMaskResponse = zSchemaQueueStatus

export const zGetBriaVideoEraseMaskRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetBriaVideoEraseMaskRequestsByRequestIdResponse =
  zSchemaVideoEraseMaskOutput

export const zGetFalAiLightxRelightRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiLightxRelightRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLightxRelightRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiLightxRelightRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLightxRelightData = z.object({
  body: zSchemaLightxRelightInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLightxRelightResponse = zSchemaQueueStatus

export const zGetFalAiLightxRelightRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLightxRelightRequestsByRequestIdResponse =
  zSchemaLightxRelightOutput

export const zGetFalAiLightxRecameraRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiLightxRecameraRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLightxRecameraRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiLightxRecameraRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLightxRecameraData = z.object({
  body: zSchemaLightxRecameraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLightxRecameraResponse = zSchemaQueueStatus

export const zGetFalAiLightxRecameraRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLightxRecameraRequestsByRequestIdResponse =
  zSchemaLightxRecameraOutput

export const zGetFalAiKlingVideoV26StandardMotionControlRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV26StandardMotionControlRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV26StandardMotionControlRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV26StandardMotionControlRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV26StandardMotionControlData = z.object({
  body: zSchemaKlingVideoV26StandardMotionControlInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV26StandardMotionControlResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoV26StandardMotionControlRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV26StandardMotionControlRequestsByRequestIdResponse =
  zSchemaKlingVideoV26StandardMotionControlOutput

export const zGetFalAiKlingVideoV26ProMotionControlRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV26ProMotionControlRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoV26ProMotionControlRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV26ProMotionControlRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoV26ProMotionControlData = z.object({
  body: zSchemaKlingVideoV26ProMotionControlInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV26ProMotionControlResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoV26ProMotionControlRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV26ProMotionControlRequestsByRequestIdResponse =
  zSchemaKlingVideoV26ProMotionControlOutput

export const zGetDecartLucyRestyleRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetDecartLucyRestyleRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutDecartLucyRestyleRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutDecartLucyRestyleRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostDecartLucyRestyleData = z.object({
  body: zSchemaLucyRestyleInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostDecartLucyRestyleResponse = zSchemaQueueStatus

export const zGetDecartLucyRestyleRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetDecartLucyRestyleRequestsByRequestIdResponse =
  zSchemaLucyRestyleOutput

export const zGetFalAiScailRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiScailRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiScailRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiScailRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiScailData = z.object({
  body: zSchemaScailInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiScailResponse = zSchemaQueueStatus

export const zGetFalAiScailRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiScailRequestsByRequestIdResponse = zSchemaScailOutput

export const zGetClarityaiCrystalVideoUpscalerRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetClarityaiCrystalVideoUpscalerRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutClarityaiCrystalVideoUpscalerRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutClarityaiCrystalVideoUpscalerRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostClarityaiCrystalVideoUpscalerData = z.object({
  body: zSchemaCrystalVideoUpscalerInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostClarityaiCrystalVideoUpscalerResponse = zSchemaQueueStatus

export const zGetClarityaiCrystalVideoUpscalerRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetClarityaiCrystalVideoUpscalerRequestsByRequestIdResponse =
  zSchemaCrystalVideoUpscalerOutput

export const zGetBriaBriaVideoEraserEraseMaskRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetBriaBriaVideoEraserEraseMaskRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutBriaBriaVideoEraserEraseMaskRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutBriaBriaVideoEraserEraseMaskRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostBriaBriaVideoEraserEraseMaskData = z.object({
  body: zSchemaBriaVideoEraserEraseMaskInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostBriaBriaVideoEraserEraseMaskResponse = zSchemaQueueStatus

export const zGetBriaBriaVideoEraserEraseMaskRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetBriaBriaVideoEraserEraseMaskRequestsByRequestIdResponse =
  zSchemaBriaVideoEraserEraseMaskOutput

export const zGetBriaBriaVideoEraserEraseKeypointsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetBriaBriaVideoEraserEraseKeypointsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutBriaBriaVideoEraserEraseKeypointsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutBriaBriaVideoEraserEraseKeypointsRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostBriaBriaVideoEraserEraseKeypointsData = z.object({
  body: zSchemaBriaVideoEraserEraseKeypointsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostBriaBriaVideoEraserEraseKeypointsResponse = zSchemaQueueStatus

export const zGetBriaBriaVideoEraserEraseKeypointsRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetBriaBriaVideoEraserEraseKeypointsRequestsByRequestIdResponse =
  zSchemaBriaVideoEraserEraseKeypointsOutput

export const zGetBriaBriaVideoEraserErasePromptRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetBriaBriaVideoEraserErasePromptRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutBriaBriaVideoEraserErasePromptRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutBriaBriaVideoEraserErasePromptRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostBriaBriaVideoEraserErasePromptData = z.object({
  body: zSchemaBriaVideoEraserErasePromptInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostBriaBriaVideoEraserErasePromptResponse = zSchemaQueueStatus

export const zGetBriaBriaVideoEraserErasePromptRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetBriaBriaVideoEraserErasePromptRequestsByRequestIdResponse =
  zSchemaBriaVideoEraserErasePromptOutput

export const zGetWanV26ReferenceToVideoRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetWanV26ReferenceToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutWanV26ReferenceToVideoRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutWanV26ReferenceToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostWanV26ReferenceToVideoData = z.object({
  body: zSchemaV26ReferenceToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostWanV26ReferenceToVideoResponse = zSchemaQueueStatus

export const zGetWanV26ReferenceToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetWanV26ReferenceToVideoRequestsByRequestIdResponse =
  zSchemaV26ReferenceToVideoOutput

export const zGetFalAiVeo31FastExtendVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiVeo31FastExtendVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVeo31FastExtendVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo31FastExtendVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiVeo31FastExtendVideoData = z.object({
  body: zSchemaVeo31FastExtendVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVeo31FastExtendVideoResponse = zSchemaQueueStatus

export const zGetFalAiVeo31FastExtendVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiVeo31FastExtendVideoRequestsByRequestIdResponse =
  zSchemaVeo31FastExtendVideoOutput

export const zGetFalAiVeo31ExtendVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiVeo31ExtendVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVeo31ExtendVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo31ExtendVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiVeo31ExtendVideoData = z.object({
  body: zSchemaVeo31ExtendVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVeo31ExtendVideoResponse = zSchemaQueueStatus

export const zGetFalAiVeo31ExtendVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiVeo31ExtendVideoRequestsByRequestIdResponse =
  zSchemaVeo31ExtendVideoOutput

export const zGetFalAiKlingVideoO1StandardVideoToVideoReferenceRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoO1StandardVideoToVideoReferenceRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoO1StandardVideoToVideoReferenceRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoO1StandardVideoToVideoReferenceRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoO1StandardVideoToVideoReferenceData = z.object(
  {
    body: zSchemaKlingVideoO1StandardVideoToVideoReferenceInput,
    path: z.optional(z.never()),
    query: z.optional(z.never()),
  },
)

/**
 * The request status.
 */
export const zPostFalAiKlingVideoO1StandardVideoToVideoReferenceResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoO1StandardVideoToVideoReferenceRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoO1StandardVideoToVideoReferenceRequestsByRequestIdResponse =
  zSchemaKlingVideoO1StandardVideoToVideoReferenceOutput

export const zGetFalAiKlingVideoO1StandardVideoToVideoEditRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoO1StandardVideoToVideoEditRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoO1StandardVideoToVideoEditRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoO1StandardVideoToVideoEditRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoO1StandardVideoToVideoEditData = z.object({
  body: zSchemaKlingVideoO1StandardVideoToVideoEditInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoO1StandardVideoToVideoEditResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoO1StandardVideoToVideoEditRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoO1StandardVideoToVideoEditRequestsByRequestIdResponse =
  zSchemaKlingVideoO1StandardVideoToVideoEditOutput

export const zGetFalAiSteadyDancerRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiSteadyDancerRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSteadyDancerRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiSteadyDancerRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSteadyDancerData = z.object({
  body: zSchemaSteadyDancerInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSteadyDancerResponse = zSchemaQueueStatus

export const zGetFalAiSteadyDancerRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSteadyDancerRequestsByRequestIdResponse =
  zSchemaSteadyDancerOutput

export const zGetFalAiOneToAllAnimation13bRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiOneToAllAnimation13bRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiOneToAllAnimation13bRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiOneToAllAnimation13bRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiOneToAllAnimation13bData = z.object({
  body: zSchemaOneToAllAnimation13bInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiOneToAllAnimation13bResponse = zSchemaQueueStatus

export const zGetFalAiOneToAllAnimation13bRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiOneToAllAnimation13bRequestsByRequestIdResponse =
  zSchemaOneToAllAnimation13bOutput

export const zGetFalAiOneToAllAnimation14bRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiOneToAllAnimation14bRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiOneToAllAnimation14bRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiOneToAllAnimation14bRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiOneToAllAnimation14bData = z.object({
  body: zSchemaOneToAllAnimation14bInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiOneToAllAnimation14bResponse = zSchemaQueueStatus

export const zGetFalAiOneToAllAnimation14bRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiOneToAllAnimation14bRequestsByRequestIdResponse =
  zSchemaOneToAllAnimation14bOutput

export const zGetFalAiWanVisionEnhancerRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiWanVisionEnhancerRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanVisionEnhancerRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVisionEnhancerRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanVisionEnhancerData = z.object({
  body: zSchemaWanVisionEnhancerInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanVisionEnhancerResponse = zSchemaQueueStatus

export const zGetFalAiWanVisionEnhancerRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanVisionEnhancerRequestsByRequestIdResponse =
  zSchemaWanVisionEnhancerOutput

export const zGetFalAiSyncLipsyncReact1RequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiSyncLipsyncReact1RequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSyncLipsyncReact1RequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiSyncLipsyncReact1RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSyncLipsyncReact1Data = z.object({
  body: zSchemaSyncLipsyncReact1Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSyncLipsyncReact1Response = zSchemaQueueStatus

export const zGetFalAiSyncLipsyncReact1RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSyncLipsyncReact1RequestsByRequestIdResponse =
  zSchemaSyncLipsyncReact1Output

export const zGetVeedVideoBackgroundRemovalFastRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetVeedVideoBackgroundRemovalFastRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutVeedVideoBackgroundRemovalFastRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutVeedVideoBackgroundRemovalFastRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostVeedVideoBackgroundRemovalFastData = z.object({
  body: zSchemaVideoBackgroundRemovalFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostVeedVideoBackgroundRemovalFastResponse = zSchemaQueueStatus

export const zGetVeedVideoBackgroundRemovalFastRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetVeedVideoBackgroundRemovalFastRequestsByRequestIdResponse =
  zSchemaVideoBackgroundRemovalFastOutput

export const zGetFalAiKlingVideoO1VideoToVideoEditRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoO1VideoToVideoEditRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoO1VideoToVideoEditRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoO1VideoToVideoEditRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoO1VideoToVideoEditData = z.object({
  body: zSchemaKlingVideoO1VideoToVideoEditInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoO1VideoToVideoEditResponse = zSchemaQueueStatus

export const zGetFalAiKlingVideoO1VideoToVideoEditRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoO1VideoToVideoEditRequestsByRequestIdResponse =
  zSchemaKlingVideoO1VideoToVideoEditOutput

export const zGetFalAiKlingVideoO1VideoToVideoReferenceRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKlingVideoO1VideoToVideoReferenceRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKlingVideoO1VideoToVideoReferenceRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoO1VideoToVideoReferenceRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKlingVideoO1VideoToVideoReferenceData = z.object({
  body: zSchemaKlingVideoO1VideoToVideoReferenceInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKlingVideoO1VideoToVideoReferenceResponse =
  zSchemaQueueStatus

export const zGetFalAiKlingVideoO1VideoToVideoReferenceRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoO1VideoToVideoReferenceRequestsByRequestIdResponse =
  zSchemaKlingVideoO1VideoToVideoReferenceOutput

export const zGetVeedVideoBackgroundRemovalRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetVeedVideoBackgroundRemovalRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutVeedVideoBackgroundRemovalRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutVeedVideoBackgroundRemovalRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostVeedVideoBackgroundRemovalData = z.object({
  body: zSchemaVideoBackgroundRemovalInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostVeedVideoBackgroundRemovalResponse = zSchemaQueueStatus

export const zGetVeedVideoBackgroundRemovalRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetVeedVideoBackgroundRemovalRequestsByRequestIdResponse =
  zSchemaVideoBackgroundRemovalOutput

export const zGetVeedVideoBackgroundRemovalGreenScreenRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetVeedVideoBackgroundRemovalGreenScreenRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutVeedVideoBackgroundRemovalGreenScreenRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutVeedVideoBackgroundRemovalGreenScreenRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostVeedVideoBackgroundRemovalGreenScreenData = z.object({
  body: zSchemaVideoBackgroundRemovalGreenScreenInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostVeedVideoBackgroundRemovalGreenScreenResponse =
  zSchemaQueueStatus

export const zGetVeedVideoBackgroundRemovalGreenScreenRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetVeedVideoBackgroundRemovalGreenScreenRequestsByRequestIdResponse =
  zSchemaVideoBackgroundRemovalGreenScreenOutput

export const zGetFalAiLtx2RetakeVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiLtx2RetakeVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtx2RetakeVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx2RetakeVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtx2RetakeVideoData = z.object({
  body: zSchemaLtx2RetakeVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtx2RetakeVideoResponse = zSchemaQueueStatus

export const zGetFalAiLtx2RetakeVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtx2RetakeVideoRequestsByRequestIdResponse =
  zSchemaLtx2RetakeVideoOutput

export const zGetDecartLucyEditFastRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetDecartLucyEditFastRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutDecartLucyEditFastRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutDecartLucyEditFastRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostDecartLucyEditFastData = z.object({
  body: zSchemaLucyEditFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostDecartLucyEditFastResponse = zSchemaQueueStatus

export const zGetDecartLucyEditFastRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetDecartLucyEditFastRequestsByRequestIdResponse =
  zSchemaLucyEditFastOutput

export const zGetFalAiSam3VideoRleRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiSam3VideoRleRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSam3VideoRleRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiSam3VideoRleRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSam3VideoRleData = z.object({
  body: zSchemaSam3VideoRleInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSam3VideoRleResponse = zSchemaQueueStatus

export const zGetFalAiSam3VideoRleRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSam3VideoRleRequestsByRequestIdResponse =
  zSchemaSam3VideoRleOutput

export const zGetFalAiSam3VideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiSam3VideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSam3VideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiSam3VideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSam3VideoData = z.object({
  body: zSchemaSam3VideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSam3VideoResponse = zSchemaQueueStatus

export const zGetFalAiSam3VideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSam3VideoRequestsByRequestIdResponse =
  zSchemaSam3VideoOutput

export const zGetFalAiEdittoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiEdittoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiEdittoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiEdittoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiEdittoData = z.object({
  body: zSchemaEdittoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiEdittoResponse = zSchemaQueueStatus

export const zGetFalAiEdittoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiEdittoRequestsByRequestIdResponse = zSchemaEdittoOutput

export const zGetFalAiFlashvsrUpscaleVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiFlashvsrUpscaleVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiFlashvsrUpscaleVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiFlashvsrUpscaleVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiFlashvsrUpscaleVideoData = z.object({
  body: zSchemaFlashvsrUpscaleVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiFlashvsrUpscaleVideoResponse = zSchemaQueueStatus

export const zGetFalAiFlashvsrUpscaleVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiFlashvsrUpscaleVideoRequestsByRequestIdResponse =
  zSchemaFlashvsrUpscaleVideoOutput

export const zGetFalAiWorkflowUtilitiesAutoSubtitleRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWorkflowUtilitiesAutoSubtitleRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWorkflowUtilitiesAutoSubtitleRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWorkflowUtilitiesAutoSubtitleRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWorkflowUtilitiesAutoSubtitleData = z.object({
  body: zSchemaWorkflowUtilitiesAutoSubtitleInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWorkflowUtilitiesAutoSubtitleResponse =
  zSchemaQueueStatus

export const zGetFalAiWorkflowUtilitiesAutoSubtitleRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiWorkflowUtilitiesAutoSubtitleRequestsByRequestIdResponse =
  zSchemaWorkflowUtilitiesAutoSubtitleOutput

export const zGetFalAiBytedanceUpscalerUpscaleVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiBytedanceUpscalerUpscaleVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiBytedanceUpscalerUpscaleVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceUpscalerUpscaleVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiBytedanceUpscalerUpscaleVideoData = z.object({
  body: zSchemaBytedanceUpscalerUpscaleVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiBytedanceUpscalerUpscaleVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiBytedanceUpscalerUpscaleVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceUpscalerUpscaleVideoRequestsByRequestIdResponse =
  zSchemaBytedanceUpscalerUpscaleVideoOutput

export const zGetFalAiVideoAsPromptRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiVideoAsPromptRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVideoAsPromptRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiVideoAsPromptRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiVideoAsPromptData = z.object({
  body: zSchemaVideoAsPromptInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVideoAsPromptResponse = zSchemaQueueStatus

export const zGetFalAiVideoAsPromptRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiVideoAsPromptRequestsByRequestIdResponse =
  zSchemaVideoAsPromptOutput

export const zGetFalAiBirefnetV2VideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiBirefnetV2VideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiBirefnetV2VideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiBirefnetV2VideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiBirefnetV2VideoData = z.object({
  body: zSchemaBirefnetV2VideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiBirefnetV2VideoResponse = zSchemaQueueStatus

export const zGetFalAiBirefnetV2VideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiBirefnetV2VideoRequestsByRequestIdResponse =
  zSchemaBirefnetV2VideoOutput

export const zGetFalAiViduQ2VideoExtensionProRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiViduQ2VideoExtensionProRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiViduQ2VideoExtensionProRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ2VideoExtensionProRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiViduQ2VideoExtensionProData = z.object({
  body: zSchemaViduQ2VideoExtensionProInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiViduQ2VideoExtensionProResponse = zSchemaQueueStatus

export const zGetFalAiViduQ2VideoExtensionProRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiViduQ2VideoExtensionProRequestsByRequestIdResponse =
  zSchemaViduQ2VideoExtensionProOutput

export const zGetMireloAiSfxV15VideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetMireloAiSfxV15VideoToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutMireloAiSfxV15VideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutMireloAiSfxV15VideoToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostMireloAiSfxV15VideoToVideoData = z.object({
  body: zSchemaSfxV15VideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostMireloAiSfxV15VideoToVideoResponse = zSchemaQueueStatus

export const zGetMireloAiSfxV15VideoToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetMireloAiSfxV15VideoToVideoRequestsByRequestIdResponse =
  zSchemaSfxV15VideoToVideoOutput

export const zGetFalAiKreaWan14bVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiKreaWan14bVideoToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiKreaWan14bVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiKreaWan14bVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiKreaWan14bVideoToVideoData = z.object({
  body: zSchemaKreaWan14bVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiKreaWan14bVideoToVideoResponse = zSchemaQueueStatus

export const zGetFalAiKreaWan14bVideoToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiKreaWan14bVideoToVideoRequestsByRequestIdResponse =
  zSchemaKreaWan14bVideoToVideoOutput

export const zGetFalAiSora2VideoToVideoRemixRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiSora2VideoToVideoRemixRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSora2VideoToVideoRemixRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiSora2VideoToVideoRemixRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiSora2VideoToVideoRemixData = z.object({
  body: zSchemaSora2VideoToVideoRemixInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSora2VideoToVideoRemixResponse = zSchemaQueueStatus

export const zGetFalAiSora2VideoToVideoRemixRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSora2VideoToVideoRemixRequestsByRequestIdResponse =
  zSchemaSora2VideoToVideoRemixOutput

export const zGetFalAiWanVaceAppsLongReframeRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanVaceAppsLongReframeRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanVaceAppsLongReframeRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVaceAppsLongReframeRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWanVaceAppsLongReframeData = z.object({
  body: zSchemaWanVaceAppsLongReframeInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanVaceAppsLongReframeResponse = zSchemaQueueStatus

export const zGetFalAiWanVaceAppsLongReframeRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanVaceAppsLongReframeRequestsByRequestIdResponse =
  zSchemaWanVaceAppsLongReframeOutput

export const zGetFalAiInfinitalkVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiInfinitalkVideoToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiInfinitalkVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiInfinitalkVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiInfinitalkVideoToVideoData = z.object({
  body: zSchemaInfinitalkVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiInfinitalkVideoToVideoResponse = zSchemaQueueStatus

export const zGetFalAiInfinitalkVideoToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiInfinitalkVideoToVideoRequestsByRequestIdResponse =
  zSchemaInfinitalkVideoToVideoOutput

export const zGetFalAiSeedvrUpscaleVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiSeedvrUpscaleVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSeedvrUpscaleVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiSeedvrUpscaleVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSeedvrUpscaleVideoData = z.object({
  body: zSchemaSeedvrUpscaleVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSeedvrUpscaleVideoResponse = zSchemaQueueStatus

export const zGetFalAiSeedvrUpscaleVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSeedvrUpscaleVideoRequestsByRequestIdResponse =
  zSchemaSeedvrUpscaleVideoOutput

export const zGetFalAiWanVaceAppsVideoEditRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanVaceAppsVideoEditRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanVaceAppsVideoEditRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVaceAppsVideoEditRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanVaceAppsVideoEditData = z.object({
  body: zSchemaWanVaceAppsVideoEditInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanVaceAppsVideoEditResponse = zSchemaQueueStatus

export const zGetFalAiWanVaceAppsVideoEditRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanVaceAppsVideoEditRequestsByRequestIdResponse =
  zSchemaWanVaceAppsVideoEditOutput

export const zGetFalAiWanV2214bAnimateReplaceRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanV2214bAnimateReplaceRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanV2214bAnimateReplaceRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV2214bAnimateReplaceRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWanV2214bAnimateReplaceData = z.object({
  body: zSchemaWanV2214bAnimateReplaceInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanV2214bAnimateReplaceResponse = zSchemaQueueStatus

export const zGetFalAiWanV2214bAnimateReplaceRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiWanV2214bAnimateReplaceRequestsByRequestIdResponse =
  zSchemaWanV2214bAnimateReplaceOutput

export const zGetFalAiWanV2214bAnimateMoveRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanV2214bAnimateMoveRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanV2214bAnimateMoveRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV2214bAnimateMoveRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanV2214bAnimateMoveData = z.object({
  body: zSchemaWanV2214bAnimateMoveInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanV2214bAnimateMoveResponse = zSchemaQueueStatus

export const zGetFalAiWanV2214bAnimateMoveRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanV2214bAnimateMoveRequestsByRequestIdResponse =
  zSchemaWanV2214bAnimateMoveOutput

export const zGetDecartLucyEditProRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetDecartLucyEditProRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutDecartLucyEditProRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutDecartLucyEditProRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostDecartLucyEditProData = z.object({
  body: zSchemaLucyEditProInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostDecartLucyEditProResponse = zSchemaQueueStatus

export const zGetDecartLucyEditProRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetDecartLucyEditProRequestsByRequestIdResponse =
  zSchemaLucyEditProOutput

export const zGetDecartLucyEditDevRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetDecartLucyEditDevRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutDecartLucyEditDevRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutDecartLucyEditDevRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostDecartLucyEditDevData = z.object({
  body: zSchemaLucyEditDevInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostDecartLucyEditDevResponse = zSchemaQueueStatus

export const zGetDecartLucyEditDevRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetDecartLucyEditDevRequestsByRequestIdResponse =
  zSchemaLucyEditDevOutput

export const zGetFalAiWan22VaceFunA14bReframeRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWan22VaceFunA14bReframeRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWan22VaceFunA14bReframeRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWan22VaceFunA14bReframeRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWan22VaceFunA14bReframeData = z.object({
  body: zSchemaWan22VaceFunA14bReframeInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWan22VaceFunA14bReframeResponse = zSchemaQueueStatus

export const zGetFalAiWan22VaceFunA14bReframeRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiWan22VaceFunA14bReframeRequestsByRequestIdResponse =
  zSchemaWan22VaceFunA14bReframeOutput

export const zGetFalAiWan22VaceFunA14bOutpaintingRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWan22VaceFunA14bOutpaintingRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWan22VaceFunA14bOutpaintingRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWan22VaceFunA14bOutpaintingRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWan22VaceFunA14bOutpaintingData = z.object({
  body: zSchemaWan22VaceFunA14bOutpaintingInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWan22VaceFunA14bOutpaintingResponse = zSchemaQueueStatus

export const zGetFalAiWan22VaceFunA14bOutpaintingRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiWan22VaceFunA14bOutpaintingRequestsByRequestIdResponse =
  zSchemaWan22VaceFunA14bOutpaintingOutput

export const zGetFalAiWan22VaceFunA14bInpaintingRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWan22VaceFunA14bInpaintingRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWan22VaceFunA14bInpaintingRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWan22VaceFunA14bInpaintingRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWan22VaceFunA14bInpaintingData = z.object({
  body: zSchemaWan22VaceFunA14bInpaintingInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWan22VaceFunA14bInpaintingResponse = zSchemaQueueStatus

export const zGetFalAiWan22VaceFunA14bInpaintingRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiWan22VaceFunA14bInpaintingRequestsByRequestIdResponse =
  zSchemaWan22VaceFunA14bInpaintingOutput

export const zGetFalAiWan22VaceFunA14bDepthRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWan22VaceFunA14bDepthRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWan22VaceFunA14bDepthRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWan22VaceFunA14bDepthRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWan22VaceFunA14bDepthData = z.object({
  body: zSchemaWan22VaceFunA14bDepthInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWan22VaceFunA14bDepthResponse = zSchemaQueueStatus

export const zGetFalAiWan22VaceFunA14bDepthRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWan22VaceFunA14bDepthRequestsByRequestIdResponse =
  zSchemaWan22VaceFunA14bDepthOutput

export const zGetFalAiWan22VaceFunA14bPoseRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWan22VaceFunA14bPoseRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWan22VaceFunA14bPoseRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWan22VaceFunA14bPoseRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWan22VaceFunA14bPoseData = z.object({
  body: zSchemaWan22VaceFunA14bPoseInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWan22VaceFunA14bPoseResponse = zSchemaQueueStatus

export const zGetFalAiWan22VaceFunA14bPoseRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWan22VaceFunA14bPoseRequestsByRequestIdResponse =
  zSchemaWan22VaceFunA14bPoseOutput

export const zGetFalAiHunyuanVideoFoleyRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiHunyuanVideoFoleyRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiHunyuanVideoFoleyRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanVideoFoleyRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiHunyuanVideoFoleyData = z.object({
  body: zSchemaHunyuanVideoFoleyInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiHunyuanVideoFoleyResponse = zSchemaQueueStatus

export const zGetFalAiHunyuanVideoFoleyRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanVideoFoleyRequestsByRequestIdResponse =
  zSchemaHunyuanVideoFoleyOutput

export const zGetFalAiSyncLipsyncV2ProRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiSyncLipsyncV2ProRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSyncLipsyncV2ProRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiSyncLipsyncV2ProRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSyncLipsyncV2ProData = z.object({
  body: zSchemaSyncLipsyncV2ProInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSyncLipsyncV2ProResponse = zSchemaQueueStatus

export const zGetFalAiSyncLipsyncV2ProRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSyncLipsyncV2ProRequestsByRequestIdResponse =
  zSchemaSyncLipsyncV2ProOutput

export const zGetFalAiWanFunControlRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanFunControlRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanFunControlRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanFunControlRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanFunControlData = z.object({
  body: zSchemaWanFunControlInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanFunControlResponse = zSchemaQueueStatus

export const zGetFalAiWanFunControlRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanFunControlRequestsByRequestIdResponse =
  zSchemaWanFunControlOutput

export const zGetBriaVideoIncreaseResolutionRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetBriaVideoIncreaseResolutionRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutBriaVideoIncreaseResolutionRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutBriaVideoIncreaseResolutionRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostBriaVideoIncreaseResolutionData = z.object({
  body: zSchemaVideoIncreaseResolutionInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostBriaVideoIncreaseResolutionResponse = zSchemaQueueStatus

export const zGetBriaVideoIncreaseResolutionRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetBriaVideoIncreaseResolutionRequestsByRequestIdResponse =
  zSchemaVideoIncreaseResolutionOutput

export const zGetFalAiInfinitalkRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiInfinitalkRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiInfinitalkRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiInfinitalkRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiInfinitalkData = z.object({
  body: zSchemaInfinitalkInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiInfinitalkResponse = zSchemaQueueStatus

export const zGetFalAiInfinitalkRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiInfinitalkRequestsByRequestIdResponse =
  zSchemaInfinitalkOutput

export const zGetMireloAiSfxV1VideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetMireloAiSfxV1VideoToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutMireloAiSfxV1VideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutMireloAiSfxV1VideoToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostMireloAiSfxV1VideoToVideoData = z.object({
  body: zSchemaSfxV1VideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostMireloAiSfxV1VideoToVideoResponse = zSchemaQueueStatus

export const zGetMireloAiSfxV1VideoToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetMireloAiSfxV1VideoToVideoRequestsByRequestIdResponse =
  zSchemaSfxV1VideoToVideoOutput

export const zGetMoonvalleyMareyPoseTransferRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetMoonvalleyMareyPoseTransferRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutMoonvalleyMareyPoseTransferRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutMoonvalleyMareyPoseTransferRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostMoonvalleyMareyPoseTransferData = z.object({
  body: zSchemaMareyPoseTransferInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostMoonvalleyMareyPoseTransferResponse = zSchemaQueueStatus

export const zGetMoonvalleyMareyPoseTransferRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetMoonvalleyMareyPoseTransferRequestsByRequestIdResponse =
  zSchemaMareyPoseTransferOutput

export const zGetMoonvalleyMareyMotionTransferRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetMoonvalleyMareyMotionTransferRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutMoonvalleyMareyMotionTransferRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutMoonvalleyMareyMotionTransferRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostMoonvalleyMareyMotionTransferData = z.object({
  body: zSchemaMareyMotionTransferInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostMoonvalleyMareyMotionTransferResponse = zSchemaQueueStatus

export const zGetMoonvalleyMareyMotionTransferRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetMoonvalleyMareyMotionTransferRequestsByRequestIdResponse =
  zSchemaMareyMotionTransferOutput

export const zGetFalAiFfmpegApiMergeVideosRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiFfmpegApiMergeVideosRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiFfmpegApiMergeVideosRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiFfmpegApiMergeVideosRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiFfmpegApiMergeVideosData = z.object({
  body: zSchemaFfmpegApiMergeVideosInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiFfmpegApiMergeVideosResponse = zSchemaQueueStatus

export const zGetFalAiFfmpegApiMergeVideosRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiFfmpegApiMergeVideosRequestsByRequestIdResponse =
  zSchemaFfmpegApiMergeVideosOutput

export const zGetFalAiWanV22A14bVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanV22A14bVideoToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanV22A14bVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV22A14bVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiWanV22A14bVideoToVideoData = z.object({
  body: zSchemaWanV22A14bVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanV22A14bVideoToVideoResponse = zSchemaQueueStatus

export const zGetFalAiWanV22A14bVideoToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanV22A14bVideoToVideoRequestsByRequestIdResponse =
  zSchemaWanV22A14bVideoToVideoOutput

export const zGetFalAiLtxv13B098DistilledExtendRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxv13B098DistilledExtendRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxv13B098DistilledExtendRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxv13B098DistilledExtendRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtxv13B098DistilledExtendData = z.object({
  body: zSchemaLtxv13B098DistilledExtendInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxv13B098DistilledExtendResponse = zSchemaQueueStatus

export const zGetFalAiLtxv13B098DistilledExtendRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtxv13B098DistilledExtendRequestsByRequestIdResponse =
  zSchemaLtxv13B098DistilledExtendOutput

export const zGetFalAiRifeVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiRifeVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiRifeVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiRifeVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiRifeVideoData = z.object({
  body: zSchemaRifeVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiRifeVideoResponse = zSchemaQueueStatus

export const zGetFalAiRifeVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiRifeVideoRequestsByRequestIdResponse =
  zSchemaRifeVideoOutput

export const zGetFalAiFilmVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiFilmVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiFilmVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiFilmVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiFilmVideoData = z.object({
  body: zSchemaFilmVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiFilmVideoResponse = zSchemaQueueStatus

export const zGetFalAiFilmVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiFilmVideoRequestsByRequestIdResponse =
  zSchemaFilmVideoOutput

export const zGetFalAiLumaDreamMachineRay2FlashModifyRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLumaDreamMachineRay2FlashModifyRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLumaDreamMachineRay2FlashModifyRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLumaDreamMachineRay2FlashModifyRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLumaDreamMachineRay2FlashModifyData = z.object({
  body: zSchemaLumaDreamMachineRay2FlashModifyInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLumaDreamMachineRay2FlashModifyResponse =
  zSchemaQueueStatus

export const zGetFalAiLumaDreamMachineRay2FlashModifyRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLumaDreamMachineRay2FlashModifyRequestsByRequestIdResponse =
  zSchemaLumaDreamMachineRay2FlashModifyOutput

export const zGetFalAiLtxv13B098DistilledMulticonditioningRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxv13B098DistilledMulticonditioningRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxv13B098DistilledMulticonditioningRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxv13B098DistilledMulticonditioningRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtxv13B098DistilledMulticonditioningData = z.object({
  body: zSchemaLtxv13B098DistilledMulticonditioningInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxv13B098DistilledMulticonditioningResponse =
  zSchemaQueueStatus

export const zGetFalAiLtxv13B098DistilledMulticonditioningRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtxv13B098DistilledMulticonditioningRequestsByRequestIdResponse =
  zSchemaLtxv13B098DistilledMulticonditioningOutput

export const zGetFalAiPixverseSoundEffectsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseSoundEffectsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseSoundEffectsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseSoundEffectsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseSoundEffectsData = z.object({
  body: zSchemaPixverseSoundEffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseSoundEffectsResponse = zSchemaQueueStatus

export const zGetFalAiPixverseSoundEffectsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseSoundEffectsRequestsByRequestIdResponse =
  zSchemaPixverseSoundEffectsOutput

export const zGetFalAiThinksoundAudioRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiThinksoundAudioRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiThinksoundAudioRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiThinksoundAudioRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiThinksoundAudioData = z.object({
  body: zSchemaThinksoundAudioInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiThinksoundAudioResponse = zSchemaQueueStatus

export const zGetFalAiThinksoundAudioRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiThinksoundAudioRequestsByRequestIdResponse =
  zSchemaThinksoundAudioOutput

export const zGetFalAiThinksoundRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiThinksoundRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiThinksoundRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiThinksoundRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiThinksoundData = z.object({
  body: zSchemaThinksoundInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiThinksoundResponse = zSchemaQueueStatus

export const zGetFalAiThinksoundRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiThinksoundRequestsByRequestIdResponse =
  zSchemaThinksoundOutput

export const zGetFalAiPixverseExtendFastRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPixverseExtendFastRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseExtendFastRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseExtendFastRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseExtendFastData = z.object({
  body: zSchemaPixverseExtendFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseExtendFastResponse = zSchemaQueueStatus

export const zGetFalAiPixverseExtendFastRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseExtendFastRequestsByRequestIdResponse =
  zSchemaPixverseExtendFastOutput

export const zGetFalAiPixverseExtendRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiPixverseExtendRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseExtendRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseExtendRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseExtendData = z.object({
  body: zSchemaPixverseExtendInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseExtendResponse = zSchemaQueueStatus

export const zGetFalAiPixverseExtendRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseExtendRequestsByRequestIdResponse =
  zSchemaPixverseExtendOutput

export const zGetFalAiPixverseLipsyncRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiPixverseLipsyncRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPixverseLipsyncRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseLipsyncRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPixverseLipsyncData = z.object({
  body: zSchemaPixverseLipsyncInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPixverseLipsyncResponse = zSchemaQueueStatus

export const zGetFalAiPixverseLipsyncRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPixverseLipsyncRequestsByRequestIdResponse =
  zSchemaPixverseLipsyncOutput

export const zGetFalAiLumaDreamMachineRay2ModifyRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLumaDreamMachineRay2ModifyRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLumaDreamMachineRay2ModifyRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLumaDreamMachineRay2ModifyRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLumaDreamMachineRay2ModifyData = z.object({
  body: zSchemaLumaDreamMachineRay2ModifyInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLumaDreamMachineRay2ModifyResponse = zSchemaQueueStatus

export const zGetFalAiLumaDreamMachineRay2ModifyRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLumaDreamMachineRay2ModifyRequestsByRequestIdResponse =
  zSchemaLumaDreamMachineRay2ModifyOutput

export const zGetFalAiWanVace14bReframeRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiWanVace14bReframeRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanVace14bReframeRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVace14bReframeRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanVace14bReframeData = z.object({
  body: zSchemaWanVace14bReframeInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanVace14bReframeResponse = zSchemaQueueStatus

export const zGetFalAiWanVace14bReframeRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanVace14bReframeRequestsByRequestIdResponse =
  zSchemaWanVace14bReframeOutput

export const zGetFalAiWanVace14bOutpaintingRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanVace14bOutpaintingRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanVace14bOutpaintingRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVace14bOutpaintingRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanVace14bOutpaintingData = z.object({
  body: zSchemaWanVace14bOutpaintingInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanVace14bOutpaintingResponse = zSchemaQueueStatus

export const zGetFalAiWanVace14bOutpaintingRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanVace14bOutpaintingRequestsByRequestIdResponse =
  zSchemaWanVace14bOutpaintingOutput

export const zGetFalAiWanVace14bInpaintingRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiWanVace14bInpaintingRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanVace14bInpaintingRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVace14bInpaintingRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanVace14bInpaintingData = z.object({
  body: zSchemaWanVace14bInpaintingInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanVace14bInpaintingResponse = zSchemaQueueStatus

export const zGetFalAiWanVace14bInpaintingRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanVace14bInpaintingRequestsByRequestIdResponse =
  zSchemaWanVace14bInpaintingOutput

export const zGetFalAiWanVace14bPoseRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanVace14bPoseRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanVace14bPoseRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVace14bPoseRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanVace14bPoseData = z.object({
  body: zSchemaWanVace14bPoseInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanVace14bPoseResponse = zSchemaQueueStatus

export const zGetFalAiWanVace14bPoseRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanVace14bPoseRequestsByRequestIdResponse =
  zSchemaWanVace14bPoseOutput

export const zGetFalAiWanVace14bDepthRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanVace14bDepthRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanVace14bDepthRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVace14bDepthRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanVace14bDepthData = z.object({
  body: zSchemaWanVace14bDepthInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanVace14bDepthResponse = zSchemaQueueStatus

export const zGetFalAiWanVace14bDepthRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanVace14bDepthRequestsByRequestIdResponse =
  zSchemaWanVace14bDepthOutput

export const zGetFalAiDwposeVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiDwposeVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiDwposeVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiDwposeVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiDwposeVideoData = z.object({
  body: zSchemaDwposeVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiDwposeVideoResponse = zSchemaQueueStatus

export const zGetFalAiDwposeVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiDwposeVideoRequestsByRequestIdResponse =
  zSchemaDwposeVideoOutput

export const zGetFalAiFfmpegApiMergeAudioVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiFfmpegApiMergeAudioVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiFfmpegApiMergeAudioVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiFfmpegApiMergeAudioVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiFfmpegApiMergeAudioVideoData = z.object({
  body: zSchemaFfmpegApiMergeAudioVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiFfmpegApiMergeAudioVideoResponse = zSchemaQueueStatus

export const zGetFalAiFfmpegApiMergeAudioVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiFfmpegApiMergeAudioVideoRequestsByRequestIdResponse =
  zSchemaFfmpegApiMergeAudioVideoOutput

export const zGetFalAiWanVace13bRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanVace13bRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanVace13bRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVace13bRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanVace13bData = z.object({
  body: zSchemaWanVace13bInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanVace13bResponse = zSchemaQueueStatus

export const zGetFalAiWanVace13bRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanVace13bRequestsByRequestIdResponse =
  zSchemaWanVace13bOutput

export const zGetFalAiLumaDreamMachineRay2FlashReframeRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLumaDreamMachineRay2FlashReframeRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLumaDreamMachineRay2FlashReframeRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLumaDreamMachineRay2FlashReframeRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLumaDreamMachineRay2FlashReframeData = z.object({
  body: zSchemaLumaDreamMachineRay2FlashReframeInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLumaDreamMachineRay2FlashReframeResponse =
  zSchemaQueueStatus

export const zGetFalAiLumaDreamMachineRay2FlashReframeRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLumaDreamMachineRay2FlashReframeRequestsByRequestIdResponse =
  zSchemaLumaDreamMachineRay2FlashReframeOutput

export const zGetFalAiLumaDreamMachineRay2ReframeRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLumaDreamMachineRay2ReframeRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLumaDreamMachineRay2ReframeRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLumaDreamMachineRay2ReframeRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLumaDreamMachineRay2ReframeData = z.object({
  body: zSchemaLumaDreamMachineRay2ReframeInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLumaDreamMachineRay2ReframeResponse = zSchemaQueueStatus

export const zGetFalAiLumaDreamMachineRay2ReframeRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLumaDreamMachineRay2ReframeRequestsByRequestIdResponse =
  zSchemaLumaDreamMachineRay2ReframeOutput

export const zGetVeedLipsyncRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetVeedLipsyncRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutVeedLipsyncRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutVeedLipsyncRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostVeedLipsyncData = z.object({
  body: zSchemaLipsyncInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostVeedLipsyncResponse = zSchemaQueueStatus

export const zGetVeedLipsyncRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetVeedLipsyncRequestsByRequestIdResponse = zSchemaLipsyncOutput

export const zGetFalAiWanVace14bRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanVace14bRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanVace14bRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVace14bRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanVace14bData = z.object({
  body: zSchemaWanVace14bInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanVace14bResponse = zSchemaQueueStatus

export const zGetFalAiWanVace14bRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanVace14bRequestsByRequestIdResponse =
  zSchemaWanVace14bOutput

export const zGetFalAiLtxVideo13bDistilledExtendRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxVideo13bDistilledExtendRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxVideo13bDistilledExtendRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideo13bDistilledExtendRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtxVideo13bDistilledExtendData = z.object({
  body: zSchemaLtxVideo13bDistilledExtendInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxVideo13bDistilledExtendResponse = zSchemaQueueStatus

export const zGetFalAiLtxVideo13bDistilledExtendRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideo13bDistilledExtendRequestsByRequestIdResponse =
  zSchemaLtxVideo13bDistilledExtendOutput

export const zGetFalAiLtxVideo13bDistilledMulticonditioningRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxVideo13bDistilledMulticonditioningRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxVideo13bDistilledMulticonditioningRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideo13bDistilledMulticonditioningRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtxVideo13bDistilledMulticonditioningData = z.object({
  body: zSchemaLtxVideo13bDistilledMulticonditioningInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxVideo13bDistilledMulticonditioningResponse =
  zSchemaQueueStatus

export const zGetFalAiLtxVideo13bDistilledMulticonditioningRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideo13bDistilledMulticonditioningRequestsByRequestIdResponse =
  zSchemaLtxVideo13bDistilledMulticonditioningOutput

export const zGetFalAiLtxVideo13bDevMulticonditioningRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxVideo13bDevMulticonditioningRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxVideo13bDevMulticonditioningRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideo13bDevMulticonditioningRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtxVideo13bDevMulticonditioningData = z.object({
  body: zSchemaLtxVideo13bDevMulticonditioningInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxVideo13bDevMulticonditioningResponse =
  zSchemaQueueStatus

export const zGetFalAiLtxVideo13bDevMulticonditioningRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideo13bDevMulticonditioningRequestsByRequestIdResponse =
  zSchemaLtxVideo13bDevMulticonditioningOutput

export const zGetFalAiLtxVideo13bDevExtendRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxVideo13bDevExtendRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxVideo13bDevExtendRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideo13bDevExtendRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtxVideo13bDevExtendData = z.object({
  body: zSchemaLtxVideo13bDevExtendInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxVideo13bDevExtendResponse = zSchemaQueueStatus

export const zGetFalAiLtxVideo13bDevExtendRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideo13bDevExtendRequestsByRequestIdResponse =
  zSchemaLtxVideo13bDevExtendOutput

export const zGetFalAiLtxVideoLoraMulticonditioningRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxVideoLoraMulticonditioningRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxVideoLoraMulticonditioningRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideoLoraMulticonditioningRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtxVideoLoraMulticonditioningData = z.object({
  body: zSchemaLtxVideoLoraMulticonditioningInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxVideoLoraMulticonditioningResponse =
  zSchemaQueueStatus

export const zGetFalAiLtxVideoLoraMulticonditioningRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideoLoraMulticonditioningRequestsByRequestIdResponse =
  zSchemaLtxVideoLoraMulticonditioningOutput

export const zGetFalAiMagiExtendVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiMagiExtendVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMagiExtendVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiMagiExtendVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiMagiExtendVideoData = z.object({
  body: zSchemaMagiExtendVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMagiExtendVideoResponse = zSchemaQueueStatus

export const zGetFalAiMagiExtendVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiMagiExtendVideoRequestsByRequestIdResponse =
  zSchemaMagiExtendVideoOutput

export const zGetFalAiMagiDistilledExtendVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiMagiDistilledExtendVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiMagiDistilledExtendVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiMagiDistilledExtendVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiMagiDistilledExtendVideoData = z.object({
  body: zSchemaMagiDistilledExtendVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiMagiDistilledExtendVideoResponse = zSchemaQueueStatus

export const zGetFalAiMagiDistilledExtendVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiMagiDistilledExtendVideoRequestsByRequestIdResponse =
  zSchemaMagiDistilledExtendVideoOutput

export const zGetFalAiWanVaceRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiWanVaceRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiWanVaceRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVaceRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiWanVaceData = z.object({
  body: zSchemaWanVaceInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiWanVaceResponse = zSchemaQueueStatus

export const zGetFalAiWanVaceRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiWanVaceRequestsByRequestIdResponse = zSchemaWanVaceOutput

export const zGetCassetteaiVideoSoundEffectsGeneratorRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetCassetteaiVideoSoundEffectsGeneratorRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutCassetteaiVideoSoundEffectsGeneratorRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutCassetteaiVideoSoundEffectsGeneratorRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostCassetteaiVideoSoundEffectsGeneratorData = z.object({
  body: zSchemaVideoSoundEffectsGeneratorInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostCassetteaiVideoSoundEffectsGeneratorResponse =
  zSchemaQueueStatus

export const zGetCassetteaiVideoSoundEffectsGeneratorRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetCassetteaiVideoSoundEffectsGeneratorRequestsByRequestIdResponse =
  zSchemaVideoSoundEffectsGeneratorOutput

export const zGetFalAiSyncLipsyncV2RequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiSyncLipsyncV2RequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSyncLipsyncV2RequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiSyncLipsyncV2RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSyncLipsyncV2Data = z.object({
  body: zSchemaSyncLipsyncV2Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSyncLipsyncV2Response = zSchemaQueueStatus

export const zGetFalAiSyncLipsyncV2RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSyncLipsyncV2RequestsByRequestIdResponse =
  zSchemaSyncLipsyncV2Output

export const zGetFalAiLatentsyncRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiLatentsyncRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLatentsyncRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiLatentsyncRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLatentsyncData = z.object({
  body: zSchemaLatentsyncInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLatentsyncResponse = zSchemaQueueStatus

export const zGetFalAiLatentsyncRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLatentsyncRequestsByRequestIdResponse =
  zSchemaLatentsyncOutput

export const zGetFalAiPikaV2PikadditionsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiPikaV2PikadditionsRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiPikaV2PikadditionsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV2PikadditionsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiPikaV2PikadditionsData = z.object({
  body: zSchemaPikaV2PikadditionsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiPikaV2PikadditionsResponse = zSchemaQueueStatus

export const zGetFalAiPikaV2PikadditionsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiPikaV2PikadditionsRequestsByRequestIdResponse =
  zSchemaPikaV2PikadditionsOutput

export const zGetFalAiLtxVideoV095MulticonditioningRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxVideoV095MulticonditioningRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxVideoV095MulticonditioningRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideoV095MulticonditioningRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiLtxVideoV095MulticonditioningData = z.object({
  body: zSchemaLtxVideoV095MulticonditioningInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxVideoV095MulticonditioningResponse =
  zSchemaQueueStatus

export const zGetFalAiLtxVideoV095MulticonditioningRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideoV095MulticonditioningRequestsByRequestIdResponse =
  zSchemaLtxVideoV095MulticonditioningOutput

export const zGetFalAiLtxVideoV095ExtendRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiLtxVideoV095ExtendRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiLtxVideoV095ExtendRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideoV095ExtendRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiLtxVideoV095ExtendData = z.object({
  body: zSchemaLtxVideoV095ExtendInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiLtxVideoV095ExtendResponse = zSchemaQueueStatus

export const zGetFalAiLtxVideoV095ExtendRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideoV095ExtendRequestsByRequestIdResponse =
  zSchemaLtxVideoV095ExtendOutput

export const zGetFalAiTopazUpscaleVideoRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  },
)

/**
 * The request status.
 */
export const zGetFalAiTopazUpscaleVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiTopazUpscaleVideoRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * The request was cancelled.
 */
export const zPutFalAiTopazUpscaleVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiTopazUpscaleVideoData = z.object({
  body: zSchemaTopazUpscaleVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiTopazUpscaleVideoResponse = zSchemaQueueStatus

export const zGetFalAiTopazUpscaleVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiTopazUpscaleVideoRequestsByRequestIdResponse =
  zSchemaTopazUpscaleVideoOutput

export const zGetFalAiBenV2VideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiBenV2VideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiBenV2VideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiBenV2VideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiBenV2VideoData = z.object({
  body: zSchemaBenV2VideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiBenV2VideoResponse = zSchemaQueueStatus

export const zGetFalAiBenV2VideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiBenV2VideoRequestsByRequestIdResponse =
  zSchemaBenV2VideoOutput

export const zGetFalAiHunyuanVideoVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiHunyuanVideoVideoToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiHunyuanVideoVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanVideoVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiHunyuanVideoVideoToVideoData = z.object({
  body: zSchemaHunyuanVideoVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiHunyuanVideoVideoToVideoResponse = zSchemaQueueStatus

export const zGetFalAiHunyuanVideoVideoToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanVideoVideoToVideoRequestsByRequestIdResponse =
  zSchemaHunyuanVideoVideoToVideoOutput

export const zGetFalAiHunyuanVideoLoraVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiHunyuanVideoLoraVideoToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiHunyuanVideoLoraVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanVideoLoraVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiHunyuanVideoLoraVideoToVideoData = z.object({
  body: zSchemaHunyuanVideoLoraVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiHunyuanVideoLoraVideoToVideoResponse = zSchemaQueueStatus

export const zGetFalAiHunyuanVideoLoraVideoToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanVideoLoraVideoToVideoRequestsByRequestIdResponse =
  zSchemaHunyuanVideoLoraVideoToVideoOutput

export const zGetFalAiFfmpegApiComposeRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiFfmpegApiComposeRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiFfmpegApiComposeRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiFfmpegApiComposeRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiFfmpegApiComposeData = z.object({
  body: zSchemaFfmpegApiComposeInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiFfmpegApiComposeResponse = zSchemaQueueStatus

export const zGetFalAiFfmpegApiComposeRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiFfmpegApiComposeRequestsByRequestIdResponse =
  zSchemaFfmpegApiComposeOutput

export const zGetFalAiSyncLipsyncRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiSyncLipsyncRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSyncLipsyncRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiSyncLipsyncRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSyncLipsyncData = z.object({
  body: zSchemaSyncLipsyncInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSyncLipsyncResponse = zSchemaQueueStatus

export const zGetFalAiSyncLipsyncRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSyncLipsyncRequestsByRequestIdResponse =
  zSchemaSyncLipsyncOutput

export const zGetFalAiAutoCaptionRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiAutoCaptionRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiAutoCaptionRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiAutoCaptionRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiAutoCaptionData = z.object({
  body: zSchemaAutoCaptionInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiAutoCaptionResponse = zSchemaQueueStatus

export const zGetFalAiAutoCaptionRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiAutoCaptionRequestsByRequestIdResponse =
  zSchemaAutoCaptionOutput

export const zGetFalAiDubbingRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiDubbingRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiDubbingRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiDubbingRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiDubbingData = z.object({
  body: zSchemaDubbingInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiDubbingResponse = zSchemaQueueStatus

export const zGetFalAiDubbingRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiDubbingRequestsByRequestIdResponse = zSchemaDubbingOutput

export const zGetFalAiVideoUpscalerRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiVideoUpscalerRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiVideoUpscalerRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiVideoUpscalerRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiVideoUpscalerData = z.object({
  body: zSchemaVideoUpscalerInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiVideoUpscalerResponse = zSchemaQueueStatus

export const zGetFalAiVideoUpscalerRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiVideoUpscalerRequestsByRequestIdResponse =
  zSchemaVideoUpscalerOutput

export const zGetFalAiCogvideox5bVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiCogvideox5bVideoToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiCogvideox5bVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiCogvideox5bVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiCogvideox5bVideoToVideoData = z.object({
  body: zSchemaCogvideox5bVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiCogvideox5bVideoToVideoResponse = zSchemaQueueStatus

export const zGetFalAiCogvideox5bVideoToVideoRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  },
)

/**
 * Result of the request.
 */
export const zGetFalAiCogvideox5bVideoToVideoRequestsByRequestIdResponse =
  zSchemaCogvideox5bVideoToVideoOutput

export const zGetFalAiControlnextRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiControlnextRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiControlnextRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiControlnextRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiControlnextData = z.object({
  body: zSchemaControlnextInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiControlnextResponse = zSchemaQueueStatus

export const zGetFalAiControlnextRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiControlnextRequestsByRequestIdResponse =
  zSchemaControlnextOutput

export const zGetFalAiSam2VideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiSam2VideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiSam2VideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiSam2VideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiSam2VideoData = z.object({
  body: zSchemaSam2VideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiSam2VideoResponse = zSchemaQueueStatus

export const zGetFalAiSam2VideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiSam2VideoRequestsByRequestIdResponse =
  zSchemaSam2VideoOutput

export const zGetFalAiAmtInterpolationRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            'Whether to include logs (`1`) in the response or not (`0`).',
        }),
      ),
    }),
  ),
})

/**
 * The request status.
 */
export const zGetFalAiAmtInterpolationRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiAmtInterpolationRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * The request was cancelled.
 */
export const zPutFalAiAmtInterpolationRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether the request was cancelled successfully.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'The request was cancelled.',
  })

export const zPostFalAiAmtInterpolationData = z.object({
  body: zSchemaAmtInterpolationInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiAmtInterpolationResponse = zSchemaQueueStatus

export const zGetFalAiAmtInterpolationRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: 'Request ID',
    }),
  }),
  query: z.optional(z.never()),
})

/**
 * Result of the request.
 */
export const zGetFalAiAmtInterpolationRequestsByRequestIdResponse =
  zSchemaAmtInterpolationOutput

export const zGetFalAiFastAnimatediffTurboVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiFastAnimatediffTurboVideoToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiFastAnimatediffTurboVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiFastAnimatediffTurboVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiFastAnimatediffTurboVideoToVideoData = z.object({
  body: zSchemaFastAnimatediffTurboVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiFastAnimatediffTurboVideoToVideoResponse =
  zSchemaQueueStatus

export const zGetFalAiFastAnimatediffTurboVideoToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiFastAnimatediffTurboVideoToVideoRequestsByRequestIdResponse =
  zSchemaFastAnimatediffTurboVideoToVideoOutput

export const zGetFalAiFastAnimatediffVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              'Whether to include logs (`1`) in the response or not (`0`).',
          }),
        ),
      }),
    ),
  })

/**
 * The request status.
 */
export const zGetFalAiFastAnimatediffVideoToVideoRequestsByRequestIdStatusResponse =
  zSchemaQueueStatus

export const zPutFalAiFastAnimatediffVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * The request was cancelled.
 */
export const zPutFalAiFastAnimatediffVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Whether the request was cancelled successfully.',
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: 'The request was cancelled.',
    })

export const zPostFalAiFastAnimatediffVideoToVideoData = z.object({
  body: zSchemaFastAnimatediffVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
})

/**
 * The request status.
 */
export const zPostFalAiFastAnimatediffVideoToVideoResponse = zSchemaQueueStatus

export const zGetFalAiFastAnimatediffVideoToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: 'Request ID',
      }),
    }),
    query: z.optional(z.never()),
  })

/**
 * Result of the request.
 */
export const zGetFalAiFastAnimatediffVideoToVideoRequestsByRequestIdResponse =
  zSchemaFastAnimatediffVideoToVideoOutput
