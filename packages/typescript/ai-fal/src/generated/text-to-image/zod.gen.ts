// This file is auto-generated by @hey-api/openapi-ts

import { z } from 'zod'

export const zFile = z.object({
  url: z.url(),
  content_type: z.optional(z.string()),
  file_name: z.optional(z.string()),
  file_size: z.optional(z.int()),
})

export const zQueueStatus = z.object({
  status: z.enum(['IN_PROGRESS', 'COMPLETED', 'FAILED']),
  response_url: z.optional(z.url()),
})

/**
 * FluxProUltraTextToImageInput
 */
export const zFluxProV11UltraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  aspect_ratio: z.optional(
    z.union([
      z.enum([
        '21:9',
        '16:9',
        '4:3',
        '3:2',
        '1:1',
        '2:3',
        '3:4',
        '9:16',
        '9:21',
      ]),
      z.string(),
    ]),
  ),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enhance the prompt for better results.',
      }),
    )
    .default(false),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The image URL to generate an image from.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.',
    }),
  ),
  image_prompt_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The strength of the image prompt, between 0 and 1.',
      }),
    )
    .default(0.1),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  raw: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Generate less processed, more natural-looking images.',
      }),
    )
    .default(false),
})

/**
 * Image
 */
export const zRegistryImageFastSdxlModelsImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxProV11UltraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zRegistryImageFastSdxlModelsImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * RGBColor
 */
export const zRgbColor = z.object({
  r: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Red color value',
      }),
    )
    .default(0),
  b: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Blue color value',
      }),
    )
    .default(0),
  g: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Green color value',
      }),
    )
    .default(0),
})

/**
 * TextToImageInput
 */
export const zRecraftV3TextToImageInput = z.object({
  prompt: z.string().min(1).max(1000),
  image_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  style: z.optional(
    z
      .enum([
        'any',
        'realistic_image',
        'digital_illustration',
        'vector_illustration',
        'realistic_image/b_and_w',
        'realistic_image/hard_flash',
        'realistic_image/hdr',
        'realistic_image/natural_light',
        'realistic_image/studio_portrait',
        'realistic_image/enterprise',
        'realistic_image/motion_blur',
        'realistic_image/evening_light',
        'realistic_image/faded_nostalgia',
        'realistic_image/forest_life',
        'realistic_image/mystic_naturalism',
        'realistic_image/natural_tones',
        'realistic_image/organic_calm',
        'realistic_image/real_life_glow',
        'realistic_image/retro_realism',
        'realistic_image/retro_snapshot',
        'realistic_image/urban_drama',
        'realistic_image/village_realism',
        'realistic_image/warm_folk',
        'digital_illustration/pixel_art',
        'digital_illustration/hand_drawn',
        'digital_illustration/grain',
        'digital_illustration/infantile_sketch',
        'digital_illustration/2d_art_poster',
        'digital_illustration/handmade_3d',
        'digital_illustration/hand_drawn_outline',
        'digital_illustration/engraving_color',
        'digital_illustration/2d_art_poster_2',
        'digital_illustration/antiquarian',
        'digital_illustration/bold_fantasy',
        'digital_illustration/child_book',
        'digital_illustration/child_books',
        'digital_illustration/cover',
        'digital_illustration/crosshatch',
        'digital_illustration/digital_engraving',
        'digital_illustration/expressionism',
        'digital_illustration/freehand_details',
        'digital_illustration/grain_20',
        'digital_illustration/graphic_intensity',
        'digital_illustration/hard_comics',
        'digital_illustration/long_shadow',
        'digital_illustration/modern_folk',
        'digital_illustration/multicolor',
        'digital_illustration/neon_calm',
        'digital_illustration/noir',
        'digital_illustration/nostalgic_pastel',
        'digital_illustration/outline_details',
        'digital_illustration/pastel_gradient',
        'digital_illustration/pastel_sketch',
        'digital_illustration/pop_art',
        'digital_illustration/pop_renaissance',
        'digital_illustration/street_art',
        'digital_illustration/tablet_sketch',
        'digital_illustration/urban_glow',
        'digital_illustration/urban_sketching',
        'digital_illustration/vanilla_dreams',
        'digital_illustration/young_adult_book',
        'digital_illustration/young_adult_book_2',
        'vector_illustration/bold_stroke',
        'vector_illustration/chemistry',
        'vector_illustration/colored_stencil',
        'vector_illustration/contour_pop_art',
        'vector_illustration/cosmics',
        'vector_illustration/cutout',
        'vector_illustration/depressive',
        'vector_illustration/editorial',
        'vector_illustration/emotional_flat',
        'vector_illustration/infographical',
        'vector_illustration/marker_outline',
        'vector_illustration/mosaic',
        'vector_illustration/naivector',
        'vector_illustration/roundish_flat',
        'vector_illustration/segmented_colors',
        'vector_illustration/sharp_contrast',
        'vector_illustration/thin',
        'vector_illustration/vector_photo',
        'vector_illustration/vivid_shapes',
        'vector_illustration/engraving',
        'vector_illustration/line_art',
        'vector_illustration/line_circuit',
        'vector_illustration/linocut',
      ])
      .register(z.globalRegistry, {
        description:
          'The style of the generated images. Vector images cost 2X as much.',
      }),
  ),
  colors: z
    .optional(
      z.array(zRgbColor).register(z.globalRegistry, {
        description: 'An array of preferable colors',
      }),
    )
    .default([]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  style_id: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The ID of the custom style reference (optional)',
    }),
  ),
})

/**
 * File
 */
export const zFalAiRecraftV3TextToImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * TextToImageOutput
 */
export const zRecraftV3TextToImageOutput = z.object({
  images: z.array(zFalAiRecraftV3TextToImageFile),
})

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export const zLoRaInput = z
  .object({
    path: z.string().register(z.globalRegistry, {
      description:
        'URL, HuggingFace repo ID (owner/repo), or local path to LoRA weights.',
    }),
    scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description: 'Scale factor for LoRA application (0.0 to 4.0).',
        }),
      )
      .default(1),
  })
  .register(z.globalRegistry, {
    description: 'LoRA weight configuration.',
  })

/**
 * ImageFile
 */
export const zImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Flux2T2ILoRAOutput
 */
export const zFlux2LoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zImageFile).register(z.globalRegistry, {
    description: 'The generated images',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * ImageSize
 */
export const zFalAiFlux2ImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Flux2TextToImageInput
 */
export const zFlux2Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFlux2ImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use for the image generation.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          'Guidance Scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(2.5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The seed to use for the generation. If not provided, a random seed will be used.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded for better results.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(4).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * ImageFile
 */
export const zFalAiFlux2ImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Flux2T2IOutput
 */
export const zFlux2Output = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFlux2ImageFile).register(z.globalRegistry, {
    description: 'The generated images',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * ImageSize
 */
export const zFalAiFlux2ProImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Flux2ProTextToImageInput
 */
export const zFlux2ProInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiFlux2ProImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for the generation.',
    }),
  ),
})

/**
 * ImageFile
 */
export const zFalAiFlux2ProImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Flux2ProOutput
 */
export const zFlux2ProOutput = z.object({
  images: z.array(zFalAiFlux2ProImageFile).register(z.globalRegistry, {
    description: 'The generated images.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the generation.',
  }),
})

/**
 * InputModel
 */
export const zTextToImage32Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Prompt for image generation.',
  }),
  aspect_ratio: z.optional(
    z
      .enum(['1:1', '2:3', '3:2', '3:4', '4:3', '4:5', '5:4', '9:16', '16:9'])
      .register(z.globalRegistry, {
        description:
          'Aspect ratio. Options: 1:1, 2:3, 3:2, 3:4, 4:3, 4:5, 5:4, 9:16, 16:9',
      }),
  ),
  prompt_enhancer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to improve the prompt.',
      }),
    )
    .default(true),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, returns the image directly in the response (increases latency).',
      }),
    )
    .default(false),
  truncate_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to truncate the prompt.',
      }),
    )
    .default(true),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Guidance scale for text.',
      }),
    )
    .default(5),
  num_inference_steps: z
    .optional(
      z.int().gte(20).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps.',
      }),
    )
    .default(30),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Random seed for reproducibility.',
      }),
    )
    .default(5555),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for image generation.',
      }),
    )
    .default(
      'Logo,Watermark,Ugly,Morbid,Extra fingers,Poorly drawn hands,Mutation,Blurry,Extra limbs,Gross proportions,Missing arms,Mutated hands,Long neck,Duplicate,Mutilated,Mutilated hands,Poorly drawn face,Deformed,Bad anatomy,Cloned face,Malformed limbs,Missing legs,Too many fingers',
    ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * OutputModel
 */
export const zTextToImage32Output = z.object({
  image: zImage,
})

/**
 * Imagen4TextToImageFastInput
 */
export const zImagen4PreviewFastInput = z.object({
  prompt: z.string().min(3).max(5000).register(z.globalRegistry, {
    description: 'The text prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  aspect_ratio: z.optional(
    z.enum(['1:1', '16:9', '9:16', '4:3', '3:4']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
})

/**
 * ImageFile
 */
export const zFalAiImagen4PreviewFastImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Imagen4TextToImageFastOutput
 */
export const zImagen4PreviewFastOutput = z.object({
  images: z
    .array(zFalAiImagen4PreviewFastImageFile)
    .register(z.globalRegistry, {
      description: 'The generated images.',
    }),
  description: z.string().register(z.globalRegistry, {
    description: 'The description of the generated images.',
  }),
})

/**
 * Imagen4TextToImageInput
 */
export const zImagen4PreviewInput = z.object({
  prompt: z.string().min(3).max(5000).register(z.globalRegistry, {
    description: 'The text prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  aspect_ratio: z.optional(
    z.enum(['1:1', '16:9', '9:16', '4:3', '3:4']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated image.',
    }),
  ),
  resolution: z.optional(
    z.enum(['1K', '2K']).register(z.globalRegistry, {
      description: 'The resolution of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
})

/**
 * ImageFile
 */
export const zFalAiImagen4PreviewImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Imagen4TextToImageOutput
 */
export const zImagen4PreviewOutput = z.object({
  images: z.array(zFalAiImagen4PreviewImageFile).register(z.globalRegistry, {
    description: 'The generated images.',
  }),
  description: z.string().register(z.globalRegistry, {
    description: 'The description of the generated images.',
  }),
})

/**
 * ImageSize
 */
export const zFalAiHidreamI1FullImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
  weight_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'Name of the LoRA weight. Used only if `path` is a Hugging Face repository, and required only if you have more than 1 safetensors file in the repo.',
    }),
  ),
})

/**
 * TextToImageInput
 */
export const zHidreamI1FullInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiHidreamI1FullImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zLoraWeight).register(z.globalRegistry, {
        description:
          'A list of LoRAs to apply to the model. Each LoRA specifies its path, scale, and optional weight name.',
      }),
    )
    .default([]),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(50),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

export const zHidreamI1FullOutput = z.unknown()

/**
 * ImageSize
 */
export const zFalAiHidreamI1DevImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * DevInput
 */
export const zHidreamI1DevInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiHidreamI1DevImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
})

/**
 * Image
 */
export const zFalAiHidreamI1DevImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zHidreamI1DevOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiHidreamI1DevImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiHidreamI1FastImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * FastInput
 */
export const zHidreamI1FastInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiHidreamI1FastImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(16),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
})

/**
 * Image
 */
export const zFalAiHidreamI1FastImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zHidreamI1FastOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiHidreamI1FastImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFluxDevImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * BaseInput
 */
export const zFluxDevInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFluxDevImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        'The speed of the generation. The higher the speed, the faster the generation.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
})

/**
 * Image
 */
export const zFalAiFluxDevImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxDevOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFluxDevImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * TextToImageInput
 */
export const zIdeogramV2Input = z.object({
  prompt: z.string(),
  aspect_ratio: z.optional(
    z
      .enum([
        '10:16',
        '16:10',
        '9:16',
        '16:9',
        '4:3',
        '3:4',
        '1:1',
        '1:3',
        '3:1',
        '3:2',
        '2:3',
      ])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image',
      }),
  ),
  style: z.optional(
    z
      .enum(['auto', 'general', 'realistic', 'design', 'render_3D', 'anime'])
      .register(z.globalRegistry, {
        description: 'The style of the generated image',
      }),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to expand the prompt with MagicPrompt functionality.',
      }),
    )
    .default(true),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'A negative prompt to avoid in the generated image',
      }),
    )
    .default(''),
})

/**
 * File
 */
export const zFalAiIdeogramV2File = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * Output
 */
export const zIdeogramV2Output = z.object({
  images: z.array(zFalAiIdeogramV2File),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for the random number generator',
  }),
})

/**
 * ImageSize
 */
export const zFalAiStableDiffusionV35LargeImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * ControlNet
 */
export const zControlNet = z.object({
  conditioning_scale: z
    .optional(
      z.number().gte(0).lte(2).register(z.globalRegistry, {
        description:
          '\n            The scale of the control net weight. This is used to scale the control net weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the control net weights.',
  }),
  control_image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to be used as the control image.',
  }),
  start_percentage: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The percentage of the image to start applying the controlnet in terms of the total timesteps.\n        ',
      }),
    )
    .default(0),
  end_percentage: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The percentage of the image to end applying the controlnet in terms of the total timesteps.\n        ',
      }),
    )
    .default(1),
})

/**
 * IPAdapter
 */
export const zIpAdapter = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'Hugging Face path to the IP-Adapter',
  }),
  mask_threshold: z
    .optional(
      z.number().gte(0.01).lte(0.99).register(z.globalRegistry, {
        description: 'Threshold for mask.',
      }),
    )
    .default(0.5),
  image_encoder_weight_name: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'Name of the image encoder.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of Image for IP-Adapter conditioning. ',
  }),
  mask_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'URL of the mask for the control image.',
    }),
  ),
  image_encoder_subfolder: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'Subfolder in which the image encoder weights exist.',
    }),
  ),
  subfolder: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'Subfolder in which the ip_adapter weights exist',
    }),
  ),
  scale: z.number().register(z.globalRegistry, {
    description: 'Scale for ip adapter.',
  }),
  image_encoder_path: z.string().register(z.globalRegistry, {
    description:
      "Path to the Image Encoder for the IP-Adapter, for example 'openai/clip-vit-large-patch14'",
  }),
  weight_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'Name of the safetensors file containing the ip-adapter weights',
    }),
  ),
})

/**
 * LoraWeight
 */
export const zFalAiStableDiffusionV35LargeLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * TextToImageInput
 */
export const zStableDiffusionV35LargeInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiStableDiffusionV35LargeImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  controlnet: z.optional(zControlNet),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  ip_adapter: z.optional(zIpAdapter),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  loras: z
    .optional(
      z
        .array(zFalAiStableDiffusionV35LargeLoraWeight)
        .register(z.globalRegistry, {
          description:
            '\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ',
        }),
    )
    .default([]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiStableDiffusionV35LargeImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zStableDiffusionV35LargeOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiStableDiffusionV35LargeImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * ControlNetUnionInput
 */
export const zControlNetUnionInput = z.object({
  conditioning_scale: z
    .optional(
      z.number().gte(0).lte(2).register(z.globalRegistry, {
        description:
          '\n            The scale of the control net weight. This is used to scale the control net weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
  mask_threshold: z
    .optional(
      z.number().gte(0.01).lte(0.99).register(z.globalRegistry, {
        description: 'Threshold for mask.',
      }),
    )
    .default(0.5),
  end_percentage: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The percentage of the image to end applying the controlnet in terms of the total timesteps.\n        ',
      }),
    )
    .default(1),
  mask_image_url: z.optional(z.union([z.string(), z.null()])),
  control_image_url: z.string().register(z.globalRegistry, {
    description: 'URL of the image to be used as the control image.',
  }),
  control_mode: z
    .enum(['canny', 'tile', 'depth', 'blur', 'pose', 'gray', 'low-quality'])
    .register(z.globalRegistry, {
      description:
        'Control Mode for Flux Controlnet Union. Supported values are:\n        - canny: Uses the edges for guided generation.\n        - tile: Uses the tiles for guided generation.\n        - depth: Utilizes a grayscale depth map for guided generation.\n        - blur: Adds a blur to the image.\n        - pose: Uses the pose of the image for guided generation.\n        - gray: Converts the image to grayscale.\n        - low-quality: Converts the image to a low-quality image.',
    }),
  start_percentage: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The percentage of the image to start applying the controlnet in terms of the total timesteps.\n        ',
      }),
    )
    .default(0),
})

/**
 * Image
 */
export const zFalAiFluxGeneralImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxGeneralOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFluxGeneralImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFluxLoraImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zFalAiFluxLoraLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * TextToImageInput
 */
export const zFluxLoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description:
          'The number of images to generate. This is always set to 1 for streaming output.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFluxLoraImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  loras: z
    .optional(
      z.array(zFalAiFluxLoraLoraWeight).register(z.globalRegistry, {
        description:
          '\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ',
      }),
    )
    .default([]),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(35).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zFalAiFluxLoraImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFluxLoraImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * LoRAInput
 */
export const zFalAiFlux2KleinLoRaInput = z.object({
  path: z.string().register(z.globalRegistry, {
    description:
      'URL, HuggingFace repo ID (owner/repo), or local path to LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description: 'Scale factor for LoRA application (0.0 to 4.0).',
      }),
    )
    .default(1),
})

/**
 * ImageFile
 */
export const zFalAiFlux2Klein9bBaseLoraImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * KleinT2IOutput
 */
export const zFlux2Klein9bBaseLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFlux2Klein9bBaseLoraImageFile)
    .register(z.globalRegistry, {
      description: 'The generated images',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * LoRAInput
 */
export const zFalAiFlux2Klein4bBaseLoraFalAiFlux2KleinLoRaInput = z.object({
  path: z.string().register(z.globalRegistry, {
    description:
      'URL, HuggingFace repo ID (owner/repo), or local path to LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description: 'Scale factor for LoRA application (0.0 to 4.0).',
      }),
    )
    .default(1),
})

/**
 * ImageFile
 */
export const zFalAiFlux2Klein4bBaseLoraImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * KleinT2IOutput
 */
export const zFlux2Klein4bBaseLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFlux2Klein4bBaseLoraImageFile)
    .register(z.globalRegistry, {
      description: 'The generated images',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux2Klein9bBaseImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Klein9BBaseInput
 */
export const zFlux2Klein9bBaseInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFlux2Klein9bBaseImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use for image generation.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If `True`, the media will be returned as a data URI. Output is not stored when this is True.',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(4).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The seed to use for the generation. If not provided, a random seed will be used.',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Negative prompt for classifier-free guidance. Describes what to avoid in the image.',
      }),
    )
    .default(''),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description: 'Guidance scale for classifier-free guidance.',
      }),
    )
    .default(5),
})

/**
 * ImageFile
 */
export const zFalAiFlux2Klein9bBaseImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Klein9BT2IOutput
 */
export const zFlux2Klein9bBaseOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFlux2Klein9bBaseImageFile).register(z.globalRegistry, {
    description: 'The generated images',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux2Klein4bBaseImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Klein4BBaseInput
 */
export const zFlux2Klein4bBaseInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFlux2Klein4bBaseImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use for image generation.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If `True`, the media will be returned as a data URI. Output is not stored when this is True.',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(4).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The seed to use for the generation. If not provided, a random seed will be used.',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Negative prompt for classifier-free guidance. Describes what to avoid in the image.',
      }),
    )
    .default(''),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description: 'Guidance scale for classifier-free guidance.',
      }),
    )
    .default(5),
})

/**
 * ImageFile
 */
export const zFalAiFlux2Klein4bBaseImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Klein4BT2IOutput
 */
export const zFlux2Klein4bBaseOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFlux2Klein4bBaseImageFile).register(z.globalRegistry, {
    description: 'The generated images',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux2Klein9bImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Klein9BDistilledInput
 */
export const zFlux2Klein9bInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFlux2Klein9bImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If `True`, the media will be returned as a data URI. Output is not stored when this is True.',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(4).lte(8).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(4),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The seed to use for the generation. If not provided, a random seed will be used.',
    }),
  ),
})

/**
 * ImageFile
 */
export const zFalAiFlux2Klein9bImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Klein9BDistilledT2IOutput
 */
export const zFlux2Klein9bOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFlux2Klein9bImageFile).register(z.globalRegistry, {
    description: 'The generated images',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux2Klein4bImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * KleinDistilledInput
 */
export const zFlux2Klein4bInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFlux2Klein4bImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If `True`, the media will be returned as a data URI. Output is not stored when this is True.',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(4).lte(8).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(4),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The seed to use for the generation. If not provided, a random seed will be used.',
    }),
  ),
})

/**
 * ImageFile
 */
export const zFalAiFlux2Klein4bImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Klein4BDistilledT2IOutput
 */
export const zFlux2Klein4bOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFlux2Klein4bImageFile).register(z.globalRegistry, {
    description: 'The generated images',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImagineArt_1_5_Input
 */
export const zImagineart15ProPreviewTextToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt describing the desired image',
  }),
  aspect_ratio: z.optional(
    z
      .enum(['1:1', '16:9', '9:16', '4:3', '3:4', '3:1', '1:3', '3:2', '2:3'])
      .register(z.globalRegistry, {
        description:
          'Image aspect ratio: 1:1, 3:1, 1:3, 16:9, 9:16, 4:3, 3:4, 3:2, 2:3',
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Seed for the image generation',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zImagineartImagineart15ProPreviewTextToImageImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ImagineArt_1_5_Output
 */
export const zImagineart15ProPreviewTextToImageOutput = z.object({
  images: z
    .array(zImagineartImagineart15ProPreviewTextToImageImage)
    .register(z.globalRegistry, {
      description: 'Generated image',
    }),
})

/**
 * ImageSize
 */
export const zFalAiGlmImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * GlmImageInput
 */
export const zGlmImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt for image generation.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'Number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiGlmImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
        'portrait_3_2',
        'landscape_3_2',
        'portrait_hd',
        'landscape_hd',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'Output image format.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If True, the image will be returned as a base64 data URI instead of a URL.',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values make the model follow the prompt more closely.',
      }),
    )
    .default(1.5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. The same seed with the same prompt will produce the same image.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If True, the prompt will be enhanced using an LLM for more detailed and higher quality results.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(10).lte(100).register(z.globalRegistry, {
        description:
          'Number of diffusion denoising steps. More steps generally produce higher quality images.',
      }),
    )
    .default(30),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable NSFW safety checking on the generated images.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zFalAiGlmImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * GlmImageOutput
 */
export const zGlmImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiGlmImageImage).register(z.globalRegistry, {
    description: 'List of URLs to the generated images.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * ImageSize
 */
export const zFalAiQwenImage2512LoraImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zFalAiQwenImage2512LoraLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * LoraInput
 */
export const zQwenImage2512LoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  image_size: z.optional(
    z.union([
      zFalAiQwenImage2512LoraImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  loras: z
    .optional(
      z.array(zFalAiQwenImage2512LoraLoraWeight).register(z.globalRegistry, {
        description:
          '\n            The LoRAs to use for the image generation. You can use up to 3 LoRAs\n            and they will be merged together to generate the final image.\n        ',
      }),
    )
    .default([]),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description: 'The guidance scale to use for the image generation.',
      }),
    )
    .default(4),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate an image from.',
      }),
    )
    .default(''),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
})

/**
 * Image
 */
export const zFalAiQwenImage2512LoraImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * QwenImage2512Output
 */
export const zQwenImage2512LoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiQwenImage2512LoraImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImage2512ImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * TextToImageInput
 */
export const zQwenImage2512Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  image_size: z.optional(
    z.union([
      zFalAiQwenImage2512ImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description: 'The guidance scale to use for the image generation.',
      }),
    )
    .default(4),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate an image from.',
      }),
    )
    .default(''),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
})

/**
 * Image
 */
export const zFalAiQwenImage2512Image = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * QwenImage2512Output
 */
export const zQwenImage2512Output = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiQwenImage2512Image).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zWanV26TextToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * TextToImageWanInput
 *
 * Input for Wan 2.6 text-to-image or mixed text-and-image generation (enable_interleave=true)
 */
export const zV26TextToImageInput = z
  .object({
    prompt: z.string().min(1).register(z.globalRegistry, {
      description:
        'Text prompt describing the desired image. Supports Chinese and English. Max 2000 characters.',
    }),
    image_size: z.optional(
      z.union([
        zWanV26TextToImageImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
      ]),
    ),
    max_images: z
      .optional(
        z.int().gte(1).lte(5).register(z.globalRegistry, {
          description:
            'Maximum number of images to generate (1-5). Actual count may be less depending on model inference.',
        }),
      )
      .default(1),
    image_url: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'Optional reference image (0 or 1). When provided, can be used for style guidance. Resolution: 384-5000px each dimension. Max size: 10MB. Formats: JPEG, JPG, PNG (no alpha), BMP, WEBP.',
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'Enable content moderation for input and output.',
        }),
      )
      .default(true),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'Random seed for reproducibility (0-2147483647).',
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            'Content to avoid in the generated image. Max 500 characters.',
        }),
      )
      .default(''),
  })
  .register(z.globalRegistry, {
    description:
      'Input for Wan 2.6 text-to-image or mixed text-and-image generation (enable_interleave=true)',
  })

/**
 * File
 */
export const zWanV26TextToImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * TextToImageWanOutput
 *
 * Output for Wan 2.6 text-to-image (can include generated text in mixed mode)
 */
export const zV26TextToImageOutput = z
  .object({
    images: z.array(zWanV26TextToImageFile).register(z.globalRegistry, {
      description: 'Generated images in PNG format',
    }),
    seed: z.int().register(z.globalRegistry, {
      description: 'The seed used for generation',
    }),
    generated_text: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'Generated text content (in mixed text-and-image mode). May be None if only images were generated.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description:
      'Output for Wan 2.6 text-to-image (can include generated text in mixed mode)',
  })

/**
 * ImageSize
 */
export const zFalAiFlux2FlashImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Flux2FlashTextToImageInput
 */
export const zFlux2FlashInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFlux2FlashImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          'Guidance Scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(2.5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The seed to use for the generation. If not provided, a random seed will be used.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded for better results.',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * ImageFile
 */
export const zFalAiFlux2FlashImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Flux2FlashT2IOutput
 */
export const zFlux2FlashOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFlux2FlashImageFile).register(z.globalRegistry, {
    description: 'The generated images',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * TextToImageRequest
 */
export const zGptImage15Input = z.object({
  prompt: z.string().min(2).register(z.globalRegistry, {
    description: 'The prompt for image generation',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'Number of images to generate',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.enum(['1024x1024', '1536x1024', '1024x1536']).register(z.globalRegistry, {
      description: 'Aspect ratio for the generated image',
    }),
  ),
  background: z.optional(
    z.enum(['auto', 'transparent', 'opaque']).register(z.globalRegistry, {
      description: 'Background for the generated image',
    }),
  ),
  quality: z.optional(
    z.enum(['low', 'medium', 'high']).register(z.globalRegistry, {
      description: 'Quality for the generated image',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'Output format for the images',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
})

/**
 * ImageFile
 */
export const zFalAiGptImage15ImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ImageResponse
 */
export const zGptImage15Output = z.object({
  images: z.array(zFalAiGptImage15ImageFile).register(z.globalRegistry, {
    description: 'The generated images.',
  }),
})

/**
 * PromptObject
 */
export const zPromptObject = z.object({
  relative_size: z.optional(z.union([z.string(), z.unknown()])),
  description: z.optional(z.union([z.string(), z.unknown()])),
  skin_tone_and_texture: z.optional(z.union([z.string(), z.unknown()])),
  appearance_details: z.optional(z.union([z.string(), z.unknown()])),
  number_of_objects: z.optional(z.union([z.int(), z.unknown()])),
  pose: z.optional(z.union([z.string(), z.unknown()])),
  expression: z.optional(z.union([z.string(), z.unknown()])),
  shape_and_color: z.optional(z.union([z.string(), z.unknown()])),
  relationship: z.string().register(z.globalRegistry, {
    description:
      'The relationship of the object to other objects in the image.',
  }),
  texture: z.optional(z.union([z.string(), z.unknown()])),
  gender: z.optional(z.union([z.string(), z.unknown()])),
  clothing: z.optional(z.union([z.string(), z.unknown()])),
  location: z.optional(z.union([z.string(), z.unknown()])),
  orientation: z.optional(z.union([z.string(), z.unknown()])),
  action: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * PhotographicCharacteristics
 */
export const zPhotographicCharacteristics = z.object({
  focus: z.optional(z.union([z.string(), z.unknown()])),
  lens_focal_length: z.optional(z.union([z.string(), z.unknown()])),
  camera_angle: z.optional(z.union([z.string(), z.unknown()])),
  depth_of_field: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * Aesthetics
 */
export const zAesthetics = z.object({
  composition: z.optional(z.union([z.string(), z.unknown()])),
  mood_atmosphere: z.optional(z.union([z.string(), z.unknown()])),
  color_scheme: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * Lighting
 */
export const zLighting = z.object({
  shadows: z.optional(z.union([z.string(), z.unknown()])),
  conditions: z.optional(z.union([z.string(), z.unknown()])),
  direction: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * StructuredPrompt
 */
export const zStructuredPrompt = z.object({
  background_setting: z.optional(z.union([z.string(), z.unknown()])),
  artistic_style: z.optional(z.union([z.string(), z.unknown()])),
  context: z.optional(z.union([z.string(), z.unknown()])),
  text_render: z.optional(z.union([z.array(z.unknown()), z.unknown()])),
  objects: z.optional(z.union([z.array(zPromptObject), z.unknown()])),
  style_medium: z.optional(z.union([z.string(), z.unknown()])),
  photographic_characteristics: z.optional(
    z.union([zPhotographicCharacteristics, z.unknown()]),
  ),
  aesthetics: z.optional(z.union([zAesthetics, z.unknown()])),
  lighting: z.optional(z.union([zLighting, z.unknown()])),
  short_description: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * GaiaLiteInputModel
 */
export const zFiboLiteGenerateInput = z.object({
  prompt: z.optional(z.union([z.string(), z.unknown()])),
  steps_num: z
    .optional(
      z.int().gte(4).lte(30).register(z.globalRegistry, {
        description: 'Number of inference steps for Fibo Lite.',
      }),
    )
    .default(8),
  aspect_ratio: z.optional(
    z
      .enum(['1:1', '2:3', '3:2', '3:4', '4:3', '4:5', '5:4', '9:16', '16:9'])
      .register(z.globalRegistry, {
        description:
          'Aspect ratio. Options: 1:1, 2:3, 3:2, 3:4, 4:3, 4:5, 5:4, 9:16, 16:9',
      }),
  ),
  image_url: z.optional(z.union([z.string(), z.unknown()])),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, returns the image directly in the response (increases latency).',
      }),
    )
    .default(false),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Random seed for reproducibility.',
      }),
    )
    .default(5555),
  structured_prompt: z.optional(z.union([zStructuredPrompt, z.unknown()])),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaFiboLiteGenerateImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * GaiaOutputModel
 */
export const zFiboLiteGenerateOutput = z.object({
  images: z
    .optional(
      z.array(z.record(z.string(), z.unknown())).register(z.globalRegistry, {
        description: 'Generated images.',
      }),
    )
    .default([]),
  image: zBriaFiboLiteGenerateImage,
  structured_prompt: z
    .record(z.string(), z.unknown())
    .register(z.globalRegistry, {
      description: 'Current prompt.',
    }),
})

/**
 * ImageSize
 */
export const zFalAiFlux2TurboImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Flux2TurboTextToImageInput
 */
export const zFlux2TurboInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFlux2TurboImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          'Guidance Scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(2.5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The seed to use for the generation. If not provided, a random seed will be used.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded for better results.',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * ImageFile
 */
export const zFalAiFlux2TurboImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Flux2TurboT2IOutput
 */
export const zFlux2TurboOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFlux2TurboImageFile).register(z.globalRegistry, {
    description: 'The generated images',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * ImageSize
 */
export const zFalAiFlux2MaxImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Flux2MaxTextToImageInput
 */
export const zFlux2MaxInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiFlux2MaxImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for the generation.',
    }),
  ),
})

/**
 * ImageFile
 */
export const zFalAiFlux2MaxImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Flux2MaxOutput
 */
export const zFlux2MaxOutput = z.object({
  images: z.array(zFalAiFlux2MaxImageFile).register(z.globalRegistry, {
    description: 'The generated images.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the generation.',
  }),
})

/**
 * ImageSize
 */
export const zFalAiLongcatImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * TextToImageInput
 */
export const zLongcatImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  image_size: z.optional(
    z.union([
      zFalAiLongcatImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description: 'The guidance scale to use for the image generation.',
      }),
    )
    .default(4.5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiLongcatImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * TextToImageOutput
 */
export const zLongcatImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiLongcatImageImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiBytedanceSeedreamV45TextToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * SeedDream45T2IInput
 */
export const zBytedanceSeedreamV45TextToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt used to generate the image',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(6).register(z.globalRegistry, {
        description:
          'Number of separate model generations to be run with the prompt.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiBytedanceSeedreamV45TextToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
        'auto_2K',
        'auto_4K',
      ]),
    ]),
  ),
  max_images: z
    .optional(
      z.int().gte(1).lte(6).register(z.globalRegistry, {
        description:
          'If set to a number greater than one, enables multi-image generation. The model will potentially return up to `max_images` images every generation, and in total, `num_images` generations will be carried out. In total, the number of images generated will be between `num_images` and `max_images*num_images`.',
      }),
    )
    .default(1),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed to control the stochasticity of image generation.',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBytedanceSeedreamV45TextToImageImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * SeedDream45T2IOutput
 */
export const zBytedanceSeedreamV45TextToImageOutput = z.object({
  images: z
    .array(zFalAiBytedanceSeedreamV45TextToImageImage)
    .register(z.globalRegistry, {
      description: 'Generated images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generation',
  }),
})

/**
 * TextToImageRequest
 */
export const zViduQ2TextToImageInput = z.object({
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: 'Text prompt for video generation, max 1500 characters',
  }),
  aspect_ratio: z.optional(
    z.enum(['16:9', '9:16', '1:1']).register(z.globalRegistry, {
      description: 'The aspect ratio of the output video',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for generation',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiViduQ2TextToImageImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * TextToImageOutput
 */
export const zViduQ2TextToImageOutput = z.object({
  image: zFalAiViduQ2TextToImageImage,
})

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export const zFalAiZImageTurboLoraLoRaInput = z
  .object({
    path: z.string().register(z.globalRegistry, {
      description: 'URL, HuggingFace repo ID (owner/repo) to lora weights.',
    }),
    scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description: 'Scale factor for LoRA application (0.0 to 4.0).',
        }),
      )
      .default(1),
  })
  .register(z.globalRegistry, {
    description: 'LoRA weight configuration.',
  })

/**
 * ImageFile
 */
export const zFalAiZImageTurboLoraImageFile = z.object({
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ZImageTurboOutput
 */
export const zZImageTurboLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiZImageTurboLoraImageFile).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()).register(z.globalRegistry, {
    description: 'The timings of the generation process.',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      'Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.',
  }),
})

/**
 * ImageSize
 */
export const zFalAiOvisImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * TextToImageInput
 */
export const zOvisImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  image_size: z.optional(
    z.union([
      zFalAiOvisImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description: 'The guidance scale to use for the image generation.',
      }),
    )
    .default(5),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate an image from.',
      }),
    )
    .default(''),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
})

/**
 * Image
 */
export const zFalAiOvisImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * OvisImageOutput
 */
export const zOvisImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiOvisImageImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * ImageSize
 */
export const zFalAiZImageTurboImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * ZImageTurboTextToImageInput
 */
export const zZImageTurboInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description: 'The acceleration level to use.',
    }),
  ),
  image_size: z.optional(
    z.union([
      zFalAiZImageTurboImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. Note: this will increase the price by 0.0025 credits per request.',
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(8),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'The same seed and the same prompt given to the same version of the model will output the same image every time.',
    }),
  ),
})

/**
 * ImageFile
 */
export const zFalAiZImageTurboImageFile = z.object({
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ZImageTurboOutput
 */
export const zZImageTurboOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiZImageTurboImageFile).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()).register(z.globalRegistry, {
    description: 'The timings of the generation process.',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      'Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux2LoraGallerySepiaVintageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * SepiaVintageInput
 *
 * Input model for Sepia Vintage Photography endpoint - Generate vintage sepia style images
 */
export const zFlux2LoraGallerySepiaVintageInput = z
  .object({
    prompt: z.string().register(z.globalRegistry, {
      description:
        'The prompt to generate a sepia vintage photography style image.',
    }),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiFlux2LoraGallerySepiaVintageImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(2).register(z.globalRegistry, {
          description: 'The strength of the sepia vintage photography effect.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(2.5),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    num_inference_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(40),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Sepia Vintage Photography endpoint - Generate vintage sepia style images',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlux2LoraGallerySepiaVintageImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * SepiaVintageOutput
 */
export const zFlux2LoraGallerySepiaVintageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation',
  }),
  images: z
    .array(zFalAiFlux2LoraGallerySepiaVintageImage)
    .register(z.globalRegistry, {
      description: 'The generated sepia vintage photography style images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux2LoraGallerySatelliteViewStyleImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * SatelliteViewStyleInput
 *
 * Input model for Satellite View Style endpoint - Generate satellite/aerial view style images
 */
export const zFlux2LoraGallerySatelliteViewStyleInput = z
  .object({
    prompt: z.string().register(z.globalRegistry, {
      description:
        'The prompt to generate a satellite/aerial view style image.',
    }),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiFlux2LoraGallerySatelliteViewStyleImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(2).register(z.globalRegistry, {
          description: 'The strength of the satellite view style effect.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(2.5),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    num_inference_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(40),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Satellite View Style endpoint - Generate satellite/aerial view style images',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlux2LoraGallerySatelliteViewStyleImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * SatelliteViewStyleOutput
 */
export const zFlux2LoraGallerySatelliteViewStyleOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation',
  }),
  images: z
    .array(zFalAiFlux2LoraGallerySatelliteViewStyleImage)
    .register(z.globalRegistry, {
      description: 'The generated satellite view style images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux2LoraGalleryRealismImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * RealismInput
 *
 * Input model for Realism endpoint - Generate realistic style images
 */
export const zFlux2LoraGalleryRealismInput = z
  .object({
    prompt: z.string().register(z.globalRegistry, {
      description:
        'The prompt to generate a realistic image with natural lighting and authentic details.',
    }),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiFlux2LoraGalleryRealismImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(2).register(z.globalRegistry, {
          description: 'The strength of the realism effect.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(2.5),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    num_inference_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(40),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Realism endpoint - Generate realistic style images',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlux2LoraGalleryRealismImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * RealismOutput
 */
export const zFlux2LoraGalleryRealismOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation',
  }),
  images: z
    .array(zFalAiFlux2LoraGalleryRealismImage)
    .register(z.globalRegistry, {
      description: 'The generated realistic style images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux2LoraGalleryHdrStyleImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * HdrStyleInput
 *
 * Input model for HDR Style endpoint - Generate HDR style images with vibrant colors
 */
export const zFlux2LoraGalleryHdrStyleInput = z
  .object({
    prompt: z.string().register(z.globalRegistry, {
      description:
        "The prompt to generate an HDR style image. The trigger word 'Hyp3rRe4list1c' will be automatically prepended.",
    }),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiFlux2LoraGalleryHdrStyleImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(2).register(z.globalRegistry, {
          description: 'The strength of the HDR style effect.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(2.5),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    num_inference_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(40),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for HDR Style endpoint - Generate HDR style images with vibrant colors',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlux2LoraGalleryHdrStyleImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * HdrStyleOutput
 */
export const zFlux2LoraGalleryHdrStyleOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation',
  }),
  images: z
    .array(zFalAiFlux2LoraGalleryHdrStyleImage)
    .register(z.globalRegistry, {
      description: 'The generated HDR style images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux2LoraGalleryDigitalComicArtImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * DigitalComicArtInput
 *
 * Input model for Digital Comic Art endpoint - Generate digital comic art style images
 */
export const zFlux2LoraGalleryDigitalComicArtInput = z
  .object({
    prompt: z.string().register(z.globalRegistry, {
      description:
        "The prompt to generate a digital comic art style image. Use 'd1g1t4l' trigger word for best results.",
    }),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiFlux2LoraGalleryDigitalComicArtImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(2).register(z.globalRegistry, {
          description: 'The strength of the digital comic art effect.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(2.5),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    num_inference_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(40),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Digital Comic Art endpoint - Generate digital comic art style images',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlux2LoraGalleryDigitalComicArtImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * DigitalComicArtOutput
 */
export const zFlux2LoraGalleryDigitalComicArtOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation',
  }),
  images: z
    .array(zFalAiFlux2LoraGalleryDigitalComicArtImage)
    .register(z.globalRegistry, {
      description: 'The generated digital comic art style images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux2LoraGalleryBallpointPenSketchImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * BallpointPenSketchInput
 *
 * Input model for Ballpoint Pen Sketch endpoint - Generate ballpoint pen sketch style images
 */
export const zFlux2LoraGalleryBallpointPenSketchInput = z
  .object({
    prompt: z.string().register(z.globalRegistry, {
      description:
        "The prompt to generate a ballpoint pen sketch style image. Use 'b4llp01nt' trigger word for best results.",
    }),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiFlux2LoraGalleryBallpointPenSketchImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
      ]),
    ),
    acceleration: z.optional(
      z.enum(['none', 'regular']).register(z.globalRegistry, {
        description:
          "Acceleration level for image generation. 'regular' balances speed and quality.",
      }),
    ),
    lora_scale: z
      .optional(
        z.number().gte(0).lte(2).register(z.globalRegistry, {
          description: 'The strength of the ballpoint pen sketch effect.',
        }),
      )
      .default(1),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'The format of the output image',
      }),
    ),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and won't be saved in history.",
        }),
      )
      .default(false),
    guidance_scale: z
      .optional(
        z.number().gte(0).lte(20).register(z.globalRegistry, {
          description:
            'The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.',
        }),
      )
      .default(2.5),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable the safety checker for the generated image.',
        }),
      )
      .default(true),
    num_inference_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: 'The number of inference steps to perform.',
        }),
      )
      .default(40),
  })
  .register(z.globalRegistry, {
    description:
      'Input model for Ballpoint Pen Sketch endpoint - Generate ballpoint pen sketch style images',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFlux2LoraGalleryBallpointPenSketchImage = z
  .object({
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * BallpointPenSketchOutput
 */
export const zFlux2LoraGalleryBallpointPenSketchOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generation',
  }),
  images: z
    .array(zFalAiFlux2LoraGalleryBallpointPenSketchImage)
    .register(z.globalRegistry, {
      description: 'The generated ballpoint pen sketch style images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation',
  }),
})

/**
 * ImagineArt_1_5_Input
 */
export const zImagineart15PreviewTextToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'Text prompt describing the desired image',
  }),
  aspect_ratio: z.optional(
    z
      .enum(['1:1', '16:9', '9:16', '4:3', '3:4', '3:1', '1:3', '3:2', '2:3'])
      .register(z.globalRegistry, {
        description:
          'Image aspect ratio: 1:1, 3:1, 1:3, 16:9, 9:16, 4:3, 3:4, 3:2, 2:3',
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Seed for the image generation',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zImageOutput = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ImageSize
 */
export const zFalAiFlux2FlexImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Flux2FlexTextToImageInput
 */
export const zFlux2FlexInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiFlux2FlexImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.',
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to expand the prompt using the model's own knowledge.",
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for the generation.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1.5).lte(10).register(z.globalRegistry, {
        description: 'The guidance scale to use for the generation.',
      }),
    )
    .default(3.5),
})

/**
 * ImageFile
 */
export const zFalAiFlux2FlexImageFile = z.object({
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Flux2FlexOutput
 */
export const zFlux2FlexOutput = z.object({
  images: z.array(zFalAiFlux2FlexImageFile).register(z.globalRegistry, {
    description: 'The generated images.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for the generation.',
  }),
})

/**
 * NanoBananaTextToImageInput
 */
export const zGemini3ProImagePreviewInput = z.object({
  prompt: z.string().min(3).max(50000).register(z.globalRegistry, {
    description: 'The text prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  enable_web_search: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Enable web search for the image generation task. This will allow the model to use the latest information from the web to generate the image.',
      }),
    )
    .default(false),
  resolution: z.optional(
    z.enum(['1K', '2K', '4K']).register(z.globalRegistry, {
      description: 'The resolution of the image to generate.',
    }),
  ),
  aspect_ratio: z.optional(
    z
      .enum([
        '21:9',
        '16:9',
        '3:2',
        '4:3',
        '5:4',
        '1:1',
        '4:5',
        '3:4',
        '2:3',
        '9:16',
      ])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
  limit_generations: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate.',
      }),
    )
    .default(false),
})

/**
 * ImageFile
 */
export const zFalAiGemini3ProImagePreviewImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * NanoBananaTextToImageOutput
 */
export const zGemini3ProImagePreviewOutput = z.object({
  images: z
    .array(zFalAiGemini3ProImagePreviewImageFile)
    .register(z.globalRegistry, {
      description: 'The generated images.',
    }),
  description: z.string().register(z.globalRegistry, {
    description: 'The description of the generated images.',
  }),
})

/**
 * NanoBananaTextToImageInput
 */
export const zNanoBananaProInput = z.object({
  prompt: z.string().min(3).max(50000).register(z.globalRegistry, {
    description: 'The text prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  enable_web_search: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Enable web search for the image generation task. This will allow the model to use the latest information from the web to generate the image.',
      }),
    )
    .default(false),
  aspect_ratio: z.optional(
    z
      .enum([
        '21:9',
        '16:9',
        '3:2',
        '4:3',
        '5:4',
        '1:1',
        '4:5',
        '3:4',
        '2:3',
        '9:16',
      ])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  resolution: z.optional(
    z.enum(['1K', '2K', '4K']).register(z.globalRegistry, {
      description: 'The resolution of the image to generate.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the random number generator.',
    }),
  ),
  limit_generations: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate.',
      }),
    )
    .default(false),
})

/**
 * ImageFile
 */
export const zFalAiNanoBananaProImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * NanoBananaTextToImageOutput
 */
export const zNanoBananaProOutput = z.object({
  images: z.array(zFalAiNanoBananaProImageFile).register(z.globalRegistry, {
    description: 'The generated images.',
  }),
  description: z.string().register(z.globalRegistry, {
    description: 'The description of the generated images.',
  }),
})

/**
 * Emu35ImageInput
 */
export const zEmu35ImageTextToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to create the image.',
  }),
  resolution: z.optional(
    z.enum(['480p', '720p']).register(z.globalRegistry, {
      description: 'The resolution of the output image.',
    }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '3:2', '1:1', '2:3', '3:4', '9:16', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the output image.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the output image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to return the image in sync mode.',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable the safety checker.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed for the inference.',
    }),
  ),
})

/**
 * ImageFile
 */
export const zFalAiEmu35ImageTextToImageImageFile = z.object({
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Emu35Output
 */
export const zEmu35ImageTextToImageOutput = z.object({
  images: z
    .array(zFalAiEmu35ImageTextToImageImageFile)
    .register(z.globalRegistry, {
      description: 'The edited image.',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed for the inference.',
  }),
})

/**
 * PromptObject
 */
export const zBriaFiboGeneratePromptObject = z.object({
  clothing: z.optional(z.union([z.string(), z.unknown()])),
  description: z.optional(z.union([z.string(), z.unknown()])),
  skin_tone_and_texture: z.optional(z.union([z.string(), z.unknown()])),
  appearance_details: z.optional(z.union([z.string(), z.unknown()])),
  number_of_objects: z.optional(z.union([z.int(), z.unknown()])),
  expression: z.optional(z.union([z.string(), z.unknown()])),
  pose: z.optional(z.union([z.string(), z.unknown()])),
  shape_and_color: z.optional(z.union([z.string(), z.unknown()])),
  relationship: z.string().register(z.globalRegistry, {
    description:
      'The relationship of the object to other objects in the image.',
  }),
  texture: z.optional(z.union([z.string(), z.unknown()])),
  gender: z.optional(z.union([z.string(), z.unknown()])),
  relative_size: z.optional(z.union([z.string(), z.unknown()])),
  location: z.optional(z.union([z.string(), z.unknown()])),
  orientation: z.optional(z.union([z.string(), z.unknown()])),
  action: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * Aesthetics
 */
export const zBriaFiboGenerateAesthetics = z.object({
  composition: z.optional(z.union([z.string(), z.unknown()])),
  mood_atmosphere: z.optional(z.union([z.string(), z.unknown()])),
  color_scheme: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * PhotographicCharacteristics
 */
export const zBriaFiboGeneratePhotographicCharacteristics = z.object({
  focus: z.optional(z.union([z.string(), z.unknown()])),
  lens_focal_length: z.optional(z.union([z.string(), z.unknown()])),
  camera_angle: z.optional(z.union([z.string(), z.unknown()])),
  depth_of_field: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * Lighting
 */
export const zBriaFiboGenerateLighting = z.object({
  shadows: z.optional(z.union([z.string(), z.unknown()])),
  conditions: z.optional(z.union([z.string(), z.unknown()])),
  direction: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * StructuredPrompt
 */
export const zBriaFiboGenerateStructuredPrompt = z.object({
  background_setting: z.optional(z.union([z.string(), z.unknown()])),
  artistic_style: z.optional(z.union([z.string(), z.unknown()])),
  context: z.optional(z.union([z.string(), z.unknown()])),
  text_render: z.optional(z.union([z.array(z.unknown()), z.unknown()])),
  objects: z.optional(
    z.union([z.array(zBriaFiboGeneratePromptObject), z.unknown()]),
  ),
  aesthetics: z.optional(z.union([zBriaFiboGenerateAesthetics, z.unknown()])),
  photographic_characteristics: z.optional(
    z.union([zBriaFiboGeneratePhotographicCharacteristics, z.unknown()]),
  ),
  style_medium: z.optional(z.union([z.string(), z.unknown()])),
  lighting: z.optional(z.union([zBriaFiboGenerateLighting, z.unknown()])),
  short_description: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * GaiaInputModel
 */
export const zFiboGenerateInput = z.object({
  prompt: z.optional(z.union([z.string(), z.unknown()])),
  aspect_ratio: z.optional(
    z
      .enum(['1:1', '2:3', '3:2', '3:4', '4:3', '4:5', '5:4', '9:16', '16:9'])
      .register(z.globalRegistry, {
        description:
          'Aspect ratio. Options: 1:1, 2:3, 3:2, 3:4, 4:3, 4:5, 5:4, 9:16, 16:9',
      }),
  ),
  steps_num: z
    .optional(
      z.int().gte(20).lte(50).register(z.globalRegistry, {
        description: 'Number of inference steps.',
      }),
    )
    .default(50),
  image_url: z.optional(z.union([z.string(), z.unknown()])),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, returns the image directly in the response (increases latency).',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.int().gte(3).lte(5).register(z.globalRegistry, {
        description: 'Guidance scale for text.',
      }),
    )
    .default(5),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: 'Random seed for reproducibility.',
      }),
    )
    .default(5555),
  structured_prompt: z.optional(
    z.union([zBriaFiboGenerateStructuredPrompt, z.unknown()]),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for image generation.',
      }),
    )
    .default(''),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zBriaFiboGenerateImage = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    height: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * GaiaOutputModel
 */
export const zFiboGenerateOutput = z.object({
  images: z
    .optional(
      z.array(z.record(z.string(), z.unknown())).register(z.globalRegistry, {
        description: 'Generated images.',
      }),
    )
    .default([]),
  image: zBriaFiboGenerateImage,
  structured_prompt: z
    .record(z.string(), z.unknown())
    .register(z.globalRegistry, {
      description: 'Current prompt.',
    }),
})

/**
 * ImageSize
 */
export const zFalAiPiflowImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * PiQwenInput
 */
export const zPiflowInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiPiflowImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(8),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducible generation. If set to None, a random seed will be used.',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPiflowImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * PiQwenOutput
 */
export const zPiflowOutput = z.object({
  images: z.array(zFalAiPiflowImage).register(z.globalRegistry, {
    description: 'The URLs of the generated images.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
})

/**
 * TextToImageRequestMini
 */
export const zGptImage1MiniInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt for image generation',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'Number of images to generate',
      }),
    )
    .default(1),
  image_size: z.optional(
    z
      .enum(['auto', '1024x1024', '1536x1024', '1024x1536'])
      .register(z.globalRegistry, {
        description: 'Aspect ratio for the generated image',
      }),
  ),
  background: z.optional(
    z.enum(['auto', 'transparent', 'opaque']).register(z.globalRegistry, {
      description: 'Background for the generated image',
    }),
  ),
  quality: z.optional(
    z.enum(['auto', 'low', 'medium', 'high']).register(z.globalRegistry, {
      description: 'Quality for the generated image',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'Output format for the images',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
})

/**
 * ImageFile
 */
export const zFalAiGptImage1MiniImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ImageResponseMini
 */
export const zGptImage1MiniOutput = z.object({
  images: z.array(zFalAiGptImage1MiniImageFile).register(z.globalRegistry, {
    description: 'The generated images.',
  }),
})

/**
 * ReveCreateInput
 *
 * Input for Reve text-to-image generation
 */
export const zReveTextToImageInput = z
  .object({
    prompt: z.string().min(1).max(2560).register(z.globalRegistry, {
      description: 'The text description of the desired image.',
    }),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate',
        }),
      )
      .default(1),
    aspect_ratio: z.optional(
      z
        .enum(['16:9', '9:16', '3:2', '2:3', '4:3', '3:4', '1:1'])
        .register(z.globalRegistry, {
          description: 'The desired aspect ratio of the generated image.',
        }),
    ),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
        }),
      )
      .default(false),
    output_format: z.optional(
      z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
        description: 'Output format for the generated image.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Input for Reve text-to-image generation',
  })

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiReveTextToImageImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ReveCreateOutput
 *
 * Output for Reve text-to-image generation
 */
export const zReveTextToImageOutput = z
  .object({
    images: z.array(zFalAiReveTextToImageImage).register(z.globalRegistry, {
      description: 'The generated images',
    }),
  })
  .register(z.globalRegistry, {
    description: 'Output for Reve text-to-image generation',
  })

/**
 * ImageSize
 */
export const zFalAiHunyuanImageV3TextToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * HunyuanTextToImageInputV3
 */
export const zHunyuanImageV3TextToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt for image-to-image.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiHunyuanImageV3TextToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.',
      }),
    )
    .default(false),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          'Controls how much the model adheres to the prompt. Higher values mean stricter adherence.',
      }),
    )
    .default(7.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'Number of denoising steps.',
      }),
    )
    .default(28),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducible results. If None, a random seed is used.',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'The negative prompt to guide the image generation away from certain concepts.',
      }),
    )
    .default(''),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiHunyuanImageV3TextToImageImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * HunyuanTextToImageV3Output
 */
export const zHunyuanImageV3TextToImageOutput = z.object({
  images: z
    .array(zFalAiHunyuanImageV3TextToImageImage)
    .register(z.globalRegistry, {
      description: 'A list of the generated images.',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The base seed used for the generation process.',
  }),
})

/**
 * ImageSize
 */
export const zFalAiWan25PreviewTextToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * TextToImageInput
 *
 * Input for text-to-image generation
 */
export const zWan25PreviewTextToImageInput = z
  .object({
    prompt: z.string().min(1).register(z.globalRegistry, {
      description:
        'The prompt for image generation. Supports Chinese and English, max 2000 characters.',
    }),
    num_images: z
      .optional(
        z.int().gte(1).lte(4).register(z.globalRegistry, {
          description: 'Number of images to generate. Values from 1 to 4.',
        }),
      )
      .default(1),
    image_size: z.optional(
      z.union([
        zFalAiWan25PreviewTextToImageImageSize,
        z.enum([
          'square_hd',
          'square',
          'portrait_4_3',
          'portrait_16_9',
          'landscape_4_3',
          'landscape_16_9',
        ]),
      ]),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: 'If set to true, the safety checker will be enabled.',
        }),
      )
      .default(true),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          'Random seed for reproducibility. If None, a random seed is chosen.',
      }),
    ),
    enable_prompt_expansion: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            'Whether to enable prompt rewriting using LLM. Improves results for short prompts but increases processing time.',
        }),
      )
      .default(true),
    negative_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'Negative prompt to describe content to avoid. Max 500 characters.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Input for text-to-image generation',
  })

/**
 * ImageFile
 */
export const zFalAiWan25PreviewTextToImageImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * TextToImageOutput
 *
 * Output for text-to-image generation
 */
export const zWan25PreviewTextToImageOutput = z
  .object({
    images: z
      .array(zFalAiWan25PreviewTextToImageImageFile)
      .register(z.globalRegistry, {
        description: 'The generated images',
      }),
    seeds: z.array(z.int()).register(z.globalRegistry, {
      description: 'The seeds used for each generated image',
    }),
    actual_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The actual prompt used if prompt rewriting was enabled',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Output for text-to-image generation',
  })

/**
 * ImageSize
 */
export const zFalAiFluxSrpoImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * BaseSRPOInput
 */
export const zFluxSrpoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFluxSrpoImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        'The speed of the generation. The higher the speed, the faster the generation.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ',
      }),
    )
    .default(4.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
})

/**
 * Image
 */
export const zFalAiFluxSrpoImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * SRPOOutput
 */
export const zFluxSrpoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFluxSrpoImage).register(z.globalRegistry, {
    description: 'The generated images.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux1SrpoImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * BaseSRPOFlux1Input
 */
export const zFlux1SrpoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFlux1SrpoImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        'The speed of the generation. The higher the speed, the faster the generation.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ',
      }),
    )
    .default(4.5),
})

/**
 * Image
 */
export const zFalAiFlux1SrpoImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * SRPOOutput
 */
export const zFlux1SrpoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFlux1SrpoImage).register(z.globalRegistry, {
    description: 'The generated images.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiHunyuanImageV21TextToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * HunyuanTextToImageInput
 */
export const zHunyuanImageV21TextToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiHunyuanImageV21TextToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  use_reprompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Enable prompt enhancement for potentially better results.',
      }),
    )
    .default(true),
  use_refiner: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable the refiner model for improved image quality.',
      }),
    )
    .default(false),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          'Controls how much the model adheres to the prompt. Higher values mean stricter adherence.',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'Number of denoising steps.',
      }),
    )
    .default(28),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducible results. If None, a random seed is used.',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'The negative prompt to guide the image generation away from certain concepts.',
      }),
    )
    .default(''),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiHunyuanImageV21TextToImageImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * HunyuanTextToImageOutput
 */
export const zHunyuanImageV21TextToImageOutput = z.object({
  images: z
    .array(zFalAiHunyuanImageV21TextToImageImage)
    .register(z.globalRegistry, {
      description: 'A list of the generated images.',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The base seed used for the generation process.',
  }),
})

/**
 * ImageSize
 */
export const zFalAiBytedanceSeedreamV4TextToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * SeedDream4T2IInput
 */
export const zBytedanceSeedreamV4TextToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt used to generate the image',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(6).register(z.globalRegistry, {
        description:
          'Number of separate model generations to be run with the prompt.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiBytedanceSeedreamV4TextToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
        'auto',
        'auto_2K',
        'auto_4K',
      ]),
    ]),
  ),
  enhance_prompt_mode: z.optional(
    z.enum(['standard', 'fast']).register(z.globalRegistry, {
      description:
        'The mode to use for enhancing prompt enhancement. Standard mode provides higher quality results but takes longer to generate. Fast mode provides average quality results but takes less time to generate.',
    }),
  ),
  max_images: z
    .optional(
      z.int().gte(1).lte(6).register(z.globalRegistry, {
        description:
          'If set to a number greater than one, enables multi-image generation. The model will potentially return up to `max_images` images every generation, and in total, `num_images` generations will be carried out. In total, the number of images generated will be between `num_images` and `max_images*num_images`.',
      }),
    )
    .default(1),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed to control the stochasticity of image generation.',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBytedanceSeedreamV4TextToImageImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * SeedDream4T2IOutput
 */
export const zBytedanceSeedreamV4TextToImageOutput = z.object({
  images: z
    .array(zFalAiBytedanceSeedreamV4TextToImageImage)
    .register(z.globalRegistry, {
      description: 'Generated images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generation',
  }),
})

/**
 * NanoBananaTextToImageInput
 */
export const zGemini25FlashImageInput = z.object({
  prompt: z.string().min(3).max(50000).register(z.globalRegistry, {
    description: 'The text prompt to generate an image from.',
  }),
  aspect_ratio: z.optional(
    z
      .enum([
        '21:9',
        '16:9',
        '3:2',
        '4:3',
        '5:4',
        '1:1',
        '4:5',
        '3:4',
        '2:3',
        '9:16',
      ])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  limit_generations: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate.',
      }),
    )
    .default(false),
})

/**
 * ImageFile
 */
export const zFalAiGemini25FlashImageImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * NanoBananaTextToImageOutput
 */
export const zGemini25FlashImageOutput = z.object({
  images: z
    .array(zFalAiGemini25FlashImageImageFile)
    .register(z.globalRegistry, {
      description: 'The generated images.',
    }),
  description: z.string().register(z.globalRegistry, {
    description: 'The description of the generated images.',
  }),
})

/**
 * NanoBananaTextToImageInput
 */
export const zNanoBananaInput = z.object({
  prompt: z.string().min(3).max(50000).register(z.globalRegistry, {
    description: 'The text prompt to generate an image from.',
  }),
  aspect_ratio: z.optional(
    z
      .enum([
        '21:9',
        '16:9',
        '3:2',
        '4:3',
        '5:4',
        '1:1',
        '4:5',
        '3:4',
        '2:3',
        '9:16',
      ])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  limit_generations: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate.',
      }),
    )
    .default(false),
})

/**
 * ImageFile
 */
export const zFalAiNanoBananaImageFile = z.object({
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * NanoBananaTextToImageOutput
 */
export const zNanoBananaOutput = z.object({
  images: z.array(zFalAiNanoBananaImageFile).register(z.globalRegistry, {
    description: 'The generated images.',
  }),
  description: z.string().register(z.globalRegistry, {
    description: 'The description of the generated images.',
  }),
})

/**
 * ImageSize
 */
export const zFalAiBytedanceDreaminaV31TextToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * DreaminaInput
 */
export const zBytedanceDreaminaV31TextToImageInput = z.object({
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'Number of images to generate',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiBytedanceDreaminaV31TextToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt used to generate the image',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed to control the stochasticity of image generation.',
    }),
  ),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to use an LLM to enhance the prompt',
      }),
    )
    .default(false),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBytedanceDreaminaV31TextToImageImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * DreaminaOutput
 */
export const zBytedanceDreaminaV31TextToImageOutput = z.object({
  images: z
    .array(zFalAiBytedanceDreaminaV31TextToImageImage)
    .register(z.globalRegistry, {
      description: 'Generated images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiWanV22A14bTextToImageLoraImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoRAWeight
 */
export const zLoRaWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
  transformer: z.optional(
    z.enum(['high', 'low', 'both']).register(z.globalRegistry, {
      description:
        "Specifies the transformer to load the lora weight into. 'high' loads into the high-noise transformer, 'low' loads it into the low-noise transformer, while 'both' loads the LoRA into both transformers.",
    }),
  ),
  weight_name: z.optional(z.union([z.string(), z.unknown()])),
})

/**
 * WanLoRAT2IRequest
 */
export const zWanV22A14bTextToImageLoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide image generation.',
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift value for the image. Must be between 1.0 and 10.0.',
      }),
    )
    .default(2),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  reverse_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If true, the video will be reversed.',
      }),
    )
    .default(false),
  image_size: z.optional(
    z.union([
      zFalAiWanV22A14bTextToImageLoraImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  loras: z
    .optional(
      z.array(zLoRaWeight).register(z.globalRegistry, {
        description: 'LoRA weights to be used in the inference.',
      }),
    )
    .default([]),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(3.5),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, input data will be checked for safety before processing.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(''),
  image_format: z.optional(
    z.enum(['png', 'jpeg']).register(z.globalRegistry, {
      description: 'The format of the output image.',
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, output video will be checked for safety after generation.',
      }),
    )
    .default(false),
  guidance_scale_2: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.',
      }),
    )
    .default(4),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(27),
})

/**
 * File
 */
export const zFalAiWanV22A14bTextToImageLoraFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * WanT2IResponse
 */
export const zWanV22A14bTextToImageLoraOutput = z.object({
  image: zFalAiWanV22A14bTextToImageLoraFile,
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
})

/**
 * ImageSize
 */
export const zFalAiWanV225bTextToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * WanSmallT2IRequest
 */
export const zWanV225bTextToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide image generation.',
  }),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(3.5),
  image_size: z.optional(
    z.union([
      zFalAiWanV225bTextToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  image_format: z.optional(
    z.enum(['png', 'jpeg']).register(z.globalRegistry, {
      description: 'The format of the output image.',
    }),
  ),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift value for the image. Must be between 1.0 and 10.0.',
      }),
    )
    .default(2),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, output video will be checked for safety after generation.',
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, input data will be checked for safety before processing.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(40),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(''),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.',
      }),
    )
    .default(false),
})

/**
 * File
 */
export const zFalAiWanV225bTextToImageFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * WanSmallT2IResponse
 */
export const zWanV225bTextToImageOutput = z.object({
  image: zFalAiWanV225bTextToImageFile,
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
})

/**
 * ImageSize
 */
export const zFalAiWanV22A14bTextToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * WanT2IRequest
 */
export const zWanV22A14bTextToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide image generation.',
  }),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.',
      }),
    )
    .default(3.5),
  acceleration: z.optional(
    z.enum(['none', 'regular']).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  image_size: z.optional(
    z.union([
      zFalAiWanV22A14bTextToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: 'Shift value for the image. Must be between 1.0 and 10.0.',
      }),
    )
    .default(2),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, output video will be checked for safety after generation.',
      }),
    )
    .default(false),
  guidance_scale_2: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.',
      }),
    )
    .default(4),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, input data will be checked for safety before processing.',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(''),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(27),
})

/**
 * File
 */
export const zFalAiWanV22A14bTextToImageFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * WanT2IResponse
 */
export const zWanV22A14bTextToImageOutput = z.object({
  image: zFalAiWanV22A14bTextToImageFile,
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
})

/**
 * ImageSize
 */
export const zFalAiQwenImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zFalAiQwenImageLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * BaseQwenImageInput
 */
export const zQwenImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the image with',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        "Acceleration level for image generation. Options: 'none', 'regular', 'high'. Higher acceleration increases speed. 'regular' balances speed and quality. 'high' is recommended for images without text.",
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(250).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(30),
  image_size: z.optional(
    z.union([
      zFalAiQwenImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zFalAiQwenImageLoraWeight).register(z.globalRegistry, {
        description:
          '\n            The LoRAs to use for the image generation. You can use up to 3 LoRAs\n            and they will be merged together to generate the final image.\n        ',
      }),
    )
    .default([]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  use_turbo: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Enable turbo mode for faster generation with high quality. When enabled, uses optimized settings (10 steps, CFG=1.2).',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt for the generation',
      }),
    )
    .default(' '),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(2.5),
})

/**
 * Image
 */
export const zFalAiQwenImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * QwenImageOutput
 */
export const zQwenImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiQwenImageImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * ImageSize
 */
export const zFalAiFluxKreaLoraStreamImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zFalAiFluxKreaLoraStreamLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * TextToImageInput
 */
export const zFluxKreaLoraStreamInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description:
          'The number of images to generate. This is always set to 1 for streaming output.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFluxKreaLoraStreamImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  loras: z
    .optional(
      z.array(zFalAiFluxKreaLoraStreamLoraWeight).register(z.globalRegistry, {
        description:
          '\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ',
      }),
    )
    .default([]),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(35).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiFluxKreaLoraStreamImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxKreaLoraStreamOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFluxKreaLoraStreamImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * ImageSize
 */
export const zFalAiFluxKreaLoraImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zFalAiFluxKreaLoraLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * TextToImageInput
 */
export const zFluxKreaLoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description:
          'The number of images to generate. This is always set to 1 for streaming output.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFluxKreaLoraImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  loras: z
    .optional(
      z.array(zFalAiFluxKreaLoraLoraWeight).register(z.globalRegistry, {
        description:
          '\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ',
      }),
    )
    .default([]),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(35).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiFluxKreaLoraImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxKreaLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFluxKreaLoraImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * ImageSize
 */
export const zFalAiFluxKreaImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * BaseKreaInput
 */
export const zFluxKreaInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFluxKreaImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        'The speed of the generation. The higher the speed, the faster the generation.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ',
      }),
    )
    .default(4.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
})

/**
 * Image
 */
export const zFalAiFluxKreaImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * KreaOutput
 */
export const zFluxKreaOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFluxKreaImage).register(z.globalRegistry, {
    description: 'The generated images.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux1KreaImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * BaseKreaFlux1Input
 */
export const zFlux1KreaInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFlux1KreaImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        'The speed of the generation. The higher the speed, the faster the generation.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ',
      }),
    )
    .default(4.5),
})

/**
 * Image
 */
export const zFalAiFlux1KreaImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * KreaOutput
 */
export const zFlux1KreaOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFlux1KreaImage).register(z.globalRegistry, {
    description: 'The generated images.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiSkyRaccoonImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * SkyRaccoonRequest
 */
export const zSkyRaccoonInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt to guide video generation.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiSkyRaccoonImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  turbo_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If true, the video will be generated faster with no noticeable degradation in the visual quality.',
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable prompt expansion.',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed for reproducibility. If None, a random seed is chosen.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative prompt for video generation.',
      }),
    )
    .default(
      'bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards',
    ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          'Number of inference steps for sampling. Higher values give better quality but take longer.',
      }),
    )
    .default(30),
})

/**
 * File
 */
export const zFalAiSkyRaccoonFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * SkyRaccoonResponse
 */
export const zSkyRaccoonOutput = z.object({
  image: zFalAiSkyRaccoonFile,
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used for generation.',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFluxKontextLoraTextToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zFalAiFluxKontextLoraTextToImageLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * BaseKontextInput
 */
export const zFluxKontextLoraTextToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate the image with',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFluxKontextLoraTextToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        'The speed of the generation. The higher the speed, the faster the generation.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  loras: z
    .optional(
      z
        .array(zFalAiFluxKontextLoraTextToImageLoraWeight)
        .register(z.globalRegistry, {
          description:
            '\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ',
        }),
    )
    .default([]),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(2.5),
  num_inference_steps: z
    .optional(
      z.int().gte(10).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(30),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiFluxKontextLoraTextToImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * KontextT2IOutput
 */
export const zFluxKontextLoraTextToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFluxKontextLoraTextToImageImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiOmnigenV2ImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * TextToImageInput
 */
export const zOmnigenV2Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      "The prompt to generate or edit an image. Use specific language like 'Add the bird from image 1 to the desk in image 2' for better results.",
  }),
  image_size: z.optional(
    z.union([
      zFalAiOmnigenV2ImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  scheduler: z.optional(
    z.enum(['euler', 'dpmsolver']).register(z.globalRegistry, {
      description: 'The scheduler to use for the diffusion process.',
    }),
  ),
  cfg_range_end: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'CFG range end value.',
      }),
    )
    .default(1),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Negative prompt to guide what should not be in the image.',
      }),
    )
    .default(
      '(((deformed))), blurry, over saturation, bad anatomy, disfigured, poorly drawn face, mutation, mutated, (extra_limb), (ugly), (poorly drawn hands), fused fingers, messy drawing, broken legs censor, censored, censor_bar',
    ),
  text_guidance_scale: z
    .optional(
      z.number().gte(1).lte(8).register(z.globalRegistry, {
        description:
          '\n            The Text Guidance scale controls how closely the model follows the text prompt.\n            Higher values make the model stick more closely to the prompt.\n        ',
      }),
    )
    .default(5),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_guidance_scale: z
    .optional(
      z.number().gte(1).lte(3).register(z.globalRegistry, {
        description:
          '\n            The Image Guidance scale controls how closely the model follows the input images.\n            For image editing: 1.3-2.0, for in-context generation: 2.0-3.0\n        ',
      }),
    )
    .default(2),
  input_image_urls: z
    .optional(
      z.array(z.string()).register(z.globalRegistry, {
        description:
          'URLs of input images to use for image editing or multi-image generation. Support up to 3 images.',
      }),
    )
    .default([]),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  cfg_range_start: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'CFG range start value.',
      }),
    )
    .default(0),
  num_inference_steps: z
    .optional(
      z.int().gte(20).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(50),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiOmnigenV2Image = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zOmnigenV2Output = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiOmnigenV2Image).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiBytedanceSeedreamV3TextToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * SeedDreamInput
 */
export const zBytedanceSeedreamV3TextToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt used to generate the image',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'Number of images to generate',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiBytedanceSeedreamV3TextToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          'Controls how closely the output image aligns with the input prompt. Higher values mean stronger prompt correlation.',
      }),
    )
    .default(2.5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        'Random seed to control the stochasticity of image generation.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBytedanceSeedreamV3TextToImageImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * SeedDreamOutput
 */
export const zBytedanceSeedreamV3TextToImageOutput = z.object({
  images: z
    .array(zFalAiBytedanceSeedreamV3TextToImageImage)
    .register(z.globalRegistry, {
      description: 'Generated images',
    }),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux1SchnellImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * SchnellFlux1TextToImageInput
 */
export const zFlux1SchnellInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFlux1SchnellImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        'The speed of the generation. The higher the speed, the faster the generation.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(12).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(4),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ',
      }),
    )
    .default(3.5),
})

/**
 * Image
 */
export const zFalAiFlux1SchnellImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFlux1SchnellOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFlux1SchnellImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFlux1DevImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * BaseFlux1Input
 */
export const zFlux1DevInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFlux1DevImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        'The speed of the generation. The higher the speed, the faster the generation.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ',
      }),
    )
    .default(3.5),
})

/**
 * Image
 */
export const zFalAiFlux1DevImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFlux1DevOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFlux1DevImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * FluxProTextToImageInputWithAR
 */
export const zFluxProKontextMaxTextToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '3:2', '1:1', '2:3', '3:4', '9:16', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enhance the prompt for better results.',
      }),
    )
    .default(false),
})

/**
 * Image
 */
export const zFalAiFluxProKontextMaxTextToImageRegistryImageFastSdxlModelsImage =
  z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int(),
  })

/**
 * Output
 */
export const zFluxProKontextMaxTextToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFluxProKontextMaxTextToImageRegistryImageFastSdxlModelsImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * FluxProTextToImageInputWithAR
 */
export const zFluxProKontextTextToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  aspect_ratio: z.optional(
    z
      .enum(['21:9', '16:9', '4:3', '3:2', '1:1', '2:3', '3:4', '9:16', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enhance the prompt for better results.',
      }),
    )
    .default(false),
})

/**
 * Image
 */
export const zFalAiFluxProKontextTextToImageRegistryImageFastSdxlModelsImage =
  z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int(),
  })

/**
 * Output
 */
export const zFluxProKontextTextToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFluxProKontextTextToImageRegistryImageFastSdxlModelsImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageGenInput
 */
export const zBagelInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for the generation.',
    }),
  ),
  use_thought: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to use thought tokens for generation. If set to true, the model will "think" to potentially improve generation quality. Increases generation time and increases the cost by 20%.',
      }),
    )
    .default(false),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBagelImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ImageOutput
 */
export const zBagelOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiBagelImage).register(z.globalRegistry, {
    description: 'The generated images.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * Imagen4TextToImageUltraInput
 */
export const zImagen4PreviewUltraInput = z.object({
  prompt: z.string().min(3).max(5000).register(z.globalRegistry, {
    description: 'The text prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  aspect_ratio: z.optional(
    z.enum(['1:1', '16:9', '9:16', '4:3', '3:4']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated image.',
    }),
  ),
  resolution: z.optional(
    z.enum(['1K', '2K']).register(z.globalRegistry, {
      description: 'The resolution of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
})

/**
 * ImageFile
 */
export const zFalAiImagen4PreviewUltraImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Imagen4TextToImageUltraOutput
 */
export const zImagen4PreviewUltraOutput = z.object({
  images: z
    .array(zFalAiImagen4PreviewUltraImageFile)
    .register(z.globalRegistry, {
      description: 'The generated images.',
    }),
  description: z.string().register(z.globalRegistry, {
    description: 'The description of the generated images.',
  }),
})

/**
 * ImageSize
 */
export const zFalAiDreamoImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * DreamOInput
 */
export const zDreamoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  first_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'URL of first reference image to use for generation.',
    }),
  ),
  image_size: z.optional(
    z.union([
      zFalAiDreamoImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  second_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'URL of second reference image to use for generation.',
    }),
  ),
  second_reference_task: z.optional(
    z.enum(['ip', 'id', 'style']).register(z.globalRegistry, {
      description: 'Task for second reference image (ip/id/style).',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  first_reference_task: z.optional(
    z.enum(['ip', 'id', 'style']).register(z.globalRegistry, {
      description: 'Task for first reference image (ip/id/style).',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The prompt to generate an image from.',
      }),
    )
    .default(''),
  ref_resolution: z
    .optional(
      z.int().gte(512).lte(1024).register(z.globalRegistry, {
        description: 'Resolution for reference images.',
      }),
    )
    .default(512),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  true_cfg: z
    .optional(
      z.number().gte(1).lte(5).register(z.globalRegistry, {
        description: 'The weight of the CFG loss.',
      }),
    )
    .default(1),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(12),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiDreamoImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * DreamOOutput
 */
export const zDreamoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used to generate the image.',
  }),
  images: z.array(zFalAiDreamoImage).register(z.globalRegistry, {
    description: 'The URLs of the generated images.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFluxLoraStreamImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zFalAiFluxLoraStreamLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * TextToImageInput
 */
export const zFluxLoraStreamInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description:
          'The number of images to generate. This is always set to 1 for streaming output.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFluxLoraStreamImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  loras: z
    .optional(
      z.array(zFalAiFluxLoraStreamLoraWeight).register(z.globalRegistry, {
        description:
          '\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ',
      }),
    )
    .default([]),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(35).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zFalAiFluxLoraStreamImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxLoraStreamOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFluxLoraStreamImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * MiniMaxTextToImageRequest
 */
export const zMinimaxImage01Input = z.object({
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enable automatic prompt optimization',
      }),
    )
    .default(false),
  aspect_ratio: z.optional(
    z
      .enum(['1:1', '16:9', '4:3', '3:2', '2:3', '3:4', '9:16', '21:9'])
      .register(z.globalRegistry, {
        description: 'Aspect ratio of the generated image',
      }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(9).register(z.globalRegistry, {
        description: 'Number of images to generate (1-9)',
      }),
    )
    .default(1),
  prompt: z.string().min(1).max(1500).register(z.globalRegistry, {
    description: 'Text prompt for image generation (max 1500 characters)',
  }),
})

/**
 * File
 */
export const zFalAiMinimaxImage01File = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * MiniMaxTextToImageOutput
 */
export const zMinimaxImage01Output = z.object({
  images: z.array(zFalAiMinimaxImage01File).register(z.globalRegistry, {
    description: 'Generated images',
  }),
})

/**
 * ImageSize
 */
export const zFalAiPonyV7ImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Input
 */
export const zPonyV7Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate images from',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(2).register(z.globalRegistry, {
        description: 'The number of images to generate',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiPonyV7ImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  noise_source: z.optional(
    z.enum(['gpu', 'cpu']).register(z.globalRegistry, {
      description:
        "\n            The source of the noise to use for generating images.\n            If set to 'gpu', the noise will be generated on the GPU.\n            If set to 'cpu', the noise will be generated on the CPU.\n        ",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description: 'Classifier free guidance scale',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(20).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to take',
      }),
    )
    .default(40),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for generating images',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPonyV7Image = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ImageOutput
 */
export const zPonyV7Output = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiPonyV7Image).register(z.globalRegistry, {
    description: 'The generated images',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiIdeogramV3ImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * RGBColor
 */
export const zFalAiIdeogramV3RgbColor = z.object({
  r: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Red color value',
      }),
    )
    .default(0),
  b: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Blue color value',
      }),
    )
    .default(0),
  g: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Green color value',
      }),
    )
    .default(0),
})

/**
 * ColorPaletteMember
 */
export const zColorPaletteMember = z.object({
  color_weight: z.optional(z.union([z.number().gte(0.05).lte(1), z.unknown()])),
  rgb: zFalAiIdeogramV3RgbColor,
})

/**
 * ColorPalette
 */
export const zColorPalette = z.object({
  members: z.optional(z.union([z.array(zColorPaletteMember), z.unknown()])),
  name: z.optional(
    z.union([
      z.enum([
        'EMBER',
        'FRESH',
        'JUNGLE',
        'MAGIC',
        'MELON',
        'MOSAIC',
        'PASTEL',
        'ULTRAMARINE',
      ]),
      z.unknown(),
    ]),
  ),
})

/**
 * BaseTextToImageInputV3
 */
export const zIdeogramV3Input = z.object({
  prompt: z.string(),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'Number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiIdeogramV3ImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
      z.unknown(),
    ]),
  ),
  style: z.optional(
    z.union([z.enum(['AUTO', 'GENERAL', 'REALISTIC', 'DESIGN']), z.unknown()]),
  ),
  style_preset: z.optional(
    z.union([
      z.enum([
        '80S_ILLUSTRATION',
        '90S_NOSTALGIA',
        'ABSTRACT_ORGANIC',
        'ANALOG_NOSTALGIA',
        'ART_BRUT',
        'ART_DECO',
        'ART_POSTER',
        'AURA',
        'AVANT_GARDE',
        'BAUHAUS',
        'BLUEPRINT',
        'BLURRY_MOTION',
        'BRIGHT_ART',
        'C4D_CARTOON',
        'CHILDRENS_BOOK',
        'COLLAGE',
        'COLORING_BOOK_I',
        'COLORING_BOOK_II',
        'CUBISM',
        'DARK_AURA',
        'DOODLE',
        'DOUBLE_EXPOSURE',
        'DRAMATIC_CINEMA',
        'EDITORIAL',
        'EMOTIONAL_MINIMAL',
        'ETHEREAL_PARTY',
        'EXPIRED_FILM',
        'FLAT_ART',
        'FLAT_VECTOR',
        'FOREST_REVERIE',
        'GEO_MINIMALIST',
        'GLASS_PRISM',
        'GOLDEN_HOUR',
        'GRAFFITI_I',
        'GRAFFITI_II',
        'HALFTONE_PRINT',
        'HIGH_CONTRAST',
        'HIPPIE_ERA',
        'ICONIC',
        'JAPANDI_FUSION',
        'JAZZY',
        'LONG_EXPOSURE',
        'MAGAZINE_EDITORIAL',
        'MINIMAL_ILLUSTRATION',
        'MIXED_MEDIA',
        'MONOCHROME',
        'NIGHTLIFE',
        'OIL_PAINTING',
        'OLD_CARTOONS',
        'PAINT_GESTURE',
        'POP_ART',
        'RETRO_ETCHING',
        'RIVIERA_POP',
        'SPOTLIGHT_80S',
        'STYLIZED_RED',
        'SURREAL_COLLAGE',
        'TRAVEL_POSTER',
        'VINTAGE_GEO',
        'VINTAGE_POSTER',
        'WATERCOLOR',
        'WEIRD',
        'WOODBLOCK_PRINT',
      ]),
      z.unknown(),
    ]),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Determine if MagicPrompt should be used in generating the request or not.',
      }),
    )
    .default(true),
  rendering_speed: z.optional(
    z.enum(['TURBO', 'BALANCED', 'QUALITY']).register(z.globalRegistry, {
      description: 'The rendering speed to use.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  color_palette: z.optional(z.union([zColorPalette, z.unknown()])),
  style_codes: z.optional(z.union([z.array(z.string()), z.unknown()])),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  image_urls: z.optional(z.union([z.array(z.string()), z.unknown()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'Description of what to exclude from an image. Descriptions in the prompt take precedence to descriptions in the negative prompt.',
      }),
    )
    .default(''),
})

/**
 * File
 */
export const zFalAiIdeogramV3File = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * OutputV3
 */
export const zIdeogramV3Output = z.object({
  images: z.array(zFalAiIdeogramV3File),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for the random number generator',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFLiteStandardImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * TextToImageInputStandard
 */
export const zFLiteStandardInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFLiteStandardImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative Prompt for generation.',
      }),
    )
    .default(''),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zFalAiFLiteStandardImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFLiteStandardOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFLiteStandardImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFLiteTextureImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * TextToImageInputTexture
 */
export const zFLiteTextureInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFLiteTextureImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Negative Prompt for generation.',
      }),
    )
    .default(''),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zFalAiFLiteTextureImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFLiteTextureOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFLiteTextureImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * TextToImageRequest
 */
export const zGptImage1TextToImageInput = z.object({
  prompt: z.string().min(2).register(z.globalRegistry, {
    description: 'The prompt for image generation',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'Number of images to generate',
      }),
    )
    .default(1),
  image_size: z.optional(
    z
      .enum(['auto', '1024x1024', '1536x1024', '1024x1536'])
      .register(z.globalRegistry, {
        description: 'Aspect ratio for the generated image',
      }),
  ),
  background: z.optional(
    z.enum(['auto', 'transparent', 'opaque']).register(z.globalRegistry, {
      description: 'Background for the generated image',
    }),
  ),
  quality: z.optional(
    z.enum(['auto', 'low', 'medium', 'high']).register(z.globalRegistry, {
      description: 'Quality for the generated image',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png', 'webp']).register(z.globalRegistry, {
      description: 'Output format for the images',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
})

/**
 * ImageFile
 */
export const zFalAiGptImage1TextToImageImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The height of the image',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The width of the image',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * ImageResponse
 */
export const zGptImage1TextToImageOutput = z.object({
  images: z
    .array(zFalAiGptImage1TextToImageImageFile)
    .register(z.globalRegistry, {
      description: 'The generated images.',
    }),
})

/**
 * ImageSize
 */
export const zFalAiSanaV1516bImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * TextToImageInput
 */
export const zSanaV1516bInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiSanaV1516bImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  style_name: z.optional(
    z
      .enum([
        '(No style)',
        'Cinematic',
        'Photographic',
        'Anime',
        'Manga',
        'Digital Art',
        'Pixel art',
        'Fantasy art',
        'Neonpunk',
        '3D Model',
      ])
      .register(z.globalRegistry, {
        description: 'The style to generate the image in.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(18),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zFalAiSanaV1516bImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zSanaV1516bOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiSanaV1516bImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiSanaV1548bImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * TextToImageInput
 */
export const zSanaV1548bInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiSanaV1548bImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  style_name: z.optional(
    z
      .enum([
        '(No style)',
        'Cinematic',
        'Photographic',
        'Anime',
        'Manga',
        'Digital Art',
        'Pixel art',
        'Fantasy art',
        'Neonpunk',
        '3D Model',
      ])
      .register(z.globalRegistry, {
        description: 'The style to generate the image in.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(18),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zFalAiSanaV1548bImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zSanaV1548bOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiSanaV1548bImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiSanaSprintImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * SprintInput
 */
export const zSanaSprintInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiSanaSprintImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  style_name: z.optional(
    z
      .enum([
        '(No style)',
        'Cinematic',
        'Photographic',
        'Anime',
        'Manga',
        'Digital Art',
        'Pixel art',
        'Fantasy art',
        'Neonpunk',
        '3D Model',
      ])
      .register(z.globalRegistry, {
        description: 'The style to generate the image in.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(20).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(2),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zFalAiSanaSprintImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zSanaSprintOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiSanaSprintImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zRundiffusionFalJuggernautFluxLightningImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * SchnellTextToImageInput
 */
export const zJuggernautFluxLightningInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zRundiffusionFalJuggernautFluxLightningImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(12).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(4),
})

/**
 * Image
 */
export const zRundiffusionFalJuggernautFluxLightningImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zJuggernautFluxLightningOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zRundiffusionFalJuggernautFluxLightningImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zRundiffusionFalRundiffusionPhotoFluxImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zRundiffusionFalRundiffusionPhotoFluxLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * PhotoLoraT2IInput
 */
export const zRundiffusionPhotoFluxInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zRundiffusionFalRundiffusionPhotoFluxImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  loras: z
    .optional(
      z
        .array(zRundiffusionFalRundiffusionPhotoFluxLoraWeight)
        .register(z.globalRegistry, {
          description:
            '\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ',
        }),
    )
    .default([]),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(35).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  photo_lora_scale: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: 'LoRA Scale of the photo lora model',
      }),
    )
    .default(0.75),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zRundiffusionFalRundiffusionPhotoFluxImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zRundiffusionPhotoFluxOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zRundiffusionFalRundiffusionPhotoFluxImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zRundiffusionFalJuggernautFluxLoraImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zRundiffusionFalJuggernautFluxLoraLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * TextToImageInput
 */
export const zJuggernautFluxLoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zRundiffusionFalJuggernautFluxLoraImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  loras: z
    .optional(
      z
        .array(zRundiffusionFalJuggernautFluxLoraLoraWeight)
        .register(z.globalRegistry, {
          description:
            '\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ',
        }),
    )
    .default([]),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(35).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zRundiffusionFalJuggernautFluxLoraImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zJuggernautFluxLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zRundiffusionFalJuggernautFluxLoraImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zRundiffusionFalJuggernautFluxProImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * DevTextToImageInput
 */
export const zJuggernautFluxProInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zRundiffusionFalJuggernautFluxProImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zRundiffusionFalJuggernautFluxProImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zJuggernautFluxProOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zRundiffusionFalJuggernautFluxProImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zRundiffusionFalJuggernautFluxBaseImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * DevTextToImageInput
 */
export const zJuggernautFluxBaseInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zRundiffusionFalJuggernautFluxBaseImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zRundiffusionFalJuggernautFluxBaseImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zJuggernautFluxBaseOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zRundiffusionFalJuggernautFluxBaseImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiCogview4ImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * TextToImageInput
 */
export const zCogview4Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiCogview4ImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(50),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiCogview4Image = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ImageOutput
 */
export const zCogview4Output = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiCogview4Image).register(z.globalRegistry, {
    description: 'The generated images',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * BaseTextToImageInput
 */
export const zIdeogramV2aTurboInput = z.object({
  prompt: z.string(),
  aspect_ratio: z.optional(
    z
      .enum([
        '10:16',
        '16:10',
        '9:16',
        '16:9',
        '4:3',
        '3:4',
        '1:1',
        '1:3',
        '3:1',
        '3:2',
        '2:3',
      ])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image',
      }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  style: z.optional(
    z
      .enum(['auto', 'general', 'realistic', 'design', 'render_3D', 'anime'])
      .register(z.globalRegistry, {
        description: 'The style of the generated image',
      }),
  ),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to expand the prompt with MagicPrompt functionality.',
      }),
    )
    .default(true),
})

/**
 * File
 */
export const zFalAiIdeogramV2aTurboFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * Output
 */
export const zIdeogramV2aTurboOutput = z.object({
  images: z.array(zFalAiIdeogramV2aTurboFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for the random number generator',
  }),
})

/**
 * BaseTextToImageInput
 */
export const zIdeogramV2aInput = z.object({
  prompt: z.string(),
  aspect_ratio: z.optional(
    z
      .enum([
        '10:16',
        '16:10',
        '9:16',
        '16:9',
        '4:3',
        '3:4',
        '1:1',
        '1:3',
        '3:1',
        '3:2',
        '2:3',
      ])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image',
      }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  style: z.optional(
    z
      .enum(['auto', 'general', 'realistic', 'design', 'render_3D', 'anime'])
      .register(z.globalRegistry, {
        description: 'The style of the generated image',
      }),
  ),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to expand the prompt with MagicPrompt functionality.',
      }),
    )
    .default(true),
})

/**
 * File
 */
export const zFalAiIdeogramV2aFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * Output
 */
export const zIdeogramV2aOutput = z.object({
  images: z.array(zFalAiIdeogramV2aFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for the random number generator',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFluxControlLoraCannyImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zFalAiFluxControlLoraCannyLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * TextToImageInput
 */
export const zFluxControlLoraCannyInput = z.object({
  control_lora_strength: z
    .optional(
      z.number().gte(0).lte(2).register(z.globalRegistry, {
        description: 'The strength of the control lora.',
      }),
    )
    .default(1),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFluxControlLoraCannyImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  loras: z
    .optional(
      z.array(zFalAiFluxControlLoraCannyLoraWeight).register(z.globalRegistry, {
        description:
          '\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ',
      }),
    )
    .default([]),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(35).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  control_lora_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        '\n            The image to use for control lora. This is used to control the style of the generated image.\n        ',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiFluxControlLoraCannyImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxControlLoraCannyOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFluxControlLoraCannyImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFluxControlLoraDepthImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zFalAiFluxControlLoraDepthLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * DepthLoraInput
 */
export const zFluxControlLoraDepthInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFluxControlLoraDepthImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  control_lora_strength: z
    .optional(
      z.number().gte(0).lte(2).register(z.globalRegistry, {
        description: 'The strength of the control lora.',
      }),
    )
    .default(1),
  preprocess_depth: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the input image will be preprocessed to extract depth information.\n            This is useful for generating depth maps from images.\n        ',
      }),
    )
    .default(true),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zFalAiFluxControlLoraDepthLoraWeight).register(z.globalRegistry, {
        description:
          '\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ',
      }),
    )
    .default([]),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(35).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  control_lora_image_url: z.string().register(z.globalRegistry, {
    description:
      '\n            The image to use for control lora. This is used to control the style of the generated image.\n        ',
  }),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiFluxControlLoraDepthImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxControlLoraDepthOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFluxControlLoraDepthImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * TextToImageInput
 */
export const zImagen3Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt describing what you want to see',
  }),
  aspect_ratio: z.optional(
    z.enum(['1:1', '16:9', '9:16', '3:4', '4:3']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated image',
    }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'Number of images to generate (1-4)',
      }),
    )
    .default(1),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for reproducible generation',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'A description of what to discourage in the generated images',
      }),
    )
    .default(''),
})

/**
 * File
 */
export const zFalAiImagen3File = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Output
 */
export const zImagen3Output = z.object({
  images: z.array(zFalAiImagen3File),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generation',
  }),
})

/**
 * TextToImageInput
 */
export const zImagen3FastInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The text prompt describing what you want to see',
  }),
  aspect_ratio: z.optional(
    z.enum(['1:1', '16:9', '9:16', '3:4', '4:3']).register(z.globalRegistry, {
      description: 'The aspect ratio of the generated image',
    }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'Number of images to generate (1-4)',
      }),
    )
    .default(1),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for reproducible generation',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'A description of what to discourage in the generated images',
      }),
    )
    .default(''),
})

/**
 * File
 */
export const zFalAiImagen3FastFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Output
 */
export const zImagen3FastOutput = z.object({
  images: z.array(zFalAiImagen3FastFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for generation',
  }),
})

/**
 * ImageSize
 */
export const zFalAiLuminaImageV2ImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * TextToImageInput
 */
export const zLuminaImageV2Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiLuminaImageV2ImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  cfg_trunc_ratio: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          'The ratio of the timestep interval to apply normalization-based guidance scale.',
      }),
    )
    .default(1),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  system_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The system prompt to use.',
      }),
    )
    .default(
      'You are an assistant designed to generate superior images with the superior degree of image-text alignment based on textual prompts or user prompts.',
    ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(4),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(30),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  cfg_normalization: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to apply normalization-based guidance scale.',
      }),
    )
    .default(true),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiLuminaImageV2Image = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * ImageOutput
 */
export const zLuminaImageV2Output = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiLuminaImageV2Image).register(z.globalRegistry, {
    description: 'The generated images',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiJanusImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * JanusInput
 */
export const zJanusInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(16).register(z.globalRegistry, {
        description: 'Number of images to generate in parallel.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiJanusImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  cfg_weight: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          'Classifier Free Guidance scale - how closely to follow the prompt.',
      }),
    )
    .default(5),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  temperature: z
    .optional(
      z.number().gte(0.1).lte(2).register(z.globalRegistry, {
        description:
          'Controls randomness in the generation. Higher values make output more random.',
      }),
    )
    .default(1),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Random seed for reproducible generation.',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiJanusImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zJanusOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiJanusImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * ImageSize
 */
export const zFalAiFluxProV11ImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * FluxProPlusTextToImageInput
 */
export const zFluxProV11Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFluxProV11ImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enhance the prompt for better results.',
      }),
    )
    .default(false),
})

/**
 * Image
 */
export const zFalAiFluxProV11RegistryImageFastSdxlModelsImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxProV11Output = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFluxProV11RegistryImageFastSdxlModelsImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * FluxProUltraTextToImageFinetunedInput
 */
export const zFluxProV11UltraFinetunedInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  finetune_id: z.string().register(z.globalRegistry, {
    description: 'References your specific model',
  }),
  safety_tolerance: z.optional(
    z.enum(['1', '2', '3', '4', '5', '6']).register(z.globalRegistry, {
      description:
        'The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.',
    }),
  ),
  image_prompt_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The strength of the image prompt, between 0 and 1.',
      }),
    )
    .default(0.1),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to enhance the prompt for better results.',
      }),
    )
    .default(false),
  raw: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Generate less processed, more natural-looking images.',
      }),
    )
    .default(false),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  aspect_ratio: z.optional(
    z.union([
      z.enum([
        '21:9',
        '16:9',
        '4:3',
        '3:2',
        '1:1',
        '2:3',
        '3:4',
        '9:16',
        '9:21',
      ]),
      z.string(),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The image URL to generate an image from.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  finetune_strength: z.number().gte(0).lte(2).register(z.globalRegistry, {
    description:
      "\n        Controls finetune influence.\n        Increase this value if your target concept isn't showing up strongly enough.\n        The optimal setting depends on your finetune and prompt\n        ",
  }),
})

/**
 * Image
 */
export const zFalAiFluxProV11UltraFinetunedRegistryImageFastSdxlModelsImage =
  z.object({
    height: z.int(),
    content_type: z.optional(z.string()).default('image/jpeg'),
    url: z.string(),
    width: z.int(),
  })

/**
 * Output
 */
export const zFluxProV11UltraFinetunedOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFluxProV11UltraFinetunedRegistryImageFastSdxlModelsImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * TextToImageInput
 */
export const zSwittiInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  sampling_top_k: z
    .optional(
      z.int().gte(10).lte(1000).register(z.globalRegistry, {
        description: 'The number of top-k tokens to sample from.',
      }),
    )
    .default(400),
  turn_off_cfg_start_si: z
    .optional(
      z.int().gte(0).lte(10).register(z.globalRegistry, {
        description: 'Disable CFG starting scale',
      }),
    )
    .default(8),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(6),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  smooth_start_si: z
    .optional(
      z.int().gte(0).lte(10).register(z.globalRegistry, {
        description: 'Smoothing starting scale',
      }),
    )
    .default(2),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  last_scale_temp: z
    .optional(
      z.number().gte(0.1).lte(10).register(z.globalRegistry, {
        description: 'Temperature after disabling CFG',
      }),
    )
    .default(0.1),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  more_diverse: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'More diverse sampling',
      }),
    )
    .default(false),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  more_smooth: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Smoothing with Gumbel softmax sampling',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  sampling_top_p: z
    .optional(
      z.number().gte(0.1).lte(1).register(z.globalRegistry, {
        description: 'The top-p probability to sample from.',
      }),
    )
    .default(0.95),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiSwittiImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * SwittiOutput
 */
export const zSwittiOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiSwittiImage).register(z.globalRegistry, {
    description: 'The generated images',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * TextToImageInput
 */
export const zSwitti512Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  sampling_top_k: z
    .optional(
      z.int().gte(10).lte(1000).register(z.globalRegistry, {
        description: 'The number of top-k tokens to sample from.',
      }),
    )
    .default(400),
  turn_off_cfg_start_si: z
    .optional(
      z.int().gte(0).lte(10).register(z.globalRegistry, {
        description: 'Disable CFG starting scale',
      }),
    )
    .default(8),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(6),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  smooth_start_si: z
    .optional(
      z.int().gte(0).lte(10).register(z.globalRegistry, {
        description: 'Smoothing starting scale',
      }),
    )
    .default(2),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  last_scale_temp: z
    .optional(
      z.number().gte(0.1).lte(10).register(z.globalRegistry, {
        description: 'Temperature after disabling CFG',
      }),
    )
    .default(0.1),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  more_diverse: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'More diverse sampling',
      }),
    )
    .default(false),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  more_smooth: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Smoothing with Gumbel softmax sampling',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  sampling_top_p: z
    .optional(
      z.number().gte(0.1).lte(1).register(z.globalRegistry, {
        description: 'The top-p probability to sample from.',
      }),
    )
    .default(0.95),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiSwitti512Image = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * SwittiOutput
 */
export const zSwitti512Output = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiSwitti512Image).register(z.globalRegistry, {
    description: 'The generated images',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * GuidanceInput
 */
export const zGuidanceInput = z.object({
  scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Impact of the guidance.',
      }),
    )
    .default(1),
  method: z.optional(
    z
      .enum([
        'controlnet_canny',
        'controlnet_depth',
        'controlnet_recoloring',
        'controlnet_color_grid',
      ])
      .register(z.globalRegistry, {
        description:
          'Which guidance type you would like to include in the generation. Up to 4 guidance methods can be combined during a single inference. This parameter is optional.',
      }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The image that should be used as guidance, in base64 format, with the method defined in guidance_method_1. Accepted formats are jpeg, jpg, png, webp. Maximum file size 12MB. If more then one guidance method is used, all guidance images must be of the same aspect ratio, and this will be the aspect ratio of the generated results. If guidance_method_1 is selected, an image must be provided.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBriaTextToImageFastImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * Output
 */
export const zBriaTextToImageFastOutput = z.object({
  images: z.array(zFalAiBriaTextToImageFastImage).register(z.globalRegistry, {
    description: 'The generated images',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed value used for generation.',
  }),
})

/**
 * GuidanceInput
 */
export const zFalAiBriaTextToImageBaseGuidanceInput = z.object({
  scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Impact of the guidance.',
      }),
    )
    .default(1),
  method: z.optional(
    z
      .enum([
        'controlnet_canny',
        'controlnet_depth',
        'controlnet_recoloring',
        'controlnet_color_grid',
      ])
      .register(z.globalRegistry, {
        description:
          'Which guidance type you would like to include in the generation. Up to 4 guidance methods can be combined during a single inference. This parameter is optional.',
      }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The image that should be used as guidance, in base64 format, with the method defined in guidance_method_1. Accepted formats are jpeg, jpg, png, webp. Maximum file size 12MB. If more then one guidance method is used, all guidance images must be of the same aspect ratio, and this will be the aspect ratio of the generated results. If guidance_method_1 is selected, an image must be provided.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBriaTextToImageBaseImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * Output
 */
export const zBriaTextToImageBaseOutput = z.object({
  images: z.array(zFalAiBriaTextToImageBaseImage).register(z.globalRegistry, {
    description: 'The generated images',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed value used for generation.',
  }),
})

/**
 * GuidanceInput
 */
export const zFalAiBriaTextToImageHdGuidanceInput = z.object({
  scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'Impact of the guidance.',
      }),
    )
    .default(1),
  method: z.optional(
    z
      .enum([
        'controlnet_canny',
        'controlnet_depth',
        'controlnet_recoloring',
        'controlnet_color_grid',
      ])
      .register(z.globalRegistry, {
        description:
          'Which guidance type you would like to include in the generation. Up to 4 guidance methods can be combined during a single inference. This parameter is optional.',
      }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The image that should be used as guidance, in base64 format, with the method defined in guidance_method_1. Accepted formats are jpeg, jpg, png, webp. Maximum file size 12MB. If more then one guidance method is used, all guidance images must be of the same aspect ratio, and this will be the aspect ratio of the generated results. If guidance_method_1 is selected, an image must be provided.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiBriaTextToImageHdImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * Output
 */
export const zBriaTextToImageHdOutput = z.object({
  images: z.array(zFalAiBriaTextToImageHdImage).register(z.globalRegistry, {
    description: 'The generated images',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed value used for generation.',
  }),
})

/**
 * ImageSize
 */
export const zFalAiRecraft20bImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * RGBColor
 */
export const zFalAiRecraft20bRgbColor = z.object({
  r: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Red color value',
      }),
    )
    .default(0),
  b: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Blue color value',
      }),
    )
    .default(0),
  g: z
    .optional(
      z.int().gte(0).lte(255).register(z.globalRegistry, {
        description: 'Green color value',
      }),
    )
    .default(0),
})

/**
 * Recraft20BTextToImageInput
 */
export const zRecraft20bInput = z.object({
  prompt: z.string().min(1).max(1000),
  image_size: z.optional(
    z.union([
      zFalAiRecraft20bImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  colors: z
    .optional(
      z.array(zFalAiRecraft20bRgbColor).register(z.globalRegistry, {
        description: 'An array of preferable colors',
      }),
    )
    .default([]),
  style: z.optional(
    z
      .enum([
        'any',
        'realistic_image',
        'digital_illustration',
        'vector_illustration',
        'realistic_image/b_and_w',
        'realistic_image/enterprise',
        'realistic_image/hard_flash',
        'realistic_image/hdr',
        'realistic_image/motion_blur',
        'realistic_image/natural_light',
        'realistic_image/studio_portrait',
        'digital_illustration/2d_art_poster',
        'digital_illustration/2d_art_poster_2',
        'digital_illustration/3d',
        'digital_illustration/80s',
        'digital_illustration/engraving_color',
        'digital_illustration/glow',
        'digital_illustration/grain',
        'digital_illustration/hand_drawn',
        'digital_illustration/hand_drawn_outline',
        'digital_illustration/handmade_3d',
        'digital_illustration/infantile_sketch',
        'digital_illustration/kawaii',
        'digital_illustration/pixel_art',
        'digital_illustration/psychedelic',
        'digital_illustration/seamless',
        'digital_illustration/voxel',
        'digital_illustration/watercolor',
        'vector_illustration/cartoon',
        'vector_illustration/doodle_line_art',
        'vector_illustration/engraving',
        'vector_illustration/flat_2',
        'vector_illustration/kawaii',
        'vector_illustration/line_art',
        'vector_illustration/line_circuit',
        'vector_illustration/linocut',
        'vector_illustration/seamless',
      ])
      .register(z.globalRegistry, {
        description:
          'The style of the generated images. Vector images cost 2X as much.',
      }),
  ),
  style_id: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The ID of the custom style reference (optional)',
    }),
  ),
})

/**
 * File
 */
export const zFalAiRecraft20bFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * Recraft20BTextToImageOutput
 */
export const zRecraft20bOutput = z.object({
  images: z.array(zFalAiRecraft20bFile),
})

/**
 * TextToImageInput
 */
export const zIdeogramV2TurboInput = z.object({
  prompt: z.string(),
  aspect_ratio: z.optional(
    z
      .enum([
        '10:16',
        '16:10',
        '9:16',
        '16:9',
        '4:3',
        '3:4',
        '1:1',
        '1:3',
        '3:1',
        '3:2',
        '2:3',
      ])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated image',
      }),
  ),
  style: z.optional(
    z
      .enum(['auto', 'general', 'realistic', 'design', 'render_3D', 'anime'])
      .register(z.globalRegistry, {
        description: 'The style of the generated image',
      }),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'Whether to expand the prompt with MagicPrompt functionality.',
      }),
    )
    .default(true),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'A negative prompt to avoid in the generated image',
      }),
    )
    .default(''),
})

/**
 * File
 */
export const zFalAiIdeogramV2TurboFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
})

/**
 * Output
 */
export const zIdeogramV2TurboOutput = z.object({
  images: z.array(zFalAiIdeogramV2TurboFile),
  seed: z.int().register(z.globalRegistry, {
    description: 'Seed used for the random number generator',
  }),
})

/**
 * TextToImageRequest
 */
export const zLumaPhotonFlashInput = z.object({
  prompt: z.string().min(3).max(5000),
  aspect_ratio: z.optional(
    z
      .enum(['16:9', '9:16', '1:1', '4:3', '3:4', '21:9', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video',
      }),
  ),
})

/**
 * File
 */
export const zFalAiLumaPhotonFlashFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * T2IOutput
 */
export const zLumaPhotonFlashOutput = z.object({
  images: z.array(zFalAiLumaPhotonFlashFile).register(z.globalRegistry, {
    description: 'The generated image',
  }),
})

/**
 * Input
 */
export const zAuraFlowInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate images from',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(2).register(z.globalRegistry, {
        description: 'The number of images to generate',
      }),
    )
    .default(1),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to perform prompt expansion (recommended)',
      }),
    )
    .default(true),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description: 'Classifier free guidance scale',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(20).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to take',
      }),
    )
    .default(50),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The seed to use for generating images',
    }),
  ),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiAuraFlowImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * Output
 */
export const zAuraFlowOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The expanded prompt',
  }),
  images: z.array(zFalAiAuraFlowImage).register(z.globalRegistry, {
    description: 'The generated images',
  }),
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used to generate the images',
  }),
})

/**
 * ImageSize
 */
export const zFalAiOmnigenV1ImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * TextToImageInput
 */
export const zOmnigenV1Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiOmnigenV1ImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  img_guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The Image Guidance scale is a measure of how close you want\n            the model to stick to your input image when looking for a related image to show you.\n        ',
      }),
    )
    .default(1.6),
  input_image_urls: z
    .optional(
      z.array(z.string()).register(z.globalRegistry, {
        description:
          'URL of images to use while generating the image, Use <img><|image_1|></img> for the first image and so on.',
      }),
    )
    .default([]),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(50),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiOmnigenV1Image = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zOmnigenV1Output = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiOmnigenV1Image).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFluxSchnellImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * SchnellTextToImageInput
 */
export const zFluxSchnellInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFluxSchnellImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  acceleration: z.optional(
    z.enum(['none', 'regular', 'high']).register(z.globalRegistry, {
      description:
        'The speed of the generation. The higher the speed, the faster the generation.',
    }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          '\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(12).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(4),
})

/**
 * Image
 */
export const zFalAiFluxSchnellImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxSchnellOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFluxSchnellImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiStableDiffusionV35MediumImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * TextToImageInput
 */
export const zStableDiffusionV35MediumInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiStableDiffusionV35MediumImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(4.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(40),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zFalAiStableDiffusionV35MediumImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zStableDiffusionV35MediumOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiStableDiffusionV35MediumImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFluxLoraInpaintingImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zFalAiFluxLoraInpaintingLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * InpaintInput
 */
export const zFluxLoraInpaintingInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description:
          'The number of images to generate. This is always set to 1 for streaming output.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFluxLoraInpaintingImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image to use for inpainting. or img2img',
  }),
  loras: z
    .optional(
      z.array(zFalAiFluxLoraInpaintingLoraWeight).register(z.globalRegistry, {
        description:
          '\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ',
      }),
    )
    .default([]),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          'The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.',
      }),
    )
    .default(0.85),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(35).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  mask_url: z.string().register(z.globalRegistry, {
    description: '\n            The mask to area to Inpaint in.\n        ',
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zFalAiFluxLoraInpaintingImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxLoraInpaintingOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFluxLoraInpaintingImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiStableDiffusionV3MediumImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * TextToImageInput
 */
export const zStableDiffusionV3MediumInput = z.object({
  prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, prompt will be upsampled with more details.',
      }),
    )
    .default(false),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiStableDiffusionV3MediumImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(28),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'The negative prompt to generate an image from.',
      }),
    )
    .default(''),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zFalAiStableDiffusionV3MediumImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * SD3Output
 */
export const zStableDiffusionV3MediumOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiStableDiffusionV3MediumImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  num_images: z.int().register(z.globalRegistry, {
    description: 'The number of images generated.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImagePrompt
 */
export const zImagePrompt = z.object({
  weight: z.optional(z.number().gte(0).lte(2)).default(1),
  stop_at: z.optional(z.number().gte(0).lte(1)).default(0.5),
  type: z.optional(z.enum(['ImagePrompt', 'PyraCanny', 'CPDS', 'FaceSwap'])),
  image_url: z.optional(z.string()),
})

/**
 * LoraWeight
 */
export const zFalAiFooocusUpscaleOrVaryLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(0.1),
})

/**
 * FooocusUpscaleOrVaryInput
 */
export const zFooocusUpscaleOrVaryInput = z.object({
  styles: z
    .optional(
      z
        .array(
          z.enum([
            'Fooocus V2',
            'Fooocus Enhance',
            'Fooocus Sharp',
            'Fooocus Semi Realistic',
            'Fooocus Masterpiece',
            'Fooocus Photograph',
            'Fooocus Negative',
            'Fooocus Cinematic',
            'SAI 3D Model',
            'SAI Analog Film',
            'SAI Anime',
            'SAI Cinematic',
            'SAI Comic Book',
            'SAI Craft Clay',
            'SAI Digital Art',
            'SAI Enhance',
            'SAI Fantasy Art',
            'SAI Isometric',
            'SAI Line Art',
            'SAI Lowpoly',
            'SAI Neonpunk',
            'SAI Origami',
            'SAI Photographic',
            'SAI Pixel Art',
            'SAI Texture',
            'MRE Cinematic Dynamic',
            'MRE Spontaneous Picture',
            'MRE Artistic Vision',
            'MRE Dark Dream',
            'MRE Gloomy Art',
            'MRE Bad Dream',
            'MRE Underground',
            'MRE Surreal Painting',
            'MRE Dynamic Illustration',
            'MRE Undead Art',
            'MRE Elemental Art',
            'MRE Space Art',
            'MRE Ancient Illustration',
            'MRE Brave Art',
            'MRE Heroic Fantasy',
            'MRE Dark Cyberpunk',
            'MRE Lyrical Geometry',
            'MRE Sumi E Symbolic',
            'MRE Sumi E Detailed',
            'MRE Manga',
            'MRE Anime',
            'MRE Comic',
            'Ads Advertising',
            'Ads Automotive',
            'Ads Corporate',
            'Ads Fashion Editorial',
            'Ads Food Photography',
            'Ads Gourmet Food Photography',
            'Ads Luxury',
            'Ads Real Estate',
            'Ads Retail',
            'Artstyle Abstract',
            'Artstyle Abstract Expressionism',
            'Artstyle Art Deco',
            'Artstyle Art Nouveau',
            'Artstyle Constructivist',
            'Artstyle Cubist',
            'Artstyle Expressionist',
            'Artstyle Graffiti',
            'Artstyle Hyperrealism',
            'Artstyle Impressionist',
            'Artstyle Pointillism',
            'Artstyle Pop Art',
            'Artstyle Psychedelic',
            'Artstyle Renaissance',
            'Artstyle Steampunk',
            'Artstyle Surrealist',
            'Artstyle Typography',
            'Artstyle Watercolor',
            'Futuristic Biomechanical',
            'Futuristic Biomechanical Cyberpunk',
            'Futuristic Cybernetic',
            'Futuristic Cybernetic Robot',
            'Futuristic Cyberpunk Cityscape',
            'Futuristic Futuristic',
            'Futuristic Retro Cyberpunk',
            'Futuristic Retro Futurism',
            'Futuristic Sci Fi',
            'Futuristic Vaporwave',
            'Game Bubble Bobble',
            'Game Cyberpunk Game',
            'Game Fighting Game',
            'Game Gta',
            'Game Mario',
            'Game Minecraft',
            'Game Pokemon',
            'Game Retro Arcade',
            'Game Retro Game',
            'Game Rpg Fantasy Game',
            'Game Strategy Game',
            'Game Streetfighter',
            'Game Zelda',
            'Misc Architectural',
            'Misc Disco',
            'Misc Dreamscape',
            'Misc Dystopian',
            'Misc Fairy Tale',
            'Misc Gothic',
            'Misc Grunge',
            'Misc Horror',
            'Misc Kawaii',
            'Misc Lovecraftian',
            'Misc Macabre',
            'Misc Manga',
            'Misc Metropolis',
            'Misc Minimalist',
            'Misc Monochrome',
            'Misc Nautical',
            'Misc Space',
            'Misc Stained Glass',
            'Misc Techwear Fashion',
            'Misc Tribal',
            'Misc Zentangle',
            'Papercraft Collage',
            'Papercraft Flat Papercut',
            'Papercraft Kirigami',
            'Papercraft Paper Mache',
            'Papercraft Paper Quilling',
            'Papercraft Papercut Collage',
            'Papercraft Papercut Shadow Box',
            'Papercraft Stacked Papercut',
            'Papercraft Thick Layered Papercut',
            'Photo Alien',
            'Photo Film Noir',
            'Photo Glamour',
            'Photo Hdr',
            'Photo Iphone Photographic',
            'Photo Long Exposure',
            'Photo Neon Noir',
            'Photo Silhouette',
            'Photo Tilt Shift',
            'Cinematic Diva',
            'Abstract Expressionism',
            'Academia',
            'Action Figure',
            'Adorable 3D Character',
            'Adorable Kawaii',
            'Art Deco',
            'Art Nouveau',
            'Astral Aura',
            'Avant Garde',
            'Baroque',
            'Bauhaus Style Poster',
            'Blueprint Schematic Drawing',
            'Caricature',
            'Cel Shaded Art',
            'Character Design Sheet',
            'Classicism Art',
            'Color Field Painting',
            'Colored Pencil Art',
            'Conceptual Art',
            'Constructivism',
            'Cubism',
            'Dadaism',
            'Dark Fantasy',
            'Dark Moody Atmosphere',
            'Dmt Art Style',
            'Doodle Art',
            'Double Exposure',
            'Dripping Paint Splatter Art',
            'Expressionism',
            'Faded Polaroid Photo',
            'Fauvism',
            'Flat 2d Art',
            'Fortnite Art Style',
            'Futurism',
            'Glitchcore',
            'Glo Fi',
            'Googie Art Style',
            'Graffiti Art',
            'Harlem Renaissance Art',
            'High Fashion',
            'Idyllic',
            'Impressionism',
            'Infographic Drawing',
            'Ink Dripping Drawing',
            'Japanese Ink Drawing',
            'Knolling Photography',
            'Light Cheery Atmosphere',
            'Logo Design',
            'Luxurious Elegance',
            'Macro Photography',
            'Mandola Art',
            'Marker Drawing',
            'Medievalism',
            'Minimalism',
            'Neo Baroque',
            'Neo Byzantine',
            'Neo Futurism',
            'Neo Impressionism',
            'Neo Rococo',
            'Neoclassicism',
            'Op Art',
            'Ornate And Intricate',
            'Pencil Sketch Drawing',
            'Pop Art 2',
            'Rococo',
            'Silhouette Art',
            'Simple Vector Art',
            'Sketchup',
            'Steampunk 2',
            'Surrealism',
            'Suprematism',
            'Terragen',
            'Tranquil Relaxing Atmosphere',
            'Sticker Designs',
            'Vibrant Rim Light',
            'Volumetric Lighting',
            'Watercolor 2',
            'Whimsical And Playful',
            'Mk Chromolithography',
            'Mk Cross Processing Print',
            'Mk Dufaycolor Photograph',
            'Mk Herbarium',
            'Mk Punk Collage',
            'Mk Mosaic',
            'Mk Van Gogh',
            'Mk Coloring Book',
            'Mk Singer Sargent',
            'Mk Pollock',
            'Mk Basquiat',
            'Mk Andy Warhol',
            'Mk Halftone Print',
            'Mk Gond Painting',
            'Mk Albumen Print',
            'Mk Aquatint Print',
            'Mk Anthotype Print',
            'Mk Inuit Carving',
            'Mk Bromoil Print',
            'Mk Calotype Print',
            'Mk Color Sketchnote',
            'Mk Cibulak Porcelain',
            'Mk Alcohol Ink Art',
            'Mk One Line Art',
            'Mk Blacklight Paint',
            'Mk Carnival Glass',
            'Mk Cyanotype Print',
            'Mk Cross Stitching',
            'Mk Encaustic Paint',
            'Mk Embroidery',
            'Mk Gyotaku',
            'Mk Luminogram',
            'Mk Lite Brite Art',
            'Mk Mokume Gane',
            'Pebble Art',
            'Mk Palekh',
            'Mk Suminagashi',
            'Mk Scrimshaw',
            'Mk Shibori',
            'Mk Vitreous Enamel',
            'Mk Ukiyo E',
            'Mk Vintage Airline Poster',
            'Mk Vintage Travel Poster',
            'Mk Bauhaus Style',
            'Mk Afrofuturism',
            'Mk Atompunk',
            'Mk Constructivism',
            'Mk Chicano Art',
            'Mk De Stijl',
            'Mk Dayak Art',
            'Mk Fayum Portrait',
            'Mk Illuminated Manuscript',
            'Mk Kalighat Painting',
            'Mk Madhubani Painting',
            'Mk Pictorialism',
            'Mk Pichwai Painting',
            'Mk Patachitra Painting',
            'Mk Samoan Art Inspired',
            'Mk Tlingit Art',
            'Mk Adnate Style',
            'Mk Ron English Style',
            'Mk Shepard Fairey Style',
          ]),
        )
        .register(z.globalRegistry, {
          description: '\n            The style to use.\n        ',
        }),
    )
    .default(['Fooocus Enhance', 'Fooocus V2', 'Fooocus Sharp']),
  uov_image_url: z.string().register(z.globalRegistry, {
    description: 'The image to upscale or vary.',
  }),
  performance: z.optional(
    z
      .enum(['Speed', 'Quality', 'Extreme Speed', 'Lightning'])
      .register(z.globalRegistry, {
        description: '\n            You can choose Speed or Quality\n        ',
      }),
  ),
  mixing_image_prompt_and_vary_upscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Mixing Image Prompt and Vary/Upscale',
      }),
    )
    .default(false),
  image_prompt_3: z.optional(zImagePrompt),
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'The prompt to use for generating the image. Be as descriptive as possible for best results.',
      }),
    )
    .default(''),
  loras: z
    .optional(
      z.array(zFalAiFooocusUpscaleOrVaryLoraWeight).register(z.globalRegistry, {
        description:
          '\n            The LoRAs to use for the image generation. You can use up to 5 LoRAs\n            and they will be merged together to generate the final image.\n        ',
      }),
    )
    .default([
      {
        path: 'https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors',
        scale: 0.1,
      },
    ]),
  image_prompt_4: z.optional(zImagePrompt),
  image_prompt_1: z.optional(zImagePrompt),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to false, the safety checker will be disabled.',
      }),
    )
    .default(true),
  sharpness: z
    .optional(
      z.number().gte(0).lte(30).register(z.globalRegistry, {
        description:
          '\n            The sharpness of the generated image. Use it to control how sharp the generated\n            image should be. Higher value means image and texture are sharper.\n        ',
      }),
    )
    .default(2),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(30).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(4),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  aspect_ratio: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          '\n            The size of the generated image. You can choose between some presets or\n            custom height and width that **must be multiples of 8**.\n        ',
      }),
    )
    .default('1024x1024'),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description:
          '\n            Number of images to generate in one request\n        ',
      }),
    )
    .default(1),
  output_format: z.optional(
    z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  refiner_model: z.optional(
    z
      .enum(['None', 'realisticVisionV60B1_v51VAE.safetensors'])
      .register(z.globalRegistry, {
        description: 'Refiner (SDXL or SD 1.5)',
      }),
  ),
  image_prompt_2: z.optional(zImagePrompt),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  uov_method: z.optional(
    z
      .enum([
        'Disabled',
        'Vary (Subtle)',
        'Vary (Strong)',
        'Upscale (1.5x)',
        'Upscale (2x)',
        'Upscale (Fast 2x)',
      ])
      .register(z.globalRegistry, {
        description: 'The method to use for upscaling or varying.',
      }),
  ),
  seed: z.optional(z.union([z.int(), z.null()])),
  refiner_switch: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            Use 0.4 for SD1.5 realistic models; 0.667 for SD1.5 anime models\n            0.8 for XL-refiners; or any value for switching two SDXL models.\n        ',
      }),
    )
    .default(0.8),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFooocusUpscaleOrVaryImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FooocusOutput
 */
export const zFooocusUpscaleOrVaryOutput = z.object({
  images: z.array(zFalAiFooocusUpscaleOrVaryImage).register(z.globalRegistry, {
    description: 'The generated image file info.',
  }),
  timings: z.record(z.string(), z.number()).register(z.globalRegistry, {
    description: 'The time taken for the generation process.',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFluxSubjectImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * FluxSubjectInput
 */
export const zFluxSubjectInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFluxSubjectImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_url: z.string().register(z.globalRegistry, {
    description: 'URL of image of the subject',
  }),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(8),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zFalAiFluxSubjectImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFluxSubjectOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFluxSubjectImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiSanaImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * TextToImageInput
 */
export const zSanaInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt to generate an image from.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiSanaImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  style_name: z.optional(
    z
      .enum([
        '(No style)',
        'Cinematic',
        'Photographic',
        'Anime',
        'Manga',
        'Digital Art',
        'Pixel art',
        'Fantasy art',
        'Neonpunk',
        '3D Model',
      ])
      .register(z.globalRegistry, {
        description: 'The style to generate the image in.',
      }),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(18),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zFalAiSanaImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zSanaOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiSanaImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiPixartSigmaImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * PixArtSigmaInput
 */
export const zPixartSigmaInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiPixartSigmaImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  style: z.optional(
    z
      .enum([
        '(No style)',
        'Cinematic',
        'Photographic',
        'Anime',
        'Manga',
        'Digital Art',
        'Pixel art',
        'Fantasy art',
        'Neonpunk',
        '3D Model',
      ])
      .register(z.globalRegistry, {
        description: 'The style to apply to the image.',
      }),
  ),
  scheduler: z.optional(
    z.enum(['DPM-SOLVER', 'SA-SOLVER']).register(z.globalRegistry, {
      description: 'The scheduler to use for the model.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(4.5),
  num_inference_steps: z
    .optional(
      z.int().gte(5).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(35),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiPixartSigmaImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * PixArtSigmaOutput
 */
export const zPixartSigmaOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiPixartSigmaImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()).register(z.globalRegistry, {
    description:
      'The timings of the different steps of the generation process.',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiSdxlControlnetUnionImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Embedding
 */
export const zEmbedding = z.object({
  tokens: z
    .optional(
      z.array(z.string()).register(z.globalRegistry, {
        description: 'The list of tokens to use for the embedding.',
      }),
    )
    .default(['<s0>', '<s1>']),
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the embedding weights.',
  }),
})

/**
 * LoraWeight
 */
export const zFalAiSdxlControlnetUnionLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights. Or HF model name.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
  force: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the embedding will be forced to be used.',
      }),
    )
    .default(false),
})

/**
 * TextToImageControlNetUnionInput
 */
export const zSdxlControlnetUnionInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  depth_preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the depth image.',
      }),
    )
    .default(true),
  image_size: z.optional(
    z.union([
      zFalAiSdxlControlnetUnionImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
      z.null(),
    ]),
  ),
  normal_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The URL of the control image.',
    }),
  ),
  embeddings: z
    .optional(
      z.array(zEmbedding).register(z.globalRegistry, {
        description: 'The list of embeddings to use.',
      }),
    )
    .default([]),
  teed_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The URL of the control image.',
    }),
  ),
  loras: z
    .optional(
      z.array(zFalAiSdxlControlnetUnionLoraWeight).register(z.globalRegistry, {
        description: 'The list of LoRA weights to use.',
      }),
    )
    .default([]),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(7.5),
  canny_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The URL of the control image.',
    }),
  ),
  segmentation_preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the segmentation image.',
      }),
    )
    .default(true),
  format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  request_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          '\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ',
      }),
    )
    .default(''),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  segmentation_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The URL of the control image.',
    }),
  ),
  openpose_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The URL of the control image.',
    }),
  ),
  canny_preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the canny image.',
      }),
    )
    .default(true),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded with additional prompts.',
      }),
    )
    .default(false),
  depth_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The URL of the control image.',
    }),
  ),
  normal_preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the normal image.',
      }),
    )
    .default(true),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  teed_preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the teed image.',
      }),
    )
    .default(true),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  controlnet_conditioning_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The scale of the controlnet conditioning.',
      }),
    )
    .default(0.5),
  safety_checker_version: z.optional(
    z.enum(['v1', 'v2']).register(z.globalRegistry, {
      description:
        'The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.',
    }),
  ),
  openpose_preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Whether to preprocess the openpose image.',
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(70).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(35),
})

/**
 * Image
 */
export const zFalAiSdxlControlnetUnionImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zSdxlControlnetUnionOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiSdxlControlnetUnionImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiKolorsImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * KolorsInput
 */
export const zKolorsInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      '\n            The prompt to use for generating the image. Be as descriptive as possible\n            for best results.\n        ',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiKolorsImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  output_format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and\n            uploaded before returning the response. This will increase the latency of\n            the function but it allows you to get the image directly in the response\n            without going through the CDN.\n        ',
      }),
    )
    .default(false),
  scheduler: z.optional(
    z
      .enum([
        'EulerDiscreteScheduler',
        'EulerAncestralDiscreteScheduler',
        'DPMSolverMultistepScheduler',
        'DPMSolverMultistepScheduler_SDE_karras',
        'UniPCMultistepScheduler',
        'DEISMultistepScheduler',
      ])
      .register(z.globalRegistry, {
        description: 'The scheduler to use for the model.',
      }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show\n            you.\n        ',
      }),
    )
    .default(5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(150).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(50),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'Seed',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small\n            details (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Enable safety checker.',
      }),
    )
    .default(true),
})

/**
 * Image
 */
export const zFalAiKolorsImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zKolorsOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiKolorsImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiStableCascadeImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * StableCascadeInput
 */
export const zStableCascadeInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiStableCascadeImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  second_stage_guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(0),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the image will be returned as base64 encoded string.\n        ',
      }),
    )
    .default(false),
  first_stage_steps: z
    .optional(
      z.int().gte(4).lte(40).register(z.globalRegistry, {
        description: 'Number of steps to run the first stage for.',
      }),
    )
    .default(20),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(4),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Cascade\n            will output the same image every time.\n        ',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to false, the safety checker will be disabled.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  second_stage_steps: z
    .optional(
      z.int().gte(4).lte(24).register(z.globalRegistry, {
        description: 'Number of steps to run the second stage for.',
      }),
    )
    .default(10),
})

/**
 * Image
 */
export const zFalAiStableCascadeImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zStableCascadeOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiStableCascadeImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFastSdxlImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Embedding
 */
export const zFalAiFastSdxlEmbedding = z.object({
  tokens: z
    .optional(
      z.array(z.string()).register(z.globalRegistry, {
        description: 'The list of tokens to use for the embedding.',
      }),
    )
    .default(['<s0>', '<s1>']),
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the embedding weights.',
  }),
})

/**
 * LoraWeight
 */
export const zFalAiFastSdxlLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights. Or HF model name.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
  force: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the embedding will be forced to be used.',
      }),
    )
    .default(false),
})

/**
 * TextToImageInput
 */
export const zFastSdxlInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiFastSdxlImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  embeddings: z
    .optional(
      z.array(zFalAiFastSdxlEmbedding).register(z.globalRegistry, {
        description: 'The list of embeddings to use.',
      }),
    )
    .default([]),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded with additional prompts.',
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zFalAiFastSdxlLoraWeight).register(z.globalRegistry, {
        description: 'The list of LoRA weights to use.',
      }),
    )
    .default([]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(7.5),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  safety_checker_version: z.optional(
    z.enum(['v1', 'v2']).register(z.globalRegistry, {
      description:
        'The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.',
    }),
  ),
  request_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          '\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ',
      }),
    )
    .default(''),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(25),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiFastSdxlImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFastSdxlOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFastSdxlImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  timings: z.record(z.string(), z.number()),
})

/**
 * ImageSize
 */
export const zFalAiStableCascadeSoteDiffusionImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * SoteDiffusionInput
 */
export const zStableCascadeSoteDiffusionInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiStableCascadeSoteDiffusionImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  second_stage_guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(2),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the image will be returned as base64 encoded string.\n        ',
      }),
    )
    .default(false),
  first_stage_steps: z
    .optional(
      z.int().gte(4).lte(50).register(z.globalRegistry, {
        description: 'Number of steps to run the first stage for.',
      }),
    )
    .default(25),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(8),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Cascade\n            will output the same image every time.\n        ',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to false, the safety checker will be disabled.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  second_stage_steps: z
    .optional(
      z.int().gte(4).lte(24).register(z.globalRegistry, {
        description: 'Number of steps to run the second stage for.',
      }),
    )
    .default(10),
})

/**
 * Image
 */
export const zFalAiStableCascadeSoteDiffusionImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zStableCascadeSoteDiffusionOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiStableCascadeSoteDiffusionImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * TextToImageRequest
 */
export const zLumaPhotonInput = z.object({
  prompt: z.string().min(3).max(5000),
  aspect_ratio: z.optional(
    z
      .enum(['16:9', '9:16', '1:1', '4:3', '3:4', '21:9', '9:21'])
      .register(z.globalRegistry, {
        description: 'The aspect ratio of the generated video',
      }),
  ),
})

/**
 * File
 */
export const zFalAiLumaPhotonFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * T2IOutput
 */
export const zLumaPhotonOutput = z.object({
  images: z.array(zFalAiLumaPhotonFile).register(z.globalRegistry, {
    description: 'The generated image',
  }),
})

/**
 * ImageSize
 */
export const zFalAiLightningModelsImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Embedding
 */
export const zFalAiLightningModelsEmbedding = z.object({
  tokens: z
    .optional(
      z.array(z.string()).register(z.globalRegistry, {
        description: 'The list of tokens to use for the embedding.',
      }),
    )
    .default(['<s0>', '<s1>']),
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the embedding weights.',
  }),
})

/**
 * LoraWeight
 */
export const zFalAiLightningModelsLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights. Or HF model name.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
  force: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the embedding will be forced to be used.',
      }),
    )
    .default(false),
})

/**
 * LightningModelsTextToImageInput
 */
export const zLightningModelsInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiLightningModelsImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  embeddings: z
    .optional(
      z.array(zFalAiLightningModelsEmbedding).register(z.globalRegistry, {
        description: 'The list of embeddings to use.',
      }),
    )
    .default([]),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded with additional prompts.',
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zFalAiLightningModelsLoraWeight).register(z.globalRegistry, {
        description: 'The list of LoRA weights to use.',
      }),
    )
    .default([]),
  scheduler: z.optional(
    z
      .enum([
        'DPM++ 2M',
        'DPM++ 2M Karras',
        'DPM++ 2M SDE',
        'DPM++ 2M SDE Karras',
        'DPM++ SDE',
        'DPM++ SDE Karras',
        'KDPM 2A',
        'Euler',
        'Euler (trailing timesteps)',
        'Euler A',
        'LCM',
        'EDMDPMSolverMultistepScheduler',
        'TCDScheduler',
      ])
      .register(z.globalRegistry, {
        description:
          'Scheduler / sampler to use for the image denoising process.',
      }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(2).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(2),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "The negative prompt to use. Use it to address details that you don't want in the image.",
      }),
    )
    .default(
      '(worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (airbrushed, cartoon, anime, semi-realistic, cgi, render, blender, digital art, manga, amateur:1.3), (3D ,3D Game, 3D Game Scene, 3D Character:1.1), (bad hands, bad anatomy, bad body, bad face, bad teeth, bad arms, bad legs, deformities:1.3)',
    ),
  format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  model_name: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The Lightning model to use.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  safety_checker_version: z.optional(
    z.enum(['v1', 'v2']).register(z.globalRegistry, {
      description:
        'The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(12).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiLightningModelsImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zLightningModelsOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiLightningModelsImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiPlaygroundV25ImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Embedding
 */
export const zFalAiPlaygroundV25Embedding = z.object({
  tokens: z
    .optional(
      z.array(z.string()).register(z.globalRegistry, {
        description: 'The list of tokens to use for the embedding.',
      }),
    )
    .default(['<s0>', '<s1>']),
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the embedding weights.',
  }),
})

/**
 * TextToImagePlaygroundv25Input
 */
export const zPlaygroundV25Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiPlaygroundV25ImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  embeddings: z
    .optional(
      z.array(zFalAiPlaygroundV25Embedding).register(z.globalRegistry, {
        description: 'The list of embeddings to use.',
      }),
    )
    .default([]),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded with additional prompts.',
      }),
    )
    .default(false),
  guidance_rescale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The rescale factor for the CFG.',
      }),
    )
    .default(0),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(3),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  safety_checker_version: z.optional(
    z.enum(['v1', 'v2']).register(z.globalRegistry, {
      description:
        'The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.',
    }),
  ),
  request_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          '\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ',
      }),
    )
    .default(''),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(25),
})

/**
 * Image
 */
export const zFalAiPlaygroundV25Image = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zPlaygroundV25Output = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiPlaygroundV25Image).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiRealisticVisionImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Embedding
 */
export const zFalAiRealisticVisionEmbedding = z.object({
  tokens: z
    .optional(
      z.array(z.string()).register(z.globalRegistry, {
        description: 'The list of tokens to use for the embedding.',
      }),
    )
    .default(['<s0>', '<s1>']),
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the embedding weights.',
  }),
})

/**
 * LoraWeight
 */
export const zFalAiRealisticVisionLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights. Or HF model name.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
  force: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the embedding will be forced to be used.',
      }),
    )
    .default(false),
})

/**
 * RealisticVisionTextToImageInput
 */
export const zRealisticVisionInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiRealisticVisionImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  embeddings: z
    .optional(
      z.array(zFalAiRealisticVisionEmbedding).register(z.globalRegistry, {
        description: 'The list of embeddings to use.',
      }),
    )
    .default([]),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded with additional prompts.',
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zFalAiRealisticVisionLoraWeight).register(z.globalRegistry, {
        description: 'The list of LoRA weights to use.',
      }),
    )
    .default([]),
  guidance_rescale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The rescale factor for the CFG.',
      }),
    )
    .default(0),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(5),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "The negative prompt to use. Use it to address details that you don't want in the image.",
      }),
    )
    .default(
      '(worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (airbrushed, cartoon, anime, semi-realistic, cgi, render, blender, digital art, manga, amateur:1.3), (3D ,3D Game, 3D Game Scene, 3D Character:1.1), (bad hands, bad anatomy, bad body, bad face, bad teeth, bad arms, bad legs, deformities:1.3)',
    ),
  format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  model_name: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The Realistic Vision model to use.',
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  safety_checker_version: z.optional(
    z.enum(['v1', 'v2']).register(z.globalRegistry, {
      description:
        'The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.',
    }),
  ),
  request_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          '\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ',
      }),
    )
    .default(''),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(70).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(35),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiRealisticVisionImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zRealisticVisionOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiRealisticVisionImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiDreamshaperImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Embedding
 */
export const zFalAiDreamshaperEmbedding = z.object({
  tokens: z
    .optional(
      z.array(z.string()).register(z.globalRegistry, {
        description: 'The list of tokens to use for the embedding.',
      }),
    )
    .default(['<s0>', '<s1>']),
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the embedding weights.',
  }),
})

/**
 * LoraWeight
 */
export const zFalAiDreamshaperLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights. Or HF model name.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
  force: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the embedding will be forced to be used.',
      }),
    )
    .default(false),
})

/**
 * DreamshaperTextToImageInput
 */
export const zDreamshaperInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiDreamshaperImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  embeddings: z
    .optional(
      z.array(zFalAiDreamshaperEmbedding).register(z.globalRegistry, {
        description: 'The list of embeddings to use.',
      }),
    )
    .default([]),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded with additional prompts.',
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zFalAiDreamshaperLoraWeight).register(z.globalRegistry, {
        description: 'The list of LoRA weights to use.',
      }),
    )
    .default([]),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          'The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.',
      }),
    )
    .default(5),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "The negative prompt to use. Use it to address details that you don't want in the image.",
      }),
    )
    .default(
      '(worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (airbrushed, cartoon, anime, semi-realistic, cgi, render, blender, digital art, manga, amateur:1.3), (3D ,3D Game, 3D Game Scene, 3D Character:1.1), (bad hands, bad anatomy, bad body, bad face, bad teeth, bad arms, bad legs, deformities:1.3)',
    ),
  format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  model_name: z.optional(
    z
      .enum([
        'Lykon/dreamshaper-xl-1-0',
        'Lykon/dreamshaper-xl-v2-turbo',
        'Lykon/dreamshaper-8',
      ])
      .register(z.globalRegistry, {
        description: 'The Dreamshaper model to use.',
      }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  safety_checker_version: z.optional(
    z.enum(['v1', 'v2']).register(z.globalRegistry, {
      description:
        'The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(70).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(35),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiDreamshaperImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zDreamshaperOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiDreamshaperImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiStableDiffusionV15ImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Embedding
 */
export const zFalAiStableDiffusionV15Embedding = z.object({
  tokens: z
    .optional(
      z.array(z.string()).register(z.globalRegistry, {
        description: 'The list of tokens to use for the embedding.',
      }),
    )
    .default(['<s0>', '<s1>']),
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the embedding weights.',
  }),
})

/**
 * LoraWeight
 */
export const zFalAiStableDiffusionV15LoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights. Or HF model name.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
  force: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the embedding will be forced to be used.',
      }),
    )
    .default(false),
})

/**
 * TextToImageSD15Input
 */
export const zStableDiffusionV15Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiStableDiffusionV15ImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  embeddings: z
    .optional(
      z.array(zFalAiStableDiffusionV15Embedding).register(z.globalRegistry, {
        description: 'The list of embeddings to use.',
      }),
    )
    .default([]),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded with additional prompts.',
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zFalAiStableDiffusionV15LoraWeight).register(z.globalRegistry, {
        description: 'The list of LoRA weights to use.',
      }),
    )
    .default([]),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(7.5),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  safety_checker_version: z.optional(
    z.enum(['v1', 'v2']).register(z.globalRegistry, {
      description:
        'The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.',
    }),
  ),
  request_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          '\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ',
      }),
    )
    .default(''),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(25),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiStableDiffusionV15Image = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zStableDiffusionV15Output = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiStableDiffusionV15Image).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * Input
 */
export const zLayerDiffusionInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'The prompt to use for generating the image. Be as descriptive as possible for best results.',
      }),
    )
    .default(''),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description: 'The guidance scale for the model.',
      }),
    )
    .default(8),
  num_inference_steps: z
    .optional(
      z.int().gte(10).lte(40).register(z.globalRegistry, {
        description: 'The number of inference steps for the model.',
      }),
    )
    .default(20),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'The prompt to use for generating the negative image. Be as descriptive as possible for best results.',
      }),
    )
    .default('text, watermark'),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to false, the safety checker will be disabled.',
      }),
    )
    .default(true),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiLayerDiffusionImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * Output
 */
export const zLayerDiffusionOutput = z.object({
  image: zFalAiLayerDiffusionImage,
  seed: z.int().register(z.globalRegistry, {
    description: 'The seed used to generate the image.',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFastLightningSdxlImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Embedding
 */
export const zFalAiFastLightningSdxlEmbedding = z.object({
  tokens: z
    .optional(
      z.array(z.string()).register(z.globalRegistry, {
        description: 'The list of tokens to use for the embedding.',
      }),
    )
    .default(['<s0>', '<s1>']),
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the embedding weights.',
  }),
})

/**
 * TextToImageLightningInput
 */
export const zFastLightningSdxlInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_size: z.optional(
    z.union([
      zFalAiFastLightningSdxlImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  embeddings: z
    .optional(
      z.array(zFalAiFastLightningSdxlEmbedding).register(z.globalRegistry, {
        description: 'The list of embeddings to use.',
      }),
    )
    .default([]),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded with additional prompts.',
      }),
    )
    .default(false),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  guidance_rescale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The rescale factor for the CFG.',
      }),
    )
    .default(0),
  safety_checker_version: z.optional(
    z.enum(['v1', 'v2']).register(z.globalRegistry, {
      description:
        'The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.',
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  num_inference_steps: z.optional(
    z.enum(['1', '2', '4', '8']).register(z.globalRegistry, {
      description: 'The number of inference steps to perform.',
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  request_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          '\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ',
      }),
    )
    .default(''),
})

/**
 * Image
 */
export const zFalAiFastLightningSdxlImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFastLightningSdxlOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFastLightningSdxlImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFastFooocusSdxlImageToImageImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Embedding
 */
export const zFalAiFastFooocusSdxlImageToImageEmbedding = z.object({
  tokens: z
    .optional(
      z.array(z.string()).register(z.globalRegistry, {
        description: 'The list of tokens to use for the embedding.',
      }),
    )
    .default(['<s0>', '<s1>']),
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the embedding weights.',
  }),
})

/**
 * ImageToImageFooocusInput
 */
export const zFastFooocusSdxlImageToImageInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  enable_refiner: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, a smaller model will try to refine the output after it was processed.',
      }),
    )
    .default(true),
  image_size: z.optional(
    z.union([
      zFalAiFastFooocusSdxlImageToImageImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
      z.null(),
    ]),
  ),
  embeddings: z
    .optional(
      z
        .array(zFalAiFastFooocusSdxlImageToImageEmbedding)
        .register(z.globalRegistry, {
          description: 'The list of embeddings to use.',
        }),
    )
    .default([]),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded with additional prompts.',
      }),
    )
    .default(true),
  guidance_rescale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The rescale factor for the CFG.',
      }),
    )
    .default(0),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(2),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  image_url: z.string().register(z.globalRegistry, {
    description:
      'The URL of the image to use as a starting point for the generation.',
  }),
  strength: z
    .optional(
      z.number().gte(0.05).lte(1).register(z.globalRegistry, {
        description:
          'determines how much the generated image resembles the initial image',
      }),
    )
    .default(0.95),
  safety_checker_version: z.optional(
    z.enum(['v1', 'v2']).register(z.globalRegistry, {
      description:
        'The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(24).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(8),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiFastFooocusSdxlImageToImageImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFastFooocusSdxlImageToImageOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z
    .array(zFalAiFastFooocusSdxlImageToImageImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFastSdxlControlnetCannyImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LoraWeight
 */
export const zFalAiFastSdxlControlnetCannyLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights. Or HF model name.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(1),
})

/**
 * TextToImageControlNetInput
 */
export const zFastSdxlControlnetCannyInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiFastSdxlControlnetCannyImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
      z.null(),
    ]),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded with additional prompts.',
      }),
    )
    .default(false),
  loras: z
    .optional(
      z
        .array(zFalAiFastSdxlControlnetCannyLoraWeight)
        .register(z.globalRegistry, {
          description: 'The list of LoRA weights to use.',
        }),
    )
    .default([]),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(7.5),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  controlnet_conditioning_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The scale of the controlnet conditioning.',
      }),
    )
    .default(0.5),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  control_image_url: z.string().register(z.globalRegistry, {
    description: 'The URL of the control image.',
  }),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(25),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  enable_deep_cache: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, DeepCache will be enabled. TBD\n        ',
      }),
    )
    .default(false),
})

/**
 * Image
 */
export const zFalAiFastSdxlControlnetCannyImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFastSdxlControlnetCannyOutput = z.object({
  images: z
    .array(zFalAiFastSdxlControlnetCannyImage)
    .register(z.globalRegistry, {
      description: 'The generated image files info.',
    }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFastLcmDiffusionImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * TextToImageLCMInput
 */
export const zFastLcmDiffusionInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiFastLcmDiffusionImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded with additional prompts.',
      }),
    )
    .default(false),
  guidance_rescale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The rescale factor for the CFG.',
      }),
    )
    .default(0),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(1.5),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  model_name: z.optional(
    z
      .enum([
        'stabilityai/stable-diffusion-xl-base-1.0',
        'runwayml/stable-diffusion-v1-5',
      ])
      .register(z.globalRegistry, {
        description: 'The name of the model to use.',
      }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(true),
  safety_checker_version: z.optional(
    z.enum(['v1', 'v2']).register(z.globalRegistry, {
      description:
        'The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.',
    }),
  ),
  request_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          '\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ',
      }),
    )
    .default(''),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(32).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(6),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiFastLcmDiffusionImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFastLcmDiffusionOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFastLcmDiffusionImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiFastFooocusSdxlImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * Embedding
 */
export const zFalAiFastFooocusSdxlEmbedding = z.object({
  tokens: z
    .optional(
      z.array(z.string()).register(z.globalRegistry, {
        description: 'The list of tokens to use for the embedding.',
      }),
    )
    .default(['<s0>', '<s1>']),
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the embedding weights.',
  }),
})

/**
 * TextToImageFooocusInput
 */
export const zFastFooocusSdxlInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  enable_refiner: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, a smaller model will try to refine the output after it was processed.',
      }),
    )
    .default(true),
  image_size: z.optional(
    z.union([
      zFalAiFastFooocusSdxlImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  embeddings: z
    .optional(
      z.array(zFalAiFastFooocusSdxlEmbedding).register(z.globalRegistry, {
        description: 'The list of embeddings to use.',
      }),
    )
    .default([]),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the prompt will be expanded with additional prompts.',
      }),
    )
    .default(true),
  guidance_rescale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: 'The rescale factor for the CFG.',
      }),
    )
    .default(0),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(2),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the safety checker will be enabled.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  format: z.optional(
    z.enum(['jpeg', 'png']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description: 'The number of images to generate.',
      }),
    )
    .default(1),
  safety_checker_version: z.optional(
    z.enum(['v1', 'v2']).register(z.globalRegistry, {
      description:
        'The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(24).register(z.globalRegistry, {
        description: 'The number of inference steps to perform.',
      }),
    )
    .default(8),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
})

/**
 * Image
 */
export const zFalAiFastFooocusSdxlImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * Output
 */
export const zFastFooocusSdxlOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: 'The prompt used for generating the image.',
  }),
  images: z.array(zFalAiFastFooocusSdxlImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  timings: z.record(z.string(), z.number()),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImageSize
 */
export const zFalAiIllusionDiffusionImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * IllusionDiffusionInput
 */
export const zIllusionDiffusionInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  image_size: z.optional(
    z.union([
      zFalAiIllusionDiffusionImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  controlnet_conditioning_scale: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: 'The scale of the ControlNet.',
      }),
    )
    .default(1),
  image_url: z.string().register(z.globalRegistry, {
    description: 'Input image url.',
  }),
  scheduler: z.optional(
    z.enum(['DPM++ Karras SDE', 'Euler']).register(z.globalRegistry, {
      description:
        'Scheduler / sampler to use for the image denoising process.',
    }),
  ),
  control_guidance_start: z.optional(z.number().gte(0).lte(1)).default(0),
  guidance_scale: z
    .optional(
      z.number().lte(50).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(7.5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
    }),
  ),
  control_guidance_end: z.optional(z.number().gte(0).lte(1)).default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  num_inference_steps: z
    .optional(
      z.int().gte(0).lte(80).register(z.globalRegistry, {
        description:
          '\n            Increasing the amount of steps tells Stable Diffusion that it should take more steps\n            to generate your final result which can increase the amount of detail in your image.\n        ',
      }),
    )
    .default(40),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiIllusionDiffusionImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * IllusionDiffusionOutput
 */
export const zIllusionDiffusionOutput = z.object({
  image: zFalAiIllusionDiffusionImage,
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
})

/**
 * ImagePrompt
 */
export const zFalAiFooocusImagePromptImagePrompt = z.object({
  weight: z.optional(z.number().gte(0).lte(2)).default(1),
  stop_at: z.optional(z.number().gte(0).lte(1)).default(0.5),
  type: z.optional(z.enum(['ImagePrompt', 'PyraCanny', 'CPDS', 'FaceSwap'])),
  image_url: z.optional(z.string()),
})

/**
 * LoraWeight
 */
export const zFalAiFooocusImagePromptLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(0.1),
})

/**
 * FooocusImagePromptInput
 */
export const zFooocusImagePromptInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'The prompt to use for generating the image. Be as descriptive as possible for best results.',
      }),
    )
    .default(''),
  uov_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The image to upscale or vary.',
    }),
  ),
  performance: z.optional(
    z
      .enum(['Speed', 'Quality', 'Extreme Speed', 'Lightning'])
      .register(z.globalRegistry, {
        description: '\n            You can choose Speed or Quality\n        ',
      }),
  ),
  image_prompt_3: z.optional(zFalAiFooocusImagePromptImagePrompt),
  styles: z
    .optional(
      z
        .array(
          z.enum([
            'Fooocus V2',
            'Fooocus Enhance',
            'Fooocus Sharp',
            'Fooocus Semi Realistic',
            'Fooocus Masterpiece',
            'Fooocus Photograph',
            'Fooocus Negative',
            'Fooocus Cinematic',
            'SAI 3D Model',
            'SAI Analog Film',
            'SAI Anime',
            'SAI Cinematic',
            'SAI Comic Book',
            'SAI Craft Clay',
            'SAI Digital Art',
            'SAI Enhance',
            'SAI Fantasy Art',
            'SAI Isometric',
            'SAI Line Art',
            'SAI Lowpoly',
            'SAI Neonpunk',
            'SAI Origami',
            'SAI Photographic',
            'SAI Pixel Art',
            'SAI Texture',
            'MRE Cinematic Dynamic',
            'MRE Spontaneous Picture',
            'MRE Artistic Vision',
            'MRE Dark Dream',
            'MRE Gloomy Art',
            'MRE Bad Dream',
            'MRE Underground',
            'MRE Surreal Painting',
            'MRE Dynamic Illustration',
            'MRE Undead Art',
            'MRE Elemental Art',
            'MRE Space Art',
            'MRE Ancient Illustration',
            'MRE Brave Art',
            'MRE Heroic Fantasy',
            'MRE Dark Cyberpunk',
            'MRE Lyrical Geometry',
            'MRE Sumi E Symbolic',
            'MRE Sumi E Detailed',
            'MRE Manga',
            'MRE Anime',
            'MRE Comic',
            'Ads Advertising',
            'Ads Automotive',
            'Ads Corporate',
            'Ads Fashion Editorial',
            'Ads Food Photography',
            'Ads Gourmet Food Photography',
            'Ads Luxury',
            'Ads Real Estate',
            'Ads Retail',
            'Artstyle Abstract',
            'Artstyle Abstract Expressionism',
            'Artstyle Art Deco',
            'Artstyle Art Nouveau',
            'Artstyle Constructivist',
            'Artstyle Cubist',
            'Artstyle Expressionist',
            'Artstyle Graffiti',
            'Artstyle Hyperrealism',
            'Artstyle Impressionist',
            'Artstyle Pointillism',
            'Artstyle Pop Art',
            'Artstyle Psychedelic',
            'Artstyle Renaissance',
            'Artstyle Steampunk',
            'Artstyle Surrealist',
            'Artstyle Typography',
            'Artstyle Watercolor',
            'Futuristic Biomechanical',
            'Futuristic Biomechanical Cyberpunk',
            'Futuristic Cybernetic',
            'Futuristic Cybernetic Robot',
            'Futuristic Cyberpunk Cityscape',
            'Futuristic Futuristic',
            'Futuristic Retro Cyberpunk',
            'Futuristic Retro Futurism',
            'Futuristic Sci Fi',
            'Futuristic Vaporwave',
            'Game Bubble Bobble',
            'Game Cyberpunk Game',
            'Game Fighting Game',
            'Game Gta',
            'Game Mario',
            'Game Minecraft',
            'Game Pokemon',
            'Game Retro Arcade',
            'Game Retro Game',
            'Game Rpg Fantasy Game',
            'Game Strategy Game',
            'Game Streetfighter',
            'Game Zelda',
            'Misc Architectural',
            'Misc Disco',
            'Misc Dreamscape',
            'Misc Dystopian',
            'Misc Fairy Tale',
            'Misc Gothic',
            'Misc Grunge',
            'Misc Horror',
            'Misc Kawaii',
            'Misc Lovecraftian',
            'Misc Macabre',
            'Misc Manga',
            'Misc Metropolis',
            'Misc Minimalist',
            'Misc Monochrome',
            'Misc Nautical',
            'Misc Space',
            'Misc Stained Glass',
            'Misc Techwear Fashion',
            'Misc Tribal',
            'Misc Zentangle',
            'Papercraft Collage',
            'Papercraft Flat Papercut',
            'Papercraft Kirigami',
            'Papercraft Paper Mache',
            'Papercraft Paper Quilling',
            'Papercraft Papercut Collage',
            'Papercraft Papercut Shadow Box',
            'Papercraft Stacked Papercut',
            'Papercraft Thick Layered Papercut',
            'Photo Alien',
            'Photo Film Noir',
            'Photo Glamour',
            'Photo Hdr',
            'Photo Iphone Photographic',
            'Photo Long Exposure',
            'Photo Neon Noir',
            'Photo Silhouette',
            'Photo Tilt Shift',
            'Cinematic Diva',
            'Abstract Expressionism',
            'Academia',
            'Action Figure',
            'Adorable 3D Character',
            'Adorable Kawaii',
            'Art Deco',
            'Art Nouveau',
            'Astral Aura',
            'Avant Garde',
            'Baroque',
            'Bauhaus Style Poster',
            'Blueprint Schematic Drawing',
            'Caricature',
            'Cel Shaded Art',
            'Character Design Sheet',
            'Classicism Art',
            'Color Field Painting',
            'Colored Pencil Art',
            'Conceptual Art',
            'Constructivism',
            'Cubism',
            'Dadaism',
            'Dark Fantasy',
            'Dark Moody Atmosphere',
            'Dmt Art Style',
            'Doodle Art',
            'Double Exposure',
            'Dripping Paint Splatter Art',
            'Expressionism',
            'Faded Polaroid Photo',
            'Fauvism',
            'Flat 2d Art',
            'Fortnite Art Style',
            'Futurism',
            'Glitchcore',
            'Glo Fi',
            'Googie Art Style',
            'Graffiti Art',
            'Harlem Renaissance Art',
            'High Fashion',
            'Idyllic',
            'Impressionism',
            'Infographic Drawing',
            'Ink Dripping Drawing',
            'Japanese Ink Drawing',
            'Knolling Photography',
            'Light Cheery Atmosphere',
            'Logo Design',
            'Luxurious Elegance',
            'Macro Photography',
            'Mandola Art',
            'Marker Drawing',
            'Medievalism',
            'Minimalism',
            'Neo Baroque',
            'Neo Byzantine',
            'Neo Futurism',
            'Neo Impressionism',
            'Neo Rococo',
            'Neoclassicism',
            'Op Art',
            'Ornate And Intricate',
            'Pencil Sketch Drawing',
            'Pop Art 2',
            'Rococo',
            'Silhouette Art',
            'Simple Vector Art',
            'Sketchup',
            'Steampunk 2',
            'Surrealism',
            'Suprematism',
            'Terragen',
            'Tranquil Relaxing Atmosphere',
            'Sticker Designs',
            'Vibrant Rim Light',
            'Volumetric Lighting',
            'Watercolor 2',
            'Whimsical And Playful',
            'Mk Chromolithography',
            'Mk Cross Processing Print',
            'Mk Dufaycolor Photograph',
            'Mk Herbarium',
            'Mk Punk Collage',
            'Mk Mosaic',
            'Mk Van Gogh',
            'Mk Coloring Book',
            'Mk Singer Sargent',
            'Mk Pollock',
            'Mk Basquiat',
            'Mk Andy Warhol',
            'Mk Halftone Print',
            'Mk Gond Painting',
            'Mk Albumen Print',
            'Mk Aquatint Print',
            'Mk Anthotype Print',
            'Mk Inuit Carving',
            'Mk Bromoil Print',
            'Mk Calotype Print',
            'Mk Color Sketchnote',
            'Mk Cibulak Porcelain',
            'Mk Alcohol Ink Art',
            'Mk One Line Art',
            'Mk Blacklight Paint',
            'Mk Carnival Glass',
            'Mk Cyanotype Print',
            'Mk Cross Stitching',
            'Mk Encaustic Paint',
            'Mk Embroidery',
            'Mk Gyotaku',
            'Mk Luminogram',
            'Mk Lite Brite Art',
            'Mk Mokume Gane',
            'Pebble Art',
            'Mk Palekh',
            'Mk Suminagashi',
            'Mk Scrimshaw',
            'Mk Shibori',
            'Mk Vitreous Enamel',
            'Mk Ukiyo E',
            'Mk Vintage Airline Poster',
            'Mk Vintage Travel Poster',
            'Mk Bauhaus Style',
            'Mk Afrofuturism',
            'Mk Atompunk',
            'Mk Constructivism',
            'Mk Chicano Art',
            'Mk De Stijl',
            'Mk Dayak Art',
            'Mk Fayum Portrait',
            'Mk Illuminated Manuscript',
            'Mk Kalighat Painting',
            'Mk Madhubani Painting',
            'Mk Pictorialism',
            'Mk Pichwai Painting',
            'Mk Patachitra Painting',
            'Mk Samoan Art Inspired',
            'Mk Tlingit Art',
            'Mk Adnate Style',
            'Mk Ron English Style',
            'Mk Shepard Fairey Style',
          ]),
        )
        .register(z.globalRegistry, {
          description: '\n            The style to use.\n        ',
        }),
    )
    .default(['Fooocus Enhance', 'Fooocus V2', 'Fooocus Sharp']),
  loras: z
    .optional(
      z.array(zFalAiFooocusImagePromptLoraWeight).register(z.globalRegistry, {
        description:
          '\n            The LoRAs to use for the image generation. You can use up to 5 LoRAs\n            and they will be merged together to generate the final image.\n        ',
      }),
    )
    .default([
      {
        path: 'https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors',
        scale: 0.1,
      },
    ]),
  image_prompt_4: z.optional(zFalAiFooocusImagePromptImagePrompt),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(30).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(4),
  sharpness: z
    .optional(
      z.number().gte(0).lte(30).register(z.globalRegistry, {
        description:
          '\n            The sharpness of the generated image. Use it to control how sharp the generated\n            image should be. Higher value means image and texture are sharper.\n        ',
      }),
    )
    .default(2),
  mixing_image_prompt_and_inpaint: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Mixing Image Prompt and Inpaint',
      }),
    )
    .default(false),
  outpaint_selections: z
    .optional(
      z
        .array(z.enum(['Left', 'Right', 'Top', 'Bottom']))
        .register(z.globalRegistry, {
          description: 'The directions to outpaint.',
        }),
    )
    .default([]),
  inpaint_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The image to use as a reference for inpainting.',
    }),
  ),
  output_format: z.optional(
    z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  refiner_model: z.optional(
    z
      .enum(['None', 'realisticVisionV60B1_v51VAE.safetensors'])
      .register(z.globalRegistry, {
        description: 'Refiner (SDXL or SD 1.5)',
      }),
  ),
  image_prompt_2: z.optional(zFalAiFooocusImagePromptImagePrompt),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  inpaint_mode: z.optional(
    z
      .enum([
        'Inpaint or Outpaint (default)',
        'Improve Detail (face, hand, eyes, etc.)',
        'Modify Content (add objects, change background, etc.)',
      ])
      .register(z.globalRegistry, {
        description: 'The mode to use for inpainting.',
      }),
  ),
  uov_method: z.optional(
    z
      .enum([
        'Disabled',
        'Vary (Subtle)',
        'Vary (Strong)',
        'Upscale (1.5x)',
        'Upscale (2x)',
        'Upscale (Fast 2x)',
      ])
      .register(z.globalRegistry, {
        description: 'The method to use for upscaling or varying.',
      }),
  ),
  seed: z.optional(z.union([z.int(), z.null()])),
  refiner_switch: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            Use 0.4 for SD1.5 realistic models; 0.667 for SD1.5 anime models\n            0.8 for XL-refiners; or any value for switching two SDXL models.\n        ',
      }),
    )
    .default(0.8),
  mixing_image_prompt_and_vary_upscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Mixing Image Prompt and Vary/Upscale',
      }),
    )
    .default(false),
  mask_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The image to use as a mask for the generated image.',
    }),
  ),
  image_prompt_1: zFalAiFooocusImagePromptImagePrompt,
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to false, the safety checker will be disabled.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description:
          '\n            Number of images to generate in one request\n        ',
      }),
    )
    .default(1),
  aspect_ratio: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          '\n            The size of the generated image. You can choose between some presets or\n            custom height and width that **must be multiples of 8**.\n        ',
      }),
    )
    .default('1024x1024'),
  inpaint_additional_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Describe what you want to inpaint.',
      }),
    )
    .default(''),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFooocusImagePromptImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FooocusOutput
 */
export const zFooocusImagePromptOutput = z.object({
  images: z.array(zFalAiFooocusImagePromptImage).register(z.globalRegistry, {
    description: 'The generated image file info.',
  }),
  timings: z.record(z.string(), z.number()).register(z.globalRegistry, {
    description: 'The time taken for the generation process.',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
})

/**
 * ImagePrompt
 */
export const zFalAiFooocusInpaintImagePrompt = z.object({
  weight: z.optional(z.number().gte(0).lte(2)).default(1),
  stop_at: z.optional(z.number().gte(0).lte(1)).default(0.5),
  type: z.optional(z.enum(['ImagePrompt', 'PyraCanny', 'CPDS', 'FaceSwap'])),
  image_url: z.optional(z.string()),
})

/**
 * LoraWeight
 */
export const zFalAiFooocusInpaintLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(0.1),
})

/**
 * FooocusInpaintInput
 */
export const zFooocusInpaintInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'The prompt to use for generating the image. Be as descriptive as possible for best results.',
      }),
    )
    .default(''),
  performance: z.optional(
    z
      .enum(['Speed', 'Quality', 'Extreme Speed', 'Lightning'])
      .register(z.globalRegistry, {
        description: '\n            You can choose Speed or Quality\n        ',
      }),
  ),
  styles: z
    .optional(
      z
        .array(
          z.enum([
            'Fooocus V2',
            'Fooocus Enhance',
            'Fooocus Sharp',
            'Fooocus Semi Realistic',
            'Fooocus Masterpiece',
            'Fooocus Photograph',
            'Fooocus Negative',
            'Fooocus Cinematic',
            'SAI 3D Model',
            'SAI Analog Film',
            'SAI Anime',
            'SAI Cinematic',
            'SAI Comic Book',
            'SAI Craft Clay',
            'SAI Digital Art',
            'SAI Enhance',
            'SAI Fantasy Art',
            'SAI Isometric',
            'SAI Line Art',
            'SAI Lowpoly',
            'SAI Neonpunk',
            'SAI Origami',
            'SAI Photographic',
            'SAI Pixel Art',
            'SAI Texture',
            'MRE Cinematic Dynamic',
            'MRE Spontaneous Picture',
            'MRE Artistic Vision',
            'MRE Dark Dream',
            'MRE Gloomy Art',
            'MRE Bad Dream',
            'MRE Underground',
            'MRE Surreal Painting',
            'MRE Dynamic Illustration',
            'MRE Undead Art',
            'MRE Elemental Art',
            'MRE Space Art',
            'MRE Ancient Illustration',
            'MRE Brave Art',
            'MRE Heroic Fantasy',
            'MRE Dark Cyberpunk',
            'MRE Lyrical Geometry',
            'MRE Sumi E Symbolic',
            'MRE Sumi E Detailed',
            'MRE Manga',
            'MRE Anime',
            'MRE Comic',
            'Ads Advertising',
            'Ads Automotive',
            'Ads Corporate',
            'Ads Fashion Editorial',
            'Ads Food Photography',
            'Ads Gourmet Food Photography',
            'Ads Luxury',
            'Ads Real Estate',
            'Ads Retail',
            'Artstyle Abstract',
            'Artstyle Abstract Expressionism',
            'Artstyle Art Deco',
            'Artstyle Art Nouveau',
            'Artstyle Constructivist',
            'Artstyle Cubist',
            'Artstyle Expressionist',
            'Artstyle Graffiti',
            'Artstyle Hyperrealism',
            'Artstyle Impressionist',
            'Artstyle Pointillism',
            'Artstyle Pop Art',
            'Artstyle Psychedelic',
            'Artstyle Renaissance',
            'Artstyle Steampunk',
            'Artstyle Surrealist',
            'Artstyle Typography',
            'Artstyle Watercolor',
            'Futuristic Biomechanical',
            'Futuristic Biomechanical Cyberpunk',
            'Futuristic Cybernetic',
            'Futuristic Cybernetic Robot',
            'Futuristic Cyberpunk Cityscape',
            'Futuristic Futuristic',
            'Futuristic Retro Cyberpunk',
            'Futuristic Retro Futurism',
            'Futuristic Sci Fi',
            'Futuristic Vaporwave',
            'Game Bubble Bobble',
            'Game Cyberpunk Game',
            'Game Fighting Game',
            'Game Gta',
            'Game Mario',
            'Game Minecraft',
            'Game Pokemon',
            'Game Retro Arcade',
            'Game Retro Game',
            'Game Rpg Fantasy Game',
            'Game Strategy Game',
            'Game Streetfighter',
            'Game Zelda',
            'Misc Architectural',
            'Misc Disco',
            'Misc Dreamscape',
            'Misc Dystopian',
            'Misc Fairy Tale',
            'Misc Gothic',
            'Misc Grunge',
            'Misc Horror',
            'Misc Kawaii',
            'Misc Lovecraftian',
            'Misc Macabre',
            'Misc Manga',
            'Misc Metropolis',
            'Misc Minimalist',
            'Misc Monochrome',
            'Misc Nautical',
            'Misc Space',
            'Misc Stained Glass',
            'Misc Techwear Fashion',
            'Misc Tribal',
            'Misc Zentangle',
            'Papercraft Collage',
            'Papercraft Flat Papercut',
            'Papercraft Kirigami',
            'Papercraft Paper Mache',
            'Papercraft Paper Quilling',
            'Papercraft Papercut Collage',
            'Papercraft Papercut Shadow Box',
            'Papercraft Stacked Papercut',
            'Papercraft Thick Layered Papercut',
            'Photo Alien',
            'Photo Film Noir',
            'Photo Glamour',
            'Photo Hdr',
            'Photo Iphone Photographic',
            'Photo Long Exposure',
            'Photo Neon Noir',
            'Photo Silhouette',
            'Photo Tilt Shift',
            'Cinematic Diva',
            'Abstract Expressionism',
            'Academia',
            'Action Figure',
            'Adorable 3D Character',
            'Adorable Kawaii',
            'Art Deco',
            'Art Nouveau',
            'Astral Aura',
            'Avant Garde',
            'Baroque',
            'Bauhaus Style Poster',
            'Blueprint Schematic Drawing',
            'Caricature',
            'Cel Shaded Art',
            'Character Design Sheet',
            'Classicism Art',
            'Color Field Painting',
            'Colored Pencil Art',
            'Conceptual Art',
            'Constructivism',
            'Cubism',
            'Dadaism',
            'Dark Fantasy',
            'Dark Moody Atmosphere',
            'Dmt Art Style',
            'Doodle Art',
            'Double Exposure',
            'Dripping Paint Splatter Art',
            'Expressionism',
            'Faded Polaroid Photo',
            'Fauvism',
            'Flat 2d Art',
            'Fortnite Art Style',
            'Futurism',
            'Glitchcore',
            'Glo Fi',
            'Googie Art Style',
            'Graffiti Art',
            'Harlem Renaissance Art',
            'High Fashion',
            'Idyllic',
            'Impressionism',
            'Infographic Drawing',
            'Ink Dripping Drawing',
            'Japanese Ink Drawing',
            'Knolling Photography',
            'Light Cheery Atmosphere',
            'Logo Design',
            'Luxurious Elegance',
            'Macro Photography',
            'Mandola Art',
            'Marker Drawing',
            'Medievalism',
            'Minimalism',
            'Neo Baroque',
            'Neo Byzantine',
            'Neo Futurism',
            'Neo Impressionism',
            'Neo Rococo',
            'Neoclassicism',
            'Op Art',
            'Ornate And Intricate',
            'Pencil Sketch Drawing',
            'Pop Art 2',
            'Rococo',
            'Silhouette Art',
            'Simple Vector Art',
            'Sketchup',
            'Steampunk 2',
            'Surrealism',
            'Suprematism',
            'Terragen',
            'Tranquil Relaxing Atmosphere',
            'Sticker Designs',
            'Vibrant Rim Light',
            'Volumetric Lighting',
            'Watercolor 2',
            'Whimsical And Playful',
            'Mk Chromolithography',
            'Mk Cross Processing Print',
            'Mk Dufaycolor Photograph',
            'Mk Herbarium',
            'Mk Punk Collage',
            'Mk Mosaic',
            'Mk Van Gogh',
            'Mk Coloring Book',
            'Mk Singer Sargent',
            'Mk Pollock',
            'Mk Basquiat',
            'Mk Andy Warhol',
            'Mk Halftone Print',
            'Mk Gond Painting',
            'Mk Albumen Print',
            'Mk Aquatint Print',
            'Mk Anthotype Print',
            'Mk Inuit Carving',
            'Mk Bromoil Print',
            'Mk Calotype Print',
            'Mk Color Sketchnote',
            'Mk Cibulak Porcelain',
            'Mk Alcohol Ink Art',
            'Mk One Line Art',
            'Mk Blacklight Paint',
            'Mk Carnival Glass',
            'Mk Cyanotype Print',
            'Mk Cross Stitching',
            'Mk Encaustic Paint',
            'Mk Embroidery',
            'Mk Gyotaku',
            'Mk Luminogram',
            'Mk Lite Brite Art',
            'Mk Mokume Gane',
            'Pebble Art',
            'Mk Palekh',
            'Mk Suminagashi',
            'Mk Scrimshaw',
            'Mk Shibori',
            'Mk Vitreous Enamel',
            'Mk Ukiyo E',
            'Mk Vintage Airline Poster',
            'Mk Vintage Travel Poster',
            'Mk Bauhaus Style',
            'Mk Afrofuturism',
            'Mk Atompunk',
            'Mk Constructivism',
            'Mk Chicano Art',
            'Mk De Stijl',
            'Mk Dayak Art',
            'Mk Fayum Portrait',
            'Mk Illuminated Manuscript',
            'Mk Kalighat Painting',
            'Mk Madhubani Painting',
            'Mk Pictorialism',
            'Mk Pichwai Painting',
            'Mk Patachitra Painting',
            'Mk Samoan Art Inspired',
            'Mk Tlingit Art',
            'Mk Adnate Style',
            'Mk Ron English Style',
            'Mk Shepard Fairey Style',
          ]),
        )
        .register(z.globalRegistry, {
          description: '\n            The style to use.\n        ',
        }),
    )
    .default(['Fooocus Enhance', 'Fooocus V2', 'Fooocus Sharp']),
  image_prompt_3: z.optional(zFalAiFooocusInpaintImagePrompt),
  loras: z
    .optional(
      z.array(zFalAiFooocusInpaintLoraWeight).register(z.globalRegistry, {
        description:
          '\n            The LoRAs to use for the image generation. You can use up to 5 LoRAs\n            and they will be merged together to generate the final image.\n        ',
      }),
    )
    .default([
      {
        path: 'https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors',
        scale: 0.1,
      },
    ]),
  image_prompt_4: z.optional(zFalAiFooocusInpaintImagePrompt),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(30).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(4),
  sharpness: z
    .optional(
      z.number().gte(0).lte(30).register(z.globalRegistry, {
        description:
          '\n            The sharpness of the generated image. Use it to control how sharp the generated\n            image should be. Higher value means image and texture are sharper.\n        ',
      }),
    )
    .default(2),
  mixing_image_prompt_and_inpaint: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'Mixing Image Prompt and Inpaint',
      }),
    )
    .default(false),
  outpaint_selections: z
    .optional(
      z
        .array(z.enum(['Left', 'Right', 'Top', 'Bottom']))
        .register(z.globalRegistry, {
          description: 'The directions to outpaint.',
        }),
    )
    .default([]),
  inpaint_image_url: z.string().register(z.globalRegistry, {
    description: 'The image to use as a reference for inpainting.',
  }),
  refiner_model: z.optional(
    z
      .enum(['None', 'realisticVisionV60B1_v51VAE.safetensors'])
      .register(z.globalRegistry, {
        description: 'Refiner (SDXL or SD 1.5)',
      }),
  ),
  output_format: z.optional(
    z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  image_prompt_2: z.optional(zFalAiFooocusInpaintImagePrompt),
  inpaint_respective_field: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The area to inpaint. Value 0 is same as "Only Masked" in A1111. Value 1 is\n            same as "Whole Image" in A1111. Only used in inpaint, not used in outpaint.\n            (Outpaint always use 1.0)\n        ',
      }),
    )
    .default(0.618),
  inpaint_mode: z.optional(
    z
      .enum([
        'Inpaint or Outpaint (default)',
        'Improve Detail (face, hand, eyes, etc.)',
        'Modify Content (add objects, change background, etc.)',
      ])
      .register(z.globalRegistry, {
        description: 'The mode to use for inpainting.',
      }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.null()])),
  refiner_switch: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            Use 0.4 for SD1.5 realistic models; 0.667 for SD1.5 anime models\n            0.8 for XL-refiners; or any value for switching two SDXL models.\n        ',
      }),
    )
    .default(0.8),
  inpaint_disable_initial_latent: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          'If set to true, the initial preprocessing will be disabled.',
      }),
    )
    .default(false),
  mask_image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The image to use as a mask for the generated image.',
    }),
  ),
  invert_mask: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to true, the mask will be inverted.',
      }),
    )
    .default(false),
  image_prompt_1: z.optional(zFalAiFooocusInpaintImagePrompt),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to false, the safety checker will be disabled.',
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description:
          '\n            Number of images to generate in one request\n        ',
      }),
    )
    .default(1),
  aspect_ratio: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          '\n            The size of the generated image. You can choose between some presets or\n            custom height and width that **must be multiples of 8**.\n        ',
      }),
    )
    .default('1024x1024'),
  inpaint_additional_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: 'Describe what you want to inpaint.',
      }),
    )
    .default(''),
  inpaint_strength: z
    .optional(
      z.number().lte(1).register(z.globalRegistry, {
        description:
          '\n            Same as the denoising strength in A1111 inpaint. Only used in inpaint, not\n            used in outpaint. (Outpaint always use 1.0)\n        ',
      }),
    )
    .default(1),
  override_inpaint_options: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "\n            If set to true, the advanced inpaint options ('inpaint_disable_initial_latent',\n            'inpaint_engine', 'inpaint_strength', 'inpaint_respective_field',\n            'inpaint_erode_or_dilate') will be overridden.\n            Otherwise, the default values will be used.\n        ",
      }),
    )
    .default(false),
  inpaint_engine: z.optional(
    z.enum(['None', 'v1', 'v2.5', 'v2.6']).register(z.globalRegistry, {
      description: 'Version of Fooocus inpaint model',
    }),
  ),
  inpaint_erode_or_dilate: z
    .optional(
      z.number().gte(-64).lte(64).register(z.globalRegistry, {
        description:
          '\n            Positive value will make white area in the mask larger, negative value will\n            make white area smaller. (default is 0, always process before any mask\n            invert)\n        ',
      }),
    )
    .default(0),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFooocusInpaintImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FooocusOutput
 */
export const zFooocusInpaintOutput = z.object({
  images: z.array(zFalAiFooocusInpaintImage).register(z.globalRegistry, {
    description: 'The generated image file info.',
  }),
  timings: z.record(z.string(), z.number()).register(z.globalRegistry, {
    description: 'The time taken for the generation process.',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
})

/**
 * ImageSize
 */
export const zFalAiLcmImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The height of the generated image.',
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: 'The width of the generated image.',
      }),
    )
    .default(512),
})

/**
 * LCMInput
 */
export const zLcmInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      'The prompt to use for generating the image. Be as descriptive as possible for best results.',
  }),
  controlnet_inpaint: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the inpainting pipeline will use controlnet inpainting.\n            Only effective for inpainting pipelines.\n        ',
      }),
    )
    .default(false),
  image_size: z.optional(
    z.union([
      zFalAiLcmImageSize,
      z.enum([
        'square_hd',
        'square',
        'portrait_4_3',
        'portrait_16_9',
        'landscape_4_3',
        'landscape_16_9',
      ]),
    ]),
  ),
  enable_safety_checks: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the resulting image will be checked whether it includes any\n            potentially unsafe content. If it does, it will be replaced with a black\n            image.\n        ',
      }),
    )
    .default(true),
  model: z.optional(
    z.enum(['sdxl', 'sdv1-5']).register(z.globalRegistry, {
      description: 'The model to use for generating the image.',
    }),
  ),
  lora_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        '\n            The url of the lora server to use for image generation.\n        ',
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(8).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  inpaint_mask_only: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the inpainting pipeline will only inpaint the provided mask\n            area. Only effective for inpainting pipelines.\n        ',
      }),
    )
    .default(false),
  num_images: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description:
          '\n            The number of images to generate. The function will return a list of images\n            with the same prompt and negative prompt but different seeds.\n        ',
      }),
    )
    .default(1),
  lora_scale: z
    .optional(
      z.number().register(z.globalRegistry, {
        description:
          '\n            The scale of the lora server to use for image generation.\n        ',
      }),
    )
    .default(1),
  image_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        '\n        The base image to use for guiding the image generation on image-to-image\n        generations. If the either width or height of the image is larger than 1024\n        pixels, the image will be resized to 1024 pixels while keeping the aspect ratio.\n        ',
    }),
  ),
  strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n        The strength of the image that is passed as `image_url`. The strength\n        determines how much the generated image will be similar to the image passed as\n        `image_url`. The higher the strength the more model gets "creative" and\n        generates an image that\'s different from the initial image. A strength of 1.0\n        means that the initial image is more or less ignored and the model will try to\n        generate an image that\'s as close as possible to the prompt.\n        ',
      }),
    )
    .default(0.8),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  request_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          '\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ',
      }),
    )
    .default(''),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        '\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ',
    }),
  ),
  mask_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        '\n        The mask to use for guiding the image generation on image\n        inpainting. The model will focus on the mask area and try to fill it with\n        the most relevant content.\n\n        The mask must be a black and white image where the white area is the area\n        that needs to be filled and the black area is the area that should be\n        ignored.\n\n        The mask must have the same dimensions as the image passed as `image_url`.\n        ',
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(12).register(z.globalRegistry, {
        description:
          '\n            The number of inference steps to use for generating the image. The more steps\n            the better the image will be but it will also take longer to generate.\n        ',
      }),
    )
    .default(4),
})

/**
 * Image
 */
export const zFalAiLcmImage = z.object({
  height: z.int(),
  content_type: z.optional(z.string()).default('image/jpeg'),
  url: z.string(),
  width: z.int(),
})

/**
 * LCMOutput
 */
export const zLcmOutput = z.object({
  images: z.array(zFalAiLcmImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  request_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          '\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ',
      }),
    )
    .default(''),
  timings: z.record(z.string(), z.number()),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  num_inference_steps: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          '\n            Number of inference steps used to generate the image. It will be the same value of the one passed in the\n            input or the default one in case none was passed.\n        ',
      }),
    )
    .default(4),
  nsfw_content_detected: z.array(z.boolean()).register(z.globalRegistry, {
    description:
      '\n            A list of booleans indicating whether the generated image contains any\n            potentially unsafe content. If the safety check is disabled, this field\n            will all will be false.\n        ',
  }),
})

/**
 * DiffusionEdgeInput
 */
export const zDiffusionEdgeInput = z.object({
  image_url: z.string().register(z.globalRegistry, {
    description: 'The text prompt you would like to convert to speech.',
  }),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiDiffusionEdgeImage = z
  .object({
    file_size: z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_name: z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
    content_type: z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * DiffusionEdgeOutput
 */
export const zDiffusionEdgeOutput = z.object({
  image: zFalAiDiffusionEdgeImage,
})

/**
 * LoraWeight
 */
export const zFalAiFooocusLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: 'URL or the path to the LoRA weights.',
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ',
      }),
    )
    .default(0.1),
})

/**
 * FooocusLegacyInput
 */
export const zFooocusInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          'The prompt to use for generating the image. Be as descriptive as possible for best results.',
      }),
    )
    .default(''),
  performance: z.optional(
    z
      .enum(['Speed', 'Quality', 'Extreme Speed', 'Lightning'])
      .register(z.globalRegistry, {
        description: '\n            You can choose Speed or Quality\n        ',
      }),
  ),
  styles: z
    .optional(
      z
        .array(
          z.enum([
            'Fooocus V2',
            'Fooocus Enhance',
            'Fooocus Sharp',
            'Fooocus Semi Realistic',
            'Fooocus Masterpiece',
            'Fooocus Photograph',
            'Fooocus Negative',
            'Fooocus Cinematic',
            'SAI 3D Model',
            'SAI Analog Film',
            'SAI Anime',
            'SAI Cinematic',
            'SAI Comic Book',
            'SAI Craft Clay',
            'SAI Digital Art',
            'SAI Enhance',
            'SAI Fantasy Art',
            'SAI Isometric',
            'SAI Line Art',
            'SAI Lowpoly',
            'SAI Neonpunk',
            'SAI Origami',
            'SAI Photographic',
            'SAI Pixel Art',
            'SAI Texture',
            'MRE Cinematic Dynamic',
            'MRE Spontaneous Picture',
            'MRE Artistic Vision',
            'MRE Dark Dream',
            'MRE Gloomy Art',
            'MRE Bad Dream',
            'MRE Underground',
            'MRE Surreal Painting',
            'MRE Dynamic Illustration',
            'MRE Undead Art',
            'MRE Elemental Art',
            'MRE Space Art',
            'MRE Ancient Illustration',
            'MRE Brave Art',
            'MRE Heroic Fantasy',
            'MRE Dark Cyberpunk',
            'MRE Lyrical Geometry',
            'MRE Sumi E Symbolic',
            'MRE Sumi E Detailed',
            'MRE Manga',
            'MRE Anime',
            'MRE Comic',
            'Ads Advertising',
            'Ads Automotive',
            'Ads Corporate',
            'Ads Fashion Editorial',
            'Ads Food Photography',
            'Ads Gourmet Food Photography',
            'Ads Luxury',
            'Ads Real Estate',
            'Ads Retail',
            'Artstyle Abstract',
            'Artstyle Abstract Expressionism',
            'Artstyle Art Deco',
            'Artstyle Art Nouveau',
            'Artstyle Constructivist',
            'Artstyle Cubist',
            'Artstyle Expressionist',
            'Artstyle Graffiti',
            'Artstyle Hyperrealism',
            'Artstyle Impressionist',
            'Artstyle Pointillism',
            'Artstyle Pop Art',
            'Artstyle Psychedelic',
            'Artstyle Renaissance',
            'Artstyle Steampunk',
            'Artstyle Surrealist',
            'Artstyle Typography',
            'Artstyle Watercolor',
            'Futuristic Biomechanical',
            'Futuristic Biomechanical Cyberpunk',
            'Futuristic Cybernetic',
            'Futuristic Cybernetic Robot',
            'Futuristic Cyberpunk Cityscape',
            'Futuristic Futuristic',
            'Futuristic Retro Cyberpunk',
            'Futuristic Retro Futurism',
            'Futuristic Sci Fi',
            'Futuristic Vaporwave',
            'Game Bubble Bobble',
            'Game Cyberpunk Game',
            'Game Fighting Game',
            'Game Gta',
            'Game Mario',
            'Game Minecraft',
            'Game Pokemon',
            'Game Retro Arcade',
            'Game Retro Game',
            'Game Rpg Fantasy Game',
            'Game Strategy Game',
            'Game Streetfighter',
            'Game Zelda',
            'Misc Architectural',
            'Misc Disco',
            'Misc Dreamscape',
            'Misc Dystopian',
            'Misc Fairy Tale',
            'Misc Gothic',
            'Misc Grunge',
            'Misc Horror',
            'Misc Kawaii',
            'Misc Lovecraftian',
            'Misc Macabre',
            'Misc Manga',
            'Misc Metropolis',
            'Misc Minimalist',
            'Misc Monochrome',
            'Misc Nautical',
            'Misc Space',
            'Misc Stained Glass',
            'Misc Techwear Fashion',
            'Misc Tribal',
            'Misc Zentangle',
            'Papercraft Collage',
            'Papercraft Flat Papercut',
            'Papercraft Kirigami',
            'Papercraft Paper Mache',
            'Papercraft Paper Quilling',
            'Papercraft Papercut Collage',
            'Papercraft Papercut Shadow Box',
            'Papercraft Stacked Papercut',
            'Papercraft Thick Layered Papercut',
            'Photo Alien',
            'Photo Film Noir',
            'Photo Glamour',
            'Photo Hdr',
            'Photo Iphone Photographic',
            'Photo Long Exposure',
            'Photo Neon Noir',
            'Photo Silhouette',
            'Photo Tilt Shift',
            'Cinematic Diva',
            'Abstract Expressionism',
            'Academia',
            'Action Figure',
            'Adorable 3D Character',
            'Adorable Kawaii',
            'Art Deco',
            'Art Nouveau',
            'Astral Aura',
            'Avant Garde',
            'Baroque',
            'Bauhaus Style Poster',
            'Blueprint Schematic Drawing',
            'Caricature',
            'Cel Shaded Art',
            'Character Design Sheet',
            'Classicism Art',
            'Color Field Painting',
            'Colored Pencil Art',
            'Conceptual Art',
            'Constructivism',
            'Cubism',
            'Dadaism',
            'Dark Fantasy',
            'Dark Moody Atmosphere',
            'Dmt Art Style',
            'Doodle Art',
            'Double Exposure',
            'Dripping Paint Splatter Art',
            'Expressionism',
            'Faded Polaroid Photo',
            'Fauvism',
            'Flat 2d Art',
            'Fortnite Art Style',
            'Futurism',
            'Glitchcore',
            'Glo Fi',
            'Googie Art Style',
            'Graffiti Art',
            'Harlem Renaissance Art',
            'High Fashion',
            'Idyllic',
            'Impressionism',
            'Infographic Drawing',
            'Ink Dripping Drawing',
            'Japanese Ink Drawing',
            'Knolling Photography',
            'Light Cheery Atmosphere',
            'Logo Design',
            'Luxurious Elegance',
            'Macro Photography',
            'Mandola Art',
            'Marker Drawing',
            'Medievalism',
            'Minimalism',
            'Neo Baroque',
            'Neo Byzantine',
            'Neo Futurism',
            'Neo Impressionism',
            'Neo Rococo',
            'Neoclassicism',
            'Op Art',
            'Ornate And Intricate',
            'Pencil Sketch Drawing',
            'Pop Art 2',
            'Rococo',
            'Silhouette Art',
            'Simple Vector Art',
            'Sketchup',
            'Steampunk 2',
            'Surrealism',
            'Suprematism',
            'Terragen',
            'Tranquil Relaxing Atmosphere',
            'Sticker Designs',
            'Vibrant Rim Light',
            'Volumetric Lighting',
            'Watercolor 2',
            'Whimsical And Playful',
            'Mk Chromolithography',
            'Mk Cross Processing Print',
            'Mk Dufaycolor Photograph',
            'Mk Herbarium',
            'Mk Punk Collage',
            'Mk Mosaic',
            'Mk Van Gogh',
            'Mk Coloring Book',
            'Mk Singer Sargent',
            'Mk Pollock',
            'Mk Basquiat',
            'Mk Andy Warhol',
            'Mk Halftone Print',
            'Mk Gond Painting',
            'Mk Albumen Print',
            'Mk Aquatint Print',
            'Mk Anthotype Print',
            'Mk Inuit Carving',
            'Mk Bromoil Print',
            'Mk Calotype Print',
            'Mk Color Sketchnote',
            'Mk Cibulak Porcelain',
            'Mk Alcohol Ink Art',
            'Mk One Line Art',
            'Mk Blacklight Paint',
            'Mk Carnival Glass',
            'Mk Cyanotype Print',
            'Mk Cross Stitching',
            'Mk Encaustic Paint',
            'Mk Embroidery',
            'Mk Gyotaku',
            'Mk Luminogram',
            'Mk Lite Brite Art',
            'Mk Mokume Gane',
            'Pebble Art',
            'Mk Palekh',
            'Mk Suminagashi',
            'Mk Scrimshaw',
            'Mk Shibori',
            'Mk Vitreous Enamel',
            'Mk Ukiyo E',
            'Mk Vintage Airline Poster',
            'Mk Vintage Travel Poster',
            'Mk Bauhaus Style',
            'Mk Afrofuturism',
            'Mk Atompunk',
            'Mk Constructivism',
            'Mk Chicano Art',
            'Mk De Stijl',
            'Mk Dayak Art',
            'Mk Fayum Portrait',
            'Mk Illuminated Manuscript',
            'Mk Kalighat Painting',
            'Mk Madhubani Painting',
            'Mk Pictorialism',
            'Mk Pichwai Painting',
            'Mk Patachitra Painting',
            'Mk Samoan Art Inspired',
            'Mk Tlingit Art',
            'Mk Adnate Style',
            'Mk Ron English Style',
            'Mk Shepard Fairey Style',
          ]),
        )
        .register(z.globalRegistry, {
          description: '\n            The style to use.\n        ',
        }),
    )
    .default(['Fooocus Enhance', 'Fooocus V2', 'Fooocus Sharp']),
  control_type: z.optional(
    z
      .enum(['ImagePrompt', 'PyraCanny', 'CPDS', 'FaceSwap'])
      .register(z.globalRegistry, {
        description: 'The type of image control',
      }),
  ),
  mask_image_url: z.optional(z.union([z.string(), z.null()])),
  loras: z
    .optional(
      z.array(zFalAiFooocusLoraWeight).register(z.globalRegistry, {
        description:
          '\n            The LoRAs to use for the image generation. You can use up to 5 LoRAs\n            and they will be merged together to generate the final image.\n        ',
      }),
    )
    .default([
      {
        path: 'https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors',
        scale: 0.1,
      },
    ]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: 'If set to false, the safety checker will be disabled.',
      }),
    )
    .default(true),
  sharpness: z
    .optional(
      z.number().gte(0).lte(30).register(z.globalRegistry, {
        description:
          '\n            The sharpness of the generated image. Use it to control how sharp the generated\n            image should be. Higher value means image and texture are sharper.\n        ',
      }),
    )
    .default(2),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(30).register(z.globalRegistry, {
        description:
          '\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ',
      }),
    )
    .default(4),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default(''),
  inpaint_image_url: z.optional(z.union([z.string(), z.null()])),
  mixing_image_prompt_and_inpaint: z.optional(z.boolean()).default(false),
  aspect_ratio: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          '\n            The size of the generated image. You can choose between some presets or\n            custom height and width that **must be multiples of 8**.\n        ',
      }),
    )
    .default('1024x1024'),
  num_images: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description:
          '\n            Number of images to generate in one request\n        ',
      }),
    )
    .default(1),
  output_format: z.optional(
    z.enum(['png', 'jpeg', 'webp']).register(z.globalRegistry, {
      description: 'The format of the generated image.',
    }),
  ),
  refiner_model: z.optional(
    z
      .enum(['None', 'realisticVisionV60B1_v51VAE.safetensors'])
      .register(z.globalRegistry, {
        description: 'Refiner (SDXL or SD 1.5)',
      }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          '\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ',
      }),
    )
    .default(false),
  control_image_url: z.optional(z.union([z.string(), z.null()])),
  seed: z.optional(z.union([z.int(), z.null()])),
  refiner_switch: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            Use 0.4 for SD1.5 realistic models; 0.667 for SD1.5 anime models\n            0.8 for XL-refiners; or any value for switching two SDXL models.\n        ',
      }),
    )
    .default(0.8),
  control_image_weight: z
    .optional(
      z.number().gte(0).lte(2).register(z.globalRegistry, {
        description:
          '\n            The strength of the control image. Use it to control how much the generated image\n            should look like the control image.\n        ',
      }),
    )
    .default(1),
  control_image_stop_at: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          '\n            The stop at value of the control image. Use it to control how much the generated image\n            should look like the control image.\n        ',
      }),
    )
    .default(1),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiFooocusImage = z
  .object({
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * FooocusOutput
 */
export const zFooocusOutput = z.object({
  images: z.array(zFalAiFooocusImage).register(z.globalRegistry, {
    description: 'The generated image file info.',
  }),
  timings: z.record(z.string(), z.number()).register(z.globalRegistry, {
    description: 'The time taken for the generation process.',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
})

/**
 * TimestepsInput
 */
export const zTimestepsInput = z.object({
  method: z.optional(
    z.enum(['default', 'array']).register(z.globalRegistry, {
      description:
        "\n            The method to use for the timesteps. If set to 'array', the timesteps will be set based\n            on the provided timesteps schedule in the `array` field.\n            Defaults to 'default' which means the scheduler will use the `num_inference_steps` parameter.\n        ",
    }),
  ),
  array: z
    .optional(
      z.array(z.int()).register(z.globalRegistry, {
        description:
          "\n           Timesteps schedule to be used if 'custom' method is selected.\n        ",
      }),
    )
    .default([]),
})

/**
 * Image
 *
 * Represents an image file.
 */
export const zFalAiLoraImage = z
  .object({
    file_size: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The size of the file in bytes.',
      }),
    ),
    height: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The height of the image in pixels.',
      }),
    ),
    url: z.string().register(z.globalRegistry, {
      description: 'The URL where the file can be downloaded from.',
    }),
    width: z.optional(
      z.int().register(z.globalRegistry, {
        description: 'The width of the image in pixels.',
      }),
    ),
    file_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          'The name of the file. It will be auto-generated if not provided.',
      }),
    ),
    content_type: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'The mime type of the file.',
      }),
    ),
    file_data: z.optional(
      z.string().register(z.globalRegistry, {
        description: 'File data',
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: 'Represents an image file.',
  })

/**
 * File
 */
export const zFalAiLoraFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: 'The size of the file in bytes.',
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        'The name of the file. It will be auto-generated if not provided.',
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'The mime type of the file.',
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: 'The URL where the file can be downloaded from.',
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: 'File data',
    }),
  ),
})

/**
 * OutputParameters
 */
export const zLoraOutput = z.object({
  images: z.array(zFalAiLoraImage).register(z.globalRegistry, {
    description: 'The generated image files info.',
  }),
  debug_latents: z.optional(zFalAiLoraFile),
  seed: z.int().register(z.globalRegistry, {
    description:
      '\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ',
  }),
  has_nsfw_concepts: z.array(z.boolean()).register(z.globalRegistry, {
    description: 'Whether the generated images contain NSFW concepts.',
  }),
  debug_per_pass_latents: z.optional(zFalAiLoraFile),
})
